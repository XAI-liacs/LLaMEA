{"id": "0343220f-e5cc-4747-a0e5-705d758f5976", "solution": "import numpy as np\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 50\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.inertia_weight = 0.7  # Inertia weight\n        self.mutation_factor = 0.5  # Differential evolution mutation factor\n        self.crossover_prob = 0.7  # Differential evolution crossover probability\n\n    def __call__(self, func):\n        # Initialize swarm positions and velocities\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - swarm) +\n                          self.c2 * r2 * (global_best_position - swarm))\n            swarm = np.clip(swarm + velocities, lb, ub)\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.swarm_size):\n                a, b, c = np.random.choice(self.swarm_size, 3, replace=False)\n                mutant_vector = np.clip(swarm[a] +\n                                        self.mutation_factor * (swarm[b] - swarm[c]), lb, ub)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob,\n                                        mutant_vector, swarm[i])\n\n                # Evaluate new trial vector\n                trial_score = func(trial_vector)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "The proposed algorithm, called \"Hybrid Dynamic Particle Evolution (HDPE),\" combines principles of particle swarm optimization and differential evolution with dynamic adaptation to efficiently explore and exploit the solution space for diverse black-box optimization problems.", "configspace": "", "generation": 0, "fitness": 0.805044397520458, "feedback": "The algorithm HDPE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.805 with standard deviation 0.017. And the mean value of best solutions found was 0.143 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": null, "metadata": {"aucs": [0.7823105751723338, 0.8107380007440392, 0.8220846166450007], "final_y": [0.14276514227501447, 0.1417001869815525, 0.14523040746012916]}, "mutation_prompt": null}
{"id": "6c7be839-f3a9-418c-a15c-1674143961a4", "solution": "import numpy as np\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 50\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.inertia_weight_initial = 0.9  # Initial inertia weight\n        self.inertia_weight_final = 0.4  # Final inertia weight\n        self.mutation_factor = 0.5  # Differential evolution mutation factor\n        self.crossover_prob = 0.7  # Differential evolution crossover probability\n\n    def __call__(self, func):\n        # Initialize swarm positions and velocities\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions\n            inertia_weight = self.inertia_weight_initial - (\n                self.inertia_weight_initial - self.inertia_weight_final) * (evaluations / self.budget)\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            velocities = (inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - swarm) +\n                          self.c2 * r2 * (global_best_position - swarm))\n            swarm = np.clip(swarm + velocities, lb, ub)\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.swarm_size):\n                a, b, c = np.random.choice(self.swarm_size, 3, replace=False)\n                mutant_vector = np.clip(swarm[a] +\n                                        self.mutation_factor * (swarm[b] - swarm[c]), lb, ub)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob,\n                                        mutant_vector, swarm[i])\n\n                # Evaluate new trial vector\n                trial_score = func(trial_vector)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "Improved Hybrid Dynamic Particle Evolution (IHDPE) by incorporating adaptive inertia weight based on evaluations to balance exploration and exploitation.", "configspace": "", "generation": 1, "fitness": 0.8061691126290486, "feedback": "The algorithm HDPE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.806 with standard deviation 0.019. And the mean value of best solutions found was 0.140 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "0343220f-e5cc-4747-a0e5-705d758f5976", "metadata": {"aucs": [0.8284256428488928, 0.8074538260030328, 0.7826278690352203], "final_y": [0.12690655251559213, 0.14169447038283967, 0.15012932864240724]}, "mutation_prompt": null}
{"id": "cf8553f8-5fd5-43f1-b3f0-a8510dc0ba13", "solution": "import numpy as np\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 50\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.inertia_weight = 0.9  # Inertia weight\n        self.mutation_factor = 0.5  # Differential evolution mutation factor\n        self.crossover_prob = 0.7  # Differential evolution crossover probability\n\n    def __call__(self, func):\n        # Initialize swarm positions and velocities\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - swarm) +\n                          self.c2 * r2 * (global_best_position - swarm))\n            swarm = np.clip(swarm + velocities, lb, ub)\n\n            # Differential Evolution mutation and crossover\n            for i in range(self.swarm_size):\n                a, b, c = np.random.choice(self.swarm_size, 3, replace=False)\n                mutant_vector = np.clip(swarm[a] +\n                                        self.mutation_factor * (swarm[b] - swarm[c]), lb, ub)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob,\n                                        mutant_vector, swarm[i])\n\n                # Evaluate new trial vector\n                trial_score = func(trial_vector)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "Enhanced the HDPE algorithm by adjusting the inertia weight for improved balance between exploration and exploitation.", "configspace": "", "generation": 1, "fitness": 0.8060925738605976, "feedback": "The algorithm HDPE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.806 with standard deviation 0.009. And the mean value of best solutions found was 0.142 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "0343220f-e5cc-4747-a0e5-705d758f5976", "metadata": {"aucs": [0.7934952178722989, 0.8103688222196372, 0.8144136814898566], "final_y": [0.15199461894408695, 0.14233280977574325, 0.13263343194703325]}, "mutation_prompt": null}
{"id": "9af3219a-fac9-4d0d-875e-e6da84710bf5", "solution": "import numpy as np\n\nclass AHDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 50\n        self.c1 = 1.5  # Reduced cognitive coefficient\n        self.c2 = 2.5  # Increased social coefficient\n        self.inertia_weight = 0.9  # Increased inertia weight for exploration\n        self.mutation_factor = 0.5\n        self.crossover_prob = 0.9  # Increased crossover probability\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - swarm) +\n                          self.c2 * r2 * (global_best_position - swarm))\n            swarm = np.clip(swarm + velocities, lb, ub)\n\n            for i in range(self.swarm_size):\n                a, b, c = np.random.choice(self.swarm_size, 3, replace=False)\n                mutant_vector = np.clip(swarm[a] +\n                                        self.mutation_factor * (swarm[b] - swarm[c]), lb, ub)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob,\n                                        mutant_vector, swarm[i])\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best_position, global_best_score", "name": "AHDPE", "description": "The improved \"Adaptive Hybrid Dynamic Particle Evolution (AHDPE)\" introduces adaptive learning rates and dynamic crossover to enhance exploration and exploitation balance.", "configspace": "", "generation": 1, "fitness": 0.7976426243212654, "feedback": "The algorithm AHDPE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.798 with standard deviation 0.009. And the mean value of best solutions found was 0.145 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "0343220f-e5cc-4747-a0e5-705d758f5976", "metadata": {"aucs": [0.7865501514465529, 0.7983601090869692, 0.808017612430274], "final_y": [0.1439341335629032, 0.1465700047299885, 0.14395320616338303]}, "mutation_prompt": null}
{"id": "3523af1d-76ee-4459-ba77-7e4472375005", "solution": "import numpy as np\n\nclass ASDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 50\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.7\n        self.mutation_factor = 0.8  # Increased mutation factor for better exploration\n        self.crossover_prob = 0.9  # Increased crossover probability for diversity\n        self.adaptation_rate = 0.1  # New adaptation rate parameter\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - swarm) +\n                          self.c2 * r2 * (global_best_position - swarm))\n            swarm = np.clip(swarm + velocities, lb, ub)\n\n            # Adaptive Differential Evolution\n            for i in range(self.swarm_size):\n                a, b, c = np.random.choice(self.swarm_size, 3, replace=False)\n                mutant_vector = np.clip(swarm[a] +\n                                        self.mutation_factor * (swarm[b] - swarm[c]), lb, ub)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob,\n                                        mutant_vector, swarm[i])\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n                        # Dynamic parameter adaptation\n                        self.mutation_factor = max(0.4, self.mutation_factor - self.adaptation_rate)\n                        self.crossover_prob = min(0.95, self.crossover_prob + self.adaptation_rate)\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best_position, global_best_score", "name": "ASDE", "description": "The improved algorithm, \"Adaptive Swarm-Differential Evolution (ASDE),\" enhances solution precision and convergence speed by dynamically adjusting parameters based on feedback from the search process.", "configspace": "", "generation": 1, "fitness": 0.7943177665572329, "feedback": "The algorithm ASDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.794 with standard deviation 0.017. And the mean value of best solutions found was 0.146 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "0343220f-e5cc-4747-a0e5-705d758f5976", "metadata": {"aucs": [0.7993393902550223, 0.8117688650782913, 0.771845044338385], "final_y": [0.13860195561380395, 0.14019306755612349, 0.15998111845862384]}, "mutation_prompt": null}
{"id": "f972e744-1f5c-4ddf-8103-7e5546ef08c8", "solution": "import numpy as np\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 50\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.inertia_weight = 0.7  # Inertia weight\n        self.mutation_factor = 0.5  # Differential evolution mutation factor\n        self.crossover_prob = 0.7  # Differential evolution crossover probability\n\n    def __call__(self, func):\n        # Initialize swarm positions and velocities\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - swarm) +\n                          self.c2 * r2 * (global_best_position - swarm))\n            swarm = np.clip(swarm + velocities, lb, ub)\n\n            # Differential Evolution mutation and crossover\n            self.crossover_prob = 0.7 + 0.3 * (1 - evaluations / self.budget)  # Adaptive crossover probability\n            for i in range(self.swarm_size):\n                a, b, c = np.random.choice(self.swarm_size, 3, replace=False)\n                mutant_vector = np.clip(swarm[a] +\n                                        self.mutation_factor * (swarm[b] - swarm[c]), lb, ub)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob,\n                                        mutant_vector, swarm[i])\n\n                # Evaluate new trial vector\n                trial_score = func(trial_vector)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "The improved HDPE algorithm introduces an adaptive crossover probability to enhance exploration and exploitation balance.", "configspace": "", "generation": 1, "fitness": 0.8128587001240231, "feedback": "The algorithm HDPE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.813 with standard deviation 0.010. And the mean value of best solutions found was 0.139 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "0343220f-e5cc-4747-a0e5-705d758f5976", "metadata": {"aucs": [0.8238488843396623, 0.8147818588215976, 0.7999453572108091], "final_y": [0.13528533198274073, 0.14247704127900085, 0.1386118279642783]}, "mutation_prompt": null}
{"id": "f6aa9a58-debd-4679-808a-816ae3472d17", "solution": "import numpy as np\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 50\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.inertia_weight = 0.7  # Inertia weight\n        self.mutation_factor = 0.5  # Differential evolution mutation factor\n        self.crossover_prob = 0.7  # Differential evolution crossover probability\n\n    def __call__(self, func):\n        # Initialize swarm positions and velocities\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            # Dynamically adjust swarm size\n            self.swarm_size = int(50 * (1 + evaluations / self.budget)) \n\n            # Update velocities and positions\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - swarm) +\n                          self.c2 * r2 * (global_best_position - swarm))\n            swarm = np.clip(swarm + velocities, lb, ub)\n\n            # Differential Evolution mutation and crossover\n            self.crossover_prob = 0.7 + 0.3 * (1 - evaluations / self.budget)  # Adaptive crossover probability\n            for i in range(self.swarm_size):\n                a, b, c = np.random.choice(self.swarm_size, 3, replace=False)\n                mutant_vector = np.clip(swarm[a] +\n                                        self.mutation_factor * (swarm[b] - swarm[c]), lb, ub)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob,\n                                        mutant_vector, swarm[i])\n\n                # Evaluate new trial vector\n                trial_score = func(trial_vector)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "Enhance global exploration by dynamically adjusting the swarm size based on the remaining budget.", "configspace": "", "generation": 2, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 50 is out of bounds for axis 0 with size 50').", "error": "IndexError('index 50 is out of bounds for axis 0 with size 50')", "parent_id": "f972e744-1f5c-4ddf-8103-7e5546ef08c8", "metadata": {}, "mutation_prompt": null}
{"id": "a6102dad-94a7-4e75-bcbb-1136c5d69ceb", "solution": "import numpy as np\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 50\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.inertia_weight = 0.7  # Inertia weight\n        self.mutation_factor = 0.5  # Differential evolution mutation factor\n        self.crossover_prob = 0.7  # Differential evolution crossover probability\n\n    def __call__(self, func):\n        # Initialize swarm positions and velocities\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.inertia_weight = 0.7 - 0.5 * (evaluations / self.budget)  # Adaptive inertia weight\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - swarm) +\n                          self.c2 * r2 * (global_best_position - swarm))\n            swarm = np.clip(swarm + velocities, lb, ub)\n\n            # Differential Evolution mutation and crossover\n            self.crossover_prob = 0.7 + 0.3 * (1 - evaluations / self.budget)  # Adaptive crossover probability\n            for i in range(self.swarm_size):\n                a, b, c = np.random.choice(self.swarm_size, 3, replace=False)\n                mutant_vector = np.clip(swarm[a] +\n                                        self.mutation_factor * (swarm[b] - swarm[c]), lb, ub)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob,\n                                        mutant_vector, swarm[i])\n\n                # Evaluate new trial vector\n                trial_score = func(trial_vector)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "Refinement of HDPE by introducing adaptive inertia weight to balance exploration and exploitation better.", "configspace": "", "generation": 2, "fitness": 0.7867171933177087, "feedback": "The algorithm HDPE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.787 with standard deviation 0.022. And the mean value of best solutions found was 0.146 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "f972e744-1f5c-4ddf-8103-7e5546ef08c8", "metadata": {"aucs": [0.7571387035968974, 0.8077180792235379, 0.7952947971326906], "final_y": [0.15251544623303026, 0.14083806878618843, 0.1433013228712594]}, "mutation_prompt": null}
{"id": "ed795075-195d-4cb1-a3b1-9638f7364ca0", "solution": "import numpy as np\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 50\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.inertia_weight = 0.7  # Inertia weight\n        self.mutation_factor = 0.5  # Differential evolution mutation factor\n        self.crossover_prob = 0.7  # Differential evolution crossover probability\n\n    def __call__(self, func):\n        # Initialize swarm positions and velocities\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            # Update velocities and positions\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            self.inertia_weight = 0.9 - 0.5 * (evaluations / self.budget)  # Dynamic inertia weight\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - swarm) +\n                          self.c2 * r2 * (global_best_position - swarm))\n            swarm = np.clip(swarm + velocities, lb, ub)\n\n            # Differential Evolution mutation and crossover\n            self.crossover_prob = 0.7 + 0.3 * (1 - evaluations / self.budget)  # Adaptive crossover probability\n            for i in range(self.swarm_size):\n                a, b, c = np.random.choice(self.swarm_size, 3, replace=False)\n                mutant_vector = np.clip(swarm[a] +\n                                        self.mutation_factor * (swarm[b] - swarm[c]), lb, ub)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob,\n                                        mutant_vector, swarm[i])\n\n                # Evaluate new trial vector\n                trial_score = func(trial_vector)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "The enhanced HDPE introduces dynamic inertia weight to improve convergence towards optimal solutions by balancing exploration and exploitation.", "configspace": "", "generation": 2, "fitness": 0.8114399623114584, "feedback": "The algorithm HDPE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.811 with standard deviation 0.017. And the mean value of best solutions found was 0.132 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "f972e744-1f5c-4ddf-8103-7e5546ef08c8", "metadata": {"aucs": [0.7870505314866751, 0.8227722529809474, 0.8244971024667527], "final_y": [0.13653969865449933, 0.13491092628992485, 0.12504836269078634]}, "mutation_prompt": null}
{"id": "f4f47707-43c5-42b4-b106-bb25a277cc9f", "solution": "import numpy as np\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 50\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.inertia_weight = 0.9  # Increased initial inertia weight\n        self.mutation_factor = 0.5  # Differential evolution mutation factor\n        self.crossover_prob = 0.7  # Differential evolution crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            # Decrease inertia weight adaptively\n            self.inertia_weight = 0.4 + 0.5 * (self.budget - evaluations) / self.budget\n            \n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - swarm) +\n                          self.c2 * r2 * (global_best_position - swarm))\n            swarm = np.clip(swarm + velocities, lb, ub)\n\n            self.crossover_prob = 0.7 + 0.3 * (1 - evaluations / self.budget)\n            for i in range(self.swarm_size):\n                a, b, c = np.random.choice(self.swarm_size, 3, replace=False)\n                mutant_vector = np.clip(swarm[a] +\n                                        self.mutation_factor * (swarm[b] - swarm[c]), lb, ub)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob,\n                                        mutant_vector, swarm[i])\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "Enhanced HDPE with adaptive inertia weight and elitist strategy for improved convergence.", "configspace": "", "generation": 2, "fitness": 0.8146953899710839, "feedback": "The algorithm HDPE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.815 with standard deviation 0.026. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "f972e744-1f5c-4ddf-8103-7e5546ef08c8", "metadata": {"aucs": [0.7828484931388416, 0.8466152050444954, 0.8146224717299149], "final_y": [0.14659239106466448, 0.12363574787431664, 0.12817387938999625]}, "mutation_prompt": null}
{"id": "eb71c52f-57e9-4af7-a302-21cc9c354e96", "solution": "import numpy as np\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 50\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.inertia_weight = 0.9  # Initial inertia weight, changed\n        self.mutation_factor = 0.5  # Differential evolution mutation factor\n        self.crossover_prob = 0.7  # Differential evolution crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight, changed\n            self.inertia_weight = 0.9 - 0.5 * (evaluations / self.budget)\n\n            # Update velocities and positions\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - swarm) +\n                          self.c2 * r2 * (global_best_position - swarm))\n            swarm = np.clip(swarm + velocities, lb, ub)\n\n            # Differential Evolution mutation and crossover\n            self.crossover_prob = 0.7 + 0.3 * (1 - evaluations / self.budget) \n            for i in range(self.swarm_size):\n                a, b, c = np.random.choice(self.swarm_size, 3, replace=False)\n                # Biodiversity preservation: ensure distinct selections, changed\n                while len({a, b, c, i}) < 4:\n                    a, b, c = np.random.choice(self.swarm_size, 3, replace=False)\n                mutant_vector = np.clip(swarm[a] +\n                                        self.mutation_factor * (swarm[b] - swarm[c]), lb, ub)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob,\n                                        mutant_vector, swarm[i])\n\n                # Evaluate new trial vector\n                trial_score = func(trial_vector)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "Enhanced HDPE with adaptive inertia weight and biodiversity preservation for improved exploration-exploitation balance.", "configspace": "", "generation": 2, "fitness": 0.8276145101714799, "feedback": "The algorithm HDPE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.828 with standard deviation 0.018. And the mean value of best solutions found was 0.130 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "f972e744-1f5c-4ddf-8103-7e5546ef08c8", "metadata": {"aucs": [0.8171072918638816, 0.8122680983629872, 0.8534681402875709], "final_y": [0.12855350959618694, 0.13499351955302896, 0.12516745589422462]}, "mutation_prompt": null}
{"id": "e62199ec-bf52-440a-981b-e7b872f1ca7a", "solution": "import numpy as np\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 50\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.inertia_weight = 0.9\n        self.mutation_factor = 0.5\n        self.crossover_prob = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = 0.9 - 0.5 * (evaluations / self.budget)\n\n            # Adaptive learning coefficients, changed\n            self.c1 = 2.5 - 1.5 * (evaluations / self.budget)\n            self.c2 = 0.5 + 1.5 * (evaluations / self.budget)\n\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - swarm) +\n                          self.c2 * r2 * (global_best_position - swarm))\n            swarm = np.clip(swarm + velocities, lb, ub)\n\n            self.crossover_prob = 0.7 + 0.3 * (1 - evaluations / self.budget) \n            for i in range(self.swarm_size):\n                a, b, c = np.random.choice(self.swarm_size, 3, replace=False)\n                while len({a, b, c, i}) < 4:\n                    a, b, c = np.random.choice(self.swarm_size, 3, replace=False)\n                # Dynamic mutation factor, changed\n                scaled_mutation_factor = self.mutation_factor * (1 + 0.5 * np.random.rand())\n                mutant_vector = np.clip(swarm[a] +\n                                        scaled_mutation_factor * (swarm[b] - swarm[c]), lb, ub)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob,\n                                        mutant_vector, swarm[i])\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "HDPE with Adaptive Inertia, Dynamic Mutation, and Adaptive Learning Coefficients for Enhanced Convergence.", "configspace": "", "generation": 3, "fitness": 0.7943071831328187, "feedback": "The algorithm HDPE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.794 with standard deviation 0.002. And the mean value of best solutions found was 0.141 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "eb71c52f-57e9-4af7-a302-21cc9c354e96", "metadata": {"aucs": [0.7910522267061167, 0.7967647326245029, 0.7951045900678366], "final_y": [0.13878063729421686, 0.1532127371586942, 0.1311637718358971]}, "mutation_prompt": null}
{"id": "d3efb18a-85a4-4ef3-8070-07a9400c242d", "solution": "import numpy as np\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_swarm_size = 50\n        self.min_swarm_size = 25\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.9\n        self.initial_mutation_factor = 0.5\n        self.crossover_prob = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm_size = self.initial_swarm_size\n        swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = swarm_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = 0.9 - 0.5 * (evaluations / self.budget)\n\n            # Adaptive mutation factor\n            self.mutation_factor = self.initial_mutation_factor + 0.2 * (evaluations / self.budget)\n\n            # Update velocities and positions\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - swarm) +\n                          self.c2 * r2 * (global_best_position - swarm))\n            swarm = np.clip(swarm + velocities, lb, ub)\n\n            self.crossover_prob = 0.7 + 0.3 * (1 - evaluations / self.budget)\n\n            for i in range(swarm_size):\n                a, b, c = np.random.choice(swarm_size, 3, replace=False)\n                while len({a, b, c, i}) < 4:\n                    a, b, c = np.random.choice(swarm_size, 3, replace=False)\n                mutant_vector = np.clip(swarm[a] +\n                                        self.mutation_factor * (swarm[b] - swarm[c]), lb, ub)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob,\n                                        mutant_vector, swarm[i])\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n            # Dynamic swarm size\n            if evaluations % (self.budget // 10) == 0:\n                swarm_size = max(self.min_swarm_size, swarm_size - 5)\n                swarm = swarm[:swarm_size]\n                velocities = velocities[:swarm_size]\n                personal_best_positions = personal_best_positions[:swarm_size]\n                personal_best_scores = personal_best_scores[:swarm_size]\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "HDPE with adaptive mutation factor and dynamic swarm size for enhanced convergence.", "configspace": "", "generation": 3, "fitness": 0.810317380380838, "feedback": "The algorithm HDPE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.810 with standard deviation 0.007. And the mean value of best solutions found was 0.134 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "eb71c52f-57e9-4af7-a302-21cc9c354e96", "metadata": {"aucs": [0.7998877791442941, 0.81718460687095, 0.8138797551272698], "final_y": [0.13639005097032741, 0.1348522894079972, 0.12943667069987652]}, "mutation_prompt": null}
{"id": "43eab106-3fb2-4e71-92a6-f3058aed8fca", "solution": "import numpy as np\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 50\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.inertia_weight = 0.9  # Initial inertia weight\n        self.mutation_factor = 0.5  # Differential evolution mutation factor\n        self.crossover_prob = 0.7  # Differential evolution crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight\n            self.inertia_weight = 0.9 - 0.5 * (evaluations / self.budget)\n\n            # Update velocities and positions\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - swarm) +\n                          self.c2 * r2 * (global_best_position - swarm))\n            swarm = np.clip(swarm + velocities, lb, ub)\n\n            # Differential Evolution mutation and crossover\n            self.crossover_prob = 0.7 + 0.3 * (1 - evaluations / self.budget) \n            self.mutation_factor = 0.5 + 0.3 * (evaluations / self.budget)  # Change made here\n            for i in range(self.swarm_size):\n                a, b, c = np.random.choice(self.swarm_size, 3, replace=False)\n                # Biodiversity preservation: ensure distinct selections\n                while len({a, b, c, i}) < 4:\n                    a, b, c = np.random.choice(self.swarm_size, 3, replace=False)\n                mutant_vector = np.clip(swarm[a] +\n                                        self.mutation_factor * (swarm[b] - swarm[c]), lb, ub)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob,\n                                        mutant_vector, swarm[i])\n\n                # Evaluate new trial vector\n                trial_score = func(trial_vector)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "Improved exploration-exploitation by adjusting mutation factor based on evaluations.", "configspace": "", "generation": 3, "fitness": 0.8060689266165806, "feedback": "The algorithm HDPE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.806 with standard deviation 0.036. And the mean value of best solutions found was 0.136 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "eb71c52f-57e9-4af7-a302-21cc9c354e96", "metadata": {"aucs": [0.7676037295621937, 0.8536016551379956, 0.7970013951495524], "final_y": [0.1438990240592798, 0.1270243411193086, 0.1380965767607163]}, "mutation_prompt": null}
{"id": "beb542f4-86f9-4917-a01e-6ee49c0b0031", "solution": "import numpy as np\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 50\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.inertia_weight = 0.9  # Initial inertia weight, changed\n        self.mutation_factor = 0.5  # Differential evolution mutation factor\n        self.crossover_prob = 0.7  # Differential evolution crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight, changed\n            self.inertia_weight = 0.9 - 0.5 * (evaluations / self.budget)\n\n            # Update velocities and positions\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - swarm) +\n                          self.c2 * r2 * (global_best_position - swarm))\n            swarm = np.clip(swarm + velocities, lb, ub)\n\n            # Differential Evolution mutation and crossover\n            self.mutation_factor = 0.5 + 0.3 * (evaluations / self.budget)  # Adaptive mutation factor based on budget utilization\n            self.crossover_prob = 0.7 + 0.3 * (1 - evaluations / self.budget) \n            for i in range(self.swarm_size):\n                a, b, c = np.random.choice(self.swarm_size, 3, replace=False)\n                # Biodiversity preservation: ensure distinct selections, changed\n                while len({a, b, c, i}) < 4:\n                    a, b, c = np.random.choice(self.swarm_size, 3, replace=False)\n                mutant_vector = np.clip(swarm[a] +\n                                        self.mutation_factor * (swarm[b] - swarm[c]), lb, ub)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob,\n                                        mutant_vector, swarm[i])\n\n                # Evaluate new trial vector\n                trial_score = func(trial_vector)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "Integrate adaptive mutation factor based on budget utilization to enhance exploration and exploitation balance.", "configspace": "", "generation": 3, "fitness": 0.8036696289301006, "feedback": "The algorithm HDPE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.804 with standard deviation 0.014. And the mean value of best solutions found was 0.136 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "eb71c52f-57e9-4af7-a302-21cc9c354e96", "metadata": {"aucs": [0.7916704869661061, 0.8227211646347029, 0.7966172351894929], "final_y": [0.1435884419080795, 0.13179113939030807, 0.1332068179732817]}, "mutation_prompt": null}
{"id": "e7d9054e-fb8b-4c30-ba57-72651ada79ec", "solution": "import numpy as np\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 50\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.inertia_weight = 0.9  # Initial inertia weight, changed\n        self.mutation_factor = 0.5  # Differential evolution mutation factor\n        self.crossover_prob = 0.7  # Differential evolution crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = self.swarm_size\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight, changed\n            self.inertia_weight = 0.9 - 0.5 * (evaluations / self.budget)\n\n            # Update velocities and positions\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - swarm) +\n                          self.c2 * r2 * (global_best_position - swarm))\n            swarm = np.clip(swarm + velocities, lb, ub)\n\n            # Differential Evolution mutation and crossover\n            self.crossover_prob = 0.7 + 0.3 * ((1 - evaluations / self.budget) ** 2)  # Changed\n            for i in range(self.swarm_size):\n                a, b, c = np.random.choice(self.swarm_size, 3, replace=False)\n                # Biodiversity preservation: ensure distinct selections, changed\n                while len({a, b, c, i}) < 4:\n                    a, b, c = np.random.choice(self.swarm_size, 3, replace=False)\n                mutant_vector = np.clip(swarm[a] +\n                                        self.mutation_factor * (swarm[b] - swarm[c]), lb, ub)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob,\n                                        mutant_vector, swarm[i])\n\n                # Evaluate new trial vector\n                trial_score = func(trial_vector)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "HDPE with adaptive inertia and improved crossover probability decay for enhanced convergence.", "configspace": "", "generation": 3, "fitness": 0.8009995661305785, "feedback": "The algorithm HDPE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.801 with standard deviation 0.010. And the mean value of best solutions found was 0.142 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "eb71c52f-57e9-4af7-a302-21cc9c354e96", "metadata": {"aucs": [0.7880995013105674, 0.8018507013570209, 0.8130484957241473], "final_y": [0.14028400886546966, 0.1506250660174625, 0.135494142640466]}, "mutation_prompt": null}
{"id": "e39b9499-f88b-479a-ba44-6ac1140447e8", "solution": "import numpy as np\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_swarm_size = 50\n        self.min_swarm_size = 25\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.9\n        self.initial_mutation_factor = 0.5\n        self.crossover_prob = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm_size = self.initial_swarm_size\n        swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = swarm_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = 0.9 - 0.5 * (evaluations / self.budget)\n\n            # Enhanced adaptive mutation factor\n            self.mutation_factor = self.initial_mutation_factor + 0.3 * (evaluations / self.budget)\n\n            # Update velocities and positions\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - swarm) +\n                          self.c2 * r2 * (global_best_position - swarm))\n            swarm = np.clip(swarm + velocities, lb, ub)\n\n            self.crossover_prob = 0.7 + 0.3 * (1 - evaluations / self.budget)\n\n            for i in range(swarm_size):\n                a, b, c = np.random.choice(swarm_size, 3, replace=False)\n                while len({a, b, c, i}) < 4:\n                    a, b, c = np.random.choice(swarm_size, 3, replace=False)\n                mutant_vector = np.clip(swarm[a] +\n                                        self.mutation_factor * (swarm[b] - swarm[c]), lb, ub)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob,\n                                        mutant_vector, swarm[i])\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n            # Dynamic swarm size\n            if evaluations % (self.budget // 10) == 0:\n                swarm_size = max(self.min_swarm_size, swarm_size - 5)\n                swarm = swarm[:swarm_size]\n                velocities = velocities[:swarm_size]\n                personal_best_positions = personal_best_positions[:swarm_size]\n                personal_best_scores = personal_best_scores[:swarm_size]\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "HDPE with enhanced adaptive mutation factor dynamics for improved convergence.", "configspace": "", "generation": 4, "fitness": 0.7958763681908111, "feedback": "The algorithm HDPE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.796 with standard deviation 0.013. And the mean value of best solutions found was 0.136 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "d3efb18a-85a4-4ef3-8070-07a9400c242d", "metadata": {"aucs": [0.7841082559139709, 0.8145328096500477, 0.7889880390084149], "final_y": [0.13577505107298837, 0.12812091742768772, 0.14550267294007024]}, "mutation_prompt": null}
{"id": "34871bd1-c029-4444-aa93-256ab3bcdc5a", "solution": "import numpy as np\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_swarm_size = 50\n        self.min_swarm_size = 25\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.9\n        self.initial_mutation_factor = 0.5\n        self.crossover_prob = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm_size = self.initial_swarm_size\n        swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = swarm_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = 0.9 - 0.5 / (1 + np.exp(-(10 * evaluations / self.budget - 5)))\n\n            # Adaptive mutation factor\n            self.mutation_factor = self.initial_mutation_factor + 0.2 * (evaluations / self.budget)\n\n            # Update velocities and positions\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - swarm) +\n                          self.c2 * r2 * (global_best_position - swarm))\n            swarm = np.clip(swarm + velocities, lb, ub)\n\n            self.crossover_prob = 0.7 + 0.3 * (1 - evaluations / self.budget)\n\n            for i in range(swarm_size):\n                a, b, c = np.random.choice(swarm_size, 3, replace=False)\n                while len({a, b, c, i}) < 4:\n                    a, b, c = np.random.choice(swarm_size, 3, replace=False)\n                mutant_vector = np.clip(swarm[a] +\n                                        self.mutation_factor * (swarm[b] - swarm[c]), lb, ub)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob,\n                                        mutant_vector, swarm[i])\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n            # Dynamic swarm size\n            if evaluations % (self.budget // 10) == 0:\n                swarm_size = max(self.min_swarm_size, swarm_size - 5)\n                swarm = swarm[:swarm_size]\n                velocities = velocities[:swarm_size]\n                personal_best_positions = personal_best_positions[:swarm_size]\n                personal_best_scores = personal_best_scores[:swarm_size]\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "Refine HDPE by introducing sigmoid decay for inertia weight to enhance convergence.", "configspace": "", "generation": 4, "fitness": 0.8106858863728928, "feedback": "The algorithm HDPE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.811 with standard deviation 0.004. And the mean value of best solutions found was 0.140 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "d3efb18a-85a4-4ef3-8070-07a9400c242d", "metadata": {"aucs": [0.8067391520876913, 0.8156547393222672, 0.8096637677087202], "final_y": [0.13221529154281364, 0.1457377725374317, 0.14327445055485155]}, "mutation_prompt": null}
{"id": "819cee8e-6cf1-4563-b8d7-c01c1ca02d78", "solution": "import numpy as np\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_swarm_size = 60  # Adjusted initial swarm size\n        self.min_swarm_size = 25\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.9\n        self.initial_mutation_factor = 0.5\n        self.crossover_prob = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm_size = self.initial_swarm_size\n        swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = swarm_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = 0.9 - 0.5 * (evaluations / self.budget)\n\n            # Adaptive mutation factor\n            self.mutation_factor = self.initial_mutation_factor + 0.2 * (evaluations / self.budget)\n\n            # Update velocities and positions\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - swarm) +\n                          self.c2 * r2 * (global_best_position - swarm))\n            swarm = np.clip(swarm + velocities, lb, ub)\n\n            self.crossover_prob = 0.7 + 0.3 * (1 - evaluations / self.budget)\n\n            for i in range(swarm_size):\n                a, b, c = np.random.choice(swarm_size, 3, replace=False)\n                while len({a, b, c, i}) < 4:\n                    a, b, c = np.random.choice(swarm_size, 3, replace=False)\n                mutant_vector = np.clip(swarm[a] +\n                                        self.mutation_factor * (swarm[b] - swarm[c]), lb, ub)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob,\n                                        mutant_vector, swarm[i])\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n            # Dynamic swarm size\n            if evaluations % (self.budget // 10) == 0:\n                swarm_size = max(self.min_swarm_size, swarm_size - 5)\n                swarm = swarm[:swarm_size]\n                velocities = velocities[:swarm_size]\n                personal_best_positions = personal_best_positions[:swarm_size]\n                personal_best_scores = personal_best_scores[:swarm_size]\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "Enhanced HDPE with calibrated initial swarm size for improved performance.", "configspace": "", "generation": 4, "fitness": 0.8082522659940993, "feedback": "The algorithm HDPE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.808 with standard deviation 0.010. And the mean value of best solutions found was 0.142 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "d3efb18a-85a4-4ef3-8070-07a9400c242d", "metadata": {"aucs": [0.8140069134524943, 0.8161512911140655, 0.7945985934157379], "final_y": [0.14141388922969667, 0.14028458244542052, 0.14429787323895293]}, "mutation_prompt": null}
{"id": "8b492ab8-5dbe-400d-8978-0f4c5562a2c0", "solution": "import numpy as np\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_swarm_size = 50\n        self.min_swarm_size = 25\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.9\n        self.initial_mutation_factor = 0.5\n        self.crossover_prob = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm_size = self.initial_swarm_size\n        swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = swarm_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = 0.9 - 0.5 * (evaluations / self.budget)\n\n            # Adaptive velocity scaling\n            velocities *= 0.9 + 0.1 * np.random.rand()\n\n            # Adaptive mutation factor\n            self.mutation_factor = self.initial_mutation_factor + 0.2 * (evaluations / self.budget)\n\n            # Update velocities and positions\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - swarm) +\n                          self.c2 * r2 * (global_best_position - swarm))\n            swarm = np.clip(swarm + velocities, lb, ub)\n\n            self.crossover_prob = 0.7 + 0.3 * (1 - evaluations / self.budget)\n\n            for i in range(swarm_size):\n                a, b, c = np.random.choice(swarm_size, 3, replace=False)\n                while len({a, b, c, i}) < 4:\n                    a, b, c = np.random.choice(swarm_size, 3, replace=False)\n                mutant_vector = np.clip(swarm[a] +\n                                        self.mutation_factor * (swarm[b] - swarm[c]), lb, ub)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob,\n                                        mutant_vector, swarm[i])\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n            # Dynamic swarm size\n            if evaluations % (self.budget // 10) == 0:\n                swarm_size = max(self.min_swarm_size, swarm_size - 5)\n                swarm = swarm[:swarm_size]\n                velocities = velocities[:swarm_size]\n                personal_best_positions = personal_best_positions[:swarm_size]\n                personal_best_scores = personal_best_scores[:swarm_size]\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "HDPE with adaptive velocity scaling for improved exploration-exploitation balance.", "configspace": "", "generation": 4, "fitness": 0.7970217550146211, "feedback": "The algorithm HDPE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.797 with standard deviation 0.013. And the mean value of best solutions found was 0.141 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "d3efb18a-85a4-4ef3-8070-07a9400c242d", "metadata": {"aucs": [0.7855540907890253, 0.8154907026343093, 0.7900204716205292], "final_y": [0.1293467057008637, 0.14598970681497137, 0.14620910449538815]}, "mutation_prompt": null}
{"id": "4e099a6a-bfc3-4e1f-a369-00bb8d6c0534", "solution": "import numpy as np\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_swarm_size = 50\n        self.min_swarm_size = 25\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.9\n        self.initial_mutation_factor = 0.5\n        self.crossover_prob = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm_size = self.initial_swarm_size\n        swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = swarm_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = 0.9 - 0.5 * (evaluations / self.budget)\n\n            # Adaptive mutation factor\n            self.mutation_factor = self.initial_mutation_factor + 0.2 * (evaluations / self.budget)\n\n            # Adaptive learning rates\n            self.c1 = 1.5 + 0.5 * (1 - evaluations / self.budget)\n            self.c2 = 1.5 + 0.5 * (evaluations / self.budget)\n\n            # Update velocities and positions\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - swarm) +\n                          self.c2 * r2 * (global_best_position - swarm))\n            swarm = np.clip(swarm + velocities, lb, ub)\n\n            self.crossover_prob = 0.7 + 0.3 * (1 - evaluations / self.budget)\n\n            for i in range(swarm_size):\n                a, b, c = np.random.choice(swarm_size, 3, replace=False)\n                while len({a, b, c, i}) < 4:\n                    a, b, c = np.random.choice(swarm_size, 3, replace=False)\n                mutant_vector = np.clip(swarm[a] +\n                                        self.mutation_factor * (swarm[b] - swarm[c]), lb, ub)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob,\n                                        mutant_vector, swarm[i])\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n            # Dynamic swarm size\n            if evaluations % (self.budget // 10) == 0:\n                swarm_size = max(self.min_swarm_size, swarm_size - 5)\n                swarm = swarm[:swarm_size]\n                velocities = velocities[:swarm_size]\n                personal_best_positions = personal_best_positions[:swarm_size]\n                personal_best_scores = personal_best_scores[:swarm_size]\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "HDPE with adaptive learning rates and enhanced local search for improved solution quality.", "configspace": "", "generation": 4, "fitness": 0.8071714765228912, "feedback": "The algorithm HDPE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.807 with standard deviation 0.003. And the mean value of best solutions found was 0.136 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "d3efb18a-85a4-4ef3-8070-07a9400c242d", "metadata": {"aucs": [0.805998452941401, 0.8110755461921476, 0.8044404304351248], "final_y": [0.12177466400497172, 0.1332478284640798, 0.15202436058216007]}, "mutation_prompt": null}
{"id": "f7bded65-b296-45a1-b823-3c6a2f5bf05f", "solution": "import numpy as np\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_swarm_size = 50\n        self.min_swarm_size = 25\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.9\n        self.initial_mutation_factor = 0.5\n        self.crossover_prob = 0.7\n\n    def levy_flight(self, dim):\n        beta = 1.5\n        sigma = (np.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.randn(dim) * sigma\n        v = np.random.randn(dim)\n        step = u / abs(v)**(1 / beta)\n        return step\n\n    def chaotic_local_search(self, position, lb, ub):\n        a = 0.5\n        b = 3.0\n        chaotic_sequence = a + (b - a) * np.random.rand(self.dim)\n        new_position = np.clip(position + chaotic_sequence * (ub - lb) * 0.01, lb, ub)\n        return new_position\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm_size = self.initial_swarm_size\n        swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = swarm_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = 0.9 - 0.5 / (1 + np.exp(-(10 * evaluations / self.budget - 5)))\n            self.mutation_factor = self.initial_mutation_factor + 0.2 * (evaluations / self.budget)\n\n            for i in range(swarm_size):\n                if np.random.rand() < 0.5:\n                    swarm[i] += self.levy_flight(self.dim)\n                else:\n                    swarm[i] = self.chaotic_local_search(swarm[i], lb, ub)\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                trial_score = func(swarm[i])\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = swarm[i]\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = swarm[i]\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n            if evaluations % (self.budget // 10) == 0:\n                swarm_size = max(self.min_swarm_size, swarm_size - 5)\n                swarm = swarm[:swarm_size]\n                velocities = velocities[:swarm_size]\n                personal_best_positions = personal_best_positions[:swarm_size]\n                personal_best_scores = personal_best_scores[:swarm_size]\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "\"Enhance HDPE by incorporating Levy flights for exploration and chaotic local search for exploitation.\"", "configspace": "", "generation": 5, "fitness": -Infinity, "feedback": "An exception occurred: AttributeError(\"module 'numpy' has no attribute 'gamma'\").", "error": "AttributeError(\"module 'numpy' has no attribute 'gamma'\")", "parent_id": "34871bd1-c029-4444-aa93-256ab3bcdc5a", "metadata": {}, "mutation_prompt": null}
{"id": "02fb7832-3059-4703-a9bb-66b8af50e8b3", "solution": "import numpy as np\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_swarm_size = 50\n        self.min_swarm_size = 25\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.9\n        self.initial_mutation_factor = 0.5\n        self.crossover_prob = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm_size = self.initial_swarm_size\n        swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = swarm_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = 0.9 - 0.5 / (1 + np.exp(-(10 * evaluations / self.budget - 5)))\n            # Dynamic learning rate\n            dynamic_lr = 0.5 + 0.5 * (evaluations / self.budget)\n\n            # Adaptive mutation factor\n            self.mutation_factor = self.initial_mutation_factor + 0.2 * (evaluations / self.budget)\n\n            # Update velocities and positions\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          dynamic_lr * self.c1 * r1 * (personal_best_positions - swarm) +\n                          self.c2 * r2 * (global_best_position - swarm))\n            swarm = np.clip(swarm + velocities, lb, ub)\n\n            # Introduce perturbation for best positions\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            self.crossover_prob = 0.7 + 0.3 * (1 - evaluations / self.budget)\n\n            for i in range(swarm_size):\n                a, b, c = np.random.choice(swarm_size, 3, replace=False)\n                while len({a, b, c, i}) < 4:\n                    a, b, c = np.random.choice(swarm_size, 3, replace=False)\n                mutant_vector = np.clip(swarm[a] +\n                                        self.mutation_factor * (swarm[b] - swarm[c]), lb, ub)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob,\n                                        mutant_vector, swarm[i])\n\n                trial_score = func(trial_vector + perturbation)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n            # Dynamic swarm size\n            if evaluations % (self.budget // 10) == 0:\n                swarm_size = max(self.min_swarm_size, swarm_size - 5)\n                swarm = swarm[:swarm_size]\n                velocities = velocities[:swarm_size]\n                personal_best_positions = personal_best_positions[:swarm_size]\n                personal_best_scores = personal_best_scores[:swarm_size]\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "Refine HDPE by adding a dynamic learning rate and introducing a perturbation factor for personal best updates to enhance exploration and exploitation balance.", "configspace": "", "generation": 5, "fitness": -Infinity, "feedback": "An exception occurred: AttributeError(\"module 'numpy' has no attribute 'gamma'\").", "error": "AttributeError(\"module 'numpy' has no attribute 'gamma'\")", "parent_id": "34871bd1-c029-4444-aa93-256ab3bcdc5a", "metadata": {}, "mutation_prompt": null}
{"id": "cb5c5431-3ff2-4e71-bfea-4f8bda48ad3e", "solution": "import numpy as np\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_swarm_size = 50\n        self.min_swarm_size = 20\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.9\n        self.initial_mutation_factor = 0.5\n        self.crossover_prob = 0.7\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm_size = self.initial_swarm_size\n        swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = swarm_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = 0.4 + 0.5 * (np.cos(np.pi * evaluations / self.budget))\n\n            # Adaptive mutation factor\n            self.mutation_factor = self.initial_mutation_factor + 0.2 * (evaluations / self.budget)\n\n            # Update velocities and positions\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - swarm) +\n                          self.c2 * r2 * (global_best_position - swarm))\n            swarm = np.clip(swarm + velocities, lb, ub)\n\n            self.crossover_prob = 0.7 + 0.3 * (1 - evaluations / self.budget)\n\n            for i in range(swarm_size):\n                a, b, c = np.random.choice(swarm_size, 3, replace=False)\n                while len({a, b, c, i}) < 4:\n                    a, b, c = np.random.choice(swarm_size, 3, replace=False)\n                mutant_vector = np.clip(swarm[a] +\n                                        self.mutation_factor * (swarm[b] - swarm[c]), lb, ub)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob,\n                                        mutant_vector, swarm[i])\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n            # Dynamic swarm size based on diversity\n            if np.std(personal_best_scores) < 1e-3:\n                swarm_size = max(self.min_swarm_size, swarm_size - 5)\n            swarm = swarm[:swarm_size]\n            velocities = velocities[:swarm_size]\n            personal_best_positions = personal_best_positions[:swarm_size]\n            personal_best_scores = personal_best_scores[:swarm_size]\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "Enhance HDPE by incorporating a cosine decay for inertia weight and adaptive swarm size based on fitness diversity.", "configspace": "", "generation": 5, "fitness": -Infinity, "feedback": "An exception occurred: AttributeError(\"module 'numpy' has no attribute 'gamma'\").", "error": "AttributeError(\"module 'numpy' has no attribute 'gamma'\")", "parent_id": "34871bd1-c029-4444-aa93-256ab3bcdc5a", "metadata": {}, "mutation_prompt": null}
{"id": "c02f5e5c-012e-48b0-a3a9-e7bbab21a540", "solution": "import numpy as np\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_swarm_size = 50\n        self.min_swarm_size = 25\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.9\n        self.initial_mutation_factor = 0.5\n        self.crossover_prob = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm_size = self.initial_swarm_size\n        swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = swarm_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = 0.9 - 0.5 / (1 + np.exp(-(10 * evaluations / self.budget - 5)))\n\n            # Adaptive mutation factor\n            self.mutation_factor = self.initial_mutation_factor + 0.2 * (evaluations / self.budget)\n\n            # Update velocities and positions\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.c1 * r1 * (personal_best_positions - swarm) +\n                          self.c2 * r2 * (global_best_position - swarm))\n            swarm = np.clip(swarm + velocities, lb, ub)\n\n            self.crossover_prob = 0.7 + 0.3 * (1 - np.cos(np.pi * evaluations / self.budget))\n\n            for i in range(swarm_size):\n                a, b, c = np.random.choice(swarm_size, 3, replace=False)\n                while len({a, b, c, i}) < 4:\n                    a, b, c = np.random.choice(swarm_size, 3, replace=False)\n                mutant_vector = np.clip(swarm[a] +\n                                        self.mutation_factor * (swarm[b] - swarm[c]), lb, ub)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob,\n                                        mutant_vector, swarm[i])\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n            # Dynamic swarm size\n            if evaluations % (self.budget // 10) == 0:\n                swarm_size = max(self.min_swarm_size, swarm_size - 5)\n                swarm = swarm[:swarm_size]\n                velocities = velocities[:swarm_size]\n                personal_best_positions = personal_best_positions[:swarm_size]\n                personal_best_scores = personal_best_scores[:swarm_size]\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "Enhance HDPE by updating the crossover probability to utilize a cosine decay function for better exploration-exploitation balance.", "configspace": "", "generation": 5, "fitness": -Infinity, "feedback": "An exception occurred: AttributeError(\"module 'numpy' has no attribute 'gamma'\").", "error": "AttributeError(\"module 'numpy' has no attribute 'gamma'\")", "parent_id": "34871bd1-c029-4444-aa93-256ab3bcdc5a", "metadata": {}, "mutation_prompt": null}
{"id": "2af42c8c-2c80-4b77-8b4f-9fd7c94ee173", "solution": "import numpy as np\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_swarm_size = 50\n        self.min_swarm_size = 25\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.9\n        self.initial_mutation_factor = 0.5\n        self.crossover_prob = 0.7\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm_size = self.initial_swarm_size\n        swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = swarm_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = 0.9 - 0.5 / (1 + np.exp(-(10 * evaluations / self.budget - 5)))\n\n            # Adaptive mutation factor\n            self.mutation_factor = self.initial_mutation_factor + 0.2 * (evaluations / self.budget)\n\n            # Adaptive learning rates for personal and global bests\n            adaptive_c1 = self.c1 * (1 - evaluations / self.budget)\n            adaptive_c2 = self.c2 * (evaluations / self.budget)\n\n            # Update velocities and positions\n            r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          adaptive_c1 * r1 * (personal_best_positions - swarm) +\n                          adaptive_c2 * r2 * (global_best_position - swarm))\n            swarm = np.clip(swarm + velocities, lb, ub)\n\n            self.crossover_prob = 0.7 + 0.3 * (1 - evaluations / self.budget)\n\n            for i in range(swarm_size):\n                a, b, c = np.random.choice(swarm_size, 3, replace=False)\n                while len({a, b, c, i}) < 4:\n                    a, b, c = np.random.choice(swarm_size, 3, replace=False)\n                mutant_vector = np.clip(swarm[a] +\n                                        self.mutation_factor * (swarm[b] - swarm[c]), lb, ub)\n                trial_vector = np.where(np.random.rand(self.dim) < self.crossover_prob,\n                                        mutant_vector, swarm[i])\n\n                trial_score = func(trial_vector)\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial_vector\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial_vector\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n            # Dynamic swarm size\n            if evaluations % (self.budget // 10) == 0:\n                swarm_size = max(self.min_swarm_size, swarm_size - 5)\n                swarm = swarm[:swarm_size]\n                velocities = velocities[:swarm_size]\n                personal_best_positions = personal_best_positions[:swarm_size]\n                personal_best_scores = personal_best_scores[:swarm_size]\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "Enhance HDPE by introducing adaptive learning rates for personal and global bests to improve exploration and exploitation balance.", "configspace": "", "generation": 5, "fitness": -Infinity, "feedback": "An exception occurred: AttributeError(\"module 'numpy' has no attribute 'gamma'\").", "error": "AttributeError(\"module 'numpy' has no attribute 'gamma'\")", "parent_id": "34871bd1-c029-4444-aa93-256ab3bcdc5a", "metadata": {}, "mutation_prompt": null}
{"id": "ee04f99b-d7e7-4b98-ba68-c1786c8d3bc9", "solution": "import numpy as np\nfrom scipy.special import gamma\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_swarm_size = 50\n        self.min_swarm_size = 25\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.9\n        self.initial_mutation_factor = 0.5\n        self.crossover_prob = 0.7\n\n    def levy_flight(self, dim):\n        beta = 1.5\n        sigma = (gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.randn(dim) * sigma\n        v = np.random.randn(dim)\n        step = u / abs(v)**(1 / beta)\n        return step\n\n    def chaotic_local_search(self, position, lb, ub):\n        a = 0.5\n        b = 3.0\n        chaotic_sequence = a + (b - a) * np.random.rand(self.dim)\n        new_position = np.clip(position + chaotic_sequence * (ub - lb) * 0.01, lb, ub)\n        return new_position\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm_size = self.initial_swarm_size\n        swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = swarm_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = 0.9 - 0.5 / (1 + np.exp(-(10 * evaluations / self.budget - 5)))\n            self.mutation_factor = self.initial_mutation_factor + 0.2 * (evaluations / self.budget)\n\n            for i in range(swarm_size):\n                if np.random.rand() < 0.5:\n                    swarm[i] += self.levy_flight(self.dim)\n                else:\n                    swarm[i] = self.chaotic_local_search(swarm[i], lb, ub)\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                trial_score = func(swarm[i])\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = swarm[i]\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = swarm[i]\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n            if evaluations % (self.budget // 10) == 0:\n                swarm_size = max(self.min_swarm_size, swarm_size - 5)\n                swarm = swarm[:swarm_size]\n                velocities = velocities[:swarm_size]\n                personal_best_positions = personal_best_positions[:swarm_size]\n                personal_best_scores = personal_best_scores[:swarm_size]\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "Fix the AttributeError by replacing `np.gamma` with `scipy.special.gamma`.", "configspace": "", "generation": 6, "fitness": 0.7588011942536544, "feedback": "The algorithm HDPE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.759 with standard deviation 0.032. And the mean value of best solutions found was 0.169 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "f7bded65-b296-45a1-b823-3c6a2f5bf05f", "metadata": {"aucs": [0.7180271327264552, 0.795857940430581, 0.7625185096039273], "final_y": [0.1756838963831603, 0.15956113312322284, 0.17234043773106633]}, "mutation_prompt": null}
{"id": "5b8fed93-7cb2-49bf-b6ac-b54328146c20", "solution": "import numpy as np\nfrom scipy.special import gamma\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_swarm_size = 50\n        self.min_swarm_size = 25\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.9\n        self.initial_mutation_factor = 0.5\n        self.crossover_prob = 0.7\n\n    def levy_flight(self, dim):\n        beta = 1.5\n        sigma = (gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.randn(dim) * sigma\n        v = np.random.randn(dim)\n        step = u / abs(v)**(1 / beta)\n        return step\n\n    def chaotic_local_search(self, position, lb, ub):\n        a = 0.5\n        b = 3.0\n        chaotic_sequence = a + (b - a) * np.random.rand(self.dim)\n        new_position = np.clip(position + chaotic_sequence * (ub - lb) * 0.01, lb, ub)\n        return new_position\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm_size = self.initial_swarm_size\n        swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = swarm_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = 0.9 - 0.5 / (1 + np.exp(-(10 * evaluations / self.budget - 5)))\n            self.mutation_factor = self.initial_mutation_factor + 0.2 * (evaluations / self.budget)\n\n            for i in range(swarm_size):\n                if np.random.rand() < 0.5:\n                    swarm[i] += self.levy_flight(self.dim)\n                else:\n                    swarm[i] = self.chaotic_local_search(swarm[i], lb, ub)\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                trial_score = func(swarm[i])\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = swarm[i]\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = swarm[i]\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n            if evaluations % (self.budget // 10) == 0:\n                swarm_size = max(self.min_swarm_size, swarm_size - 5)\n                swarm = swarm[:swarm_size]\n                velocities = velocities[:swarm_size]\n                personal_best_positions = personal_best_positions[:swarm_size]\n                personal_best_scores = personal_best_scores[:swarm_size]\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "Enhance HDPE by incorporating Levy flights for exploration and chaotic local search for exploitation, using scipy for the gamma function.", "configspace": "", "generation": 6, "fitness": 0.75486826324023, "feedback": "The algorithm HDPE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.755 with standard deviation 0.036. And the mean value of best solutions found was 0.174 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "f7bded65-b296-45a1-b823-3c6a2f5bf05f", "metadata": {"aucs": [0.7079649931777782, 0.7955659795951365, 0.7610738169477751], "final_y": [0.19060548980379255, 0.15970824724333832, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "8c0cfd12-5482-4319-acbb-57d7ae78eb22", "solution": "import numpy as np\nfrom scipy.special import gamma\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_swarm_size = 50\n        self.min_swarm_size = 25\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.9\n        self.initial_mutation_factor = 0.5\n        self.crossover_prob = 0.7\n\n    def levy_flight(self, dim):\n        beta = 1.5\n        sigma = (gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.randn(dim) * sigma\n        v = np.random.randn(dim)\n        step = u / abs(v)**(1 / beta)\n        return step\n\n    def chaotic_local_search(self, position, lb, ub):\n        a = 0.5\n        b = 3.0\n        chaotic_sequence = a + (b - a) * np.random.rand(self.dim)\n        new_position = np.clip(position + chaotic_sequence * (ub - lb) * 0.01, lb, ub)\n        return new_position\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm_size = self.initial_swarm_size\n        swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = swarm_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = 0.9 - 0.5 / (1 + np.exp(-(10 * evaluations / self.budget - 5)))\n            self.mutation_factor = self.initial_mutation_factor + 0.2 * (evaluations / self.budget)\n\n            for i in range(swarm_size):\n                if np.random.rand() < 0.5:\n                    swarm[i] += self.levy_flight(self.dim)\n                else:\n                    swarm[i] = self.chaotic_local_search(swarm[i], lb, ub)\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                trial_score = func(swarm[i])\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = swarm[i]\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = swarm[i]\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n            if evaluations % (self.budget // 10) == 0:\n                swarm_size = max(self.min_swarm_size, swarm_size - 5)\n                swarm = swarm[:swarm_size]\n                velocities = velocities[:swarm_size]\n                personal_best_positions = personal_best_positions[:swarm_size]\n                personal_best_scores = personal_best_scores[:swarm_size]\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "Enhance HDPE by replacing `numpy.gamma` with `scipy.special.gamma` for compatibility.", "configspace": "", "generation": 6, "fitness": 0.757929340843854, "feedback": "The algorithm HDPE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.758 with standard deviation 0.032. And the mean value of best solutions found was 0.172 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "f7bded65-b296-45a1-b823-3c6a2f5bf05f", "metadata": {"aucs": [0.7177704519311264, 0.7949437536526608, 0.7610738169477751], "final_y": [0.1843269533238565, 0.15995080288358676, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "334e757f-c0c4-4eab-a5d1-c49681e08727", "solution": "import numpy as np\nimport scipy.special as sp\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_swarm_size = 50\n        self.min_swarm_size = 25\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.9\n        self.initial_mutation_factor = 0.5\n        self.crossover_prob = 0.7\n\n    def levy_flight(self, dim):\n        beta = 1.5\n        sigma = (sp.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (sp.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.randn(dim) * sigma\n        v = np.random.randn(dim)\n        step = u / abs(v)**(1 / beta)\n        return step\n\n    def chaotic_local_search(self, position, lb, ub):\n        a = 0.5\n        b = 3.0\n        chaotic_sequence = a + (b - a) * np.random.rand(self.dim)\n        new_position = np.clip(position + chaotic_sequence * (ub - lb) * 0.01, lb, ub)\n        return new_position\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm_size = self.initial_swarm_size\n        swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = swarm_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = 0.9 - 0.5 / (1 + np.exp(-(10 * evaluations / self.budget - 5)))\n            self.mutation_factor = self.initial_mutation_factor + 0.2 * (evaluations / self.budget)\n\n            for i in range(swarm_size):\n                if np.random.rand() < 0.5:\n                    swarm[i] += self.levy_flight(self.dim)\n                else:\n                    swarm[i] = self.chaotic_local_search(swarm[i], lb, ub)\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                trial_score = func(swarm[i])\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = swarm[i]\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = swarm[i]\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n            if evaluations % (self.budget // 10) == 0:\n                swarm_size = max(self.min_swarm_size, swarm_size - 5)\n                swarm = swarm[:swarm_size]\n                velocities = velocities[:swarm_size]\n                personal_best_positions = personal_best_positions[:swarm_size]\n                personal_best_scores = personal_best_scores[:swarm_size]\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "Enhance HDPE by incorporating Levy flights for exploration and chaotic local search for exploitation, with a fix for the numpy gamma function.", "configspace": "", "generation": 6, "fitness": 0.7622444084154897, "feedback": "The algorithm HDPE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.762 with standard deviation 0.037. And the mean value of best solutions found was 0.172 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "f7bded65-b296-45a1-b823-3c6a2f5bf05f", "metadata": {"aucs": [0.713181680218786, 0.803389590286403, 0.7701619547412799], "final_y": [0.19093646357051453, 0.15638670286911138, 0.16885800839087373]}, "mutation_prompt": null}
{"id": "4a4c918d-5552-4147-a7a0-98906dd0ef8b", "solution": "import numpy as np\nfrom scipy.special import gamma\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_swarm_size = 50\n        self.min_swarm_size = 25\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.9\n        self.initial_mutation_factor = 0.5\n        self.crossover_prob = 0.7\n\n    def levy_flight(self, dim):\n        beta = 1.5\n        sigma = (gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.randn(dim) * sigma\n        v = np.random.randn(dim)\n        step = u / abs(v)**(1 / beta)\n        return step\n\n    def chaotic_local_search(self, position, lb, ub):\n        a = 0.5\n        b = 3.0\n        chaotic_sequence = a + (b - a) * np.random.rand(self.dim)\n        new_position = np.clip(position + chaotic_sequence * (ub - lb) * 0.01, lb, ub)\n        return new_position\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm_size = self.initial_swarm_size\n        swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = swarm_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = 0.9 - 0.5 / (1 + np.exp(-(10 * evaluations / self.budget - 5)))\n            self.mutation_factor = self.initial_mutation_factor + 0.2 * (evaluations / self.budget)\n\n            for i in range(swarm_size):\n                if np.random.rand() < 0.5:\n                    swarm[i] += self.levy_flight(self.dim)\n                else:\n                    swarm[i] = self.chaotic_local_search(swarm[i], lb, ub)\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                trial_score = func(swarm[i])\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = swarm[i]\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = swarm[i]\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n            if evaluations % (self.budget // 10) == 0:\n                swarm_size = max(self.min_swarm_size, swarm_size - 5)\n                swarm = swarm[:swarm_size]\n                velocities = velocities[:swarm_size]\n                personal_best_positions = personal_best_positions[:swarm_size]\n                personal_best_scores = personal_best_scores[:swarm_size]\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "Enhance HDPE by replacing the unsupported `np.gamma` with `scipy.special.gamma` for Levy flights.", "configspace": "", "generation": 6, "fitness": 0.7608529028648814, "feedback": "The algorithm HDPE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.761 with standard deviation 0.028. And the mean value of best solutions found was 0.170 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "f7bded65-b296-45a1-b823-3c6a2f5bf05f", "metadata": {"aucs": [0.7264899805153145, 0.7949949111315546, 0.7610738169477751], "final_y": [0.17602294526139572, 0.1599384302256256, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "fe1ce062-641c-4d5c-8a51-2c865df8e36d", "solution": "import numpy as np\nimport scipy.special as sp\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_swarm_size = 50\n        self.min_swarm_size = 25\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.9\n        self.initial_mutation_factor = 0.5\n        self.crossover_prob = 0.7\n\n    def levy_flight(self, dim):\n        beta = 1.5\n        sigma = (sp.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (sp.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.randn(dim) * sigma\n        v = np.random.randn(dim)\n        step = u / abs(v)**(1 / beta)\n        return step\n\n    def chaotic_local_search(self, position, lb, ub):\n        a = 0.5\n        b = 3.0\n        chaotic_sequence = a + (b - a) * np.random.rand(self.dim)\n        new_position = np.clip(position + chaotic_sequence * (ub - lb) * 0.01, lb, ub)\n        return new_position\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm_size = self.initial_swarm_size\n        swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = swarm_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = 0.9 - 0.7 / (1 + np.exp(-(10 * evaluations / self.budget - 5)))\n            self.mutation_factor = self.initial_mutation_factor + 0.2 * (evaluations / self.budget)\n\n            for i in range(swarm_size):\n                if np.random.rand() < 0.5:\n                    swarm[i] += self.levy_flight(self.dim)\n                else:\n                    swarm[i] = self.chaotic_local_search(swarm[i], lb, ub)\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                trial_score = func(swarm[i])\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = swarm[i]\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = swarm[i]\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n            if evaluations % (self.budget // 10) == 0:\n                swarm_size = max(self.min_swarm_size, swarm_size - 5)\n                swarm = swarm[:swarm_size]\n                velocities = velocities[:swarm_size]\n                personal_best_positions = personal_best_positions[:swarm_size]\n                personal_best_scores = personal_best_scores[:swarm_size]\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "Improve HDPE by fine-tuning the inertia weight decay function to enhance convergence speed and solution quality.", "configspace": "", "generation": 7, "fitness": 0.7589531818439871, "feedback": "The algorithm HDPE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.759 with standard deviation 0.031. And the mean value of best solutions found was 0.172 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "334e757f-c0c4-4eab-a5d1-c49681e08727", "metadata": {"aucs": [0.718715805219853, 0.795422214285282, 0.7627215260268262], "final_y": [0.18263562093592112, 0.1597574490590289, 0.17225298684564339]}, "mutation_prompt": null}
{"id": "09f321c6-37aa-40aa-bf41-9b76d05a2567", "solution": "import numpy as np\nimport scipy.special as sp\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_swarm_size = 50\n        self.min_swarm_size = 25\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.9\n        self.initial_mutation_factor = 0.5\n        self.crossover_prob = 0.7\n\n    def levy_flight(self, dim):\n        beta = 1.5\n        sigma = (sp.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (sp.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.randn(dim) * sigma\n        v = np.random.randn(dim)\n        step = u / abs(v)**(1 / beta)\n        return step\n\n    def chaotic_local_search(self, position, lb, ub):\n        a = 0.5\n        b = 3.0\n        chaotic_sequence = a + (b - a) * np.random.rand(self.dim)\n        new_position = np.clip(position + chaotic_sequence * (ub - lb) * 0.01, lb, ub)\n        return new_position\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm_size = self.initial_swarm_size\n        swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = swarm_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = 0.9 - 0.4 * (evaluations / self.budget)  # Adjusted decay strategy\n            self.mutation_factor = self.initial_mutation_factor * (1 - evaluations / self.budget)  # Adjusted decay\n\n            for i in range(swarm_size):\n                if np.random.rand() < 0.5:\n                    swarm[i] += self.levy_flight(self.dim)\n                else:\n                    swarm[i] = self.chaotic_local_search(swarm[i], lb, ub)\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                trial_score = func(swarm[i])\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = swarm[i]\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = swarm[i]\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n            if evaluations % (self.budget // 10) == 0:\n                swarm_size = max(self.min_swarm_size, swarm_size - 5)\n                swarm = swarm[:swarm_size]\n                velocities = velocities[:swarm_size]\n                personal_best_positions = personal_best_positions[:swarm_size]\n                personal_best_scores = personal_best_scores[:swarm_size]\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "Refine HDPE by adjusting inertia weight and mutation factor decay strategies for more dynamic exploration and exploitation balance.", "configspace": "", "generation": 7, "fitness": 0.7593093776230591, "feedback": "The algorithm HDPE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.759 with standard deviation 0.037. And the mean value of best solutions found was 0.170 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "334e757f-c0c4-4eab-a5d1-c49681e08727", "metadata": {"aucs": [0.7099943490166745, 0.8003813912254626, 0.7675523926270401], "final_y": [0.18098612694661287, 0.15764324581498024, 0.17016618847626308]}, "mutation_prompt": null}
{"id": "64523620-99b5-433c-9a3f-5595654f2704", "solution": "import numpy as np\nimport scipy.special as sp\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_swarm_size = 50\n        self.min_swarm_size = 25\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.9\n        self.initial_mutation_factor = 0.5\n        self.crossover_prob = 0.7\n\n    def levy_flight(self, dim):\n        beta = 1.5\n        sigma = (sp.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (sp.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.randn(dim) * sigma\n        v = np.random.randn(dim)\n        step = u / abs(v)**(1 / beta)\n        return step\n\n    def chaotic_local_search(self, position, lb, ub):\n        a = 0.5\n        b = 3.0\n        chaotic_sequence = a + (b - a) * np.random.rand(self.dim)\n        new_position = np.clip(position + chaotic_sequence * (ub - lb) * 0.01, lb, ub)\n        return new_position\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm_size = self.initial_swarm_size\n        swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = swarm_size\n\n        while evaluations < self.budget:\n            diversity = np.mean(np.std(swarm, axis=0))\n            self.inertia_weight = 0.9 - 0.5 * (diversity / (ub - lb).mean())\n            self.mutation_factor = self.initial_mutation_factor + 0.2 * (1 - diversity / (ub - lb).mean())\n\n            for i in range(swarm_size):\n                if np.random.rand() < 0.5:\n                    swarm[i] += self.levy_flight(self.dim)\n                else:\n                    swarm[i] = self.chaotic_local_search(swarm[i], lb, ub)\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                trial_score = func(swarm[i])\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = swarm[i]\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = swarm[i]\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n            if evaluations % (self.budget // 10) == 0:\n                swarm_size = max(self.min_swarm_size, swarm_size - 5)\n                swarm = swarm[:swarm_size]\n                velocities = velocities[:swarm_size]\n                personal_best_positions = personal_best_positions[:swarm_size]\n                personal_best_scores = personal_best_scores[:swarm_size]\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "Enhance HDPE by dynamically adapting the inertia weight and mutation factor based on swarm diversity for improved exploration and exploitation balance.", "configspace": "", "generation": 7, "fitness": 0.7589307640991853, "feedback": "The algorithm HDPE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.759 with standard deviation 0.039. And the mean value of best solutions found was 0.170 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "334e757f-c0c4-4eab-a5d1-c49681e08727", "metadata": {"aucs": [0.7085501943500854, 0.8041767013138752, 0.7640653966335954], "final_y": [0.18176917483057242, 0.1561328067351868, 0.17160152984443477]}, "mutation_prompt": null}
{"id": "5164e673-5750-4da1-9795-95f2ccfd741f", "solution": "import numpy as np\nimport scipy.special as sp\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_swarm_size = 50\n        self.min_swarm_size = 25\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.9\n        self.initial_mutation_factor = 0.5\n        self.crossover_prob = 0.7\n\n    def levy_flight(self, dim):\n        beta = 1.5\n        sigma = (sp.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (sp.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.randn(dim) * sigma\n        v = np.random.randn(dim)\n        step = u / abs(v)**(1 / beta)\n        return step\n\n    def chaotic_local_search(self, position, lb, ub):\n        a = 0.5\n        b = 3.0\n        chaotic_sequence = a + (b - a) * np.random.rand(self.dim)\n        new_position = np.clip(position + chaotic_sequence * (ub - lb) * 0.01, lb, ub)\n        return new_position\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm_size = self.initial_swarm_size\n        swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = swarm_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = 0.9 - 0.4 / (1 + np.exp(-(10 * evaluations / self.budget - 5)))\n            self.mutation_factor = self.initial_mutation_factor + 0.2 * (evaluations / self.budget)\n\n            for i in range(swarm_size):\n                if np.random.rand() < 0.5:\n                    swarm[i] += self.levy_flight(self.dim)\n                else:\n                    swarm[i] = self.chaotic_local_search(swarm[i], lb, ub)\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                trial_score = func(swarm[i])\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = swarm[i]\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = swarm[i]\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n            if evaluations % (self.budget // 10) == 0:\n                swarm_size = max(self.min_swarm_size, swarm_size - 5)\n                swarm = swarm[:swarm_size]\n                velocities = velocities[:swarm_size]\n                personal_best_positions = personal_best_positions[:swarm_size]\n                personal_best_scores = personal_best_scores[:swarm_size]\n\n            if evaluations % (self.budget // 4) == 0:\n                swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "Improve HDPE by introducing adaptive inertia weight decay and a periodic reinitialization for diversity enhancement.", "configspace": "", "generation": 7, "fitness": 0.7612595183024053, "feedback": "The algorithm HDPE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.761 with standard deviation 0.030. And the mean value of best solutions found was 0.169 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "334e757f-c0c4-4eab-a5d1-c49681e08727", "metadata": {"aucs": [0.7244242776703025, 0.7982804602891387, 0.7610738169477751], "final_y": [0.17687681939710953, 0.15861863170514223, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "8603bdbc-3cc1-4f2f-878c-01d10215994d", "solution": "import numpy as np\nimport scipy.special as sp\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_swarm_size = 50\n        self.min_swarm_size = 25\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.9\n        self.initial_mutation_factor = 0.5\n        self.crossover_prob = 0.7\n\n    def levy_flight(self, dim, scale):\n        beta = 1.5\n        sigma = (sp.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (sp.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.randn(dim) * sigma\n        v = np.random.randn(dim)\n        step = scale * u / abs(v)**(1 / beta)  # Change 1\n        return step\n\n    def chaotic_local_search(self, position, lb, ub, evaluations):\n        a = 0.5\n        b = 3.0\n        amplitude = 0.01 * (1 + 0.5 * evaluations / self.budget)  # Change 2\n        chaotic_sequence = a + (b - a) * np.random.rand(self.dim)\n        new_position = np.clip(position + chaotic_sequence * (ub - lb) * amplitude, lb, ub)  # Change 3\n        return new_position\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm_size = self.initial_swarm_size\n        swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = swarm_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = 0.9 - 0.5 / (1 + np.exp(-(10 * evaluations / self.budget - 5)))\n            self.mutation_factor = self.initial_mutation_factor + 0.2 * (evaluations / self.budget)\n\n            for i in range(swarm_size):\n                scale = 1 - evaluations / self.budget  # Additional parameter for adaptability\n                if np.random.rand() < 0.5:\n                    swarm[i] += self.levy_flight(self.dim, scale)\n                else:\n                    swarm[i] = self.chaotic_local_search(swarm[i], lb, ub, evaluations)\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                trial_score = func(swarm[i])\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = swarm[i]\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = swarm[i]\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n            if evaluations % (self.budget // 10) == 0:\n                swarm_size = max(self.min_swarm_size, swarm_size - 5)\n                swarm = swarm[:swarm_size]\n                velocities = velocities[:swarm_size]\n                personal_best_positions = personal_best_positions[:swarm_size]\n                personal_best_scores = personal_best_scores[:swarm_size]\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "Introduce adaptive Levy flight scaling and dynamic chaotic search amplitude to enhance exploration and exploitation balance.", "configspace": "", "generation": 7, "fitness": 0.7554423946152617, "feedback": "The algorithm HDPE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.755 with standard deviation 0.038. And the mean value of best solutions found was 0.174 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "334e757f-c0c4-4eab-a5d1-c49681e08727", "metadata": {"aucs": [0.7064930948853156, 0.7987602720126945, 0.7610738169477751], "final_y": [0.19049982368405227, 0.15841753017245908, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "63d93c9c-d002-447c-962d-bd3c9aaea40f", "solution": "import numpy as np\nimport scipy.special as sp\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_swarm_size = 50\n        self.min_swarm_size = 25\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.9\n        self.initial_mutation_factor = 0.5\n        self.crossover_prob = 0.7\n\n    def levy_flight(self, dim):\n        beta = 1.5\n        sigma = (sp.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (sp.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.randn(dim) * sigma\n        v = np.random.randn(dim)\n        step = u / abs(v)**(1 / beta)\n        return step\n\n    def chaotic_local_search(self, position, lb, ub):\n        a = 0.5\n        b = 3.0\n        chaotic_sequence = a + (b - a) * np.random.rand(self.dim)\n        new_position = np.clip(position + chaotic_sequence * (ub - lb) * 0.01, lb, ub)\n        return new_position\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm_size = self.initial_swarm_size\n        swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = swarm_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = 0.9 - 0.4 / (1 + np.exp(-(10 * evaluations / self.budget - 5)))\n            self.mutation_factor = self.initial_mutation_factor + 0.2 * (evaluations / self.budget)\n\n            for i in range(swarm_size):\n                if np.random.rand() < self.crossover_prob:\n                    swarm[i] += self.levy_flight(self.dim)\n                else:\n                    swarm[i] = self.chaotic_local_search(swarm[i], lb, ub)\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                trial_score = func(swarm[i])\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = swarm[i]\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = swarm[i]\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n            if evaluations % (self.budget // 10) == 0:\n                swarm_size = max(self.min_swarm_size, swarm_size - 5)\n                swarm = swarm[:swarm_size]\n                velocities = velocities[:swarm_size]\n                personal_best_positions = personal_best_positions[:swarm_size]\n                personal_best_scores = personal_best_scores[:swarm_size]\n\n            if evaluations % (self.budget // 4) == 0:\n                swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "Refine HDPE by introducing a dynamic crossover probability adjusted based on population diversity to better balance exploration and exploitation.", "configspace": "", "generation": 8, "fitness": 0.7538963062233037, "feedback": "The algorithm HDPE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.754 with standard deviation 0.039. And the mean value of best solutions found was 0.175 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "5164e673-5750-4da1-9795-95f2ccfd741f", "metadata": {"aucs": [0.7032290036088882, 0.7973860981132476, 0.7610738169477751], "final_y": [0.19253287494666038, 0.15891187842725996, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "31562d22-acdc-4f93-bcde-c8640c48e6fe", "solution": "import numpy as np\nimport scipy.special as sp\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_swarm_size = 50\n        self.min_swarm_size = 25\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.9\n        self.initial_mutation_factor = 0.5\n        self.crossover_prob = 0.7\n\n    def levy_flight(self, dim):\n        beta = 1.5\n        sigma = (sp.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (sp.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.randn(dim) * sigma\n        v = np.random.randn(dim)\n        step = u / abs(v)**(1 / beta)\n        return step\n\n    def chaotic_local_search(self, position, lb, ub):\n        a = 0.5\n        b = 3.0\n        chaotic_sequence = a + (b - a) * np.random.rand(self.dim)\n        new_position = np.clip(position + chaotic_sequence * (ub - lb) * 0.01, lb, ub)\n        return new_position\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm_size = self.initial_swarm_size\n        swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = swarm_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = 0.9 - 0.4 / (1 + np.exp(-(10 * evaluations / self.budget - 5)))\n            self.mutation_factor = self.initial_mutation_factor + 0.2 * (evaluations / self.budget)\n            self.crossover_prob = 0.7 - 0.3 * (evaluations / self.budget)  # Adjust crossover probability\n\n            for i in range(swarm_size):\n                if np.random.rand() < 0.5:\n                    swarm[i] += self.levy_flight(self.dim)\n                else:\n                    swarm[i] = self.chaotic_local_search(swarm[i], lb, ub)\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                trial_score = func(swarm[i])\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = swarm[i]\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = swarm[i]\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n            if evaluations % (self.budget // 10) == 0:\n                swarm_size = max(self.min_swarm_size, swarm_size - 5)\n                swarm = swarm[:swarm_size]\n                velocities = velocities[:swarm_size]\n                personal_best_positions = personal_best_positions[:swarm_size]\n                personal_best_scores = personal_best_scores[:swarm_size]\n\n            if evaluations % (self.budget // 4) == 0:\n                swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "Improve HDPE by dynamically adjusting the crossover probability based on iterations to enhance exploration. ", "configspace": "", "generation": 8, "fitness": 0.7592450924949826, "feedback": "The algorithm HDPE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.759 with standard deviation 0.030. And the mean value of best solutions found was 0.172 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "5164e673-5750-4da1-9795-95f2ccfd741f", "metadata": {"aucs": [0.7220712784808941, 0.7945901820562783, 0.7610738169477751], "final_y": [0.18203058811851536, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "9e64eac5-880b-4a62-9e53-2e53e20255fe", "solution": "import numpy as np\nimport scipy.special as sp\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_swarm_size = 50\n        self.min_swarm_size = 25\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.9\n        self.initial_mutation_factor = 0.5\n        self.crossover_prob = 0.7\n        self.mutation_prob = 0.1  # New mutation probability\n\n    def levy_flight(self, dim):\n        beta = 1.5\n        sigma = (sp.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (sp.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.randn(dim) * sigma\n        v = np.random.randn(dim)\n        step = u / abs(v)**(1 / beta)\n        return step\n\n    def chaotic_local_search(self, position, lb, ub):\n        a = 0.5\n        b = 3.0\n        chaotic_sequence = a + (b - a) * np.random.rand(self.dim)\n        new_position = np.clip(position + chaotic_sequence * (ub - lb) * 0.01, lb, ub)\n        return new_position\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm_size = self.initial_swarm_size\n        swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = swarm_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = 0.9 - 0.4 * (evaluations / self.budget)**2  # Non-linear decay\n            self.mutation_factor = self.initial_mutation_factor + 0.2 * (evaluations / self.budget)\n\n            for i in range(swarm_size):\n                if np.random.rand() < self.mutation_prob:  # Adjust mutation probability\n                    swarm[i] += self.levy_flight(self.dim)\n                else:\n                    swarm[i] = self.chaotic_local_search(swarm[i], lb, ub)\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                trial_score = func(swarm[i])\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = swarm[i]\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = swarm[i]\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n            if evaluations % (self.budget // 10) == 0:\n                swarm_size = max(self.min_swarm_size, swarm_size - 5)\n                swarm = swarm[:swarm_size]\n                velocities = velocities[:swarm_size]\n                personal_best_positions = personal_best_positions[:swarm_size]\n                personal_best_scores = personal_best_scores[:swarm_size]\n\n            if evaluations % (self.budget // 4) == 0:\n                swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "Enhance HDPE by implementing a non-linear inertia weight decay and integrating a mutation probability adjustment for exploration-exploitation balance.", "configspace": "", "generation": 8, "fitness": 0.7633384435949514, "feedback": "The algorithm HDPE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.763 with standard deviation 0.027. And the mean value of best solutions found was 0.170 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "5164e673-5750-4da1-9795-95f2ccfd741f", "metadata": {"aucs": [0.7316095463850723, 0.7973319674520065, 0.7610738169477751], "final_y": [0.17803011283809922, 0.15899851719620517, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "1a80c74f-8dfd-4227-b573-38df75981607", "solution": "import numpy as np\nimport scipy.special as sp\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_swarm_size = 50\n        self.min_swarm_size = 25\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.9\n        self.initial_mutation_factor = 0.5\n        self.crossover_prob = 0.7\n\n    def levy_flight(self, dim):\n        beta = 1.5\n        sigma = (sp.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (sp.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.randn(dim) * sigma\n        v = np.random.randn(dim)\n        step = u / abs(v)**(1 / beta)\n        return step\n\n    def chaotic_local_search(self, position, lb, ub):\n        a = 0.5\n        b = 3.0\n        chaotic_sequence = a + (b - a) * np.random.rand(self.dim)\n        new_position = np.clip(position + chaotic_sequence * (ub - lb) * 0.01, lb, ub)\n        return new_position\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm_size = self.initial_swarm_size\n        swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = swarm_size\n\n        while evaluations < self.budget:\n            # Modified this line for refined inertia weight decay\n            self.inertia_weight = 0.9 - 0.4 / (1 + np.exp(-(12 * evaluations / self.budget - 6)))\n            self.mutation_factor = self.initial_mutation_factor + 0.2 * (evaluations / self.budget)\n\n            for i in range(swarm_size):\n                if np.random.rand() < 0.5:\n                    swarm[i] += self.levy_flight(self.dim)\n                else:\n                    swarm[i] = self.chaotic_local_search(swarm[i], lb, ub)\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                trial_score = func(swarm[i])\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = swarm[i]\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = swarm[i]\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n            if evaluations % (self.budget // 10) == 0:\n                swarm_size = max(self.min_swarm_size, swarm_size - 5)\n                swarm = swarm[:swarm_size]\n                velocities = velocities[:swarm_size]\n                personal_best_positions = personal_best_positions[:swarm_size]\n                personal_best_scores = personal_best_scores[:swarm_size]\n\n            if evaluations % (self.budget // 4) == 0:\n                swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "Improve HDPE by refining the inertia weight decay function for enhanced convergence behavior.", "configspace": "", "generation": 8, "fitness": 0.7556485564008657, "feedback": "The algorithm HDPE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.756 with standard deviation 0.037. And the mean value of best solutions found was 0.170 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "5164e673-5750-4da1-9795-95f2ccfd741f", "metadata": {"aucs": [0.7076272358889485, 0.7980091305020838, 0.7613093028115647], "final_y": [0.17968818600221748, 0.15869054276257955, 0.17286223338516926]}, "mutation_prompt": null}
{"id": "a0f719e9-9474-4289-b7b5-1751935b1edb", "solution": "import numpy as np\nimport scipy.special as sp\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_swarm_size = 50\n        self.min_swarm_size = 25\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.9\n        self.initial_mutation_factor = 0.5\n        self.crossover_prob = 0.7\n\n    def levy_flight(self, dim):\n        beta = 1.5\n        sigma = (sp.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (sp.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.randn(dim) * sigma\n        v = np.random.randn(dim)\n        step = u / abs(v)**(1 / beta)\n        return step\n\n    def chaotic_local_search(self, position, lb, ub):\n        a = 0.5\n        b = 3.0\n        chaotic_sequence = a + (b - a) * np.random.rand(self.dim)\n        new_position = np.clip(position + chaotic_sequence * (ub - lb) * 0.01, lb, ub)\n        return new_position\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm_size = self.initial_swarm_size\n        swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = swarm_size\n\n        while evaluations < self.budget:\n            self.inertia_weight *= 0.98  # Exponential decay for inertia weight\n            self.mutation_factor = self.initial_mutation_factor * (1 + 0.2 * np.sin(evaluations))  # Chaotic mutation factor\n\n            for i in range(swarm_size):\n                if np.random.rand() < 0.5:\n                    swarm[i] += self.levy_flight(self.dim)\n                else:\n                    swarm[i] = self.chaotic_local_search(swarm[i], lb, ub)\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                trial_score = func(swarm[i])\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = swarm[i]\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = swarm[i]\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n            if evaluations % (self.budget // 10) == 0:\n                swarm_size = max(self.min_swarm_size, swarm_size - 5)\n                swarm = swarm[:swarm_size]\n                velocities = velocities[:swarm_size]\n                personal_best_positions = personal_best_positions[:swarm_size]\n                personal_best_scores = personal_best_scores[:swarm_size]\n\n            if evaluations % (self.budget // 4) == 0:\n                swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "Enhance HDPE by incorporating exponential decay for inertia weight and chaotic mutation factor for further diversity.", "configspace": "", "generation": 8, "fitness": 0.7575576928699846, "feedback": "The algorithm HDPE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.758 with standard deviation 0.034. And the mean value of best solutions found was 0.174 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "5164e673-5750-4da1-9795-95f2ccfd741f", "metadata": {"aucs": [0.714734839547561, 0.7968644221146177, 0.7610738169477751], "final_y": [0.18891166241654134, 0.15918611069771016, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "cef80fb6-9fe6-40c8-9be5-f0f27001e28d", "solution": "import numpy as np\nimport scipy.special as sp\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_swarm_size = 50\n        self.min_swarm_size = 25\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.9\n        self.initial_mutation_factor = 0.5\n        self.crossover_prob = 0.7\n        self.mutation_prob = 0.1  # New mutation probability\n\n    def levy_flight(self, dim):\n        beta = 1.5\n        sigma = (sp.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (sp.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.randn(dim) * sigma\n        v = np.random.randn(dim)\n        step = u / abs(v)**(1 / beta)\n        return step\n\n    def chaotic_local_search(self, position, lb, ub):\n        a = 0.5\n        b = 3.0\n        chaotic_sequence = a + (b - a) * np.random.rand(self.dim)\n        new_position = np.clip(position + chaotic_sequence * (ub - lb) * 0.01, lb, ub)\n        return new_position\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm_size = self.initial_swarm_size\n        swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = swarm_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = 0.9 - 0.4 * (evaluations / self.budget)**2  # Non-linear decay\n            self.mutation_factor = self.initial_mutation_factor + 0.2 * (evaluations / self.budget)\n\n            for i in range(swarm_size):\n                if np.random.rand() < self.mutation_prob:  # Adjust mutation probability\n                    swarm[i] += self.levy_flight(self.dim)\n                else:\n                    swarm[i] = self.chaotic_local_search(swarm[i], lb, ub)\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                trial_score = func(swarm[i])\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = swarm[i]\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = swarm[i]\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n            if evaluations % (self.budget // 10) == 0:\n                swarm_size = max(self.min_swarm_size, int(swarm_size - 5 + 10 * np.random.rand()))  # Dynamic swarm size\n                swarm = swarm[:swarm_size]\n                velocities = velocities[:swarm_size]\n                personal_best_positions = personal_best_positions[:swarm_size]\n                personal_best_scores = personal_best_scores[:swarm_size]\n\n            if evaluations % (self.budget // 4) == 0:\n                swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "Introduced a dynamic swarm size adjustment and occasional random restarts for enhanced exploration-exploitation balance.", "configspace": "", "generation": 9, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 50 is out of bounds for axis 0 with size 50').", "error": "IndexError('index 50 is out of bounds for axis 0 with size 50')", "parent_id": "9e64eac5-880b-4a62-9e53-2e53e20255fe", "metadata": {}, "mutation_prompt": null}
{"id": "60691ff3-bf29-48c0-9f9a-931bd1c5aa9b", "solution": "import numpy as np\nimport scipy.special as sp\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_swarm_size = 50\n        self.min_swarm_size = 25\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.9\n        self.initial_mutation_factor = 0.5\n        self.crossover_prob = 0.7\n        self.mutation_prob = 0.1  # New mutation probability\n\n    def levy_flight(self, dim):\n        beta = 1.5\n        sigma = (sp.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (sp.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.randn(dim) * sigma\n        v = np.random.randn(dim)\n        step = u / abs(v)**(1 / beta)\n        return step\n\n    def chaotic_local_search(self, position, lb, ub):\n        a = 0.6  # Modified from 0.5\n        b = 3.0\n        chaotic_sequence = a + (b - a) * np.random.rand(self.dim)\n        new_position = np.clip(position + chaotic_sequence * (ub - lb) * 0.01, lb, ub)\n        return new_position\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm_size = self.initial_swarm_size\n        swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = swarm_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = 0.9 - 0.4 * (evaluations / self.budget)**2  # Non-linear decay\n            self.mutation_factor = self.initial_mutation_factor + 0.2 * (evaluations / self.budget)\n            self.mutation_prob = 0.1 - 0.05 * (evaluations / self.budget)  # Dynamic mutation probability\n\n            for i in range(swarm_size):\n                if np.random.rand() < self.mutation_prob:  # Adjust mutation probability\n                    swarm[i] += self.levy_flight(self.dim)\n                else:\n                    swarm[i] = self.chaotic_local_search(swarm[i], lb, ub)\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                trial_score = func(swarm[i])\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = swarm[i]\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = swarm[i]\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n            if evaluations % (self.budget // 10) == 0:\n                swarm_size = max(self.min_swarm_size, swarm_size - 5)\n                swarm = swarm[:swarm_size]\n                velocities = velocities[:swarm_size]\n                personal_best_positions = personal_best_positions[:swarm_size]\n                personal_best_scores = personal_best_scores[:swarm_size]\n\n            if evaluations % (self.budget // 4) == 0:\n                swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "Improve HDPE by refining chaotic local search and introducing dynamic mutation probability decay.", "configspace": "", "generation": 9, "fitness": 0.7627207423668564, "feedback": "The algorithm HDPE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.763 with standard deviation 0.028. And the mean value of best solutions found was 0.170 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "9e64eac5-880b-4a62-9e53-2e53e20255fe", "metadata": {"aucs": [0.7295296641367166, 0.7975587460160776, 0.7610738169477751], "final_y": [0.1778770953441653, 0.15890760632950374, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "d41de5f6-bb87-4b6a-8516-83f8c9829444", "solution": "import numpy as np\nimport scipy.special as sp\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_swarm_size = 50\n        self.min_swarm_size = 25\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.9\n        self.initial_mutation_factor = 0.5\n        self.crossover_prob = 0.7\n        self.mutation_prob = 0.1  # New mutation probability\n\n    def levy_flight(self, dim):\n        beta = 1.5\n        sigma = (sp.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (sp.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.randn(dim) * sigma\n        v = np.random.randn(dim)\n        step = u / abs(v)**(1 / beta)\n        return step\n\n    def chaotic_local_search(self, position, lb, ub):\n        a = 0.5\n        b = 3.0\n        chaotic_sequence = a + (b - a) * np.random.rand(self.dim)\n        new_position = np.clip(position + chaotic_sequence * (ub - lb) * 0.01, lb, ub)\n        return new_position\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm_size = self.initial_swarm_size\n        swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = swarm_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = 0.9 - 0.4 * (evaluations / self.budget)**2  # Non-linear decay\n            self.mutation_factor = self.initial_mutation_factor + 0.2 * (evaluations / self.budget)\n            self.crossover_prob = 0.7 + 0.2 * np.sin(np.pi * evaluations / self.budget)  # Adaptive crossover probability\n\n            for i in range(swarm_size):\n                if np.random.rand() < self.mutation_prob:  # Adjust mutation probability\n                    swarm[i] += self.levy_flight(self.dim)\n                else:\n                    swarm[i] = self.chaotic_local_search(swarm[i], lb, ub)\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                trial_score = func(swarm[i])\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = swarm[i]\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = swarm[i]\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n            if evaluations % (self.budget // 10) == 0:\n                swarm_size = max(self.min_swarm_size, swarm_size - 5)\n                swarm = swarm[:swarm_size]\n                velocities = velocities[:swarm_size]\n                personal_best_positions = personal_best_positions[:swarm_size]\n                personal_best_scores = personal_best_scores[:swarm_size]\n\n            if evaluations % (self.budget // 4) == 0:\n                swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "Introduce adaptive crossover probability to enhance exploration and exploitation dynamics.", "configspace": "", "generation": 9, "fitness": 0.762455550411491, "feedback": "The algorithm HDPE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.762 with standard deviation 0.029. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "9e64eac5-880b-4a62-9e53-2e53e20255fe", "metadata": {"aucs": [0.7277366806418479, 0.7985561536448501, 0.7610738169477751], "final_y": [0.18081493664882442, 0.15807276809097937, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "20977228-4860-44fa-9b14-8de218b44d5b", "solution": "import numpy as np\nimport scipy.special as sp\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_swarm_size = 50\n        self.min_swarm_size = 25\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.9\n        self.initial_mutation_factor = 0.5\n        self.crossover_prob = 0.7\n        self.mutation_prob = 0.1  # New mutation probability\n\n    def levy_flight(self, dim):\n        beta = 1.5\n        sigma = (sp.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (sp.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.randn(dim) * sigma\n        v = np.random.randn(dim)\n        step = u / abs(v)**(1 / beta)\n        return step\n\n    def chaotic_local_search(self, position, lb, ub):\n        a = 0.5\n        b = 3.0\n        chaotic_sequence = a + (b - a) * np.random.rand(self.dim)\n        new_position = np.clip(position + chaotic_sequence * (ub - lb) * 0.01, lb, ub)\n        return new_position\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm_size = self.initial_swarm_size\n        swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = swarm_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = 0.9 - 0.4 * (evaluations / self.budget)**2  # Non-linear decay\n            self.mutation_factor = self.initial_mutation_factor + 0.2 * (evaluations / self.budget)\n\n            for i in range(swarm_size):\n                if np.random.rand() < self.mutation_prob:  # Adjust mutation probability\n                    swarm[i] += self.levy_flight(self.dim)\n                else:\n                    swarm[i] = self.chaotic_local_search(swarm[i], lb, ub)\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                trial_score = func(swarm[i])\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = swarm[i]\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = swarm[i]\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n            if evaluations % (self.budget // 10) == 0:\n                swarm_size = max(self.min_swarm_size, swarm_size - 5 + int(global_best_score * 10))  # Adaptive resizing\n                swarm = swarm[:swarm_size]\n                velocities = velocities[:swarm_size]\n                personal_best_positions = personal_best_positions[:swarm_size]\n                personal_best_scores = personal_best_scores[:swarm_size]\n\n            if evaluations % (self.budget // 4) == 0:\n                swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n                self.mutation_prob = 0.1 + 0.1 * np.random.rand()  # Dynamic mutation probability\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "Introduce adaptive swarm resizing and dynamic mutation probability to enhance exploration and exploitation balance.", "configspace": "", "generation": 9, "fitness": 0.7608881410001472, "feedback": "The algorithm HDPE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.761 with standard deviation 0.031. And the mean value of best solutions found was 0.172 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "9e64eac5-880b-4a62-9e53-2e53e20255fe", "metadata": {"aucs": [0.7229134434464346, 0.7986771626062321, 0.7610738169477751], "final_y": [0.1833044711823586, 0.15846001584394498, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "10aedd81-238c-40ba-8cc4-293f3666d1e2", "solution": "import numpy as np\nimport scipy.special as sp\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_swarm_size = 50\n        self.min_swarm_size = 25\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.9\n        self.initial_mutation_factor = 0.5\n        self.crossover_prob = 0.7\n        self.mutation_prob = 0.1  # New mutation probability\n\n    def levy_flight(self, dim):\n        beta = 1.5\n        sigma = (sp.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (sp.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.randn(dim) * sigma\n        v = np.random.randn(dim)\n        step = u / abs(v)**(1 / beta)\n        return step\n\n    def chaotic_local_search(self, position, lb, ub, scale_factor=0.01):\n        a = 0.5\n        b = 3.0\n        chaotic_sequence = a + (b - a) * np.random.rand(self.dim)\n        new_position = np.clip(position + chaotic_sequence * (ub - lb) * scale_factor, lb, ub)\n        return new_position\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm_size = self.initial_swarm_size\n        swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = swarm_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = 0.9 - 0.4 * (evaluations / self.budget)**2  # Non-linear decay\n            self.mutation_factor = self.initial_mutation_factor + 0.2 * (evaluations / self.budget)\n            scale_factor = 0.01 + 0.04 * (evaluations / self.budget)  # Adaptive chaos scaling\n\n            for i in range(swarm_size):\n                if np.random.rand() < self.mutation_prob:  # Adjust mutation probability\n                    swarm[i] += self.levy_flight(self.dim)\n                else:\n                    swarm[i] = self.chaotic_local_search(swarm[i], lb, ub, scale_factor)\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                trial_score = func(swarm[i])\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = swarm[i]\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = swarm[i]\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n            if evaluations % (self.budget // 10) == 0:\n                swarm_size = max(self.min_swarm_size, swarm_size - 5)\n                swarm = swarm[:swarm_size]\n                velocities = velocities[:swarm_size]\n                personal_best_positions = personal_best_positions[:swarm_size]\n                personal_best_scores = personal_best_scores[:swarm_size]\n\n            if evaluations % (self.budget // 4) == 0:\n                swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "Enhance HDPE by incorporating adaptive chaos scaling and improved selection strategy to balance exploration-exploitation.", "configspace": "", "generation": 9, "fitness": 0.7700030783163138, "feedback": "The algorithm HDPE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.770 with standard deviation 0.019. And the mean value of best solutions found was 0.167 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "9e64eac5-880b-4a62-9e53-2e53e20255fe", "metadata": {"aucs": [0.7519327100548331, 0.7970027079463332, 0.7610738169477751], "final_y": [0.16905849702540965, 0.15900483320810965, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "e022c24f-5847-4bc1-ad96-22a038cc914f", "solution": "import numpy as np\nimport scipy.special as sp\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_swarm_size = 50\n        self.min_swarm_size = 25\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.9\n        self.initial_mutation_factor = 0.5\n        self.crossover_prob = 0.7\n        self.mutation_prob = 0.1  # New mutation probability\n\n    def levy_flight(self, dim):\n        beta = 1.5\n        sigma = (sp.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (sp.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.randn(dim) * sigma\n        v = np.random.randn(dim)\n        step = u / abs(v)**(1 / beta)\n        return step\n\n    def chaotic_local_search(self, position, lb, ub, scale_factor=0.01):\n        a = 0.5\n        b = 3.0\n        chaotic_sequence = a + (b - a) * np.random.rand(self.dim)\n        new_position = np.clip(position + chaotic_sequence * (ub - lb) * scale_factor, lb, ub)\n        return new_position\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm_size = self.initial_swarm_size\n        swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = swarm_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = 0.9 - 0.4 * (evaluations / self.budget)**2  # Non-linear decay\n            self.mutation_factor = self.initial_mutation_factor + 0.2 * (evaluations / self.budget)\n            scale_factor = 0.01 + 0.04 * (evaluations / self.budget)  # Adaptive chaos scaling\n\n            for i in range(swarm_size):\n                if np.random.rand() < self.mutation_prob:  # Adjust mutation probability\n                    swarm[i] += self.levy_flight(self.dim)\n                else:\n                    swarm[i] = self.chaotic_local_search(swarm[i], lb, ub, scale_factor)\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                trial_score = func(swarm[i])\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = swarm[i]\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = swarm[i]\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n            if evaluations % (self.budget // 10) == 0:\n                swarm_size = max(self.min_swarm_size, swarm_size - 5)\n                swarm = swarm[:swarm_size]\n                velocities = velocities[:swarm_size]\n                personal_best_positions = personal_best_positions[:swarm_size]\n                personal_best_scores = personal_best_scores[:swarm_size]\n\n            if evaluations % (self.budget // 4) == 0:\n                swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "Enhance HDPE by incorporating adaptive chaos scaling and improved selection strategy to balance exploration-exploitation.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('list index out of range').", "error": "IndexError('list index out of range')", "parent_id": "10aedd81-238c-40ba-8cc4-293f3666d1e2", "metadata": {"aucs": [0.7519327100548331, 0.7970027079463332, 0.7610738169477751], "final_y": [0.16905849702540965, 0.15900483320810965, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "a9e9bbbc-9ccf-4644-870f-2fcb53347a7a", "solution": "import numpy as np\nimport scipy.special as sp\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_swarm_size = 50\n        self.min_swarm_size = 25\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.9\n        self.initial_mutation_factor = 0.5\n        self.crossover_prob = 0.7\n        self.mutation_prob = 0.1  # New mutation probability\n\n    def levy_flight(self, dim):\n        beta = 1.5\n        sigma = (sp.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (sp.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.randn(dim) * sigma\n        v = np.random.randn(dim)\n        step = u / abs(v)**(1 / beta)\n        return step\n\n    def chaotic_local_search(self, position, lb, ub, scale_factor=0.01):\n        a = 0.5\n        b = 3.0\n        chaotic_sequence = a + (b - a) * np.random.rand(self.dim)\n        new_position = np.clip(position + chaotic_sequence * (ub - lb) * scale_factor, lb, ub)\n        return new_position\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm_size = self.initial_swarm_size\n        swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = swarm_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = 0.9 - 0.4 * (evaluations / self.budget)**2  # Non-linear decay\n            self.mutation_factor = self.initial_mutation_factor + 0.2 * (evaluations / self.budget)\n            scale_factor = 0.01 + 0.04 * (evaluations / self.budget)  # Adaptive chaos scaling\n\n            for i in range(swarm_size):\n                if np.random.rand() < self.mutation_prob:  # Adjust mutation probability\n                    swarm[i] += self.levy_flight(self.dim)\n                else:\n                    swarm[i] = self.chaotic_local_search(swarm[i], lb, ub, scale_factor)\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                trial_score = func(swarm[i])\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = swarm[i]\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = swarm[i]\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n            if evaluations % (self.budget // 10) == 0:\n                swarm_size = max(self.min_swarm_size, swarm_size - 5)\n                swarm = swarm[:swarm_size]\n                velocities = velocities[:swarm_size]\n                personal_best_positions = personal_best_positions[:swarm_size]\n                personal_best_scores = personal_best_scores[:swarm_size]\n\n            if evaluations % (self.budget // 4) == 0:\n                elite_idx = np.argsort(personal_best_scores)[:5]\n                swarm[:5] = personal_best_positions[elite_idx]\n                swarm[5:] = np.random.uniform(lb, ub, (swarm_size - 5, self.dim))\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "Enhance HDPE by introducing adaptive learning rates for velocity updates and incorporating elite-based reinitialization to refine exploration and exploitation balance.", "configspace": "", "generation": 10, "fitness": 0.7681334315909133, "feedback": "The algorithm HDPE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.768 with standard deviation 0.021. And the mean value of best solutions found was 0.168 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "10aedd81-238c-40ba-8cc4-293f3666d1e2", "metadata": {"aucs": [0.7470987732145766, 0.7962277046103878, 0.7610738169477751], "final_y": [0.1727894606163547, 0.15944193724790656, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "0373902d-fd59-4908-8762-e62c127e18a2", "solution": "import numpy as np\nimport scipy.special as sp\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_swarm_size = 50\n        self.min_swarm_size = 25\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.9\n        self.initial_mutation_factor = 0.5\n        self.crossover_prob = 0.7\n        self.mutation_prob = 0.1\n\n    def levy_flight(self, dim):\n        beta = 1.5\n        sigma = (sp.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (sp.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.randn(dim) * sigma\n        v = np.random.randn(dim)\n        step = u / abs(v)**(1 / beta)\n        return step\n\n    def chaotic_local_search(self, position, lb, ub, scale_factor=0.01):\n        a = 0.5\n        b = 3.0\n        chaotic_sequence = a + (b - a) * np.random.rand(self.dim)\n        new_position = np.clip(position + chaotic_sequence * (ub - lb) * scale_factor, lb, ub)\n        return new_position\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm_size = self.initial_swarm_size\n        swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = swarm_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = 0.9 - 0.4 * (evaluations / self.budget)**2\n            self.mutation_factor = self.initial_mutation_factor + 0.2 * (evaluations / self.budget)\n            scale_factor = 0.01 + 0.03 * (evaluations / self.budget)\n\n            for i in range(swarm_size):\n                if np.random.rand() < self.mutation_prob:\n                    swarm[i] += self.levy_flight(self.dim)\n                else:\n                    swarm[i] = self.chaotic_local_search(swarm[i], lb, ub, scale_factor)\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                trial_score = func(swarm[i])\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = swarm[i]\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = swarm[i]\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n            if evaluations % (self.budget // 10) == 0:\n                swarm_size = max(self.min_swarm_size, swarm_size - 5)\n                swarm = swarm[:swarm_size]\n                velocities = velocities[:swarm_size]\n                personal_best_positions = personal_best_positions[:swarm_size]\n                personal_best_scores = personal_best_scores[:swarm_size]\n\n            if evaluations % (self.budget // 4) == 0:\n                swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "Optimize HDPE by adjusting chaos scaling to enhance exploration-exploitation balance.", "configspace": "", "generation": 10, "fitness": 0.758085974444314, "feedback": "The algorithm HDPE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.758 with standard deviation 0.033. And the mean value of best solutions found was 0.174 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "10aedd81-238c-40ba-8cc4-293f3666d1e2", "metadata": {"aucs": [0.7158525271166426, 0.7973315792685243, 0.7610738169477751], "final_y": [0.189446628755226, 0.15899867285557134, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "b223fed5-617c-40a6-b764-986274989c73", "solution": "import numpy as np\nimport scipy.special as sp\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_swarm_size = 50\n        self.min_swarm_size = 25\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.9\n        self.initial_mutation_factor = 0.5\n        self.crossover_prob = 0.7\n        self.mutation_prob = 0.1  # New mutation probability\n\n    def levy_flight(self, dim):\n        beta = 1.5\n        sigma = (sp.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (sp.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.randn(dim) * sigma\n        v = np.random.randn(dim)\n        step = u / abs(v)**(1 / beta)\n        return step\n\n    def chaotic_local_search(self, position, lb, ub, scale_factor=0.01):\n        a = 0.5\n        b = 3.0\n        chaotic_sequence = a + (b - a) * np.random.rand(self.dim)\n        new_position = np.clip(position + chaotic_sequence * (ub - lb) * scale_factor, lb, ub)\n        return new_position\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm_size = self.initial_swarm_size\n        swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = swarm_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = 0.9 - 0.3 * (evaluations / self.budget)**2  # Adjusted inertia weight decay\n            self.mutation_factor = self.initial_mutation_factor + 0.2 * (evaluations / self.budget)\n            scale_factor = 0.01 + 0.04 * (evaluations / self.budget)  # Adaptive chaos scaling\n\n            for i in range(swarm_size):\n                if np.random.rand() < self.mutation_prob:  # Adjust mutation probability\n                    swarm[i] += self.levy_flight(self.dim)\n                else:\n                    swarm[i] = self.chaotic_local_search(swarm[i], lb, ub, scale_factor)\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                trial_score = func(swarm[i])\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = swarm[i]\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = swarm[i]\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n            if evaluations % (self.budget // 10) == 0:\n                swarm_size = max(self.min_swarm_size, swarm_size - 5)\n                swarm = swarm[:swarm_size]\n                velocities = velocities[:swarm_size]\n                personal_best_positions = personal_best_positions[:swarm_size]\n                personal_best_scores = personal_best_scores[:swarm_size]\n\n            if evaluations % (self.budget // 4) == 0:\n                swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "Enhance HDPE by refining inertia weight decay for improved convergence.", "configspace": "", "generation": 10, "fitness": 0.7623888620653846, "feedback": "The algorithm HDPE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.762 with standard deviation 0.030. And the mean value of best solutions found was 0.172 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "10aedd81-238c-40ba-8cc4-293f3666d1e2", "metadata": {"aucs": [0.726152311190178, 0.7999404580582008, 0.7610738169477751], "final_y": [0.18429981879273338, 0.15795596089294328, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "60fd8b6a-ba96-49e6-8b49-bb1858824d00", "solution": "import numpy as np\nimport scipy.special as sp\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_swarm_size = 50\n        self.min_swarm_size = 25\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.9\n        self.initial_mutation_factor = 0.5\n        self.crossover_prob = 0.7\n        self.mutation_prob = 0.1  # New mutation probability\n\n    def levy_flight(self, dim):\n        beta = 1.5\n        sigma = (sp.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (sp.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.randn(dim) * sigma\n        v = np.random.randn(dim)\n        step = u / abs(v)**(1 / beta)\n        return step\n\n    def chaotic_local_search(self, position, lb, ub, scale_factor=0.01):\n        a = 0.5\n        b = 3.0\n        chaotic_sequence = a + (b - a) * np.random.rand(self.dim)\n        new_position = np.clip(position + chaotic_sequence * (ub - lb) * scale_factor, lb, ub)\n        return new_position\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm_size = self.initial_swarm_size\n        swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = swarm_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = 0.9 - 0.4 * (evaluations / self.budget)**2  # Non-linear decay\n            self.mutation_factor = self.initial_mutation_factor * np.exp(-3 * (evaluations / self.budget))  # Exponential decay\n            scale_factor = 0.01 + 0.04 * (evaluations / self.budget)  # Adaptive chaos scaling\n\n            for i in range(swarm_size):\n                if np.random.rand() < self.mutation_prob:  # Adjust mutation probability\n                    swarm[i] += self.levy_flight(self.dim)\n                else:\n                    swarm[i] = self.chaotic_local_search(swarm[i], lb, ub, scale_factor)\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                trial_score = func(swarm[i])\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = swarm[i]\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = swarm[i]\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n            if evaluations % (self.budget // 10) == 0:\n                swarm_size = max(self.min_swarm_size, int(swarm_size * 0.9))  # Dynamic size adjustment\n                swarm = swarm[:swarm_size]\n                velocities = velocities[:swarm_size]\n                personal_best_positions = personal_best_positions[:swarm_size]\n                personal_best_scores = personal_best_scores[:swarm_size]\n\n            if evaluations % (self.budget // 4) == 0:\n                swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "Enhance HDPE by introducing dynamic swarm size adjustment and exponential decay in mutation factor to improve convergence.", "configspace": "", "generation": 10, "fitness": 0.7610994716892826, "feedback": "The algorithm HDPE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.761 with standard deviation 0.027. And the mean value of best solutions found was 0.172 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "10aedd81-238c-40ba-8cc4-293f3666d1e2", "metadata": {"aucs": [0.7276344160637949, 0.7945901820562783, 0.7610738169477751], "final_y": [0.18286954324635507, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "b7143d3c-303e-4c5f-abd6-810907fe6548", "solution": "import numpy as np\nimport scipy.special as sp\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_swarm_size = 50\n        self.min_swarm_size = 25\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.9\n        self.initial_mutation_factor = 0.5\n        self.crossover_prob = 0.7\n        self.mutation_prob = 0.1  # New mutation probability\n\n    def levy_flight(self, dim):\n        beta = 1.5\n        sigma = (sp.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (sp.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.randn(dim) * sigma\n        v = np.random.randn(dim)\n        step = u / abs(v)**(1 / beta)\n        return step\n\n    def chaotic_local_search(self, position, lb, ub, scale_factor=0.01):\n        a = 0.5\n        b = 3.0\n        chaotic_sequence = a + (b - a) * np.random.rand(self.dim)\n        new_position = np.clip(position + chaotic_sequence * (ub - lb) * scale_factor, lb, ub)\n        return new_position\n\n    def crowding_distance(self, scores):\n        if len(scores) < 2:\n            return np.zeros(len(scores))\n        sorted_idx = np.argsort(scores) \n        distances = np.zeros(len(scores))\n        distances[sorted_idx[0]] = distances[sorted_idx[-1]] = np.inf\n        for i in range(1, len(scores) - 1):\n            distances[sorted_idx[i]] = scores[sorted_idx[i + 1]] - scores[sorted_idx[i - 1]]\n        return distances\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm_size = self.initial_swarm_size\n        swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = swarm_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = 0.9 - 0.4 * (evaluations / self.budget)**2  # Non-linear decay\n            self.mutation_factor = self.initial_mutation_factor + 0.2 * (evaluations / self.budget)\n            scale_factor = 0.01 + 0.04 * (evaluations / self.budget)  # Adaptive chaos scaling\n\n            for i in range(swarm_size):\n                if np.random.rand() < self.mutation_prob:  # Adjust mutation probability\n                    swarm[i] += self.levy_flight(self.dim)\n                else:\n                    swarm[i] = self.chaotic_local_search(swarm[i], lb, ub, scale_factor)\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                trial_score = func(swarm[i])\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = swarm[i]\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = swarm[i]\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n            if evaluations % (self.budget // 10) == 0:\n                distances = self.crowding_distance(personal_best_scores)\n                sorted_idx = np.argsort(distances)[-self.min_swarm_size:]\n                swarm = swarm[sorted_idx]\n                velocities = velocities[sorted_idx]\n                personal_best_positions = personal_best_positions[sorted_idx]\n                personal_best_scores = personal_best_scores[sorted_idx]\n\n            if evaluations % (self.budget // 4) == 0:\n                elite_idx = np.argsort(personal_best_scores)[:5]\n                swarm[:5] = personal_best_positions[elite_idx]\n                swarm[5:] = np.random.uniform(lb, ub, (swarm_size - 5, self.dim))\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "Implement diversity preservation by introducing a crowding distance mechanism to improve exploration and exploitation balance.", "configspace": "", "generation": 11, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 25 is out of bounds for axis 0 with size 25').", "error": "IndexError('index 25 is out of bounds for axis 0 with size 25')", "parent_id": "a9e9bbbc-9ccf-4644-870f-2fcb53347a7a", "metadata": {}, "mutation_prompt": null}
{"id": "71817fc1-fd5a-46b4-b28f-ad808ee98869", "solution": "import numpy as np\nimport scipy.special as sp\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_swarm_size = 50\n        self.min_swarm_size = 25\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.9\n        self.initial_mutation_factor = 0.5\n        self.initial_crossover_prob = 0.7  # Changed for adaptive crossover\n        self.mutation_prob = 0.1\n\n    def levy_flight(self, dim):\n        beta = 1.5\n        sigma = (sp.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (sp.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.randn(dim) * sigma\n        v = np.random.randn(dim)\n        step = u / abs(v)**(1 / beta)\n        return step\n\n    def chaotic_local_search(self, position, lb, ub, scale_factor=0.01):\n        a = 0.5\n        b = 3.0\n        chaotic_sequence = a + (b - a) * np.random.rand(self.dim)\n        new_position = np.clip(position + chaotic_sequence * (ub - lb) * scale_factor, lb, ub)\n        return new_position\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm_size = self.initial_swarm_size\n        swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = swarm_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = 0.9 - 0.5 * (evaluations / self.budget)**3  # Modified decay rate\n            self.mutation_factor = self.initial_mutation_factor + 0.2 * (evaluations / self.budget)\n            self.crossover_prob = self.initial_crossover_prob * (1 - evaluations / self.budget)  # Adaptive crossover\n            scale_factor = 0.01 + 0.04 * (evaluations / self.budget)\n\n            for i in range(swarm_size):\n                if np.random.rand() < self.mutation_prob:\n                    swarm[i] += self.levy_flight(self.dim)\n                else:\n                    swarm[i] = self.chaotic_local_search(swarm[i], lb, ub, scale_factor)\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                trial_score = func(swarm[i])\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = swarm[i]\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = swarm[i]\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n            if evaluations % (self.budget // 10) == 0:\n                swarm_size = max(self.min_swarm_size, swarm_size - 5)\n                swarm = swarm[:swarm_size]\n                velocities = velocities[:swarm_size]\n                personal_best_positions = personal_best_positions[:swarm_size]\n                personal_best_scores = personal_best_scores[:swarm_size]\n\n            if evaluations % (self.budget // 4) == 0:\n                elite_idx = np.argsort(personal_best_scores)[:5]\n                swarm[:5] = personal_best_positions[elite_idx]\n                swarm[5:] = np.random.uniform(lb, ub, (swarm_size - 5, self.dim))\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "Introduce adaptive crossover probability and employ a dynamic inertia weight adjustment to enhance exploration and exploitation balance.", "configspace": "", "generation": 11, "fitness": 0.7759700575928097, "feedback": "The algorithm HDPE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.776 with standard deviation 0.035. And the mean value of best solutions found was 0.162 (0. is the best) with standard deviation 0.017.", "error": "", "parent_id": "a9e9bbbc-9ccf-4644-870f-2fcb53347a7a", "metadata": {"aucs": [0.7273225574046849, 0.7945901820562783, 0.8059974333174661], "final_y": [0.1825788774271082, 0.1601017669387199, 0.14212651079204242]}, "mutation_prompt": null}
{"id": "a734083c-316c-424b-b92a-a9d79b455495", "solution": "import numpy as np\nimport scipy.special as sp\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_swarm_size = 50\n        self.min_swarm_size = 25\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.9\n        self.initial_mutation_factor = 0.5\n        self.crossover_prob = 0.7\n        self.mutation_prob = 0.1\n\n    def levy_flight(self, dim):\n        beta = 1.5\n        sigma = (sp.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (sp.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.randn(dim) * sigma\n        v = np.random.randn(dim)\n        step = u / abs(v)**(1 / beta)\n        return step\n\n    def chaotic_local_search(self, position, lb, ub, scale_factor=0.01):\n        a = 0.5\n        b = 3.0\n        chaotic_sequence = a + (b - a) * np.random.rand(self.dim)\n        new_position = np.clip(position + chaotic_sequence * (ub - lb) * scale_factor, lb, ub)\n        return new_position\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm_size = self.initial_swarm_size\n        swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = swarm_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = 0.9 - 0.4 * (evaluations / self.budget)**2\n            self.mutation_factor = self.initial_mutation_factor + 0.2 * (evaluations / self.budget)\n            self.crossover_prob = 0.7 + 0.2 * np.sin(np.pi * evaluations / self.budget) # Time-varying crossover\n            scale_factor = 0.01 + 0.04 * (evaluations / self.budget)\n\n            for i in range(swarm_size):\n                if np.random.rand() < self.mutation_prob:\n                    swarm[i] += self.levy_flight(self.dim)\n                else:\n                    swarm[i] = self.chaotic_local_search(swarm[i], lb, ub, scale_factor)\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                trial_score = func(swarm[i])\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = swarm[i]\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = swarm[i]\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n            if evaluations % (self.budget // 10) == 0:\n                swarm_size = max(self.min_swarm_size, swarm_size - 5)\n                swarm = swarm[:swarm_size]\n                velocities = velocities[:swarm_size]\n                personal_best_positions = personal_best_positions[:swarm_size]\n                personal_best_scores = personal_best_scores[:swarm_size]\n\n            if evaluations % (self.budget // 4) == 0:\n                elite_idx = np.argsort(personal_best_scores)[:5]\n                swarm[:5] = personal_best_positions[elite_idx]\n                swarm[5:] = np.random.uniform(lb, ub, (swarm_size - 5, self.dim))\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "Enhance HDPE by incorporating time-varying crossover probability and mutation factor to adaptively balance exploration and exploitation over iterations.", "configspace": "", "generation": 11, "fitness": 0.7730178161194226, "feedback": "The algorithm HDPE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.773 with standard deviation 0.027. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "a9e9bbbc-9ccf-4644-870f-2fcb53347a7a", "metadata": {"aucs": [0.7357983456041366, 0.7971287316729343, 0.7861263710811968], "final_y": [0.17846051682616937, 0.1585154175157817, 0.1574319996193766]}, "mutation_prompt": null}
{"id": "ae029b88-d810-418c-acce-4eb0ff062045", "solution": "import numpy as np\nimport scipy.special as sp\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_swarm_size = 50\n        self.min_swarm_size = 25\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.9\n        self.initial_mutation_factor = 0.5\n        self.crossover_prob = 0.7\n        self.mutation_prob = 0.1  # New mutation probability\n\n    def levy_flight(self, dim):\n        beta = 1.5\n        sigma = (sp.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (sp.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.randn(dim) * sigma\n        v = np.random.randn(dim)\n        step = u / abs(v)**(1 / beta)\n        return step\n\n    def chaotic_local_search(self, position, lb, ub, scale_factor=0.01):\n        a = 0.5\n        b = 3.0\n        chaotic_sequence = a + (b - a) * np.random.rand(self.dim)\n        new_position = np.clip(position + chaotic_sequence * (ub - lb) * scale_factor, lb, ub)\n        return new_position\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm_size = self.initial_swarm_size\n        swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = swarm_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = 0.8 - 0.5 * (evaluations / self.budget)**2  # Adjusted non-linear decay\n            self.mutation_factor = self.initial_mutation_factor + 0.2 * (evaluations / self.budget)\n            scale_factor = 0.02 + 0.04 * (evaluations / self.budget)  # Adjusted chaos scaling\n\n            for i in range(swarm_size):\n                if np.random.rand() < self.mutation_prob:\n                    swarm[i] += self.levy_flight(self.dim)\n                else:\n                    swarm[i] = self.chaotic_local_search(swarm[i], lb, ub, scale_factor)\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                trial_score = func(swarm[i])\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = swarm[i]\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = swarm[i]\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n            if evaluations % (self.budget // 10) == 0:\n                swarm_size = max(self.min_swarm_size, swarm_size - 5)\n                swarm = swarm[:swarm_size]\n                velocities = velocities[:swarm_size]\n                personal_best_positions = personal_best_positions[:swarm_size]\n                personal_best_scores = personal_best_scores[:swarm_size]\n\n            if evaluations % (self.budget // 4) == 0:\n                elite_idx = np.argsort(personal_best_scores)[:5]\n                swarm[:5] = personal_best_positions[elite_idx]\n                swarm[5:] = np.random.uniform(lb, ub, (swarm_size - 5, self.dim))\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "Improve HDPE by refining the inertial weight decay and adjusting chaotic search perturbations for better convergence.", "configspace": "", "generation": 11, "fitness": 0.7627710730846419, "feedback": "The algorithm HDPE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.763 with standard deviation 0.035. And the mean value of best solutions found was 0.168 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "a9e9bbbc-9ccf-4644-870f-2fcb53347a7a", "metadata": {"aucs": [0.7199148698616047, 0.804783850450357, 0.7636144989419642], "final_y": [0.1869714526989158, 0.15246934884516428, 0.1655752774234478]}, "mutation_prompt": null}
{"id": "904bb448-8521-4e8b-b090-98a372c03bd8", "solution": "import numpy as np\nimport scipy.special as sp\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_swarm_size = 50\n        self.min_swarm_size = 20  # Changed for more flexibility\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.9\n        self.initial_mutation_factor = 0.4  # Adjusted\n        self.crossover_prob = 0.7\n        self.mutation_prob = 0.1\n\n    def levy_flight(self, dim):\n        beta = 1.5\n        sigma = (sp.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (sp.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.randn(dim) * sigma\n        v = np.random.randn(dim)\n        step = u / abs(v)**(1 / beta)\n        return step\n\n    def chaotic_local_search(self, position, lb, ub, scale_factor=0.015):  # Adjusted scale factor\n        a = 0.5\n        b = 3.0\n        chaotic_sequence = a + (b - a) * np.random.rand(self.dim)\n        new_position = np.clip(position + chaotic_sequence * (ub - lb) * scale_factor, lb, ub)\n        return new_position\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm_size = self.initial_swarm_size\n        swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = swarm_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = 0.8 - 0.3 * (evaluations / self.budget)**2  # Changed decay\n            self.mutation_factor = self.initial_mutation_factor + 0.15 * (evaluations / self.budget)  # Adjusted\n            adaptive_scale_factor = 0.02 + 0.03 * (evaluations / self.budget)  # Modified\n\n            for i in range(swarm_size):\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - swarm[i]) +\n                                 self.c2 * np.random.rand(self.dim) * (global_best_position - swarm[i]))\n                velocities[i] = np.clip(velocities[i], -abs(ub - lb), abs(ub - lb))  # Velocity clipping\n\n                swarm[i] += velocities[i]\n                if np.random.rand() < self.mutation_prob:\n                    swarm[i] += self.levy_flight(self.dim)\n                else:\n                    swarm[i] = self.chaotic_local_search(swarm[i], lb, ub, adaptive_scale_factor)\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                trial_score = func(swarm[i])\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = swarm[i]\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = swarm[i]\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n            if evaluations % (self.budget // 10) == 0:\n                swarm_size = max(self.min_swarm_size, swarm_size - 4)  # Adjusted decrement\n                swarm = swarm[:swarm_size]\n                velocities = velocities[:swarm_size]\n                personal_best_positions = personal_best_positions[:swarm_size]\n                personal_best_scores = personal_best_scores[:swarm_size]\n\n            if evaluations % (self.budget // 4) == 0:\n                elite_idx = np.argsort(personal_best_scores)[:5]\n                swarm[:5] = personal_best_positions[elite_idx]\n                swarm[5:] = np.random.uniform(lb, ub, (swarm_size - 5, self.dim))\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "Introduce dynamic swarm resizing and adaptive velocity scaling in HDPE to enhance convergence and diversity.", "configspace": "", "generation": 11, "fitness": 0.7955171317778204, "feedback": "The algorithm HDPE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.796 with standard deviation 0.008. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "a9e9bbbc-9ccf-4644-870f-2fcb53347a7a", "metadata": {"aucs": [0.786466028397581, 0.8056602506563435, 0.7944251162795364], "final_y": [0.14745567343402488, 0.14548569346170992, 0.1516384978712716]}, "mutation_prompt": null}
{"id": "0b790621-6db0-4e75-b64a-8fc36e11cc87", "solution": "import numpy as np\nimport scipy.special as sp\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_swarm_size = 50\n        self.min_swarm_size = 20\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.9\n        self.initial_mutation_factor = 0.4\n        self.crossover_prob = 0.7\n        self.mutation_prob = 0.1\n\n    def levy_flight(self, dim):\n        beta = 1.5\n        sigma = (sp.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (sp.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.randn(dim) * sigma\n        v = np.random.randn(dim)\n        step = u / abs(v)**(1 / beta)\n        return step\n\n    def chaotic_local_search(self, position, lb, ub, scale_factor=0.02):  # Adjusted scale factor\n        a = 0.5\n        b = 3.0\n        chaotic_sequence = a + (b - a) * np.random.rand(self.dim)\n        new_position = np.clip(position + chaotic_sequence * (ub - lb) * scale_factor, lb, ub)\n        return new_position\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm_size = self.initial_swarm_size\n        swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = swarm_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = 0.8 - 0.3 * (evaluations / self.budget)**2\n            self.mutation_factor = self.initial_mutation_factor + 0.15 * (evaluations / self.budget)\n            adaptive_scale_factor = 0.02 + 0.03 * (evaluations / self.budget)\n\n            for i in range(swarm_size):\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - swarm[i]) +\n                                 self.c2 * np.random.rand(self.dim) * (global_best_position - swarm[i]))\n                velocities[i] = np.clip(velocities[i], -abs(ub - lb), abs(ub - lb))\n\n                swarm[i] += velocities[i]\n                if np.random.rand() < self.mutation_prob:\n                    swarm[i] += self.levy_flight(self.dim)\n                else:\n                    swarm[i] = self.chaotic_local_search(swarm[i], lb, ub, adaptive_scale_factor)\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                trial_score = func(swarm[i])\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = swarm[i]\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = swarm[i]\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n            if evaluations % (self.budget // 10) == 0:\n                swarm_size = max(self.min_swarm_size, swarm_size - 5)  # Adjusted decrement\n                swarm = swarm[:swarm_size]\n                velocities = velocities[:swarm_size]\n                personal_best_positions = personal_best_positions[:swarm_size]\n                personal_best_scores = personal_best_scores[:swarm_size]\n\n            if evaluations % (self.budget // 4) == 0:\n                elite_idx = np.argsort(personal_best_scores)[:5]\n                swarm[:5] = personal_best_positions[elite_idx]\n                swarm[5:] = np.random.uniform(lb, ub, (swarm_size - 5, self.dim))\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "Enhance HDPE by incorporating chaos-driven exploration and adaptive swarm contraction for improved solution discovery. ", "configspace": "", "generation": 12, "fitness": 0.7883114436517064, "feedback": "The algorithm HDPE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.788 with standard deviation 0.013. And the mean value of best solutions found was 0.153 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "904bb448-8521-4e8b-b090-98a372c03bd8", "metadata": {"aucs": [0.7709370907379626, 0.8027088132481542, 0.7912884269690024], "final_y": [0.14531520092701455, 0.15598715571909572, 0.15845094923084868]}, "mutation_prompt": null}
{"id": "3e3fbd2f-a8e1-4bf8-b9a2-ab8d532fc168", "solution": "import numpy as np\nimport scipy.special as sp\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_swarm_size = 50\n        self.min_swarm_size = 20\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.9\n        self.initial_mutation_factor = 0.4\n        self.crossover_prob = 0.7\n        self.mutation_prob = 0.1  # Original mutation probability\n\n    def levy_flight(self, dim):\n        beta = 1.5\n        sigma = (sp.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (sp.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.randn(dim) * sigma\n        v = np.random.randn(dim)\n        step = u / abs(v)**(1 / beta)\n        return step\n\n    def chaotic_local_search(self, position, lb, ub, scale_factor=0.015):\n        a = 0.5\n        b = 3.0\n        chaotic_sequence = a + (b - a) * np.random.rand(self.dim)\n        new_position = np.clip(position + chaotic_sequence * (ub - lb) * scale_factor, lb, ub)\n        return new_position\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm_size = self.initial_swarm_size\n        swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = swarm_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = 0.8 - 0.3 * (evaluations / self.budget)**2\n            self.mutation_factor = self.initial_mutation_factor + 0.15 * (evaluations / self.budget)\n            adaptive_scale_factor = 0.02 + 0.03 * (evaluations / self.budget)\n\n            for i in range(swarm_size):\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - swarm[i]) +\n                                 self.c2 * np.random.rand(self.dim) * (global_best_position - swarm[i]))\n                velocities[i] = np.clip(velocities[i], -abs(ub - lb), abs(ub - lb))\n\n                swarm[i] += velocities[i]\n                self.mutation_prob = 0.1 + 0.2 * (1 - evaluations / self.budget)  # Adaptive mutation probability\n                if np.random.rand() < self.mutation_prob:\n                    swarm[i] += self.levy_flight(self.dim)\n                else:\n                    swarm[i] = self.chaotic_local_search(swarm[i], lb, ub, adaptive_scale_factor)\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                trial_score = func(swarm[i])\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = swarm[i]\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = swarm[i]\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n            if evaluations % (self.budget // 10) == 0:\n                swarm_size = max(self.min_swarm_size, swarm_size - 4)\n                swarm = swarm[:swarm_size]\n                velocities = velocities[:swarm_size]\n                personal_best_positions = personal_best_positions[:swarm_size]\n                personal_best_scores = personal_best_scores[:swarm_size]\n\n            if evaluations % (self.budget // 4) == 0:\n                elite_idx = np.argsort(personal_best_scores)[:5]\n                swarm[:5] = personal_best_positions[elite_idx]\n                swarm[5:] = np.random.uniform(lb, ub, (swarm_size - 5, self.dim))\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "Enhance HDPE by incorporating adaptive mutation probability scaling to improve solution diversity and convergence rate.", "configspace": "", "generation": 12, "fitness": 0.8066123983637357, "feedback": "The algorithm HDPE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.807 with standard deviation 0.013. And the mean value of best solutions found was 0.147 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "904bb448-8521-4e8b-b090-98a372c03bd8", "metadata": {"aucs": [0.8245222818923738, 0.7965870905869704, 0.7987278226118627], "final_y": [0.13423356064533443, 0.15285275623565753, 0.1530548842024806]}, "mutation_prompt": null}
{"id": "90ddfb09-8bde-4c7b-8751-3800ab342a02", "solution": "import numpy as np\nimport scipy.special as sp\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_swarm_size = 50\n        self.min_swarm_size = 20\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.9\n        self.initial_mutation_factor = 0.4\n        self.crossover_prob = 0.7\n        self.mutation_prob = 0.1\n\n    def levy_flight(self, dim):\n        beta = 1.5\n        sigma = (sp.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (sp.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.randn(dim) * sigma\n        v = np.random.randn(dim)\n        step = u / abs(v)**(1 / beta)\n        return step\n\n    def chaotic_local_search(self, position, lb, ub, scale_factor=0.015):\n        a = 0.5\n        b = 3.0\n        chaotic_sequence = a + (b - a) * np.random.rand(self.dim)\n        new_position = np.clip(position + chaotic_sequence * (ub - lb) * scale_factor, lb, ub)\n        return new_position\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm_size = self.initial_swarm_size\n        swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = swarm_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = 0.8 - 0.3 * (evaluations / self.budget)**2\n            adaptive_scale_factor = 0.02 + 0.03 * (evaluations / self.budget)\n            adaptive_learning_factor = 0.5 + 1.5 * (1 - evaluations / self.budget)\n\n            for i in range(swarm_size):\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 adaptive_learning_factor * np.random.rand(self.dim) * (personal_best_positions[i] - swarm[i]) +\n                                 adaptive_learning_factor * np.random.rand(self.dim) * (global_best_position - swarm[i]))\n                velocities[i] = np.clip(velocities[i], -abs(ub - lb), abs(ub - lb))\n\n                swarm[i] += velocities[i]\n                if np.random.rand() < self.mutation_prob:\n                    swarm[i] += self.levy_flight(self.dim)\n                else:\n                    swarm[i] = self.chaotic_local_search(swarm[i], lb, ub, adaptive_scale_factor)\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                trial_score = func(swarm[i])\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = swarm[i]\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = swarm[i]\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n            if evaluations % (self.budget // 10) == 0:\n                swarm_size = max(self.min_swarm_size, swarm_size - 4)\n                swarm = swarm[:swarm_size]\n                velocities = velocities[:swarm_size]\n                personal_best_positions = personal_best_positions[:swarm_size]\n                personal_best_scores = personal_best_scores[:swarm_size]\n\n            if evaluations % (self.budget // 2) == 0:\n                elite_indices = np.argsort(personal_best_scores)[:10]\n                swarm[:10] = personal_best_positions[elite_indices]\n                swarm[10:] = np.random.uniform(lb, ub, (swarm_size - 10, self.dim))\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "Enhance HDPE with an adaptive learning factor and intelligent individual selection to improve exploration-exploitation balance.", "configspace": "", "generation": 12, "fitness": 0.7787750265670703, "feedback": "The algorithm HDPE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.779 with standard deviation 0.020. And the mean value of best solutions found was 0.162 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "904bb448-8521-4e8b-b090-98a372c03bd8", "metadata": {"aucs": [0.7594908878020639, 0.8063344982748878, 0.7704996936242595], "final_y": [0.168865912792049, 0.15007200148397926, 0.16601508573136947]}, "mutation_prompt": null}
{"id": "1f6254b4-bd5c-4d06-8efc-eaf49b0350a9", "solution": "import numpy as np\nimport scipy.special as sp\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_swarm_size = 50\n        self.min_swarm_size = 20  # Changed for more flexibility\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.9\n        self.initial_mutation_factor = 0.4  # Adjusted\n        self.crossover_prob = 0.7\n        self.mutation_prob = 0.1\n\n    def levy_flight(self, dim):\n        beta = 1.5\n        sigma = (sp.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (sp.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.randn(dim) * sigma\n        v = np.random.randn(dim)\n        step = u / abs(v)**(1 / beta)\n        return step\n\n    def chaotic_local_search(self, position, lb, ub, scale_factor=0.015):  # Adjusted scale factor\n        a = 0.5\n        b = 3.0\n        chaotic_sequence = a + (b - a) * np.random.rand(self.dim)\n        new_position = np.clip(position + chaotic_sequence * (ub - lb) * scale_factor, lb, ub)\n        return new_position\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm_size = self.initial_swarm_size\n        swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = swarm_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = 0.8 - 0.3 * (evaluations / self.budget)**2  # Changed decay\n            self.mutation_factor = self.initial_mutation_factor + 0.15 * (evaluations / self.budget)  # Adjusted\n            adaptive_scale_factor = 0.02 + 0.03 * (evaluations / self.budget)  # Modified\n            self.crossover_prob = 0.6 + 0.4 * (1 - evaluations / self.budget)  # Dynamic crossover probability\n\n            for i in range(swarm_size):\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - swarm[i]) +\n                                 self.c2 * np.random.rand(self.dim) * (global_best_position - swarm[i]))\n                velocities[i] = np.clip(velocities[i], -abs(ub - lb), abs(ub - lb))  # Velocity clipping\n\n                swarm[i] += velocities[i]\n                if np.random.rand() < self.mutation_prob:\n                    swarm[i] += self.levy_flight(self.dim)\n                else:\n                    swarm[i] = self.chaotic_local_search(swarm[i], lb, ub, adaptive_scale_factor)\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                trial_score = func(swarm[i])\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = swarm[i]\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = swarm[i]\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n            if evaluations % (self.budget // 10) == 0:\n                swarm_size = max(self.min_swarm_size, swarm_size - 4)  # Adjusted decrement\n                swarm = swarm[:swarm_size]\n                velocities = velocities[:swarm_size]\n                personal_best_positions = personal_best_positions[:swarm_size]\n                personal_best_scores = personal_best_scores[:swarm_size]\n\n            if evaluations % (self.budget // 4) == 0:\n                elite_idx = np.argsort(personal_best_scores)[:5]\n                swarm[:5] = personal_best_positions[elite_idx]\n                swarm[5:] = np.random.uniform(lb, ub, (swarm_size - 5, self.dim))\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "Enhance HDPE by introducing dynamic crossover probability adjustment to further improve exploration and exploitation balance.", "configspace": "", "generation": 12, "fitness": 0.7865153158422805, "feedback": "The algorithm HDPE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.787 with standard deviation 0.010. And the mean value of best solutions found was 0.158 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "904bb448-8521-4e8b-b090-98a372c03bd8", "metadata": {"aucs": [0.7726148461753795, 0.7951441757475661, 0.7917869256038961], "final_y": [0.15985172175457618, 0.1580313056038447, 0.1573604174731138]}, "mutation_prompt": null}
{"id": "88df352d-35b9-453b-a7d1-1d861a4f332a", "solution": "import numpy as np\nimport scipy.special as sp\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_swarm_size = 50\n        self.min_swarm_size = 20\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.9\n        self.initial_mutation_factor = 0.4\n        self.crossover_prob = 0.7\n        self.mutation_prob = 0.2  # Modified mutation probability\n\n    def levy_flight(self, dim):\n        beta = 1.5\n        sigma = (sp.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (sp.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.randn(dim) * sigma\n        v = np.random.randn(dim)\n        step = u / abs(v)**(1 / beta)\n        return step\n\n    def chaotic_local_search(self, position, lb, ub, scale_factor=0.02):  # Adjusted scale factor\n        a = 0.5\n        b = 3.0\n        chaotic_sequence = a + (b - a) * np.random.rand(self.dim)\n        new_position = np.clip(position + chaotic_sequence * (ub - lb) * scale_factor, lb, ub)\n        return new_position\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm_size = self.initial_swarm_size\n        swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = swarm_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = 0.8 - 0.3 * (evaluations / self.budget)**2\n            self.mutation_factor = self.initial_mutation_factor + 0.25 * (evaluations / self.budget)  # Adjusted\n\n            for i in range(swarm_size):\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - swarm[i]) +\n                                 self.c2 * np.random.rand(self.dim) * (global_best_position - swarm[i]))\n                velocities[i] = np.clip(velocities[i], -abs(ub - lb), abs(ub - lb))\n\n                if np.random.rand() < self.mutation_prob:\n                    swarm[i] += self.levy_flight(self.dim)\n                else:\n                    swarm[i] = self.chaotic_local_search(swarm[i], lb, ub, scale_factor=0.02 + 0.03 * (evaluations / self.budget))\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                trial_score = func(swarm[i])\n                evaluations += 1\n                if trial_score < personal_best_scores[i] or np.random.rand() < 0.1:  # Introduced random update\n                    personal_best_positions[i] = swarm[i]\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = swarm[i]\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n            if evaluations % (self.budget // 10) == 0:\n                swarm_size = max(self.min_swarm_size, swarm_size - 4)\n                swarm = swarm[:swarm_size]\n                velocities = velocities[:swarm_size]\n                personal_best_positions = personal_best_positions[:swarm_size]\n                personal_best_scores = personal_best_scores[:swarm_size]\n\n            if evaluations % (self.budget // 4) == 0:\n                elite_idx = np.argsort(personal_best_scores)[:5]\n                swarm[:5] = personal_best_positions[elite_idx]\n                swarm[5:] = np.random.uniform(lb, ub, (swarm_size - 5, self.dim))\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "Introduce enhanced mutation strategy and adaptively update particle's best positions to boost exploration and convergence.", "configspace": "", "generation": 12, "fitness": 0.7664731637736072, "feedback": "The algorithm HDPE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.766 with standard deviation 0.030. And the mean value of best solutions found was 0.168 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "904bb448-8521-4e8b-b090-98a372c03bd8", "metadata": {"aucs": [0.7245058644462825, 0.7945901820562783, 0.7803234448182612], "final_y": [0.1856336827134032, 0.1601017669387199, 0.15859941904059394]}, "mutation_prompt": null}
{"id": "d00e0b40-8a25-4a9b-9563-c2c3fb060004", "solution": "import numpy as np\nimport scipy.special as sp\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_swarm_size = 50\n        self.min_swarm_size = 20\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.9\n        self.initial_mutation_factor = 0.4\n        self.crossover_prob = 0.7\n        self.mutation_prob = 0.1\n\n    def levy_flight(self, dim):\n        beta = 1.5\n        sigma = (sp.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (sp.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.randn(dim) * sigma\n        v = np.random.randn(dim)\n        step = u / abs(v)**(1 / beta)\n        return step\n\n    def chaotic_local_search(self, position, lb, ub, scale_factor=0.015):\n        a = 0.5\n        b = 3.0\n        chaotic_sequence = a + (b - a) * np.random.rand(self.dim)\n        new_position = np.clip(position + chaotic_sequence * (ub - lb) * scale_factor, lb, ub)\n        return new_position\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm_size = self.initial_swarm_size\n        swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = swarm_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = 0.5 + 0.4 * np.sin(5 * np.pi * (evaluations / self.budget))  # Chaotic inertia weight\n            self.mutation_factor = self.initial_mutation_factor + 0.15 * (evaluations / self.budget)\n            adaptive_scale_factor = 0.02 + 0.03 * (evaluations / self.budget)\n\n            for i in range(swarm_size):\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - swarm[i]) +\n                                 self.c2 * np.random.rand(self.dim) * (global_best_position - swarm[i]))\n                velocities[i] = np.clip(velocities[i], -0.5 * abs(ub - lb), 0.5 * abs(ub - lb))  # Dynamic velocity clamping\n\n                swarm[i] += velocities[i]\n                self.mutation_prob = 0.1 + 0.2 * (1 - evaluations / self.budget)\n                if np.random.rand() < self.mutation_prob:\n                    swarm[i] += self.levy_flight(self.dim)\n                else:\n                    swarm[i] = self.chaotic_local_search(swarm[i], lb, ub, adaptive_scale_factor)\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                trial_score = func(swarm[i])\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = swarm[i]\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = swarm[i]\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n            if evaluations % (self.budget // 10) == 0:\n                swarm_size = max(self.min_swarm_size, swarm_size - 4)\n                swarm = swarm[:swarm_size]\n                velocities = velocities[:swarm_size]\n                personal_best_positions = personal_best_positions[:swarm_size]\n                personal_best_scores = personal_best_scores[:swarm_size]\n\n            if evaluations % (self.budget // 4) == 0:\n                elite_idx = np.argsort(personal_best_scores)[:5]\n                swarm[:5] = personal_best_positions[elite_idx]\n                swarm[5:] = np.random.uniform(lb, ub, (swarm_size - 5, self.dim))\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "Enhance HDPE by introducing chaotic inertia weight and dynamic velocity clamping to improve exploration and exploitation balance.", "configspace": "", "generation": 13, "fitness": 0.7902855778988073, "feedback": "The algorithm HDPE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.790 with standard deviation 0.009. And the mean value of best solutions found was 0.156 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "3e3fbd2f-a8e1-4bf8-b9a2-ab8d532fc168", "metadata": {"aucs": [0.7985653618549391, 0.7948958562722923, 0.7773955155691901], "final_y": [0.14544122735799658, 0.15786383198254494, 0.16419542128225717]}, "mutation_prompt": null}
{"id": "8ef324c9-33ca-4a56-a832-60effca69548", "solution": "import numpy as np\nimport scipy.special as sp\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_swarm_size = 50\n        self.min_swarm_size = 20\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.9\n        self.initial_mutation_factor = 0.4\n        self.crossover_prob = 0.7\n        self.mutation_prob = 0.1  # Original mutation probability\n\n    def levy_flight(self, dim):\n        beta = 1.5\n        sigma = (sp.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (sp.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.randn(dim) * sigma\n        v = np.random.randn(dim)\n        step = u / abs(v)**(1 / beta)\n        return step\n\n    def chaotic_local_search(self, position, lb, ub, scale_factor=0.015):\n        a = 0.5\n        b = 3.0\n        chaotic_sequence = a + (b - a) * np.random.rand(self.dim)\n        new_position = np.clip(position + chaotic_sequence * (ub - lb) * scale_factor, lb, ub)\n        return new_position\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm_size = self.initial_swarm_size\n        swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = swarm_size\n\n        elite_archive_positions = []\n        elite_archive_scores = []\n\n        while evaluations < self.budget:\n            self.inertia_weight = 0.8 - 0.3 * (evaluations / self.budget)**2\n            self.mutation_factor = self.initial_mutation_factor + 0.15 * (evaluations / self.budget)\n            adaptive_scale_factor = 0.02 + 0.03 * (evaluations / self.budget)\n\n            for i in range(swarm_size):\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - swarm[i]) +\n                                 self.c2 * np.random.rand(self.dim) * (global_best_position - swarm[i]))\n                velocities[i] = np.clip(velocities[i], -abs(ub - lb), abs(ub - lb))\n\n                swarm[i] += velocities[i]\n                self.mutation_prob = 0.1 + 0.2 * (1 - evaluations / self.budget)  # Adaptive mutation probability\n                if np.random.rand() < self.mutation_prob:\n                    swarm[i] += self.levy_flight(self.dim)\n                else:\n                    swarm[i] = self.chaotic_local_search(swarm[i], lb, ub, adaptive_scale_factor)\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                trial_score = func(swarm[i])\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = swarm[i]\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = swarm[i]\n                        global_best_score = trial_score\n                        elite_archive_positions.append(global_best_position)\n                        elite_archive_scores.append(global_best_score)\n                        if evaluations >= self.budget:\n                            break\n\n            if evaluations % (self.budget // 10) == 0:\n                swarm_size = max(self.min_swarm_size, swarm_size - 4)\n                swarm = swarm[:swarm_size]\n                velocities = velocities[:swarm_size]\n                personal_best_positions = personal_best_positions[:swarm_size]\n                personal_best_scores = personal_best_scores[:swarm_size]\n\n            if evaluations % (self.budget // 4) == 0:\n                elite_idx = np.argsort(personal_best_scores)[:5]\n                swarm[:5] = personal_best_positions[elite_idx]\n                swarm[5:] = np.random.uniform(lb, ub, (swarm_size - 5, self.dim))\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "Introduce an elite archive mechanism to better explore promising regions.", "configspace": "", "generation": 13, "fitness": 0.782273101056231, "feedback": "The algorithm HDPE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.782 with standard deviation 0.018. And the mean value of best solutions found was 0.155 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "3e3fbd2f-a8e1-4bf8-b9a2-ab8d532fc168", "metadata": {"aucs": [0.7675045872374848, 0.8081909145260535, 0.7711238014051548], "final_y": [0.15607505636754415, 0.15120887077296863, 0.1581161806631367]}, "mutation_prompt": null}
{"id": "44fef62f-680e-43a5-a158-fa1ce8905678", "solution": "import numpy as np\nimport scipy.special as sp\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_swarm_size = 50\n        self.min_swarm_size = 20\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.9\n        self.initial_mutation_factor = 0.4\n        self.crossover_prob = 0.7\n        self.mutation_prob = 0.1\n\n    def levy_flight(self, dim):\n        beta = 1.5\n        sigma = (sp.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (sp.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.randn(dim) * sigma\n        v = np.random.randn(dim)\n        step = u / abs(v)**(1 / beta)\n        return step\n\n    def chaotic_local_search(self, position, lb, ub, scale_factor=0.015):\n        a = 0.5\n        b = 3.0\n        chaotic_sequence = a + (b - a) * np.random.rand(self.dim)\n        new_position = np.clip(position + chaotic_sequence * (ub - lb) * scale_factor, lb, ub)\n        return new_position\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm_size = self.initial_swarm_size\n        swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = swarm_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = 0.8 - 0.3 * (evaluations / self.budget)**2\n            self.mutation_factor = self.initial_mutation_factor + 0.15 * (evaluations / self.budget)\n            adaptive_scale_factor = 0.02 + 0.03 * (evaluations / self.budget)\n\n            for i in range(swarm_size):\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - swarm[i]) +\n                                 self.c2 * np.random.rand(self.dim) * (global_best_position - swarm[i]))\n                velocities[i] = np.clip(velocities[i], -abs(ub - lb), abs(ub - lb))\n\n                swarm[i] += velocities[i]\n\n                # Changed mutation probability calculation\n                self.mutation_prob = 0.1 + 0.3 * (1 - evaluations / self.budget)\n                if np.random.rand() < self.mutation_prob:\n                    swarm[i] += self.levy_flight(self.dim)\n                else:\n                    swarm[i] = self.chaotic_local_search(swarm[i], lb, ub, adaptive_scale_factor)\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                trial_score = func(swarm[i])\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = swarm[i]\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = swarm[i]\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n            if evaluations % (self.budget // 10) == 0:\n                swarm_size = max(self.min_swarm_size, swarm_size - 4)\n                swarm = swarm[:swarm_size]\n                velocities = velocities[:swarm_size]\n                personal_best_positions = personal_best_positions[:swarm_size]\n                personal_best_scores = personal_best_scores[:swarm_size]\n\n            if evaluations % (self.budget // 4) == 0:\n                elite_idx = np.argsort(personal_best_scores)[:5]\n                swarm[:5] = personal_best_positions[elite_idx]\n                swarm[5:] = np.random.uniform(lb, ub, (swarm_size - 5, self.dim))\n                # Added elite solution sharing\n                global_best_position = np.mean(personal_best_positions[elite_idx], axis=0)\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "Introduced elite solution sharing and a dynamic constraint handling mechanism to enhance exploration and exploitation balance.", "configspace": "", "generation": 13, "fitness": 0.7805431826085049, "feedback": "The algorithm HDPE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.781 with standard deviation 0.014. And the mean value of best solutions found was 0.152 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "3e3fbd2f-a8e1-4bf8-b9a2-ab8d532fc168", "metadata": {"aucs": [0.7645294846059475, 0.7978690391257428, 0.7792310240938239], "final_y": [0.1517719920378815, 0.15586299982518137, 0.14799119998615407]}, "mutation_prompt": null}
{"id": "188d550b-63c2-4e6d-a370-454095612e26", "solution": "import numpy as np\nimport scipy.special as sp\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_swarm_size = 50\n        self.min_swarm_size = 20\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.9\n        self.initial_mutation_factor = 0.4\n        self.crossover_prob = 0.7\n        self.mutation_prob = 0.1  # Original mutation probability\n\n    def levy_flight(self, dim):\n        beta = 1.5\n        sigma = (sp.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (sp.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.randn(dim) * sigma\n        v = np.random.randn(dim)\n        step = u / abs(v)**(1 / beta)\n        return step\n\n    def chaotic_local_search(self, position, lb, ub, scale_factor=0.015):\n        a = 0.5\n        b = 3.0\n        chaotic_sequence = a + (b - a) * np.random.rand(self.dim)\n        new_position = np.clip(position + chaotic_sequence * (ub - lb) * scale_factor, lb, ub)\n        return new_position\n\n    def crossover(self, parent1, parent2, lb, ub):\n        alpha = np.random.rand(self.dim)\n        child = alpha * parent1 + (1 - alpha) * parent2\n        return np.clip(child, lb, ub)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm_size = self.initial_swarm_size\n        swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = swarm_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = 0.8 - 0.3 * (evaluations / self.budget)**2\n            self.mutation_factor = self.initial_mutation_factor + 0.15 * (evaluations / self.budget)\n            adaptive_scale_factor = 0.02 + 0.03 * (evaluations / self.budget)\n\n            for i in range(swarm_size):\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - swarm[i]) +\n                                 self.c2 * np.random.rand(self.dim) * (global_best_position - swarm[i]))\n                velocities[i] = np.clip(velocities[i], -abs(ub - lb), abs(ub - lb))\n\n                swarm[i] += velocities[i]\n                self.mutation_prob = 0.1 + 0.2 * (1 - evaluations / self.budget)  # Adaptive mutation probability\n                if np.random.rand() < self.mutation_prob:\n                    swarm[i] += self.levy_flight(self.dim)\n                elif np.random.rand() < self.crossover_prob:\n                    parent2_idx = np.random.randint(swarm_size)\n                    swarm[i] = self.crossover(swarm[i], swarm[parent2_idx], lb, ub)\n                else:\n                    swarm[i] = self.chaotic_local_search(swarm[i], lb, ub, adaptive_scale_factor)\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                trial_score = func(swarm[i])\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = swarm[i]\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = swarm[i]\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n            if evaluations % (self.budget // 10) == 0:\n                swarm_size = max(self.min_swarm_size, swarm_size - 4)\n                swarm = swarm[:swarm_size]\n                velocities = velocities[:swarm_size]\n                personal_best_positions = personal_best_positions[:swarm_size]\n                personal_best_scores = personal_best_scores[:swarm_size]\n\n            if evaluations % (self.budget // 4) == 0:\n                elite_idx = np.argsort(personal_best_scores)[:5]\n                swarm[:5] = personal_best_positions[elite_idx]\n                swarm[5:] = np.random.uniform(lb, ub, (swarm_size - 5, self.dim))\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "Improve HDPE by integrating an elite crossover mechanism to enhance exploration and exploitation balance.", "configspace": "", "generation": 13, "fitness": 0.7889078591379066, "feedback": "The algorithm HDPE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.789 with standard deviation 0.005. And the mean value of best solutions found was 0.159 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "3e3fbd2f-a8e1-4bf8-b9a2-ab8d532fc168", "metadata": {"aucs": [0.7832420683671864, 0.7945901820562783, 0.7888913269902555], "final_y": [0.15977635217417452, 0.1601017669387199, 0.1561742802579944]}, "mutation_prompt": null}
{"id": "db6ef44e-f5e7-4325-96ba-5789ec30a009", "solution": "import numpy as np\nimport scipy.special as sp\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_swarm_size = 50\n        self.min_swarm_size = 20\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.9\n        self.initial_mutation_factor = 0.4\n        self.crossover_prob = 0.7\n        self.mutation_prob = 0.1  # Original mutation probability\n\n    def levy_flight(self, dim):\n        beta = 1.5\n        sigma = (sp.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (sp.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.randn(dim) * sigma\n        v = np.random.randn(dim)\n        step = u / abs(v)**(1 / beta)\n        return step\n\n    def chaotic_local_search(self, position, lb, ub, scale_factor=0.015):\n        a = 0.5\n        b = 3.0\n        chaotic_sequence = a + (b - a) * np.random.rand(self.dim)\n        new_position = np.clip(position + chaotic_sequence * (ub - lb) * scale_factor, lb, ub)\n        return new_position\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm_size = self.initial_swarm_size\n        swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = swarm_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = 0.8 - 0.3 * (evaluations / self.budget)**2\n            self.mutation_factor = self.initial_mutation_factor + 0.15 * (evaluations / self.budget)\n            adaptive_scale_factor = 0.02 + 0.03 * (evaluations / self.budget)\n\n            for i in range(swarm_size):\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - swarm[i]) +\n                                 self.c2 * np.random.rand(self.dim) * (global_best_position - swarm[i]))\n                velocities[i] = np.clip(velocities[i], -abs(ub - lb), abs(ub - lb))\n\n                swarm[i] += velocities[i]\n                self.mutation_prob = 0.1 + 0.2 * (1 - evaluations / self.budget)  # Adaptive mutation probability\n                if np.random.rand() < self.mutation_prob:\n                    swarm[i] += self.levy_flight(self.dim)\n                else:\n                    swarm[i] = self.chaotic_local_search(swarm[i], lb, ub, adaptive_scale_factor)\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                trial_score = func(swarm[i])\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = swarm[i]\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = swarm[i]\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n            if evaluations % (self.budget // 10) == 0:\n                swarm_size = max(self.min_swarm_size, swarm_size - 4)\n                swarm = swarm[:swarm_size]\n                velocities = velocities[:swarm_size]\n                personal_best_positions = personal_best_positions[:swarm_size]\n                personal_best_scores = personal_best_scores[:swarm_size]\n\n            if evaluations % (self.budget // 4) == 0:\n                elite_idx = np.argsort(personal_best_scores)[:5]\n                swarm[:5] = personal_best_positions[elite_idx]\n                # Introduce elite crossover\n                for j in range(5, swarm_size):\n                    if np.random.rand() < 0.5:\n                        partner = personal_best_positions[np.random.choice(elite_idx)]\n                        swarm[j] = 0.5 * (swarm[j] + partner)\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "Introduce elite crossover to HDPE to enhance exploration and exploitation balance for better convergence.", "configspace": "", "generation": 13, "fitness": 0.7840916301447637, "feedback": "The algorithm HDPE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.784 with standard deviation 0.015. And the mean value of best solutions found was 0.159 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "3e3fbd2f-a8e1-4bf8-b9a2-ab8d532fc168", "metadata": {"aucs": [0.7641480456831145, 0.7983174545963847, 0.7898093901547918], "final_y": [0.16608474927358585, 0.15599165282163507, 0.15633133561645696]}, "mutation_prompt": null}
{"id": "7ffcf7e4-44f3-4498-918a-b774ac8b044e", "solution": "import numpy as np\nimport scipy.special as sp\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_swarm_size = 50\n        self.min_swarm_size = 20\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.9\n        self.initial_mutation_factor = 0.4\n        self.crossover_prob = 0.7\n        self.mutation_prob = 0.1\n\n    def levy_flight(self, dim):\n        beta = 1.5\n        sigma = (sp.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (sp.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.randn(dim) * sigma\n        v = np.random.randn(dim)\n        step = u / abs(v)**(1 / beta)\n        return step\n\n    def chaotic_local_search(self, position, lb, ub, scale_factor=0.015):\n        a = 0.5\n        b = 3.0\n        chaotic_sequence = a + (b - a) * np.random.rand(self.dim)\n        new_position = np.clip(position + chaotic_sequence * (ub - lb) * scale_factor, lb, ub)\n        return new_position\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm_size = self.initial_swarm_size\n        swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = swarm_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = 0.9 * np.exp(-5 * evaluations / self.budget)  # Exponential decay for inertia weight\n            self.mutation_factor = self.initial_mutation_factor + 0.15 * (evaluations / self.budget)\n            adaptive_scale_factor = 0.02 + 0.03 * (evaluations / self.budget)\n\n            for i in range(swarm_size):\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - swarm[i]) +\n                                 self.c2 * np.random.rand(self.dim) * (global_best_position - swarm[i]))\n                velocities[i] = np.clip(velocities[i], -0.5 * abs(ub - lb), 0.5 * abs(ub - lb))  # Dynamic velocity clamping\n\n                swarm[i] += velocities[i]\n                self.mutation_prob = 0.1 + 0.2 * (1 - evaluations / self.budget)\n                if np.random.rand() < self.mutation_prob:\n                    swarm[i] += self.levy_flight(self.dim)\n                else:\n                    swarm[i] = self.chaotic_local_search(swarm[i], lb, ub, adaptive_scale_factor)\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                trial_score = func(swarm[i])\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = swarm[i]\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = swarm[i]\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n            if evaluations % (self.budget // 10) == 0:\n                swarm_size = max(self.min_swarm_size, swarm_size - 4)\n                swarm = swarm[:swarm_size]\n                velocities = velocities[:swarm_size]\n                personal_best_positions = personal_best_positions[:swarm_size]\n                personal_best_scores = personal_best_scores[:swarm_size]\n\n            if evaluations % (self.budget // 4) == 0:\n                elite_idx = np.argsort(personal_best_scores)[:5]\n                swarm[:5] = personal_best_positions[elite_idx]\n                swarm[5:] = np.random.uniform(lb, ub, (swarm_size - 5, self.dim))\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "Introduced exponential decay to inertia weight for improved convergence.", "configspace": "", "generation": 14, "fitness": 0.8165267423624161, "feedback": "The algorithm HDPE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.817 with standard deviation 0.009. And the mean value of best solutions found was 0.142 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "d00e0b40-8a25-4a9b-9563-c2c3fb060004", "metadata": {"aucs": [0.8217963140464077, 0.8242718870154067, 0.8035120260254338], "final_y": [0.1355380860541836, 0.13848788460518457, 0.15167991288808147]}, "mutation_prompt": null}
{"id": "c2f15cba-e18f-405a-9272-1b9e9ba5e769", "solution": "import numpy as np\nimport scipy.special as sp\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_swarm_size = 50\n        self.min_swarm_size = 20\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.9\n        self.initial_mutation_factor = 0.4\n        self.crossover_prob = 0.7\n        self.mutation_prob = 0.1\n\n    def levy_flight(self, dim):\n        beta = 1.5\n        sigma = (sp.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (sp.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.randn(dim) * sigma\n        v = np.random.randn(dim)\n        step = u / abs(v)**(1 / beta)\n        return step\n\n    def chaotic_local_search(self, position, lb, ub, scale_factor=0.015):\n        a = 0.5\n        b = 3.0\n        chaotic_sequence = a + (b - a) * np.random.rand(self.dim)\n        new_position = np.clip(position + chaotic_sequence * (ub - lb) * scale_factor, lb, ub)\n        return new_position\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm_size = self.initial_swarm_size\n        swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = swarm_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = 0.5 + 0.4 * np.sin(5 * np.pi * (evaluations / self.budget))  # Chaotic inertia weight\n            self.mutation_factor = self.initial_mutation_factor + 0.15 * (evaluations / self.budget)\n            adaptive_scale_factor = 0.02 + 0.03 * (evaluations / self.budget)\n\n            for i in range(swarm_size):\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - swarm[i]) +\n                                 self.c2 * np.random.rand(self.dim) * (global_best_position - swarm[i]))\n                velocities[i] = np.clip(velocities[i], -0.5 * abs(ub - lb), 0.5 * abs(ub - lb))  # Dynamic velocity clamping\n\n                swarm[i] += velocities[i]\n                self.mutation_prob = 0.1 + 0.2 * (1 - evaluations / self.budget) * (personal_best_scores[i] / global_best_score)\n                if np.random.rand() < self.mutation_prob:\n                    swarm[i] += self.levy_flight(self.dim)\n                else:\n                    swarm[i] = self.chaotic_local_search(swarm[i], lb, ub, adaptive_scale_factor)\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                trial_score = func(swarm[i])\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = swarm[i]\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = swarm[i]\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n            if evaluations % (self.budget // 10) == 0:\n                swarm_size = max(self.min_swarm_size, swarm_size - 4)\n                swarm = swarm[:swarm_size]\n                velocities = velocities[:swarm_size]\n                personal_best_positions = personal_best_positions[:swarm_size]\n                personal_best_scores = personal_best_scores[:swarm_size]\n\n            if evaluations % (self.budget // 4) == 0:\n                elite_idx = np.argsort(personal_best_scores)[:5]\n                swarm[:5] = personal_best_positions[elite_idx]\n                swarm[5:] = np.random.uniform(lb, ub, (swarm_size - 5, self.dim))\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "Adjust mutation probability to enhance convergence by making it adaptive with respect to personal best performance.", "configspace": "", "generation": 14, "fitness": 0.8214400665775536, "feedback": "The algorithm HDPE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.821 with standard deviation 0.008. And the mean value of best solutions found was 0.145 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "d00e0b40-8a25-4a9b-9563-c2c3fb060004", "metadata": {"aucs": [0.8261807243349402, 0.8096770736686953, 0.8284624017290255], "final_y": [0.13889818078199723, 0.15157150911226236, 0.1431929852401661]}, "mutation_prompt": null}
{"id": "1529b240-57aa-47c7-915c-776eabf9f456", "solution": "import numpy as np\nimport scipy.special as sp\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_swarm_size = 50\n        self.min_swarm_size = 20\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.9\n        self.initial_mutation_factor = 0.4\n        self.crossover_prob = 0.7\n        self.mutation_prob = 0.1\n\n    def levy_flight(self, dim):\n        beta = 1.5\n        sigma = (sp.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (sp.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.randn(dim) * sigma\n        v = np.random.randn(dim)\n        step = u / abs(v)**(1 / beta)\n        return step\n\n    def chaotic_local_search(self, position, lb, ub, scale_factor=0.015):\n        a = 0.5\n        b = 3.0\n        chaotic_sequence = a + (b - a) * np.random.rand(self.dim)\n        new_position = np.clip(position + chaotic_sequence * (ub - lb) * scale_factor, lb, ub)\n        return new_position\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm_size = self.initial_swarm_size\n        swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = swarm_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = 0.5 + 0.4 * np.sin(5 * np.pi * (evaluations / self.budget))  # Chaotic inertia weight\n            self.mutation_factor = self.initial_mutation_factor + 0.15 * (1 - evaluations / self.budget)  # Adaptive scaling\n            adaptive_scale_factor = 0.02 + 0.03 * (evaluations / self.budget)\n\n            for i in range(swarm_size):\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - swarm[i]) +\n                                 self.c2 * np.random.rand(self.dim) * (global_best_position - swarm[i]))\n                velocities[i] = np.clip(velocities[i], -0.5 * abs(ub - lb), 0.5 * abs(ub - lb))  # Dynamic velocity clamping\n\n                swarm[i] += velocities[i]\n                self.mutation_prob = 0.1 + 0.2 * (1 - evaluations / self.budget)\n                if np.random.rand() < self.mutation_prob:\n                    swarm[i] += self.levy_flight(self.dim)\n                else:\n                    swarm[i] = self.chaotic_local_search(swarm[i], lb, ub, adaptive_scale_factor)\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                trial_score = func(swarm[i])\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = swarm[i]\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = swarm[i]\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n            if evaluations % (self.budget // 10) == 0:\n                swarm_size = max(self.min_swarm_size, swarm_size - 4)\n                swarm = swarm[:swarm_size]\n                velocities = velocities[:swarm_size]\n                personal_best_positions = personal_best_positions[:swarm_size]\n                personal_best_scores = personal_best_scores[:swarm_size]\n\n            if evaluations % (self.budget // 4) == 0:\n                elite_idx = np.argsort(personal_best_scores)[:5]\n                swarm[:5] = personal_best_positions[elite_idx]\n                swarm[5:] = np.random.uniform(lb, ub, (swarm_size - 5, self.dim))\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "Introduce adaptive mutation factor scaling for improved convergence.", "configspace": "", "generation": 14, "fitness": 0.8273479807274068, "feedback": "The algorithm HDPE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.827 with standard deviation 0.022. And the mean value of best solutions found was 0.141 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "d00e0b40-8a25-4a9b-9563-c2c3fb060004", "metadata": {"aucs": [0.8349241476650116, 0.8492422231994852, 0.7978775713177233], "final_y": [0.13314969215957106, 0.13888451460760265, 0.1496615900698568]}, "mutation_prompt": null}
{"id": "3a9e4e14-3e08-493e-9352-226c4cedb08f", "solution": "import numpy as np\nimport scipy.special as sp\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_swarm_size = 50\n        self.min_swarm_size = 20\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.9\n        self.initial_mutation_factor = 0.4\n        self.crossover_prob = 0.7\n        self.mutation_prob = 0.1\n\n    def levy_flight(self, dim):\n        beta = 1.5\n        sigma = (sp.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (sp.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.randn(dim) * sigma\n        v = np.random.randn(dim)\n        step = u / abs(v)**(1 / beta)\n        return step\n\n    def chaotic_local_search(self, position, lb, ub, scale_factor=0.015):\n        a = 0.5\n        b = 3.0\n        chaotic_sequence = a + (b - a) * np.random.rand(self.dim)\n        new_position = np.clip(position + chaotic_sequence * (ub - lb) * scale_factor, lb, ub)\n        return new_position\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm_size = self.initial_swarm_size\n        swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = swarm_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = 0.5 + 0.4 * np.sin(5 * np.pi * (evaluations / self.budget))\n            self.mutation_factor = self.initial_mutation_factor + 0.15 * (evaluations / self.budget)\n            adaptive_scale_factor = 0.02 + 0.03 * (evaluations / self.budget)\n\n            diversity_factor = np.std(swarm, axis=0) / (ub - lb)  # Added line for diversity\n            mutation_adjustment = (np.random.rand(self.dim) < diversity_factor).astype(float)  # Added\n\n            for i in range(swarm_size):\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - swarm[i]) +\n                                 self.c2 * np.random.rand(self.dim) * (global_best_position - swarm[i]))\n                velocities[i] = np.clip(velocities[i], -0.5 * abs(ub - lb), 0.5 * abs(ub - lb))\n\n                swarm[i] += velocities[i]\n                self.mutation_prob = 0.1 + 0.2 * (1 - evaluations / self.budget)\n                if np.random.rand() < self.mutation_prob:\n                    swarm[i] += self.levy_flight(self.dim) * mutation_adjustment  # Modified\n                else:\n                    swarm[i] = self.chaotic_local_search(swarm[i], lb, ub, adaptive_scale_factor)\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                trial_score = func(swarm[i])\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = swarm[i]\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = swarm[i]\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n            if evaluations % (self.budget // 10) == 0:\n                swarm_size = max(self.min_swarm_size, swarm_size - 4)\n                swarm = swarm[:swarm_size]\n                velocities = velocities[:swarm_size]\n                personal_best_positions = personal_best_positions[:swarm_size]\n                personal_best_scores = personal_best_scores[:swarm_size]\n\n            if evaluations % (self.budget // 4) == 0:\n                elite_idx = np.argsort(personal_best_scores)[:5]\n                swarm[:5] = personal_best_positions[elite_idx]\n                swarm[5:] = np.random.uniform(lb, ub, (swarm_size - 5, self.dim))\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "Refine HDPE by incorporating diversity-driven exploration with adaptive mutation strategies to enhance convergence speed and solution quality.", "configspace": "", "generation": 14, "fitness": 0.8350764239909575, "feedback": "The algorithm HDPE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.835 with standard deviation 0.013. And the mean value of best solutions found was 0.132 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "d00e0b40-8a25-4a9b-9563-c2c3fb060004", "metadata": {"aucs": [0.8477311179657503, 0.8397733743422502, 0.817724779664872], "final_y": [0.12494271434563253, 0.12956087823932028, 0.14009024990700936]}, "mutation_prompt": null}
{"id": "3b13979e-57a7-4e37-b7ba-1f26c9b9e10c", "solution": "import numpy as np\nimport scipy.special as sp\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_swarm_size = 50\n        self.min_swarm_size = 20\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.9\n        self.initial_mutation_factor = 0.4\n        self.crossover_prob = 0.7\n        self.mutation_prob = 0.1\n\n    def levy_flight(self, dim):\n        beta = 1.5\n        sigma = (sp.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (sp.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.randn(dim) * sigma\n        v = np.random.randn(dim)\n        step = u / abs(v)**(1 / beta)\n        return step\n\n    def chaotic_local_search(self, position, lb, ub, scale_factor=0.015):\n        a = 0.5\n        b = 3.0\n        chaotic_sequence = a + (b - a) * np.random.rand(self.dim)\n        new_position = np.clip(position + chaotic_sequence * (ub - lb) * scale_factor, lb, ub)\n        return new_position\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm_size = self.initial_swarm_size\n        swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = swarm_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = 0.5 + 0.4 * np.sin(5 * np.pi * (evaluations / self.budget))  # Chaotic inertia weight\n            self.mutation_factor = self.initial_mutation_factor + 0.15 * (evaluations / self.budget)\n            adaptive_scale_factor = 0.02 + 0.03 * (evaluations / self.budget)\n\n            for i in range(swarm_size):\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - swarm[i]) +\n                                 self.c2 * np.random.rand(self.dim) * (global_best_position - swarm[i]))\n                velocities[i] = np.clip(velocities[i], -0.5 * abs(ub - lb), 0.5 * abs(ub - lb))  # Dynamic velocity clamping\n\n                swarm[i] += velocities[i]\n                self.mutation_prob = 0.1 + 0.2 * (1 - evaluations / self.budget)\n                if np.random.rand() < self.mutation_prob:\n                    swarm[i] += self.levy_flight(self.dim)\n                else:\n                    swarm[i] = self.chaotic_local_search(swarm[i], lb, ub, adaptive_scale_factor)\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                trial_score = func(swarm[i])\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = swarm[i]\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = swarm[i]\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n            self.crossover_prob = 0.7 + 0.3 * np.sin(3 * np.pi * (evaluations / self.budget))  # Adaptive crossover probability\n\n            if evaluations % (self.budget // 10) == 0:\n                swarm_size = max(self.min_swarm_size, swarm_size - 4)\n                swarm = swarm[:swarm_size]\n                velocities = velocities[:swarm_size]\n                personal_best_positions = personal_best_positions[:swarm_size]\n                personal_best_scores = personal_best_scores[:swarm_size]\n\n            if evaluations % (self.budget // 4) == 0:\n                elite_idx = np.argsort(personal_best_scores)[:5]\n                swarm[:5] = personal_best_positions[elite_idx]\n                swarm[5:] = np.random.uniform(lb, ub, (swarm_size - 5, self.dim))\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "Introduce a small modification to adaptively adjust the crossover probability based on the optimization progress to improve solution exploration.", "configspace": "", "generation": 14, "fitness": 0.8177498332389194, "feedback": "The algorithm HDPE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.818 with standard deviation 0.006. And the mean value of best solutions found was 0.139 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "d00e0b40-8a25-4a9b-9563-c2c3fb060004", "metadata": {"aucs": [0.8119304697063577, 0.8258500463002192, 0.8154689837101816], "final_y": [0.1431620418558034, 0.14244820095611466, 0.13232169063241694]}, "mutation_prompt": null}
{"id": "ccd7eda3-484f-4b80-9296-97f7adfdfb16", "solution": "import numpy as np\nimport scipy.special as sp\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_swarm_size = 50\n        self.min_swarm_size = 20\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.9\n        self.initial_mutation_factor = 0.4\n        self.crossover_prob = 0.7\n        self.mutation_prob = 0.1\n        self.dynamic_population = True  # New flag for dynamic resizing\n\n    def levy_flight(self, dim):\n        beta = 1.5\n        sigma = (sp.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (sp.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.randn(dim) * sigma\n        v = np.random.randn(dim)\n        step = u / abs(v)**(1 / beta)\n        return step\n\n    def chaotic_local_search(self, position, lb, ub, scale_factor=0.015):\n        a = 0.5\n        b = 3.0\n        chaotic_sequence = a + (b - a) * np.random.rand(self.dim)\n        new_position = np.clip(position + chaotic_sequence * (ub - lb) * scale_factor, lb, ub)\n        return new_position\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm_size = self.initial_swarm_size\n        swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = swarm_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = 0.7 + 0.2 * np.cos(3 * np.pi * (evaluations / self.budget))  # Modified\n            self.mutation_factor = self.initial_mutation_factor * (1.2 - evaluations / self.budget)  # Modified\n            adaptive_scale_factor = 0.02 + 0.08 * (1 - evaluations / self.budget)  # Modified\n\n            diversity_factor = np.std(swarm, axis=0) / (ub - lb)\n            mutation_adjustment = (np.random.rand(self.dim) < diversity_factor).astype(float)\n\n            for i in range(swarm_size):\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - swarm[i]) +\n                                 self.c2 * np.random.rand(self.dim) * (global_best_position - swarm[i]))\n                velocities[i] = np.clip(velocities[i], -0.5 * abs(ub - lb), 0.5 * abs(ub - lb))\n\n                swarm[i] += velocities[i]\n                self.mutation_prob = 0.15 + 0.3 * (evaluations / self.budget)  # Modified\n                if np.random.rand() < self.mutation_prob:\n                    swarm[i] += self.levy_flight(self.dim) * mutation_adjustment\n                else:\n                    swarm[i] = self.chaotic_local_search(swarm[i], lb, ub, adaptive_scale_factor)\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                trial_score = func(swarm[i])\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = swarm[i]\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = swarm[i]\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n            if self.dynamic_population:  # New condition\n                swarm_size = max(self.min_swarm_size, int(self.initial_swarm_size * (1.0 + np.sin(evaluations * np.pi / self.budget))))  # New line\n                swarm = swarm[:swarm_size]\n                velocities = velocities[:swarm_size]\n                personal_best_positions = personal_best_positions[:swarm_size]\n                personal_best_scores = personal_best_scores[:swarm_size]\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "Enhance HDPE by introducing a dynamic population resizing and a self-adaptive parameter control mechanism to balance exploration and exploitation effectively.", "configspace": "", "generation": 15, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 50 is out of bounds for axis 0 with size 50').", "error": "IndexError('index 50 is out of bounds for axis 0 with size 50')", "parent_id": "3a9e4e14-3e08-493e-9352-226c4cedb08f", "metadata": {}, "mutation_prompt": null}
{"id": "34a6c5a6-952b-4d23-b913-e08b919082ab", "solution": "import numpy as np\nimport scipy.special as sp\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_swarm_size = 50\n        self.min_swarm_size = 20\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.9\n        self.initial_mutation_factor = 0.4\n        self.crossover_prob = 0.7\n        self.mutation_prob = 0.1\n\n    def levy_flight(self, dim):\n        beta = 1.5\n        sigma = (sp.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (sp.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.randn(dim) * sigma\n        v = np.random.randn(dim)\n        step = u / abs(v)**(1 / beta)\n        return step\n\n    def chaotic_local_search(self, position, lb, ub, scale_factor=0.015):\n        a = 0.5\n        b = 3.0\n        chaotic_sequence = a + (b - a) * np.random.rand(self.dim)\n        new_position = np.clip(position + chaotic_sequence * (ub - lb) * scale_factor, lb, ub)\n        return new_position\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm_size = self.initial_swarm_size\n        swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = swarm_size\n\n        while evaluations < self.budget:\n            self.inertia_weight *= 0.99  # Changed line for adaptive inertia decay\n            self.mutation_factor = self.initial_mutation_factor + 0.15 * (evaluations / self.budget)\n            adaptive_scale_factor = 0.02 + 0.03 * (evaluations / self.budget)\n\n            diversity_factor = np.std(swarm, axis=0) / (ub - lb)\n            mutation_adjustment = (np.random.rand(self.dim) < diversity_factor).astype(float)\n\n            for i in range(swarm_size):\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - swarm[i]) +\n                                 self.c2 * np.random.rand(self.dim) * (global_best_position - swarm[i]))\n                velocities[i] = np.clip(velocities[i], -0.5 * abs(ub - lb), 0.5 * abs(ub - lb))\n\n                swarm[i] += velocities[i]\n                self.mutation_prob = 0.1 + 0.2 * (1 - evaluations / self.budget)\n                if np.random.rand() < self.mutation_prob:\n                    swarm[i] += self.levy_flight(self.dim) * mutation_adjustment\n                else:\n                    swarm[i] = self.chaotic_local_search(swarm[i], lb, ub, adaptive_scale_factor)\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                trial_score = func(swarm[i])\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = swarm[i]\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = swarm[i]\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n            if evaluations % (self.budget // 10) == 0:\n                swarm_size = max(self.min_swarm_size, swarm_size - 4)\n                swarm = swarm[:swarm_size]\n                velocities = velocities[:swarm_size]\n                personal_best_positions = personal_best_positions[:swarm_size]\n                personal_best_scores = personal_best_scores[:swarm_size]\n\n            if evaluations % (self.budget // 4) == 0:\n                elite_idx = np.argsort(personal_best_scores)[:5]\n                swarm[:5] = personal_best_positions[elite_idx]\n                swarm[5:] = np.random.uniform(lb, ub, (swarm_size - 5, self.dim))\n                velocities[5:] = np.random.uniform(-abs(ub - lb), abs(ub - lb), (swarm_size - 5, self.dim))  # Changed line for elite retention\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "Refine HDPE by integrating an adaptive inertia weight decay and enhanced elite swarm retention to boost convergence and maintain solution quality.", "configspace": "", "generation": 15, "fitness": 0.8213701965533587, "feedback": "The algorithm HDPE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.821 with standard deviation 0.033. And the mean value of best solutions found was 0.141 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "3a9e4e14-3e08-493e-9352-226c4cedb08f", "metadata": {"aucs": [0.780029209181875, 0.8239155836649288, 0.8601657968132723], "final_y": [0.15301040174481828, 0.1419799610473793, 0.12667627272150406]}, "mutation_prompt": null}
{"id": "1d99a7a3-42c7-476c-8c86-2c74bbf6d6b2", "solution": "import numpy as np\nimport scipy.special as sp\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_swarm_size = 50\n        self.min_swarm_size = 20\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.9\n        self.initial_mutation_factor = 0.4\n        self.crossover_prob = 0.7\n        self.mutation_prob = 0.1\n\n    def levy_flight(self, dim):\n        beta = 1.5\n        sigma = (sp.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (sp.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.randn(dim) * sigma\n        v = np.random.randn(dim)\n        step = u / abs(v)**(1 / beta)\n        return step\n\n    def chaotic_local_search(self, position, lb, ub, scale_factor=0.015):\n        a = 0.5\n        b = 3.0\n        chaotic_sequence = a + (b - a) * np.random.rand(self.dim)\n        new_position = np.clip(position + chaotic_sequence * (ub - lb) * scale_factor, lb, ub)\n        return new_position\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm_size = self.initial_swarm_size\n        swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = swarm_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = 0.5 + 0.4 * np.sin(5 * np.pi * (evaluations / self.budget))\n            self.mutation_factor = self.initial_mutation_factor + 0.15 * (evaluations / self.budget)\n            adaptive_scale_factor = 0.02 + 0.03 * (evaluations / self.budget)\n\n            diversity_factor = np.std(swarm, axis=0) / (ub - lb)\n            mutation_adjustment = (np.random.rand(self.dim) < diversity_factor).astype(float)\n\n            elite_variance_factor = 1.0 - (0.5 * evaluations / self.budget)  # Added\n            for i in range(swarm_size):\n                velocities[i] = (elite_variance_factor * self.inertia_weight * velocities[i] +\n                                 self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - swarm[i]) +\n                                 self.c2 * np.random.rand(self.dim) * (global_best_position - swarm[i]))\n                velocities[i] = np.clip(velocities[i], -0.5 * abs(ub - lb), 0.5 * abs(ub - lb))\n\n                swarm[i] += velocities[i]\n                self.mutation_prob = 0.1 + 0.2 * (1 - evaluations / self.budget)\n                if np.random.rand() < self.mutation_prob:\n                    swarm[i] += self.levy_flight(self.dim) * mutation_adjustment\n                else:\n                    swarm[i] = self.chaotic_local_search(swarm[i], lb, ub, adaptive_scale_factor)\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                trial_score = func(swarm[i])\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = swarm[i]\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = swarm[i]\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n            if evaluations % (self.budget // 10) == 0:\n                swarm_size = max(self.min_swarm_size, swarm_size - 4)\n                swarm = swarm[:swarm_size]\n                velocities = velocities[:swarm_size]\n                personal_best_positions = personal_best_positions[:swarm_size]\n                personal_best_scores = personal_best_scores[:swarm_size]\n\n            if evaluations % (self.budget // 4) == 0:\n                elite_idx = np.argsort(personal_best_scores)[:5]\n                swarm[:5] = personal_best_positions[elite_idx]\n                swarm[5:] = np.random.uniform(lb, ub, (swarm_size - 5, self.dim))\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "Enhance HDPE by introducing temporal variance reduction in velocity updates and elite-guided exploration to improve robustness and convergence.", "configspace": "", "generation": 15, "fitness": 0.8225688021550445, "feedback": "The algorithm HDPE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.823 with standard deviation 0.005. And the mean value of best solutions found was 0.137 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "3a9e4e14-3e08-493e-9352-226c4cedb08f", "metadata": {"aucs": [0.8156704160848552, 0.8258393649169693, 0.8261966254633086], "final_y": [0.1349576659215752, 0.1386276551667548, 0.13615154104288385]}, "mutation_prompt": null}
{"id": "9df902c7-e030-448b-b014-20db9f53bf49", "solution": "import numpy as np\nimport scipy.special as sp\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_swarm_size = 50\n        self.min_swarm_size = 20\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.9\n        self.initial_mutation_factor = 0.4\n        self.crossover_prob = 0.7\n        self.mutation_prob = 0.1\n\n    def levy_flight(self, dim):\n        beta = 1.5\n        sigma = (sp.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (sp.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.randn(dim) * sigma\n        v = np.random.randn(dim)\n        step = u / abs(v)**(1 / beta)\n        return step\n\n    def chaotic_local_search(self, position, lb, ub, scale_factor=0.015):\n        a = 0.5\n        b = 3.0\n        chaotic_sequence = a + (b - a) * np.random.rand(self.dim)\n        new_position = np.clip(position + chaotic_sequence * (ub - lb) * scale_factor, lb, ub)\n        return new_position\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm_size = self.initial_swarm_size\n        swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = swarm_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = 0.5 + 0.4 * np.sin(5 * np.pi * (evaluations / self.budget))\n            self.mutation_factor = self.initial_mutation_factor + 0.15 * (evaluations / self.budget)\n            adaptive_scale_factor = 0.02 + 0.03 * (evaluations / self.budget)\n\n            diversity_factor = np.std(swarm, axis=0) / (ub - lb)  # Added line for diversity\n            mutation_adjustment = (np.random.rand(self.dim) < diversity_factor).astype(float)  # Added\n\n            for i in range(swarm_size):\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - swarm[i]) +\n                                 self.c2 * np.random.rand(self.dim) * (global_best_position - swarm[i]))\n                velocities[i] = np.clip(velocities[i], -0.5 * abs(ub - lb), 0.5 * abs(ub - lb))\n\n                swarm[i] += velocities[i]\n                self.crossover_prob = 0.5 + 0.5 * np.random.rand()  # Modified line to adjust crossover dynamically\n                self.mutation_prob = 0.1 + 0.2 * (1 - evaluations / self.budget)\n                if np.random.rand() < self.mutation_prob:\n                    swarm[i] += self.levy_flight(self.dim) * mutation_adjustment  # Modified\n                else:\n                    swarm[i] = self.chaotic_local_search(swarm[i], lb, ub, adaptive_scale_factor)\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                trial_score = func(swarm[i])\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = swarm[i]\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = swarm[i]\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n            if evaluations % (self.budget // 10) == 0:\n                swarm_size = max(self.min_swarm_size, swarm_size - 4)\n                swarm = swarm[:swarm_size]\n                velocities = velocities[:swarm_size]\n                personal_best_positions = personal_best_positions[:swarm_size]\n                personal_best_scores = personal_best_scores[:swarm_size]\n\n            if evaluations % (self.budget // 4) == 0:\n                elite_idx = np.argsort(personal_best_scores)[:5]\n                swarm[:5] = personal_best_positions[elite_idx]\n                swarm[5:] = np.random.uniform(lb, ub, (swarm_size - 5, self.dim))\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "Enhance HDPE by dynamically adjusting the crossover probability to improve solution diversity and convergence.", "configspace": "", "generation": 15, "fitness": 0.8282088623145532, "feedback": "The algorithm HDPE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.828 with standard deviation 0.013. And the mean value of best solutions found was 0.138 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "3a9e4e14-3e08-493e-9352-226c4cedb08f", "metadata": {"aucs": [0.8105991915539933, 0.8416579548187659, 0.8323694405709], "final_y": [0.14312085405008423, 0.13275599836733543, 0.1386919649623236]}, "mutation_prompt": null}
{"id": "867892a1-506b-4f7c-a31c-fc2dc9a44e2a", "solution": "import numpy as np\nimport scipy.special as sp\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_swarm_size = 50\n        self.min_swarm_size = 20\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.9\n        self.initial_mutation_factor = 0.4\n        self.crossover_prob = 0.7\n        self.mutation_prob = 0.1\n\n    def levy_flight(self, dim):\n        beta = 1.5\n        sigma = (sp.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (sp.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.randn(dim) * sigma\n        v = np.random.randn(dim)\n        step = u / abs(v)**(1 / beta)\n        return step\n\n    def chaotic_local_search(self, position, lb, ub, scale_factor=0.015):\n        a = 0.5\n        b = 3.0\n        chaotic_sequence = a + (b - a) * np.random.rand(self.dim)\n        new_position = np.clip(position + chaotic_sequence * (ub - lb) * scale_factor, lb, ub)\n        return new_position\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm_size = self.initial_swarm_size\n        swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = swarm_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = 0.5 + 0.4 * np.cos(5 * np.pi * (evaluations / self.budget))  # Modified line\n            self.mutation_factor = self.initial_mutation_factor + 0.15 * (evaluations / self.budget)\n            adaptive_scale_factor = 0.02 + 0.03 * (evaluations / self.budget)\n\n            diversity_factor = np.std(swarm, axis=0) / (ub - lb)  # Added line for diversity\n            mutation_adjustment = (np.random.rand(self.dim) < diversity_factor).astype(float)  # Added\n\n            for i in range(swarm_size):\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - swarm[i]) +\n                                 self.c2 * np.random.rand(self.dim) * (global_best_position - swarm[i]))\n                velocities[i] = np.clip(velocities[i], -0.5 * abs(ub - lb), 0.5 * abs(ub - lb))\n\n                swarm[i] += velocities[i]\n                self.mutation_prob = 0.1 + 0.2 * (1 - evaluations / self.budget)\n                if np.random.rand() < self.mutation_prob:\n                    swarm[i] += self.levy_flight(self.dim) * mutation_adjustment  # Modified\n                else:\n                    swarm[i] = self.chaotic_local_search(swarm[i], lb, ub, adaptive_scale_factor)\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                trial_score = func(swarm[i])\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = swarm[i]\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = swarm[i]\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n            if evaluations % (self.budget // 10) == 0:\n                swarm_size = max(self.min_swarm_size, swarm_size - 4)\n                swarm = swarm[:swarm_size]\n                velocities = velocities[:swarm_size]\n                personal_best_positions = personal_best_positions[:swarm_size]\n                personal_best_scores = personal_best_scores[:swarm_size]\n\n            if evaluations % (self.budget // 4) == 0:\n                elite_idx = np.argsort(personal_best_scores)[:5]\n                swarm[:5] = personal_best_positions[elite_idx]\n                swarm[5:] = np.random.uniform(lb, ub, (swarm_size - 5, self.dim))\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "Enhance HDPE by utilizing dynamic inertia weight adjustment to improve balance between exploration and exploitation.", "configspace": "", "generation": 15, "fitness": 0.822679804626525, "feedback": "The algorithm HDPE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.823 with standard deviation 0.011. And the mean value of best solutions found was 0.138 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "3a9e4e14-3e08-493e-9352-226c4cedb08f", "metadata": {"aucs": [0.8345934445999508, 0.8071770667988685, 0.826268902480756], "final_y": [0.13186425181452488, 0.1533135547984008, 0.1299485090923984]}, "mutation_prompt": null}
{"id": "02f27201-354e-45a9-934d-c9327e37e7e5", "solution": "import numpy as np\nimport scipy.special as sp\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_swarm_size = 50\n        self.min_swarm_size = 20\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.9\n        self.initial_mutation_factor = 0.4\n        self.crossover_prob = 0.7\n        self.mutation_prob = 0.1\n\n    def levy_flight(self, dim):\n        beta = 1.5\n        sigma = (sp.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (sp.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.randn(dim) * sigma\n        v = np.random.randn(dim)\n        step = u / abs(v)**(1 / beta)\n        return step\n\n    def chaotic_local_search(self, position, lb, ub, scale_factor=0.015):\n        a = 0.5\n        b = 3.0\n        chaotic_sequence = a + (b - a) * np.random.rand(self.dim)\n        new_position = np.clip(position + chaotic_sequence * (ub - lb) * scale_factor, lb, ub)\n        return new_position\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm_size = self.initial_swarm_size\n        swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = swarm_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = 0.5 + 0.1 * np.sin(5 * np.pi * (evaluations / self.budget))  # Modified line\n            self.mutation_factor = self.initial_mutation_factor + 0.15 * (evaluations / self.budget)\n            adaptive_scale_factor = 0.02 + 0.03 * (evaluations / self.budget)\n\n            diversity_factor = np.std(swarm, axis=0) / (ub - lb)\n            mutation_adjustment = (np.random.rand(self.dim) < diversity_factor).astype(float)\n\n            for i in range(swarm_size):\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - swarm[i]) +\n                                 self.c2 * np.random.rand(self.dim) * (global_best_position - swarm[i]))\n                velocities[i] = np.clip(velocities[i], -0.5 * abs(ub - lb), 0.5 * abs(ub - lb))\n\n                swarm[i] += velocities[i]\n                self.crossover_prob = 0.5 + 0.5 * np.random.rand()\n                self.mutation_prob = 0.1 + 0.2 * (1 - evaluations / self.budget)\n                if np.random.rand() < self.mutation_prob:\n                    swarm[i] += self.levy_flight(self.dim) * mutation_adjustment\n                else:\n                    swarm[i] = self.chaotic_local_search(swarm[i], lb, ub, adaptive_scale_factor)\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                trial_score = func(swarm[i])\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = swarm[i]\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = swarm[i]\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n            if evaluations % (self.budget // 10) == 0:\n                swarm_size = max(self.min_swarm_size, swarm_size - 4)\n                swarm = swarm[:swarm_size]\n                velocities = velocities[:swarm_size]\n                personal_best_positions = personal_best_positions[:swarm_size]\n                personal_best_scores = personal_best_scores[:swarm_size]\n\n            if evaluations % (self.budget // 4) == 0:\n                elite_idx = np.argsort(personal_best_scores)[:5]\n                swarm[:5] = personal_best_positions[elite_idx]\n                swarm[5:] = np.random.uniform(lb, ub, (swarm_size - 5, self.dim))\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "Enhance HDPE by adjusting the inertia weight dynamically to improve exploration and exploitation balance.", "configspace": "", "generation": 16, "fitness": 0.8211642292906459, "feedback": "The algorithm HDPE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.821 with standard deviation 0.021. And the mean value of best solutions found was 0.142 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "9df902c7-e030-448b-b014-20db9f53bf49", "metadata": {"aucs": [0.8493260919586126, 0.7990557979050573, 0.8151107980082676], "final_y": [0.1276340854633764, 0.15665285194233358, 0.14226348303572656]}, "mutation_prompt": null}
{"id": "d2a7ec72-8080-4ddc-90ca-a8959ca61456", "solution": "import numpy as np\nimport scipy.special as sp\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_swarm_size = 50\n        self.min_swarm_size = 20\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.9\n        self.initial_mutation_factor = 0.4\n        self.crossover_prob = 0.7\n        self.mutation_prob = 0.1\n\n    def levy_flight(self, dim):\n        beta = 1.5\n        sigma = (sp.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (sp.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.randn(dim) * sigma\n        v = np.random.randn(dim)\n        step = u / abs(v)**(1 / beta)\n        return step\n\n    def chaotic_local_search(self, position, lb, ub, scale_factor=0.015):\n        a = 0.5\n        b = 3.0\n        chaotic_sequence = a + (b - a) * np.random.rand(self.dim)\n        new_position = np.clip(position + chaotic_sequence * (ub - lb) * scale_factor, lb, ub)\n        return new_position\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm_size = self.initial_swarm_size\n        swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = swarm_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = 0.5 + 0.4 * np.sin(5 * np.pi * (evaluations / self.budget))\n            self.mutation_factor = self.initial_mutation_factor + 0.15 * (evaluations / self.budget)\n            adaptive_scale_factor = 0.02 + 0.03 * (evaluations / self.budget)\n\n            diversity_factor = np.std(swarm, axis=0) / (ub - lb)  # Added line for diversity\n            mutation_adjustment = (np.random.rand(self.dim) < diversity_factor).astype(float)  # Added\n\n            for i in range(swarm_size):\n                learning_rate = 0.1 + 0.9 * (1 - evaluations / self.budget)  # Modified line\n                velocities[i] = (learning_rate * self.inertia_weight * velocities[i] +  # Modified line\n                                 self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - swarm[i]) +\n                                 self.c2 * np.random.rand(self.dim) * (global_best_position - swarm[i]))\n                velocities[i] = np.clip(velocities[i], -0.5 * abs(ub - lb), 0.5 * abs(ub - lb))\n\n                swarm[i] += velocities[i]\n                self.crossover_prob = 0.5 + 0.5 * np.random.rand()  # Modified line to adjust crossover dynamically\n                self.mutation_prob = 0.1 + 0.2 * (1 - evaluations / self.budget)\n                if np.random.rand() < self.mutation_prob:\n                    swarm[i] += self.levy_flight(self.dim) * mutation_adjustment  # Modified\n                else:\n                    swarm[i] = self.chaotic_local_search(swarm[i], lb, ub, adaptive_scale_factor)\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                trial_score = func(swarm[i])\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = swarm[i]\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = swarm[i]\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n            if evaluations % (self.budget // 10) == 0:\n                swarm_size = max(self.min_swarm_size, swarm_size - 4)\n                swarm = swarm[:swarm_size]\n                velocities = velocities[:swarm_size]\n                personal_best_positions = personal_best_positions[:swarm_size]\n                personal_best_scores = personal_best_scores[:swarm_size]\n\n            if evaluations % (self.budget // 4) == 0:\n                elite_idx = np.argsort(personal_best_scores)[:5]\n                swarm[:5] = personal_best_positions[elite_idx]\n                swarm[5:] = np.random.uniform(lb, ub, (swarm_size - 5, self.dim))\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "Enhance HDPE by introducing a dynamic learning rate for velocities to balance exploration and exploitation.", "configspace": "", "generation": 16, "fitness": 0.8169601357227328, "feedback": "The algorithm HDPE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.817 with standard deviation 0.008. And the mean value of best solutions found was 0.139 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "9df902c7-e030-448b-b014-20db9f53bf49", "metadata": {"aucs": [0.8273897303956744, 0.8159517664826504, 0.8075389102898735], "final_y": [0.13801323940537213, 0.13802352661794515, 0.14224877416646942]}, "mutation_prompt": null}
{"id": "1ccf7804-8b63-46b2-9dbe-05cebccd2469", "solution": "import numpy as np\nimport scipy.special as sp\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_swarm_size = 50\n        self.min_swarm_size = 20\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.9\n        self.initial_mutation_factor = 0.4\n        self.crossover_prob = 0.7\n        self.mutation_prob = 0.1\n\n    def levy_flight(self, dim):\n        beta = 1.5\n        sigma = (sp.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (sp.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.randn(dim) * sigma\n        v = np.random.randn(dim)\n        step = u / abs(v)**(1 / beta)\n        return step\n\n    def gaussian_mutation(self, solution):  # Added function\n        return solution + np.random.normal(0, 0.1, self.dim)  # Modified line\n\n    def chaotic_local_search(self, position, lb, ub, scale_factor=0.015):\n        a = 0.5\n        b = 3.0\n        chaotic_sequence = a + (b - a) * np.random.rand(self.dim)\n        new_position = np.clip(position + chaotic_sequence * (ub - lb) * scale_factor, lb, ub)\n        return new_position\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm_size = self.initial_swarm_size\n        swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = swarm_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = 0.5 + 0.4 * np.sin(5 * np.pi * (evaluations / self.budget))\n            self.mutation_factor = self.initial_mutation_factor + 0.15 * (evaluations / self.budget)\n            adaptive_scale_factor = 0.02 + 0.03 * (evaluations / self.budget)\n\n            diversity_factor = np.std(swarm, axis=0) / (ub - lb)\n            mutation_adjustment = (np.random.rand(self.dim) < diversity_factor).astype(float)\n\n            for i in range(swarm_size):\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - swarm[i]) +\n                                 self.c2 * np.random.rand(self.dim) * (global_best_position - swarm[i]))\n                velocities[i] = np.clip(velocities[i], -0.5 * abs(ub - lb), 0.5 * abs(ub - lb))\n\n                swarm[i] += velocities[i]\n                self.crossover_prob = 0.5 + 0.5 * np.random.rand()\n                self.mutation_prob = 0.1 + 0.2 * (1 - evaluations / self.budget)\n                if np.random.rand() < self.mutation_prob:\n                    swarm[i] = self.gaussian_mutation(swarm[i])  # Modified line\n                else:\n                    swarm[i] = self.chaotic_local_search(swarm[i], lb, ub, adaptive_scale_factor)\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                trial_score = func(swarm[i])\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = swarm[i]\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = swarm[i]\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n            if evaluations % (self.budget // 10) == 0:\n                swarm_size = max(self.min_swarm_size, swarm_size - 4)\n                swarm = swarm[:swarm_size]\n                velocities = velocities[:swarm_size]\n                personal_best_positions = personal_best_positions[:swarm_size]\n                personal_best_scores = personal_best_scores[:swarm_size]\n\n            if evaluations % (self.budget // 4) == 0:\n                elite_idx = np.argsort(personal_best_scores)[:5]\n                swarm[:5] = personal_best_positions[elite_idx]\n                swarm[5:] = np.random.uniform(lb, ub, (swarm_size - 5, self.dim))\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "Refine HDPE by introducing a Gaussian mutation mechanism to improve exploration and convergence balance.", "configspace": "", "generation": 16, "fitness": 0.8050115402434278, "feedback": "The algorithm HDPE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.805 with standard deviation 0.013. And the mean value of best solutions found was 0.147 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "9df902c7-e030-448b-b014-20db9f53bf49", "metadata": {"aucs": [0.8032908310345015, 0.8220311329652839, 0.7897126567304982], "final_y": [0.14688880305970542, 0.14355452109233824, 0.15164547408065587]}, "mutation_prompt": null}
{"id": "11529495-7c95-4aa9-bb7e-f03d2633dc2a", "solution": "import numpy as np\nimport scipy.special as sp\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_swarm_size = 50\n        self.min_swarm_size = 20\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.9\n        self.initial_mutation_factor = 0.4\n        self.crossover_prob = 0.7\n        self.mutation_prob = 0.1\n\n    def levy_flight(self, dim):\n        beta = 1.5\n        sigma = (sp.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (sp.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.randn(dim) * sigma\n        v = np.random.randn(dim)\n        step = u / abs(v)**(1 / beta)\n        return step\n\n    def chaotic_local_search(self, position, lb, ub, scale_factor=0.015):\n        a = 0.5\n        b = 3.0\n        chaotic_sequence = a + (b - a) * np.random.rand(self.dim)\n        new_position = np.clip(position + chaotic_sequence * (ub - lb) * scale_factor, lb, ub)\n        return new_position\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm_size = self.initial_swarm_size\n        swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = swarm_size\n\n        while evaluations < self.budget:\n            diversity_factor = np.std(swarm, axis=0) / (ub - lb)  # Added line for diversity\n            self.inertia_weight = 0.5 + 0.4 * np.sin(5 * np.pi * (evaluations / self.budget)) * (1 - np.mean(diversity_factor))  # Modified line\n\n            self.mutation_factor = self.initial_mutation_factor + 0.15 * (evaluations / self.budget)\n            adaptive_scale_factor = 0.02 + 0.03 * (evaluations / self.budget)\n\n            mutation_adjustment = (np.random.rand(self.dim) < diversity_factor).astype(float)  # Added\n\n            for i in range(swarm_size):\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - swarm[i]) +\n                                 self.c2 * np.random.rand(self.dim) * (global_best_position - swarm[i]))\n                velocities[i] = np.clip(velocities[i], -0.5 * abs(ub - lb), 0.5 * abs(ub - lb))\n\n                swarm[i] += velocities[i]\n                self.crossover_prob = 0.5 + 0.5 * np.random.rand()  # Modified line to adjust crossover dynamically\n                self.mutation_prob = 0.1 + 0.2 * (1 - evaluations / self.budget)\n                if np.random.rand() < self.mutation_prob:\n                    swarm[i] += self.levy_flight(self.dim) * mutation_adjustment  # Modified\n                else:\n                    swarm[i] = self.chaotic_local_search(swarm[i], lb, ub, adaptive_scale_factor)\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                trial_score = func(swarm[i])\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = swarm[i]\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = swarm[i]\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n            if evaluations % (self.budget // 10) == 0:\n                swarm_size = max(self.min_swarm_size, swarm_size - 4)\n                swarm = swarm[:swarm_size]\n                velocities = velocities[:swarm_size]\n                personal_best_positions = personal_best_positions[:swarm_size]\n                personal_best_scores = personal_best_scores[:swarm_size]\n\n            if evaluations % (self.budget // 4) == 0:\n                elite_idx = np.argsort(personal_best_scores)[:5]\n                swarm[:5] = personal_best_positions[elite_idx]\n                swarm[5:] = np.random.uniform(lb, ub, (swarm_size - 5, self.dim))\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "Refine HDPE by dynamically adjusting the inertia weight as a function of the diversity factor for better convergence.", "configspace": "", "generation": 16, "fitness": 0.8129359169938469, "feedback": "The algorithm HDPE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.813 with standard deviation 0.021. And the mean value of best solutions found was 0.144 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "9df902c7-e030-448b-b014-20db9f53bf49", "metadata": {"aucs": [0.7880256488150795, 0.8124068664899936, 0.8383752356764675], "final_y": [0.15280895817133344, 0.14694996330726218, 0.13199805645193763]}, "mutation_prompt": null}
{"id": "7b776208-cfab-4617-91b0-6f0cc3f0bff3", "solution": "import numpy as np\nimport scipy.special as sp\n\nclass HDPE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_swarm_size = 50\n        self.min_swarm_size = 20\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.inertia_weight = 0.9\n        self.initial_mutation_factor = 0.4\n        self.crossover_prob = 0.7\n        self.mutation_prob = 0.1\n\n    def levy_flight(self, dim):\n        beta = 1.5\n        sigma = (sp.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (sp.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.randn(dim) * sigma\n        v = np.random.randn(dim)\n        step = u / abs(v)**(1 / beta)\n        return step\n\n    def chaotic_local_search(self, position, lb, ub, scale_factor=0.015):\n        a = 0.5\n        b = 3.0\n        chaotic_sequence = a + (b - a) * np.random.rand(self.dim)\n        adaptive_scale = scale_factor * (1 + np.std(position) / (ub - lb))  # Modified\n        new_position = np.clip(position + chaotic_sequence * (ub - lb) * adaptive_scale, lb, ub)  # Modified\n        return new_position\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm_size = self.initial_swarm_size\n        swarm = np.random.uniform(lb, ub, (swarm_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (swarm_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(ind) for ind in swarm])\n        global_best_position = swarm[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        evaluations = swarm_size\n\n        while evaluations < self.budget:\n            self.inertia_weight = 0.5 + 0.4 * np.sin(5 * np.pi * (evaluations / self.budget))\n            self.mutation_factor = self.initial_mutation_factor + 0.15 * (evaluations / self.budget)\n            adaptive_scale_factor = 0.02 + 0.03 * (evaluations / self.budget)\n\n            diversity_factor = np.std(swarm, axis=0) / (ub - lb)  # Added line for diversity\n            mutation_adjustment = (np.random.rand(self.dim) < diversity_factor).astype(float)  # Added\n\n            for i in range(swarm_size):\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - swarm[i]) +\n                                 self.c2 * np.random.rand(self.dim) * (global_best_position - swarm[i]))\n                velocities[i] = np.clip(velocities[i], -0.5 * abs(ub - lb), 0.5 * abs(ub - lb))\n\n                swarm[i] += velocities[i]\n                self.crossover_prob = 0.5 + 0.5 * np.random.rand()  # Modified line to adjust crossover dynamically\n                self.mutation_prob = 0.1 + 0.2 * (1 - evaluations / self.budget)\n                if np.random.rand() < self.mutation_prob:\n                    swarm[i] += self.levy_flight(self.dim) * mutation_adjustment  # Modified\n                else:\n                    swarm[i] = self.chaotic_local_search(swarm[i], lb, ub, adaptive_scale_factor)\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                trial_score = func(swarm[i])\n                evaluations += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = swarm[i]\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = swarm[i]\n                        global_best_score = trial_score\n                        if evaluations >= self.budget:\n                            break\n\n            if evaluations % (self.budget // 10) == 0:\n                swarm_size = max(self.min_swarm_size, swarm_size - 4)\n                swarm = swarm[:swarm_size]\n                velocities = velocities[:swarm_size]\n                personal_best_positions = personal_best_positions[:swarm_size]\n                personal_best_scores = personal_best_scores[:swarm_size]\n\n            if evaluations % (self.budget // 4) == 0:\n                elite_idx = np.argsort(personal_best_scores)[:5]\n                swarm[:5] = personal_best_positions[elite_idx]  # Reinforce elite positions\n                swarm[5:] = np.random.uniform(lb, ub, (swarm_size - 5, self.dim))\n\n        return global_best_position, global_best_score", "name": "HDPE", "description": "Update HDPE by introducing adaptive chaotic sequence scaling and elite position reinforcement to improve exploration and convergence.", "configspace": "", "generation": 16, "fitness": 0.818398347486653, "feedback": "The algorithm HDPE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.818 with standard deviation 0.025. And the mean value of best solutions found was 0.138 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "9df902c7-e030-448b-b014-20db9f53bf49", "metadata": {"aucs": [0.8512686235077378, 0.8114926840404807, 0.7924337349117402], "final_y": [0.12770626725950474, 0.14179258647145143, 0.1450683747876309]}, "mutation_prompt": null}
