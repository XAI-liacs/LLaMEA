{"id": "9d02e1ac-3e2b-4820-be41-557aeac4f4c4", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20  # Population size for DE\n        self.F = 0.8  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n        return result.x if result.success else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "A hybrid Differential Evolution with Quasi-Oppositional Initialization and Local Search (BFGS) that encourages periodicity for optimizing multilayered photonic structures.", "configspace": "", "generation": 0, "fitness": 0.9064377285298809, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.906 with standard deviation 0.034. And the mean value of best solutions found was 0.176 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": null, "metadata": {"aucs": [0.932260367920839, 0.928572906741042, 0.8584799109277618], "final_y": [0.1818843949325728, 0.18187968060544402, 0.16485701886074233]}, "mutation_prompt": null}
{"id": "2d5bc589-1e54-4533-bc4c-8f169b5a77d0", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F = 0.8\n        self.CR = 0.9\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        best_idx = np.argmin([self._evaluate(ind, func) for ind in population])\n        best_candidate = population[best_idx]\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            adaptive_CR = self.CR * (0.5 + 0.5 * np.random.rand())\n            cross_points = np.random.rand(self.dim) < adaptive_CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        new_population[0] = best_candidate  # Elitism: preserve best candidate\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n        return result.x if result.success else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Enhanced HybridDE with variable adaptive crossover rates and elitism for improved exploration and convergence.", "configspace": "", "generation": 1, "fitness": 0.8726571782520628, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.873 with standard deviation 0.081. And the mean value of best solutions found was 0.195 (0. is the best) with standard deviation 0.018.", "error": "", "parent_id": "9d02e1ac-3e2b-4820-be41-557aeac4f4c4", "metadata": {"aucs": [0.9316850436274102, 0.9281262670372369, 0.7581602240915417], "final_y": [0.1818843949325728, 0.18187968060544402, 0.2206526147280521]}, "mutation_prompt": null}
{"id": "86491395-50da-4bea-844c-810edf32ef61", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, dim)  # Adaptive population size\n        self.F = 0.8  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            F_adaptive = 0.5 + np.random.rand() * 0.5  # Adaptive F\n            mutant = np.clip(a + F_adaptive * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n        return result.x if result.success else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        # Bias towards periodicity by introducing penalty for non-periodicity\n        periodicity_penalty = np.std(candidate) * 0.1\n        return func(candidate) + periodicity_penalty\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "An Enhanced HybridDE with Adaptive Parameters and Periodicity-Promoting Bias integrated for optimizing multilayered photonic structures.", "configspace": "", "generation": 1, "fitness": 0.953139591548954, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.953 with standard deviation 0.040. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "9d02e1ac-3e2b-4820-be41-557aeac4f4c4", "metadata": {"aucs": [0.9833565445780522, 0.9790283677029205, 0.8970338623658891], "final_y": [0.16485727886349832, 0.16485722052580187, 0.16485616820735127]}, "mutation_prompt": null}
{"id": "fec413e1-9d9c-40d8-a3a1-9639e81b5459", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n        if result.success:\n            return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2)  # Enforce periodicity\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Enhanced HybridDE with adaptive parameter control and periodicity-driven local search to improve optimization of multilayered photonic structures.", "configspace": "", "generation": 1, "fitness": 0.9615442321860804, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.962 with standard deviation 0.014. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "9d02e1ac-3e2b-4820-be41-557aeac4f4c4", "metadata": {"aucs": [0.9572093655645889, 0.9802334090574292, 0.9471899219362233], "final_y": [0.16485591495707597, 0.16485597358016013, 0.1648581941757935]}, "mutation_prompt": null}
{"id": "5058eb24-6ed1-4d7a-9649-507662344b06", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20  # Population size for DE\n        self.F = 0.8  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _periodicity_mutation(self, a, b, c, lb, ub):\n        mutation = a + self.F * (b - c)\n        # Encourage periodicity by adding a sinusoidal component\n        mutation += np.sin(np.arange(self.dim) * np.pi / self.dim)\n        return np.clip(mutation, lb, ub)\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = self._periodicity_mutation(a, b, c, bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n        return result.x if result.success else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Enhanced HybridDE algorithm introducing a periodicity-aware mutation operator and adaptive crossover rate to better navigate the complex optimization landscape of multilayered photonic structures.", "configspace": "", "generation": 1, "fitness": 0.9278292860989681, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.928 with standard deviation 0.052. And the mean value of best solutions found was 0.179 (0. is the best) with standard deviation 0.020.", "error": "", "parent_id": "9d02e1ac-3e2b-4820-be41-557aeac4f4c4", "metadata": {"aucs": [0.9801708801487562, 0.856948212954853, 0.9463687651932952], "final_y": [0.16486010797611128, 0.2072587157028981, 0.16485726121579514]}, "mutation_prompt": null}
{"id": "8a436ae1-bfd0-4459-8bb0-b24d76ec4cc8", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20  # Population size for DE\n        self.F = 0.8  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR * (1 - self.used_budget / self.budget)\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n        return result.x if result.success else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Enhancing exploration by adapting crossover probability dynamically for improved performance in HybridDE.", "configspace": "", "generation": 1, "fitness": 0.932436238787882, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.932 with standard deviation 0.020. And the mean value of best solutions found was 0.178 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "9d02e1ac-3e2b-4820-be41-557aeac4f4c4", "metadata": {"aucs": [0.9322678863958425, 0.9085488444507169, 0.9564919855170866], "final_y": [0.1818843949325728, 0.1881326818252269, 0.16485922956047538]}, "mutation_prompt": null}
{"id": "41ee0150-d782-4573-b104-cf3cbcd9ffc5", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9\n        self.CR_min, self.CR_max = 0.4, 0.9\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n        if result.success:\n            return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 4], 4)  # Enforce stronger periodicity\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Augmented HybridDE with dynamic population resizing and enhanced periodicity enforcement to optimize photonic structures.", "configspace": "", "generation": 2, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"cannot access local variable 'ub' where it is not associated with a value\").", "error": "UnboundLocalError(\"cannot access local variable 'ub' where it is not associated with a value\")", "parent_id": "fec413e1-9d9c-40d8-a3a1-9639e81b5459", "metadata": {}, "mutation_prompt": null}
{"id": "28fd639f-6a9a-4a4d-ac91-1c844242b895", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c) + 0.1 * (population[i] - a), bounds.lb, bounds.ub)  # Added exploration term\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n        if result.success:\n            return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2)  # Enforce periodicity\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Improved HybridDE by modifying mutation strategy to enhance exploration and exploitation balance.", "configspace": "", "generation": 2, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"cannot access local variable 'ub' where it is not associated with a value\").", "error": "UnboundLocalError(\"cannot access local variable 'ub' where it is not associated with a value\")", "parent_id": "fec413e1-9d9c-40d8-a3a1-9639e81b5459", "metadata": {}, "mutation_prompt": null}
{"id": "969182cc-2382-4118-9a73-a126cab8381f", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n        if result.success:\n            return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2)  # Enforce periodicity\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            mirrored_population = lb + ub - population  # Mirror the population for diversity\n            population = np.vstack((population, mirrored_population))\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Enhanced HybridDE with adaptive parameter control and periodicity-driven local search using mirrored candidates for diversity.", "configspace": "", "generation": 2, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"cannot access local variable 'ub' where it is not associated with a value\").", "error": "UnboundLocalError(\"cannot access local variable 'ub' where it is not associated with a value\")", "parent_id": "fec413e1-9d9c-40d8-a3a1-9639e81b5459", "metadata": {}, "mutation_prompt": null}
{"id": "678c93de-715c-4e43-9f10-5feca0b4d0bc", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.4, 0.9  # Adjusted differential weight range\n        self.CR_min, self.CR_max = 0.5, 0.9  # Adjusted crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        periodic_population = np.tile(population[:, :self.dim // 2], (1, 2))  # Enforce periodicity in initialization\n        return np.vstack((population, q_opposite_population, periodic_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n        if result.success:\n            return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2)  # Enforce periodicity\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Refined HybridDE with periodicity-guided initialization and enhanced adaptive parameter scaling to improve exploration-exploitation balance for photonic optimization.", "configspace": "", "generation": 2, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"cannot access local variable 'ub' where it is not associated with a value\").", "error": "UnboundLocalError(\"cannot access local variable 'ub' where it is not associated with a value\")", "parent_id": "fec413e1-9d9c-40d8-a3a1-9639e81b5459", "metadata": {}, "mutation_prompt": null}
{"id": "07bbfd30-545b-4a27-a72f-416593df083d", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n        if result.success:\n            return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2)  # Enforce periodicity\n        # Introduced a refined local search with gradient check\n        refined_candidate = minimize(func, periodic_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='CG').x\n        return refined_candidate if self._evaluate(refined_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Enhanced HybridDE with opposition-based learning and improved local search for higher precision in photonic structure optimization.", "configspace": "", "generation": 2, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"cannot access local variable 'ub' where it is not associated with a value\").", "error": "UnboundLocalError(\"cannot access local variable 'ub' where it is not associated with a value\")", "parent_id": "fec413e1-9d9c-40d8-a3a1-9639e81b5459", "metadata": {}, "mutation_prompt": null}
{"id": "914cfa7b-ccf3-4bbf-9ad0-4c062ac730cd", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n        self.best_solution = None\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n    \n    def _local_search(self, best_candidate, func, bounds):\n        result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n        if result.success:\n            return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2)  # Enforce periodicity\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        candidate_score = func(candidate)\n        if self.best_solution is None or candidate_score < self._evaluate(self.best_solution, func):\n            self.best_solution = candidate\n        return candidate_score\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        return self.best_solution", "name": "HybridDE", "description": "Introduced elitism in DE to preserve the best solution found so far, enhancing convergence stability and solution quality.", "configspace": "", "generation": 3, "fitness": -Infinity, "feedback": "An exception occurred: RecursionError('maximum recursion depth exceeded').", "error": "RecursionError('maximum recursion depth exceeded')", "parent_id": "fec413e1-9d9c-40d8-a3a1-9639e81b5459", "metadata": {}, "mutation_prompt": null}
{"id": "5bb64756-8b71-4b1c-9c8f-7cf05e45badb", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), options={'maxiter': 50}, method='L-BFGS-B')\n        if result.success:\n            return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2)  # Enforce periodicity\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Introduces a refined local search mechanism using periodicity-driven L-BFGS-B for enhanced convergence.", "configspace": "", "generation": 3, "fitness": 0.9539699595778145, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.954 with standard deviation 0.018. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "fec413e1-9d9c-40d8-a3a1-9639e81b5459", "metadata": {"aucs": [0.9323883486073707, 0.9773032679736233, 0.9522182621524496], "final_y": [0.1818843949325728, 0.16485626993216673, 0.16485754722212642]}, "mutation_prompt": null}
{"id": "b4014d0b-6332-4b5e-938f-dd477f7aafed", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(20, self.budget // 10)  # Dynamic population size adjustment\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n        if result.success:\n            return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2)  # Enforce periodicity\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Enhance the HybridDE algorithm by incorporating dynamic population size adjustment to better adapt to the optimization landscape.", "configspace": "", "generation": 3, "fitness": 0.9538691722209629, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.954 with standard deviation 0.024. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "fec413e1-9d9c-40d8-a3a1-9639e81b5459", "metadata": {"aucs": [0.9460750593925976, 0.9287219669279333, 0.9868104903423578], "final_y": [0.16485752975277768, 0.18187884026907986, 0.16485715719903726]}, "mutation_prompt": null}
{"id": "332c5e00-f5b5-475f-9e91-1d901d5f112b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c) + 0.1 * (np.random.rand(self.dim) - 0.5), bounds.lb, bounds.ub)  # Added mutation\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n        if result.success:\n            best_candidate = result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2)  # Enforce periodicity\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Improved HybridDE by enhancing local search with periodicity constraints and augmenting DE step with a mutation mechanism to better explore the search space.", "configspace": "", "generation": 3, "fitness": 0.9585058986997609, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.959 with standard deviation 0.019. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "fec413e1-9d9c-40d8-a3a1-9639e81b5459", "metadata": {"aucs": [0.9328207898293956, 0.979925904739329, 0.9627710015305582], "final_y": [0.18187884304024848, 0.16485620153450142, 0.16486129690354834]}, "mutation_prompt": null}
{"id": "a117ce1f-c6b8-408f-9cdc-cd4e2d60d76e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.95  # Enhanced adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n        if result.success:\n            return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2)  # Enforce periodicity\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Refined HybridDE with enhanced adaptive crossover probability strategy for improved black-box optimization performance.", "configspace": "", "generation": 3, "fitness": 0.9460844536498745, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.946 with standard deviation 0.010. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "fec413e1-9d9c-40d8-a3a1-9639e81b5459", "metadata": {"aucs": [0.9328506061866707, 0.9488169356714886, 0.956585819091464], "final_y": [0.18188076587508006, 0.16485775304841366, 0.16485705842817555]}, "mutation_prompt": null}
{"id": "cead6b02-5eef-420c-8a92-03ecad896252", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='TNC')  # Changed method\n        if result.success:\n            return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2)  # Enforce periodicity\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Improved HybridDE with slight adaptation to the local search strategy for optimizing multilayered photonic structures.", "configspace": "", "generation": 4, "fitness": 0.9390763139823216, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.939 with standard deviation 0.027. And the mean value of best solutions found was 0.177 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "fec413e1-9d9c-40d8-a3a1-9639e81b5459", "metadata": {"aucs": [0.9122937569927821, 0.9281635013685161, 0.9767716835856667], "final_y": [0.18532101578879023, 0.18187968060544402, 0.1648569763517287]}, "mutation_prompt": null}
{"id": "2567bb5a-54f0-44d0-a212-ad42f65286bb", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n        if result.success:\n            best_candidate = result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2)  # Enforce periodicity with adaptive segment\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Improved Enhanced HybridDE by incorporating adaptive periodicity updates in local search for better reflection maximization.", "configspace": "", "generation": 4, "fitness": 0.95011738243584, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.950 with standard deviation 0.028. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "fec413e1-9d9c-40d8-a3a1-9639e81b5459", "metadata": {"aucs": [0.9427894660508279, 0.9195450850754168, 0.9880175961812752], "final_y": [0.16485686652172726, 0.16485724937269308, 0.16485667368891854]}, "mutation_prompt": null}
{"id": "a533941c-2829-458a-89e9-c7f3b910846f", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n        self.chaos = 0.7\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        self.chaos = 4 * self.chaos * (1 - self.chaos)  # Logistic map\n        F = self.F_min + self.chaos * (self.F_max - self.F_min)\n        CR = self.CR_max - self.chaos * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n        if result.success:\n            return result.x\n        periodic_candidate = np.roll(best_candidate, shift=self.dim // 4)  # Improved periodicity\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Improved HybridDE by incorporating chaotic maps for adaptive parameter generation and enhanced local search for better convergence.", "configspace": "", "generation": 4, "fitness": 0.9502409281438494, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.950 with standard deviation 0.016. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "fec413e1-9d9c-40d8-a3a1-9639e81b5459", "metadata": {"aucs": [0.9328886376616977, 0.9467786815318608, 0.9710554652379896], "final_y": [0.1818843949325728, 0.1648558918962021, 0.16485976130212154]}, "mutation_prompt": null}
{"id": "8c49b43e-8eea-4341-b06c-74388ae9f36b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n        if result.success:\n            return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2)  # Enforce periodicity\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        self.population_size += int(self.budget * 0.001)  # Adjust population size dynamically based on budget\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Improved convergence speed by incorporating a dynamic population size adjustment based on the budget used, enhancing exploration-exploitation balance.", "configspace": "", "generation": 4, "fitness": 0.9508054016097978, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.951 with standard deviation 0.017. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "fec413e1-9d9c-40d8-a3a1-9639e81b5459", "metadata": {"aucs": [0.9556360431227449, 0.9276640275306911, 0.9691161341759575], "final_y": [0.1648560753470193, 0.18187836420890346, 0.16485702141301106]}, "mutation_prompt": null}
{"id": "bd21d6ab-02c2-4bac-8157-4451d7c6ed7e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n        if result.success:\n            periodic_candidate = np.tile(result.x[:self.dim // 2], 2)  # Enforce periodicity\n            return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(result.x, func) else result.x\n        return best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Refined HybridDE with enhanced local search periodicity enforcement to improve convergence on multilayered photonic structures.", "configspace": "", "generation": 4, "fitness": 0.9274078865583893, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.927 with standard deviation 0.037. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "fec413e1-9d9c-40d8-a3a1-9639e81b5459", "metadata": {"aucs": [0.933865290714287, 0.9692100339156233, 0.8791483350452575], "final_y": [0.1818843949325728, 0.16485775684363524, 0.16485599085052283]}, "mutation_prompt": null}
{"id": "f236f399-65a6-4a5b-a3a0-0a1fc532b0f0", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n        if result.success:\n            return result.x\n        adapt_ratio = self.used_budget / self.budget  # New line added for adaptive periodicity\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * adapt_ratio  # Enforce periodicity\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Introducing adaptive periodicity enforcement in the local search phase to refine solution convergence for multilayered photonic structures.", "configspace": "", "generation": 5, "fitness": 0.9470408864984167, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.947 with standard deviation 0.024. And the mean value of best solutions found was 0.176 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "fec413e1-9d9c-40d8-a3a1-9639e81b5459", "metadata": {"aucs": [0.9323954411827853, 0.9281377692484372, 0.9805894490640277], "final_y": [0.18187988208374817, 0.18187968060544402, 0.16485608532406204]}, "mutation_prompt": null}
{"id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.5:  # Selective local search\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.01 * np.random.randn(self.dim // 2, 2)).flatten()  # Adaptive periodic enforcement\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Enhanced HybridDE with selective local search and adaptive periodic enforcement for improved optimization of multilayered photonic structures.", "configspace": "", "generation": 5, "fitness": 0.9774319130564436, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.977 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "fec413e1-9d9c-40d8-a3a1-9639e81b5459", "metadata": {"aucs": [0.9659358417787995, 0.9825754186899682, 0.9837844787005632], "final_y": [0.16485586311153322, 0.16485615487090866, 0.16485612930374927]}, "mutation_prompt": null}
{"id": "b0e513f9-4cc9-456c-9130-63225a41a369", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n        if result.success:\n            best_candidate = result.x  # Update the best_candidate to the result of local search\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2)  # Enforce periodicity\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Improved exploitation stage in HybridDE by integrating local search with gradient-based optimization and symmetry enforcement.", "configspace": "", "generation": 5, "fitness": 0.9649133415244702, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.965 with standard deviation 0.023. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "fec413e1-9d9c-40d8-a3a1-9639e81b5459", "metadata": {"aucs": [0.9324908807442617, 0.9814147382218101, 0.9808344056073386], "final_y": [0.1818843949325728, 0.16485656115930825, 0.16485608532406204]}, "mutation_prompt": null}
{"id": "7b5174bb-5382-4996-9534-e20d340de178", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9\n        self.CR_min, self.CR_max = 0.4, 0.9\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            diversity_factor = np.random.uniform(0.9, 1.1)\n            trial = np.clip(trial * diversity_factor, bounds.lb, bounds.ub)\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n        if result.success:\n            return result.x\n        enhanced_candidate = best_candidate + np.sin(np.linspace(0, np.pi, self.dim)) * 0.01\n        return enhanced_candidate if self._evaluate(enhanced_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Improved HybridDE by integrating a diversity enhancement mechanism and a more effective local search strategy to better explore and exploit the optimization landscape.", "configspace": "", "generation": 5, "fitness": 0.9484976749277637, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.948 with standard deviation 0.023. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "fec413e1-9d9c-40d8-a3a1-9639e81b5459", "metadata": {"aucs": [0.9322601978305017, 0.9812760978284236, 0.9319567291243656], "final_y": [0.1818843949325728, 0.1648564658680527, 0.16485950103500524]}, "mutation_prompt": null}
{"id": "802878ae-27e4-40d0-872d-123965bf5c64", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9\n        self.CR_min, self.CR_max = 0.4, 0.9\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2)\n        result = minimize(func, periodic_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n        if result.success:\n            return result.x\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Fine-tune local search strategy by initializing with a periodic candidate to improve solution refinement.", "configspace": "", "generation": 5, "fitness": 0.9468121901430577, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.947 with standard deviation 0.048. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "fec413e1-9d9c-40d8-a3a1-9639e81b5459", "metadata": {"aucs": [0.8782907916822619, 0.9811288974737834, 0.9810168812731279], "final_y": [0.164857319727171, 0.1648564658680527, 0.16485608532406204]}, "mutation_prompt": null}
{"id": "05ea294d-7bf1-4fca-95fa-1e0439a3f0ba", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.5:  # Selective local search\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.05 * np.random.randn(self.dim // 2, 2)).flatten()  # Adaptive periodic enforcement\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Enhanced HybridDE with improved adaptive periodic enforcement for more robust optimization of multilayered photonic structures.", "configspace": "", "generation": 6, "fitness": 0.9399062417368257, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.940 with standard deviation 0.030. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9495116461089518, 0.9703694202475723, 0.8998376588539531], "final_y": [0.16485910269274273, 0.1648563643504959, 0.16485657976219437]}, "mutation_prompt": null}
{"id": "c8bb64d2-6b54-4e92-8c9a-72b929eff2a7", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = (self.used_budget / self.budget) ** 2\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.5:  # Selective local search\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.01 * np.random.randn(self.dim // 2, 2)).flatten()  # Adaptive periodic enforcement\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Enhanced HybridDE with selective local search and adaptive periodic enforcement with improved adaptive parameter scaling.", "configspace": "", "generation": 6, "fitness": 0.9014184686580086, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.901 with standard deviation 0.063. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9250237247068067, 0.8156718954405102, 0.9635597858267088], "final_y": [0.1818843949325728, 0.16485740577450503, 0.16485750331951643]}, "mutation_prompt": null}
{"id": "ff91a210-5aff-48f8-abdf-e88b765fbc10", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.3, 0.8  # Adjusted crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.7:  # Increased probability for selective local search\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.01 * np.random.randn(self.dim // 2, 2)).flatten()  # Adaptive periodic enforcement\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Enhanced HybridDE with optimized crossover mechanism and refined local search for superior optimization of multilayered photonic structures.", "configspace": "", "generation": 6, "fitness": 0.8436802602543843, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.844 with standard deviation 0.077. And the mean value of best solutions found was 0.207 (0. is the best) with standard deviation 0.036.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9322744884249233, 0.7443133098250665, 0.8544529825131629], "final_y": [0.1818843949325728, 0.25781124525436083, 0.18187864380544116]}, "mutation_prompt": null}
{"id": "e6dc6f10-d9ab-458f-bfca-f3fc11cde34d", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25  # Increased population size\n        self.F_min, self.F_max = 0.6, 0.9  # Slightly adjusted differential weight range\n        self.CR_min, self.CR_max = 0.3, 0.8  # Adjusted crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.7:  # Increased probability of local search\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.02 * np.random.randn(self.dim // 2, 2)).flatten()  # Adjusted periodic scale\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Refined HybridDE with enhanced local search and improved periodicity enforcement, ensuring better exploration and exploitation balance.", "configspace": "", "generation": 6, "fitness": 0.9625962775510978, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.963 with standard deviation 0.013. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9515719780712447, 0.9801421106683987, 0.9560747439136497], "final_y": [0.16485658079529342, 0.1648580950622821, 0.16485707331784094]}, "mutation_prompt": null}
{"id": "972546b9-a870-4093-9864-b0c264e3e819", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.3, 0.9  # Enhanced adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.5:  # Selective local search\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.01 * np.random.randn(self.dim // 2, 2)).flatten()  # Adaptive periodic enforcement\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Improved HybridDE with enhanced adaptive crossover probability range for better local exploration.", "configspace": "", "generation": 6, "fitness": 0.9578907647407102, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.958 with standard deviation 0.017. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9347536419081863, 0.9633250595930044, 0.9755935927209399], "final_y": [0.1818784953130974, 0.1648655471753514, 0.16485811904348546]}, "mutation_prompt": null}
{"id": "c3cac10c-dae6-4c5d-8bb3-f7e2069bf7e9", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.5:  # Selective local search\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.01 * np.random.randn(self.dim // 2, 2)).flatten()  # Adaptive periodic enforcement\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        self.population_size = int(self.population_size * (1 + 0.1 * np.sin(self.used_budget / self.budget * np.pi)))  # Dynamic population size adjustment\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Refined HybridDE using dynamic population size adjustment for enhanced exploration and exploitation.", "configspace": "", "generation": 7, "fitness": 0.9474743323594197, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.947 with standard deviation 0.015. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9495116461089518, 0.928137947720281, 0.964773403249026], "final_y": [0.16485910269274273, 0.18187843003622783, 0.16485731948282956]}, "mutation_prompt": null}
{"id": "35321744-0ac6-459a-9a39-b557bb146c4b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.7:  # Increased probability for selective local search\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2)  # Adjusted adaptive periodic enforcement\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Optimized HybridDE with enhanced local search activation probability and refined adaptive periodic enforcement for improved searching efficiency.", "configspace": "", "generation": 7, "fitness": 0.9743404544654882, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.974 with standard deviation 0.014. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9540224011494443, 0.9855437130675199, 0.9834552491795009], "final_y": [0.1648559682336116, 0.16485595410826492, 0.1648564400364383]}, "mutation_prompt": null}
{"id": "02dde78c-fbc1-488a-8fe4-4f83e8573228", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9\n        self.CR_min, self.CR_max = 0.4, 0.9\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        if self.used_budget / self.budget > 0.6:  # Dynamic population sizing\n            self.population_size = max(10, self.population_size // 2)\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.5:\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.01 * np.random.randn(self.dim // 2, 2)).flatten()\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "The Adaptive HybridDE now incorporates dynamic population sizing and enhanced mutation strategies to further improve optimization performance for multilayered photonic structures.", "configspace": "", "generation": 7, "fitness": 0.9683900599918916, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.968 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9791095751902177, 0.9589546371956238, 0.9671059675898334], "final_y": [0.16485691032190242, 0.16485714575519006, 0.16485617238178019]}, "mutation_prompt": null}
{"id": "04969c86-1567-4fec-85e6-58389bbfb9ba", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        chaotic_population = np.sin(np.pi * (population - lb) / (ub - lb)) * (ub - lb) + lb  # Enhanced initialization\n        return np.vstack((population, q_opposite_population, chaotic_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.5:  # Selective local search\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x * (1 + 0.005 * np.random.randn(self.dim))  # Improved refinement\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.01 * np.random.randn(self.dim // 2, 2)).flatten()\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Introduced a chaotic initialization and enhanced local search to refine promising candidate solutions.", "configspace": "", "generation": 7, "fitness": 0.9423946975156836, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.942 with standard deviation 0.021. And the mean value of best solutions found was 0.175 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9300297378649937, 0.925815216991787, 0.9713391376902705], "final_y": [0.18187916592069164, 0.17722453837866037, 0.1648561424116186]}, "mutation_prompt": null}
{"id": "400cf348-d1d1-46f6-935c-d62a31388e7e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.7:  # Selective local search (modified probability)\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                best_candidate = result.x  # Accept the improved local search result\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.01 * np.random.randn(self.dim // 2, 2)).flatten()  # Adaptive periodic enforcement\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Refined HybridDE with improved local search strategy and adaptive periodic enforcement for optimized multilayered photonic structures.", "configspace": "", "generation": 7, "fitness": 0.9552597880568077, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.955 with standard deviation 0.023. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.925424980624604, 0.9822867016595566, 0.9580676818862625], "final_y": [0.1818790476884461, 0.16485620431066872, 0.16485827762556904]}, "mutation_prompt": null}
{"id": "92723291-a295-4a7d-98e4-8e33e90a637d", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.6:  # Adjusted selective local search probability\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                best_candidate = result.x  # Ensure updated candidate on success\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.02 * np.random.randn(self.dim // 2, 2)).flatten()  # Slight perturbation increase\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Enhanced HybridDE with adaptive periodic constraints and integrated perturbation to improve convergence towards optimal solutions in complex optimization landscapes.", "configspace": "", "generation": 8, "fitness": 0.9441825101368583, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.944 with standard deviation 0.031. And the mean value of best solutions found was 0.169 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9324088786539487, 0.9129916025621889, 0.9871470491944373], "final_y": [0.17713837257717735, 0.16486130850945457, 0.16485660159643323]}, "mutation_prompt": null}
{"id": "0d4c4866-3890-452f-8296-f98e0360d222", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.5:  # Selective local search\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x + 0.01 * np.random.randn(self.dim)  # Adaptive gradient-based adjustment\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.01 * np.random.randn(self.dim // 2, 2)).flatten()  # Adaptive periodic enforcement\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Improved local search by adding an adaptive gradient-based adjustment to enhance exploration near optimal solutions.", "configspace": "", "generation": 8, "fitness": 0.9466352730446571, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.947 with standard deviation 0.011. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9577935582357853, 0.931228286441005, 0.950883974457181], "final_y": [0.16485638465531205, 0.16485663042931276, 0.1648566479506951]}, "mutation_prompt": null}
{"id": "564c9b80-b37a-4ad8-87b9-3f3a975b7bd3", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.7:  # Selective local search probability increased\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.005 * np.random.randn(self.dim // 2, 2)).flatten()  # Refined periodic enforcement\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Enhanced HybridDE with strategic local search and refined adaptive periodic enforcement for optimal multilayered photonic structures.", "configspace": "", "generation": 8, "fitness": 0.9509079151095552, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.951 with standard deviation 0.009. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9601808788368694, 0.953433534297912, 0.9391093321938843], "final_y": [0.16485627876178288, 0.16485769735969547, 0.1648563095575244]}, "mutation_prompt": null}
{"id": "57179de0-b753-4094-b76b-468c28dff423", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.4, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.8  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.5:  # Selective local search\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.05 * np.random.randn(self.dim // 2, 2)).flatten()  # Adaptive periodic enforcement\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Enhanced HybridDE with refined local search and adaptive parameter tuning to boost multilayer photonic structure optimization.", "configspace": "", "generation": 8, "fitness": 0.9328908560854982, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.933 with standard deviation 0.031. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9760580315779228, 0.9171575336246626, 0.9054570030539093], "final_y": [0.16485836508341856, 0.16485639966367893, 0.16485671227941134]}, "mutation_prompt": null}
{"id": "deb26507-ff58-4406-96b6-49774c1962c4", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population) * np.random.uniform(0.9, 1.1)  # Enhanced initialization\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        search_chance = 0.4 + 0.1 * np.cos(self.used_budget * np.pi / self.budget)  # Dynamic adjustment\n        if np.random.rand() < search_chance:  # Selective local search\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.01 * np.random.randn(self.dim // 2, 2)).flatten()\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Refined HybridDE with enhanced initialization and dynamic local search adjustment for improved convergence in photonic structure optimization.", "configspace": "", "generation": 8, "fitness": 0.926953786009514, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.927 with standard deviation 0.015. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9347753238515651, 0.9396867276821181, 0.9063993064948586], "final_y": [0.16485717416361445, 0.1648598791903736, 0.18187878448638373]}, "mutation_prompt": null}
