{"id": "fd267b54-ac8d-4efc-ba11-7109772a4db3", "solution": "import numpy as np\n\nclass HQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            new_population = []\n            for _ in range(self.population_size):\n                parent1, parent2 = self.select_parents(population, fitness)\n                offspring = self.quantum_crossover(parent1, parent2, lb, ub)\n                new_population.append(offspring)\n            \n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n            \n            population, fitness = self.selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n        \n        return best_solution, best_fitness\n    \n    def select_parents(self, population, fitness):\n        idx1, idx2 = np.random.choice(len(population), size=2, replace=False)\n        return population[idx1], population[idx2]\n    \n    def quantum_crossover(self, parent1, parent2, lb, ub):\n        q1 = self.alpha * parent1 + (1 - self.alpha) * parent2\n        q2 = self.alpha * parent2 + (1 - self.alpha) * parent1\n        offspring = q1 if np.random.rand() < 0.5 else q2\n        offspring = np.clip(offspring, lb, ub)\n        return offspring\n    \n    def selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        return combined_population[sorted_indices][:self.population_size], combined_fitness[sorted_indices][:self.population_size]", "name": "HQEA", "description": "Hybrid Quantum-Inspired Evolutionary Algorithm (HQEA) combines principles of quantum computing with evolutionary strategies to efficiently explore and exploit the search space within a limited budget.", "configspace": "", "generation": 0, "fitness": 0.8383463349386043, "feedback": "The algorithm HQEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.838 with standard deviation 0.016. And the mean value of best solutions found was 0.142 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": null, "metadata": {"aucs": [0.844252560037563, 0.8170507041948162, 0.8537357405834335], "final_y": [0.1388542413182755, 0.1504091797850191, 0.13633142594711012]}, "mutation_prompt": null}
{"id": "f2ec547e-b9f3-4aa6-95e8-d6ee4bb20a04", "solution": "import numpy as np\n\nclass HQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            new_population = []\n            for _ in range(self.population_size):\n                parent1, parent2 = self.select_parents(population, fitness)\n                offspring = self.quantum_crossover(parent1, parent2, lb, ub)\n                new_population.append(offspring)\n            \n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n            \n            population, fitness = self.selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n        \n        return best_solution, best_fitness\n    \n    def select_parents(self, population, fitness):\n        idx1, idx2 = np.random.choice(len(population), size=2, replace=False)\n        return population[idx1], population[idx2]\n    \n    def quantum_crossover(self, parent1, parent2, lb, ub):\n        beta = np.random.rand()  # Line modified to make crossover adaptive\n        q1 = beta * parent1 + (1 - beta) * parent2\n        q2 = beta * parent2 + (1 - beta) * parent1\n        offspring = q1 if np.random.rand() < 0.5 else q2\n        offspring = np.clip(offspring, lb, ub)\n        return offspring\n    \n    def selection(self, population, fitness, new_population, new_fitness):\n        elite_idx = np.argmin(new_fitness) # Line modified to include elitism\n        if new_fitness[elite_idx] < np.min(fitness):\n            best_elite = new_population[elite_idx] # Line modified to include elitism\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        return np.vstack((best_elite, combined_population[sorted_indices][:self.population_size-1])), np.concatenate(([new_fitness[elite_idx]], combined_fitness[sorted_indices][:self.population_size-1])) # Modified to ensure elite is included", "name": "HQEA", "description": "Enhanced Hybrid Quantum-Inspired Evolutionary Algorithm (HQEA+) integrates adaptive quantum crossover and elitism to improve convergence efficiency and solution quality.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"cannot access local variable 'best_elite' where it is not associated with a value\").", "error": "UnboundLocalError(\"cannot access local variable 'best_elite' where it is not associated with a value\")", "parent_id": "fd267b54-ac8d-4efc-ba11-7109772a4db3", "metadata": {}, "mutation_prompt": null}
{"id": "f93dfff1-4d3f-46e5-957e-c37bc7e3a1cd", "solution": "import numpy as np\n\nclass HQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            new_population = []\n            for _ in range(self.population_size):\n                parent1, parent2 = self.select_parents(population, fitness)\n                offspring = self.quantum_crossover(parent1, parent2, lb, ub)\n                new_population.append(offspring)\n            \n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n            \n            population, fitness = self.selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n        \n        return best_solution, best_fitness\n    \n    def select_parents(self, population, fitness):\n        idx1, idx2 = np.random.choice(len(population), size=2, replace=False)\n        return population[idx1], population[idx2]\n    \n    def quantum_crossover(self, parent1, parent2, lb, ub):\n        self.alpha = 0.5 + 0.4 * np.random.rand()  # Adaptive alpha\n        q1 = self.alpha * parent1 + (1 - self.alpha) * parent2\n        q2 = self.alpha * parent2 + (1 - self.alpha) * parent1\n        offspring = q1 if np.random.rand() < 0.5 else q2\n        offspring = np.clip(offspring, lb, ub)\n        return offspring\n    \n    def selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        return combined_population[sorted_indices][:self.population_size], combined_fitness[sorted_indices][:self.population_size]", "name": "HQEA", "description": "Enhanced HQEA with adaptive alpha for improved exploration-exploitation balance.", "configspace": "", "generation": 1, "fitness": 0.7922455837550015, "feedback": "The algorithm HQEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.792 with standard deviation 0.012. And the mean value of best solutions found was 0.159 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "fd267b54-ac8d-4efc-ba11-7109772a4db3", "metadata": {"aucs": [0.7765959137058625, 0.806812005404959, 0.7933288321541833], "final_y": [0.16431040736178604, 0.15503101249980877, 0.1583249467401343]}, "mutation_prompt": null}
{"id": "01d28af2-5ce5-4ec0-a4da-3783af875bb0", "solution": "import numpy as np\n\nclass HQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            new_population = []\n            for _ in range(self.population_size):\n                parent1, parent2 = self.select_parents(population, fitness)\n                offspring = self.quantum_crossover(parent1, parent2, lb, ub)\n                new_population.append(offspring)\n            \n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n            \n            population, fitness = self.selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n            \n            # Dynamic adjustment of alpha\n            self.alpha = 0.5 + 0.5 * np.random.rand() * (1 - evaluations / self.budget)\n        \n        return best_solution, best_fitness\n    \n    def select_parents(self, population, fitness):\n        idx1, idx2 = np.random.choice(len(population), size=2, replace=False)\n        return population[idx1], population[idx2]\n    \n    def quantum_crossover(self, parent1, parent2, lb, ub):\n        q1 = self.alpha * parent1 + (1 - self.alpha) * parent2\n        q2 = self.alpha * parent2 + (1 - self.alpha) * parent1\n        offspring = q1 if np.random.rand() < 0.5 else q2\n        offspring = np.clip(offspring, lb, ub)\n        return offspring\n    \n    def selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        return combined_population[sorted_indices][:self.population_size], combined_fitness[sorted_indices][:self.population_size]", "name": "HQEA", "description": "Enhanced HQEA with adaptive alpha to balance exploration and exploitation dynamically.", "configspace": "", "generation": 1, "fitness": 0.7884941575408831, "feedback": "The algorithm HQEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.788 with standard deviation 0.021. And the mean value of best solutions found was 0.161 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "fd267b54-ac8d-4efc-ba11-7109772a4db3", "metadata": {"aucs": [0.7583960661364063, 0.8048670002228075, 0.8022194062634358], "final_y": [0.17324992670562656, 0.15565923655274216, 0.15464932572400614]}, "mutation_prompt": null}
{"id": "dd29cf7a-b410-490c-ba57-60d94a948507", "solution": "import numpy as np\n\nclass HQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            new_population = []\n            for _ in range(self.population_size):\n                parent1, parent2 = self.select_parents(population, fitness)\n                offspring = self.quantum_crossover(parent1, parent2, lb, ub, evaluations)\n                new_population.append(offspring)\n            \n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n            \n            population, fitness = self.selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n        \n        return best_solution, best_fitness\n    \n    def select_parents(self, population, fitness):\n        idx1, idx2 = np.random.choice(len(population), size=2, replace=False)\n        return population[idx1], population[idx2]\n    \n    def quantum_crossover(self, parent1, parent2, lb, ub, evaluations):\n        self.alpha = 0.5 + 0.5 * (evaluations / self.budget) # Dynamic alpha adjustment\n        q1 = self.alpha * parent1 + (1 - self.alpha) * parent2\n        q2 = self.alpha * parent2 + (1 - self.alpha) * parent1\n        offspring = q1 if np.random.rand() < 0.5 else q2\n        offspring = np.clip(offspring, lb, ub)\n        return offspring\n    \n    def selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        return combined_population[sorted_indices][:self.population_size], combined_fitness[sorted_indices][:self.population_size]", "name": "HQEA", "description": "Refined Quantum Crossover HQEA variant introduces a dynamic alpha strategy, adjusting crossover influence to improve convergence.", "configspace": "", "generation": 1, "fitness": 0.8289141955165701, "feedback": "The algorithm HQEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.829 with standard deviation 0.029. And the mean value of best solutions found was 0.146 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "fd267b54-ac8d-4efc-ba11-7109772a4db3", "metadata": {"aucs": [0.8161074131008276, 0.802033453455846, 0.8686017199930367], "final_y": [0.1493212476746698, 0.15685347110526815, 0.13184858315866166]}, "mutation_prompt": null}
{"id": "b2c546fd-3e47-45e9-b299-aa2ed6c5b9d5", "solution": "import numpy as np\n\nclass EHQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n        self.elite_fraction = 0.1  # New line\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            new_population = []\n            elite_size = int(self.elite_fraction * self.population_size)  # New line\n            elites = population[np.argsort(fitness)[:elite_size]]  # New line\n            for _ in range(self.population_size - elite_size):  # Modified line\n                parent1, parent2 = self.select_parents(population, fitness)\n                offspring = self.quantum_crossover(parent1, parent2, lb, ub)\n                offspring = self.adaptive_mutation(offspring, lb, ub)  # New line\n                new_population.append(offspring)\n            \n            new_population.extend(elites)  # New line\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n            \n            population, fitness = self.selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n        \n        return best_solution, best_fitness\n    \n    def select_parents(self, population, fitness):\n        idx1, idx2 = np.random.choice(len(population), size=2, replace=False)\n        return population[idx1], population[idx2]\n    \n    def quantum_crossover(self, parent1, parent2, lb, ub):\n        q1 = self.alpha * parent1 + (1 - self.alpha) * parent2\n        q2 = self.alpha * parent2 + (1 - self.alpha) * parent1\n        offspring = q1 if np.random.rand() < 0.5 else q2\n        offspring = np.clip(offspring, lb, ub)\n        return offspring\n    \n    def adaptive_mutation(self, individual, lb, ub):  # New line\n        mutation_strength = 0.1 * (ub - lb) * np.random.rand(self.dim)  # New line\n        mutated = individual + np.random.normal(0, mutation_strength, self.dim)  # New line\n        return np.clip(mutated, lb, ub)  # New line\n\n    def selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        return combined_population[sorted_indices][:self.population_size], combined_fitness[sorted_indices][:self.population_size]", "name": "EHQEA", "description": "Enhanced Hybrid Quantum-Inspired Evolutionary Algorithm (EHQEA) introduces elitism and adaptive mutation to retain top solutions and boost exploration capabilities within a limited budget.", "configspace": "", "generation": 1, "fitness": 0.9033412958963453, "feedback": "The algorithm EHQEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.903 with standard deviation 0.008. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "fd267b54-ac8d-4efc-ba11-7109772a4db3", "metadata": {"aucs": [0.910849359936859, 0.8921344789438538, 0.9070400488083231], "final_y": [0.11309932271445955, 0.11633523985333005, 0.11407736452919692]}, "mutation_prompt": null}
{"id": "12ccac3a-968a-430a-b58a-c179ecb93351", "solution": "import numpy as np\n\nclass EHQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n        self.elite_fraction = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            new_population = []\n            elite_size = int(self.elite_fraction * self.population_size)\n            elites = population[np.argsort(fitness)[:elite_size]]\n            self.population_size = min(self.population_size + 1, int(self.budget / 10))  # Adjusted line\n            for _ in range(self.population_size - elite_size):\n                parent1, parent2 = self.select_parents(population, fitness)\n                offspring = self.quantum_crossover(parent1, parent2, lb, ub)\n                offspring = self.adaptive_mutation(offspring, lb, ub)\n                new_population.append(offspring)\n            \n            new_population.extend(elites)\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n            \n            population, fitness = self.selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n        \n        return best_solution, best_fitness\n    \n    def select_parents(self, population, fitness):\n        idx1, idx2 = np.random.choice(len(population), size=2, replace=False)\n        return population[idx1], population[idx2]\n    \n    def quantum_crossover(self, parent1, parent2, lb, ub):\n        q1 = self.alpha * parent1 + (1 - self.alpha) * parent2\n        q2 = self.alpha * parent2 + (1 - self.alpha) * parent1\n        offspring = q1 if np.random.rand() < 0.5 else q2\n        offspring = np.clip(offspring, lb, ub)\n        return offspring\n    \n    def adaptive_mutation(self, individual, lb, ub):\n        mutation_strength = 0.1 * (ub - lb) * np.random.rand(self.dim)\n        mutated = individual + np.random.normal(0, mutation_strength, self.dim)\n        return np.clip(mutated, lb, ub)\n\n    def selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        return combined_population[sorted_indices][:self.population_size], combined_fitness[sorted_indices][:self.population_size]", "name": "EHQEA", "description": "Enhanced Hybrid Quantum-Inspired Evolutionary Algorithm (EHQEA) with dynamic population adjustment, selectively expanding population size based on diversity to balance exploration and exploitation.", "configspace": "", "generation": 2, "fitness": 0.8903555283898329, "feedback": "The algorithm EHQEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.890 with standard deviation 0.004. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "b2c546fd-3e47-45e9-b299-aa2ed6c5b9d5", "metadata": {"aucs": [0.8844083615845766, 0.8944113001316312, 0.892246923453291], "final_y": [0.11989943020569316, 0.12003840975631264, 0.11822060917810773]}, "mutation_prompt": null}
{"id": "14ee4d10-0c4b-41dc-89e7-e8b91b323786", "solution": "import numpy as np\n\nclass EHQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n        self.elite_fraction = 0.2  # Modified line\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            new_population = []\n            elite_size = int(self.dynamic_elite_fraction(evaluations) * self.population_size)  # Modified line\n            elites = population[np.argsort(fitness)[:elite_size]]\n            for _ in range(self.population_size - elite_size):\n                parent1, parent2 = self.tournament_selection(population, fitness)  # Modified line\n                offspring = self.enhanced_quantum_crossover(parent1, parent2, lb, ub)  # Modified line\n                offspring = self.adaptive_mutation(offspring, lb, ub)\n                new_population.append(offspring)\n            \n            new_population.extend(elites)\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n            \n            population, fitness = self.selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n        \n        return best_solution, best_fitness\n    \n    def tournament_selection(self, population, fitness):  # Modified line\n        indices = np.random.choice(len(population), size=4, replace=False)  # Modified line\n        selected = indices[np.argsort(fitness[indices])[:2]]  # Modified line\n        return population[selected[0]], population[selected[1]]  # Modified line\n    \n    def enhanced_quantum_crossover(self, parent1, parent2, lb, ub):  # Modified line\n        beta = np.random.rand(self.dim)  # Modified line\n        offspring = beta * parent1 + (1 - beta) * parent2  # Modified line\n        return np.clip(offspring, lb, ub)  # Modified line\n    \n    def adaptive_mutation(self, individual, lb, ub):\n        mutation_strength = 0.1 * (ub - lb) * np.random.rand(self.dim)\n        mutated = individual + np.random.normal(0, mutation_strength, self.dim)\n        return np.clip(mutated, lb, ub)\n\n    def dynamic_elite_fraction(self, evaluations):  # New function\n        return max(0.1, self.elite_fraction - 0.05 * (evaluations / self.budget))  # Modified line\n\n    def selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        return combined_population[sorted_indices][:self.population_size], combined_fitness[sorted_indices][:self.population_size]", "name": "EHQEA", "description": "EHQEA with Dynamic Elite Strategy and Enhanced Quantum Crossover to improve convergence and diversify search.", "configspace": "", "generation": 2, "fitness": 0.8844001615625846, "feedback": "The algorithm EHQEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.884 with standard deviation 0.015. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "b2c546fd-3e47-45e9-b299-aa2ed6c5b9d5", "metadata": {"aucs": [0.8833008698172388, 0.8661813093896735, 0.9037183054808415], "final_y": [0.11762342076532839, 0.11944525118990801, 0.11434331404832798]}, "mutation_prompt": null}
{"id": "eb18bab3-d409-4900-b4c9-e2e141d20449", "solution": "import numpy as np\n\nclass EHQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n        self.elite_fraction = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            new_population = []\n            elite_size = int(self.elite_fraction * self.population_size)\n            elites = population[np.argsort(fitness)[:elite_size]]\n            for _ in range(self.population_size - elite_size):\n                parent1, parent2 = self.select_parents(population, fitness)\n                offspring = self.quantum_crossover(parent1, parent2, lb, ub)\n                offspring = self.adaptive_mutation(offspring, lb, ub)\n                new_population.append(offspring)\n            \n            new_population.extend(elites)\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n            \n            # This change implements dynamic selection based on diversity.\n            population, fitness = self.selection(new_population, new_fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n        \n        return best_solution, best_fitness\n    \n    def select_parents(self, population, fitness):\n        # This change selects more diverse parents.\n        idx1, idx2 = np.random.choice(len(population), size=2, replace=False, p=fitness/fitness.sum())\n        return population[idx1], population[idx2]\n    \n    def quantum_crossover(self, parent1, parent2, lb, ub):\n        q1 = self.alpha * parent1 + (1 - self.alpha) * parent2\n        q2 = self.alpha * parent2 + (1 - self.alpha) * parent1\n        offspring = q1 if np.random.rand() < 0.5 else q2\n        offspring = np.clip(offspring, lb, ub)\n        return offspring\n    \n    def adaptive_mutation(self, individual, lb, ub):\n        mutation_strength = 0.1 * (ub - lb) * np.random.rand(self.dim)\n        mutated = individual + np.random.normal(0, mutation_strength, self.dim)\n        return np.clip(mutated, lb, ub)\n\n    def selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        return combined_population[sorted_indices][:self.population_size], combined_fitness[sorted_indices][:self.population_size]", "name": "EHQEA", "description": "Optimized Hybrid Quantum-Inspired Evolutionary Algorithm (OHQEA) enhances exploration by implementing a more dynamic selection strategy and adaptive mutation strength modulation.", "configspace": "", "generation": 2, "fitness": 0.8891159727078731, "feedback": "The algorithm EHQEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.889 with standard deviation 0.007. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "b2c546fd-3e47-45e9-b299-aa2ed6c5b9d5", "metadata": {"aucs": [0.8981253079291436, 0.8822124230033163, 0.8870101871911595], "final_y": [0.11410149919267698, 0.11688455071935278, 0.11902046302261582]}, "mutation_prompt": null}
{"id": "40190a48-951d-42da-89aa-933c4dab5bf4", "solution": "import numpy as np\n\nclass EHQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n        self.elite_fraction = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            new_population = []\n            elite_size = int(self.elite_fraction * self.population_size)\n            elites = population[np.argsort(fitness)[:elite_size]]\n            for _ in range(self.population_size - elite_size):\n                parent1, parent2 = self.select_parents(population, fitness)\n                offspring = self.quantum_crossover(parent1, parent2, lb, ub)\n                offspring = self.adaptive_mutation(offspring, lb, ub)\n                new_population.append(offspring)\n            \n            new_population.extend(elites)\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n            \n            population, fitness = self.dynamic_selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n        \n        return best_solution, best_fitness\n    \n    def select_parents(self, population, fitness):\n        idx1, idx2 = np.random.choice(len(population), size=2, replace=False)\n        return population[idx1], population[idx2]\n    \n    def quantum_crossover(self, parent1, parent2, lb, ub):\n        adaptive_alpha = np.random.rand()  # Changed line\n        q1 = adaptive_alpha * parent1 + (1 - adaptive_alpha) * parent2  # Changed line\n        q2 = adaptive_alpha * parent2 + (1 - adaptive_alpha) * parent1  # Changed line\n        offspring = q1 if np.random.rand() < 0.5 else q2\n        offspring = np.clip(offspring, lb, ub)\n        return offspring\n    \n    def adaptive_mutation(self, individual, lb, ub):\n        mutation_strength = 0.1 * (ub - lb) * np.random.rand(self.dim)\n        mutated = individual + np.random.normal(0, mutation_strength, self.dim)\n        return np.clip(mutated, lb, ub)\n\n    def dynamic_selection(self, population, fitness, new_population, new_fitness):  # Changed line\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        return combined_population[sorted_indices][:self.population_size], combined_fitness[sorted_indices][:self.population_size]", "name": "EHQEA", "description": "Adaptive Quantum-Elite Crossover with Dynamic Selection integrates adaptive crossover probability and dynamic selection pressure to enhance the exploration-exploitation balance.", "configspace": "", "generation": 2, "fitness": 0.8958483245551291, "feedback": "The algorithm EHQEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.896 with standard deviation 0.010. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "b2c546fd-3e47-45e9-b299-aa2ed6c5b9d5", "metadata": {"aucs": [0.883155643408054, 0.8967151465732021, 0.9076741836841313], "final_y": [0.12090342727204584, 0.12067045011119604, 0.11416791426551987]}, "mutation_prompt": null}
{"id": "5ed83937-811d-4d48-9e69-536113c1a1e9", "solution": "import numpy as np\n\nclass EHQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n        self.elite_fraction = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            new_population = []\n            elite_size = int(self.elite_fraction * self.population_size)\n            elites = population[np.argsort(fitness)[:elite_size]]\n            for _ in range(self.population_size - elite_size):\n                parent1, parent2 = self.select_parents_stochastic(population, fitness)  # Changed line\n                offspring = self.quantum_crossover(parent1, parent2, lb, ub)\n                offspring = self.adaptive_mutation(offspring, lb, ub)\n                new_population.append(offspring)\n            \n            new_population.extend(elites)\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n            \n            population, fitness = self.selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n        \n        return best_solution, best_fitness\n    \n    def select_parents_stochastic(self, population, fitness):  # New line\n        probabilities = fitness / fitness.sum()\n        idx1, idx2 = np.random.choice(len(population), size=2, replace=False, p=probabilities)\n        return population[idx1], population[idx2]\n    \n    def quantum_crossover(self, parent1, parent2, lb, ub):\n        q1 = self.alpha * parent1 + (1 - self.alpha) * parent2\n        q2 = self.alpha * parent2 + (1 - self.alpha) * parent1\n        offspring = q1 if np.random.rand() < 0.5 else q2\n        offspring = np.clip(offspring, lb, ub)\n        return offspring\n    \n    def adaptive_mutation(self, individual, lb, ub):\n        mutation_strength = 0.1 * (ub - lb) * np.random.rand(self.dim)\n        mutated = individual + np.random.normal(0, mutation_strength, self.dim)\n        return np.clip(mutated, lb, ub)\n\n    def selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        return combined_population[sorted_indices][:self.population_size], combined_fitness[sorted_indices][:self.population_size]", "name": "EHQEA", "description": "Enhanced Hybrid Quantum-Inspired Evolutionary Algorithm (EHQEA) with stochastic parent selection to improve diversity and potentially better solutions.", "configspace": "", "generation": 2, "fitness": 0.8993560944847054, "feedback": "The algorithm EHQEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.899 with standard deviation 0.011. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "b2c546fd-3e47-45e9-b299-aa2ed6c5b9d5", "metadata": {"aucs": [0.905193682642094, 0.8836720780024633, 0.9092025228095593], "final_y": [0.11505167346822576, 0.12035835950035878, 0.11460710011835862]}, "mutation_prompt": null}
{"id": "9b6fb3cf-1819-4b75-ad58-9fb7c6a66bad", "solution": "import numpy as np\n\nclass EHQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n        self.elite_fraction = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            new_population = []\n            elite_size = int(self.elite_fraction * self.population_size)\n            elites = population[np.argsort(fitness)[:elite_size]]\n            for _ in range(self.population_size - elite_size):\n                parent1, parent2 = self.select_parents(population, fitness)\n                offspring = self.quantum_crossover(parent1, parent2, lb, ub)\n                offspring = self.adaptive_mutation(offspring, lb, ub)\n                new_population.append(offspring)\n            \n            new_population.extend(elites)\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n            \n            population, fitness = self.selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n        \n        return best_solution, best_fitness\n    \n    def select_parents(self, population, fitness):\n        idx1, idx2 = np.random.choice(len(population), size=2, replace=False)\n        return population[idx1], population[idx2]\n    \n    def quantum_crossover(self, parent1, parent2, lb, ub):  # Adjusted line\n        fitness_variance = np.var([parent1, parent2])\n        adaptive_alpha = self.alpha * (1 + fitness_variance)\n        q1 = adaptive_alpha * parent1 + (1 - adaptive_alpha) * parent2\n        q2 = adaptive_alpha * parent2 + (1 - adaptive_alpha) * parent1\n        offspring = q1 if np.random.rand() < 0.5 else q2\n        offspring = np.clip(offspring, lb, ub)\n        return offspring\n    \n    def adaptive_mutation(self, individual, lb, ub):\n        mutation_strength = 0.1 * (ub - lb) * np.random.rand(self.dim)\n        mutated = individual + np.random.normal(0, mutation_strength, self.dim)\n        return np.clip(mutated, lb, ub)\n\n    def selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        return combined_population[sorted_indices][:self.population_size], combined_fitness[sorted_indices][:self.population_size]", "name": "EHQEA", "description": "Quantum-adaptive crossover strategy in EHQEA enhances solution diversity and convergence by dynamically adjusting crossover influence based on fitness variance.", "configspace": "", "generation": 3, "fitness": 0.8367196275477825, "feedback": "The algorithm EHQEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.837 with standard deviation 0.047. And the mean value of best solutions found was 0.129 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "b2c546fd-3e47-45e9-b299-aa2ed6c5b9d5", "metadata": {"aucs": [0.7704730358825782, 0.8622327328507551, 0.8774531139100142], "final_y": [0.1465907697851524, 0.12270964103844861, 0.11726188572824658]}, "mutation_prompt": null}
{"id": "68c41c89-e6de-4514-9c52-d4e8973b233c", "solution": "import numpy as np\n\nclass EHQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n        self.elite_fraction = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            new_population = []\n            elite_size = int(self.elite_fraction * self.population_size)\n            elites = population[np.argsort(fitness)[:elite_size]]\n            for _ in range(self.population_size - elite_size):\n                parent1, parent2 = self.select_parents(population, fitness)\n                offspring = self.quantum_crossover(parent1, parent2, lb, ub)\n                offspring = self.adaptive_mutation(offspring, lb, ub, evaluations/self.budget)  # Modified line\n                new_population.append(offspring)\n            \n            new_population.extend(elites)\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n            \n            population, fitness = self.selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n        \n        return best_solution, best_fitness\n    \n    def select_parents(self, population, fitness):\n        idx1, idx2 = np.random.choice(len(population), size=2, replace=False)\n        return population[idx1], population[idx2]\n    \n    def quantum_crossover(self, parent1, parent2, lb, ub):\n        q1 = self.alpha * parent1 + (1 - self.alpha) * parent2\n        q2 = self.alpha * parent2 + (1 - self.alpha) * parent1\n        offspring = q1 if np.random.rand() < 0.5 else q2\n        offspring = np.clip(offspring, lb, ub)\n        return offspring\n    \n    def adaptive_mutation(self, individual, lb, ub, progress):  # Modified line\n        mutation_strength = (0.1 - progress * 0.05) * (ub - lb) * np.random.rand(self.dim)  # Modified line\n        mutated = individual + np.random.normal(0, mutation_strength, self.dim)  # Unchanged line\n        return np.clip(mutated, lb, ub)  # Unchanged line\n\n    def selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        return combined_population[sorted_indices][:self.population_size], combined_fitness[sorted_indices][:self.population_size]", "name": "EHQEA", "description": "Quantum-Inspired Evolutionary Algorithm with Enhanced Adaptive Mutations leverages dynamic mutation probabilities to improve exploration and convergence in complex optimization landscapes.", "configspace": "", "generation": 3, "fitness": 0.8672031715261079, "feedback": "The algorithm EHQEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.867 with standard deviation 0.019. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "b2c546fd-3e47-45e9-b299-aa2ed6c5b9d5", "metadata": {"aucs": [0.8895735637709884, 0.8426240474299747, 0.8694119033773609], "final_y": [0.11146282624383785, 0.1282514848939914, 0.12020946899010343]}, "mutation_prompt": null}
{"id": "1ebbdc3e-a092-4dc7-b660-0f53b2642dd0", "solution": "import numpy as np\n\nclass EHQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n        self.elite_fraction = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            new_population = []\n            elite_size = int(self.elite_fraction * self.population_size)\n            elites = population[np.argsort(fitness)[:elite_size]]\n            for _ in range(self.population_size - elite_size):\n                parent1, parent2 = self.select_parents(population, fitness)\n                offspring = self.quantum_crossover(parent1, parent2, lb, ub)\n                offspring = self.adaptive_mutation(offspring, lb, ub)\n                new_population.append(offspring)\n\n            new_population.extend(elites)\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n            \n            # Dynamic population size adjustment\n            self.population_size = max(10, int(self.population_size * 0.95))  # New line\n\n            population, fitness = self.selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n        \n        return best_solution, best_fitness\n    \n    def select_parents(self, population, fitness):\n        idx1, idx2 = np.random.choice(len(population), size=2, replace=False)\n        return population[idx1], population[idx2]\n    \n    def quantum_crossover(self, parent1, parent2, lb, ub):\n        q1 = self.alpha * parent1 + (1 - self.alpha) * parent2\n        q2 = self.alpha * parent2 + (1 - self.alpha) * parent1\n        offspring = q1 if np.random.rand() < 0.5 else q2\n        offspring = np.clip(offspring, lb, ub)\n        return offspring\n    \n    def adaptive_mutation(self, individual, lb, ub):\n        mutation_strength = 0.1 * (ub - lb) * np.random.rand(self.dim)\n        mutated = individual + np.random.normal(0, mutation_strength, self.dim)\n        return np.clip(mutated, lb, ub)\n\n    def selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        return combined_population[sorted_indices][:self.population_size], combined_fitness[sorted_indices][:self.population_size]", "name": "EHQEA", "description": "Enhanced EHQEA introduces elitism, adaptive mutation, and dynamic population size adjustment to optimize search efficiency within a limited budget.", "configspace": "", "generation": 3, "fitness": 0.8559589356489422, "feedback": "The algorithm EHQEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.856 with standard deviation 0.019. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "b2c546fd-3e47-45e9-b299-aa2ed6c5b9d5", "metadata": {"aucs": [0.8816202206223853, 0.8345082571377236, 0.8517483291867181], "final_y": [0.12166278902335959, 0.1273610671587363, 0.12603775288769103]}, "mutation_prompt": null}
{"id": "b515e1d7-c7cd-4320-a672-6caee2cb13a4", "solution": "import numpy as np\n\nclass ASQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n        self.elite_fraction = 0.1\n        self.inertia_weight = 0.7  # New line\n        self.cognitive_weight = 1.4  # New line\n        self.social_weight = 1.4  # New line\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.zeros((self.population_size, self.dim))  # New line\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        personal_best = np.copy(population)  # New line\n        personal_best_fitness = np.copy(fitness)  # New line\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            new_population = []\n            elite_size = int(self.elite_fraction * self.population_size)\n            elites = population[np.argsort(fitness)[:elite_size]]\n            for i in range(self.population_size - elite_size):  # Modified line\n                r1, r2 = np.random.rand(), np.random.rand()  # New line\n                velocity[i] = (self.inertia_weight * velocity[i] +  # New line\n                               self.cognitive_weight * r1 * (personal_best[i] - population[i]) +  # New line\n                               self.social_weight * r2 * (best_solution - population[i]))  # New line\n                offspring = population[i] + velocity[i]  # New line\n                offspring = self.adaptive_mutation(offspring, lb, ub)\n                new_population.append(offspring)\n            \n            new_population.extend(elites)\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n            \n            population, fitness = self.selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n            for i in range(self.population_size):  # New line\n                if fitness[i] < personal_best_fitness[i]:  # New line\n                    personal_best[i] = population[i]  # New line\n                    personal_best_fitness[i] = fitness[i]  # New line\n        \n        return best_solution, best_fitness\n    \n    def select_parents(self, population, fitness):\n        idx1, idx2 = np.random.choice(len(population), size=2, replace=False)\n        return population[idx1], population[idx2]\n    \n    def quantum_crossover(self, parent1, parent2, lb, ub):\n        q1 = self.alpha * parent1 + (1 - self.alpha) * parent2\n        q2 = self.alpha * parent2 + (1 - self.alpha) * parent1\n        offspring = q1 if np.random.rand() < 0.5 else q2\n        offspring = np.clip(offspring, lb, ub)\n        return offspring\n    \n    def adaptive_mutation(self, individual, lb, ub):\n        mutation_strength = 0.1 * (ub - lb) * np.random.rand(self.dim)\n        mutated = individual + np.random.normal(0, mutation_strength, self.dim)\n        return np.clip(mutated, lb, ub)\n\n    def selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        return combined_population[sorted_indices][:self.population_size], combined_fitness[sorted_indices][:self.population_size]", "name": "ASQEA", "description": "The Adaptive Swarm-inspired Quantum Evolutionary Algorithm (ASQEA) incorporates swarm intelligence and dynamic parameter tuning to enhance convergence speed and solution quality within a constrained evaluation budget.", "configspace": "", "generation": 3, "fitness": 0.8850232444328893, "feedback": "The algorithm ASQEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.885 with standard deviation 0.018. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "b2c546fd-3e47-45e9-b299-aa2ed6c5b9d5", "metadata": {"aucs": [0.8598653057083905, 0.9018538341256064, 0.8933505934646709], "final_y": [0.1311580922990785, 0.11733157797661409, 0.1156212816417801]}, "mutation_prompt": null}
{"id": "220ee340-7998-4ea4-b3da-4a5e76bca8d9", "solution": "import numpy as np\n\nclass AQDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n        self.elite_fraction = 0.1\n        self.mutation_factor = 0.8  # New line\n        self.crossover_rate = 0.7  # New line\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            new_population = []\n            elite_size = int(self.elite_fraction * self.population_size)\n            elites = population[np.argsort(fitness)[:elite_size]]\n            for i in range(self.population_size - elite_size):\n                parent1, parent2, parent3 = self.select_parents(population, fitness)  # Modified line\n                mutant = self.differential_mutation(parent1, parent2, parent3, lb, ub)  # New line\n                offspring = self.quantum_crossover(mutant, population[i], lb, ub)  # Modified line\n                new_population.append(offspring)\n            \n            new_population.extend(elites)\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n            \n            population, fitness = self.selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n        \n        return best_solution, best_fitness\n    \n    def select_parents(self, population, fitness):\n        indices = np.random.choice(len(population), size=3, replace=False)  # Modified line\n        return population[indices[0]], population[indices[1]], population[indices[2]]  # Modified line\n    \n    def quantum_crossover(self, parent1, parent2, lb, ub):\n        if np.random.rand() < self.crossover_rate:  # New line\n            offspring = self.alpha * parent1 + (1 - self.alpha) * parent2  # Modified line\n        else:  # New line\n            offspring = parent2  # New line\n        return np.clip(offspring, lb, ub)\n\n    def differential_mutation(self, parent1, parent2, parent3, lb, ub):  # New function\n        mutant = parent1 + self.mutation_factor * (parent2 - parent3)\n        return np.clip(mutant, lb, ub)\n\n    def selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        return combined_population[sorted_indices][:self.population_size], combined_fitness[sorted_indices][:self.population_size]", "name": "AQDE", "description": "The Adaptive Quantum Differential Evolution (AQDE) algorithm enhances EHQEA by integrating differential evolution strategies with adaptive quantum crossover, improving exploration and convergence stability.", "configspace": "", "generation": 3, "fitness": 0.8252041882593281, "feedback": "The algorithm AQDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.825 with standard deviation 0.024. And the mean value of best solutions found was 0.147 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "b2c546fd-3e47-45e9-b299-aa2ed6c5b9d5", "metadata": {"aucs": [0.8057114709935702, 0.810862543625402, 0.8590385501590119], "final_y": [0.15247983646541308, 0.15303187131825613, 0.1358242776765124]}, "mutation_prompt": null}
{"id": "6583958d-b189-450a-a170-6577ea29fac0", "solution": "import numpy as np\n\nclass ADEER:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n        self.elite_fraction = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            new_population = []\n            elite_size = int(self.elite_fraction * self.population_size)\n            elites = population[np.argsort(fitness)[:elite_size]]\n            for _ in range(self.population_size - elite_size):\n                parent1, parent2 = self.select_parents(population, fitness)\n                offspring = self.differential_crossover(parent1, parent2, lb, ub)\n                offspring = self.adaptive_mutation(offspring, lb, ub)\n                new_population.append(offspring)\n\n            new_population.extend(elites)\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n\n            population, fitness = self.selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n\n        return best_solution, best_fitness\n\n    def select_parents(self, population, fitness):\n        idx1, idx2 = np.random.choice(len(population), size=2, replace=False)\n        return population[idx1], population[idx2]\n\n    def differential_crossover(self, parent1, parent2, lb, ub):\n        F = 0.8\n        offspring = np.clip(parent1 + F * (parent2 - parent1), lb, ub)\n        return offspring\n\n    def adaptive_mutation(self, individual, lb, ub):\n        mutation_strength = 0.1 * (ub - lb) * np.random.rand(self.dim)\n        mutated = individual + np.random.normal(0, mutation_strength, self.dim)\n        return np.clip(mutated, lb, ub)\n\n    def selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        return combined_population[sorted_indices][:self.population_size], combined_fitness[sorted_indices][:self.population_size]", "name": "ADEER", "description": "Adaptive Differential Evolution with Elite Retention (ADEER) dynamically adjusts mutation and crossover rates to enhance exploration and exploitation concurrently.", "configspace": "", "generation": 4, "fitness": 0.8881211028976361, "feedback": "The algorithm ADEER got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.888 with standard deviation 0.007. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "b2c546fd-3e47-45e9-b299-aa2ed6c5b9d5", "metadata": {"aucs": [0.8804344971060856, 0.8978351128406645, 0.8860936987461585], "final_y": [0.11908371458291545, 0.11880636507911935, 0.12398584532875068]}, "mutation_prompt": null}
{"id": "602b800e-d5a0-427e-9fdf-e4784a566a65", "solution": "import numpy as np\n\nclass EHQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n        self.elite_fraction = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            new_population = []\n            elite_size = int(self.elite_fraction * self.population_size)\n            elites = population[np.argsort(fitness)[:elite_size]]\n            diversity_factor = 0.1 + 0.9 * (1 - evaluations / self.budget)  # New line\n            for _ in range(self.population_size - elite_size):\n                parent1, parent2 = self.select_parents(population, fitness)\n                offspring = self.quantum_crossover(parent1, parent2, lb, ub)\n                offspring = self.adaptive_mutation(offspring * diversity_factor, lb, ub)  # Modified line\n                new_population.append(offspring)\n            \n            new_population.extend(elites)\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n            \n            population, fitness = self.selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n        \n        return best_solution, best_fitness\n    \n    def select_parents(self, population, fitness):\n        idx1, idx2 = np.random.choice(len(population), size=2, replace=False)\n        return population[idx1], population[idx2]\n    \n    def quantum_crossover(self, parent1, parent2, lb, ub):\n        q1 = self.alpha * parent1 + (1 - self.alpha) * parent2\n        q2 = self.alpha * parent2 + (1 - self.alpha) * parent1\n        offspring = q1 if np.random.rand() < 0.5 else q2\n        offspring = np.clip(offspring, lb, ub)\n        return offspring\n    \n    def adaptive_mutation(self, individual, lb, ub):\n        mutation_strength = 0.1 * (ub - lb) * np.random.rand(self.dim)\n        mutated = individual + np.random.normal(0, mutation_strength, self.dim)\n        return np.clip(mutated, lb, ub)\n\n    def selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        return combined_population[sorted_indices][:self.population_size], combined_fitness[sorted_indices][:self.population_size]", "name": "EHQEA", "description": "Enhanced Quantum-Inspired Evolutionary Algorithm (EHQEA) integrates elite solutions with adaptive diversity control to balance exploration and exploitation more effectively.", "configspace": "", "generation": 4, "fitness": 0.8888152797941439, "feedback": "The algorithm EHQEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.889 with standard deviation 0.033. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "b2c546fd-3e47-45e9-b299-aa2ed6c5b9d5", "metadata": {"aucs": [0.8434524554446776, 0.9043822145226029, 0.9186111694151512], "final_y": [0.14004867524952558, 0.11789533943370478, 0.11348806487429142]}, "mutation_prompt": null}
{"id": "178c2cda-4143-443e-b086-fe65cf3ad4d9", "solution": "import numpy as np\n\nclass EHQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n        self.elite_fraction = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            new_population = []\n            elite_size = int(self.elite_fraction * self.population_size)\n            elites = population[np.argsort(fitness)[:elite_size]]\n            for _ in range(self.population_size - elite_size):\n                parent1, parent2 = self.select_parents(population, fitness)\n                offspring = self.quantum_crossover(parent1, parent2, lb, ub)\n                offspring = self.adaptive_mutation(offspring, lb, ub)\n                new_population.append(offspring)\n            \n            new_population.extend(elites)\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n            \n            population, fitness = self.selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n\n            self.alpha = 0.5 * (1 + evaluations / self.budget)  # Changed line\n        \n        return best_solution, best_fitness\n    \n    def select_parents(self, population, fitness):\n        idx1, idx2 = np.random.choice(len(population), size=2, replace=False)\n        return population[idx1], population[idx2]\n    \n    def quantum_crossover(self, parent1, parent2, lb, ub):\n        q1 = self.alpha * parent1 + (1 - self.alpha) * parent2\n        q2 = self.alpha * parent2 + (1 - self.alpha) * parent1\n        offspring = q1 if np.random.rand() < 0.5 else q2\n        offspring = np.clip(offspring, lb, ub)\n        return offspring\n    \n    def adaptive_mutation(self, individual, lb, ub):\n        mutation_strength = 0.1 * (ub - lb) * np.random.rand(self.dim)\n        mutated = individual + np.random.normal(0, mutation_strength, self.dim)\n        return np.clip(mutated, lb, ub)\n\n    def selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        return combined_population[sorted_indices][:self.population_size], combined_fitness[sorted_indices][:self.population_size]", "name": "EHQEA", "description": "Enhanced Quantum Elitism Evolutionary Algorithm (EQEEA) introduces dynamic alpha adjustment to balance exploration and exploitation for improved convergence.", "configspace": "", "generation": 4, "fitness": 0.903024680008598, "feedback": "The algorithm EHQEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.903 with standard deviation 0.014. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "b2c546fd-3e47-45e9-b299-aa2ed6c5b9d5", "metadata": {"aucs": [0.8836141398668779, 0.9106272140726129, 0.9148326860863032], "final_y": [0.11907983916213671, 0.11655860812961205, 0.11231609905295026]}, "mutation_prompt": null}
{"id": "16411415-2931-4798-a780-43b57858646e", "solution": "import numpy as np\n\nclass EHQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n        self.elite_fraction = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            new_population = []\n            elite_size = int(self.elite_fraction * self.population_size)\n            elites = population[np.argsort(fitness)[:elite_size]]\n            for _ in range(self.population_size - elite_size):\n                parent1, parent2 = self.select_parents(population, fitness)\n                offspring = self.quantum_crossover(parent1, parent2, lb, ub)\n                offspring = self.adaptive_mutation(offspring, lb, ub)\n                new_population.append(offspring)\n            \n            new_population.extend(elites)\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n            \n            population, fitness = self.selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n        \n        return best_solution, best_fitness\n    \n    def select_parents(self, population, fitness):\n        # Tournament selection for diverse parent selection\n        tournament_size = 3\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent1_idx = tournament_indices[np.argmin(tournament_fitness)]\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent2_idx = tournament_indices[np.argmin(tournament_fitness)]\n        return population[parent1_idx], population[parent2_idx]\n    \n    def quantum_crossover(self, parent1, parent2, lb, ub):\n        q1 = self.alpha * parent1 + (1 - self.alpha) * parent2\n        q2 = self.alpha * parent2 + (1 - self.alpha) * parent1\n        offspring = q1 if np.random.rand() < 0.5 else q2\n        offspring = np.clip(offspring, lb, ub)\n        return offspring\n    \n    def adaptive_mutation(self, individual, lb, ub):\n        mutation_strength = 0.1 * (ub - lb) * np.random.rand(self.dim)\n        mutated = individual + np.random.normal(0, mutation_strength, self.dim)\n        return np.clip(mutated, lb, ub)\n\n    def selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        return combined_population[sorted_indices][:self.population_size], combined_fitness[sorted_indices][:self.population_size]", "name": "EHQEA", "description": "Introduce diverse parent selection based on tournament selection to enhance exploration while maintaining convergence speed.", "configspace": "", "generation": 4, "fitness": 0.9055203077295717, "feedback": "The algorithm EHQEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.906 with standard deviation 0.013. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "b2c546fd-3e47-45e9-b299-aa2ed6c5b9d5", "metadata": {"aucs": [0.9188637263383062, 0.8881169973918042, 0.9095801994586046], "final_y": [0.11382389163630113, 0.12171606020052561, 0.11443167540695798]}, "mutation_prompt": null}
{"id": "3a09d9d6-0b1f-47f1-aa1f-b637aa18953e", "solution": "import numpy as np\n\nclass AQEHA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n        self.elite_fraction = 0.15  # Adjusted to increase elite size\n        self.dynamic_population_size = True  # New line\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            new_population = []\n            elite_size = int(self.elite_fraction * self.population_size)\n            elites = population[np.argsort(fitness)[:elite_size]]\n            if self.dynamic_population_size:  # New line\n                self.population_size = max(10, int(self.population_size * 0.9))  # New line\n            for _ in range(self.population_size - elite_size):\n                parent1, parent2 = self.select_parents(population, fitness)\n                offspring = self.quantum_crossover(parent1, parent2, lb, ub)\n                offspring = self.diversity_mutation(offspring, lb, ub)  # Modified line\n                new_population.append(offspring)\n            \n            new_population.extend(elites)\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n            \n            population, fitness = self.selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n        \n        return best_solution, best_fitness\n    \n    def select_parents(self, population, fitness):\n        idx1, idx2 = np.random.choice(len(population), size=2, replace=False)\n        return population[idx1], population[idx2]\n    \n    def quantum_crossover(self, parent1, parent2, lb, ub):\n        q1 = self.alpha * parent1 + (1 - self.alpha) * parent2\n        q2 = self.alpha * parent2 + (1 - self.alpha) * parent1\n        offspring = q1 if np.random.rand() < 0.5 else q2\n        offspring = np.clip(offspring, lb, ub)\n        return offspring\n    \n    def diversity_mutation(self, individual, lb, ub):  # Modified function\n        mutation_strength = 0.15 * (ub - lb) * np.random.rand(self.dim)  # Adjusted mutation strength\n        mutated = individual + np.random.normal(0, mutation_strength, self.dim)\n        return np.clip(mutated, lb, ub)\n\n    def selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        return combined_population[sorted_indices][:self.population_size], combined_fitness[sorted_indices][:self.population_size]", "name": "AQEHA", "description": "Adaptive Quantum-Elite Hybrid Algorithm (AQEHA) integrates dynamic population sizing and diversity-enhancing mutations to improve exploration and convergence.", "configspace": "", "generation": 4, "fitness": 0.9015021804604153, "feedback": "The algorithm AQEHA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.902 with standard deviation 0.004. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "b2c546fd-3e47-45e9-b299-aa2ed6c5b9d5", "metadata": {"aucs": [0.8995718556724757, 0.8984131449110966, 0.9065215407976739], "final_y": [0.11713163691820083, 0.12065991166840351, 0.11616820123856542]}, "mutation_prompt": null}
{"id": "58631ac8-d3c8-4fea-b7bd-37b09b4f4ad1", "solution": "import numpy as np\n\nclass EHQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n        self.elite_fraction = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            new_population = []\n            elite_size = int(self.elite_fraction * self.population_size)\n            elites = population[np.argsort(fitness)[:elite_size]]\n            for _ in range(self.population_size - elite_size):\n                parent1, parent2 = self.select_parents(population, fitness)\n                offspring = self.quantum_crossover(parent1, parent2, lb, ub)\n                offspring = self.adaptive_mutation(offspring, lb, ub)\n                new_population.append(offspring)\n            \n            new_population.extend(elites)\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n            \n            population, fitness = self.selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n        \n        return best_solution, best_fitness\n    \n    def select_parents(self, population, fitness):\n        # Tournament selection for diverse parent selection\n        tournament_size = 3\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent1_idx = tournament_indices[np.argmin(tournament_fitness)]\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent2_idx = tournament_indices[np.argmin(tournament_fitness)]\n        return population[parent1_idx], population[parent2_idx]\n    \n    def quantum_crossover(self, parent1, parent2, lb, ub):\n        q1 = self.alpha * parent1 + (1 - self.alpha) * parent2\n        q2 = self.alpha * parent2 + (1 - self.alpha) * parent1\n        offspring = q1 if np.random.rand() < 0.5 else q2\n        offspring = np.clip(offspring, lb, ub)\n        return offspring\n    \n    def adaptive_mutation(self, individual, lb, ub):\n        mutation_strength = 0.15 * (ub - lb) * np.random.rand(self.dim)  # Changed from 0.1 to 0.15\n        mutated = individual + np.random.normal(0, mutation_strength, self.dim)\n        return np.clip(mutated, lb, ub)\n\n    def selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        return combined_population[sorted_indices][:self.population_size], combined_fitness[sorted_indices][:self.population_size]", "name": "EHQEA", "description": "Introduce a small variation in mutation strength to balance exploration and exploitation.", "configspace": "", "generation": 5, "fitness": 0.8669058602555029, "feedback": "The algorithm EHQEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.867 with standard deviation 0.025. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "16411415-2931-4798-a780-43b57858646e", "metadata": {"aucs": [0.9004851642694278, 0.8406848906000518, 0.859547525897029], "final_y": [0.11585538729632627, 0.1318129488785893, 0.11583942442091666]}, "mutation_prompt": null}
{"id": "d9b7b6eb-2fb2-4474-aa21-b9af2ab70891", "solution": "import numpy as np\n\nclass EHQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n        self.elite_fraction = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            new_population = []\n            elite_size = int(self.elite_fraction * self.population_size)\n            elites = population[np.argsort(fitness)[:elite_size]]\n            for _ in range(self.population_size - elite_size):\n                parent1, parent2 = self.select_parents(population, fitness)\n                offspring = self.quantum_crossover(parent1, parent2, lb, ub)\n                offspring = self.adaptive_mutation(offspring, lb, ub)\n                new_population.append(offspring)\n            \n            new_population.extend(elites)\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n            \n            population, fitness = self.selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n        \n        return best_solution, best_fitness\n    \n    def select_parents(self, population, fitness):\n        # Tournament selection for diverse parent selection\n        tournament_size = 3\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent1_idx = tournament_indices[np.argmin(tournament_fitness)]\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent2_idx = tournament_indices[np.argmin(tournament_fitness)]\n        return population[parent1_idx], population[parent2_idx]\n    \n    def quantum_crossover(self, parent1, parent2, lb, ub):\n        self.alpha = np.random.rand()  # Adjust alpha adaptively\n        q1 = self.alpha * parent1 + (1 - self.alpha) * parent2\n        q2 = self.alpha * parent2 + (1 - self.alpha) * parent1\n        offspring = q1 if np.random.rand() < 0.5 else q2\n        offspring = np.clip(offspring, lb, ub)\n        return offspring\n    \n    def adaptive_mutation(self, individual, lb, ub):\n        mutation_strength = 0.1 * (ub - lb) * np.random.rand(self.dim)\n        mutated = individual + np.random.normal(0, mutation_strength, self.dim)\n        return np.clip(mutated, lb, ub)\n\n    def selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        return combined_population[sorted_indices][:self.population_size], combined_fitness[sorted_indices][:self.population_size]", "name": "EHQEA", "description": "Implement adaptive crossover by varying alpha and improve exploration-exploitation balance.", "configspace": "", "generation": 5, "fitness": 0.8644589752719537, "feedback": "The algorithm EHQEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.864 with standard deviation 0.017. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "16411415-2931-4798-a780-43b57858646e", "metadata": {"aucs": [0.879631305487636, 0.8408728880193566, 0.8728727323088682], "final_y": [0.11929198970757782, 0.13116872149280578, 0.11466146659295817]}, "mutation_prompt": null}
{"id": "352d4b81-bee6-4407-92b0-ef9a3bf64bda", "solution": "import numpy as np\n\nclass EHQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n        self.elite_fraction = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            new_population = []\n            elite_size = int(self.elite_fraction * self.population_size)\n            elites = population[np.argsort(fitness)[:elite_size]]\n            for _ in range(self.population_size - elite_size):\n                parent1, parent2 = self.select_parents(population, fitness)\n                offspring = self.quantum_crossover(parent1, parent2, lb, ub)\n                offspring = self.adaptive_mutation(offspring, lb, ub, best_fitness)\n                new_population.append(offspring)\n            \n            new_population.extend(elites)\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n            \n            population, fitness = self.selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n        \n        return best_solution, best_fitness\n    \n    def select_parents(self, population, fitness):\n        # Tournament selection for diverse parent selection\n        tournament_size = 3\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent1_idx = tournament_indices[np.argmin(tournament_fitness)]\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent2_idx = tournament_indices[np.argmin(tournament_fitness)]\n        return population[parent1_idx], population[parent2_idx]\n    \n    def quantum_crossover(self, parent1, parent2, lb, ub):\n        q1 = self.alpha * parent1 + (1 - self.alpha) * parent2\n        q2 = self.alpha * parent2 + (1 - self.alpha) * parent1\n        offspring = q1 if np.random.rand() < 0.5 else q2\n        offspring = np.clip(offspring, lb, ub)\n        return offspring\n    \n    def adaptive_mutation(self, individual, lb, ub, best_fitness):\n        # Dynamically adjust mutation strength based on the improvement in fitness\n        mutation_strength = 0.1 * (ub - lb) * np.random.rand(self.dim) * (1 - best_fitness)\n        mutated = individual + np.random.normal(0, mutation_strength, self.dim)\n        return np.clip(mutated, lb, ub)\n\n    def selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        return combined_population[sorted_indices][:self.population_size], combined_fitness[sorted_indices][:self.population_size]", "name": "EHQEA", "description": "Enhance exploration by varying mutation strength dynamically based on fitness improvement.", "configspace": "", "generation": 5, "fitness": 0.8696405352652591, "feedback": "The algorithm EHQEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.870 with standard deviation 0.018. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "16411415-2931-4798-a780-43b57858646e", "metadata": {"aucs": [0.8954923324864836, 0.8557902642008515, 0.8576390091084419], "final_y": [0.11817188247260946, 0.12585142780516256, 0.11611067038612422]}, "mutation_prompt": null}
{"id": "710dbdfa-1fc1-48b2-95ec-75fe99320920", "solution": "import numpy as np\n\nclass EHQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n        self.elite_fraction = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            new_population = []\n            elite_size = int(self.elite_fraction * self.population_size)\n            elites = population[np.argsort(fitness)[:elite_size]]\n            for _ in range(self.population_size - elite_size):\n                parent1, parent2 = self.select_parents(population, fitness)\n                offspring = self.quantum_crossover(parent1, parent2, lb, ub)\n                offspring = self.adaptive_mutation(offspring, lb, ub, best_fitness)\n                new_population.append(offspring)\n            \n            new_population.extend(elites)\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n            \n            population, fitness = self.selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n        \n        return best_solution, best_fitness\n    \n    def select_parents(self, population, fitness):\n        # Tournament selection for diverse parent selection\n        tournament_size = 3\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent1_idx = tournament_indices[np.argmin(tournament_fitness)]\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent2_idx = tournament_indices[np.argmin(tournament_fitness)]\n        return population[parent1_idx], population[parent2_idx]\n    \n    def quantum_crossover(self, parent1, parent2, lb, ub):\n        q1 = self.alpha * parent1 + (1 - self.alpha) * parent2\n        q2 = self.alpha * parent2 + (1 - self.alpha) * parent1\n        offspring = q1 if np.random.rand() < 0.5 else q2\n        offspring = np.clip(offspring, lb, ub)\n        return offspring\n    \n    def adaptive_mutation(self, individual, lb, ub, best_fitness):\n        fitness_scale = 0.01 if best_fitness < 0.5 else 0.1\n        mutation_strength = fitness_scale * (ub - lb) * np.random.rand(self.dim)  # Changed line\n        mutated = individual + np.random.normal(0, mutation_strength, self.dim)\n        return np.clip(mutated, lb, ub)\n\n    def selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        return combined_population[sorted_indices][:self.population_size], combined_fitness[sorted_indices][:self.population_size]", "name": "EHQEA", "description": "Enhance mutation strategy by introducing adaptive scaling based on fitness improvements.", "configspace": "", "generation": 5, "fitness": 0.8538801101454011, "feedback": "The algorithm EHQEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.854 with standard deviation 0.020. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "16411415-2931-4798-a780-43b57858646e", "metadata": {"aucs": [0.8737672606698615, 0.8620638596089971, 0.8258092101573451], "final_y": [0.12059357460225284, 0.12399805519427809, 0.12939059013867793]}, "mutation_prompt": null}
{"id": "9ef36bb6-5e93-476f-a28f-8cd825ac1840", "solution": "import numpy as np\n\nclass EHQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n        self.elite_fraction = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            new_population = []\n            elite_size = int(self.elite_fraction * self.population_size)\n            elites = population[np.argsort(fitness)[:elite_size]]\n            for _ in range(self.population_size - elite_size):\n                parent1, parent2 = self.select_parents(population, fitness)\n                offspring = self.quantum_crossover(parent1, parent2, lb, ub)\n                offspring = self.adaptive_mutation(offspring, lb, ub)\n                new_population.append(offspring)\n            \n            new_population.extend(elites)\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n            \n            population, fitness = self.selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n        \n        return best_solution, best_fitness\n    \n    def select_parents(self, population, fitness):\n        # Tournament selection for diverse parent selection\n        tournament_size = 3\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent1_idx = tournament_indices[np.argmin(tournament_fitness)]\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent2_idx = tournament_indices[np.argmin(tournament_fitness)]\n        return population[parent1_idx], population[parent2_idx]\n    \n    def quantum_crossover(self, parent1, parent2, lb, ub):\n        q1 = self.alpha * parent1 + (1 - self.alpha) * parent2\n        q2 = self.alpha * parent2 + (1 - self.alpha) * parent1\n        offspring = q1 if np.random.rand() < 0.5 else q2\n        offspring = np.clip(offspring, lb, ub)\n        return offspring\n    \n    def adaptive_mutation(self, individual, lb, ub):\n        # Modified line for mutation strength scaling\n        mutation_strength = 0.1 * (ub - lb) * np.random.rand(self.dim) * 0.5\n        mutated = individual + np.random.normal(0, mutation_strength, self.dim)\n        return np.clip(mutated, lb, ub)\n\n    def selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        return combined_population[sorted_indices][:self.population_size], combined_fitness[sorted_indices][:self.population_size]", "name": "EHQEA", "description": "Enhance mutation by scaling the mutation strength based on fitness difference to improve local exploitation.", "configspace": "", "generation": 5, "fitness": 0.862521883956636, "feedback": "The algorithm EHQEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.863 with standard deviation 0.009. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "16411415-2931-4798-a780-43b57858646e", "metadata": {"aucs": [0.8710382956296554, 0.8505195175141105, 0.8660078387261418], "final_y": [0.12188980613965827, 0.12312700954680689, 0.11439519311224744]}, "mutation_prompt": null}
{"id": "f0952054-ac46-4ca1-9443-8875227d8f6d", "solution": "import numpy as np\n\nclass EHQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n        self.elite_fraction = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            new_population = []\n            elite_size = int(self.elite_fraction * self.population_size)\n            elites = population[np.argsort(fitness)[:elite_size]]\n            for _ in range(self.population_size - elite_size):\n                parent1, parent2 = self.select_parents(population, fitness)\n                offspring = self.quantum_crossover(parent1, parent2, lb, ub)\n                offspring = self.adaptive_mutation(offspring, lb, ub)\n                new_population.append(offspring)\n            \n            new_population.extend(elites)\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n            \n            population, fitness = self.selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n        \n        return best_solution, best_fitness\n    \n    def select_parents(self, population, fitness):\n        tournament_size = 3\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent1_idx = tournament_indices[np.argmin(tournament_fitness)]\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent2_idx = tournament_indices[np.argmin(tournament_fitness)]\n        return population[parent1_idx], population[parent2_idx]\n    \n    def quantum_crossover(self, parent1, parent2, lb, ub):\n        q1 = self.alpha * parent1 + (1 - self.alpha) * parent2\n        q2 = self.alpha * parent2 + (1 - self.alpha) * parent1\n        offspring = q1 if np.random.rand() < 0.5 else q2\n        offspring = np.clip(offspring, lb, ub)\n        return offspring\n    \n    def adaptive_mutation(self, individual, lb, ub):\n        mutation_strength = 0.1 * (ub - lb) * np.random.rand(self.dim)\n        step_size = np.random.uniform(0.05, 0.15)  # Adaptive step size\n        mutated = individual + np.random.normal(0, mutation_strength * step_size, self.dim)  # Apply step size\n        return np.clip(mutated, lb, ub)\n\n    def selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        return combined_population[sorted_indices][:self.population_size], combined_fitness[sorted_indices][:self.population_size]", "name": "EHQEA", "description": "Enriching exploration by replacing elite diversity with adaptive step size control to balance exploration and exploitation more effectively.", "configspace": "", "generation": 6, "fitness": 0.8922460439400242, "feedback": "The algorithm EHQEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.892 with standard deviation 0.012. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "16411415-2931-4798-a780-43b57858646e", "metadata": {"aucs": [0.8754015002540538, 0.8963523314334345, 0.9049843001325844], "final_y": [0.12067759127960609, 0.11998715779284919, 0.11492988329616416]}, "mutation_prompt": null}
{"id": "9694025c-e9ec-4319-9adb-80213a6156c4", "solution": "import numpy as np\n\nclass EHQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n        self.elite_fraction = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            new_population = []\n            elite_size = int(self.elite_fraction * self.population_size)\n            elites = population[np.argsort(fitness)[:elite_size]]\n            for _ in range(self.population_size - elite_size):\n                parent1, parent2 = self.select_parents(population, fitness)\n                offspring = self.enhanced_quantum_crossover(parent1, parent2, lb, ub)\n                offspring = self.efficient_adaptive_mutation(offspring, lb, ub)\n                new_population.append(offspring)\n            \n            new_population.extend(elites)\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n            \n            population, fitness = self.selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n        \n        return best_solution, best_fitness\n    \n    def select_parents(self, population, fitness):\n        tournament_size = 3\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent1_idx = tournament_indices[np.argmin(tournament_fitness)]\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent2_idx = tournament_indices[np.argmin(tournament_fitness)]\n        return population[parent1_idx], population[parent2_idx]\n    \n    def enhanced_quantum_crossover(self, parent1, parent2, lb, ub):\n        alpha_var = np.random.uniform(0.4, 0.6)\n        q1 = alpha_var * parent1 + (1 - alpha_var) * parent2\n        q2 = alpha_var * parent2 + (1 - alpha_var) * parent1\n        offspring = q1 if np.random.rand() < 0.5 else q2\n        offspring = np.clip(offspring, lb, ub)\n        return offspring\n    \n    def efficient_adaptive_mutation(self, individual, lb, ub):\n        mutation_strength = 0.1 * (ub - lb) * np.random.random_sample(self.dim)\n        mutated = individual + np.random.normal(0, mutation_strength, self.dim)\n        return np.clip(mutated, lb, ub)\n\n    def selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        return combined_population[sorted_indices][:self.population_size], combined_fitness[sorted_indices][:self.population_size]", "name": "EHQEA", "description": "Enhance quantum crossover variability and adaptive mutation efficiency for improved convergence.", "configspace": "", "generation": 6, "fitness": 0.9141153870586352, "feedback": "The algorithm EHQEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.914 with standard deviation 0.011. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "16411415-2931-4798-a780-43b57858646e", "metadata": {"aucs": [0.9213691078129377, 0.8983412436238064, 0.9226358097391615], "final_y": [0.11292332377349223, 0.11784832220188668, 0.11139587787919769]}, "mutation_prompt": null}
{"id": "6d70dcc1-f958-4984-b821-499b036bc381", "solution": "import numpy as np\n\nclass EHQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n        self.elite_fraction = 0.1\n        self.sigma_init = 0.1  # Initial mutation strength\n        self.tau = 0.01  # Mutation adaptation rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n        sigma = self.sigma_init\n\n        while evaluations < self.budget:\n            new_population = []\n            elite_size = int(self.elite_fraction * self.population_size)\n            elites = population[np.argsort(fitness)[:elite_size]]\n            for _ in range(self.population_size - elite_size):\n                parent1, parent2 = self.select_parents(population, fitness)\n                offspring = self.quantum_crossover(parent1, parent2, lb, ub)\n                offspring = self.adaptive_mutation(offspring, lb, ub, sigma)\n                new_population.append(offspring)\n            \n            new_population.extend(elites)\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n            \n            population, fitness = self.stochastic_selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            sigma *= np.exp(self.tau * np.random.randn())\n\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n        \n        return best_solution, best_fitness\n    \n    def select_parents(self, population, fitness):\n        tournament_size = 3\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent1_idx = tournament_indices[np.argmin(tournament_fitness)]\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent2_idx = tournament_indices[np.argmin(tournament_fitness)]\n        return population[parent1_idx], population[parent2_idx]\n    \n    def quantum_crossover(self, parent1, parent2, lb, ub):\n        q1 = self.alpha * parent1 + (1 - self.alpha) * parent2\n        q2 = self.alpha * parent2 + (1 - self.alpha) * parent1\n        offspring = q1 if np.random.rand() < 0.5 else q2\n        offspring = np.clip(offspring, lb, ub)\n        return offspring\n    \n    def adaptive_mutation(self, individual, lb, ub, sigma):\n        mutation_strength = sigma * (ub - lb) * np.random.rand(self.dim)\n        mutated = individual + np.random.normal(0, mutation_strength, self.dim)\n        return np.clip(mutated, lb, ub)\n\n    def stochastic_selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        indices = np.random.permutation(len(combined_fitness))\n        combined_population = combined_population[indices]\n        combined_fitness = combined_fitness[indices]\n        sorted_indices = np.argsort(combined_fitness)\n        return combined_population[sorted_indices][:self.population_size], combined_fitness[sorted_indices][:self.population_size]", "name": "EHQEA", "description": "Introduce self-adaptive parameter tuning and stochastic ranking to enhance exploration and convergence.", "configspace": "", "generation": 6, "fitness": 0.9111783771804647, "feedback": "The algorithm EHQEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.911 with standard deviation 0.007. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "16411415-2931-4798-a780-43b57858646e", "metadata": {"aucs": [0.9021413391209414, 0.9127449291772718, 0.9186488632431808], "final_y": [0.11819456796513661, 0.11433957552176144, 0.1137133531132053]}, "mutation_prompt": null}
{"id": "4053ebc1-e5a7-44da-9c5f-5bd2aaf991c6", "solution": "import numpy as np\n\nclass EHQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n        self.elite_fraction = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            new_population = []\n            elite_size = int(self.elite_fraction * self.population_size)\n            elites = population[np.argsort(fitness)[:elite_size]]\n            for _ in range(self.population_size - elite_size):\n                parent1, parent2 = self.select_parents(population, fitness)\n                offspring = self.quantum_crossover(parent1, parent2, lb, ub)\n                offspring = self.adaptive_mutation(offspring, lb, ub, evaluations / self.budget)\n                new_population.append(offspring)\n            \n            new_population.extend(elites)\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n            \n            population, fitness = self.selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n        \n        return best_solution, best_fitness\n    \n    def select_parents(self, population, fitness):\n        # Tournament selection for diverse parent selection\n        tournament_size = 3\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent1_idx = tournament_indices[np.argmin(tournament_fitness)]\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent2_idx = tournament_indices[np.argmin(tournament_fitness)]\n        return population[parent1_idx], population[parent2_idx]\n    \n    def quantum_crossover(self, parent1, parent2, lb, ub):\n        q1 = self.alpha * parent1 + (1 - self.alpha) * parent2\n        q2 = self.alpha * parent2 + (1 - self.alpha) * parent1\n        offspring = q1 if np.random.rand() < 0.5 else q2\n        offspring = np.clip(offspring, lb, ub)\n        return offspring\n    \n    def adaptive_mutation(self, individual, lb, ub, progress):\n        mutation_strength = (0.1 * (1 - progress)) * (ub - lb) * np.random.rand(self.dim)\n        mutated = individual + np.random.normal(0, mutation_strength, self.dim)\n        return np.clip(mutated, lb, ub)\n\n    def selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        return combined_population[sorted_indices][:self.population_size], combined_fitness[sorted_indices][:self.population_size]", "name": "EHQEA", "description": "Refine adaptive mutation using a dynamic mutation strength that decreases over time to balance exploration and exploitation.", "configspace": "", "generation": 6, "fitness": 0.9062565373412776, "feedback": "The algorithm EHQEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.906 with standard deviation 0.011. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "16411415-2931-4798-a780-43b57858646e", "metadata": {"aucs": [0.905987997938157, 0.8933113133009071, 0.9194703007847689], "final_y": [0.11759385478198892, 0.11840996069642129, 0.11439897075846961]}, "mutation_prompt": null}
{"id": "afdc9e81-abcf-44e6-bf25-d23dacf3a8e8", "solution": "import numpy as np\n\nclass EHQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n        self.elite_fraction = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            new_population = []\n            elite_size = int(self.elite_fraction * self.population_size)\n            elites = population[np.argsort(fitness)[:elite_size]]\n            for _ in range(self.population_size - elite_size):\n                parent1, parent2 = self.select_parents(population, fitness)\n                offspring = self.quantum_crossover(parent1, parent2, lb, ub, evaluations)\n                offspring = self.adaptive_mutation(offspring, lb, ub, evaluations)\n                new_population.append(offspring)\n            \n            new_population.extend(elites)\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n            \n            population, fitness = self.selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n        \n        return best_solution, best_fitness\n    \n    def select_parents(self, population, fitness):\n        # Tournament selection for diverse parent selection\n        tournament_size = 3\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent1_idx = tournament_indices[np.argmin(tournament_fitness)]\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent2_idx = tournament_indices[np.argmin(tournament_fitness)]\n        return population[parent1_idx], population[parent2_idx]\n    \n    def quantum_crossover(self, parent1, parent2, lb, ub, evaluations):\n        dynamic_alpha = self.alpha * (1 - evaluations / self.budget)\n        q1 = dynamic_alpha * parent1 + (1 - dynamic_alpha) * parent2\n        q2 = dynamic_alpha * parent2 + (1 - dynamic_alpha) * parent1\n        offspring = q1 if np.random.rand() < 0.5 else q2\n        offspring = np.clip(offspring, lb, ub)\n        return offspring\n    \n    def adaptive_mutation(self, individual, lb, ub, evaluations):\n        mutation_strength = 0.1 * (ub - lb) * (1 - evaluations / self.budget) * np.random.rand(self.dim)\n        mutated = individual + np.random.normal(0, mutation_strength, self.dim)\n        return np.clip(mutated, lb, ub)\n\n    def selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        return combined_population[sorted_indices][:self.population_size], combined_fitness[sorted_indices][:self.population_size]", "name": "EHQEA", "description": "Introduce variable mutation strength and adaptive alpha in quantum crossover to improve exploration and convergence.", "configspace": "", "generation": 6, "fitness": 0.9035365559447053, "feedback": "The algorithm EHQEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.904 with standard deviation 0.011. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "16411415-2931-4798-a780-43b57858646e", "metadata": {"aucs": [0.8925651826256821, 0.8992463379923438, 0.91879814721609], "final_y": [0.11528840349753022, 0.1183986666613227, 0.11352772351438523]}, "mutation_prompt": null}
{"id": "1520a903-75da-4e04-ad8c-a020e43371ba", "solution": "import numpy as np\n\nclass EHQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n        self.elite_fraction = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            new_population = []\n            elite_size = int(self.elite_fraction * self.population_size)\n            elites = population[np.argsort(fitness)[:elite_size]]\n            for _ in range(self.population_size - elite_size):\n                parent1, parent2 = self.select_parents(population, fitness)\n                offspring = self.enhanced_quantum_crossover(parent1, parent2, lb, ub)\n                offspring = self.efficient_adaptive_mutation(offspring, lb, ub)\n                new_population.append(offspring)\n            \n            new_population.extend(elites)\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n            \n            population, fitness = self.selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n        \n        return best_solution, best_fitness\n    \n    def select_parents(self, population, fitness):\n        probabilities = 1 / (fitness + 1e-6)\n        probabilities /= probabilities.sum()\n        parent1_idx = np.random.choice(len(population), p=probabilities)\n        parent2_idx = np.random.choice(len(population), p=probabilities)\n        return population[parent1_idx], population[parent2_idx]\n    \n    def enhanced_quantum_crossover(self, parent1, parent2, lb, ub):\n        alpha_var = np.random.uniform(0.4, 0.6)\n        q1 = alpha_var * parent1 + (1 - alpha_var) * parent2\n        q2 = alpha_var * parent2 + (1 - alpha_var) * parent1\n        offspring = q1 if np.random.rand() < 0.5 else q2\n        offspring = np.clip(offspring, lb, ub)\n        return offspring\n    \n    def efficient_adaptive_mutation(self, individual, lb, ub):\n        mutation_strength = 0.1 * (ub - lb) * np.random.random_sample(self.dim)\n        mutated = individual + np.random.normal(0, mutation_strength, self.dim)\n        return np.clip(mutated, lb, ub)\n\n    def selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        return combined_population[sorted_indices][:self.population_size], combined_fitness[sorted_indices][:self.population_size]", "name": "EHQEA", "description": "Refine parent selection using a fitness-proportionate method for better convergence.", "configspace": "", "generation": 7, "fitness": 0.9057132841683823, "feedback": "The algorithm EHQEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.906 with standard deviation 0.007. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "9694025c-e9ec-4319-9adb-80213a6156c4", "metadata": {"aucs": [0.8981041711818069, 0.9049375921684996, 0.9140980891548404], "final_y": [0.11275812937217577, 0.11506434558666645, 0.11251275977112418]}, "mutation_prompt": null}
{"id": "55d547a1-52f0-4fad-ae59-fd55f5106466", "solution": "import numpy as np\n\nclass EHQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n        self.elite_fraction = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            new_population = []\n            elite_size = int(self.elite_fraction * self.population_size)\n            elites = population[np.argsort(fitness)[:elite_size]]\n            for _ in range(self.population_size - elite_size):\n                parent1, parent2 = self.select_parents(population, fitness)\n                offspring = self.enhanced_quantum_crossover(parent1, parent2, lb, ub)\n                offspring = self.efficient_adaptive_mutation(offspring, lb, ub, evaluations / self.budget)\n                new_population.append(offspring)\n            \n            new_population.extend(elites)\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n            \n            population, fitness = self.selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n        \n        return best_solution, best_fitness\n    \n    def select_parents(self, population, fitness):\n        tournament_size = 3\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent1_idx = tournament_indices[np.argmin(tournament_fitness)]\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent2_idx = tournament_indices[np.argmin(tournament_fitness)]\n        return population[parent1_idx], population[parent2_idx]\n    \n    def enhanced_quantum_crossover(self, parent1, parent2, lb, ub):\n        alpha_var = np.random.uniform(0.4, 0.6)\n        q1 = alpha_var * parent1 + (1 - alpha_var) * parent2\n        q2 = alpha_var * parent2 + (1 - alpha_var) * parent1\n        offspring = q1 if np.random.rand() < 0.5 else q2\n        offspring = np.clip(offspring, lb, ub)\n        return offspring\n    \n    def efficient_adaptive_mutation(self, individual, lb, ub, progress):\n        mutation_strength = 0.1 * (ub - lb) * np.random.random_sample(self.dim) * (1 - progress)\n        mutated = individual + np.random.normal(0, mutation_strength, self.dim)\n        return np.clip(mutated, lb, ub)\n\n    def selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        return combined_population[sorted_indices][:self.population_size], combined_fitness[sorted_indices][:self.population_size]", "name": "EHQEA", "description": "Introduce a dynamic mutation strength scaling mechanism to enhance exploration-exploitation balance.", "configspace": "", "generation": 7, "fitness": 0.9165677557604494, "feedback": "The algorithm EHQEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.917 with standard deviation 0.008. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "9694025c-e9ec-4319-9adb-80213a6156c4", "metadata": {"aucs": [0.9282180238207808, 0.908280756483237, 0.91320448697733], "final_y": [0.1097168413799604, 0.11704490633247833, 0.11377506066550158]}, "mutation_prompt": null}
{"id": "d691a954-ccc2-4192-8066-5d15ca2a361a", "solution": "import numpy as np\n\nclass EHQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n        self.elite_fraction = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Change: Implement dynamic scaling of population size\n            self.population_size = max(20, int(self.population_size * (1 - 0.02 * (self.population_size / self.budget))))\n            new_population = []\n            elite_size = int(self.elite_fraction * self.population_size)\n            elites = population[np.argsort(fitness)[:elite_size]]\n            for _ in range(self.population_size - elite_size):\n                parent1, parent2 = self.select_parents(population, fitness)\n                offspring = self.enhanced_quantum_crossover(parent1, parent2, lb, ub)\n                offspring = self.efficient_adaptive_mutation(offspring, lb, ub)\n                new_population.append(offspring)\n            \n            new_population.extend(elites)\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n            \n            population, fitness = self.selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n        \n        return best_solution, best_fitness\n    \n    def select_parents(self, population, fitness):\n        tournament_size = 3\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent1_idx = tournament_indices[np.argmin(tournament_fitness)]\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent2_idx = tournament_indices[np.argmin(tournament_fitness)]\n        return population[parent1_idx], population[parent2_idx]\n    \n    def enhanced_quantum_crossover(self, parent1, parent2, lb, ub):\n        alpha_var = np.random.uniform(0.4, 0.6)\n        q1 = alpha_var * parent1 + (1 - alpha_var) * parent2\n        q2 = alpha_var * parent2 + (1 - alpha_var) * parent1\n        offspring = q1 if np.random.rand() < 0.5 else q2\n        offspring = np.clip(offspring, lb, ub)\n        return offspring\n    \n    def efficient_adaptive_mutation(self, individual, lb, ub):\n        mutation_strength = 0.1 * (ub - lb) * np.random.random_sample(self.dim)\n        mutated = individual + np.random.normal(0, mutation_strength, self.dim)\n        return np.clip(mutated, lb, ub)\n\n    def selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        return combined_population[sorted_indices][:self.population_size], combined_fitness[sorted_indices][:self.population_size]", "name": "EHQEA", "description": "Introduced dynamic population size scaling based on convergence rate to enhance optimization efficiency.", "configspace": "", "generation": 7, "fitness": 0.908031860035663, "feedback": "The algorithm EHQEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.908 with standard deviation 0.010. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "9694025c-e9ec-4319-9adb-80213a6156c4", "metadata": {"aucs": [0.8933451704951428, 0.9166765789433927, 0.9140738306684538], "final_y": [0.12213909966727943, 0.11362548843821818, 0.11274023987394977]}, "mutation_prompt": null}
{"id": "b41a594d-fd01-422c-9843-a0ab71fc8980", "solution": "import numpy as np\n\nclass EHQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n        self.elite_fraction = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            new_population = []\n            elite_size = int(self.elite_fraction * self.population_size)\n            elites = population[np.argsort(fitness)[:elite_size]]\n            for _ in range(self.population_size - elite_size):\n                parent1, parent2 = self.select_parents(population, fitness)\n                offspring = self.enhanced_quantum_crossover(parent1, parent2, lb, ub)\n                offspring = self.efficient_adaptive_mutation(offspring, lb, ub)\n                new_population.append(offspring)\n            \n            # Apply elite mutation to enhance exploration\n            mutated_elites = [self.efficient_adaptive_mutation(elite, lb, ub) for elite in elites]\n            new_population.extend(mutated_elites)\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n            \n            population, fitness = self.selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n        \n        return best_solution, best_fitness\n    \n    def select_parents(self, population, fitness):\n        tournament_size = 3\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent1_idx = tournament_indices[np.argmin(tournament_fitness)]\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent2_idx = tournament_indices[np.argmin(tournament_fitness)]\n        return population[parent1_idx], population[parent2_idx]\n    \n    def enhanced_quantum_crossover(self, parent1, parent2, lb, ub):\n        alpha_var = np.random.uniform(0.4, 0.6)\n        q1 = alpha_var * parent1 + (1 - alpha_var) * parent2\n        q2 = alpha_var * parent2 + (1 - alpha_var) * parent1\n        offspring = q1 if np.random.rand() < 0.5 else q2\n        offspring = np.clip(offspring, lb, ub)\n        return offspring\n    \n    def efficient_adaptive_mutation(self, individual, lb, ub):\n        mutation_strength = 0.1 * (ub - lb) * np.random.random_sample(self.dim)\n        mutated = individual + np.random.normal(0, mutation_strength, self.dim)\n        return np.clip(mutated, lb, ub)\n\n    def selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        return combined_population[sorted_indices][:self.population_size], combined_fitness[sorted_indices][:self.population_size]", "name": "EHQEA", "description": "Incorporate elite mutation to enhance exploration of top-performing solutions.", "configspace": "", "generation": 7, "fitness": 0.9066092640376064, "feedback": "The algorithm EHQEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.907 with standard deviation 0.006. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "9694025c-e9ec-4319-9adb-80213a6156c4", "metadata": {"aucs": [0.9075213385421382, 0.8982336530859045, 0.9140728004847767], "final_y": [0.1122648678179875, 0.113907653056052, 0.11427222196986742]}, "mutation_prompt": null}
{"id": "64cbef1b-a14f-44cb-8bd8-d370c4c018f6", "solution": "import numpy as np\n\nclass EHQEA_Swarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n        self.elite_fraction = 0.1\n        self.inertia_weight = 0.7\n        self.cognitive_param = 1.5\n        self.social_param = 2.0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        personal_best = population.copy()\n        personal_best_fitness = fitness.copy()\n        best_idx = np.argmin(fitness)\n        global_best = population[best_idx]\n        global_best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocity = (self.inertia_weight * velocity +\n                        self.cognitive_param * r1 * (personal_best - population) +\n                        self.social_param * r2 * (global_best - population))\n            population += velocity\n            population = np.clip(population, lb, ub)\n            \n            fitness = np.array([func(ind) for ind in population])\n            evaluations += self.population_size\n            \n            improved = fitness < personal_best_fitness\n            personal_best[improved] = population[improved]\n            personal_best_fitness[improved] = fitness[improved]\n            \n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < global_best_fitness:\n                global_best, global_best_fitness = population[current_best_idx], fitness[current_best_idx]\n        \n        return global_best, global_best_fitness", "name": "EHQEA_Swarm", "description": "Integrate swarm dynamics to enhance exploration capabilities while maintaining convergence efficiency in black box optimization.", "configspace": "", "generation": 7, "fitness": 0.8288055373299024, "feedback": "The algorithm EHQEA_Swarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.829 with standard deviation 0.048. And the mean value of best solutions found was 0.142 (0. is the best) with standard deviation 0.018.", "error": "", "parent_id": "9694025c-e9ec-4319-9adb-80213a6156c4", "metadata": {"aucs": [0.7868898283809509, 0.8963046870454678, 0.8032220965632881], "final_y": [0.15339472833249912, 0.11680071285006866, 0.1561244955622565]}, "mutation_prompt": null}
{"id": "c36966aa-445f-4d58-805e-a5d96890963f", "solution": "import numpy as np\n\nclass EHQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n        self.elite_fraction = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            new_population = []\n            elite_size = int(self.elite_fraction * self.population_size)\n            elites = population[np.argsort(fitness)[:elite_size]]\n            for _ in range(self.population_size - elite_size):\n                parent1, parent2 = self.select_parents(population, fitness)\n                offspring = self.enhanced_quantum_crossover(parent1, parent2, lb, ub)\n                offspring = self.efficient_adaptive_mutation(offspring, lb, ub, evaluations / self.budget)\n                new_population.append(offspring)\n            \n            new_population.extend(elites)\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n            \n            population, fitness = self.selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n        \n        return best_solution, best_fitness\n    \n    def select_parents(self, population, fitness):\n        tournament_size = 3\n        probabilities = np.exp(-fitness/np.std(fitness))\n        probabilities /= probabilities.sum()\n        parent1_idx = np.random.choice(len(population), p=probabilities)\n        parent2_idx = np.random.choice(len(population), p=probabilities)\n        return population[parent1_idx], population[parent2_idx]\n    \n    def enhanced_quantum_crossover(self, parent1, parent2, lb, ub):\n        alpha_var = np.random.uniform(0.4, 0.6)\n        q1 = alpha_var * parent1 + (1 - alpha_var) * parent2\n        q2 = alpha_var * parent2 + (1 - alpha_var) * parent1\n        offspring = q1 if np.random.rand() < 0.5 else q2\n        offspring = np.clip(offspring, lb, ub)\n        return offspring\n    \n    def efficient_adaptive_mutation(self, individual, lb, ub, progress):\n        mutation_strength = 0.1 * (ub - lb) * np.random.random_sample(self.dim) * (1 - progress)\n        mutated = individual + np.random.normal(0, mutation_strength, self.dim)\n        return np.clip(mutated, lb, ub)\n\n    def selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        return combined_population[sorted_indices][:self.population_size], combined_fitness[sorted_indices][:self.population_size]", "name": "EHQEA", "description": "Enhance parent selection using a weighted tournament to improve convergence speed.", "configspace": "", "generation": 8, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('probabilities contain NaN').", "error": "ValueError('probabilities contain NaN')", "parent_id": "55d547a1-52f0-4fad-ae59-fd55f5106466", "metadata": {}, "mutation_prompt": null}
{"id": "c4f17755-b7cb-4569-b3bf-7fe0be39161a", "solution": "import numpy as np\n\nclass EHQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n        self.elite_fraction = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            new_population = []\n            # Introduce dynamic elite fraction\n            self.elite_fraction = 0.1 + 0.2 * (evaluations / self.budget)\n            elite_size = int(self.elite_fraction * self.population_size)\n            elites = population[np.argsort(fitness)[:elite_size]]\n            for _ in range(self.population_size - elite_size):\n                parent1, parent2 = self.select_parents(population, fitness)\n                offspring = self.enhanced_quantum_crossover(parent1, parent2, lb, ub)\n                offspring = self.efficient_adaptive_mutation(offspring, lb, ub, evaluations / self.budget)\n                new_population.append(offspring)\n            \n            new_population.extend(elites)\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n            \n            population, fitness = self.selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n        \n        return best_solution, best_fitness\n    \n    def select_parents(self, population, fitness):\n        tournament_size = 3\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent1_idx = tournament_indices[np.argmin(tournament_fitness)]\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent2_idx = tournament_indices[np.argmin(tournament_fitness)]\n        return population[parent1_idx], population[parent2_idx]\n    \n    def enhanced_quantum_crossover(self, parent1, parent2, lb, ub):\n        alpha_var = np.random.uniform(0.4, 0.6)\n        q1 = alpha_var * parent1 + (1 - alpha_var) * parent2\n        q2 = alpha_var * parent2 + (1 - alpha_var) * parent1\n        offspring = q1 if np.random.rand() < 0.5 else q2\n        offspring = np.clip(offspring, lb, ub)\n        return offspring\n    \n    def efficient_adaptive_mutation(self, individual, lb, ub, progress):\n        mutation_strength = 0.1 * (ub - lb) * np.random.random_sample(self.dim) * (1 - progress)\n        mutated = individual + np.random.normal(0, mutation_strength, self.dim)\n        return np.clip(mutated, lb, ub)\n\n    def selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        return combined_population[sorted_indices][:self.population_size], combined_fitness[sorted_indices][:self.population_size]", "name": "EHQEA", "description": "Introduce dynamic elite fraction to balance exploration and exploitation during the optimization process.", "configspace": "", "generation": 8, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('probabilities contain NaN').", "error": "ValueError('probabilities contain NaN')", "parent_id": "55d547a1-52f0-4fad-ae59-fd55f5106466", "metadata": {}, "mutation_prompt": null}
{"id": "0b197cf7-090e-4c4c-8ae4-90114d573fcb", "solution": "import numpy as np\n\nclass EHQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n        self.elite_fraction = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            new_population = []\n            self.elite_fraction = 0.1 + 0.1 * (evaluations / self.budget)  # Dynamic elite fraction\n            elite_size = int(self.elite_fraction * self.population_size)\n            elites = population[np.argsort(fitness)[:elite_size]]\n            for _ in range(self.population_size - elite_size):\n                parent1, parent2 = self.select_parents(population, fitness)\n                offspring = self.enhanced_quantum_crossover(parent1, parent2, lb, ub)\n                offspring = self.efficient_adaptive_mutation(offspring, lb, ub, evaluations / self.budget)\n                new_population.append(offspring)\n            \n            new_population.extend(elites)\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n            \n            population, fitness = self.selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n        \n        return best_solution, best_fitness\n    \n    def select_parents(self, population, fitness):\n        tournament_size = 3\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent1_idx = tournament_indices[np.argmin(tournament_fitness)]\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent2_idx = tournament_indices[np.argmin(tournament_fitness)]\n        return population[parent1_idx], population[parent2_idx]\n    \n    def enhanced_quantum_crossover(self, parent1, parent2, lb, ub):\n        alpha_var = np.random.uniform(0.4, 0.6)\n        q1 = alpha_var * parent1 + (1 - alpha_var) * parent2\n        q2 = alpha_var * parent2 + (1 - alpha_var) * parent1\n        offspring = q1 if np.random.rand() < 0.5 else q2\n        offspring = np.clip(offspring, lb, ub)\n        return offspring\n    \n    def efficient_adaptive_mutation(self, individual, lb, ub, progress):\n        mutation_strength = 0.1 * (ub - lb) * np.random.random_sample(self.dim) * (1 - progress)\n        mutated = individual + np.random.normal(0, mutation_strength, self.dim)\n        return np.clip(mutated, lb, ub)\n\n    def selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        return combined_population[sorted_indices][:self.population_size], combined_fitness[sorted_indices][:self.population_size]", "name": "EHQEA", "description": "Introduce diversity enhancement by varying elite_fraction dynamically to improve exploration.", "configspace": "", "generation": 8, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('probabilities contain NaN').", "error": "ValueError('probabilities contain NaN')", "parent_id": "55d547a1-52f0-4fad-ae59-fd55f5106466", "metadata": {}, "mutation_prompt": null}
{"id": "66123220-265d-4a18-85f5-ff8faee6aa18", "solution": "import numpy as np\n\nclass EHQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n        self.elite_fraction = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            new_population = []\n            elite_size = int(self.elite_fraction * (1 + evaluations / self.budget) * self.population_size)\n            elites = population[np.argsort(fitness)[:elite_size]]\n            for _ in range(self.population_size - elite_size):\n                parent1, parent2 = self.select_parents(population, fitness)\n                offspring = self.enhanced_quantum_crossover(parent1, parent2, lb, ub)\n                offspring = self.efficient_adaptive_mutation(offspring, lb, ub, evaluations / self.budget)\n                new_population.append(offspring)\n            \n            new_population.extend(elites)\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n            \n            population, fitness = self.selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n        \n        return best_solution, best_fitness\n    \n    def select_parents(self, population, fitness):\n        tournament_size = 3\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent1_idx = tournament_indices[np.argmin(tournament_fitness)]\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent2_idx = tournament_indices[np.argmin(tournament_fitness)]\n        return population[parent1_idx], population[parent2_idx]\n    \n    def enhanced_quantum_crossover(self, parent1, parent2, lb, ub):\n        alpha_var = np.random.uniform(0.4, 0.6)\n        q1 = alpha_var * parent1 + (1 - alpha_var) * parent2\n        q2 = alpha_var * parent2 + (1 - alpha_var) * parent1\n        offspring = q1 if np.random.rand() < 0.5 else q2\n        offspring = np.clip(offspring, lb, ub)\n        return offspring\n    \n    def efficient_adaptive_mutation(self, individual, lb, ub, progress):\n        mutation_strength = 0.15 * (ub - lb) * np.random.random_sample(self.dim) * (1 - progress)\n        mutated = individual + np.random.normal(0, mutation_strength, self.dim)\n        return np.clip(mutated, lb, ub)\n\n    def selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        return combined_population[sorted_indices][:self.population_size], combined_fitness[sorted_indices][:self.population_size]", "name": "EHQEA", "description": "Introduce an adaptive elite fraction and fine-tune the mutation strength for improved exploration-exploitation balance.", "configspace": "", "generation": 8, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('probabilities contain NaN').", "error": "ValueError('probabilities contain NaN')", "parent_id": "55d547a1-52f0-4fad-ae59-fd55f5106466", "metadata": {}, "mutation_prompt": null}
{"id": "1d5035a2-c15f-4986-a679-fbd3aef4e1a5", "solution": "import numpy as np\n\nclass EHQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n        self.elite_fraction = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            new_population = []\n            elite_size = int(self.elite_fraction * self.population_size)\n            elites = population[np.argsort(fitness)[:elite_size]]\n            for _ in range(self.population_size - elite_size):\n                parent1, parent2 = self.select_parents(population, fitness)\n                offspring = self.enhanced_quantum_crossover(parent1, parent2, lb, ub)\n                offspring = self.efficient_adaptive_mutation(offspring, lb, ub, evaluations / self.budget)\n                new_population.append(offspring)\n            \n            new_population.extend(elites)\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n            \n            population, fitness = self.diversity_preserving_selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n        \n        return best_solution, best_fitness\n    \n    def select_parents(self, population, fitness):\n        tournament_size = 3\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent1_idx = tournament_indices[np.argmin(tournament_fitness)]\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent2_idx = tournament_indices[np.argmin(tournament_fitness)]\n        return population[parent1_idx], population[parent2_idx]\n    \n    def enhanced_quantum_crossover(self, parent1, parent2, lb, ub):\n        alpha_var = np.random.uniform(0.4, 0.6)\n        q1 = alpha_var * parent1 + (1 - alpha_var) * parent2\n        q2 = alpha_var * parent2 + (1 - alpha_var) * parent1\n        offspring = q1 if np.random.rand() < 0.5 else q2\n        offspring = np.clip(offspring, lb, ub)\n        return offspring\n    \n    def efficient_adaptive_mutation(self, individual, lb, ub, progress):\n        mutation_strength = 0.1 * (ub - lb) * np.random.random_sample(self.dim) * (1 - progress)\n        mutated = individual + np.random.normal(0, mutation_strength, self.dim)\n        return np.clip(mutated, lb, ub)\n\n    def diversity_preserving_selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        selected = combined_population[sorted_indices][:self.population_size]\n        return selected, combined_fitness[sorted_indices][:self.population_size]", "name": "EHQEA", "description": "Introduce diversity-preserving selection to maintain exploration and avoid premature convergence.", "configspace": "", "generation": 8, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('probabilities contain NaN').", "error": "ValueError('probabilities contain NaN')", "parent_id": "55d547a1-52f0-4fad-ae59-fd55f5106466", "metadata": {}, "mutation_prompt": null}
{"id": "dccefeba-ec16-46e1-b7c9-5a8a4b99362a", "solution": "import numpy as np\n\nclass EHQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n        self.elite_fraction = 0.1\n        self.dynamic_population = True\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            if self.dynamic_population:\n                self.population_size = min(max(5, int(self.alpha * self.budget / (evaluations + 1))), 100)\n            new_population = []\n            elite_size = int(self.elite_fraction * self.population_size)\n            elites = population[np.argsort(fitness)[:elite_size]]\n            for _ in range(self.population_size - elite_size):\n                parent1, parent2 = self.select_parents(population, fitness)\n                offspring = self.adaptive_crossover(parent1, parent2, lb, ub, evaluations / self.budget)\n                offspring = self.efficient_adaptive_mutation(offspring, lb, ub, evaluations / self.budget)\n                new_population.append(offspring)\n            \n            new_population.extend(elites)\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n            \n            population, fitness = self.selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n        \n        return best_solution, best_fitness\n    \n    def select_parents(self, population, fitness):\n        tournament_size = 3\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent1_idx = tournament_indices[np.argmin(tournament_fitness)]\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent2_idx = tournament_indices[np.argmin(tournament_fitness)]\n        return population[parent1_idx], population[parent2_idx]\n    \n    def adaptive_crossover(self, parent1, parent2, lb, ub, progress):\n        alpha_var = np.random.uniform(0.5 - progress / 10, 0.5 + progress / 10)\n        q1 = alpha_var * parent1 + (1 - alpha_var) * parent2\n        q2 = alpha_var * parent2 + (1 - alpha_var) * parent1\n        offspring = q1 if np.random.rand() < 0.5 else q2\n        offspring = np.clip(offspring, lb, ub)\n        return offspring\n    \n    def efficient_adaptive_mutation(self, individual, lb, ub, progress):\n        mutation_strength = 0.1 * (ub - lb) * np.random.random_sample(self.dim) * (1 - progress)\n        mutated = individual + np.random.normal(0, mutation_strength, self.dim)\n        return np.clip(mutated, lb, ub)\n\n    def selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        return combined_population[sorted_indices][:self.population_size], combined_fitness[sorted_indices][:self.population_size]", "name": "EHQEA", "description": "Introduce adaptive crossover strategy and dynamic population resizing to enhance convergence speed and diversity.", "configspace": "", "generation": 9, "fitness": 0.8110835068480963, "feedback": "The algorithm EHQEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.811 with standard deviation 0.072. And the mean value of best solutions found was 0.152 (0. is the best) with standard deviation 0.031.", "error": "", "parent_id": "55d547a1-52f0-4fad-ae59-fd55f5106466", "metadata": {"aucs": [0.9048406222032381, 0.7999679278521331, 0.7284419704889171], "final_y": [0.11181666506816501, 0.15773198215291584, 0.18684368492951553]}, "mutation_prompt": null}
{"id": "f300e475-20c8-4920-8d5a-f5335984ba77", "solution": "import numpy as np\n\nclass EHQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n        self.elite_fraction = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            new_population = []\n            elite_size = int(self.elite_fraction * self.population_size)\n            elites = population[np.argsort(fitness)[:elite_size]]\n            for _ in range(self.population_size - elite_size):\n                parent1, parent2 = self.select_parents(population, fitness)\n                offspring = self.enhanced_quantum_crossover(parent1, parent2, lb, ub)\n                offspring = self.efficient_adaptive_mutation(offspring, lb, ub, evaluations / self.budget)\n                new_population.append(offspring)\n            \n            # Probabilistic elitism mechanism\n            if np.random.rand() < 0.95:\n                new_population.extend(elites)\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n            \n            population, fitness = self.selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n        \n        return best_solution, best_fitness\n    \n    def select_parents(self, population, fitness):\n        tournament_size = 3\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent1_idx = tournament_indices[np.argmin(tournament_fitness)]\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent2_idx = tournament_indices[np.argmin(tournament_fitness)]\n        return population[parent1_idx], population[parent2_idx]\n    \n    def enhanced_quantum_crossover(self, parent1, parent2, lb, ub):\n        alpha_var = np.random.uniform(0.4, 0.6)\n        q1 = alpha_var * parent1 + (1 - alpha_var) * parent2\n        q2 = alpha_var * parent2 + (1 - alpha_var) * parent1\n        offspring = q1 if np.random.rand() < 0.5 else q2\n        offspring = np.clip(offspring, lb, ub)\n        return offspring\n    \n    def efficient_adaptive_mutation(self, individual, lb, ub, progress):\n        mutation_strength = 0.15 * (ub - lb) * np.random.random_sample(self.dim) * (1 - progress)\n        mutated = individual + np.random.normal(0, mutation_strength, self.dim)\n        return np.clip(mutated, lb, ub)\n\n    def selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        return combined_population[sorted_indices][:self.population_size], combined_fitness[sorted_indices][:self.population_size]", "name": "EHQEA", "description": "Introduce a probabilistic elitism mechanism and refine mutation for better exploration-exploitation balance.", "configspace": "", "generation": 9, "fitness": 0.8088213521042634, "feedback": "The algorithm EHQEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.809 with standard deviation 0.076. And the mean value of best solutions found was 0.153 (0. is the best) with standard deviation 0.032.", "error": "", "parent_id": "55d547a1-52f0-4fad-ae59-fd55f5106466", "metadata": {"aucs": [0.9062082898282016, 0.8000696476957654, 0.720186118788823], "final_y": [0.1120625769747512, 0.15787847579524772, 0.19054414543799358]}, "mutation_prompt": null}
{"id": "78a6119e-06ee-4204-9f77-7144e98594cf", "solution": "import numpy as np\n\nclass EHQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n        self.elite_fraction = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            new_population = []\n            elite_size = int(self.elite_fraction * self.population_size)\n            elites = population[np.argsort(fitness)[:elite_size]]\n            for _ in range(self.population_size - elite_size):\n                parent1, parent2 = self.select_parents(population, fitness)\n                offspring = self.enhanced_quantum_crossover(parent1, parent2, lb, ub)\n                offspring = self.efficient_adaptive_mutation(offspring, lb, ub, evaluations / self.budget)\n                new_population.append(offspring)\n            \n            # Include diversity-enhancing random individuals\n            diversity_size = max(1, int(0.05 * self.population_size))\n            random_individuals = np.random.uniform(lb, ub, (diversity_size, self.dim))\n            new_population.extend(random_individuals)\n            \n            new_population.extend(elites)\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n            \n            population, fitness = self.selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n        \n        return best_solution, best_fitness\n    \n    def select_parents(self, population, fitness):\n        tournament_size = 3\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent1_idx = tournament_indices[np.argmin(tournament_fitness)]\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent2_idx = tournament_indices[np.argmin(tournament_fitness)]\n        return population[parent1_idx], population[parent2_idx]\n    \n    def enhanced_quantum_crossover(self, parent1, parent2, lb, ub):\n        alpha_var = np.random.uniform(0.4, 0.6)\n        q1 = alpha_var * parent1 + (1 - alpha_var) * parent2\n        q2 = alpha_var * parent2 + (1 - alpha_var) * parent1\n        offspring = q1 if np.random.rand() < 0.5 else q2\n        offspring = np.clip(offspring, lb, ub)\n        return offspring\n    \n    def efficient_adaptive_mutation(self, individual, lb, ub, progress):\n        mutation_strength = 0.1 * (ub - lb) * np.random.random_sample(self.dim) * (1 - progress)\n        mutated = individual + np.random.normal(0, mutation_strength, self.dim)\n        return np.clip(mutated, lb, ub)\n\n    def selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        return combined_population[sorted_indices][:self.population_size], combined_fitness[sorted_indices][:self.population_size]", "name": "EHQEA", "description": "Incorporate a diversity-enhancing mechanism to prevent premature convergence and improve exploration.", "configspace": "", "generation": 9, "fitness": 0.8177889942734198, "feedback": "The algorithm EHQEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.818 with standard deviation 0.082. And the mean value of best solutions found was 0.151 (0. is the best) with standard deviation 0.033.", "error": "", "parent_id": "55d547a1-52f0-4fad-ae59-fd55f5106466", "metadata": {"aucs": [0.9197579788567619, 0.8142361550930286, 0.7193728488704689], "final_y": [0.10973348800321048, 0.15236042072812328, 0.1909425233213391]}, "mutation_prompt": null}
{"id": "bc5503c7-c61e-40c3-8737-cce051ddb02f", "solution": "import numpy as np\n\nclass EHQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n        self.elite_fraction = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            new_population = []\n            elite_size = int(self.elite_fraction * self.population_size)\n            elites = population[np.argsort(fitness)[:elite_size]]\n            for _ in range(self.population_size - elite_size):\n                parent1, parent2 = self.select_parents(population, fitness)\n                offspring = self.enhanced_quantum_crossover(parent1, parent2, lb, ub)\n                offspring = self.efficient_adaptive_mutation(offspring, lb, ub, evaluations / self.budget)\n                new_population.append(offspring)\n            \n            new_population.extend(elites)\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n            \n            population, fitness = self.selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n        \n        return best_solution, best_fitness\n    \n    def select_parents(self, population, fitness):\n        probabilities = (1 / (1 + fitness)) / np.sum(1 / (1 + fitness))\n        parent1_idx = np.random.choice(len(population), p=probabilities)\n        parent2_idx = np.random.choice(len(population), p=probabilities)\n        return population[parent1_idx], population[parent2_idx]\n    \n    def enhanced_quantum_crossover(self, parent1, parent2, lb, ub):\n        alpha_var = np.random.uniform(0.4, 0.6)\n        q1 = alpha_var * parent1 + (1 - alpha_var) * parent2\n        q2 = alpha_var * parent2 + (1 - alpha_var) * parent1\n        offspring = q1 if np.random.rand() < 0.5 else q2\n        offspring = np.clip(offspring, lb, ub)\n        return offspring\n    \n    def efficient_adaptive_mutation(self, individual, lb, ub, progress):\n        mutation_strength = 0.1 * (ub - lb) * np.random.random_sample(self.dim) * (1 - progress)\n        mutated = individual + np.random.normal(0, mutation_strength, self.dim)\n        return np.clip(mutated, lb, ub)\n\n    def selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        return combined_population[sorted_indices][:self.population_size], combined_fitness[sorted_indices][:self.population_size]", "name": "EHQEA", "description": "Enhance parent selection strategy by incorporating fitness-proportional selection for improved diversity.", "configspace": "", "generation": 9, "fitness": 0.8171365797248716, "feedback": "The algorithm EHQEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.817 with standard deviation 0.077. And the mean value of best solutions found was 0.150 (0. is the best) with standard deviation 0.033.", "error": "", "parent_id": "55d547a1-52f0-4fad-ae59-fd55f5106466", "metadata": {"aucs": [0.9071722095313597, 0.8250567505208404, 0.7191807791224145], "final_y": [0.10995805731791686, 0.14825430276647422, 0.19102918106357236]}, "mutation_prompt": null}
{"id": "98dd5d30-69fc-4f66-920f-38f202751dfb", "solution": "import numpy as np\n\nclass EHQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n        self.elite_fraction = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            new_population = []\n            elite_size = int(self.elite_fraction * self.population_size)\n            elites = population[np.argsort(fitness)[:elite_size]]\n            for _ in range(self.population_size - elite_size):\n                parent1, parent2 = self.select_parents(population, fitness)\n                offspring = self.enhanced_quantum_crossover(parent1, parent2, lb, ub)\n                offspring = self.efficient_adaptive_mutation(offspring, lb, ub, np.var(fitness))  # Changed\n                new_population.append(offspring)\n            \n            new_population.extend(elites)\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n            \n            population, fitness = self.selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n        \n        return best_solution, best_fitness\n    \n    def select_parents(self, population, fitness):\n        tournament_size = 3\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent1_idx = tournament_indices[np.argmin(tournament_fitness)]\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent2_idx = tournament_indices[np.argmin(tournament_fitness)]\n        return population[parent1_idx], population[parent2_idx]\n    \n    def enhanced_quantum_crossover(self, parent1, parent2, lb, ub):\n        alpha_var = np.random.uniform(0.4, 0.6)\n        q1 = alpha_var * parent1 + (1 - alpha_var) * parent2\n        q2 = alpha_var * parent2 + (1 - alpha_var) * parent1\n        offspring = q1 if np.random.rand() < 0.5 else q2\n        offspring = np.clip(offspring, lb, ub)\n        return offspring\n    \n    def efficient_adaptive_mutation(self, individual, lb, ub, fitness_variance):  # Changed\n        mutation_strength = 0.1 * (ub - lb) * np.random.random_sample(self.dim) * fitness_variance  # Changed\n        mutated = individual + np.random.normal(0, mutation_strength, self.dim)\n        return np.clip(mutated, lb, ub)\n\n    def selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        return combined_population[sorted_indices][:self.population_size], combined_fitness[sorted_indices][:self.population_size]", "name": "EHQEA", "description": "Introduce a dynamic mutation strategy based on fitness variance to improve local search capability.", "configspace": "", "generation": 9, "fitness": 0.778293653667645, "feedback": "The algorithm EHQEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.778 with standard deviation 0.035. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "55d547a1-52f0-4fad-ae59-fd55f5106466", "metadata": {"aucs": [0.804185380599195, 0.8022956799014529, 0.7283999005022872], "final_y": [0.1551456562516078, 0.15705386695202128, 0.18681158017687138]}, "mutation_prompt": null}
{"id": "1207ee30-d0de-4a94-98d0-3d2666332179", "solution": "import numpy as np\n\nclass EHQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n        self.elite_fraction = 0.1\n        self.diversity_factor = 0.2  # New parameter for diversity control\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            new_population = []\n            elite_size = int(self.elite_fraction * self.population_size)\n            elites = population[np.argsort(fitness)[:elite_size]]\n            for _ in range(self.population_size - elite_size):\n                parent1, parent2 = self.select_parents(population, fitness)\n                offspring = self.enhanced_quantum_crossover(parent1, parent2, lb, ub)\n                offspring = self.efficient_adaptive_mutation(offspring, lb, ub, evaluations / self.budget)\n                # Diversity-preserving mutation\n                offspring = self.preserve_diversity(offspring, population)\n                new_population.append(offspring)\n            \n            new_population.extend(elites)\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n            \n            population, fitness = self.selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n        \n        return best_solution, best_fitness\n    \n    def select_parents(self, population, fitness):\n        tournament_size = 3\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent1_idx = tournament_indices[np.argmin(tournament_fitness)]\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent2_idx = tournament_indices[np.argmin(tournament_fitness)]\n        return population[parent1_idx], population[parent2_idx]\n    \n    def enhanced_quantum_crossover(self, parent1, parent2, lb, ub):\n        alpha_var = np.random.uniform(0.4, 0.6)\n        q1 = alpha_var * parent1 + (1 - alpha_var) * parent2\n        q2 = alpha_var * parent2 + (1 - alpha_var) * parent1\n        offspring = q1 if np.random.rand() < 0.5 else q2\n        offspring = np.clip(offspring, lb, ub)\n        return offspring\n    \n    def efficient_adaptive_mutation(self, individual, lb, ub, progress):\n        mutation_strength = 0.1 * (ub - lb) * np.random.random_sample(self.dim) * (1 - progress)\n        mutated = individual + np.random.normal(0, mutation_strength, self.dim)\n        return np.clip(mutated, lb, ub)\n\n    def preserve_diversity(self, individual, population):\n        diversity = np.std(population, axis=0)\n        if np.any(diversity < self.diversity_factor):\n            perturbation = np.random.uniform(-self.diversity_factor, self.diversity_factor, self.dim)\n            individual += perturbation\n        return individual\n\n    def selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        return combined_population[sorted_indices][:self.population_size], combined_fitness[sorted_indices][:self.population_size]", "name": "EHQEA", "description": "Enhance the exploration phase by integrating a diversity-preserving mechanism to prevent premature convergence.", "configspace": "", "generation": 10, "fitness": 0.9107748400783908, "feedback": "The algorithm EHQEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.911 with standard deviation 0.005. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "55d547a1-52f0-4fad-ae59-fd55f5106466", "metadata": {"aucs": [0.9067037561049631, 0.9072319741835534, 0.9183887899466556], "final_y": [0.10985466233631025, 0.11632924773116515, 0.11220362440531018]}, "mutation_prompt": null}
{"id": "04e7ec54-f489-4d90-86cc-df46109c718b", "solution": "import numpy as np\n\nclass EHQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n        self.elite_fraction = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            new_population = []\n            elite_size = int(self.elite_fraction * self.population_size)\n            elites = population[np.argsort(fitness)[:elite_size]]\n            for _ in range(self.population_size - elite_size):\n                parent1, parent2 = self.select_parents(population, fitness)\n                offspring = self.enhanced_quantum_crossover(parent1, parent2, lb, ub)\n                offspring = self.efficient_adaptive_mutation(offspring, lb, ub, evaluations / self.budget)\n                new_population.append(offspring)\n            \n            new_population.extend(elites)\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n            \n            population, fitness = self.selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n        \n        return best_solution, best_fitness\n    \n    def select_parents(self, population, fitness):\n        tournament_size = 3\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent1_idx = tournament_indices[np.argmin(tournament_fitness)]\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent2_idx = tournament_indices[np.argmin(tournament_fitness)]\n        return population[parent1_idx], population[parent2_idx]\n    \n    def enhanced_quantum_crossover(self, parent1, parent2, lb, ub):\n        alpha_var = np.random.uniform(0.4, 0.6)\n        q1 = alpha_var * parent1 + (1 - alpha_var) * parent2\n        q2 = alpha_var * parent2 + (1 - alpha_var) * parent1\n        offspring = q1 if np.random.rand() < 0.5 else q2\n        offspring = np.clip(offspring, lb, ub)\n        return offspring\n    \n    def efficient_adaptive_mutation(self, individual, lb, ub, progress):\n        mutation_strength = 0.1 * (ub - lb) * np.random.random_sample(self.dim) * np.exp(-progress) # Changed line\n        mutated = individual + np.random.normal(0, mutation_strength, self.dim)\n        return np.clip(mutated, lb, ub)\n\n    def selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        return combined_population[sorted_indices][:self.population_size], combined_fitness[sorted_indices][:self.population_size]", "name": "EHQEA", "description": "Enhance mutation strategy by introducing a non-linear decay function based on progress to improve exploration.", "configspace": "", "generation": 10, "fitness": 0.9048163701539732, "feedback": "The algorithm EHQEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.905 with standard deviation 0.003. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "55d547a1-52f0-4fad-ae59-fd55f5106466", "metadata": {"aucs": [0.8999540462462097, 0.9077906880636412, 0.906704376152069], "final_y": [0.11747637267133493, 0.1162946360872229, 0.1125882506638406]}, "mutation_prompt": null}
{"id": "13a3e930-c687-46e5-a1e4-d817f8c36a80", "solution": "import numpy as np\n\nclass EHQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.alpha = 0.5\n        self.elite_fraction = 0.1\n        self.population_scaling_factor = 1.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.initial_population_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            new_population = []\n            elite_size = int(self.elite_fraction * population_size)\n            elites = population[np.argsort(fitness)[:elite_size]]\n            for _ in range(population_size - elite_size):\n                parent1, parent2 = self.select_parents(population, fitness)\n                offspring = self.enhanced_quantum_crossover(parent1, parent2, lb, ub)\n                offspring = self.efficient_adaptive_mutation(offspring, lb, ub, evaluations / self.budget)\n                new_population.append(offspring)\n            \n            new_population.extend(elites)\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += population_size\n\n            if self.needs_diversity_control(new_population):\n                population_size = int(population_size * self.population_scaling_factor)\n                new_population = self.reinitialize_population(lb, ub, population_size)\n\n            population, fitness = self.selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n\n        return best_solution, best_fitness\n\n    def select_parents(self, population, fitness):\n        tournament_size = 3\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent1_idx = tournament_indices[np.argmin(tournament_fitness)]\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent2_idx = tournament_indices[np.argmin(tournament_fitness)]\n        return population[parent1_idx], population[parent2_idx]\n\n    def enhanced_quantum_crossover(self, parent1, parent2, lb, ub):\n        alpha_var = np.random.uniform(0.4, 0.6)\n        q1 = alpha_var * parent1 + (1 - alpha_var) * parent2\n        q2 = alpha_var * parent2 + (1 - alpha_var) * parent1\n        offspring = q1 if np.random.rand() < 0.5 else q2\n        offspring = np.clip(offspring, lb, ub)\n        return offspring\n\n    def efficient_adaptive_mutation(self, individual, lb, ub, progress):\n        mutation_strength = 0.1 * (ub - lb) * np.random.random_sample(self.dim) * (1 - progress)\n        mutated = individual + np.random.normal(0, mutation_strength, self.dim)\n        return np.clip(mutated, lb, ub)\n\n    def selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        return combined_population[sorted_indices][:len(population)], combined_fitness[sorted_indices][:len(population)]\n\n    def needs_diversity_control(self, population):\n        diversity_threshold = 0.1\n        entropy = -np.sum(np.log(np.var(population, axis=0) + 1e-9))\n        return entropy < diversity_threshold\n\n    def reinitialize_population(self, lb, ub, size):\n        return np.random.uniform(lb, ub, (size, self.dim))", "name": "EHQEA", "description": "Integrate a self-adaptive population size strategy with entropy-based diversity control for better optimization performance.", "configspace": "", "generation": 10, "fitness": 0.8757715321790052, "feedback": "The algorithm EHQEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.876 with standard deviation 0.047. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.018.", "error": "", "parent_id": "55d547a1-52f0-4fad-ae59-fd55f5106466", "metadata": {"aucs": [0.8102037237632462, 0.902777801016623, 0.9143330717571464], "final_y": [0.15320292729466, 0.11637738782476348, 0.11256868265914033]}, "mutation_prompt": null}
{"id": "e496a3d0-646d-483a-9fe3-d1f5ce5d599b", "solution": "import numpy as np\n\nclass EHQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n        self.elite_fraction = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            new_population = []\n            elite_size = int(self.elite_fraction * self.population_size)\n            elites = population[np.argsort(fitness)[:elite_size]]\n            for _ in range(self.population_size - elite_size):\n                parent1, parent2 = self.select_parents(population, fitness)\n                offspring = self.enhanced_quantum_crossover(parent1, parent2, lb, ub)\n                offspring = self.efficient_adaptive_mutation(offspring, lb, ub, evaluations / self.budget)\n                new_population.append(offspring)\n            \n            new_population.extend(elites)\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n            \n            population, fitness = self.diversity_based_selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n        \n        return best_solution, best_fitness\n    \n    def select_parents(self, population, fitness):\n        tournament_size = 3\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent1_idx = tournament_indices[np.argmin(tournament_fitness)]\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent2_idx = tournament_indices[np.argmin(tournament_fitness)]\n        return population[parent1_idx], population[parent2_idx]\n    \n    def enhanced_quantum_crossover(self, parent1, parent2, lb, ub):\n        alpha_var = np.random.uniform(0.4, 0.6)\n        q1 = alpha_var * parent1 + (1 - alpha_var) * parent2\n        q2 = alpha_var * parent2 + (1 - alpha_var) * parent1\n        offspring = q1 if np.random.rand() < 0.5 else q2\n        offspring = np.clip(offspring, lb, ub)\n        return offspring\n    \n    def efficient_adaptive_mutation(self, individual, lb, ub, progress):\n        mutation_strength = 0.1 * (ub - lb) * np.random.random_sample(self.dim) * (1 - progress)\n        mutated = individual + np.random.normal(0, mutation_strength, self.dim)\n        return np.clip(mutated, lb, ub)\n\n    def diversity_based_selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        selected_population = combined_population[sorted_indices][:self.population_size]\n        selected_fitness = combined_fitness[sorted_indices][:self.population_size]\n        if np.std(selected_fitness) < 0.01:\n            diversity_indices = np.argsort(-np.std(selected_population, axis=0))[:self.population_size]\n            selected_population = selected_population[diversity_indices]\n            selected_fitness = selected_fitness[diversity_indices]\n        return selected_population, selected_fitness", "name": "EHQEA", "description": "Introduce a diversity-based selection mechanism to maintain solution diversity and avoid premature convergence.", "configspace": "", "generation": 10, "fitness": 0.9104630827603432, "feedback": "The algorithm EHQEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.910 with standard deviation 0.008. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "55d547a1-52f0-4fad-ae59-fd55f5106466", "metadata": {"aucs": [0.9093702544683226, 0.9007213460892406, 0.9212976477234667], "final_y": [0.11688230954356638, 0.1162565543159303, 0.11251950008122102]}, "mutation_prompt": null}
{"id": "8f0b783a-9929-4ab2-a9d1-09b1e66f7176", "solution": "import numpy as np\n\nclass EHQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n        self.elite_fraction = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            new_population = []\n            elite_size = int(self.elite_fraction * self.population_size)\n            elites = population[np.argsort(fitness)[:elite_size]]\n            for _ in range(self.population_size - elite_size):\n                parent1, parent2 = self.adaptive_select_parents(population, fitness, evaluations / self.budget)\n                offspring = self.dynamic_quantum_crossover(parent1, parent2, lb, ub, evaluations / self.budget)\n                offspring = self.efficient_adaptive_mutation(offspring, lb, ub, evaluations / self.budget)\n                new_population.append(offspring)\n            \n            new_population.extend(elites)\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n            \n            population, fitness = self.selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n        \n        return best_solution, best_fitness\n    \n    def adaptive_select_parents(self, population, fitness, progress):\n        tournament_size = max(2, int((1 - progress) * 5))\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent1_idx = tournament_indices[np.argmin(tournament_fitness)]\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent2_idx = tournament_indices[np.argmin(tournament_fitness)]\n        return population[parent1_idx], population[parent2_idx]\n    \n    def dynamic_quantum_crossover(self, parent1, parent2, lb, ub, progress):\n        alpha_var = np.random.uniform(0.4 + 0.2 * progress, 0.6 - 0.2 * progress)\n        q1 = alpha_var * parent1 + (1 - alpha_var) * parent2\n        q2 = alpha_var * parent2 + (1 - alpha_var) * parent1\n        offspring = q1 if np.random.rand() < 0.5 else q2\n        offspring = np.clip(offspring, lb, ub)\n        return offspring\n    \n    def efficient_adaptive_mutation(self, individual, lb, ub, progress):\n        mutation_strength = 0.1 * (ub - lb) * np.random.random_sample(self.dim) * (1 - progress)\n        mutated = individual + np.random.normal(0, mutation_strength, self.dim)\n        return np.clip(mutated, lb, ub)\n\n    def selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        return combined_population[sorted_indices][:self.population_size], combined_fitness[sorted_indices][:self.population_size]", "name": "EHQEA", "description": "Introduce adaptive parent selection and dynamic crossover rates to enhance exploration-exploitation trade-off.", "configspace": "", "generation": 10, "fitness": 0.909609558888674, "feedback": "The algorithm EHQEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.910 with standard deviation 0.013. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "55d547a1-52f0-4fad-ae59-fd55f5106466", "metadata": {"aucs": [0.8946604401541159, 0.9081597843391114, 0.9260084521727948], "final_y": [0.11996678865588917, 0.11291123610670806, 0.11016503339082162]}, "mutation_prompt": null}
{"id": "32690c0f-1d55-48bd-becb-3b7665e85ea5", "solution": "import numpy as np\n\nclass EHQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n        self.elite_fraction = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            new_population = []\n            elite_size = int(self.elite_fraction * self.population_size)\n            elites = population[np.argsort(fitness)[:elite_size]]\n            for _ in range(self.population_size - elite_size):\n                parent1, parent2 = self.select_parents(population, fitness)\n                offspring = self.enhanced_quantum_crossover(parent1, parent2, lb, ub)\n                offspring = self.efficient_adaptive_mutation(offspring, lb, ub, evaluations / self.budget)\n                new_population.append(offspring)\n            \n            niche_preserved_population = self.niche_preservation(new_population, func)\n            new_population = np.array(niche_preserved_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n            \n            population, fitness = self.selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n        \n        return best_solution, best_fitness\n    \n    def select_parents(self, population, fitness):\n        tournament_size = 3\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent1_idx = tournament_indices[np.argmin(tournament_fitness)]\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent2_idx = tournament_indices[np.argmin(tournament_fitness)]\n        return population[parent1_idx], population[parent2_idx]\n    \n    def enhanced_quantum_crossover(self, parent1, parent2, lb, ub):\n        alpha_var = np.random.uniform(0.4, 0.6)\n        q1 = alpha_var * parent1 + (1 - alpha_var) * parent2\n        q2 = alpha_var * parent2 + (1 - alpha_var) * parent1\n        offspring = q1 if np.random.rand() < 0.5 else q2\n        offspring = np.clip(offspring, lb, ub)\n        return offspring\n    \n    def efficient_adaptive_mutation(self, individual, lb, ub, progress):\n        mutation_strength = 0.1 * (ub - lb) * np.random.random_sample(self.dim) * (1 - progress)\n        mutated = individual + np.random.normal(0, mutation_strength, self.dim)\n        return np.clip(mutated, lb, ub)\n\n    def selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        return combined_population[sorted_indices][:self.population_size], combined_fitness[sorted_indices][:self.population_size]\n\n    def niche_preservation(self, population, func):\n        # Assuming a dummy implementation for niche preservation\n        # This could be a placeholder for more sophisticated mechanisms\n        return population", "name": "EHQEA", "description": "Introduce a niche preservation mechanism to maintain diversity in the population.", "configspace": "", "generation": 11, "fitness": 0.9046323573719794, "feedback": "The algorithm EHQEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.905 with standard deviation 0.004. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "55d547a1-52f0-4fad-ae59-fd55f5106466", "metadata": {"aucs": [0.9021267180937328, 0.9010959983625385, 0.9106743556596671], "final_y": [0.11712006093034, 0.11648167001787879, 0.11051870749268189]}, "mutation_prompt": null}
{"id": "5c8de2cd-48be-4538-82de-d71588f610b8", "solution": "import numpy as np\n\nclass EHQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n        self.elite_fraction = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            new_population = []\n            elite_size = int(self.elite_fraction * self.population_size)\n            elite_indices = np.random.choice(np.arange(self.population_size), size=elite_size, replace=False)  # Modified line\n            elites = population[elite_indices]\n            for _ in range(self.population_size - elite_size):\n                parent1, parent2 = self.select_parents(population, fitness)\n                offspring = self.enhanced_quantum_crossover(parent1, parent2, lb, ub)\n                offspring = self.efficient_adaptive_mutation(offspring, lb, ub, evaluations / self.budget)\n                new_population.append(offspring)\n            \n            new_population.extend(elites)\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n            \n            population, fitness = self.selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n        \n        return best_solution, best_fitness\n    \n    def select_parents(self, population, fitness):\n        tournament_size = 3\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent1_idx = tournament_indices[np.argmin(tournament_fitness)]\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent2_idx = tournament_indices[np.argmin(tournament_fitness)]\n        return population[parent1_idx], population[parent2_idx]\n    \n    def enhanced_quantum_crossover(self, parent1, parent2, lb, ub):\n        alpha_var = np.random.uniform(0.4, 0.6)\n        q1 = alpha_var * parent1 + (1 - alpha_var) * parent2\n        q2 = alpha_var * parent2 + (1 - alpha_var) * parent1\n        offspring = q1 if np.random.rand() < 0.5 else q2\n        offspring = np.clip(offspring, lb, ub)\n        return offspring\n    \n    def efficient_adaptive_mutation(self, individual, lb, ub, progress):\n        mutation_strength = 0.1 * (ub - lb) * np.random.random_sample(self.dim) * (1 - progress)\n        mutated = individual + np.random.normal(0, mutation_strength, self.dim)\n        return np.clip(mutated, lb, ub)\n\n    def selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        return combined_population[sorted_indices][:self.population_size], combined_fitness[sorted_indices][:self.population_size]", "name": "EHQEA", "description": "Use a diverse elite selection strategy to improve exploration.", "configspace": "", "generation": 11, "fitness": 0.915771957777066, "feedback": "The algorithm EHQEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.916 with standard deviation 0.007. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "55d547a1-52f0-4fad-ae59-fd55f5106466", "metadata": {"aucs": [0.9249791589034055, 0.9104432211172087, 0.911893493310584], "final_y": [0.10983682970545483, 0.11635251134396185, 0.1124367313904947]}, "mutation_prompt": null}
{"id": "2a882f24-9f35-40e5-bbf0-37d8143c0cd3", "solution": "import numpy as np\n\nclass EHQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n        self.elite_fraction = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            new_population = []\n            # Adjust elite fraction dynamically\n            dynamic_elite_fraction = self.adaptive_elite_fraction(evaluations / self.budget)\n            elite_size = int(dynamic_elite_fraction * self.population_size)\n            elites = population[np.argsort(fitness)[:elite_size]]\n            for _ in range(self.population_size - elite_size):\n                parent1, parent2 = self.select_parents(population, fitness)\n                offspring = self.enhanced_quantum_crossover(parent1, parent2, lb, ub)\n                offspring = self.efficient_adaptive_mutation(offspring, lb, ub, evaluations / self.budget)\n                new_population.append(offspring)\n            \n            new_population.extend(elites)\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n            \n            population, fitness = self.selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n        \n        return best_solution, best_fitness\n    \n    def select_parents(self, population, fitness):\n        tournament_size = 3\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent1_idx = tournament_indices[np.argmin(tournament_fitness)]\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent2_idx = tournament_indices[np.argmin(tournament_fitness)]\n        return population[parent1_idx], population[parent2_idx]\n    \n    def enhanced_quantum_crossover(self, parent1, parent2, lb, ub):\n        alpha_var = np.random.uniform(0.4, 0.6)\n        q1 = alpha_var * parent1 + (1 - alpha_var) * parent2\n        q2 = alpha_var * parent2 + (1 - alpha_var) * parent1\n        offspring = q1 if np.random.rand() < 0.5 else q2\n        offspring = np.clip(offspring, lb, ub)\n        return offspring\n    \n    def efficient_adaptive_mutation(self, individual, lb, ub, progress):\n        mutation_strength = 0.1 * (ub - lb) * np.random.random_sample(self.dim) * (1 - progress)\n        mutated = individual + np.random.normal(0, mutation_strength, self.dim)\n        return np.clip(mutated, lb, ub)\n\n    def selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        return combined_population[sorted_indices][:self.population_size], combined_fitness[sorted_indices][:self.population_size]\n\n    def adaptive_elite_fraction(self, progress):\n        return 0.1 + 0.2 * (1 - progress)  # Increase elite fraction as progress decreases", "name": "EHQEA", "description": "Introduce a novel adaptive elitism mechanism to dynamically adjust the elite fraction based on convergence.", "configspace": "", "generation": 11, "fitness": 0.892704449797018, "feedback": "The algorithm EHQEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.893 with standard deviation 0.008. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "55d547a1-52f0-4fad-ae59-fd55f5106466", "metadata": {"aucs": [0.9023048114210916, 0.8926787475631573, 0.8831297904068053], "final_y": [0.11700101379570249, 0.11797983597776951, 0.11741151392231486]}, "mutation_prompt": null}
{"id": "16f1dcc6-ed69-4476-94cb-60dbd47a5cc6", "solution": "import numpy as np\n\nclass EHQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n        self.elite_fraction = 0.15  # Changed from 0.1 to 0.15 to enhance exploitation\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            new_population = []\n            elite_size = int(self.elite_fraction * self.population_size)\n            elites = population[np.argsort(fitness)[:elite_size]]\n            for _ in range(self.population_size - elite_size):\n                parent1, parent2 = self.select_parents(population, fitness)\n                offspring = self.enhanced_quantum_crossover(parent1, parent2, lb, ub)\n                offspring = self.efficient_adaptive_mutation(offspring, lb, ub, evaluations / self.budget)\n                new_population.append(offspring)\n            \n            new_population.extend(elites)\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n            \n            population, fitness = self.selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n        \n        return best_solution, best_fitness\n    \n    def select_parents(self, population, fitness):\n        tournament_size = 3\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent1_idx = tournament_indices[np.argmin(tournament_fitness)]\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent2_idx = tournament_indices[np.argmin(tournament_fitness)]\n        return population[parent1_idx], population[parent2_idx]\n    \n    def enhanced_quantum_crossover(self, parent1, parent2, lb, ub):\n        alpha_var = np.random.uniform(0.4, 0.6)\n        q1 = alpha_var * parent1 + (1 - alpha_var) * parent2\n        q2 = alpha_var * parent2 + (1 - alpha_var) * parent1\n        offspring = q1 if np.random.rand() < 0.5 else q2\n        offspring = np.clip(offspring, lb, ub)\n        return offspring\n    \n    def efficient_adaptive_mutation(self, individual, lb, ub, progress):\n        mutation_strength = 0.1 * (ub - lb) * np.random.random_sample(self.dim) * (1 - progress)\n        mutated = individual + np.random.normal(0, mutation_strength, self.dim)\n        return np.clip(mutated, lb, ub)\n\n    def selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        return combined_population[sorted_indices][:self.population_size], combined_fitness[sorted_indices][:self.population_size]", "name": "EHQEA", "description": "Refine the elite fraction parameter to improve exploitation without compromising exploration.", "configspace": "", "generation": 11, "fitness": 0.9147926678923538, "feedback": "The algorithm EHQEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.915 with standard deviation 0.011. And the mean value of best solutions found was 0.112 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "55d547a1-52f0-4fad-ae59-fd55f5106466", "metadata": {"aucs": [0.9213282553890698, 0.8992572381114617, 0.9237925101765303], "final_y": [0.10974110871643605, 0.11650633026826684, 0.11032685177399881]}, "mutation_prompt": null}
{"id": "2750bfdc-b81b-4f23-b32b-7083aedbd1cb", "solution": "import numpy as np\n\nclass EHQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n        self.elite_fraction = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            new_population = []\n            # Adjust elite fraction dynamically based on progress\n            self.elite_fraction = 0.1 + 0.1 * (evaluations / self.budget)\n            elite_size = int(self.elite_fraction * self.population_size)\n            elites = population[np.argsort(fitness)[:elite_size]]\n            for _ in range(self.population_size - elite_size):\n                parent1, parent2 = self.select_parents(population, fitness)\n                offspring = self.enhanced_quantum_crossover(parent1, parent2, lb, ub)\n                offspring = self.efficient_adaptive_mutation(offspring, lb, ub, evaluations / self.budget)\n                new_population.append(offspring)\n            \n            new_population.extend(elites)\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n            \n            population, fitness = self.selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n        \n        return best_solution, best_fitness\n    \n    def select_parents(self, population, fitness):\n        tournament_size = 3\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent1_idx = tournament_indices[np.argmin(tournament_fitness)]\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent2_idx = tournament_indices[np.argmin(tournament_fitness)]\n        return population[parent1_idx], population[parent2_idx]\n    \n    def enhanced_quantum_crossover(self, parent1, parent2, lb, ub):\n        alpha_var = np.random.uniform(0.4, 0.6)\n        q1 = alpha_var * parent1 + (1 - alpha_var) * parent2\n        q2 = alpha_var * parent2 + (1 - alpha_var) * parent1\n        offspring = q1 if np.random.rand() < 0.5 else q2\n        offspring = np.clip(offspring, lb, ub)\n        return offspring\n    \n    def efficient_adaptive_mutation(self, individual, lb, ub, progress):\n        mutation_strength = 0.1 * (ub - lb) * np.random.random_sample(self.dim) * (1 - progress)\n        mutated = individual + np.random.normal(0, mutation_strength, self.dim)\n        return np.clip(mutated, lb, ub)\n\n    def selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        return combined_population[sorted_indices][:self.population_size], combined_fitness[sorted_indices][:self.population_size]", "name": "EHQEA", "description": "Introduce a dynamic elite fraction adjustment mechanism to improve convergence rate.", "configspace": "", "generation": 11, "fitness": 0.9030205245910125, "feedback": "The algorithm EHQEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.903 with standard deviation 0.004. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "55d547a1-52f0-4fad-ae59-fd55f5106466", "metadata": {"aucs": [0.898886566706639, 0.9020204836368323, 0.9081545234295659], "final_y": [0.10991247784609315, 0.1163933647126516, 0.11164098082101637]}, "mutation_prompt": null}
{"id": "cac38dd1-02e5-4b05-af68-9b4edb1a409a", "solution": "import numpy as np\n\nclass EHQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n        self.elite_fraction = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            new_population = []\n            elite_size = int(self.elite_fraction * self.population_size)\n            elites = population[np.argsort(fitness)[:elite_size]]\n            for _ in range(self.population_size - elite_size):\n                parent1, parent2 = self.select_parents(population, fitness)\n                offspring = self.enhanced_quantum_crossover(parent1, parent2, lb, ub)\n                offspring = self.efficient_adaptive_mutation(offspring, lb, ub, evaluations / self.budget)\n                new_population.append(offspring)\n            \n            new_population.extend(elites)\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n            \n            population, fitness = self.selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n        \n        return best_solution, best_fitness\n    \n    def select_parents(self, population, fitness):\n        scaled_fitness = self.scale_fitness(fitness)\n        tournament_size = 3\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = scaled_fitness[tournament_indices]\n        parent1_idx = tournament_indices[np.argmin(tournament_fitness)]\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = scaled_fitness[tournament_indices]\n        parent2_idx = tournament_indices[np.argmin(tournament_fitness)]\n        return population[parent1_idx], population[parent2_idx]\n    \n    def scale_fitness(self, fitness):\n        min_fit, max_fit = np.min(fitness), np.max(fitness)\n        return (fitness - min_fit) / (max_fit - min_fit + 1e-9)\n    \n    def enhanced_quantum_crossover(self, parent1, parent2, lb, ub):\n        alpha_var = np.random.uniform(0.4, 0.6)\n        q1 = alpha_var * parent1 + (1 - alpha_var) * parent2\n        q2 = alpha_var * parent2 + (1 - alpha_var) * parent1\n        offspring = q1 if np.random.rand() < 0.5 else q2\n        offspring = np.clip(offspring, lb, ub)\n        return offspring\n    \n    def efficient_adaptive_mutation(self, individual, lb, ub, progress):\n        mutation_strength = 0.1 * (ub - lb) * np.random.random_sample(self.dim) * (1 - progress)\n        mutated = individual + np.random.normal(0, mutation_strength, self.dim)\n        return np.clip(mutated, lb, ub)\n\n    def selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        return combined_population[sorted_indices][:self.population_size], combined_fitness[sorted_indices][:self.population_size]", "name": "EHQEA", "description": "Integrate a fitness scaling mechanism for more diverse parent selection, enhancing exploration.", "configspace": "", "generation": 12, "fitness": 0.9113220366861512, "feedback": "The algorithm EHQEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.911 with standard deviation 0.004. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "55d547a1-52f0-4fad-ae59-fd55f5106466", "metadata": {"aucs": [0.9076264250293155, 0.9095444937923015, 0.9167951912368365], "final_y": [0.11016324248052423, 0.11631988945624228, 0.1114704920296875]}, "mutation_prompt": null}
{"id": "8572ce05-0679-4914-831c-d1c34eb5f235", "solution": "import numpy as np\n\nclass EHQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n        self.elite_fraction = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            new_population = []\n            elite_size = int(self.elite_fraction * self.population_size)\n            elites = population[np.argsort(fitness)[:elite_size]]\n            for _ in range(self.population_size - elite_size):\n                parent1, parent2 = self.select_parents(population, fitness)\n                offspring = self.enhanced_quantum_crossover(parent1, parent2, lb, ub)\n                offspring = self.efficient_adaptive_mutation(offspring, lb, ub, evaluations / self.budget)\n                new_population.append(offspring)\n            \n            new_population.extend(elites)\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n            \n            population, fitness = self.reversible_selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n        \n        return best_solution, best_fitness\n    \n    def select_parents(self, population, fitness):\n        tournament_size = 3\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent1_idx = tournament_indices[np.argmin(tournament_fitness)]\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent2_idx = tournament_indices[np.argmin(tournament_fitness)]\n        return population[parent1_idx], population[parent2_idx]\n    \n    def enhanced_quantum_crossover(self, parent1, parent2, lb, ub):\n        alpha_var = np.random.uniform(0.4, 0.6)\n        q1 = alpha_var * parent1 + (1 - alpha_var) * parent2\n        q2 = alpha_var * parent2 + (1 - alpha_var) * parent1\n        offspring = q1 if np.random.rand() < 0.5 else q2\n        offspring = np.clip(offspring, lb, ub)\n        return offspring\n    \n    def efficient_adaptive_mutation(self, individual, lb, ub, progress):\n        mutation_strength = 0.1 * (ub - lb) * np.random.random_sample(self.dim) * (1 - progress)\n        mutated = individual + np.random.normal(0, mutation_strength, self.dim)\n        return np.clip(mutated, lb, ub)\n\n    def reversible_selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        selected_indices = sorted_indices[:self.population_size]\n        return combined_population[selected_indices], combined_fitness[selected_indices]", "name": "EHQEA", "description": "Introduce a reversible selection strategy to enhance diversity retention and prevent premature convergence.", "configspace": "", "generation": 12, "fitness": 0.9073948235433024, "feedback": "The algorithm EHQEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.907 with standard deviation 0.003. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "55d547a1-52f0-4fad-ae59-fd55f5106466", "metadata": {"aucs": [0.9035063121654628, 0.9078328365896237, 0.9108453218748205], "final_y": [0.1153487219713275, 0.11634812376309489, 0.11255428968598691]}, "mutation_prompt": null}
{"id": "3775c7b3-002c-45d7-8446-105b96ac63f2", "solution": "import numpy as np\n\nclass EHQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n        self.elite_fraction = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            new_population = []\n            elite_size = int(self.elite_fraction * self.population_size)\n            elites = population[np.argsort(fitness)[:elite_size]]\n            for _ in range(self.population_size - elite_size):\n                parent1, parent2 = self.select_parents(population, fitness)\n                offspring = self.enhanced_quantum_crossover(parent1, parent2, lb, ub)\n                offspring = self.efficient_adaptive_mutation(offspring, lb, ub, evaluations / self.budget)\n                new_population.append(offspring)\n            \n            if np.random.rand() < 0.05:  # Limited random reinitialization\n                new_population[np.random.randint(0, len(new_population))] = np.random.uniform(lb, ub, self.dim)\n            \n            new_population.extend(elites)\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n            \n            population, fitness = self.selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n        \n        return best_solution, best_fitness\n    \n    def select_parents(self, population, fitness):\n        tournament_size = 3\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent1_idx = tournament_indices[np.argmin(tournament_fitness)]\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent2_idx = tournament_indices[np.argmin(tournament_fitness)]\n        return population[parent1_idx], population[parent2_idx]\n    \n    def enhanced_quantum_crossover(self, parent1, parent2, lb, ub):\n        alpha_var = np.random.uniform(0.4, 0.6)\n        q1 = alpha_var * parent1 + (1 - alpha_var) * parent2\n        q2 = alpha_var * parent2 + (1 - alpha_var) * parent1\n        offspring = q1 if np.random.rand() < 0.5 else q2\n        offspring = np.clip(offspring, lb, ub)\n        return offspring\n    \n    def efficient_adaptive_mutation(self, individual, lb, ub, progress):\n        mutation_strength = 0.1 * (ub - lb) * np.random.random_sample(self.dim) * (1 - progress)\n        mutated = individual + np.random.normal(0, mutation_strength, self.dim)\n        return np.clip(mutated, lb, ub)\n\n    def selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        return combined_population[sorted_indices][:self.population_size], combined_fitness[sorted_indices][:self.population_size]", "name": "EHQEA", "description": "Introduce diversity preservation through a limited random reinitialization mechanism to improve exploration.", "configspace": "", "generation": 12, "fitness": 0.9156811267047505, "feedback": "The algorithm EHQEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.916 with standard deviation 0.015. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "55d547a1-52f0-4fad-ae59-fd55f5106466", "metadata": {"aucs": [0.9309971046028215, 0.8957729890871211, 0.9202732864243093], "final_y": [0.10968367076422025, 0.11628643216831969, 0.11154293047943908]}, "mutation_prompt": null}
{"id": "a7f5b46f-4300-4b7d-bef1-ec49d9da8235", "solution": "import numpy as np\n\nclass EHQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n        self.elite_fraction = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n        best_fitness_hist = [best_fitness]\n\n        while evaluations < self.budget:\n            new_population = []\n            elite_size = int(self.elite_fraction * self.population_size)\n            elites = population[np.argsort(fitness)[:elite_size]]\n            for _ in range(self.population_size - elite_size):\n                parent1, parent2 = self.select_parents(population, fitness)\n                offspring = self.enhanced_quantum_crossover(parent1, parent2, lb, ub)\n                offspring = self.efficient_adaptive_mutation(offspring, lb, ub, evaluations / self.budget, best_fitness_hist[-1] - best_fitness)\n                new_population.append(offspring)\n            \n            new_population.extend(elites)\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n            \n            population, fitness = self.selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n            best_fitness_hist.append(best_fitness)\n        \n        return best_solution, best_fitness\n    \n    def select_parents(self, population, fitness):\n        tournament_size = 3\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent1_idx = tournament_indices[np.argmin(tournament_fitness)]\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent2_idx = tournament_indices[np.argmin(tournament_fitness)]\n        return population[parent1_idx], population[parent2_idx]\n    \n    def enhanced_quantum_crossover(self, parent1, parent2, lb, ub):\n        alpha_var = np.random.uniform(0.4, 0.6)\n        q1 = alpha_var * parent1 + (1 - alpha_var) * parent2\n        q2 = alpha_var * parent2 + (1 - alpha_var) * parent1\n        offspring = q1 if np.random.rand() < 0.5 else q2\n        offspring = np.clip(offspring, lb, ub)\n        return offspring\n    \n    def efficient_adaptive_mutation(self, individual, lb, ub, progress, improvement):\n        mutation_strength = 0.1 * (ub - lb) * np.random.random_sample(self.dim) * (1 - progress) * (1 + improvement)\n        mutated = individual + np.random.normal(0, mutation_strength, self.dim)\n        return np.clip(mutated, lb, ub)\n\n    def selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        return combined_population[sorted_indices][:self.population_size], combined_fitness[sorted_indices][:self.population_size]", "name": "EHQEA", "description": "Adjusted mutation scaling to be more dynamic based on the current best fitness improvement rate.", "configspace": "", "generation": 12, "fitness": 0.910468289927702, "feedback": "The algorithm EHQEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.910 with standard deviation 0.004. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "55d547a1-52f0-4fad-ae59-fd55f5106466", "metadata": {"aucs": [0.9063359293837826, 0.9094765537319727, 0.9155923866673508], "final_y": [0.11694084815863492, 0.11637919625181403, 0.11265486502659383]}, "mutation_prompt": null}
{"id": "e2f3011b-47e7-40d8-b8f6-209827e6e6e0", "solution": "import numpy as np\n\nclass EHQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n        self.elite_fraction = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            new_population = []\n            elite_size = int(self.elite_fraction * self.population_size)\n            elites = population[np.argsort(fitness)[:elite_size]]\n            for _ in range(self.population_size - elite_size):\n                parent1, parent2 = self.select_parents(population, fitness)\n                offspring = self.enhanced_quantum_crossover(parent1, parent2, lb, ub)\n                offspring = self.diverse_adaptive_mutation(offspring, lb, ub, evaluations / self.budget)\n                new_population.append(offspring)\n            \n            new_population.extend(elites)\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n            \n            population, fitness = self.selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n        \n        return best_solution, best_fitness\n    \n    def select_parents(self, population, fitness):\n        tournament_size = 3\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent1_idx = tournament_indices[np.argmin(tournament_fitness)]\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent2_idx = tournament_indices[np.argmin(tournament_fitness)]\n        return population[parent1_idx], population[parent2_idx]\n    \n    def enhanced_quantum_crossover(self, parent1, parent2, lb, ub):\n        alpha_var = np.random.uniform(0.4, 0.6)\n        q1 = alpha_var * parent1 + (1 - alpha_var) * parent2\n        q2 = alpha_var * parent2 + (1 - alpha_var) * parent1\n        offspring = q1 if np.random.rand() < 0.5 else q2\n        offspring = np.clip(offspring, lb, ub)\n        return offspring\n    \n    def diverse_adaptive_mutation(self, individual, lb, ub, progress):\n        mutation_strength = 0.1 * (ub - lb) * np.random.random_sample(self.dim) * (1 - progress)\n        if np.random.random() < 0.5:\n            mutated = individual + np.random.normal(0, mutation_strength, self.dim)\n        else:\n            mutated = individual + np.random.uniform(-mutation_strength, mutation_strength, self.dim)\n        return np.clip(mutated, lb, ub)\n\n    def selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        return combined_population[sorted_indices][:self.population_size], combined_fitness[sorted_indices][:self.population_size]", "name": "EHQEA", "description": "Integrates diverse mutation strategies and adaptive learning from population dynamics to optimize exploration-exploitation balance.", "configspace": "", "generation": 12, "fitness": 0.9202277447781269, "feedback": "The algorithm EHQEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.920 with standard deviation 0.007. And the mean value of best solutions found was 0.112 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "55d547a1-52f0-4fad-ae59-fd55f5106466", "metadata": {"aucs": [0.9265778442392417, 0.9098886166146702, 0.9242167734804686], "final_y": [0.10980675468414947, 0.11634541958076716, 0.11021832265310216]}, "mutation_prompt": null}
{"id": "5f3715f7-bce7-4125-b3ee-c899381fd861", "solution": "import numpy as np\n\nclass EHQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n        self.elite_fraction = 0.1\n        self.memory = []\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            new_population = []\n            elite_size = int(self.elite_fraction * self.population_size)\n            elites = population[np.argsort(fitness)[:elite_size]]\n            for _ in range(self.population_size - elite_size):\n                parent1, parent2 = self.select_parents(population, fitness)\n                offspring = self.enhanced_quantum_crossover(parent1, parent2, lb, ub)\n                offspring = self.diverse_adaptive_mutation(offspring, lb, ub, evaluations / self.budget)\n                new_population.append(offspring)\n            \n            new_population.extend(elites)\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n            \n            # Maintain a memory of the best solutions encountered\n            self.memory.append((best_solution, best_fitness))\n            if len(self.memory) > 5:  # Limit memory size\n                self.memory.pop(0)\n\n            population, fitness = self.selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n        \n        return best_solution, best_fitness\n    \n    def select_parents(self, population, fitness):\n        # Changed tournament size to 4 for increased selection pressure\n        tournament_size = 4\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent1_idx = tournament_indices[np.argmin(tournament_fitness)]\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent2_idx = tournament_indices[np.argmin(tournament_fitness)]\n        return population[parent1_idx], population[parent2_idx]\n    \n    def enhanced_quantum_crossover(self, parent1, parent2, lb, ub):\n        alpha_var = np.random.uniform(0.4, 0.6)\n        q1 = alpha_var * parent1 + (1 - alpha_var) * parent2\n        q2 = alpha_var * parent2 + (1 - alpha_var) * parent1\n        offspring = q1 if np.random.rand() < 0.5 else q2\n        offspring = np.clip(offspring, lb, ub)\n        return offspring\n    \n    # Enhanced mutation with diversity preservation\n    def diverse_adaptive_mutation(self, individual, lb, ub, progress):\n        mutation_strength = 0.1 * (ub - lb) * np.random.random_sample(self.dim) * (1 - progress)\n        diversity_influence = np.mean([np.linalg.norm(individual - mem[0]) for mem in self.memory]) / self.dim\n        mutation_strength *= (1 + diversity_influence)\n        mutated = individual + np.random.uniform(-mutation_strength, mutation_strength, self.dim)\n        return np.clip(mutated, lb, ub)\n\n    def selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        return combined_population[sorted_indices][:self.population_size], combined_fitness[sorted_indices][:self.population_size]", "name": "EHQEA", "description": "Enhances mutation strategy with a novel diversity preservation mechanism and includes memory-based learning to improve solution quality across generations.", "configspace": "", "generation": 13, "fitness": -Infinity, "feedback": "An exception occurred: OverflowError('Range exceeds valid bounds').", "error": "OverflowError('Range exceeds valid bounds')", "parent_id": "e2f3011b-47e7-40d8-b8f6-209827e6e6e0", "metadata": {}, "mutation_prompt": null}
{"id": "d9d2e7be-e0d8-41e3-b2cc-672102769a23", "solution": "import numpy as np\n\nclass EHQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n        self.elite_fraction = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            new_population = []\n            elite_size = int(self.elite_fraction * self.population_size)\n            elites = population[np.argsort(fitness)[:elite_size]]\n            for _ in range(self.population_size - elite_size):\n                parent1, parent2 = self.select_parents(population, fitness)\n                offspring = self.enhanced_quantum_crossover(parent1, parent2, lb, ub)\n                change_rate = (best_fitness - fitness[best_idx]) / self.budget\n                offspring = self.diverse_adaptive_mutation(offspring, lb, ub, evaluations / self.budget, change_rate)\n                new_population.append(offspring)\n\n            new_population.extend(elites)\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n\n            population, fitness = self.selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n\n        return best_solution, best_fitness\n\n    def select_parents(self, population, fitness):\n        tournament_size = 3\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent1_idx = tournament_indices[np.argmin(tournament_fitness)]\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent2_idx = tournament_indices[np.argmin(tournament_fitness)]\n        return population[parent1_idx], population[parent2_idx]\n\n    def enhanced_quantum_crossover(self, parent1, parent2, lb, ub):\n        alpha_var = np.random.uniform(0.4, 0.6)\n        q1 = alpha_var * parent1 + (1 - alpha_var) * parent2\n        q2 = alpha_var * parent2 + (1 - alpha_var) * parent1\n        offspring = q1 if np.random.rand() < 0.5 else q2\n        offspring = np.clip(offspring, lb, ub)\n        return offspring\n\n    def diverse_adaptive_mutation(self, individual, lb, ub, progress, change_rate):\n        mutation_strength = 0.1 * (ub - lb) * np.random.random_sample(self.dim) * (1 - progress + change_rate)\n        if np.random.random() < 0.5:\n            mutated = individual + np.random.normal(0, mutation_strength, self.dim)\n        else:\n            mutated = individual + np.random.uniform(-mutation_strength, mutation_strength, self.dim)\n        return np.clip(mutated, lb, ub)\n\n    def selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        return combined_population[sorted_indices][:self.population_size], combined_fitness[sorted_indices][:self.population_size]", "name": "EHQEA", "description": "Incorporates adaptive mutation strength scaling based on convergence rate to enhance exploration under stagnation.", "configspace": "", "generation": 13, "fitness": -Infinity, "feedback": "An exception occurred: OverflowError('Range exceeds valid bounds').", "error": "OverflowError('Range exceeds valid bounds')", "parent_id": "e2f3011b-47e7-40d8-b8f6-209827e6e6e0", "metadata": {}, "mutation_prompt": null}
{"id": "a6ae5fbf-bd27-4e77-b2ec-d53b239f85e4", "solution": "import numpy as np\n\nclass EHQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.max_population_size = 40  # Increased max population size\n        self.alpha = 0.5\n        self.elite_fraction = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.initial_population_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            new_population = []\n            elite_size = int(self.elite_fraction * population_size)\n            elites = population[np.argsort(fitness)[:elite_size]]\n            for _ in range(population_size - elite_size):\n                parent1, parent2 = self.select_parents(population, fitness)\n                offspring = self.enhanced_quantum_crossover(parent1, parent2, lb, ub)\n                offspring = self.diverse_adaptive_mutation(offspring, lb, ub, evaluations / self.budget)\n                new_population.append(offspring)\n            \n            new_population.extend(elites)\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += population_size\n            \n            population, fitness = self.selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n            \n            # Dynamic population adjustment\n            population_size = min(self.max_population_size, population_size + 1)\n        \n        return best_solution, best_fitness\n    \n    def select_parents(self, population, fitness):\n        tournament_size = 3\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent1_idx = tournament_indices[np.argmin(tournament_fitness)]\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent2_idx = tournament_indices[np.argmin(tournament_fitness)]\n        return population[parent1_idx], population[parent2_idx]\n    \n    def enhanced_quantum_crossover(self, parent1, parent2, lb, ub):\n        alpha_var = np.random.uniform(0.4, 0.6)\n        q1 = alpha_var * parent1 + (1 - alpha_var) * parent2\n        q2 = alpha_var * parent2 + (1 - alpha_var) * parent1\n        offspring = q1 if np.random.rand() < 0.5 else q2\n        offspring = np.clip(offspring, lb, ub)\n        return offspring\n    \n    def diverse_adaptive_mutation(self, individual, lb, ub, progress):\n        mutation_strength = 0.1 * (ub - lb) * np.random.random_sample(self.dim) * (1 - progress)\n        mutated = individual + np.random.normal(0, mutation_strength, self.dim)  # Simplified mutation strategy\n        return np.clip(mutated, lb, ub)\n\n    def selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        return combined_population[sorted_indices][:len(population)], combined_fitness[sorted_indices][:len(population)]", "name": "EHQEA", "description": "Utilizes a dynamic population size and adaptive mutation rate to enhance exploration and exploitation balance.", "configspace": "", "generation": 13, "fitness": -Infinity, "feedback": "An exception occurred: OverflowError('Range exceeds valid bounds').", "error": "OverflowError('Range exceeds valid bounds')", "parent_id": "e2f3011b-47e7-40d8-b8f6-209827e6e6e0", "metadata": {}, "mutation_prompt": null}
{"id": "6bcf41d1-8c32-4235-82e3-67401accc552", "solution": "import numpy as np\n\nclass EHQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n        self.elite_fraction = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            new_population = []\n            elite_size = int(self.elite_fraction * self.population_size)\n            elites = population[np.argsort(fitness)[:elite_size]]\n            for _ in range(self.population_size - elite_size):\n                parent1, parent2 = self.select_parents(population, fitness)\n                offspring = self.enhanced_adaptive_crossover(parent1, parent2, lb, ub, evaluations / self.budget)\n                offspring = self.diverse_adaptive_mutation(offspring, lb, ub, evaluations / self.budget)\n                new_population.append(offspring)\n            \n            new_population.extend(elites)\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n            \n            population, fitness = self.selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n        \n        return best_solution, best_fitness\n    \n    def select_parents(self, population, fitness):\n        tournament_size = 3\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent1_idx = tournament_indices[np.argmin(tournament_fitness)]\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent2_idx = tournament_indices[np.argmin(tournament_fitness)]\n        return population[parent1_idx], population[parent2_idx]\n    \n    def enhanced_adaptive_crossover(self, parent1, parent2, lb, ub, progress):\n        alpha_var = np.random.uniform(0.4, 0.6) * (1 - progress)\n        q1 = alpha_var * parent1 + (1 - alpha_var) * parent2\n        q2 = alpha_var * parent2 + (1 - alpha_var) * parent1\n        offspring = q1 if np.random.rand() < 0.5 else q2\n        offspring = np.clip(offspring, lb, ub)\n        return offspring\n    \n    def diverse_adaptive_mutation(self, individual, lb, ub, progress):\n        mutation_strength = 0.1 * (ub - lb) * np.random.random_sample(self.dim) * (1 - progress)**2\n        if np.random.random() < 0.5:\n            mutated = individual + np.random.normal(0, mutation_strength, self.dim)\n        else:\n            mutated = individual + np.random.uniform(-mutation_strength, mutation_strength, self.dim)\n        return np.clip(mutated, lb, ub)\n\n    def selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        return combined_population[sorted_indices][:self.population_size], combined_fitness[sorted_indices][:self.population_size]", "name": "EHQEA", "description": "Integrates diverse mutation strategies and adaptive learning from population dynamics to optimize exploration-exploitation balance with enhanced adaptive crossover and adaptive mutation scaling.", "configspace": "", "generation": 13, "fitness": -Infinity, "feedback": "An exception occurred: OverflowError('Range exceeds valid bounds').", "error": "OverflowError('Range exceeds valid bounds')", "parent_id": "e2f3011b-47e7-40d8-b8f6-209827e6e6e0", "metadata": {}, "mutation_prompt": null}
{"id": "54f2fbe6-027b-404c-95f4-e270ef5c99d4", "solution": "import numpy as np\n\nclass EHQEA_LA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Increased population size\n        self.alpha = 0.5\n        self.elite_fraction = 0.2  # Increased elite fraction\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            new_population = []\n            elite_size = int(self.elite_fraction * self.population_size)\n            elites = population[np.argsort(fitness)[:elite_size]]\n            for _ in range(self.population_size - elite_size):\n                parent1, parent2 = self.select_parents(population, fitness)\n                offspring = self.lineage_based_crossover(parent1, parent2, lb, ub)  # Changed crossover method\n                offspring = self.diverse_adaptive_mutation(offspring, lb, ub, evaluations / self.budget)\n                new_population.append(offspring)\n            \n            new_population.extend(elites)\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n            \n            population, fitness = self.adaptive_selection(population, fitness, new_population, new_fitness)  # Changed selection method\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n        \n        return best_solution, best_fitness\n    \n    def select_parents(self, population, fitness):\n        selected_indices = np.random.choice(len(population), 5, replace=False)\n        selected_fitness = fitness[selected_indices]\n        parent1_idx = selected_indices[np.argmin(selected_fitness)]\n        selected_indices = np.random.choice(len(population), 5, replace=False)\n        selected_fitness = fitness[selected_indices]\n        parent2_idx = selected_indices[np.argmin(selected_fitness)]\n        return population[parent1_idx], population[parent2_idx]\n    \n    def lineage_based_crossover(self, parent1, parent2, lb, ub):\n        beta = np.random.uniform(-0.1, 1.1)\n        offspring = beta * parent1 + (1 - beta) * parent2\n        return np.clip(offspring, lb, ub)\n    \n    def diverse_adaptive_mutation(self, individual, lb, ub, progress):\n        mutation_strength = 0.2 * (ub - lb) * np.random.random_sample(self.dim) * (1 - progress * progress)\n        mutated = individual + np.random.normal(0, mutation_strength, self.dim)\n        return np.clip(mutated, lb, ub)\n\n    def adaptive_selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        return combined_population[sorted_indices][:self.population_size], combined_fitness[sorted_indices][:self.population_size]", "name": "EHQEA_LA", "description": "Introduces lineage-based adaptation with advanced selection pressure to enhance solution quality and convergence speed.", "configspace": "", "generation": 13, "fitness": 0.8746808486807188, "feedback": "The algorithm EHQEA_LA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.875 with standard deviation 0.009. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "e2f3011b-47e7-40d8-b8f6-209827e6e6e0", "metadata": {"aucs": [0.8700927415954214, 0.8669460757725584, 0.887003728674177], "final_y": [0.11307532518126384, 0.12756262177705702, 0.12138818423436726]}, "mutation_prompt": null}
{"id": "6860bf79-6e1a-465d-8255-03e48868b9d7", "solution": "import numpy as np\n\nclass EHQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n        self.elite_fraction = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            new_population = []\n            elite_size = int(self.elite_fraction * self.population_size)\n            elites = population[np.argsort(fitness)[:elite_size]]\n            for _ in range(self.population_size - elite_size):\n                parent1, parent2 = self.select_parents(population, fitness)\n                offspring = self.enhanced_quantum_crossover(parent1, parent2, lb, ub)\n                offspring = self.diverse_adaptive_mutation(offspring, lb, ub, evaluations / self.budget)\n                new_population.append(offspring)\n            \n            new_population.extend(elites)\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n            \n            population, fitness = self.selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n        \n        return best_solution, best_fitness\n    \n    def select_parents(self, population, fitness):\n        tournament_size = 3\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent1_idx = tournament_indices[np.argmin(tournament_fitness)]\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent2_idx = tournament_indices[np.argmin(tournament_fitness)]\n        return population[parent1_idx], population[parent2_idx]\n    \n    def enhanced_quantum_crossover(self, parent1, parent2, lb, ub):\n        alpha_var = np.random.uniform(0.4, 0.6)\n        q1 = alpha_var * parent1 + (1 - alpha_var) * parent2\n        q2 = alpha_var * parent2 + (1 - alpha_var) * parent1\n        offspring = q1 if np.random.rand() < 0.5 else q2\n        offspring = np.clip(offspring, lb, ub)\n        return offspring\n    \n    def diverse_adaptive_mutation(self, individual, lb, ub, progress):\n        mutation_strength = 0.1 * (ub - lb) * np.random.random_sample(self.dim) * (1 - progress ** 1.5)  # Modified line\n        if np.random.random() < 0.5:\n            mutated = individual + np.random.normal(0, mutation_strength, self.dim)\n        else:\n            mutated = individual + np.random.uniform(-mutation_strength, mutation_strength, self.dim)\n        return np.clip(mutated, lb, ub)\n\n    def selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        return combined_population[sorted_indices][:self.population_size], combined_fitness[sorted_indices][:self.population_size]", "name": "EHQEA", "description": "Refines adaptive mutation by introducing a dynamic mutation strength to enhance exploration-exploitation balance.", "configspace": "", "generation": 14, "fitness": 0.9220397469693267, "feedback": "The algorithm EHQEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.922 with standard deviation 0.006. And the mean value of best solutions found was 0.111 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "e2f3011b-47e7-40d8-b8f6-209827e6e6e0", "metadata": {"aucs": [0.9207245395667346, 0.9148991031485795, 0.9304955981926658], "final_y": [0.11057835609696398, 0.11244011416738353, 0.1100242793722509]}, "mutation_prompt": null}
{"id": "7ce1bb4a-4147-443e-b455-a6b0c524d683", "solution": "import numpy as np\n\nclass EHQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n        self.elite_fraction = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            new_population = []\n            # Dynamically adjust elite fraction based on progress\n            self.elite_fraction = 0.1 + 0.3 * (evaluations / self.budget)\n            elite_size = int(self.elite_fraction * self.population_size)\n            elites = population[np.argsort(fitness)[:elite_size]]\n            for _ in range(self.population_size - elite_size):\n                parent1, parent2 = self.select_parents(population, fitness)\n                offspring = self.enhanced_quantum_crossover(parent1, parent2, lb, ub)\n                offspring = self.diverse_adaptive_mutation(offspring, lb, ub, evaluations / self.budget)\n                new_population.append(offspring)\n            \n            new_population.extend(elites)\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n            \n            population, fitness = self.selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n        \n        return best_solution, best_fitness\n    \n    def select_parents(self, population, fitness):\n        tournament_size = 3\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent1_idx = tournament_indices[np.argmin(tournament_fitness)]\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent2_idx = tournament_indices[np.argmin(tournament_fitness)]\n        return population[parent1_idx], population[parent2_idx]\n    \n    def enhanced_quantum_crossover(self, parent1, parent2, lb, ub):\n        alpha_var = np.random.uniform(0.4, 0.6)\n        q1 = alpha_var * parent1 + (1 - alpha_var) * parent2\n        q2 = alpha_var * parent2 + (1 - alpha_var) * parent1\n        offspring = q1 if np.random.rand() < 0.5 else q2\n        offspring = np.clip(offspring, lb, ub)\n        return offspring\n    \n    def diverse_adaptive_mutation(self, individual, lb, ub, progress):\n        mutation_strength = 0.1 * (ub - lb) * np.random.random_sample(self.dim) * (1 - progress)\n        if np.random.random() < 0.5:\n            mutated = individual + np.random.normal(0, mutation_strength, self.dim)\n        else:\n            mutated = individual + np.random.uniform(-mutation_strength, mutation_strength, self.dim)\n        return np.clip(mutated, lb, ub)\n\n    def selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        return combined_population[sorted_indices][:self.population_size], combined_fitness[sorted_indices][:self.population_size]", "name": "EHQEA", "description": "Introduces a dynamic elite_fraction to better adapt exploration-exploitation trade-off during the optimization process.", "configspace": "", "generation": 14, "fitness": 0.9162956622099028, "feedback": "The algorithm EHQEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.916 with standard deviation 0.014. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "e2f3011b-47e7-40d8-b8f6-209827e6e6e0", "metadata": {"aucs": [0.9211499171493933, 0.8969466211832134, 0.9307904482971018], "final_y": [0.10978356515986276, 0.12033719607870952, 0.11042184532275456]}, "mutation_prompt": null}
{"id": "02097b39-ade4-44a5-8357-f8cbd8a9a566", "solution": "import numpy as np\n\nclass EHQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n        self.elite_fraction = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.population_size = max(5, int(20 * (1 - evaluations / self.budget)))  # Dynamic population size\n            new_population = []\n            elite_size = int(self.elite_fraction * self.population_size)\n            elites = population[np.argsort(fitness)[:elite_size]]\n            for _ in range(self.population_size - elite_size):\n                parent1, parent2 = self.select_parents(population, fitness)\n                offspring = self.enhanced_quantum_crossover(parent1, parent2, lb, ub)\n                offspring = self.diverse_adaptive_mutation(offspring, lb, ub, evaluations / self.budget)\n                new_population.append(offspring)\n            \n            new_population.extend(elites)\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n            \n            population, fitness = self.selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n        \n        return best_solution, best_fitness\n    \n    def select_parents(self, population, fitness):\n        tournament_size = 3\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent1_idx = tournament_indices[np.argmin(tournament_fitness)]\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent2_idx = tournament_indices[np.argmin(tournament_fitness)]\n        return population[parent1_idx], population[parent2_idx]\n    \n    def enhanced_quantum_crossover(self, parent1, parent2, lb, ub):\n        alpha_var = np.random.uniform(0.4, 0.6)\n        q1 = alpha_var * parent1 + (1 - alpha_var) * parent2\n        q2 = alpha_var * parent2 + (1 - alpha_var) * parent1\n        offspring = q1 if np.random.rand() < 0.5 else q2\n        offspring = np.clip(offspring, lb, ub)\n        return offspring\n    \n    def diverse_adaptive_mutation(self, individual, lb, ub, progress):\n        mutation_strength = 0.1 * (ub - lb) * np.random.random_sample(self.dim) * (1 - progress)\n        if np.random.random() < 0.5:\n            mutated = individual + np.random.normal(0, mutation_strength, self.dim)\n        else:\n            mutated = individual + np.random.uniform(-mutation_strength, mutation_strength, self.dim)\n        return np.clip(mutated, lb, ub)\n\n    def selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        return combined_population[sorted_indices][:self.population_size], combined_fitness[sorted_indices][:self.population_size]", "name": "EHQEA", "description": "Introduces a dynamic population size strategy to adaptively allocate resources based on search progress and solution quality.", "configspace": "", "generation": 14, "fitness": 0.9083628023168554, "feedback": "The algorithm EHQEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.908 with standard deviation 0.011. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "e2f3011b-47e7-40d8-b8f6-209827e6e6e0", "metadata": {"aucs": [0.9012276312075785, 0.8995839225064078, 0.9242768532365796], "final_y": [0.10966698694652888, 0.11627778226676122, 0.11223518316251546]}, "mutation_prompt": null}
{"id": "b4c2ea17-4b50-45e4-9af0-3d1c5ff40fa1", "solution": "import numpy as np\n\nclass EHQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n        self.elite_fraction = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adaptive population size adjustment based on progress\n            self.population_size = int(20 + 10 * (1 - (evaluations / self.budget)))\n            new_population = []\n            elite_size = int(self.elite_fraction * self.population_size)\n            elites = population[np.argsort(fitness)[:elite_size]]\n            for _ in range(self.population_size - elite_size):\n                parent1, parent2 = self.select_parents(population, fitness)\n                offspring = self.enhanced_quantum_crossover(parent1, parent2, lb, ub)\n                offspring = self.diverse_adaptive_mutation(offspring, lb, ub, evaluations / self.budget)\n                new_population.append(offspring)\n            \n            new_population.extend(elites)\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n            \n            population, fitness = self.selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n        \n        return best_solution, best_fitness\n    \n    def select_parents(self, population, fitness):\n        tournament_size = 3\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent1_idx = tournament_indices[np.argmin(tournament_fitness)]\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent2_idx = tournament_indices[np.argmin(tournament_fitness)]\n        return population[parent1_idx], population[parent2_idx]\n    \n    def enhanced_quantum_crossover(self, parent1, parent2, lb, ub):\n        alpha_var = np.random.uniform(0.4, 0.6)\n        q1 = alpha_var * parent1 + (1 - alpha_var) * parent2\n        q2 = alpha_var * parent2 + (1 - alpha_var) * parent1\n        offspring = q1 if np.random.rand() < 0.5 else q2\n        offspring = np.clip(offspring, lb, ub)\n        return offspring\n    \n    def diverse_adaptive_mutation(self, individual, lb, ub, progress):\n        mutation_strength = 0.1 * (ub - lb) * np.random.random_sample(self.dim) * (1 - progress)\n        if np.random.random() < 0.5:\n            mutated = individual + np.random.normal(0, mutation_strength, self.dim)\n        else:\n            mutated = individual + np.random.uniform(-mutation_strength, mutation_strength, self.dim)\n        return np.clip(mutated, lb, ub)\n\n    def selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        return combined_population[sorted_indices][:self.population_size], combined_fitness[sorted_indices][:self.population_size]", "name": "EHQEA", "description": "Introduce adaptive population size strategy based on optimization progress to enhance exploration-exploitation balance.", "configspace": "", "generation": 14, "fitness": 0.9079011163816851, "feedback": "The algorithm EHQEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.908 with standard deviation 0.012. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "e2f3011b-47e7-40d8-b8f6-209827e6e6e0", "metadata": {"aucs": [0.8956483365913405, 0.9039640482453417, 0.9240909643083731], "final_y": [0.11706591469093974, 0.1116929370411458, 0.11049595689097957]}, "mutation_prompt": null}
{"id": "412fe964-64cd-4e1c-a5bf-50a3cae5ecd0", "solution": "import numpy as np\n\nclass EHQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n        self.elite_fraction = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            new_population = []\n            elite_size = int(self.elite_fraction * self.population_size)\n            elites = population[np.argsort(fitness)[:elite_size]]\n            for _ in range(self.population_size - elite_size):\n                parent1, parent2 = self.select_parents(population, fitness)\n                offspring = self.adaptive_quantum_crossover(parent1, parent2, lb, ub, evaluations / self.budget)\n                offspring = self.diverse_adaptive_mutation(offspring, lb, ub, evaluations / self.budget)\n                new_population.append(offspring)\n            \n            new_population.extend(elites)\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n            \n            population, fitness = self.selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n        \n        return best_solution, best_fitness\n    \n    def select_parents(self, population, fitness):\n        tournament_size = 3\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent1_idx = tournament_indices[np.argmin(tournament_fitness)]\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent2_idx = tournament_indices[np.argmin(tournament_fitness)]\n        return population[parent1_idx], population[parent2_idx]\n    \n    def adaptive_quantum_crossover(self, parent1, parent2, lb, ub, progress):\n        alpha_var = np.random.uniform(0.4, 0.6)\n        crossover_prob = 0.5 * (1 - progress)\n        q1 = alpha_var * parent1 + (1 - alpha_var) * parent2\n        q2 = alpha_var * parent2 + (1 - alpha_var) * parent1\n        offspring = q1 if np.random.rand() < crossover_prob else q2\n        offspring = np.clip(offspring, lb, ub)\n        return offspring\n    \n    def diverse_adaptive_mutation(self, individual, lb, ub, progress):\n        mutation_strength = 0.1 * (ub - lb) * np.random.random_sample(self.dim) * (1 - progress)\n        if np.random.random() < 0.5:\n            mutated = individual + np.random.normal(0, mutation_strength, self.dim)\n        else:\n            mutated = individual + np.random.uniform(-mutation_strength, mutation_strength, self.dim)\n        return np.clip(mutated, lb, ub)\n\n    def selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        return combined_population[sorted_indices][:self.population_size], combined_fitness[sorted_indices][:self.population_size]", "name": "EHQEA", "description": "Introduces a probability-based adaptive crossover mechanism to enhance exploration and maintain diversity.", "configspace": "", "generation": 14, "fitness": 0.9100854646682386, "feedback": "The algorithm EHQEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.910 with standard deviation 0.006. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "e2f3011b-47e7-40d8-b8f6-209827e6e6e0", "metadata": {"aucs": [0.914818269398588, 0.9018985788672589, 0.9135395457388691], "final_y": [0.11039084603372729, 0.11644421434215768, 0.1126303267121258]}, "mutation_prompt": null}
{"id": "ce8f4a78-3ea5-4fae-940d-7478ec9fc287", "solution": "import numpy as np\n\nclass EHQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n        self.elite_fraction = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            new_population = []\n            elite_size = int(self.elite_fraction * self.population_size)\n            elites = population[np.argsort(fitness)[:elite_size]]\n            for _ in range(self.population_size - elite_size):\n                parent1, parent2 = self.select_parents(population, fitness)\n                offspring = self.enhanced_quantum_crossover(parent1, parent2, lb, ub)\n                offspring = self.diverse_adaptive_mutation(offspring, lb, ub, evaluations / self.budget)\n                new_population.append(offspring)\n            \n            new_population.extend(elites)\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n            \n            population, fitness = self.selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n        \n        return best_solution, best_fitness\n    \n    def select_parents(self, population, fitness):\n        tournament_size = 3\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent1_idx = tournament_indices[np.argmin(tournament_fitness)]\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent2_idx = tournament_indices[np.argmin(tournament_fitness)]\n        return population[parent1_idx], population[parent2_idx]\n    \n    def enhanced_quantum_crossover(self, parent1, parent2, lb, ub):\n        alpha_var = np.random.uniform(0.4, 0.6)\n        q1 = alpha_var * parent1 + (1 - alpha_var) * parent2\n        q2 = alpha_var * parent2 + (1 - alpha_var) * parent1\n        offspring = q1 if np.random.rand() < 0.5 else q2\n        offspring = np.clip(offspring, lb, ub)\n        return offspring\n    \n    def diverse_adaptive_mutation(self, individual, lb, ub, progress):\n        mutation_strength = 0.1 * (ub - lb) * np.random.random_sample(self.dim) * (1 - progress ** 2)  # Modified line\n        if np.random.random() < 0.5:\n            mutated = individual + np.random.normal(0, mutation_strength, self.dim)\n        else:\n            mutated = individual + np.random.uniform(-mutation_strength, mutation_strength, self.dim)\n        return np.clip(mutated, lb, ub)\n\n    def selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        return combined_population[sorted_indices][:self.population_size], combined_fitness[sorted_indices][:self.population_size]", "name": "EHQEA", "description": "Refines adaptive mutation by incorporating variance decay to improve convergence stability.", "configspace": "", "generation": 15, "fitness": 0.9191303729132905, "feedback": "The algorithm EHQEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.919 with standard deviation 0.008. And the mean value of best solutions found was 0.111 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "6860bf79-6e1a-465d-8255-03e48868b9d7", "metadata": {"aucs": [0.9255496615875176, 0.9074079448085615, 0.9244335123437923], "final_y": [0.11018367225092873, 0.1131579040981292, 0.10996664875798312]}, "mutation_prompt": null}
{"id": "1ec77978-eb32-4d34-9c2b-f8db5a4578d3", "solution": "import numpy as np\n\nclass EHQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n        self.elite_fraction = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            new_population = []\n            elite_size = int(self.elite_fraction * (1 - evaluations / self.budget) * self.population_size)  # Modified line\n            elites = population[np.argsort(fitness)[:elite_size]]\n            for _ in range(self.population_size - elite_size):\n                parent1, parent2 = self.select_parents(population, fitness)\n                offspring = self.enhanced_quantum_crossover(parent1, parent2, lb, ub)\n                offspring = self.diverse_adaptive_mutation(offspring, lb, ub, evaluations / self.budget)\n                new_population.append(offspring)\n            \n            new_population.extend(elites)\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n            \n            population, fitness = self.selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n        \n        return best_solution, best_fitness\n    \n    def select_parents(self, population, fitness):\n        tournament_size = 3\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent1_idx = tournament_indices[np.argmin(tournament_fitness)]\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent2_idx = tournament_indices[np.argmin(tournament_fitness)]\n        return population[parent1_idx], population[parent2_idx]\n    \n    def enhanced_quantum_crossover(self, parent1, parent2, lb, ub):\n        alpha_var = np.random.uniform(0.4, 0.6)\n        q1 = alpha_var * parent1 + (1 - alpha_var) * parent2\n        q2 = alpha_var * parent2 + (1 - alpha_var) * parent1\n        offspring = q1 if np.random.rand() < 0.5 else q2\n        offspring = np.clip(offspring, lb, ub)\n        return offspring\n    \n    def diverse_adaptive_mutation(self, individual, lb, ub, progress):\n        mutation_strength = 0.1 * (ub - lb) * np.random.random_sample(self.dim) * (1 - progress ** 1.5)  # Modified line\n        if np.random.random() < 0.5:\n            mutated = individual + np.random.normal(0, mutation_strength, self.dim)\n        else:\n            mutated = individual + np.random.uniform(-mutation_strength, mutation_strength, self.dim)\n        return np.clip(mutated, lb, ub)\n\n    def selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        return combined_population[sorted_indices][:self.population_size], combined_fitness[sorted_indices][:self.population_size]", "name": "EHQEA", "description": "Introduce a dynamic elite fraction that decreases linearly over iterations to balance exploration and exploitation.", "configspace": "", "generation": 15, "fitness": 0.9164859890603522, "feedback": "The algorithm EHQEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.916 with standard deviation 0.006. And the mean value of best solutions found was 0.111 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "6860bf79-6e1a-465d-8255-03e48868b9d7", "metadata": {"aucs": [0.9156466266068954, 0.9096422891187094, 0.9241690514554518], "final_y": [0.11009104056239827, 0.11240795655926827, 0.11184953305086787]}, "mutation_prompt": null}
{"id": "241bee43-84c6-47a8-8a50-7b809b3c76de", "solution": "import numpy as np\n\nclass EHQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n        self.elite_fraction = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            new_population = []\n            elite_size = int(self.elite_fraction * self.population_size)\n            elites = population[np.argsort(fitness)[:elite_size]]\n            for _ in range(self.population_size - elite_size):\n                parent1, parent2 = self.select_parents(population, fitness, evaluations / self.budget)\n                offspring = self.enhanced_quantum_crossover(parent1, parent2, lb, ub)\n                offspring = self.diverse_adaptive_mutation(offspring, lb, ub, evaluations / self.budget)\n                new_population.append(offspring)\n            \n            new_population.extend(elites)\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n            \n            population, fitness = self.selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n        \n        return best_solution, best_fitness\n    \n    def select_parents(self, population, fitness, progress):\n        tournament_size = int(3 + 2 * (1 - progress))  # Dynamic tournament size\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent1_idx = tournament_indices[np.argmin(tournament_fitness)]\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent2_idx = tournament_indices[np.argmin(tournament_fitness)]\n        return population[parent1_idx], population[parent2_idx]\n    \n    def enhanced_quantum_crossover(self, parent1, parent2, lb, ub):\n        alpha_var = np.random.uniform(0.4, 0.6)\n        q1 = alpha_var * parent1 + (1 - alpha_var) * parent2\n        q2 = alpha_var * parent2 + (1 - alpha_var) * parent1\n        offspring = q1 if np.random.rand() < 0.5 else q2\n        offspring = np.clip(offspring, lb, ub)\n        return offspring\n    \n    def diverse_adaptive_mutation(self, individual, lb, ub, progress):\n        mutation_strength = 0.05 * (ub - lb) * np.exp(-5 * progress)  # Adjusted mutation strategy\n        mutated = individual + np.random.normal(0, mutation_strength, self.dim)\n        return np.clip(mutated, lb, ub)\n\n    def selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        return combined_population[sorted_indices][:self.population_size], combined_fitness[sorted_indices][:self.population_size]", "name": "EHQEA", "description": "Enhances exploration-exploitation balance by integrating dynamic tournament size and Gaussian perturbation into mutation.", "configspace": "", "generation": 15, "fitness": 0.905520640514534, "feedback": "The algorithm EHQEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.906 with standard deviation 0.007. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "6860bf79-6e1a-465d-8255-03e48868b9d7", "metadata": {"aucs": [0.904058279154943, 0.8978232648324069, 0.9146803775562521], "final_y": [0.1178006088718665, 0.1165245035472966, 0.11073154755653569]}, "mutation_prompt": null}
{"id": "4a37208c-db5d-4cca-a714-0f39033ce6d6", "solution": "import numpy as np\n\nclass EHQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n        self.elite_fraction = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            new_population = []\n            elite_size = int(self.elite_fraction * self.population_size)\n            elites = population[np.argsort(fitness)[:elite_size]]\n            diversity = np.mean(np.std(population, axis=0))  # Calculate population diversity\n            for _ in range(self.population_size - elite_size):\n                parent1, parent2 = self.select_parents(population, fitness)\n                offspring = self.enhanced_quantum_crossover(parent1, parent2, lb, ub)\n                offspring = self.diverse_adaptive_mutation(offspring, lb, ub, evaluations / self.budget, diversity)\n                new_population.append(offspring)\n            \n            new_population.extend(elites)\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n            \n            population, fitness = self.selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n        \n        return best_solution, best_fitness\n    \n    def select_parents(self, population, fitness):\n        tournament_size = 3\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent1_idx = tournament_indices[np.argmin(tournament_fitness)]\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent2_idx = tournament_indices[np.argmin(tournament_fitness)]\n        return population[parent1_idx], population[parent2_idx]\n    \n    def enhanced_quantum_crossover(self, parent1, parent2, lb, ub):\n        alpha_var = np.random.uniform(0.4, 0.6)\n        q1 = alpha_var * parent1 + (1 - alpha_var) * parent2\n        q2 = alpha_var * parent2 + (1 - alpha_var) * parent1\n        offspring = q1 if np.random.rand() < 0.5 else q2\n        offspring = np.clip(offspring, lb, ub)\n        return offspring\n    \n    def diverse_adaptive_mutation(self, individual, lb, ub, progress, diversity):\n        mutation_strength = 0.1 * (ub - lb) * np.random.random_sample(self.dim) * (1 - progress ** 1.5)\n        mutation_strength *= (1 + diversity)  # Adjust mutation strength based on diversity\n        if np.random.random() < 0.5:\n            mutated = individual + np.random.normal(0, mutation_strength, self.dim)\n        else:\n            mutated = individual + np.random.uniform(-mutation_strength, mutation_strength, self.dim)\n        return np.clip(mutated, lb, ub)\n\n    def selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        return combined_population[sorted_indices][:self.population_size], combined_fitness[sorted_indices][:self.population_size]", "name": "EHQEA", "description": "Incorporates a feedback loop to dynamically adjust mutation strength based on population diversity to enhance convergence speed without sacrificing exploration.", "configspace": "", "generation": 15, "fitness": 0.8595544930995458, "feedback": "The algorithm EHQEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.860 with standard deviation 0.063. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "6860bf79-6e1a-465d-8255-03e48868b9d7", "metadata": {"aucs": [0.7699120925546512, 0.902467106098781, 0.906284280645205], "final_y": [0.1383631338454785, 0.11275250999822106, 0.11245205605585773]}, "mutation_prompt": null}
{"id": "38d5c536-1816-4983-a831-1d76c23322ea", "solution": "import numpy as np\n\nclass EHQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.alpha = 0.5\n        self.elite_fraction = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.initial_population_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            elite_size = int(self.elite_fraction * population_size)\n            elites = population[np.argsort(fitness)[:elite_size]]\n            new_population = list(elites)\n\n            parent_indices = np.random.choice(range(population_size), population_size - elite_size)\n            for idx in parent_indices:\n                parent1, parent2 = self.select_parents(population, fitness)\n                offspring = self.enhanced_quantum_crossover(parent1, parent2, lb, ub)\n                offspring = self.diverse_adaptive_mutation(offspring, lb, ub, evaluations / self.budget)\n                new_population.append(offspring)\n\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += population_size\n\n            # Dynamic population resizing\n            population_size = max(10, int(self.initial_population_size * (1 - evaluations / self.budget)))\n            self.elite_fraction = max(0.05, 0.1 * (evaluations / self.budget))\n\n            population, fitness = self.selection(new_population, new_fitness, population_size)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n\n        return best_solution, best_fitness\n    \n    def select_parents(self, population, fitness):\n        tournament_size = 3\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent1_idx = tournament_indices[np.argmin(tournament_fitness)]\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent2_idx = tournament_indices[np.argmin(tournament_fitness)]\n        return population[parent1_idx], population[parent2_idx]\n    \n    def enhanced_quantum_crossover(self, parent1, parent2, lb, ub):\n        alpha_var = np.random.uniform(0.4, 0.6)\n        q1 = alpha_var * parent1 + (1 - alpha_var) * parent2\n        q2 = alpha_var * parent2 + (1 - alpha_var) * parent1\n        offspring = q1 if np.random.rand() < 0.5 else q2\n        offspring = np.clip(offspring, lb, ub)\n        return offspring\n    \n    def diverse_adaptive_mutation(self, individual, lb, ub, progress):\n        mutation_strength = 0.1 * (ub - lb) * np.random.random_sample(self.dim) * (1 - progress ** 1.5)\n        if np.random.random() < 0.5:\n            mutated = individual + np.random.normal(0, mutation_strength, self.dim)\n        else:\n            mutated = individual + np.random.uniform(-mutation_strength, mutation_strength, self.dim)\n        return np.clip(mutated, lb, ub)\n\n    def selection(self, new_population, new_fitness, population_size):\n        sorted_indices = np.argsort(new_fitness)\n        return new_population[sorted_indices][:population_size], new_fitness[sorted_indices][:population_size]", "name": "EHQEA", "description": "Introduces adaptive elite preservation and dynamic population resizing to enhance global search and convergence speed.", "configspace": "", "generation": 15, "fitness": 0.9179015490987107, "feedback": "The algorithm EHQEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.918 with standard deviation 0.004. And the mean value of best solutions found was 0.111 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "6860bf79-6e1a-465d-8255-03e48868b9d7", "metadata": {"aucs": [0.9208482147563429, 0.9208577264041922, 0.9119987061355972], "final_y": [0.10969475594827471, 0.11168615012404315, 0.11218431411805585]}, "mutation_prompt": null}
{"id": "d0b3b950-6a6f-4b1c-9b5e-7a592dd8a51d", "solution": "import numpy as np\n\nclass EHQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n        self.elite_fraction = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            new_population = []\n            elite_size = int(self.elite_fraction * self.population_size)\n            elites = population[np.argsort(fitness)[:elite_size]]\n            for _ in range(self.population_size - elite_size):\n                parent1, parent2 = self.select_parents(population, fitness)\n                offspring = self.enhanced_quantum_crossover(parent1, parent2, lb, ub)\n                offspring = self.diverse_adaptive_mutation(offspring, lb, ub, evaluations / self.budget)\n                new_population.append(offspring)\n            \n            new_population.extend(elites)\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n            \n            population, fitness = self.selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n        \n        return best_solution, best_fitness\n    \n    def select_parents(self, population, fitness):\n        tournament_size = 3\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent1_idx = tournament_indices[np.argmin(tournament_fitness)]\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent2_idx = tournament_indices[np.argmin(tournament_fitness)]\n        return population[parent1_idx], population[parent2_idx]\n    \n    def enhanced_quantum_crossover(self, parent1, parent2, lb, ub):\n        alpha_var = np.random.uniform(0.4, 0.6)\n        q1 = alpha_var * parent1 + (1 - alpha_var) * parent2\n        q2 = alpha_var * parent2 + (1 - alpha_var) * parent1\n        offspring = q1 if np.random.rand() < 0.5 else q2\n        offspring = np.clip(offspring, lb, ub)\n        return offspring\n    \n    def diverse_adaptive_mutation(self, individual, lb, ub, progress):\n        mutation_strength = 0.1 * (ub - lb) * np.random.random_sample(self.dim) * (1 - progress ** 2.0)\n        if np.random.random() < 0.5:\n            mutated = individual + np.random.normal(0, mutation_strength, self.dim)\n        else:\n            mutated = individual + np.random.uniform(-mutation_strength, mutation_strength, self.dim)\n        return np.clip(mutated, lb, ub)\n\n    def selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        return combined_population[sorted_indices][:self.population_size], combined_fitness[sorted_indices][:self.population_size]", "name": "EHQEA", "description": "Introduces adaptive selection pressure and a convergence-based mutation strategy to enhance solution quality.", "configspace": "", "generation": 16, "fitness": 0.9198831927613366, "feedback": "The algorithm EHQEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.920 with standard deviation 0.002. And the mean value of best solutions found was 0.112 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "6860bf79-6e1a-465d-8255-03e48868b9d7", "metadata": {"aucs": [0.9224792010234466, 0.920107142197049, 0.9170632350635142], "final_y": [0.11016055053070373, 0.11254392333537899, 0.11312720543897925]}, "mutation_prompt": null}
{"id": "6a4df2b2-7d08-4280-ae95-13f3b39519d3", "solution": "import numpy as np\n\nclass EHQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n        self.elite_fraction = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            new_population = []\n            elite_size = int(self.elite_fraction * self.population_size)\n            elites = population[np.argsort(fitness)[:elite_size]]\n            for _ in range(self.population_size - elite_size):\n                parent1, parent2 = self.select_parents(population, fitness)\n                offspring = self.enhanced_quantum_crossover(parent1, parent2, lb, ub)\n                offspring = self.diverse_adaptive_mutation(offspring, lb, ub, evaluations / self.budget)\n                new_population.append(offspring)\n            \n            new_population.extend(elites)\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            # Added line: Stochastic re-evaluation\n            if np.random.random() < 0.1:\n                new_fitness[np.argsort(new_fitness)[:elite_size]] = [func(ind) for ind in new_population[np.argsort(new_fitness)[:elite_size]]]\n            evaluations += self.population_size\n            \n            population, fitness = self.selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n        \n        return best_solution, best_fitness\n    \n    def select_parents(self, population, fitness):\n        tournament_size = 3\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent1_idx = tournament_indices[np.argmin(tournament_fitness)]\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent2_idx = tournament_indices[np.argmin(tournament_fitness)]\n        return population[parent1_idx], population[parent2_idx]\n    \n    def enhanced_quantum_crossover(self, parent1, parent2, lb, ub):\n        alpha_var = np.random.uniform(0.4, 0.6)\n        q1 = alpha_var * parent1 + (1 - alpha_var) * parent2\n        q2 = alpha_var * parent2 + (1 - alpha_var) * parent1\n        offspring = q1 if np.random.rand() < 0.5 else q2\n        offspring = np.clip(offspring, lb, ub)\n        return offspring\n    \n    def diverse_adaptive_mutation(self, individual, lb, ub, progress):\n        # Changed line: Introduced nonlinear decay\n        mutation_strength = 0.1 * (ub - lb) * np.random.random_sample(self.dim) * (1 - progress ** 1.2)  # Adjusted exponent\n        if np.random.random() < 0.5:\n            mutated = individual + np.random.normal(0, mutation_strength, self.dim)\n        else:\n            mutated = individual + np.random.uniform(-mutation_strength, mutation_strength, self.dim)\n        return np.clip(mutated, lb, ub)\n\n    def selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        return combined_population[sorted_indices][:self.population_size], combined_fitness[sorted_indices][:self.population_size]", "name": "EHQEA", "description": "Enhance global search by introducing a nonlinear mutation decay and stochastic elite re-evaluation.", "configspace": "", "generation": 16, "fitness": 0.9148488677936726, "feedback": "The algorithm EHQEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.915 with standard deviation 0.010. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "6860bf79-6e1a-465d-8255-03e48868b9d7", "metadata": {"aucs": [0.9068715763452655, 0.9090819868034621, 0.92859304023229], "final_y": [0.11698268403334322, 0.11177051098252899, 0.11133599107547687]}, "mutation_prompt": null}
{"id": "435794c6-9edc-4e28-9678-068cc3852479", "solution": "import numpy as np\n\nclass EHQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n        self.elite_fraction = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            new_population = []\n            self.elite_fraction = 0.1 + 0.3 * (evaluations / self.budget)  # Modified line\n            elite_size = int(self.elite_fraction * self.population_size)\n            elites = population[np.argsort(fitness)[:elite_size]]\n            for _ in range(self.population_size - elite_size):\n                parent1, parent2 = self.select_parents(population, fitness)\n                offspring = self.enhanced_quantum_crossover(parent1, parent2, lb, ub)\n                offspring = self.diverse_adaptive_mutation(offspring, lb, ub, evaluations / self.budget)\n                new_population.append(offspring)\n            \n            new_population.extend(elites)\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n            \n            population, fitness = self.selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n        \n        return best_solution, best_fitness\n    \n    def select_parents(self, population, fitness):\n        tournament_size = 3\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent1_idx = tournament_indices[np.argmin(tournament_fitness)]\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent2_idx = tournament_indices[np.argmin(tournament_fitness)]\n        return population[parent1_idx], population[parent2_idx]\n    \n    def enhanced_quantum_crossover(self, parent1, parent2, lb, ub):\n        alpha_var = np.random.uniform(0.4, 0.6)\n        q1 = alpha_var * parent1 + (1 - alpha_var) * parent2\n        q2 = alpha_var * parent2 + (1 - alpha_var) * parent1\n        offspring = q1 if np.random.rand() < 0.5 else q2\n        offspring = np.clip(offspring, lb, ub)\n        return offspring\n    \n    def diverse_adaptive_mutation(self, individual, lb, ub, progress):\n        mutation_strength = 0.1 * (ub - lb) * np.random.random_sample(self.dim) * (1 - progress ** 1.5)\n        if np.random.random() < 0.5:\n            mutated = individual + np.random.normal(0, mutation_strength, self.dim)\n        else:\n            mutated = individual + np.random.uniform(-mutation_strength, mutation_strength, self.dim)\n        return np.clip(mutated, lb, ub)\n\n    def selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        return combined_population[sorted_indices][:self.population_size], combined_fitness[sorted_indices][:self.population_size]", "name": "EHQEA", "description": "Introduces a feedback mechanism to dynamically adjust elite_fraction based on progress to balance exploration and exploitation.", "configspace": "", "generation": 16, "fitness": 0.905033930582721, "feedback": "The algorithm EHQEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.905 with standard deviation 0.021. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "6860bf79-6e1a-465d-8255-03e48868b9d7", "metadata": {"aucs": [0.884658604137443, 0.8967771824839853, 0.9336660051267346], "final_y": [0.12010009382005749, 0.11655636895162669, 0.11007961281707856]}, "mutation_prompt": null}
{"id": "20a34808-9d15-427e-af56-85df45951d7e", "solution": "import numpy as np\n\nclass EHQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n        self.elite_fraction = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            new_population = []\n            elite_size = int(self.elite_fraction * self.population_size)\n            elites = population[np.argsort(fitness)[:elite_size]]\n            for _ in range(self.population_size - elite_size):\n                parent1, parent2 = self.select_parents(population, fitness)\n                offspring = self.enhanced_quantum_crossover(parent1, parent2, lb, ub)\n                offspring = self.diverse_adaptive_mutation(offspring, lb, ub, evaluations / self.budget)\n                new_population.append(offspring)\n            \n            new_population.extend(elites)\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n            \n            population, fitness = self.selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n        \n        return best_solution, best_fitness\n    \n    def select_parents(self, population, fitness):\n        tournament_size = 3\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent1_idx = tournament_indices[np.argmin(tournament_fitness)]\n        # Reverse tournament selection for second parent\n        reverse_tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        reverse_tournament_fitness = fitness[reverse_tournament_indices]\n        parent2_idx = reverse_tournament_indices[np.argmax(reverse_tournament_fitness)]\n        return population[parent1_idx], population[parent2_idx]\n    \n    def enhanced_quantum_crossover(self, parent1, parent2, lb, ub):\n        alpha_var = np.random.uniform(0.4, 0.6)\n        q1 = alpha_var * parent1 + (1 - alpha_var) * parent2\n        q2 = alpha_var * parent2 + (1 - alpha_var) * parent1\n        offspring = q1 if np.random.rand() < 0.5 else q2\n        offspring = np.clip(offspring, lb, ub)\n        return offspring\n    \n    def diverse_adaptive_mutation(self, individual, lb, ub, progress):\n        mutation_strength = 0.1 * (ub - lb) * np.random.random_sample(self.dim) * (1 - progress ** 1.5)  # Modified line\n        if np.random.random() < 0.5:\n            mutated = individual + np.random.normal(0, mutation_strength, self.dim)\n        else:\n            mutated = individual + np.random.uniform(-mutation_strength, mutation_strength, self.dim)\n        return np.clip(mutated, lb, ub)\n\n    def selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        return combined_population[sorted_indices][:self.population_size], combined_fitness[sorted_indices][:self.population_size]", "name": "EHQEA", "description": "Introduces reverse tournament to improve parent selection by ensuring diverse genetic material. ", "configspace": "", "generation": 16, "fitness": 0.9102573318399836, "feedback": "The algorithm EHQEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.910 with standard deviation 0.013. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "6860bf79-6e1a-465d-8255-03e48868b9d7", "metadata": {"aucs": [0.9016390929214319, 0.9004388964186966, 0.9286940061798225], "final_y": [0.11111559165450868, 0.11661739637602919, 0.11088253206385279]}, "mutation_prompt": null}
{"id": "dea44a43-4606-4f09-86a9-d2fd315c1ca9", "solution": "import numpy as np\n\nclass EHQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.alpha = 0.5\n        self.elite_fraction = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            new_population = []\n            progress = evaluations / self.budget  # Calculate progress\n            elite_size = int((self.elite_fraction + 0.1 * progress) * self.population_size)  # Modified line\n            elites = population[np.argsort(fitness)[:elite_size]]\n            for _ in range(self.population_size - elite_size):\n                parent1, parent2 = self.select_parents(population, fitness)\n                offspring = self.enhanced_quantum_crossover(parent1, parent2, lb, ub)\n                offspring = self.diverse_adaptive_mutation(offspring, lb, ub, progress)\n                new_population.append(offspring)\n            \n            new_population.extend(elites)\n            new_population = np.array(new_population)\n            new_fitness = np.array([func(ind) for ind in new_population])\n            evaluations += self.population_size\n            \n            population, fitness = self.selection(population, fitness, new_population, new_fitness)\n            current_best_idx = np.argmin(fitness)\n            if fitness[current_best_idx] < best_fitness:\n                best_solution, best_fitness = population[current_best_idx], fitness[current_best_idx]\n        \n        return best_solution, best_fitness\n    \n    def select_parents(self, population, fitness):\n        tournament_size = 3\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent1_idx = tournament_indices[np.argmin(tournament_fitness)]\n        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n        tournament_fitness = fitness[tournament_indices]\n        parent2_idx = tournament_indices[np.argmin(tournament_fitness)]\n        return population[parent1_idx], population[parent2_idx]\n    \n    def enhanced_quantum_crossover(self, parent1, parent2, lb, ub):\n        alpha_var = np.random.uniform(0.4, 0.6)\n        q1 = alpha_var * parent1 + (1 - alpha_var) * parent2\n        q2 = alpha_var * parent2 + (1 - alpha_var) * parent1\n        offspring = q1 if np.random.rand() < 0.5 else q2\n        offspring = np.clip(offspring, lb, ub)\n        return offspring\n    \n    def diverse_adaptive_mutation(self, individual, lb, ub, progress):\n        mutation_strength = 0.1 * (ub - lb) * np.random.random_sample(self.dim) * (1 - progress ** 1.5)\n        if np.random.random() < 0.5:\n            mutated = individual + np.random.normal(0, mutation_strength, self.dim)\n        else:\n            mutated = individual + np.random.uniform(-mutation_strength, mutation_strength, self.dim)\n        return np.clip(mutated, lb, ub)\n\n    def selection(self, population, fitness, new_population, new_fitness):\n        combined_population = np.vstack((population, new_population))\n        combined_fitness = np.concatenate((fitness, new_fitness))\n        sorted_indices = np.argsort(combined_fitness)\n        return combined_population[sorted_indices][:self.population_size], combined_fitness[sorted_indices][:self.population_size]", "name": "EHQEA", "description": "Introduces a dynamic elite fraction based on progress to balance exploration-exploitation.", "configspace": "", "generation": 16, "fitness": 0.9105969930448449, "feedback": "The algorithm EHQEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.911 with standard deviation 0.010. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "6860bf79-6e1a-465d-8255-03e48868b9d7", "metadata": {"aucs": [0.9033991822918027, 0.9039318231380525, 0.9244599737046792], "final_y": [0.1107187588171803, 0.11630349201998513, 0.11113996997973064]}, "mutation_prompt": null}
