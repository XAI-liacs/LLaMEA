{"id": "d3b7ebc2-f2f4-4d77-98e0-702c428671b7", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(population_size):\n                a, b, c = population[np.random.choice(population_size, 3, replace=False)]\n                mutant_vector = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n                cross_points = np.random.rand(self.dim) < CR\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_value = func(trial_vector)\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n        return res.x, res.fun\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        # Step 1: Perform Differential Evolution for global exploration\n        best_solution_de, best_value_de = self.differential_evolution(func, bounds)\n\n        # Step 2: Perform local optimization using BFGS from best DE solution\n        best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n\n        # Return the best found solution and its value\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "A hybrid metaheuristic algorithm combining Quasi-Oppositional Differential Evolution with local BFGS optimization to efficiently explore and exploit the search space, encouraging periodicity via tailored cost functions.", "configspace": "", "generation": 0, "fitness": 0.8759242082942892, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.876 with standard deviation 0.060. And the mean value of best solutions found was 0.192 (0. is the best) with standard deviation 0.018.", "error": "", "parent_id": null, "metadata": {"aucs": [0.8063191274665457, 0.953031405984128, 0.8684220914321934], "final_y": [0.21209171792107728, 0.16820001955891606, 0.19559360201596931]}, "mutation_prompt": null}
{"id": "5a397f83-cd4c-46d3-8bc9-f2fa885f778b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(population_size):\n                a, b, c = population[np.random.choice(population_size, 3, replace=False)]\n                mutant_vector = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n                cross_points = np.random.rand(self.dim) < (CR + np.random.rand() * 0.1)  # Adjusted line\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_value = func(trial_vector)\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n        return res.x, res.fun\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        # Step 1: Perform Differential Evolution for global exploration\n        best_solution_de, best_value_de = self.differential_evolution(func, bounds)\n\n        # Step 2: Perform local optimization using BFGS from best DE solution\n        best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n\n        # Return the best found solution and its value\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced exploration by dynamically adjusting the crossover rate (CR) in Differential Evolution.", "configspace": "", "generation": 1, "fitness": 0.8377472091634911, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.838 with standard deviation 0.086. And the mean value of best solutions found was 0.209 (0. is the best) with standard deviation 0.032.", "error": "", "parent_id": "d3b7ebc2-f2f4-4d77-98e0-702c428671b7", "metadata": {"aucs": [0.801979604720133, 0.9568314371565609, 0.7544305856137793], "final_y": [0.21821839956598432, 0.16717072492109386, 0.24282347529337867]}, "mutation_prompt": null}
{"id": "a080e622-fb68-4505-92a7-ca03c667ac77", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(population_size):\n                a, b, c = population[np.random.choice(population_size, 3, replace=False)]\n                mutant_vector = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n                cross_points = np.random.rand(self.dim) < CR * (1 - self.func_evals / self.budget)  # Adaptive CR\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_value = func(trial_vector)\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n        return res.x, res.fun\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        # Step 1: Perform Differential Evolution for global exploration\n        best_solution_de, best_value_de = self.differential_evolution(func, bounds)\n\n        # Step 2: Perform local optimization using BFGS from best DE solution\n        best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n\n        # Return the best found solution and its value\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "An enhanced hybrid metaheuristic combining Quasi-Oppositional Differential Evolution with local BFGS optimization, incorporating adaptive crossover rates for improved exploration and exploitation.", "configspace": "", "generation": 1, "fitness": 0.8138419158810768, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.814 with standard deviation 0.141. And the mean value of best solutions found was 0.223 (0. is the best) with standard deviation 0.068.", "error": "", "parent_id": "d3b7ebc2-f2f4-4d77-98e0-702c428671b7", "metadata": {"aucs": [0.9310949850918847, 0.6148974021024463, 0.8955333604488998], "final_y": [0.17281737004190145, 0.3185373583156972, 0.1779028563363263]}, "mutation_prompt": null}
{"id": "1f9462b8-396a-47fd-b8fc-0d7146494fa1", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(population_size):\n                a, b, c = population[np.random.choice(population_size, 3, replace=False)]\n                mutant_vector = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)  # Adaptive crossover rate\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_value = func(trial_vector)\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        x0 = 0.5 * (x0 + (bounds.ub + bounds.lb) / 2)  # Strategically adjust initial x0\n        res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n        return res.x, res.fun\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        # Step 1: Perform Differential Evolution for global exploration\n        best_solution_de, best_value_de = self.differential_evolution(func, bounds)\n\n        # Step 2: Perform local optimization using BFGS from best DE solution\n        best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n\n        # Return the best found solution and its value\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced hybrid metaheuristic algorithm using adaptive crossover rate in DE and strategic local BFGS initialization for improved performance.", "configspace": "", "generation": 1, "fitness": 0.9419244020392123, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.942 with standard deviation 0.020. And the mean value of best solutions found was 0.172 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "d3b7ebc2-f2f4-4d77-98e0-702c428671b7", "metadata": {"aucs": [0.9602373434738486, 0.9512643689910408, 0.9142714936527475], "final_y": [0.1658590832537803, 0.17458383738752414, 0.17675344394787018]}, "mutation_prompt": null}
{"id": "1ff2ece7-219d-48c1-8ccf-f1b5655efc06", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n        self.memory_bank = []  # Memory bank for best solutions\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def adaptive_mutation(self, a, b, c, F, bounds):\n        # Adaptive strategy based on success of previous mutations\n        return np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(population_size):\n                indices = np.random.choice(population_size, 3, replace=False)\n                a, b, c = population[indices]\n                mutant_vector = self.adaptive_mutation(a, b, c, F, bounds)\n                cross_points = np.random.rand(self.dim) < CR\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_value = func(trial_vector)\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                    self.memory_bank.append(best_solution)  # Store best solutions\n\n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n        return res.x, res.fun\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        # Step 1: Perform Differential Evolution for global exploration\n        best_solution_de, best_value_de = self.differential_evolution(func, bounds)\n\n        # Step 2: Perform local optimization using BFGS from best DE solution\n        best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n\n        # Return the best found solution and its value\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced hybrid metaheuristic optimizer combining Quasi-Oppositional Differential Evolution with adaptive mutation strategies and a memory bank of best solutions, supplemented by local BFGS optimization to effectively balance exploration and exploitation while maintaining periodicity.", "configspace": "", "generation": 1, "fitness": 0.8573755927475925, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.857 with standard deviation 0.094. And the mean value of best solutions found was 0.197 (0. is the best) with standard deviation 0.035.", "error": "", "parent_id": "d3b7ebc2-f2f4-4d77-98e0-702c428671b7", "metadata": {"aucs": [0.9416893715720327, 0.7262179088795797, 0.904219497791165], "final_y": [0.16996486826611534, 0.24627254454514735, 0.17341598517965806]}, "mutation_prompt": null}
{"id": "9c33bde2-959c-4a61-bcf1-bc0350fd867e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def adaptive_differential_evolution(self, func, bounds, population_size=12, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_value = float('inf')\n        best_solution = population[0]\n\n        while self.func_evals < self.budget:\n            for i in range(population_size):\n                a, b, c = population[np.random.choice(population_size, 3, replace=False)]\n                F = np.random.uniform(0.4, 0.9)  # Adaptive mutation factor\n                mutant_vector = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n                cross_points = np.random.rand(self.dim) < CR\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_value = func(trial_vector)\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def learning_based_local_bfgs(self, func, x0, bounds):\n        memory = [x0]\n        def enhanced_func(x):\n            memory.append(x)\n            return func(x)\n        \n        res = minimize(enhanced_func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n        return res.x if res.success else memory[-1], res.fun\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        # Step 1: Perform Adaptive Differential Evolution for global exploration\n        best_solution_de, best_value_de = self.adaptive_differential_evolution(func, bounds)\n\n        # Step 2: Perform Learning-based Local Optimization using BFGS\n        best_solution_bfgs, best_value_bfgs = self.learning_based_local_bfgs(func, best_solution_de, bounds)\n\n        return best_solution_bfgs, best_value_bfgs", "name": "EnhancedHybridOptimizer", "description": "An enhanced hybrid optimizer integrating Quasi-Oppositional DE with adaptive mutation and learning-based local BFGS, promoting modular periodicity and adaptive exploration.", "configspace": "", "generation": 1, "fitness": 0.8564176165746145, "feedback": "The algorithm EnhancedHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.856 with standard deviation 0.028. And the mean value of best solutions found was 0.177 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "d3b7ebc2-f2f4-4d77-98e0-702c428671b7", "metadata": {"aucs": [0.834889119639061, 0.8955576835407839, 0.8388060465439984], "final_y": [0.1822782895621965, 0.18263575564562307, 0.16515531535824024]}, "mutation_prompt": null}
{"id": "63aaadf2-10de-4383-959e-78a2c8364074", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        opp_factor = 0.4 + 0.2 * np.random.rand()  # Adaptive factor for better diversity\n        return (mid_point + range_ * (np.random.rand(self.dim) - opp_factor),\n                mid_point - range_ * (np.random.rand(self.dim) - opp_factor))\n\n    def differential_evolution(self, func, bounds, population_size=None, F=0.5, CR=0.9):\n        if population_size is None:\n            population_size = min(20, self.budget // (2 * self.dim))  # Dynamic population size based on budget\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(population_size):\n                a, b, c = population[np.random.choice(population_size, 3, replace=False)]\n                mutant_vector = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_value = func(trial_vector)\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        x0 = 0.5 * (x0 + (bounds.ub + bounds.lb) / 2)\n        res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n        return res.x, res.fun\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        best_solution_de, best_value_de = self.differential_evolution(func, bounds)\n\n        best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Refined hybrid metaheuristic using adaptive quasi-oppositional initialization and dynamic population sizing for improved exploration and exploitation balance.", "configspace": "", "generation": 2, "fitness": 0.848666035537053, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.849 with standard deviation 0.097. And the mean value of best solutions found was 0.203 (0. is the best) with standard deviation 0.041.", "error": "", "parent_id": "1f9462b8-396a-47fd-b8fc-0d7146494fa1", "metadata": {"aucs": [0.9354854335996939, 0.8976898543835538, 0.7128228186279111], "final_y": [0.1648897975213809, 0.18485656830038144, 0.2593703312646919]}, "mutation_prompt": null}
{"id": "dfc43e51-80e8-4278-898b-05de2970bdfa", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(population_size):\n                a, b, c = population[np.random.choice(population_size, 3, replace=False)]\n                mutant_vector = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget) + 0.1  # Slightly increased adaptive crossover rate\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_value = func(trial_vector)\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        x0 = 0.5 * (x0 + (bounds.ub + bounds.lb) / 2)  # Strategically adjust initial x0\n        res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n        return res.x, res.fun\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        # Step 1: Perform Differential Evolution for global exploration\n        best_solution_de, best_value_de = self.differential_evolution(func, bounds)\n\n        # Step 2: Perform local optimization using BFGS from best DE solution\n        best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n\n        # Return the best found solution and its value\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Adaptive hybrid metaheuristic with global Differential Evolution and local BFGS, employing quasi-oppositional initialization and improved strategic crossover for enhanced reflectivity optimization.", "configspace": "", "generation": 2, "fitness": 0.868574117990684, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.869 with standard deviation 0.035. And the mean value of best solutions found was 0.195 (0. is the best) with standard deviation 0.017.", "error": "", "parent_id": "1f9462b8-396a-47fd-b8fc-0d7146494fa1", "metadata": {"aucs": [0.8220640187117835, 0.8779513379505484, 0.90570699730972], "final_y": [0.2179210124021248, 0.19018783418675766, 0.1761941102082536]}, "mutation_prompt": null}
{"id": "ed04698f-b665-42dc-9eb2-904e5f90b242", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, F=0.5, CR=0.9):\n        population_size = int(10 + (self.budget - self.func_evals) / 10)  # Adaptive population size\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(population_size):\n                a, b, c = population[np.random.choice(population_size, 3, replace=False)]\n                mutant_vector = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)  # Adaptive crossover rate\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_value = func(trial_vector)\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        x0 = 0.5 * (x0 + (bounds.ub + bounds.lb) / 2)  # Strategically adjust initial x0\n        res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n        return res.x, res.fun\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        # Step 1: Perform Differential Evolution for global exploration\n        best_solution_de, best_value_de = self.differential_evolution(func, bounds)\n\n        # Step 2: Perform local optimization using BFGS from best DE solution\n        best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n\n        # Return the best found solution and its value\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Refined hybrid metaheuristic algorithm with adaptive population size in DE for enhanced exploration-exploitation balance.", "configspace": "", "generation": 2, "fitness": 0.8209179732628803, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.821 with standard deviation 0.136. And the mean value of best solutions found was 0.203 (0. is the best) with standard deviation 0.040.", "error": "", "parent_id": "1f9462b8-396a-47fd-b8fc-0d7146494fa1", "metadata": {"aucs": [0.628498147631379, 0.9196164682759717, 0.9146393038812903], "final_y": [0.25954024047653157, 0.17142919084623198, 0.1790109602375719]}, "mutation_prompt": null}
{"id": "790eca77-7510-48e9-bcfe-eeacd44ea9a3", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(population_size):\n                a, b, c = population[np.random.choice(population_size, 3, replace=False)]\n                mutant_vector = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)  # Adaptive crossover rate\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                # Encourage periodicity in solutions\n                trial_vector = np.round(trial_vector)  # Promote periodic solutions\n                trial_value = func(trial_vector)\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        x0 = 0.5 * (x0 + (bounds.ub + bounds.lb) / 2)  # Strategically adjust initial x0\n        res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n        return res.x, res.fun\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        # Step 1: Perform Differential Evolution for global exploration\n        best_solution_de, best_value_de = self.differential_evolution(func, bounds)\n\n        # Step 2: Early stopping if budget usage is below threshold\n        if self.func_evals < 0.8 * self.budget:\n            # Step 3: Perform local optimization using BFGS from best DE solution\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        # Return the best found solution and its value\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced metaheuristic with periodicity promotion and early stopping for improved convergence in black box optimization.", "configspace": "", "generation": 2, "fitness": 0.894965274972288, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.895 with standard deviation 0.035. And the mean value of best solutions found was 0.184 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "1f9462b8-396a-47fd-b8fc-0d7146494fa1", "metadata": {"aucs": [0.8690203848834492, 0.8714796711486728, 0.944395768884742], "final_y": [0.19718900495955072, 0.188301084668978, 0.16661747825089956]}, "mutation_prompt": null}
{"id": "51be2e83-b783-485f-b1ee-f35101cfe000", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(population_size):\n                a, b, c = population[np.random.choice(population_size, 3, replace=False)]\n                mutant_vector = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_value = func(trial_vector)\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n\n                # Dynamic scaling factor\n                if self.func_evals % (self.budget // 10) == 0:\n                    F = max(0.1, F * 0.9)\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        x0 = 0.5 * (x0 + (bounds.ub + bounds.lb) / 2)\n        res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n        return res.x, res.fun\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        # Step 1: Perform Differential Evolution for global exploration\n        best_solution_de, best_value_de = self.differential_evolution(func, bounds)\n\n        # Step 2: Perform local optimization using BFGS from best DE solution\n        best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n\n        # Return the best found solution and its value\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Improved hybrid metaheuristic algorithm using dynamic population and crossover scaling in DE with BFGS for enhanced global and local search capabilities.", "configspace": "", "generation": 2, "fitness": 0.831613713009717, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.832 with standard deviation 0.050. And the mean value of best solutions found was 0.209 (0. is the best) with standard deviation 0.021.", "error": "", "parent_id": "1f9462b8-396a-47fd-b8fc-0d7146494fa1", "metadata": {"aucs": [0.8810883280771626, 0.8503438717337829, 0.7634089392182056], "final_y": [0.18671455292990513, 0.20360225780166052, 0.23650430979071158]}, "mutation_prompt": null}
{"id": "171079d5-a791-43df-b589-6c5c905a5823", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(population_size):\n                a, b, c = population[np.random.choice(population_size, 3, replace=False)]\n                mutant_vector = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)  # Adaptive crossover rate\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                # Encourage periodicity in solutions\n                trial_vector = np.round(trial_vector)  # Promote periodic solutions\n                trial_value = func(trial_vector)\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n            \n            # Dynamic population size adjustment (1 line change)\n            population_size = min(population_size + 1, 20)\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        x0 = 0.5 * (x0 + (bounds.ub + bounds.lb) / 2)  # Strategically adjust initial x0\n        res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n        return res.x, res.fun\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        # Step 1: Perform Differential Evolution for global exploration\n        best_solution_de, best_value_de = self.differential_evolution(func, bounds)\n\n        # Step 2: Early stopping if budget usage is below threshold\n        if self.func_evals < 0.8 * self.budget:\n            # Step 3: Perform local optimization using BFGS from best DE solution\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        # Return the best found solution and its value\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced metaheuristic with dynamic population size adjustment to improve convergence in black box optimization.", "configspace": "", "generation": 3, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 10 is out of bounds for axis 0 with size 10').", "error": "IndexError('index 10 is out of bounds for axis 0 with size 10')", "parent_id": "790eca77-7510-48e9-bcfe-eeacd44ea9a3", "metadata": {}, "mutation_prompt": null}
{"id": "43ed3f14-6993-4df1-b39e-e9b4dc3f779b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n    \n    def landscape_smoothing(self, func, x, alpha=0.1):\n        perturbed = x + alpha * (np.random.rand(self.dim) - 0.5)\n        return (func(x) + func(perturbed)) / 2\n\n    def differential_evolution(self, func, bounds, population_size=12, F=0.6, CR=0.95):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(population_size):\n                a, b, c = population[np.random.choice(population_size, 3, replace=False)]\n                mutant_vector = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.round(trial_vector)\n                \n                trial_value = self.landscape_smoothing(func, trial_vector)\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        x0 = 0.5 * (x0 + (bounds.ub + bounds.lb) / 2)\n        res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n        return res.x, res.fun\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        best_solution_de, best_value_de = self.differential_evolution(func, bounds)\n\n        if self.func_evals < 0.8 * self.budget:\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Adaptive hybrid metaheuristic with periodicity constraints and fitness landscape smoothing for enhanced convergence in black box optimization.", "configspace": "", "generation": 3, "fitness": 0.9076558347369682, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.908 with standard deviation 0.016. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "790eca77-7510-48e9-bcfe-eeacd44ea9a3", "metadata": {"aucs": [0.9232923651709043, 0.9136225481558524, 0.8860525908841479], "final_y": [0.1649636716205104, 0.16690954584368634, 0.16694774279160984]}, "mutation_prompt": null}
{"id": "1417421d-f28e-4c8a-b479-fdd89af15c12", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(population_size):\n                a, b, c = population[np.random.choice(population_size, 3, replace=False)]\n                adaptive_F = F * (1 - self.func_evals / self.budget)  # Adaptive mutation factor\n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)  # Adaptive crossover rate\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                # Encourage periodicity in solutions\n                trial_vector = np.round(trial_vector)  # Promote periodic solutions\n                trial_value = func(trial_vector)\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        x0 = 0.5 * (x0 + (bounds.ub + bounds.lb) / 2)  # Strategically adjust initial x0\n        res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n        return res.x, res.fun\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        # Step 1: Perform Differential Evolution for global exploration\n        best_solution_de, best_value_de = self.differential_evolution(func, bounds)\n\n        # Step 2: Early stopping if budget usage is below threshold\n        if self.func_evals < 0.8 * self.budget:\n            # Step 3: Perform local optimization using BFGS from best DE solution\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        # Return the best found solution and its value\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Improved convergence by dynamically adjusting Differential Evolution's mutation factor based on the remaining budget.", "configspace": "", "generation": 3, "fitness": 0.9099459573656336, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.910 with standard deviation 0.042. And the mean value of best solutions found was 0.180 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "790eca77-7510-48e9-bcfe-eeacd44ea9a3", "metadata": {"aucs": [0.8611367004451398, 0.9636284143855476, 0.9050727572662135], "final_y": [0.19222529856169346, 0.1662767851119603, 0.1825142635697411]}, "mutation_prompt": null}
{"id": "317fbf02-6553-449a-839d-143963c9b98b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(population_size):\n                a, b, c = population[np.random.choice(population_size, 3, replace=False)]\n                mutant_vector = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)  # Adaptive crossover rate\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                # Encourage periodicity in solutions with adaptive adjustment\n                trial_vector = np.round(trial_vector * (1 + 0.1 * np.sin(2 * np.pi * self.func_evals / self.budget)))\n                trial_value = func(trial_vector)\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        x0 = 0.5 * (x0 + (bounds.ub + bounds.lb) / 2)  # Strategically adjust initial x0\n        res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n        return res.x, res.fun\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        # Step 1: Perform Differential Evolution for global exploration\n        best_solution_de, best_value_de = self.differential_evolution(func, bounds)\n\n        # Step 2: Early stopping if budget usage is below threshold\n        if self.func_evals < 0.8 * self.budget:\n            # Step 3: Perform local optimization using BFGS from best DE solution\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        # Return the best found solution and its value\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced metaheuristic optimizer with adaptive periodicity enforcement for improved convergence in black box optimization.", "configspace": "", "generation": 3, "fitness": 0.7272503280359679, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.727 with standard deviation 0.096. And the mean value of best solutions found was 0.234 (0. is the best) with standard deviation 0.062.", "error": "", "parent_id": "790eca77-7510-48e9-bcfe-eeacd44ea9a3", "metadata": {"aucs": [0.7225216275917321, 0.6120291454951314, 0.8472002110210402], "final_y": [0.19003017217649143, 0.3207484959594884, 0.18974537053289342]}, "mutation_prompt": null}
{"id": "1ba3fe6f-5d93-4cc3-ba6e-f592380698e7", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(population_size):\n                a, b, c = population[np.random.choice(population_size, 3, replace=False)]\n                # Introduce stochastic adaptation in mutation scaling\n                F_dynamic = F + np.random.normal(0, 0.1 * F)\n                mutant_vector = np.clip(a + F_dynamic * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)  # Adaptive crossover rate\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                # Encourage periodicity in solutions\n                trial_vector = np.round(trial_vector)  # Promote periodic solutions\n                trial_value = func(trial_vector)\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        x0 = 0.5 * (x0 + (bounds.ub + bounds.lb) / 2)  # Strategically adjust initial x0\n        res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n        return res.x, res.fun\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        # Step 1: Perform Differential Evolution for global exploration\n        best_solution_de, best_value_de = self.differential_evolution(func, bounds)\n\n        # Step 2: Early stopping if budget usage is below threshold\n        if self.func_evals < 0.8 * self.budget:\n            # Step 3: Perform local optimization using BFGS from best DE solution\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        # Return the best found solution and its value\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Introduced stochastic adaptive mutation scaling to enhance exploration and convergence in black box optimization.", "configspace": "", "generation": 3, "fitness": 0.8658360625482714, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.866 with standard deviation 0.045. And the mean value of best solutions found was 0.190 (0. is the best) with standard deviation 0.019.", "error": "", "parent_id": "790eca77-7510-48e9-bcfe-eeacd44ea9a3", "metadata": {"aucs": [0.9286952479479452, 0.8313047711120721, 0.8375081685847969], "final_y": [0.16561165562170754, 0.19452375970184554, 0.21110697814569146]}, "mutation_prompt": null}
{"id": "7023d2da-2535-4d68-9821-6f1a70caa141", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(population_size):\n                a, b, c = population[np.random.choice(population_size, 3, replace=False)]\n                adaptive_F = F * (1 - self.func_evals / self.budget)  # Adaptive mutation factor\n                adaptive_F = max(0.1, adaptive_F)  # Ensure mutation factor doesn't drop too low\n                \n                # Dynamic population size adjustment\n                if self.func_evals % (self.budget // 10) == 0:\n                    population_size = max(4, int(population_size * 0.9))\n                    population = population[:population_size]\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)  # Adaptive crossover rate\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.round(trial_vector)  # Promote periodic solutions\n                trial_value = func(trial_vector)\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        x0 = 0.5 * (x0 + (bounds.ub + bounds.lb) / 2)  # Strategically adjust initial x0\n        res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n        return res.x, res.fun\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        # Step 1: Perform Differential Evolution for global exploration\n        best_solution_de, best_value_de = self.differential_evolution(func, bounds)\n\n        # Step 2: Early stopping if budget usage is below threshold\n        if self.func_evals < 0.8 * self.budget:\n            # Step 3: Perform local optimization using BFGS from best DE solution\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        # Return the best found solution and its value\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced exploration by introducing dynamic population size and adaptive mutation strategies in Differential Evolution.", "configspace": "", "generation": 4, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 9 is out of bounds for axis 0 with size 9').", "error": "IndexError('index 9 is out of bounds for axis 0 with size 9')", "parent_id": "1417421d-f28e-4c8a-b479-fdd89af15c12", "metadata": {}, "mutation_prompt": null}
{"id": "4b6c615f-1577-4471-a9a6-e9aaeafbe200", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(population_size):\n                a, b, c = population[np.random.choice(population_size, 3, replace=False)]\n                adaptive_F = F * (1 - (self.func_evals ** 0.5) / (self.budget ** 0.5))  # Adjusted adaptive mutation factor\n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - (self.func_evals ** 0.5) / (self.budget ** 0.5))  # Adjusted adaptive crossover rate\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.round(trial_vector)  # Promote periodic solutions\n                trial_value = func(trial_vector)\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        x0 = 0.5 * (x0 + (bounds.ub + bounds.lb) / 2)\n        res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n        return res.x, res.fun\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        best_solution_de, best_value_de = self.differential_evolution(func, bounds)\n\n        if self.func_evals < 0.8 * self.budget:\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced adaptiveness in mutation and crossover rates for improved convergence using DE and local optimization.", "configspace": "", "generation": 4, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 9 is out of bounds for axis 0 with size 9').", "error": "IndexError('index 9 is out of bounds for axis 0 with size 9')", "parent_id": "1417421d-f28e-4c8a-b479-fdd89af15c12", "metadata": {}, "mutation_prompt": null}
{"id": "c6a8b3e7-9e97-4f01-8ab9-58339e6cdead", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(population_size):\n                a, b, c = population[np.random.choice(population_size, 3, replace=False)]\n                adaptive_F = F * (1 - self.func_evals / self.budget)  # Adaptive mutation factor\n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)  # Adaptive crossover rate\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_value = func(trial_vector)\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                # Adaptive Selection Strategy: Replace less fit individuals based on budget\n                elif np.random.rand() < (1 - self.func_evals / self.budget):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        x0 = 0.5 * (x0 + (bounds.ub + bounds.lb) / 2)  # Strategically adjust initial x0\n        res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n        return res.x, res.fun\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        # Step 1: Perform Differential Evolution for global exploration\n        best_solution_de, best_value_de = self.differential_evolution(func, bounds)\n\n        # Step 2: Early stopping if budget usage is below threshold\n        if self.func_evals < 0.8 * self.budget:\n            # Step 3: Perform local optimization using BFGS from best DE solution\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        # Return the best found solution and its value\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Enhance convergence by altering Differential Evolution's selection strategy based on the budget.", "configspace": "", "generation": 4, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 9 is out of bounds for axis 0 with size 9').", "error": "IndexError('index 9 is out of bounds for axis 0 with size 9')", "parent_id": "1417421d-f28e-4c8a-b479-fdd89af15c12", "metadata": {}, "mutation_prompt": null}
{"id": "38803aa4-b2e0-4eac-8112-a6cf644affd1", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(population_size):\n                a, b, c = population[np.random.choice(population_size, 3, replace=False)]\n                adaptive_F = F * (1 - self.func_evals / self.budget)  # Adaptive mutation factor\n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = (CR * (1 - self.func_evals / self.budget))  # Adaptive crossover rate\n                cross_points = np.random.rand(self.dim) < CR_dynamic * np.cos(2 * np.pi * self.func_evals / self.budget)  # Periodic adjustment factor\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                # Encourage periodicity in solutions\n                trial_vector = np.round(trial_vector)  # Promote periodic solutions\n                trial_value = func(trial_vector)\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        x0 = 0.5 * (x0 + (bounds.ub + bounds.lb) / 2)  # Strategically adjust initial x0\n        res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n        return res.x, res.fun\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        # Step 1: Perform Differential Evolution for global exploration\n        best_solution_de, best_value_de = self.differential_evolution(func, bounds)\n\n        # Step 2: Early stopping if budget usage is below threshold\n        if self.func_evals < 0.8 * self.budget:\n            # Step 3: Perform local optimization using BFGS from best DE solution\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        # Return the best found solution and its value\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Improved convergence by incorporating periodic adjustment factor in Differential Evolution's crossover rate.", "configspace": "", "generation": 4, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 9 is out of bounds for axis 0 with size 9').", "error": "IndexError('index 9 is out of bounds for axis 0 with size 9')", "parent_id": "1417421d-f28e-4c8a-b479-fdd89af15c12", "metadata": {}, "mutation_prompt": null}
{"id": "1ab5e5fa-56d6-496d-8b37-fb27c1a26a17", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n        self.best_solution_history = None  # Initialize history to store best solutions\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(population_size):\n                a, b, c = population[np.random.choice(population_size, 3, replace=False)]\n                adaptive_F = F * (1 - self.func_evals / self.budget)  # Adaptive mutation factor\n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)  # Adaptive crossover rate\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                # Encourage periodicity in solutions\n                trial_vector = np.round(trial_vector)  # Promote periodic solutions\n                trial_value = func(trial_vector)\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                    self.best_solution_history = trial_vector  # Update history with best solution\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        if self.best_solution_history is not None:\n            x0 = 0.5 * (x0 + self.best_solution_history)  # Merge with historical best\n        res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n        return res.x, res.fun\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        # Step 1: Perform Differential Evolution for global exploration\n        best_solution_de, best_value_de = self.differential_evolution(func, bounds)\n\n        # Step 2: Early stopping if budget usage is below threshold\n        if self.func_evals < 0.8 * self.budget:\n            # Step 3: Perform local optimization using BFGS from best DE solution\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        # Return the best found solution and its value\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced local search initialization by incorporating historical best solutions to improve convergence.", "configspace": "", "generation": 4, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 9 is out of bounds for axis 0 with size 9').", "error": "IndexError('index 9 is out of bounds for axis 0 with size 9')", "parent_id": "1417421d-f28e-4c8a-b479-fdd89af15c12", "metadata": {}, "mutation_prompt": null}
{"id": "ab8359b8-fdb1-48d1-967e-299c9c45552e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(population_size):\n                a, b, c = population[np.random.choice(population_size, 3, replace=False)]\n                adaptive_F = F * (1 - self.func_evals / self.budget)  # Adaptive mutation factor\n                adaptive_F = max(0.1, adaptive_F)  # Ensure mutation factor doesn't drop too low\n                \n                # Dynamic population size adjustment\n                if self.func_evals % (self.budget // 10) == 0:\n                    population_size = max(4, int(population_size * 0.9))\n                    population = population[:population_size]\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)  # Adaptive crossover rate\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.round(trial_vector)  # Promote periodic solutions\n                trial_value = func(trial_vector)\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        x0 = np.clip(0.5 * (x0 + (bounds.ub + bounds.lb) / 2), bounds.lb, bounds.ub)  # Adjust x0 within bounds\n        res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n        return res.x, res.fun\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        # Step 1: Perform Differential Evolution for global exploration\n        best_solution_de, best_value_de = self.differential_evolution(func, bounds)\n\n        # Step 2: Early stopping if budget usage is below threshold\n        if self.func_evals < 0.8 * self.budget:\n            # Step 3: Perform local optimization using BFGS from best DE solution\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        # Return the best found solution and its value\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Improved local optimization stability by ensuring initial guess is within bounds, enhancing convergence reliability.", "configspace": "", "generation": 5, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 9 is out of bounds for axis 0 with size 9').", "error": "IndexError('index 9 is out of bounds for axis 0 with size 9')", "parent_id": "7023d2da-2535-4d68-9821-6f1a70caa141", "metadata": {}, "mutation_prompt": null}
{"id": "1d17456e-f282-4fc8-8509-4de2d89e337a", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(population_size):\n                a, b, c = population[np.random.choice(population_size, 3, replace=False)]\n                adaptive_F = F * (1 - self.func_evals / self.budget)  # Adaptive mutation factor\n                adaptive_F = max(0.1, adaptive_F)  # Ensure mutation factor doesn't drop too low\n                \n                if self.func_evals % (self.budget // 10) == 0:\n                    population_size = max(4, int(population_size * 0.9))\n                    population = population[:min(population_size, len(population))]  # Ensure no index out of bounds\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)  # Adaptive crossover rate\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.round(trial_vector)  # Promote periodic solutions\n                trial_value = func(trial_vector)\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        x0 = 0.5 * (x0 + (bounds.ub + bounds.lb) / 2)  # Strategically adjust initial x0\n        res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n        return res.x, res.fun\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        # Step 1: Perform Differential Evolution for global exploration\n        best_solution_de, best_value_de = self.differential_evolution(func, bounds)\n\n        # Step 2: Early stopping if budget usage is below threshold\n        if self.func_evals < 0.8 * self.budget:\n            # Step 3: Perform local optimization using BFGS from best DE solution\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        # Return the best found solution and its value\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Improved adaptive strategy in Differential Evolution by ensuring population size adjustment doesn't cause index out of bounds error.", "configspace": "", "generation": 5, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 9 is out of bounds for axis 0 with size 9').", "error": "IndexError('index 9 is out of bounds for axis 0 with size 9')", "parent_id": "7023d2da-2535-4d68-9821-6f1a70caa141", "metadata": {}, "mutation_prompt": null}
{"id": "5ac442bb-aa97-481f-a022-f0cd0c389495", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(len(population)):  # Change 1: Ensure valid index access\n                a, b, c = population[np.random.choice(len(population), 3, replace=False)]  # Change 2\n                adaptive_F = F * (1 - self.func_evals / self.budget)  # Adaptive mutation factor\n                adaptive_F = max(0.1, adaptive_F)  # Ensure mutation factor doesn't drop too low\n                \n                # Dynamic population size adjustment\n                if self.func_evals % (self.budget // 10) == 0 and len(population) > 4:  # Change 3\n                    population_size = max(4, int(len(population) * 0.9))\n                    population = population[:population_size]\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)  # Adaptive crossover rate\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.round(trial_vector)  # Promote periodic solutions\n                trial_value = func(trial_vector)\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        x0 = 0.5 * (x0 + (bounds.ub + bounds.lb) / 2)  # Strategically adjust initial x0\n        res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n        return res.x, res.fun\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        # Step 1: Perform Differential Evolution for global exploration\n        best_solution_de, best_value_de = self.differential_evolution(func, bounds)\n\n        # Step 2: Early stopping if budget usage is below threshold\n        if self.func_evals < 0.8 * self.budget:\n            # Step 3: Perform local optimization using BFGS from best DE solution\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        # Return the best found solution and its value\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Improved solution robustness by ensuring valid index access and maintaining population integrity.", "configspace": "", "generation": 5, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 9 is out of bounds for axis 0 with size 9').", "error": "IndexError('index 9 is out of bounds for axis 0 with size 9')", "parent_id": "7023d2da-2535-4d68-9821-6f1a70caa141", "metadata": {}, "mutation_prompt": null}
{"id": "c5e3c113-70d1-42ff-ab4d-92eaeb33d718", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(population_size):\n                a, b, c = population[np.random.choice(population_size, 3, replace=False)]\n                adaptive_F = F * (1 - self.func_evals / self.budget)\n                adaptive_F = max(0.1, adaptive_F)\n                \n                if self.func_evals % (self.budget // 10) == 0:\n                    population_size = max(4, min(population_size, len(population)))  # Ensure size within bounds\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.round(trial_vector)  # Promote periodic solutions\n                trial_value = func(trial_vector)\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        x0 = 0.5 * (x0 + (bounds.ub + bounds.lb) / 2)\n        res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n        return res.x, res.fun\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        best_solution_de, best_value_de = self.differential_evolution(func, bounds)\n\n        if self.func_evals < 0.8 * self.budget:\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Improved robustness by adjusting dynamic population size and ensuring boundary handling in Differential Evolution.", "configspace": "", "generation": 5, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 9 is out of bounds for axis 0 with size 9').", "error": "IndexError('index 9 is out of bounds for axis 0 with size 9')", "parent_id": "7023d2da-2535-4d68-9821-6f1a70caa141", "metadata": {}, "mutation_prompt": null}
{"id": "54e2ecf6-a59c-42e0-9c75-9a311f970fd6", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=20, F=0.6, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(population_size):\n                a, b, c = population[np.random.choice(population_size, 3, replace=False)]\n                adaptive_F = F * (1 - self.func_evals / self.budget) + 0.2  # Increase adaptive factor range\n                adaptive_F = max(0.1, min(0.9, adaptive_F))  # Ensure mutation factor stays within bounds\n                \n                # Dynamic population size adjustment\n                if self.func_evals % (self.budget // 8) == 0:  # Adjust frequency\n                    population_size = max(4, int(population_size * 0.85))\n                    population = population[:population_size]\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget) + 0.1  # Adjust crossover range\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.round(trial_vector)  # Promote periodic solutions\n                trial_value = func(trial_vector)\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        x0 = 0.7 * x0 + 0.3 * (bounds.ub + bounds.lb) / 2  # Refine initial x0 adjustment\n        res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n        return res.x, res.fun\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        # Step 1: Perform Differential Evolution for global exploration\n        best_solution_de, best_value_de = self.differential_evolution(func, bounds)\n\n        # Step 2: Early stopping if budget usage is below threshold\n        if self.func_evals < 0.9 * self.budget:  # Adjust threshold\n            # Step 3: Perform local optimization using BFGS from best DE solution\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        # Return the best found solution and its value\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Multi-strategy modular algorithm combining dynamic population, adaptive mutation, and periodicity in DE, with improved adaptive BFGS for local refinement.", "configspace": "", "generation": 5, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 17 is out of bounds for axis 0 with size 17').", "error": "IndexError('index 17 is out of bounds for axis 0 with size 17')", "parent_id": "7023d2da-2535-4d68-9821-6f1a70caa141", "metadata": {}, "mutation_prompt": null}
{"id": "163d17f2-77f3-4aa4-8313-ef54f30d0d62", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(population_size):\n                a, b, c = population[np.random.choice(population_size, 3, replace=False)]\n                adaptive_F = F * (1 - self.func_evals / self.budget)  # Adaptive mutation factor\n                adaptive_F = max(0.1, adaptive_F)  # Ensure mutation factor doesn't drop too low\n                \n                # Dynamic population size adjustment\n                if self.func_evals % (self.budget // 10) == 0:\n                    population_size = max(4, int(population_size * 0.8))  # Adjusting scaling factor from 0.9 to 0.8\n                    population = population[:population_size]\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)  # Adaptive crossover rate\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.round(trial_vector)  # Promote periodic solutions\n                trial_value = func(trial_vector)\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        x0 = np.clip(0.5 * (x0 + (bounds.ub + bounds.lb) / 2), bounds.lb, bounds.ub)  # Adjust x0 within bounds\n        res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n        return res.x, res.fun\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        # Step 1: Perform Differential Evolution for global exploration\n        best_solution_de, best_value_de = self.differential_evolution(func, bounds)\n\n        # Step 2: Early stopping if budget usage is below threshold\n        if self.func_evals < 0.8 * self.budget:  # Adjust threshold from 0.8 to 0.85\n            # Step 3: Perform local optimization using BFGS from best DE solution\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        # Return the best found solution and its value\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Improved global exploration by adjusting population sampling and enhanced stability with dynamic resource allocation.", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 8 is out of bounds for axis 0 with size 8').", "error": "IndexError('index 8 is out of bounds for axis 0 with size 8')", "parent_id": "ab8359b8-fdb1-48d1-967e-299c9c45552e", "metadata": {}, "mutation_prompt": null}
{"id": "a4c25484-af13-4c54-8bb9-0fe7e5185a37", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(population_size):\n                indices = np.random.choice(population_size, 3, replace=False)\n                a, b, c = population[indices]\n                adaptive_F = F * (1 - self.func_evals / self.budget)  # Adaptive mutation factor\n                adaptive_F = max(0.1, adaptive_F)  # Ensure mutation factor doesn't drop too low\n                \n                # Dynamic population size adjustment\n                if self.func_evals % (self.budget // 10) == 0:\n                    population_size = max(4, int(population_size * 0.9))\n                    population = population[:population_size]\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)  # Adaptive crossover rate\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.round(trial_vector)  # Promote periodic solutions\n                trial_value = func(trial_vector)\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        x0 = np.clip(0.5 * (x0 + (bounds.ub + bounds.lb) / 2), bounds.lb, bounds.ub)  # Adjust x0 within bounds\n        res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n        return res.x, res.fun\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        # Step 1: Perform Differential Evolution for global exploration\n        best_solution_de, best_value_de = self.differential_evolution(func, bounds)\n\n        # Step 2: Early stopping if budget usage is below threshold\n        if self.func_evals < 0.8 * self.budget:\n            # Step 3: Perform local optimization using BFGS from best DE solution\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        # Return the best found solution and its value\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Introduced a safeguard to ensure the selection of unique indices in DE, preventing the IndexError by ensuring selected indices are within bounds.", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 9 is out of bounds for axis 0 with size 9').", "error": "IndexError('index 9 is out of bounds for axis 0 with size 9')", "parent_id": "ab8359b8-fdb1-48d1-967e-299c9c45552e", "metadata": {}, "mutation_prompt": null}
{"id": "8db641e6-9ee5-4851-8ed7-f20fe4fb662d", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(population_size):\n                a, b, c = population[np.random.choice(population_size, 3, replace=False)]\n                adaptive_F = F * (1 - self.func_evals / self.budget)  # Adaptive mutation factor\n                adaptive_F = max(0.1, adaptive_F)  # Ensure mutation factor doesn't drop too low\n                \n                # Dynamic population size adjustment\n                if self.func_evals % (self.budget // 10) == 0:\n                    population_size = max(4, int(population_size * 0.9))\n                    # Reset population to avoid index errors\n                    population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)  # Adaptive crossover rate\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.round(trial_vector)  # Promote periodic solutions\n                trial_value = func(trial_vector)\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        x0 = np.clip(0.5 * (x0 + (bounds.ub + bounds.lb) / 2), bounds.lb, bounds.ub)  # Adjust x0 within bounds\n        res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n        return res.x, res.fun\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        # Step 1: Perform Differential Evolution for global exploration\n        best_solution_de, best_value_de = self.differential_evolution(func, bounds)\n\n        # Step 2: Early stopping if budget usage is below threshold\n        if self.func_evals < 0.8 * self.budget:\n            # Step 3: Perform local optimization using BFGS from best DE solution\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        # Return the best found solution and its value\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Improved dynamic population handling by resetting population size after shrinkage to avoid index errors.", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 9 is out of bounds for axis 0 with size 9').", "error": "IndexError('index 9 is out of bounds for axis 0 with size 9')", "parent_id": "ab8359b8-fdb1-48d1-967e-299c9c45552e", "metadata": {}, "mutation_prompt": null}
{"id": "1ecef794-c5a2-4255-86aa-81db64dd93f9", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(population_size):\n                a, b, c = population[np.random.choice(population_size, 3, replace=False)]\n                adaptive_F = F * (1 - self.func_evals / self.budget)  # Adaptive mutation factor\n                adaptive_F = max(0.1, adaptive_F)  # Ensure mutation factor doesn't drop too low\n                \n                # Dynamic population size adjustment\n                if self.func_evals % (self.budget // 10) == 0:\n                    population_size = max(4, int(population_size * 0.9))\n                    population = population[:population_size]\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)  # Adaptive crossover rate\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.round(trial_vector)  # Promote periodic solutions\n                if np.random.rand() < 0.5:  # Adjust mutant_vector promotion\n                    trial_vector = np.round(trial_vector)\n                trial_value = func(trial_vector)\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        x0 = np.clip(0.5 * (x0 + (bounds.ub + bounds.lb) / 2), bounds.lb, bounds.ub)  # Adjust x0 within bounds\n        res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n        return res.x, res.fun\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        # Step 1: Perform Differential Evolution for global exploration\n        best_solution_de, best_value_de = self.differential_evolution(func, bounds)\n\n        # Step 2: Early stopping if budget usage is below threshold\n        if self.func_evals < 0.8 * self.budget:\n            # Step 3: Perform local optimization using BFGS from best DE solution\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        # Return the best found solution and its value\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced periodicity promotion by rounding trial vectors and adjusted mutant vector selection to improve global exploration and convergence to optimal solutions.", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 9 is out of bounds for axis 0 with size 9').", "error": "IndexError('index 9 is out of bounds for axis 0 with size 9')", "parent_id": "ab8359b8-fdb1-48d1-967e-299c9c45552e", "metadata": {}, "mutation_prompt": null}
{"id": "949746bb-853d-4edb-8683-242cf3e74d8e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(population_size):\n                indices = np.random.choice(population_size, 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                adaptive_F = F * (1 - self.func_evals / self.budget)  # Adaptive mutation factor\n                adaptive_F = max(0.1, adaptive_F)  # Ensure mutation factor doesn't drop too low\n                \n                # Dynamic population size adjustment\n                if self.func_evals % (self.budget // 10) == 0:\n                    population_size = max(4, int(population_size * 0.9))\n                    population = population[:population_size]\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)  # Adaptive crossover rate\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.round(trial_vector)  # Promote periodic solutions\n                trial_value = func(trial_vector)\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        x0 = np.clip(0.5 * (x0 + (bounds.ub + bounds.lb) / 2), bounds.lb, bounds.ub)  # Adjust x0 within bounds\n        res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n        return res.x, res.fun\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        # Step 1: Perform Differential Evolution for global exploration\n        best_solution_de, best_value_de = self.differential_evolution(func, bounds)\n\n        # Step 2: Early stopping if budget usage is below threshold\n        if self.func_evals < 0.8 * self.budget:\n            # Step 3: Perform local optimization using BFGS from best DE solution\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        # Return the best found solution and its value\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Improved mutation strategy by ensuring selection of distinct individuals in Differential Evolution.", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 9 is out of bounds for axis 0 with size 9').", "error": "IndexError('index 9 is out of bounds for axis 0 with size 9')", "parent_id": "ab8359b8-fdb1-48d1-967e-299c9c45552e", "metadata": {}, "mutation_prompt": null}
{"id": "21d6c6e8-3863-407b-b6df-afb5097cb85c", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(population_size):\n                a, b, c = population[np.random.choice(population_size, 3, replace=False)]\n                adaptive_F = F * (1 - self.func_evals / self.budget)  # Adaptive mutation factor\n                adaptive_F = max(0.2, adaptive_F)  # Ensure mutation factor doesn't drop too low (change 1)\n                \n                # Adjust dynamic population size within the loop\n                if self.func_evals % (self.budget // 10) == 0:\n                    population_size = min(10, max(4, int(population_size * 0.85)))  # Adjust scaling factor (change 2)\n                    population = population[:population_size]\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)  # Adaptive crossover rate\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.round(trial_vector)  # Promote periodic solutions\n                trial_value = func(trial_vector)\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        x0 = np.clip(0.5 * (x0 + (bounds.ub + bounds.lb) / 2), bounds.lb, bounds.ub)  # Adjust x0 within bounds\n        res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n        return res.x, res.fun\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        # Step 1: Perform Differential Evolution for global exploration\n        best_solution_de, best_value_de = self.differential_evolution(func, bounds)\n\n        # Step 2: Early stopping if budget usage is below threshold\n        if self.func_evals < 0.85 * self.budget:  # Adjust threshold (change 3)\n            # Step 3: Perform local optimization using BFGS from best DE solution\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        # Return the best found solution and its value\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced exploration and exploitation balance by adjusting population size and mutation factor adaptively.", "configspace": "", "generation": 7, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 8 is out of bounds for axis 0 with size 8').", "error": "IndexError('index 8 is out of bounds for axis 0 with size 8')", "parent_id": "163d17f2-77f3-4aa4-8313-ef54f30d0d62", "metadata": {}, "mutation_prompt": null}
{"id": "900ba2f7-a82d-4ddc-b165-aab24268a176", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(population_size):\n                a, b, c = population[np.random.choice(population_size, 3, replace=False)]\n                adaptive_F = F * (1 - self.func_evals / (2 * self.budget))  # Adjusted adaptive mutation factor\n                adaptive_F = max(0.1, adaptive_F)  # Ensure mutation factor doesn't drop too low\n                \n                # Dynamic population size adjustment\n                if self.func_evals % (self.budget // 10) == 0:\n                    population_size = max(4, int(population_size * 0.8))  # Adjusting scaling factor from 0.9 to 0.8\n                    population = population[:population_size]\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)  # Adaptive crossover rate\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.round(trial_vector) % (bounds.ub - bounds.lb) + bounds.lb  # Improved periodic solution handling\n                trial_value = func(trial_vector)\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        x0 = np.clip(0.5 * (x0 + (bounds.ub + bounds.lb) / 2), bounds.lb, bounds.ub)  # Adjust x0 within bounds\n        res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n        return res.x, res.fun\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        # Step 1: Perform Differential Evolution for global exploration\n        best_solution_de, best_value_de = self.differential_evolution(func, bounds)\n\n        # Step 2: Early stopping if budget usage is below threshold\n        if self.func_evals < 0.8 * self.budget:  # Adjust threshold from 0.8 to 0.85\n            # Step 3: Perform local optimization using BFGS from best DE solution\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        # Return the best found solution and its value\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced convergence speed and accuracy by dynamic mutation factor adjustment and improved periodic solution handling.", "configspace": "", "generation": 7, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 8 is out of bounds for axis 0 with size 8').", "error": "IndexError('index 8 is out of bounds for axis 0 with size 8')", "parent_id": "163d17f2-77f3-4aa4-8313-ef54f30d0d62", "metadata": {}, "mutation_prompt": null}
{"id": "32643c6d-ce24-464c-b27d-e1d231761f9d", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(population_size):\n                if population_size >= 3:  # Ensure sufficient population for selection\n                    a, b, c = population[np.random.choice(population_size, 3, replace=False)]\n                else:\n                    continue\n                \n                adaptive_F = F * (1 - self.func_evals / self.budget)  # Adaptive mutation factor\n                adaptive_F = max(0.1, adaptive_F)  # Ensure mutation factor doesn't drop too low\n                \n                # Dynamic population size adjustment\n                if self.func_evals % (self.budget // 10) == 0:\n                    population_size = max(4, int(population_size * 0.8))  # Adjusting scaling factor from 0.9 to 0.8\n                    population = population[:population_size]\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)  # Adaptive crossover rate\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.round(trial_vector)  # Promote periodic solutions\n                trial_value = func(trial_vector)\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        x0 = np.clip(0.5 * (x0 + (bounds.ub + bounds.lb) / 2), bounds.lb, bounds.ub)  # Adjust x0 within bounds\n        res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n        return res.x, res.fun\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        # Step 1: Perform Differential Evolution for global exploration\n        best_solution_de, best_value_de = self.differential_evolution(func, bounds)\n\n        # Step 2: Early stopping if budget usage is below threshold\n        if self.func_evals < 0.8 * self.budget:  # Adjust threshold from 0.8 to 0.85\n            # Step 3: Perform local optimization using BFGS from best DE solution\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        # Return the best found solution and its value\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced stability by increasing robustness to ensure adequate sizing of selected arrays.", "configspace": "", "generation": 7, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 8 is out of bounds for axis 0 with size 8').", "error": "IndexError('index 8 is out of bounds for axis 0 with size 8')", "parent_id": "163d17f2-77f3-4aa4-8313-ef54f30d0d62", "metadata": {}, "mutation_prompt": null}
{"id": "238aeb9c-8bd3-412d-8cec-ecda0bb04a7a", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        # Change 1: Fixing initialization strategy to prevent out-of-bound issues\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return np.clip(mid_point + range_ * (np.random.rand(self.dim) - 0.5), bounds.lb, bounds.ub), \\\n               np.clip(mid_point - range_ * (np.random.rand(self.dim) - 0.5), bounds.lb, bounds.ub)\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(population_size):\n                a, b, c = population[np.random.choice(population_size, 3, replace=False)]\n                adaptive_F = F * (1 - self.func_evals / self.budget)\n                adaptive_F = max(0.1, adaptive_F)\n                \n                # Change 2: Correcting the dynamic population adjustment to avoid indexing issues\n                if self.func_evals % (self.budget // 10) == 0 and len(population) > 4:\n                    population_size = max(4, int(len(population) * 0.8))\n                    population = population[:population_size]\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.round(trial_vector)  # Promote periodic solutions\n                trial_value = func(trial_vector)\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        x0 = np.clip(0.5 * (x0 + (bounds.ub + bounds.lb) / 2), bounds.lb, bounds.ub)\n        res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n        return res.x, res.fun\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        # Step 1: Perform Differential Evolution for global exploration\n        best_solution_de, best_value_de = self.differential_evolution(func, bounds)\n\n        # Step 2: Early stopping if budget usage is below threshold\n        if self.func_evals < 0.8 * self.budget:\n            # Step 3: Perform local optimization using BFGS from best DE solution\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        # Return the best found solution and its value\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced stability and performance by fine-tuning adaptive mechanisms in DE and improving initialization strategy for robust optimization.", "configspace": "", "generation": 7, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 8 is out of bounds for axis 0 with size 8').", "error": "IndexError('index 8 is out of bounds for axis 0 with size 8')", "parent_id": "163d17f2-77f3-4aa4-8313-ef54f30d0d62", "metadata": {}, "mutation_prompt": null}
{"id": "176e3166-15d8-4057-bd1a-203773765e52", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(population_size):\n                a, b, c = population[np.random.choice(population_size, 3, replace=False)]\n                adaptive_F = F * (1 - self.func_evals / self.budget)  # Adaptive mutation factor\n                adaptive_F = max(0.1, adaptive_F)  # Ensure mutation factor doesn't drop too low\n                \n                # Dynamic population size adjustment\n                if self.func_evals % (self.budget // 10) == 0:\n                    population_size = max(4, int(population_size * 0.9))  # Changed scaling factor back to 0.9\n                    population = population[:population_size]\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)  # Adaptive crossover rate\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.round(trial_vector)  # Promote periodic solutions\n                trial_value = func(trial_vector)\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        x0 = np.clip(0.5 * (x0 + (bounds.ub + bounds.lb) / 2), bounds.lb, bounds.ub)  # Adjust x0 within bounds\n        res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n        return res.x, res.fun\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        # Step 1: Perform Differential Evolution for global exploration\n        best_solution_de, best_value_de = self.differential_evolution(func, bounds)\n\n        # Step 2: Early stopping if budget usage is below threshold\n        if self.func_evals < 0.85 * self.budget:  # Restored threshold to 0.85\n            # Step 3: Perform local optimization using BFGS from best DE solution\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        # Return the best found solution and its value\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced exploration with modified initialization strategy and convergence refinement.", "configspace": "", "generation": 7, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 9 is out of bounds for axis 0 with size 9').", "error": "IndexError('index 9 is out of bounds for axis 0 with size 9')", "parent_id": "163d17f2-77f3-4aa4-8313-ef54f30d0d62", "metadata": {}, "mutation_prompt": null}
{"id": "19b162fe-bb54-4839-b6f9-e0d647348119", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(min(population_size, len(population))):  # Ensure index is within bounds\n                a, b, c = population[np.random.choice(population_size, 3, replace=False)]\n                adaptive_F = F * (1 - self.func_evals / self.budget)  # Adaptive mutation factor\n                adaptive_F = max(0.2, adaptive_F)  # Ensure mutation factor doesn't drop too low (change 1)\n                \n                # Adjust dynamic population size within the loop\n                if self.func_evals % (self.budget // 10) == 0:\n                    population_size = min(10, max(4, int(population_size * 0.85)))  # Adjust scaling factor (change 2)\n                    population = population[:population_size]\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)  # Adaptive crossover rate\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.round(trial_vector)  # Promote periodic solutions\n                trial_value = func(trial_vector)\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        x0 = np.clip(0.5 * (x0 + (bounds.ub + bounds.lb) / 2), bounds.lb, bounds.ub)  # Adjust x0 within bounds\n        res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n        return res.x, res.fun\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        # Step 1: Perform Differential Evolution for global exploration\n        best_solution_de, best_value_de = self.differential_evolution(func, bounds)\n\n        # Step 2: Early stopping if budget usage is below threshold\n        if self.func_evals < 0.85 * self.budget:  # Adjust threshold (change 3)\n            # Step 3: Perform local optimization using BFGS from best DE solution\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        # Return the best found solution and its value\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Improved periodicity and robustness of the exploration-exploitation balance in optimization.", "configspace": "", "generation": 8, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 8 is out of bounds for axis 0 with size 8').", "error": "IndexError('index 8 is out of bounds for axis 0 with size 8')", "parent_id": "21d6c6e8-3863-407b-b6df-afb5097cb85c", "metadata": {}, "mutation_prompt": null}
{"id": "eafd2008-77af-4538-b232-8fd0bab07bce", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(population_size):\n                a, b, c = population[np.random.choice(population_size, 3, replace=False)]\n                adaptive_F = F * (1 - self.func_evals / self.budget)  # Adaptive mutation factor\n                adaptive_F = max(0.2, adaptive_F)  # Ensure mutation factor doesn't drop too low (change 1)\n                \n                # Adjust dynamic population size within the loop\n                if self.func_evals % (self.budget // 10) == 0:\n                    population_size = min(10, max(4, int(population_size * 0.85)))  # Adjust scaling factor (change 2)\n                    population = population[:population_size]\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)  # Adaptive crossover rate\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.round(trial_vector / 0.25) * 0.25  # Promote periodic solutions\n                trial_value = func(trial_vector)\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        x0 = np.clip(0.5 * (x0 + (bounds.ub + bounds.lb) / 2), bounds.lb, bounds.ub)  # Adjust x0 within bounds\n        res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n        return res.x, res.fun\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        # Step 1: Perform Differential Evolution for global exploration\n        best_solution_de, best_value_de = self.differential_evolution(func, bounds)\n\n        # Step 2: Early stopping if budget usage is below threshold\n        if self.func_evals < 0.85 * self.budget:  # Adjust threshold (change 3)\n            # Step 3: Perform local optimization using BFGS from best DE solution\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        # Return the best found solution and its value\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Introduced a periodicity encouraging mechanism by rounding trial vector entries to the nearest quarter wavelength.", "configspace": "", "generation": 8, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 8 is out of bounds for axis 0 with size 8').", "error": "IndexError('index 8 is out of bounds for axis 0 with size 8')", "parent_id": "21d6c6e8-3863-407b-b6df-afb5097cb85c", "metadata": {}, "mutation_prompt": null}
{"id": "e473002c-05fc-41cd-8044-dd4da540f346", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(len(population)):  # Ensure i is within bounds\n                a, b, c = population[np.random.choice(len(population), 3, replace=False)]\n                adaptive_F = F * (1 - self.func_evals / self.budget)\n                adaptive_F = max(0.2, adaptive_F)\n                \n                # Adjust dynamic population size within the loop only when needed\n                if self.func_evals % (self.budget // 10) == 0 and len(population) > 4:\n                    new_size = min(10, max(4, int(len(population) * 0.85)))\n                    population = population[:new_size]\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.round(trial_vector)\n                trial_value = func(trial_vector)\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        x0 = np.clip(0.5 * (x0 + (bounds.ub + bounds.lb) / 2), bounds.lb, bounds.ub)\n        res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n        return res.x, res.fun\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        # Step 1: Perform Differential Evolution for global exploration\n        best_solution_de, best_value_de = self.differential_evolution(func, bounds)\n\n        # Step 2: Early stopping if budget usage is below threshold\n        if self.func_evals < 0.85 * self.budget:\n            # Step 3: Perform local optimization using BFGS from best DE solution\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        # Return the best found solution and its value\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced exploration and exploitation with adaptive mutation factor adjustments to prevent index errors and optimize reflectivity efficiently.", "configspace": "", "generation": 8, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 8 is out of bounds for axis 0 with size 8').", "error": "IndexError('index 8 is out of bounds for axis 0 with size 8')", "parent_id": "21d6c6e8-3863-407b-b6df-afb5097cb85c", "metadata": {}, "mutation_prompt": null}
{"id": "5ae35edb-e78f-42f2-a579-dccab919696a", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(population_size):\n                a, b, c = population[np.random.choice(population_size, 3, replace=False)]\n                adaptive_F = F * (1 - self.func_evals / self.budget)\n                adaptive_F = max(0.2, adaptive_F)\n\n                if self.func_evals % (self.budget // 10) == 0:\n                    population_size = min(10, max(4, int(population_size * 0.85)))\n                    population = np.vstack((population, np.random.uniform(bounds.lb, bounds.ub, (10 - population_size, self.dim))))  # Corrected line\n\n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.round(trial_vector)\n                trial_value = func(trial_vector)\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        x0 = np.clip(0.5 * (x0 + (bounds.ub + bounds.lb) / 2), bounds.lb, bounds.ub)\n        res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n        return res.x, res.fun\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        best_solution_de, best_value_de = self.differential_evolution(func, bounds)\n\n        if self.func_evals < 0.85 * self.budget:\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Adaptive hybrid optimization strategy with corrected population size and enhanced local search.", "configspace": "", "generation": 8, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 8 is out of bounds for axis 0 with size 8').", "error": "IndexError('index 8 is out of bounds for axis 0 with size 8')", "parent_id": "21d6c6e8-3863-407b-b6df-afb5097cb85c", "metadata": {}, "mutation_prompt": null}
{"id": "d2a1b33e-a503-4803-a3af-496a7f69bf53", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(population_size):\n                a, b, c = population[np.random.choice(population_size, 3, replace=False)]\n                adaptive_F = F * (1 - self.func_evals / self.budget)  # Adaptive mutation factor\n                adaptive_F = max(0.3, adaptive_F)  # Ensure mutation factor doesn't drop too low (change 1)\n                \n                # Adjust dynamic population size within the loop\n                if self.func_evals % (self.budget // 10) == 0:\n                    population_size = min(10, max(4, int(population_size * 0.85)))  # Adjust scaling factor (change 2)\n                    population = population[:population_size]\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)  # Adaptive crossover rate\n                CR_dynamic = max(0.5, CR_dynamic)  # Ensure crossover rate doesn't drop too low (change 3)\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.round(trial_vector)  # Promote periodic solutions\n                trial_value = func(trial_vector)\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        x0 = np.clip(0.5 * (x0 + (bounds.ub + bounds.lb) / 2), bounds.lb, bounds.ub)  # Adjust x0 within bounds\n        res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n        return res.x, res.fun\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        # Step 1: Perform Differential Evolution for global exploration\n        best_solution_de, best_value_de = self.differential_evolution(func, bounds)\n\n        # Step 2: Early stopping if budget usage is below threshold\n        if self.func_evals < 0.85 * self.budget:  # Adjust threshold (change 3)\n            # Step 3: Perform local optimization using BFGS from best DE solution\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        # Return the best found solution and its value\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Adaptive mutation and crossover enhancements for improved convergence while maintaining periodicity.", "configspace": "", "generation": 8, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 8 is out of bounds for axis 0 with size 8').", "error": "IndexError('index 8 is out of bounds for axis 0 with size 8')", "parent_id": "21d6c6e8-3863-407b-b6df-afb5097cb85c", "metadata": {}, "mutation_prompt": null}
{"id": "2745be3c-7897-4431-aca0-b4d0226e2eae", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(min(population_size, len(population))):\n                a, b, c = population[np.random.choice(population_size, 3, replace=False)]\n                adaptive_F = F * (1 - self.func_evals / self.budget)\n                adaptive_F = max(0.2, adaptive_F)\n                \n                if self.func_evals % (self.budget // 10) == 0:\n                    population_size = min(10, max(4, int(population_size * 0.9)))  # Adjust scaling factor (change 1)\n                    population = population[:population_size]\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.round(trial_vector - 0.5)  # Promote periodic solutions by rounding (change 2)\n                trial_value = func(trial_vector)\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        x0 = np.clip(0.5 * (x0 + (bounds.ub + bounds.lb) / 2), bounds.lb, bounds.ub)\n        res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n        return res.x, res.fun\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        best_solution_de, best_value_de = self.differential_evolution(func, bounds)\n\n        if self.func_evals < 0.85 * self.budget:\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Refined exploration in hybrid optimization by adjusting dynamic population size and rounding step for periodic solutions.", "configspace": "", "generation": 9, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 9 is out of bounds for axis 0 with size 9').", "error": "IndexError('index 9 is out of bounds for axis 0 with size 9')", "parent_id": "19b162fe-bb54-4839-b6f9-e0d647348119", "metadata": {}, "mutation_prompt": null}
{"id": "ca044059-67e8-4b26-a282-f0d5dfa55f11", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(min(population_size, len(population))):  # Ensure index is within bounds\n                a, b, c = population[np.random.choice(population_size, 3, replace=False)]\n                adaptive_F = F * (1 - self.func_evals / self.budget)  # Adaptive mutation factor\n                adaptive_F = max(0.2, adaptive_F)  # Ensure mutation factor doesn't drop too low (change 1)\n                \n                # Adjust dynamic population size within the loop\n                if self.func_evals % (self.budget // 10) == 0:\n                    population_size = min(len(population), max(4, int(population_size * 0.85)))  # Corrected indexing (change 2)\n                    population = population[:population_size]\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)  # Adaptive crossover rate\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.round(trial_vector)  # Promote periodic solutions\n                trial_value = func(trial_vector)\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        x0 = np.clip(0.5 * (x0 + (bounds.ub + bounds.lb) / 2), bounds.lb, bounds.ub)  # Adjust x0 within bounds\n        res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n        return res.x, res.fun\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        # Step 1: Perform Differential Evolution for global exploration\n        best_solution_de, best_value_de = self.differential_evolution(func, bounds)\n\n        # Step 2: Early stopping if budget usage is below threshold\n        if self.func_evals < 0.85 * self.budget:  # Adjust threshold (change 3)\n            # Step 3: Perform local optimization using BFGS from best DE solution\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        # Return the best found solution and its value\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced exploration and exploitation by correcting population size indexing and ensuring adaptive dynamics.", "configspace": "", "generation": 9, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 8 is out of bounds for axis 0 with size 8').", "error": "IndexError('index 8 is out of bounds for axis 0 with size 8')", "parent_id": "19b162fe-bb54-4839-b6f9-e0d647348119", "metadata": {}, "mutation_prompt": null}
{"id": "ca54aaca-76a5-4eca-9a70-e5874d8e8308", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(min(population_size, len(population))):\n                a, b, c = population[np.random.choice(population_size, 3, replace=False)]\n                adaptive_F = F * (1 - self.func_evals / self.budget)  # Adaptive mutation factor\n                adaptive_F = max(0.2, adaptive_F)\n                \n                # Adjust dynamic population size within the loop\n                if self.func_evals % (self.budget // 10) == 0:\n                    population_size = min(10, max(4, int(population_size * 0.85)))\n                    population = population[:population_size]\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)  # Adaptive crossover rate\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.round(trial_vector)\n                trial_value = func(trial_vector)\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        x0 = np.clip(0.5 * (x0 + (bounds.ub + bounds.lb) / 2), bounds.lb, bounds.ub)\n        res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n        return res.x, res.fun\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        # Step 1: Perform Differential Evolution for global exploration\n        best_solution_de, best_value_de = self.differential_evolution(func, bounds)\n\n        # Step 2: Early stopping if budget usage is below threshold\n        if self.func_evals < 0.85 * self.budget:\n            # Step 3: Perform local optimization using BFGS from best DE solution\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Incorporates a dynamic exploration-exploitation strategy with adaptive population management and periodicity encouragement.", "configspace": "", "generation": 9, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 8 is out of bounds for axis 0 with size 8').", "error": "IndexError('index 8 is out of bounds for axis 0 with size 8')", "parent_id": "19b162fe-bb54-4839-b6f9-e0d647348119", "metadata": {}, "mutation_prompt": null}
{"id": "cd9ce3d4-0c1f-4f8a-b0c9-c310d4532bb0", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(len(population)):  # Ensure index is within bounds\n                a, b, c = population[np.random.choice(len(population), 3, replace=False)]  # Adjusted to use len(population)\n                adaptive_F = F * (1 - self.func_evals / self.budget)  # Adaptive mutation factor\n                adaptive_F = max(0.2, adaptive_F)  # Ensure mutation factor doesn't drop too low (change 1)\n                \n                # Adjust dynamic population size within the loop\n                if self.func_evals % (self.budget // 10) == 0:\n                    population_size = min(10, max(4, int(population_size * 0.85)))  # Adjust scaling factor (change 2)\n                    population = population[:population_size]\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)  # Adaptive crossover rate\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.round(trial_vector)  # Promote periodic solutions\n                trial_value = func(trial_vector)\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        x0 = np.clip(0.5 * (x0 + (bounds.ub + bounds.lb) / 2), bounds.lb, bounds.ub)  # Adjust x0 within bounds\n        res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n        return res.x, res.fun\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        # Step 1: Perform Differential Evolution for global exploration\n        best_solution_de, best_value_de = self.differential_evolution(func, bounds)\n\n        # Step 2: Early stopping if budget usage is below threshold\n        if self.func_evals < 0.85 * self.budget:  # Adjust threshold (change 3)\n            # Step 3: Perform local optimization using BFGS from best DE solution\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        # Return the best found solution and its value\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Improved indexing to prevent IndexError during dynamic population size adjustment in differential evolution.", "configspace": "", "generation": 9, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 8 is out of bounds for axis 0 with size 8').", "error": "IndexError('index 8 is out of bounds for axis 0 with size 8')", "parent_id": "19b162fe-bb54-4839-b6f9-e0d647348119", "metadata": {}, "mutation_prompt": null}
{"id": "7aff6177-27fd-4992-b738-54d615da2408", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            for i in range(population_size):  # Adjusted to check full population size\n                a, b, c = population[np.random.choice(population_size, 3, replace=False)]\n                adaptive_F = F * (1 - self.func_evals / self.budget)  \n                adaptive_F = max(0.3, adaptive_F)  # Ensured minimum mutation factor\n\n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget) \n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n\n                trial_vector = np.round(trial_vector * 2) / 2  # Enhanced periodic promotion\n                trial_value = func(trial_vector)\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n\n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n\n                if self.func_evals >= self.budget:\n                    break\n\n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        x0 = np.clip(0.5 * (x0 + (bounds.ub + bounds.lb) / 2), bounds.lb, bounds.ub) \n        res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n        return res.x, res.fun\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        best_solution_de, best_value_de = self.differential_evolution(func, bounds)\n\n        if self.func_evals < 0.85 * self.budget:  \n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced periodic solutions and dynamic adjustments in DE for improved optimization.", "configspace": "", "generation": 9, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 8 is out of bounds for axis 0 with size 8').", "error": "IndexError('index 8 is out of bounds for axis 0 with size 8')", "parent_id": "19b162fe-bb54-4839-b6f9-e0d647348119", "metadata": {}, "mutation_prompt": null}
{"id": "563199c2-75f5-430b-90d3-a532b9738d94", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(min(population_size, len(population))):\n                a, b, c = population[np.random.choice(population_size, 3, replace=False)]\n                adaptive_F = F * (1 - self.func_evals / self.budget)\n                adaptive_F = max(0.2, adaptive_F)\n                \n                if self.func_evals % (self.budget // 10) == 0:\n                    population_size = max(4, int(population_size * 0.9))\n                    population = population[:population_size]\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.clip(np.round(trial_vector), bounds.lb, bounds.ub)  # Improved periodic solutions (change 1)\n                trial_value = func(trial_vector)\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        x0 = np.clip(0.5 * (x0 + (bounds.ub + bounds.lb) / 2), bounds.lb, bounds.ub)\n        res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n        return res.x, res.fun\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        best_solution_de, best_value_de = self.differential_evolution(func, bounds)\n\n        if self.func_evals < 0.85 * self.budget:\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced hybrid optimization with adaptive constraints and improved periodicity handling.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 9 is out of bounds for axis 0 with size 9').", "error": "IndexError('index 9 is out of bounds for axis 0 with size 9')", "parent_id": "2745be3c-7897-4431-aca0-b4d0226e2eae", "metadata": {}, "mutation_prompt": null}
{"id": "68986736-b21c-475d-9ee8-87865e4a54f3", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(min(population_size, len(population))):\n                a, b, c = population[np.random.choice(population_size, 3, replace=False)]\n                adaptive_F = F * (1 - self.func_evals / self.budget)\n                adaptive_F = max(0.2, adaptive_F)\n                \n                if self.func_evals % (self.budget // 10) == 0:\n                    population_size = min(10, max(4, int(population_size * 0.9)))  # Adjust scaling factor (change 1)\n                    population = population[:population_size]\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.round(trial_vector)  # Ensure rounding is applied correctly (change 2)\n                trial_value = func(trial_vector)\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        x0 = np.clip(0.5 * (x0 + (bounds.ub + bounds.lb) / 2), bounds.lb, bounds.ub)\n        res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n        return res.x, res.fun\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        best_solution_de, best_value_de = self.differential_evolution(func, bounds)\n\n        if self.func_evals < 0.85 * self.budget:\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced handling of population indices and rounding to promote periodic solutions in hybrid metaheuristics for black box optimization.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 9 is out of bounds for axis 0 with size 9').", "error": "IndexError('index 9 is out of bounds for axis 0 with size 9')", "parent_id": "2745be3c-7897-4431-aca0-b4d0226e2eae", "metadata": {}, "mutation_prompt": null}
{"id": "f57eb015-4d0a-4c21-8c85-657b603987d0", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(min(population_size, len(population))):\n                a, b, c = population[np.random.choice(population_size, 3, replace=False)]\n                adaptive_F = F * (1 - self.func_evals / self.budget)\n                adaptive_F = max(0.2, adaptive_F)\n                \n                if self.func_evals % (self.budget // 10) == 0:\n                    population_size = max(4, int(population_size * 0.9))  # Adjust scaling factor (correction)\n                    population = population[:population_size]\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.round(trial_vector - 0.5)  # Promote periodic solutions by rounding (change 2)\n                trial_value = func(trial_vector)\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        x0 = np.clip(0.5 * (x0 + (bounds.ub + bounds.lb) / 2), bounds.lb, bounds.ub)\n        res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n        return res.x, res.fun\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        best_solution_de, best_value_de = self.differential_evolution(func, bounds)\n\n        if self.func_evals < 0.85 * self.budget:\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced solution for hybrid optimization with dynamic population size adjustment and rounding for periodic solutions.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 9 is out of bounds for axis 0 with size 9').", "error": "IndexError('index 9 is out of bounds for axis 0 with size 9')", "parent_id": "2745be3c-7897-4431-aca0-b4d0226e2eae", "metadata": {}, "mutation_prompt": null}
{"id": "553f2e12-1c33-49af-9543-2c146bbc2e0e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(min(population_size, len(population))):\n                a, b, c = population[np.random.choice(population_size, 3, replace=False)]\n                adaptive_F = F * (1 - self.func_evals / self.budget)\n                adaptive_F = max(0.2, adaptive_F)\n                \n                if self.func_evals % (self.budget // 10) == 0:\n                    population_size = min(10, max(4, int(population_size * 0.9)))  # Adjust scaling factor (change 1)\n                    population = population[:population_size]\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.round(trial_vector)  # Adjust rounding strategy for promoting periodic solutions\n                trial_value = func(trial_vector)\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        x0 = np.clip(0.5 * (x0 + (bounds.ub + bounds.lb) / 2), bounds.lb, bounds.ub)\n        res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n        return res.x, res.fun\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        best_solution_de, best_value_de = self.differential_evolution(func, bounds)\n\n        if self.func_evals < 0.85 * self.budget:\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Improved handling of index bounds and adjusted rounding for promoting periodic solutions in hybrid optimization.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 9 is out of bounds for axis 0 with size 9').", "error": "IndexError('index 9 is out of bounds for axis 0 with size 9')", "parent_id": "2745be3c-7897-4431-aca0-b4d0226e2eae", "metadata": {}, "mutation_prompt": null}
{"id": "6b3990a2-7772-4a14-bb40-7cd3e630ae4e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(min(population_size, len(population))):\n                a, b, c = population[np.random.choice(population_size, 3, replace=False)]\n                adaptive_F = F * (1 - self.func_evals / self.budget)\n                adaptive_F = max(0.2, adaptive_F)\n                \n                if self.func_evals % (self.budget // 10) == 0:\n                    population_size = min(10, max(4, int(population_size * 0.9)))\n                    population = population[:population_size]\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.clip(np.round(trial_vector), bounds.lb, bounds.ub)  # Change 1: Ensure valid values\n                trial_value = func(trial_vector)\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        x0 = np.clip(0.5 * (x0 + (bounds.ub + bounds.lb) / 2), bounds.lb, bounds.ub)\n        res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n        return res.x, res.fun\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        best_solution_de, best_value_de = self.differential_evolution(func, bounds)\n\n        if self.func_evals < 0.85 * self.budget:\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced hybrid optimization by integrating dynamic strategy adaptation and leveraging periodic solutions through modified mutation and crossover mechanisms.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 9 is out of bounds for axis 0 with size 9').", "error": "IndexError('index 9 is out of bounds for axis 0 with size 9')", "parent_id": "2745be3c-7897-4431-aca0-b4d0226e2eae", "metadata": {}, "mutation_prompt": null}
{"id": "58213b81-8e46-4b6e-b281-d23b2044399b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(min(population_size, len(population))):\n                a, b, c = population[np.random.choice(population_size, 3, replace=False)]\n                adaptive_F = F * (1 - self.func_evals / self.budget)\n                adaptive_F = max(0.2, adaptive_F)\n                \n                if self.func_evals % (self.budget // 10) == 0:\n                    population_size = max(4, int(population_size * 0.9))\n                    population = population[:population_size]\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.clip(np.round(trial_vector), bounds.lb, bounds.ub)  # Improved periodic solutions (change 1)\n                trial_value = func(trial_vector)\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        x0 = np.clip(0.5 * (x0 + (bounds.ub + bounds.lb) / 2), bounds.lb, bounds.ub)\n        res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n        return res.x, res.fun\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        best_solution_de, best_value_de = self.differential_evolution(func, bounds, population_size=20)  # Increased initial population size (change 2)\n\n        if self.func_evals < 0.85 * self.budget:\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Efficient hybrid metaheuristic optimization with periodicity enhancements and adaptive population resizing.", "configspace": "", "generation": 11, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 18 is out of bounds for axis 0 with size 18').", "error": "IndexError('index 18 is out of bounds for axis 0 with size 18')", "parent_id": "563199c2-75f5-430b-90d3-a532b9738d94", "metadata": {}, "mutation_prompt": null}
{"id": "5a192045-7d52-4fef-a5ed-a4359a898026", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(min(population_size, len(population))):\n                a, b, c = population[np.random.choice(population_size, 3, replace=False)]\n                adaptive_F = F * (1 - self.func_evals / self.budget)\n                adaptive_F = max(0.2, adaptive_F)\n                \n                if self.func_evals % (self.budget // 10) == 0:\n                    population_size = max(4, int(population_size * 0.95))  # Change 1: Adjust population decay rate\n                    population = population[:population_size]\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget) + 0.1  # Change 2: Enhance crossover probability\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.clip(np.round(trial_vector), bounds.lb, bounds.ub)  # Improved periodic solutions\n                trial_value = func(trial_vector)\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        x0 = np.clip(0.5 * (x0 + (bounds.ub + bounds.lb) / 2), bounds.lb, bounds.ub)\n        res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n        return res.x, res.fun\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        best_solution_de, best_value_de = self.differential_evolution(func, bounds)\n\n        if self.func_evals < 0.85 * self.budget:\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Improved hybrid optimization using adaptive sampling with periodic reinforcement for better convergence and stability.", "configspace": "", "generation": 11, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 9 is out of bounds for axis 0 with size 9').", "error": "IndexError('index 9 is out of bounds for axis 0 with size 9')", "parent_id": "563199c2-75f5-430b-90d3-a532b9738d94", "metadata": {}, "mutation_prompt": null}
{"id": "35fb3864-aec3-4522-8da7-7a1e9c7dc679", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(min(population_size, len(population))):\n                a, b, c = population[np.random.choice(population_size, 3, replace=False)]\n                adaptive_F = F * (1 - self.func_evals / self.budget)\n                adaptive_F = max(0.2, adaptive_F)\n                \n                if self.func_evals % (self.budget // 10) == 0:\n                    population_size = max(4, int(population_size * 0.9))\n                    population = population[:population_size]\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.clip(np.round(trial_vector), bounds.lb, bounds.ub)  # Improved periodic solutions (change 1)\n                trial_value = func(trial_vector)\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                # Add a condition to adjust population size dynamically\n                if self.func_evals % (self.budget // 5) == 0 and population_size < 10:\n                    population_size += 1\n                    population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        x0 = np.clip(0.5 * (x0 + (bounds.ub + bounds.lb) / 2), bounds.lb, bounds.ub)\n        res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n        return res.x, res.fun\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        best_solution_de, best_value_de = self.differential_evolution(func, bounds)\n\n        if self.func_evals < 0.85 * self.budget:\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Refined hybrid optimization with enhanced periodicity handling and adaptive population management.", "configspace": "", "generation": 11, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 9 is out of bounds for axis 0 with size 9').", "error": "IndexError('index 9 is out of bounds for axis 0 with size 9')", "parent_id": "563199c2-75f5-430b-90d3-a532b9738d94", "metadata": {}, "mutation_prompt": null}
{"id": "0adb6feb-ec6d-4613-bfab-6d9e64a6d8ef", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(min(population_size, len(population))):\n                a, b, c = population[np.random.choice(len(population), 3, replace=False)]\n                adaptive_F = F * (1 - self.func_evals / self.budget)\n                adaptive_F = max(0.2, adaptive_F)\n                \n                if self.func_evals % (self.budget // 10) == 0 and population_size > 4:\n                    population_size = max(4, int(population_size * 0.9))\n                    population = population[:population_size]\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.clip(np.round(trial_vector), bounds.lb, bounds.ub)  # Improved periodic solutions (change 1)\n                trial_value = func(trial_vector)\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        x0 = np.clip(0.5 * (x0 + (bounds.ub + bounds.lb) / 2), bounds.lb, bounds.ub)\n        res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n        return res.x, res.fun\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        best_solution_de, best_value_de = self.differential_evolution(func, bounds)\n\n        if self.func_evals < 0.85 * self.budget:\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Improved handling of population size adaptation in differential evolution to ensure indexing is within bounds.", "configspace": "", "generation": 11, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 9 is out of bounds for axis 0 with size 9').", "error": "IndexError('index 9 is out of bounds for axis 0 with size 9')", "parent_id": "563199c2-75f5-430b-90d3-a532b9738d94", "metadata": {}, "mutation_prompt": null}
{"id": "4a206679-a61a-4fc3-8ce2-fe3b245807d7", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            population_size = max(4, int(population_size * (0.9 + 0.1 * (self.func_evals / self.budget))))  # Adjust population size dynamically (change 1)\n            for i in range(min(population_size, len(population))):\n                a, b, c = population[np.random.choice(population_size, 3, replace=False)]\n                adaptive_F = F * (1 - self.func_evals / self.budget)\n                adaptive_F = max(0.2, adaptive_F)\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.clip(np.round(trial_vector), bounds.lb, bounds.ub)\n                trial_value = func(trial_vector)\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        x0 = np.clip(0.5 * (x0 + (bounds.ub + bounds.lb) / 2), bounds.lb, bounds.ub)\n        res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n        return res.x, res.fun\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        best_solution_de, best_value_de = self.differential_evolution(func, bounds)\n\n        if self.func_evals < 0.85 * self.budget:\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Refined hybrid optimization with improved population management and adaptive local search integration.", "configspace": "", "generation": 11, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 9 is out of bounds for axis 0 with size 9').", "error": "IndexError('index 9 is out of bounds for axis 0 with size 9')", "parent_id": "563199c2-75f5-430b-90d3-a532b9738d94", "metadata": {}, "mutation_prompt": null}
{"id": "5d1a3a58-4e72-437b-a8f0-7c2b1eaa1603", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(min(population_size, len(population))):\n                a, b, c = population[np.random.choice(population_size, 3, replace=False)]\n                adaptive_F = F * (1 - self.func_evals / self.budget)\n                adaptive_F = max(0.2, adaptive_F)\n                \n                if self.func_evals % (self.budget // 10) == 0:\n                    population_size = max(4, int(population_size * 0.9))\n                    population = population[:population_size]\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.clip(np.round(trial_vector), bounds.lb, bounds.ub)\n                trial_value = func(trial_vector)\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        x0 = np.clip(0.5 * (x0 + (bounds.ub + bounds.lb) / 2), bounds.lb, bounds.ub)\n        res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n        return res.x, res.fun\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        best_solution_de, best_value_de = self.differential_evolution(func, bounds, population_size=20)\n\n        if self.func_evals < 0.85 * self.budget:\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced hybrid metaheuristic optimization using adaptive population size and periodicity constraints for robust exploration and exploitation.", "configspace": "", "generation": 12, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 18 is out of bounds for axis 0 with size 18').", "error": "IndexError('index 18 is out of bounds for axis 0 with size 18')", "parent_id": "58213b81-8e46-4b6e-b281-d23b2044399b", "metadata": {}, "mutation_prompt": null}
{"id": "fae98a8a-732c-4e2b-9bc6-80210078b8ec", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(min(population_size, len(population))):\n                a, b, c = population[np.random.choice(population_size, 3, replace=False)]\n                adaptive_F = F * (1 - self.func_evals / self.budget)\n                adaptive_F = max(0.2, adaptive_F)\n                \n                if self.func_evals % (self.budget // 10) == 0:\n                    population_size = max(4, int(population_size * 0.9))\n                    population = population[:population_size]\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.clip(np.round(trial_vector), bounds.lb, bounds.ub)\n                trial_value = func(trial_vector)\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        x0 = np.clip(0.5 * (x0 + (bounds.ub + bounds.lb) / 2), bounds.lb, bounds.ub)\n        res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n        return res.x, res.fun\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        best_solution_de, best_value_de = self.differential_evolution(func, bounds, population_size=25)  # Adjusted initial pop size\n\n        if self.func_evals < 0.85 * self.budget:\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced hybrid metaheuristic optimization with improved periodicity handling and adaptive differential evolution.", "configspace": "", "generation": 12, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 22 is out of bounds for axis 0 with size 22').", "error": "IndexError('index 22 is out of bounds for axis 0 with size 22')", "parent_id": "58213b81-8e46-4b6e-b281-d23b2044399b", "metadata": {}, "mutation_prompt": null}
{"id": "c57ae6e8-13ec-4939-87fe-a1f8c573f0a3", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(min(population_size, len(population))):\n                a, b, c = population[np.random.choice(len(population), 3, replace=False)]  # Changed population_size to len(population)\n\n                adaptive_F = F * (1 - self.func_evals / self.budget)\n                adaptive_F = max(0.2, adaptive_F)\n                \n                if self.func_evals % (self.budget // 10) == 0:\n                    population_size = max(4, int(population_size * 0.9))\n                    population = population[:population_size]\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.clip(np.round(trial_vector), bounds.lb, bounds.ub)  # Improved periodic solutions (change 1)\n                trial_value = func(trial_vector)\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        x0 = np.clip(0.5 * (x0 + (bounds.ub + bounds.lb) / 2), bounds.lb, bounds.ub)\n        res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n        return res.x, res.fun\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        best_solution_de, best_value_de = self.differential_evolution(func, bounds, population_size=20)  # Increased initial population size (change 2)\n\n        if self.func_evals < 0.85 * self.budget:\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Improved hybrid metaheuristic optimization by adjusting the index for population selection to avoid out-of-bounds errors.", "configspace": "", "generation": 12, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 18 is out of bounds for axis 0 with size 18').", "error": "IndexError('index 18 is out of bounds for axis 0 with size 18')", "parent_id": "58213b81-8e46-4b6e-b281-d23b2044399b", "metadata": {}, "mutation_prompt": null}
{"id": "dfc4af06-80e2-414f-b7fd-f0f6898a400f", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(min(population_size, len(population))):\n                a, b, c = population[np.random.choice(population_size, 3, replace=False)]\n                adaptive_F = F * (1 - self.func_evals / self.budget)\n                adaptive_F = max(0.2, adaptive_F)\n                \n                if self.func_evals % (self.budget // 10) == 0 and self.func_evals < 0.9 * self.budget:\n                    population_size = max(4, int(population_size * 0.9))\n                    population = population[:population_size]\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.clip(np.round(trial_vector), bounds.lb, bounds.ub)  # Improved periodic solutions (change 1)\n                trial_value = func(trial_vector)\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        x0 = np.clip(0.5 * (x0 + (bounds.ub + bounds.lb) / 2), bounds.lb, bounds.ub)\n        res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n        return res.x, res.fun\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        best_solution_de, best_value_de = self.differential_evolution(func, bounds, population_size=20)  # Increased initial population size (change 2)\n\n        if self.func_evals < 0.85 * self.budget:\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Improved error handling for adaptive population resizing in hybrid metaheuristic optimizer.", "configspace": "", "generation": 12, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 18 is out of bounds for axis 0 with size 18').", "error": "IndexError('index 18 is out of bounds for axis 0 with size 18')", "parent_id": "58213b81-8e46-4b6e-b281-d23b2044399b", "metadata": {}, "mutation_prompt": null}
{"id": "53fbb93d-825a-4296-828e-180ae1db52cd", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(min(population_size, len(population))):\n                a, b, c = population[np.random.choice(population_size, 3, replace=False)]\n                adaptive_F = F * (1 - self.func_evals / self.budget)\n                adaptive_F = max(0.2, adaptive_F)\n                \n                if self.func_evals % (self.budget // 10) == 0:\n                    population_size = max(4, int(population_size * 0.85))  # Adjusted reduction rate (change 1)\n                    population = population[:population_size]\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.clip(np.round(trial_vector), bounds.lb, bounds.ub)\n                trial_value = func(trial_vector)\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        x0 = np.clip(0.5 * (x0 + (bounds.ub + bounds.lb) / 2), bounds.lb, bounds.ub)\n        res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n        return res.x, res.fun\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        best_solution_de, best_value_de = self.differential_evolution(func, bounds, population_size=22)  # Adjust initial population size (change 2)\n\n        if self.func_evals < 0.85 * self.budget:\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced hybrid optimizer with adaptive differential evolution and improved periodicity control.", "configspace": "", "generation": 12, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 18 is out of bounds for axis 0 with size 18').", "error": "IndexError('index 18 is out of bounds for axis 0 with size 18')", "parent_id": "58213b81-8e46-4b6e-b281-d23b2044399b", "metadata": {}, "mutation_prompt": null}
{"id": "1c3c4d3e-b744-41ac-bae0-31ed7846c2bc", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(min(population_size, len(population))):\n                a, b, c = population[np.random.choice(population_size, 3, replace=False)]\n                adaptive_F = F * (1 - self.func_evals / self.budget)\n                adaptive_F = max(0.2, adaptive_F)\n                \n                if self.func_evals % (self.budget // 10) == 0:\n                    population_size = max(4, int(population_size * 0.9))\n                    population = population[:population_size]\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                trial_value = func(trial_vector)\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        if self.func_evals < 0.85 * self.budget:  # This line is modified\n            x0 = np.clip(0.5 * (x0 + (bounds.ub + bounds.lb) / 2), bounds.lb, bounds.ub)\n            res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n            return res.x, res.fun\n        return x0, func(x0)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        best_solution_de, best_value_de = self.differential_evolution(func, bounds, population_size=20)\n\n        if self.func_evals < 0.85 * self.budget:\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced hybrid metaheuristic optimization with dynamic bounds adjustment for improved robustness.", "configspace": "", "generation": 13, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 18 is out of bounds for axis 0 with size 18').", "error": "IndexError('index 18 is out of bounds for axis 0 with size 18')", "parent_id": "5d1a3a58-4e72-437b-a8f0-7c2b1eaa1603", "metadata": {}, "mutation_prompt": null}
{"id": "cd0ba881-67cb-4503-a43c-37caabc12281", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(min(population_size, len(population))):\n                a, b, c = population[np.random.choice(len(population), 3, replace=False)]\n                adaptive_F = F * (1 - self.func_evals / self.budget)\n                adaptive_F = max(0.2, adaptive_F)\n                \n                if self.func_evals % (self.budget // 10) == 0:\n                    population_size = max(4, int(population_size * 0.9))\n                    population = population[:population_size]\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.clip(np.round(trial_vector), bounds.lb, bounds.ub)\n                trial_value = func(trial_vector)\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        x0 = np.clip(0.5 * (x0 + (bounds.ub + bounds.lb) / 2), bounds.lb, bounds.ub)\n        res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n        return res.x, res.fun\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        best_solution_de, best_value_de = self.differential_evolution(func, bounds, population_size=20)\n\n        if self.func_evals < 0.85 * self.budget:\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Improved error handling by adjusting indexing to prevent IndexError during population size variation.", "configspace": "", "generation": 13, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 18 is out of bounds for axis 0 with size 18').", "error": "IndexError('index 18 is out of bounds for axis 0 with size 18')", "parent_id": "5d1a3a58-4e72-437b-a8f0-7c2b1eaa1603", "metadata": {}, "mutation_prompt": null}
{"id": "493075ea-218e-48c9-a428-b743539e4047", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(min(population_size, len(population))):\n                a, b, c = population[np.random.choice(min(population_size, len(population)), 3, replace=False)]\n                adaptive_F = F * (1 - self.func_evals / self.budget)\n                adaptive_F = max(0.2, adaptive_F)\n                \n                if self.func_evals % (self.budget // 10) == 0:\n                    population_size = max(4, int(population_size * 0.9))\n                    population = population[:population_size]\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.clip(np.round(trial_vector), bounds.lb, bounds.ub)\n                trial_value = func(trial_vector)\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        x0 = np.clip(0.5 * (x0 + (bounds.ub + bounds.lb) / 2), bounds.lb, bounds.ub)\n        res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n        return res.x, res.fun\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        best_solution_de, best_value_de = self.differential_evolution(func, bounds, population_size=20)\n\n        if self.func_evals < 0.85 * self.budget:\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced hybrid optimization using adaptive population size and periodicity constraints, fixed with boundary checks for index errors.", "configspace": "", "generation": 13, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 18 is out of bounds for axis 0 with size 18').", "error": "IndexError('index 18 is out of bounds for axis 0 with size 18')", "parent_id": "5d1a3a58-4e72-437b-a8f0-7c2b1eaa1603", "metadata": {}, "mutation_prompt": null}
{"id": "185e949e-7e07-4901-aae8-098e5e17b276", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(min(population_size, len(population))):\n                indices = np.random.choice(population_size, 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                adaptive_F = F * (1 - self.func_evals / self.budget)\n                adaptive_F = max(0.2, adaptive_F)\n                \n                if self.func_evals % (self.budget // 10) == 0:\n                    population_size = max(4, int(population_size * 0.9))\n                    population = population[:population_size]\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.clip(np.round(trial_vector), bounds.lb, bounds.ub)\n                trial_value = func(trial_vector)\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        x0 = np.clip(0.5 * (x0 + (bounds.ub + bounds.lb) / 2), bounds.lb, bounds.ub)\n        res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n        return res.x, res.fun\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        best_solution_de, best_value_de = self.differential_evolution(func, bounds, population_size=20)\n\n        if self.func_evals < 0.85 * self.budget:\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Improved population management by ensuring indices are within bounds, enhancing robustness to dimensional changes.", "configspace": "", "generation": 13, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 18 is out of bounds for axis 0 with size 18').", "error": "IndexError('index 18 is out of bounds for axis 0 with size 18')", "parent_id": "5d1a3a58-4e72-437b-a8f0-7c2b1eaa1603", "metadata": {}, "mutation_prompt": null}
{"id": "3e6f7238-af0b-41d1-a22b-75737b06618e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(min(population_size, len(population))):\n                a, b, c = population[np.random.choice(len(population), 3, replace=False)]  # Adjusted array handling\n                adaptive_F = F * (1 - self.func_evals / self.budget)\n                adaptive_F = max(0.2, adaptive_F)\n                \n                if self.func_evals % (self.budget // 10) == 0:\n                    population_size = max(4, int(population_size * 0.9))\n                    population = population[:population_size]\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.clip(np.round(trial_vector), bounds.lb, bounds.ub)\n                trial_value = func(trial_vector)\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        x0 = np.clip(0.5 * (x0 + (bounds.ub + bounds.lb) / 2), bounds.lb, bounds.ub)\n        res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n        return res.x, res.fun\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        best_solution_de, best_value_de = self.differential_evolution(func, bounds, population_size=20)\n\n        if self.func_evals < 0.85 * self.budget:\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Refined hybrid metaheuristic optimization incorporating adjusted array handling to avoid index errors while maintaining modular and periodicity principles.", "configspace": "", "generation": 13, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 18 is out of bounds for axis 0 with size 18').", "error": "IndexError('index 18 is out of bounds for axis 0 with size 18')", "parent_id": "5d1a3a58-4e72-437b-a8f0-7c2b1eaa1603", "metadata": {}, "mutation_prompt": null}
{"id": "5e2d2b32-7640-404b-8b01-0ac9a6f1f0c3", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(min(population_size, len(population))):\n                a, b, c = population[np.random.choice(population_size, 3, replace=False)]\n                adaptive_F = F * (1 - self.func_evals / self.budget)\n                adaptive_F = max(0.2, adaptive_F)\n                \n                if self.func_evals % (self.budget // 10) == 0:\n                    population_size = max(4, int(population_size * 0.9))\n                    population = population[:population_size]\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                try:\n                    trial_value = func(trial_vector)\n                except IndexError:\n                    continue\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        if self.func_evals < 0.85 * self.budget:\n            x0 = np.clip(0.5 * (x0 + (bounds.ub + bounds.lb) / 2), bounds.lb, bounds.ub)\n            res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n            return res.x, res.fun\n        return x0, func(x0)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        best_solution_de, best_value_de = self.differential_evolution(func, bounds, population_size=20)\n\n        if self.func_evals < 0.85 * self.budget:\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced hybrid metaheuristic optimizer with error handling and population size constraints for robustness.", "configspace": "", "generation": 14, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 18 is out of bounds for axis 0 with size 18').", "error": "IndexError('index 18 is out of bounds for axis 0 with size 18')", "parent_id": "1c3c4d3e-b744-41ac-bae0-31ed7846c2bc", "metadata": {}, "mutation_prompt": null}
{"id": "53701515-d97c-4960-b80e-88b7495b8425", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(min(population_size, len(population))):\n                a, b, c = population[np.random.choice(len(population), 3, replace=False)]  # Adjusted line\n                adaptive_F = F * (1 - self.func_evals / self.budget)\n                adaptive_F = max(0.2, adaptive_F)\n                \n                if self.func_evals % (self.budget // 10) == 0:\n                    population_size = max(4, int(population_size * 0.9))\n                    population = population[:population_size]\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                trial_value = func(trial_vector)\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        if self.func_evals < 0.85 * self.budget:  # This line is modified\n            x0 = np.clip(0.5 * (x0 + (bounds.ub + bounds.lb) / 2), bounds.lb, bounds.ub)\n            res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n            return res.x, res.fun\n        return x0, func(x0)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        best_solution_de, best_value_de = self.differential_evolution(func, bounds, population_size=20)\n\n        if self.func_evals < 0.85 * self.budget:\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Improved handling of population size adjustment to prevent index errors during dynamic downsizing.", "configspace": "", "generation": 14, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 18 is out of bounds for axis 0 with size 18').", "error": "IndexError('index 18 is out of bounds for axis 0 with size 18')", "parent_id": "1c3c4d3e-b744-41ac-bae0-31ed7846c2bc", "metadata": {}, "mutation_prompt": null}
{"id": "1b9d034f-bc4d-4864-8f71-93b5340c53f6", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(min(population_size, len(population))):\n                a, b, c = population[np.random.choice(population_size, 3, replace=False)]\n                adaptive_F = F * (1 - self.func_evals / self.budget)\n                adaptive_F = max(0.2, adaptive_F)\n                \n                if self.func_evals % (self.budget // 10) == 0:\n                    population_size = max(4, int(population_size * 0.9))\n                    population = population[:population_size]\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                trial_value = func(trial_vector)\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        if self.func_evals < 0.85 * self.budget:  # This line is modified\n            x0 = np.clip(0.5 * (x0 + (bounds.ub + bounds.lb) / 2), bounds.lb, bounds.ub)\n            res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n            return res.x, res.fun\n        return x0, func(x0)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        best_solution_de, best_value_de = self.differential_evolution(func, bounds, population_size=20)\n\n        if self.func_evals < 0.85 * self.budget:\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Refined adaptive strategy for differential evolution to prevent index errors and improve robustness.", "configspace": "", "generation": 14, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 18 is out of bounds for axis 0 with size 18').", "error": "IndexError('index 18 is out of bounds for axis 0 with size 18')", "parent_id": "1c3c4d3e-b744-41ac-bae0-31ed7846c2bc", "metadata": {}, "mutation_prompt": null}
{"id": "b8971f0a-f1fc-4ae5-ac3e-7b25f28ff4dc", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(min(population_size, len(population))):\n                a, b, c = population[np.random.choice(min(len(population), population_size), 3, replace=False)]\n                adaptive_F = F * (1 - self.func_evals / self.budget)\n                adaptive_F = max(0.2, adaptive_F)\n                \n                if self.func_evals % (self.budget // 10) == 0:\n                    population_size = max(4, int(population_size * 0.9))\n                    population = population[:population_size]\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                trial_value = func(trial_vector)\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        if self.func_evals < 0.85 * self.budget:  # This line is modified\n            x0 = np.clip(0.5 * (x0 + (bounds.ub + bounds.lb) / 2), bounds.lb, bounds.ub)\n            res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n            return res.x, res.fun\n        return x0, func(x0)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        best_solution_de, best_value_de = self.differential_evolution(func, bounds, population_size=20)\n\n        if self.func_evals < 0.85 * self.budget:\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced hybrid metaheuristic optimization with dynamic bounds adjustment and robust population size handling.", "configspace": "", "generation": 14, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 18 is out of bounds for axis 0 with size 18').", "error": "IndexError('index 18 is out of bounds for axis 0 with size 18')", "parent_id": "1c3c4d3e-b744-41ac-bae0-31ed7846c2bc", "metadata": {}, "mutation_prompt": null}
{"id": "a42d606e-2d34-4db1-8554-da3ed59b0aca", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(min(population_size, len(population))):\n                if len(population) < 3:  # Ensure at least 3 individuals\n                    population = np.vstack((population, np.random.uniform(bounds.lb, bounds.ub, (3 - len(population), self.dim))))\n                a, b, c = population[np.random.choice(population_size, 3, replace=False)]\n                adaptive_F = F * (1 - self.func_evals / self.budget)\n                adaptive_F = max(0.2, adaptive_F)\n                \n                if self.func_evals % (self.budget // 10) == 0:\n                    population_size = max(4, int(population_size * 0.9))\n                    population = population[:population_size]\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                trial_value = func(trial_vector)\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        if self.func_evals < 0.85 * self.budget:  # This line is modified\n            x0 = np.clip(0.5 * (x0 + (bounds.ub + bounds.lb) / 2), bounds.lb, bounds.ub)\n            res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n            return res.x, res.fun\n        return x0, func(x0)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        best_solution_de, best_value_de = self.differential_evolution(func, bounds, population_size=20)\n\n        if self.func_evals < 0.85 * self.budget:\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Improved stability of differential evolution by adjusting initial population to prevent index errors.", "configspace": "", "generation": 14, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 18 is out of bounds for axis 0 with size 18').", "error": "IndexError('index 18 is out of bounds for axis 0 with size 18')", "parent_id": "1c3c4d3e-b744-41ac-bae0-31ed7846c2bc", "metadata": {}, "mutation_prompt": null}
{"id": "e714cf3d-f515-4998-9580-bc3515c4b8c2", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(min(population_size, len(population))):\n                a, b, c = population[np.random.choice(min(population_size, len(population)), 3, replace=False)] # Changed line\n                adaptive_F = F * (1 - self.func_evals / self.budget)\n                adaptive_F = max(0.2, adaptive_F)\n                \n                if self.func_evals % (self.budget // 10) == 0:\n                    population_size = max(4, int(population_size * 0.9))\n                    population = population[:population_size]\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                try:\n                    trial_value = func(trial_vector)\n                except IndexError:\n                    continue\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        if self.func_evals < 0.85 * self.budget:\n            x0 = np.clip(0.5 * (x0 + (bounds.ub + bounds.lb) / 2), bounds.lb, bounds.ub)\n            res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n            return res.x, res.fun\n        return x0, func(x0)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        best_solution_de, best_value_de = self.differential_evolution(func, bounds, population_size=20)\n\n        if self.func_evals < 0.85 * self.budget:\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Improved robustness through bounds adjustment to prevent indexing errors.", "configspace": "", "generation": 15, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 18 is out of bounds for axis 0 with size 18').", "error": "IndexError('index 18 is out of bounds for axis 0 with size 18')", "parent_id": "5e2d2b32-7640-404b-8b01-0ac9a6f1f0c3", "metadata": {}, "mutation_prompt": null}
{"id": "f9d24f0b-f4b5-4c83-8a77-24ca8bade980", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(min(population_size, len(population))):\n                a, b, c = population[np.random.choice(population_size, 3, replace=False)]\n                adaptive_F = F * (1 - self.func_evals / self.budget)\n                adaptive_F = max(0.2, adaptive_F)\n                \n                if self.func_evals % (self.budget // 10) == 0:\n                    population_size = max(4, int(population_size * 0.9))\n                    population = population[:population_size]\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                try:\n                    trial_value = func(trial_vector)\n                except IndexError:\n                    continue\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                population[i] = trial_vector if trial_value < func(population[i]) else population[i]\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        if self.func_evals < 0.85 * self.budget:\n            x0 = np.clip(0.5 * (x0 + (bounds.ub + bounds.lb) / 2), bounds.lb, bounds.ub)\n            res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n            return res.x, res.fun\n        return x0, func(x0)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        best_solution_de, best_value_de = self.differential_evolution(func, bounds, population_size=20)\n\n        if self.func_evals < 0.85 * self.budget:\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Refined hybrid optimizer with improved boundary handling and adaptive population strategies for robust black box optimization.", "configspace": "", "generation": 15, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 18 is out of bounds for axis 0 with size 18').", "error": "IndexError('index 18 is out of bounds for axis 0 with size 18')", "parent_id": "5e2d2b32-7640-404b-8b01-0ac9a6f1f0c3", "metadata": {}, "mutation_prompt": null}
{"id": "b2a89f3f-c565-44a6-a2da-57efeec22fe8", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(min(population_size, len(population))):\n                indices = np.random.choice(population_size, 3, replace=False)\n                a, b, c = population[indices]  # Adjusted line: fixed potential out-of-bounds index issue\n                adaptive_F = F * (1 - self.func_evals / self.budget)\n                adaptive_F = max(0.2, adaptive_F)\n                \n                if self.func_evals % (self.budget // 10) == 0:\n                    population_size = max(4, int(population_size * 0.9))\n                    population = population[:population_size]\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                try:\n                    trial_value = func(trial_vector)\n                except IndexError:\n                    continue\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        if self.func_evals < 0.85 * self.budget:\n            x0 = np.clip(0.5 * (x0 + (bounds.ub + bounds.lb) / 2), bounds.lb, bounds.ub)\n            res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n            return res.x, res.fun\n        return x0, func(x0)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        best_solution_de, best_value_de = self.differential_evolution(func, bounds, population_size=20)\n\n        if self.func_evals < 0.85 * self.budget:\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Improved robustness by adjusting index selection to prevent out-of-bounds errors in differential evolution.", "configspace": "", "generation": 15, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 18 is out of bounds for axis 0 with size 18').", "error": "IndexError('index 18 is out of bounds for axis 0 with size 18')", "parent_id": "5e2d2b32-7640-404b-8b01-0ac9a6f1f0c3", "metadata": {}, "mutation_prompt": null}
{"id": "1ccdd6f1-74d8-42f9-8f29-466f39ecdddf", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(min(population_size, len(population))):\n                a, b, c = population[np.random.choice(min(population_size, len(population)), 3, replace=False)]\n                adaptive_F = F * (1 - self.func_evals / self.budget)\n                adaptive_F = max(0.2, adaptive_F)\n                \n                if self.func_evals % (self.budget // 10) == 0:\n                    population_size = max(4, int(population_size * 0.9))\n                    population = population[:population_size]\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                try:\n                    trial_value = func(trial_vector)\n                except IndexError:\n                    continue\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        if self.func_evals < 0.85 * self.budget:\n            x0 = np.clip(0.5 * (x0 + (bounds.ub + bounds.lb) / 2), bounds.lb, bounds.ub)\n            res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n            return res.x, res.fun\n        return x0, func(x0)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        best_solution_de, best_value_de = self.differential_evolution(func, bounds, population_size=20)\n\n        if self.func_evals < 0.85 * self.budget:\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Hybrid optimizer with adaptive differential evolution and local search, addressing population index bounds.", "configspace": "", "generation": 15, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 18 is out of bounds for axis 0 with size 18').", "error": "IndexError('index 18 is out of bounds for axis 0 with size 18')", "parent_id": "5e2d2b32-7640-404b-8b01-0ac9a6f1f0c3", "metadata": {}, "mutation_prompt": null}
{"id": "75033fbf-1790-4e83-b57e-8b0fc6b047c8", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(min(population_size, len(population))):\n                a, b, c = population[np.random.choice(len(population), 3, replace=False)]  # Changed line\n                adaptive_F = F * (1 - self.func_evals / self.budget)\n                adaptive_F = max(0.2, adaptive_F)\n                \n                if self.func_evals % (self.budget // 10) == 0:\n                    population_size = max(4, int(population_size * 0.9))\n                    population = population[:population_size]\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                try:\n                    trial_value = func(trial_vector)\n                except IndexError:\n                    continue\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        if self.func_evals < 0.85 * self.budget:\n            x0 = np.clip(0.5 * (x0 + (bounds.ub + bounds.lb) / 2), bounds.lb, bounds.ub)\n            res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n            return res.x, res.fun\n        return x0, func(x0)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        best_solution_de, best_value_de = self.differential_evolution(func, bounds, population_size=20)\n\n        if self.func_evals < 0.85 * self.budget:\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Improved hybrid metaheuristic optimizer with error handling and adaptive population size constraints for robustness.", "configspace": "", "generation": 15, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 18 is out of bounds for axis 0 with size 18').", "error": "IndexError('index 18 is out of bounds for axis 0 with size 18')", "parent_id": "5e2d2b32-7640-404b-8b01-0ac9a6f1f0c3", "metadata": {}, "mutation_prompt": null}
{"id": "da00e1f8-db7a-41f1-a34a-623f02a8e32b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(min(population_size, len(population))):\n                a, b, c = population[np.random.choice(min(len(population), population_size), 3, replace=False)] # Changed line\n                adaptive_F = F * (1 - self.func_evals / self.budget)\n                adaptive_F = max(0.2, adaptive_F)\n                \n                if self.func_evals % (self.budget // 10) == 0:\n                    population_size = max(4, int(population_size * 0.9))\n                    population = population[:population_size]\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                try:\n                    trial_value = func(trial_vector)\n                except IndexError:\n                    continue\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        if self.func_evals < 0.85 * self.budget:\n            x0 = np.clip(0.5 * (x0 + (bounds.ub + bounds.lb) / 2), bounds.lb, bounds.ub)\n            res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n            return res.x, res.fun\n        return x0, func(x0)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        best_solution_de, best_value_de = self.differential_evolution(func, bounds, population_size=20)\n\n        if self.func_evals < 0.85 * self.budget:\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "The algorithm adapts differential evolution's selection mechanism to avoid index errors and improve robustness.", "configspace": "", "generation": 16, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 18 is out of bounds for axis 0 with size 18').", "error": "IndexError('index 18 is out of bounds for axis 0 with size 18')", "parent_id": "e714cf3d-f515-4998-9580-bc3515c4b8c2", "metadata": {}, "mutation_prompt": null}
{"id": "faf10a03-abdb-4949-a79a-3316fbdf7052", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(min(population_size, len(population))):\n                try: # Added error handling line\n                    a, b, c = population[np.random.choice(min(population_size, len(population)), 3, replace=False)] # Changed line\n                except IndexError:\n                    continue\n                adaptive_F = F * (1 - self.func_evals / self.budget)\n                adaptive_F = max(0.2, adaptive_F)\n                \n                if self.func_evals % (self.budget // 10) == 0:\n                    population_size = max(4, int(population_size * 0.9))\n                    population = population[:population_size]\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                try:\n                    trial_value = func(trial_vector)\n                except IndexError:\n                    continue\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        if self.func_evals < 0.85 * self.budget:\n            x0 = np.clip(0.5 * (x0 + (bounds.ub + bounds.lb) / 2), bounds.lb, bounds.ub)\n            res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n            return res.x, res.fun\n        return x0, func(x0)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        best_solution_de, best_value_de = self.differential_evolution(func, bounds, population_size=20)\n\n        if self.func_evals < 0.85 * self.budget:\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced error handling for improved robustness in the differential evolution phase.", "configspace": "", "generation": 16, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 18 is out of bounds for axis 0 with size 18').", "error": "IndexError('index 18 is out of bounds for axis 0 with size 18')", "parent_id": "e714cf3d-f515-4998-9580-bc3515c4b8c2", "metadata": {}, "mutation_prompt": null}
{"id": "a473f56f-4df9-4c96-acd1-407f19d99cd8", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(min(population_size, len(population))):\n                a, b, c = population[np.random.choice(len(population), 3, replace=False)]  # Changed line\n                adaptive_F = F * (1 - self.func_evals / self.budget)\n                adaptive_F = max(0.2, adaptive_F)\n                \n                if self.func_evals % (self.budget // 10) == 0:\n                    population_size = max(4, int(population_size * 0.9))\n                    population = population[:population_size]\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                try:\n                    trial_value = func(trial_vector)\n                except IndexError:\n                    continue\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        if self.func_evals < 0.85 * self.budget:\n            x0 = np.clip(0.5 * (x0 + (bounds.ub + bounds.lb) / 2), bounds.lb, bounds.ub)\n            res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n            return res.x, res.fun\n        return x0, func(x0)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        best_solution_de, best_value_de = self.differential_evolution(func, bounds, population_size=20)\n\n        if self.func_evals < 0.85 * self.budget:\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Adaptive population resizing to prevent IndexError during candidate selection.", "configspace": "", "generation": 16, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 18 is out of bounds for axis 0 with size 18').", "error": "IndexError('index 18 is out of bounds for axis 0 with size 18')", "parent_id": "e714cf3d-f515-4998-9580-bc3515c4b8c2", "metadata": {}, "mutation_prompt": null}
{"id": "a89b6dce-f27f-4480-8496-236a2abc0e23", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(min(population_size, len(population))):\n                a, b, c = population[np.random.choice(population_size, 3, replace=False)] # Changed line\n                adaptive_F = F * (1 - self.func_evals / self.budget)\n                adaptive_F = max(0.2, adaptive_F)\n                \n                if self.func_evals % (self.budget // 10) == 0:\n                    population_size = max(4, int(population_size * 0.9))\n                    population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim)) # Changed line\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                try:\n                    trial_value = func(trial_vector)\n                except IndexError:\n                    continue\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        if self.func_evals < 0.85 * self.budget:\n            x0 = np.clip(0.5 * (x0 + (bounds.ub + bounds.lb) / 2), bounds.lb, bounds.ub)\n            res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n            return res.x, res.fun\n        return x0, func(x0)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        best_solution_de, best_value_de = self.differential_evolution(func, bounds, population_size=20)\n\n        if self.func_evals < 0.85 * self.budget:\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced robustness by dynamic adjustment of population size and reinitialization to mitigate indexing errors.", "configspace": "", "generation": 16, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 18 is out of bounds for axis 0 with size 18').", "error": "IndexError('index 18 is out of bounds for axis 0 with size 18')", "parent_id": "e714cf3d-f515-4998-9580-bc3515c4b8c2", "metadata": {}, "mutation_prompt": null}
{"id": "ce28d120-d4b9-4418-9fa9-f4113c917a14", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(min(population_size, len(population))):\n                a, b, c = population[np.random.choice(len(population), 3, replace=False)] # Changed line\n                adaptive_F = F * (1 - self.func_evals / self.budget)\n                adaptive_F = max(0.2, adaptive_F)\n                \n                if self.func_evals % (self.budget // 10) == 0:\n                    population_size = max(4, int(population_size * 0.9))\n                    population = population[:population_size]\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                try:\n                    trial_value = func(trial_vector)\n                except IndexError:\n                    continue\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        if self.func_evals < 0.85 * self.budget:\n            x0 = np.clip(0.5 * (x0 + (bounds.ub + bounds.lb) / 2), bounds.lb, bounds.ub)\n            res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n            return res.x, res.fun\n        return x0, func(x0)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        best_solution_de, best_value_de = self.differential_evolution(func, bounds, population_size=20)\n\n        if self.func_evals < 0.85 * self.budget:\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Introduced safe indexing in population selection to prevent IndexError.", "configspace": "", "generation": 16, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 18 is out of bounds for axis 0 with size 18').", "error": "IndexError('index 18 is out of bounds for axis 0 with size 18')", "parent_id": "e714cf3d-f515-4998-9580-bc3515c4b8c2", "metadata": {}, "mutation_prompt": null}
{"id": "55e2013f-bb51-43ec-b14d-972feb136065", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(min(population_size, len(population))):\n                a, b, c = population[np.random.choice(min(len(population), population_size), 3, replace=False)] # Changed line\n                adaptive_F = F * (1 - (self.func_evals / self.budget)**2)  # Changed line\n                adaptive_F = max(0.2, adaptive_F)\n                \n                if self.func_evals % (self.budget // 10) == 0:\n                    population_size = max(4, int(population_size * 0.9))\n                    population = population[:population_size]\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                try:\n                    trial_value = func(trial_vector)\n                except IndexError:\n                    continue\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        if self.func_evals < 0.85 * self.budget:\n            x0 = np.clip(0.5 * (x0 + (bounds.ub + bounds.lb) / 2), bounds.lb, bounds.ub)\n            res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n            return res.x, res.fun\n        return x0, func(x0)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        best_solution_de, best_value_de = self.differential_evolution(func, bounds, population_size=20)\n\n        if self.func_evals < 0.85 * self.budget:\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced adaptive control for mutation factor in differential evolution for robust convergence.", "configspace": "", "generation": 17, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 18 is out of bounds for axis 0 with size 18').", "error": "IndexError('index 18 is out of bounds for axis 0 with size 18')", "parent_id": "da00e1f8-db7a-41f1-a34a-623f02a8e32b", "metadata": {}, "mutation_prompt": null}
{"id": "3b697280-82cb-4bd0-ab64-a1419cd0c242", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(population_size):  # Changed line to avoid index error\n                indices = np.random.choice(population_size, 3, replace=False)  # Changed line for clearer random selection\n                a, b, c = population[indices]\n                adaptive_F = F * (1 - self.func_evals / self.budget)\n                adaptive_F = max(0.2, adaptive_F)\n                \n                if self.func_evals % (self.budget // 10) == 0:\n                    population_size = max(4, int(population_size * 0.9))\n                    population = population[:population_size]\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                \n                trial_value = func(trial_vector)  # Removed exception handling, update after ensuring correctness\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        if self.func_evals < 0.85 * self.budget:\n            x0 = np.clip(0.5 * (x0 + (bounds.ub + bounds.lb) / 2), bounds.lb, bounds.ub)\n            res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n            return res.x, res.fun\n        return x0, func(x0)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        best_solution_de, best_value_de = self.differential_evolution(func, bounds, population_size=20)\n\n        if self.func_evals < 0.85 * self.budget:\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "The algorithm adapts differential evolution's selection and mutation mechanism with adaptive parameters for robustness and efficiency in a constrained evaluation budget.", "configspace": "", "generation": 17, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 18 is out of bounds for axis 0 with size 18').", "error": "IndexError('index 18 is out of bounds for axis 0 with size 18')", "parent_id": "da00e1f8-db7a-41f1-a34a-623f02a8e32b", "metadata": {}, "mutation_prompt": null}
{"id": "80700df5-03df-41fc-952d-03fd5c42f7c0", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(min(population_size, len(population))):\n                indices = np.random.choice(min(len(population), population_size), 3, replace=False)\n                a, b, c = population[indices] # Changed line\n                adaptive_F = F * (1 - self.func_evals / self.budget)\n                adaptive_F = max(0.2, adaptive_F)\n                \n                if self.func_evals % (self.budget // 10) == 0:\n                    population_size = max(4, int(population_size * 0.9))\n                    population = population[:population_size]\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                try:\n                    trial_value = func(trial_vector)\n                except IndexError:\n                    continue\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        if self.func_evals < 0.85 * self.budget:\n            x0 = np.clip(0.5 * (x0 + (bounds.ub + bounds.lb) / 2), bounds.lb, bounds.ub)\n            res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n            return res.x, res.fun\n        return x0, func(x0)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        best_solution_de, best_value_de = self.differential_evolution(func, bounds, population_size=20)\n\n        if self.func_evals < 0.85 * self.budget:\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Refines index selection in differential evolution to prevent out-of-bound errors and improve robustness.", "configspace": "", "generation": 17, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 18 is out of bounds for axis 0 with size 18').", "error": "IndexError('index 18 is out of bounds for axis 0 with size 18')", "parent_id": "da00e1f8-db7a-41f1-a34a-623f02a8e32b", "metadata": {}, "mutation_prompt": null}
{"id": "0e1ded27-2b88-4698-801e-0c427f5995e8", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(min(population_size, len(population))):\n                indices = [index for index in range(min(len(population), population_size)) if index != i]  # Changed line\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_F = F * (1 - self.func_evals / self.budget)\n                adaptive_F = max(0.2, adaptive_F)\n                \n                if self.func_evals % (self.budget // 10) == 0:\n                    population_size = max(4, int(population_size * 0.9))\n                    population = population[:population_size]\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                try:\n                    trial_value = func(trial_vector)\n                except IndexError:\n                    continue\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        if self.func_evals < 0.85 * self.budget:\n            x0 = np.clip(0.5 * (x0 + (bounds.ub + bounds.lb) / 2), bounds.lb, bounds.ub)\n            res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n            return res.x, res.fun\n        return x0, func(x0)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        best_solution_de, best_value_de = self.differential_evolution(func, bounds, population_size=20)\n\n        if self.func_evals < 0.85 * self.budget:\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced mutation strategy in differential evolution prevents IndexError and improves search space exploration.", "configspace": "", "generation": 17, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 18 is out of bounds for axis 0 with size 18').", "error": "IndexError('index 18 is out of bounds for axis 0 with size 18')", "parent_id": "da00e1f8-db7a-41f1-a34a-623f02a8e32b", "metadata": {}, "mutation_prompt": null}
{"id": "bc0f8897-5a31-4daf-a176-5b4fe9cba080", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(min(population_size, len(population))):\n                indices = np.random.choice(population_size, 3, replace=False) # Changed line\n                a, b, c = population[indices]\n                adaptive_F = F * (1 - self.func_evals / self.budget)\n                adaptive_F = max(0.2, adaptive_F)\n                \n                if self.func_evals % (self.budget // 10) == 0:\n                    population_size = max(4, int(population_size * 0.9))\n                    population = population[:population_size]\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                try:\n                    trial_value = func(trial_vector)\n                except IndexError:\n                    continue\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        if self.func_evals < 0.85 * self.budget:\n            x0 = np.clip(0.5 * (x0 + (bounds.ub + bounds.lb) / 2), bounds.lb, bounds.ub)\n            res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n            return res.x, res.fun\n        return x0, func(x0)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        best_solution_de, best_value_de = self.differential_evolution(func, bounds, population_size=20)\n\n        if self.func_evals < 0.85 * self.budget:\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced index selection in differential evolution to avoid out-of-bounds errors.", "configspace": "", "generation": 17, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 18 is out of bounds for axis 0 with size 18').", "error": "IndexError('index 18 is out of bounds for axis 0 with size 18')", "parent_id": "da00e1f8-db7a-41f1-a34a-623f02a8e32b", "metadata": {}, "mutation_prompt": null}
{"id": "0311e7be-fe8d-488a-8a39-ed7ddb6233a3", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(min(population_size, len(population))):\n                indices = np.random.choice(min(len(population), population_size), 3, replace=False) # Changed line\n                a, b, c = population[indices]\n                adaptive_F = F * (1 - (self.func_evals / self.budget)**2)  \n                adaptive_F = max(0.2, adaptive_F)\n                \n                if self.func_evals % (self.budget // 10) == 0:\n                    population_size = max(4, int(population_size * 0.9))\n                    population = population[:population_size]\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                try:\n                    trial_value = func(trial_vector)\n                except IndexError:\n                    continue\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        if self.func_evals < 0.85 * self.budget:\n            x0 = np.clip(0.5 * (x0 + (bounds.ub + bounds.lb) / 2), bounds.lb, bounds.ub)\n            res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n            return res.x, res.fun\n        return x0, func(x0)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        best_solution_de, best_value_de = self.differential_evolution(func, bounds, population_size=20)\n\n        if self.func_evals < 0.85 * self.budget:\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Adjusted differential evolution algorithm by refining index handling to avoid IndexError in mutation selection.", "configspace": "", "generation": 18, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 18 is out of bounds for axis 0 with size 18').", "error": "IndexError('index 18 is out of bounds for axis 0 with size 18')", "parent_id": "55e2013f-bb51-43ec-b14d-972feb136065", "metadata": {}, "mutation_prompt": null}
{"id": "7b20a2c6-411f-4d41-b37b-d10096608d67", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(min(population_size, len(population))):\n                a, b, c = population[np.random.choice(len(population), 3, replace=False)]  # Changed line\n                adaptive_F = F * (1 - (self.func_evals / self.budget)**2)  # Changed line\n                adaptive_F = max(0.2, adaptive_F)\n                \n                if self.func_evals % (self.budget // 10) == 0:\n                    population_size = max(4, int(population_size * 0.9))\n                    population = population[:population_size]\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                try:\n                    trial_value = func(trial_vector)\n                except IndexError:\n                    continue\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        if self.func_evals < 0.85 * self.budget:\n            x0 = np.clip(0.5 * (x0 + (bounds.ub + bounds.lb) / 2), bounds.lb, bounds.ub)\n            res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n            return res.x, res.fun\n        return x0, func(x0)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        best_solution_de, best_value_de = self.differential_evolution(func, bounds, population_size=20)\n\n        if self.func_evals < 0.85 * self.budget:\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Improved handling of population size to avoid index errors during differential evolution.", "configspace": "", "generation": 18, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 18 is out of bounds for axis 0 with size 18').", "error": "IndexError('index 18 is out of bounds for axis 0 with size 18')", "parent_id": "55e2013f-bb51-43ec-b14d-972feb136065", "metadata": {}, "mutation_prompt": null}
{"id": "73c57c76-5df8-48a6-a8c7-f4d2d77d82cf", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(min(population_size, len(population))):\n                indices = np.random.choice(min(len(population), population_size), 3, replace=False) # Modified line\n                a, b, c = population[indices]\n                adaptive_F = F * (1 - (self.func_evals / self.budget)**2)\n                adaptive_F = max(0.2, adaptive_F)\n                \n                if self.func_evals % (self.budget // 10) == 0:\n                    population_size = max(4, int(population_size * 0.9))\n                    population = population[:population_size]\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                try:\n                    trial_value = func(trial_vector)\n                except IndexError:\n                    continue\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        if self.func_evals < 0.85 * self.budget:\n            x0 = np.clip(0.5 * (x0 + (bounds.ub + bounds.lb) / 2), bounds.lb, bounds.ub)\n            res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n            return res.x, res.fun\n        return x0, func(x0)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        best_solution_de, best_value_de = self.differential_evolution(func, bounds, population_size=20)\n\n        if self.func_evals < 0.85 * self.budget:\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Improved handling of edge cases by adding bounds checking to prevent index errors during differential evolution.", "configspace": "", "generation": 18, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 18 is out of bounds for axis 0 with size 18').", "error": "IndexError('index 18 is out of bounds for axis 0 with size 18')", "parent_id": "55e2013f-bb51-43ec-b14d-972feb136065", "metadata": {}, "mutation_prompt": null}
{"id": "8f6b98e8-2ee9-4acd-bf15-c5b8e6c5465f", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(min(population_size, len(population))):\n                a, b, c = population[np.random.choice(min(len(population), population_size), 3, replace=False)]\n                adaptive_F = F * (1 - (self.func_evals / self.budget)**2)\n                adaptive_F = max(0.2, adaptive_F)\n                \n                if self.func_evals % (self.budget // 10) == 0 and len(population) > 4:  # Changed line\n                    population_size = max(4, int(population_size * 0.9))\n                    population = population[:population_size]\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                try:\n                    trial_value = func(trial_vector)\n                except IndexError:\n                    continue\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        if self.func_evals < 0.85 * self.budget:\n            x0 = np.clip(0.5 * (x0 + (bounds.ub + bounds.lb) / 2), bounds.lb, bounds.ub)\n            res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n            return res.x, res.fun\n        return x0, func(x0)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        best_solution_de, best_value_de = self.differential_evolution(func, bounds, population_size=20)\n\n        if self.func_evals < 0.85 * self.budget:\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Refined adaptive control for mutation factor with dynamic population size adjustment in DE for enhanced robustness.", "configspace": "", "generation": 18, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 18 is out of bounds for axis 0 with size 18').", "error": "IndexError('index 18 is out of bounds for axis 0 with size 18')", "parent_id": "55e2013f-bb51-43ec-b14d-972feb136065", "metadata": {}, "mutation_prompt": null}
{"id": "201726e2-ba68-4f97-be22-359e78f8dce1", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(min(population_size, len(population))):\n                a, b, c = population[np.random.choice(min(len(population), population_size), 3, replace=False)] # Changed line\n                adaptive_F = F * (1 - (self.func_evals / self.budget)**2)  # Changed line\n                adaptive_F = max(0.2, adaptive_F)\n                \n                if self.func_evals % (self.budget // 10) == 0:\n                    population_size = max(4, int(population_size * 0.9))\n                    population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim)) # Changed line\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                try:\n                    trial_value = func(trial_vector)\n                except IndexError:\n                    continue\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        if self.func_evals < 0.85 * self.budget:\n            x0 = np.clip(0.5 * (x0 + (bounds.ub + bounds.lb) / 2), bounds.lb, bounds.ub)\n            res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n            return res.x, res.fun\n        return x0, func(x0)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        best_solution_de, best_value_de = self.differential_evolution(func, bounds, population_size=20)\n\n        if self.func_evals < 0.85 * self.budget:\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Adaptive population management and refined initialization for robust convergence in an enhanced hybrid metaheuristic optimizer.", "configspace": "", "generation": 18, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 18 is out of bounds for axis 0 with size 18').", "error": "IndexError('index 18 is out of bounds for axis 0 with size 18')", "parent_id": "55e2013f-bb51-43ec-b14d-972feb136065", "metadata": {}, "mutation_prompt": null}
{"id": "73d30c91-3504-48a8-8d53-9eaa2b8ed782", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(min(population_size, len(population))):\n                indices = np.random.choice(len(population), 3, replace=False) # Changed line 1\n                a, b, c = population[indices]\n                adaptive_F = F * (1 - (self.func_evals / self.budget)**1.5) # Changed line 2\n                adaptive_F = max(0.2, adaptive_F)\n                \n                if self.func_evals % (self.budget // 10) == 0 and population_size > 4: # Changed line 3\n                    population_size = max(4, int(population_size * 0.9))\n                    population = population[:population_size]\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                try:\n                    trial_value = func(trial_vector)\n                except IndexError:\n                    continue\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        if self.func_evals < 0.85 * self.budget:\n            x0 = np.clip(0.5 * (x0 + (bounds.ub + bounds.lb) / 2), bounds.lb, bounds.ub)\n            res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n            return res.x, res.fun\n        return x0, func(x0)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        best_solution_de, best_value_de = self.differential_evolution(func, bounds, population_size=20)\n\n        if self.func_evals < 0.85 * self.budget:\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Incremental adaptive population resizing and enhanced mutation strategy in DE for robust optimization.", "configspace": "", "generation": 19, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 18 is out of bounds for axis 0 with size 18').", "error": "IndexError('index 18 is out of bounds for axis 0 with size 18')", "parent_id": "0311e7be-fe8d-488a-8a39-ed7ddb6233a3", "metadata": {}, "mutation_prompt": null}
{"id": "f7bf7971-0fd5-4112-8807-bb00ab938e06", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(min(population_size, len(population))):\n                indices = np.random.choice(len(population), 3, replace=False) # Changed line\n                a, b, c = population[indices]\n                adaptive_F = F * (1 - (self.func_evals / self.budget)**2)  \n                adaptive_F = max(0.2, adaptive_F)\n                \n                if self.func_evals % (self.budget // 10) == 0:\n                    population_size = max(4, int(population_size * 0.9))\n                    population = population[:population_size]\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                try:\n                    trial_value = func(trial_vector)\n                except IndexError:\n                    continue\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        if self.func_evals < 0.85 * self.budget:\n            x0 = np.clip(0.5 * (x0 + (bounds.ub + bounds.lb) / 2), bounds.lb, bounds.ub)\n            res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n            return res.x, res.fun\n        return x0, func(x0)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        best_solution_de, best_value_de = self.differential_evolution(func, bounds, population_size=20)\n\n        if self.func_evals < 0.85 * self.budget:\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced differential evolution with better mutation control and adaptive CR for improved performance.", "configspace": "", "generation": 19, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 18 is out of bounds for axis 0 with size 18').", "error": "IndexError('index 18 is out of bounds for axis 0 with size 18')", "parent_id": "0311e7be-fe8d-488a-8a39-ed7ddb6233a3", "metadata": {}, "mutation_prompt": null}
{"id": "1e061bd3-d4c4-4fc5-9ca9-10cd9f7ef0b9", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(min(population_size, len(population))):\n                indices = np.random.choice(len(population), 3, replace=False)  # Changed line\n                a, b, c = population[indices]\n                adaptive_F = F * (1 - (self.func_evals / self.budget)**2)  \n                adaptive_F = max(0.2, adaptive_F)\n                \n                if self.func_evals % (self.budget // 10) == 0:\n                    population_size = max(4, int(population_size * 0.9))\n                    population = population[:population_size]  # Changed line\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                try:\n                    trial_value = func(trial_vector)\n                except IndexError:\n                    continue\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        if self.func_evals < 0.85 * self.budget:\n            x0 = np.clip(0.5 * (x0 + (bounds.ub + bounds.lb) / 2), bounds.lb, bounds.ub)\n            res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n            return res.x, res.fun\n        return x0, func(x0)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        best_solution_de, best_value_de = self.differential_evolution(func, bounds, population_size=20)\n\n        if self.func_evals < 0.85 * self.budget:\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced differential evolution with refined population control and fixed mutation selection to prevent IndexError.", "configspace": "", "generation": 19, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 18 is out of bounds for axis 0 with size 18').", "error": "IndexError('index 18 is out of bounds for axis 0 with size 18')", "parent_id": "0311e7be-fe8d-488a-8a39-ed7ddb6233a3", "metadata": {}, "mutation_prompt": null}
{"id": "0c74b107-2cee-4a0e-b24b-b849d16cefa8", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(min(population_size, len(population))):\n                indices = np.random.choice(population_size, 3, replace=False)  # Changed line\n                a, b, c = population[indices]\n                adaptive_F = F * (1 - (self.func_evals / self.budget)**2)  \n                adaptive_F = max(0.2, adaptive_F)\n                \n                if self.func_evals % (self.budget // 10) == 0:\n                    population_size = max(4, int(population_size * 0.9))\n                    population = population[:population_size]\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                try:\n                    trial_value = func(trial_vector)\n                except IndexError:\n                    continue\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        if self.func_evals < 0.85 * self.budget:\n            x0 = np.clip(0.5 * (x0 + (bounds.ub + bounds.lb) / 2), bounds.lb, bounds.ub)\n            res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n            return res.x, res.fun\n        return x0, func(x0)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        best_solution_de, best_value_de = self.differential_evolution(func, bounds, population_size=20)\n\n        if self.func_evals < 0.85 * self.budget:\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Improved population size adaptation in differential evolution to prevent IndexError in mutation selection.", "configspace": "", "generation": 19, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 18 is out of bounds for axis 0 with size 18').", "error": "IndexError('index 18 is out of bounds for axis 0 with size 18')", "parent_id": "0311e7be-fe8d-488a-8a39-ed7ddb6233a3", "metadata": {}, "mutation_prompt": null}
{"id": "11d16a8c-04ff-4ea0-8693-d44042115f55", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(population_size):\n                valid_indices = [idx for idx in range(population_size) if idx != i] # Changed line\n                indices = np.random.choice(valid_indices, 3, replace=False) # Changed line\n                a, b, c = population[indices]\n                adaptive_F = F * (1 - (self.func_evals / self.budget)**1.5) # Changed line\n                \n                if self.func_evals % (self.budget // 10) == 0:\n                    population_size = max(4, int(population_size * 0.9))\n                    population = population[:population_size]\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                try:\n                    trial_value = func(trial_vector)\n                except IndexError:\n                    continue\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        if self.func_evals < 0.85 * self.budget:\n            x0 = np.clip(0.5 * (x0 + (bounds.ub + bounds.lb) / 2), bounds.lb, bounds.ub)\n            res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n            return res.x, res.fun\n        return x0, func(x0)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        best_solution_de, best_value_de = self.differential_evolution(func, bounds, population_size=20)\n\n        if self.func_evals < 0.85 * self.budget:\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced DE strategy by correcting index handling and tuning adaptive parameters for robust optimization.", "configspace": "", "generation": 19, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 18 is out of bounds for axis 0 with size 18').", "error": "IndexError('index 18 is out of bounds for axis 0 with size 18')", "parent_id": "0311e7be-fe8d-488a-8a39-ed7ddb6233a3", "metadata": {}, "mutation_prompt": null}
{"id": "1555d6c6-3f0d-4126-8141-37d1e4284dc6", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(min(population_size, len(population))):\n                indices = np.random.choice(len(population), 3, replace=False)\n                a, b, c = population[indices]\n                adaptive_F = F * (1 - (self.func_evals / self.budget)**1.5)\n                adaptive_F = max(0.2, adaptive_F)\n                \n                if self.func_evals % (self.budget // 10) == 0 and len(population) > 4: # Change 1\n                    population_size = max(4, int(population_size * 0.9))\n                    population = population[:population_size]\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                try:\n                    trial_value = func(trial_vector)\n                except IndexError:\n                    continue\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        if self.func_evals < 0.85 * self.budget:\n            x0 = np.clip(0.5 * (x0 + (bounds.ub + bounds.lb) / 2), bounds.lb, bounds.ub)\n            res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n            return res.x, res.fun\n        return x0, func(x0)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        best_solution_de, best_value_de = self.differential_evolution(func, bounds, population_size=20)\n\n        if self.func_evals < 0.85 * self.budget:\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced population management and adaptive mutation in DE for black box optimization.", "configspace": "", "generation": 20, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 18 is out of bounds for axis 0 with size 18').", "error": "IndexError('index 18 is out of bounds for axis 0 with size 18')", "parent_id": "73d30c91-3504-48a8-8d53-9eaa2b8ed782", "metadata": {}, "mutation_prompt": null}
{"id": "e7be9c28-c397-44ec-9782-a6f6c5cced8b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(min(population_size, len(population))):\n                indices = np.random.choice(len(population), 3, replace=False)\n                a, b, c = population[indices]\n                adaptive_F = F * (1 - (self.func_evals / self.budget)**1.5)\n                adaptive_F = max(0.2, adaptive_F)\n                \n                if self.func_evals % (self.budget // 10) == 0 and population_size > 4:\n                    population_size = max(4, int(population_size * 0.9))\n                    population = population[:population_size]\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                try:\n                    trial_value = func(trial_vector)\n                except IndexError:\n                    continue\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        if self.func_evals < 0.85 * self.budget:\n            x0 = np.clip(0.5 * (x0 + (bounds.ub + bounds.lb) / 2), bounds.lb, bounds.ub)\n            res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n            return res.x, res.fun\n        return x0, func(x0)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        best_solution_de, best_value_de = self.differential_evolution(func, bounds, population_size=20)\n\n        if self.func_evals < 0.85 * self.budget:\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced differential evolution with population size correction and boundary handling for robust optimization.", "configspace": "", "generation": 20, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 18 is out of bounds for axis 0 with size 18').", "error": "IndexError('index 18 is out of bounds for axis 0 with size 18')", "parent_id": "73d30c91-3504-48a8-8d53-9eaa2b8ed782", "metadata": {}, "mutation_prompt": null}
{"id": "d8c8ce8a-dfbf-4f0c-9ed0-93d34c96fd5d", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(min(population_size, len(population))):\n                indices = np.random.choice(len(population), 3, replace=False)\n                a, b, c = population[indices]\n                adaptive_F = F * (1 - (self.func_evals / self.budget)**1.5)\n                adaptive_F = max(0.2, adaptive_F)\n\n                # Change in line: Avoid resizing to less than the current population size\n                if self.func_evals % (self.budget // 10) == 0 and len(population) > 4:\n                    population_size = max(4, int(len(population) * 0.9))\n                    population = population[:population_size]\n\n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                try:\n                    trial_value = func(trial_vector)\n                except IndexError:\n                    continue\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n\n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        if self.func_evals < 0.85 * self.budget:\n            x0 = np.clip(0.5 * (x0 + (bounds.ub + bounds.lb) / 2), bounds.lb, bounds.ub)\n            res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n            return res.x, res.fun\n        return x0, func(x0)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        best_solution_de, best_value_de = self.differential_evolution(func, bounds, population_size=20)\n\n        if self.func_evals < 0.85 * self.budget:\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced stability in population resizing and mutation in DE for robust black box optimization.", "configspace": "", "generation": 20, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 18 is out of bounds for axis 0 with size 18').", "error": "IndexError('index 18 is out of bounds for axis 0 with size 18')", "parent_id": "73d30c91-3504-48a8-8d53-9eaa2b8ed782", "metadata": {}, "mutation_prompt": null}
{"id": "0e5806a5-8199-4f4d-8cc4-8309bb92918b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(min(population_size, len(population))):\n                indices = np.random.choice(len(population), 3, replace=False) # Changed line 1\n                a, b, c = population[indices]\n                adaptive_F = F * (1 - (self.func_evals / self.budget)**1.5) \n                adaptive_F = max(0.2, adaptive_F)\n                \n                if self.func_evals % (self.budget // 10) == 0 and population_size > 4: \n                    population_size = max(4, int(population_size * 0.9))\n                    population = population[:population_size]\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                try:\n                    trial_value = func(trial_vector)\n                except IndexError:\n                    continue\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        if self.func_evals < 0.85 * self.budget:\n            x0 = np.clip(0.5 * (x0 + (bounds.ub + bounds.lb) / 2), bounds.lb, bounds.ub)\n            res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n            return res.x, res.fun\n        return x0, func(x0)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        best_solution_de, best_value_de = self.differential_evolution(func, bounds, population_size=20)\n\n        if self.func_evals < 0.85 * self.budget:\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Hybrid DE with adaptive population reduction for efficient search and robustness.", "configspace": "", "generation": 20, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 18 is out of bounds for axis 0 with size 18').", "error": "IndexError('index 18 is out of bounds for axis 0 with size 18')", "parent_id": "73d30c91-3504-48a8-8d53-9eaa2b8ed782", "metadata": {}, "mutation_prompt": null}
{"id": "681bbf85-32f5-4ed3-aa13-3978e26a7a8d", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.func_evals = 0\n\n    def quasi_oppositional_initialization(self, bounds):\n        mid_point = (bounds.ub + bounds.lb) / 2\n        range_ = (bounds.ub - bounds.lb) / 2\n        return (mid_point + range_ * (np.random.rand(self.dim) - 0.5),\n                mid_point - range_ * (np.random.rand(self.dim) - 0.5))\n\n    def differential_evolution(self, func, bounds, population_size=10, F=0.5, CR=0.9):\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            for i in range(min(population_size, len(population))):\n                indices = np.random.choice(len(population), 3, replace=False)\n                a, b, c = population[indices]\n                adaptive_F = F * (1 - (self.func_evals / self.budget)**1.5)\n                adaptive_F = max(0.2, adaptive_F)\n                \n                if self.func_evals % (self.budget // 10) == 0 and population_size > 4:\n                    population_size = max(4, int(population_size * 0.9))\n                    population = np.vstack([population, np.random.uniform(bounds.lb, bounds.ub, (population_size - len(population), self.dim))]) # Changed line\n                \n                mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n                CR_dynamic = CR * (1 - self.func_evals / self.budget)\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                trial_vector = np.where(cross_points, mutant_vector, population[i])\n                \n                trial_vector = np.clip(trial_vector, bounds.lb, bounds.ub)\n                try:\n                    trial_value = func(trial_vector)\n                except IndexError:\n                    continue\n                self.func_evals += 1\n                if trial_value < best_value:\n                    best_value = trial_value\n                    best_solution = trial_vector\n                \n                if trial_value < func(population[i]):\n                    population[i] = trial_vector\n                \n                if self.func_evals >= self.budget:\n                    break\n        \n        return best_solution, best_value\n\n    def local_bfgs_optimization(self, func, x0, bounds):\n        if self.func_evals < 0.85 * self.budget:\n            x0 = np.clip(0.5 * (x0 + (bounds.ub + bounds.lb) / 2), bounds.lb, bounds.ub)\n            res = minimize(func, x0, method='L-BFGS-B', bounds=np.array(list(zip(bounds.lb, bounds.ub))))\n            return res.x, res.fun\n        return x0, func(x0)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        init1, init2 = self.quasi_oppositional_initialization(bounds)\n        \n        best_solution_de, best_value_de = self.differential_evolution(func, bounds, population_size=20)\n\n        if self.func_evals < 0.85 * self.budget:\n            best_solution_bfgs, best_value_bfgs = self.local_bfgs_optimization(func, best_solution_de, bounds)\n        else:\n            best_solution_bfgs, best_value_bfgs = best_solution_de, best_value_de\n\n        return best_solution_bfgs, best_value_bfgs", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced mutation strategy for better convergence and population size adaptation in DE.", "configspace": "", "generation": 20, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('negative dimensions are not allowed').", "error": "ValueError('negative dimensions are not allowed')", "parent_id": "73d30c91-3504-48a8-8d53-9eaa2b8ed782", "metadata": {}, "mutation_prompt": null}
