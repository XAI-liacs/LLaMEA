{"id": "0b6cb531-379c-42ae-b491-0491e6e0a354", "solution": "import numpy as np\n\nclass HybridHarmonyDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.harmony_memory_size = 10\n        self.hmcr = 0.9  # Harmony Memory Considering Rate\n        self.par = 0.3   # Pitch Adjusting Rate\n        self.f = 0.5     # Differential weight\n        self.cr = 0.9    # Crossover probability\n\n    def __call__(self, func):\n        # Initialize harmony memory\n        harmony_memory = np.random.uniform(\n            low=func.bounds.lb, high=func.bounds.ub, size=(self.harmony_memory_size, self.dim)\n        )\n        harmony_fitness = np.array([func(hm) for hm in harmony_memory])\n        evaluations = self.harmony_memory_size\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Generate new harmony\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.hmcr:\n                    # Memory consideration\n                    new_harmony[i] = harmony_memory[np.random.randint(self.harmony_memory_size), i]\n                    if np.random.rand() < self.par:\n                        # Pitch adjustment\n                        new_harmony[i] += np.random.uniform(-1, 1) * (func.bounds.ub[i] - func.bounds.lb[i]) * 0.01\n                else:\n                    # Random selection\n                    new_harmony[i] = np.random.uniform(func.bounds.lb[i], func.bounds.ub[i])\n\n            new_harmony = np.clip(new_harmony, func.bounds.lb, func.bounds.ub)\n            new_harmony_fitness = func(new_harmony)\n            evaluations += 1\n\n            # Differential Evolution\n            if evaluations < self.budget:\n                idxs = np.random.choice(self.harmony_memory_size, 3, replace=False)\n                x1, x2, x3 = harmony_memory[idxs]\n                mutant_vector = x1 + self.f * (x2 - x3)\n                trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, new_harmony)\n                trial_vector = np.clip(trial_vector, func.bounds.lb, func.bounds.ub)\n                trial_fitness = func(trial_vector)\n                evaluations += 1\n\n                # Select the best solution\n                if trial_fitness < new_harmony_fitness:\n                    new_harmony, new_harmony_fitness = trial_vector, trial_fitness\n\n            # Update harmony memory if new harmony is better\n            worst_idx = np.argmax(harmony_fitness)\n            if new_harmony_fitness < harmony_fitness[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                harmony_fitness[worst_idx] = new_harmony_fitness\n\n        # Return the best solution found\n        best_idx = np.argmin(harmony_fitness)\n        return harmony_memory[best_idx]", "name": "HybridHarmonyDifferentialEvolution", "description": "A hybrid harmony search and differential evolution algorithm that combines global exploration with local exploitation to efficiently optimize black box functions within given budget constraints.", "configspace": "", "generation": 0, "fitness": 0.1869734850737718, "feedback": "The algorithm HybridHarmonyDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.187 with standard deviation 0.041. And the mean value of best solutions found was 0.302 (0. is the best) with standard deviation 0.318.", "error": "", "parent_id": null, "metadata": {"aucs": [0.23955574861062034, 0.18204228615541107, 0.13932242045528398], "final_y": [0.06757480468435928, 0.08709608939099321, 0.750946027055325]}, "mutation_prompt": null}
{"id": "48240291-4fa3-46a2-96f5-a9306213d002", "solution": "import numpy as np\n\nclass HybridHarmonyDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.harmony_memory_size = 10\n        self.hmcr = 0.9  # Harmony Memory Considering Rate\n        self.par = 0.3   # Pitch Adjusting Rate\n        self.f = 0.5     # Differential weight\n        self.cr = 0.9    # Crossover probability\n\n    def __call__(self, func):\n        # Initialize harmony memory\n        harmony_memory = np.random.uniform(\n            low=func.bounds.lb, high=func.bounds.ub, size=(self.harmony_memory_size, self.dim)\n        )\n        harmony_fitness = np.array([func(hm) for hm in harmony_memory])\n        evaluations = self.harmony_memory_size\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Generate new harmony\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.hmcr:\n                    # Memory consideration\n                    new_harmony[i] = harmony_memory[np.random.randint(self.harmony_memory_size), i]\n                    if np.random.rand() < self.par:\n                        # Adaptive Pitch adjustment\n                        adapt_factor = 1 - (evaluations / self.budget)\n                        new_harmony[i] += np.random.uniform(-1, 1) * (func.bounds.ub[i] - func.bounds.lb[i]) * 0.01 * adapt_factor\n                else:\n                    # Random selection\n                    new_harmony[i] = np.random.uniform(func.bounds.lb[i], func.bounds.ub[i])\n\n            new_harmony = np.clip(new_harmony, func.bounds.lb, func.bounds.ub)\n            new_harmony_fitness = func(new_harmony)\n            evaluations += 1\n\n            # Differential Evolution\n            if evaluations < self.budget:\n                idxs = np.random.choice(self.harmony_memory_size, 3, replace=False)\n                x1, x2, x3 = harmony_memory[idxs]\n                mutant_vector = x1 + self.f * (x2 - x3)\n                trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, new_harmony)\n                trial_vector = np.clip(trial_vector, func.bounds.lb, func.bounds.ub)\n                trial_fitness = func(trial_vector)\n                evaluations += 1\n\n                # Select the best solution\n                if trial_fitness < new_harmony_fitness:\n                    new_harmony, new_harmony_fitness = trial_vector, trial_fitness\n\n            # Update harmony memory if new harmony is better\n            worst_idx = np.argmax(harmony_fitness)\n            if new_harmony_fitness < harmony_fitness[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                harmony_fitness[worst_idx] = new_harmony_fitness\n\n        # Return the best solution found\n        best_idx = np.argmin(harmony_fitness)\n        return harmony_memory[best_idx]", "name": "HybridHarmonyDifferentialEvolution", "description": "A hybrid harmony search and differential evolution algorithm with adaptive pitch adjustment to optimize black box functions efficiently within budget constraints.", "configspace": "", "generation": 1, "fitness": 0.28432088132688055, "feedback": "The algorithm HybridHarmonyDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.284 with standard deviation 0.114. And the mean value of best solutions found was 0.288 (0. is the best) with standard deviation 0.405.", "error": "", "parent_id": "0b6cb531-379c-42ae-b491-0491e6e0a354", "metadata": {"aucs": [0.28086803719490316, 0.4257847633748343, 0.14630984341090425], "final_y": [0.00377296837570191, 0.0006788518764079074, 0.8609311089730469]}, "mutation_prompt": null}
{"id": "1e868ff3-7c5e-49ce-91bd-582875b8930d", "solution": "import numpy as np\n\nclass HybridHarmonyDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.harmony_memory_size = 10\n        self.hmcr = 0.9  # Harmony Memory Considering Rate\n        self.par = 0.3   # Pitch Adjusting Rate\n        self.f = 0.5     # Differential weight\n        self.cr = 0.9    # Crossover probability\n\n    def __call__(self, func):\n        # Initialize harmony memory\n        harmony_memory = np.random.uniform(\n            low=func.bounds.lb, high=func.bounds.ub, size=(self.harmony_memory_size, self.dim)\n        )\n        harmony_fitness = np.array([func(hm) for hm in harmony_memory])\n        evaluations = self.harmony_memory_size\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Generate new harmony\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.hmcr:\n                    # Memory consideration\n                    new_harmony[i] = harmony_memory[np.random.randint(self.harmony_memory_size), i]\n                    if np.random.rand() < self.par:\n                        # Adaptive Pitch adjustment\n                        adapt_factor = 1 - (evaluations / self.budget)\n                        new_harmony[i] += np.random.uniform(-1, 1) * (func.bounds.ub[i] - func.bounds.lb[i]) * 0.01 * adapt_factor\n                else:\n                    # Random selection\n                    new_harmony[i] = np.random.uniform(func.bounds.lb[i], func.bounds.ub[i])\n\n            new_harmony = np.clip(new_harmony, func.bounds.lb, func.bounds.ub)\n            new_harmony_fitness = func(new_harmony)\n            evaluations += 1\n\n            # Differential Evolution\n            if evaluations < self.budget:\n                idxs = np.random.choice(self.harmony_memory_size, 3, replace=False)\n                x1, x2, x3 = harmony_memory[idxs]\n                self.f = 0.5 + 0.5 * (1 - evaluations / self.budget)  # Learning factor adjustment\n                mutant_vector = x1 + self.f * (x2 - x3)\n                trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, new_harmony)\n                trial_vector = np.clip(trial_vector, func.bounds.lb, func.bounds.ub)\n                trial_fitness = func(trial_vector)\n                evaluations += 1\n\n                # Select the best solution\n                if trial_fitness < new_harmony_fitness:\n                    new_harmony, new_harmony_fitness = trial_vector, trial_fitness\n\n            # Update harmony memory if new harmony is better\n            worst_idx = np.argmax(harmony_fitness)\n            if new_harmony_fitness < harmony_fitness[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                harmony_fitness[worst_idx] = new_harmony_fitness\n\n        # Return the best solution found\n        best_idx = np.argmin(harmony_fitness)\n        return harmony_memory[best_idx]", "name": "HybridHarmonyDifferentialEvolution", "description": "Integrate a learning factor adjustment to enhance the exploration-exploitation balance in the hybrid harmony and differential evolution algorithm.", "configspace": "", "generation": 2, "fitness": 0.30829346870765206, "feedback": "The algorithm HybridHarmonyDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.308 with standard deviation 0.090. And the mean value of best solutions found was 0.094 (0. is the best) with standard deviation 0.133.", "error": "", "parent_id": "48240291-4fa3-46a2-96f5-a9306213d002", "metadata": {"aucs": [0.391069970518348, 0.18245986513396428, 0.3513505704706439], "final_y": [1.927497447651436e-07, 0.2817434961762621, 0.000585835560720372]}, "mutation_prompt": null}
{"id": "ef7b1c9e-d75c-4f72-824b-0517277eef97", "solution": "import numpy as np\n\nclass HybridHarmonyDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.harmony_memory_size = 10\n        self.hmcr = 0.9  # Harmony Memory Considering Rate\n        self.par = 0.3   # Pitch Adjusting Rate\n        self.f = 0.5     # Differential weight\n        self.cr = 0.9    # Crossover probability\n\n    def __call__(self, func):\n        # Initialize harmony memory\n        harmony_memory = np.random.uniform(\n            low=func.bounds.lb, high=func.bounds.ub, size=(self.harmony_memory_size, self.dim)\n        )\n        harmony_fitness = np.array([func(hm) for hm in harmony_memory])\n        evaluations = self.harmony_memory_size\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Generate new harmony\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.hmcr:\n                    # Memory consideration\n                    new_harmony[i] = harmony_memory[np.random.randint(self.harmony_memory_size), i]\n                    if np.random.rand() < self.par:\n                        # Adaptive Pitch adjustment\n                        adapt_factor = 1 - (evaluations / self.budget)\n                        new_harmony[i] += np.random.uniform(-1, 1) * (func.bounds.ub[i] - func.bounds.lb[i]) * 0.01 * adapt_factor\n                else:\n                    # Random selection\n                    new_harmony[i] = np.random.uniform(func.bounds.lb[i], func.bounds.ub[i])\n\n            new_harmony = np.clip(new_harmony, func.bounds.lb, func.bounds.ub)\n            new_harmony_fitness = func(new_harmony)\n            evaluations += 1\n\n            # Differential Evolution\n            if evaluations < self.budget:\n                idxs = np.random.choice(self.harmony_memory_size, 3, replace=False)\n                x1, x2, x3 = harmony_memory[idxs]\n                self.f = 0.5 + 0.5 * (1 - evaluations / self.budget)  # Learning factor adjustment\n                mutant_vector = x1 + self.f * (x2 - x3)\n                trial_vector = np.where(np.random.rand(self.dim) < self.cr * (1 - evaluations / self.budget), mutant_vector, new_harmony)\n                trial_vector = np.clip(trial_vector, func.bounds.lb, func.bounds.ub)\n                trial_fitness = func(trial_vector)\n                evaluations += 1\n\n                # Select the best solution\n                if trial_fitness < new_harmony_fitness:\n                    new_harmony, new_harmony_fitness = trial_vector, trial_fitness\n\n            # Update harmony memory if new harmony is better\n            worst_idx = np.argmax(harmony_fitness)\n            if new_harmony_fitness < harmony_fitness[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                harmony_fitness[worst_idx] = new_harmony_fitness\n\n        # Return the best solution found\n        best_idx = np.argmin(harmony_fitness)\n        return harmony_memory[best_idx]", "name": "HybridHarmonyDifferentialEvolution", "description": "Introduce a decay factor to dynamically adjust the Crossover probability for improved exploration-exploitation trade-off.", "configspace": "", "generation": 3, "fitness": 0.18406644011450612, "feedback": "The algorithm HybridHarmonyDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.184 with standard deviation 0.043. And the mean value of best solutions found was 0.644 (0. is the best) with standard deviation 0.531.", "error": "", "parent_id": "1e868ff3-7c5e-49ce-91bd-582875b8930d", "metadata": {"aucs": [0.24343489950552555, 0.14327821300287347, 0.16548620783511936], "final_y": [0.0076524445568089934, 1.3080801548749315, 0.6158857158697094]}, "mutation_prompt": null}
{"id": "a642df26-3851-4a6a-b349-37607aa27805", "solution": "import numpy as np\n\nclass HybridHarmonyDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.harmony_memory_size = 10\n        self.hmcr = 0.9  # Harmony Memory Considering Rate\n        self.par = 0.3   # Pitch Adjusting Rate\n        self.f = 0.5     # Differential weight\n        self.cr = 0.9    # Crossover probability\n\n    def __call__(self, func):\n        # Initialize harmony memory\n        harmony_memory = np.random.uniform(\n            low=func.bounds.lb, high=func.bounds.ub, size=(self.harmony_memory_size, self.dim)\n        )\n        harmony_fitness = np.array([func(hm) for hm in harmony_memory])\n        evaluations = self.harmony_memory_size\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Generate new harmony\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.hmcr:\n                    # Memory consideration\n                    new_harmony[i] = harmony_memory[np.random.randint(self.harmony_memory_size), i]\n                    if np.random.rand() < self.par:\n                        # Adaptive Pitch adjustment with dynamic PAR\n                        adapt_factor = 1 - (evaluations / self.budget)\n                        self.par = 0.1 + 0.2 * adapt_factor  # Dynamic adjustment \n                        new_harmony[i] += np.random.uniform(-1, 1) * (func.bounds.ub[i] - func.bounds.lb[i]) * 0.01 * adapt_factor\n                else:\n                    # Random selection\n                    new_harmony[i] = np.random.uniform(func.bounds.lb[i], func.bounds.ub[i])\n\n            new_harmony = np.clip(new_harmony, func.bounds.lb, func.bounds.ub)\n            new_harmony_fitness = func(new_harmony)\n            evaluations += 1\n\n            # Differential Evolution\n            if evaluations < self.budget:\n                idxs = np.random.choice(self.harmony_memory_size, 3, replace=False)\n                x1, x2, x3 = harmony_memory[idxs]\n                self.f = 0.5 + 0.5 * (1 - evaluations / self.budget)  # Learning factor adjustment\n                mutant_vector = x1 + self.f * (x2 - x3)\n                trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, new_harmony)\n                trial_vector = np.clip(trial_vector, func.bounds.lb, func.bounds.ub)\n                trial_fitness = func(trial_vector)\n                evaluations += 1\n\n                # Select the best solution\n                if trial_fitness < new_harmony_fitness:\n                    new_harmony, new_harmony_fitness = trial_vector, trial_fitness\n\n            # Update harmony memory if new harmony is better\n            worst_idx = np.argmax(harmony_fitness)\n            if new_harmony_fitness < harmony_fitness[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                harmony_fitness[worst_idx] = new_harmony_fitness\n\n        # Return the best solution found\n        best_idx = np.argmin(harmony_fitness)\n        return harmony_memory[best_idx]", "name": "HybridHarmonyDifferentialEvolution", "description": "Integrate a dynamic adjustment to the pitch adjusting rate (PAR) for improved adaptability.", "configspace": "", "generation": 4, "fitness": 0.2752386875808751, "feedback": "The algorithm HybridHarmonyDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.275 with standard deviation 0.010. And the mean value of best solutions found was 0.011 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "1e868ff3-7c5e-49ce-91bd-582875b8930d", "metadata": {"aucs": [0.2836480028763583, 0.2611484337176563, 0.28091962614861077], "final_y": [0.008897474185715685, 0.012697260868280635, 0.012058517472573188]}, "mutation_prompt": null}
{"id": "87cd4099-c0d4-4928-9e37-b7ad2a6bb11c", "solution": "import numpy as np\n\nclass HybridHarmonyDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.harmony_memory_size = 10\n        self.hmcr = 0.9  # Harmony Memory Considering Rate\n        self.par = 0.3   # Pitch Adjusting Rate\n        self.f = 0.5     # Differential weight\n        self.cr = 0.9    # Crossover probability\n\n    def __call__(self, func):\n        # Initialize harmony memory\n        harmony_memory = np.random.uniform(\n            low=func.bounds.lb, high=func.bounds.ub, size=(self.harmony_memory_size, self.dim)\n        )\n        harmony_fitness = np.array([func(hm) for hm in harmony_memory])\n        evaluations = self.harmony_memory_size\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Generate new harmony\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.hmcr:\n                    # Memory consideration\n                    new_harmony[i] = harmony_memory[np.random.randint(self.harmony_memory_size), i]\n                    if np.random.rand() < self.par:\n                        # Adaptive Pitch adjustment\n                        adapt_factor = 1 - (evaluations / self.budget)\n                        new_harmony[i] += np.random.uniform(-1, 1) * (func.bounds.ub[i] - func.bounds.lb[i]) * 0.01 * adapt_factor\n                else:\n                    # Random selection\n                    new_harmony[i] = np.random.uniform(func.bounds.lb[i], func.bounds.ub[i])\n\n            new_harmony = np.clip(new_harmony, func.bounds.lb, func.bounds.ub)\n            new_harmony_fitness = func(new_harmony)\n            evaluations += 1\n\n            # Differential Evolution\n            if evaluations < self.budget:\n                idxs = np.random.choice(self.harmony_memory_size, 3, replace=False)\n                x1, x2, x3 = harmony_memory[idxs]\n                self.f = 0.5 + 0.5 * (1 - evaluations / self.budget)  # Learning factor adjustment\n                mutant_vector = x1 + self.f * (x2 - x3)\n                trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, new_harmony)\n                trial_vector = np.clip(trial_vector, func.bounds.lb, func.bounds.ub)\n                trial_fitness = func(trial_vector)\n                evaluations += 1\n\n                # Select the best solution\n                if trial_fitness < new_harmony_fitness:\n                    new_harmony, new_harmony_fitness = trial_vector, trial_fitness\n\n            # Update harmony memory if new harmony is better\n            worst_idx = np.argmax(harmony_fitness)\n            if new_harmony_fitness < harmony_fitness[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                harmony_fitness[worst_idx] = new_harmony_fitness\n\n        # Return the best solution found\n        best_idx = np.argmin(harmony_fitness)\n        return harmony_memory[best_idx]", "name": "HybridHarmonyDifferentialEvolution", "description": "Introduce a dynamic adjustment to the pitch adjusting rate (PAR) based on remaining evaluations to enhance convergence.", "configspace": "", "generation": 5, "fitness": 0.4715158935595139, "feedback": "The algorithm HybridHarmonyDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.472 with standard deviation 0.054. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "1e868ff3-7c5e-49ce-91bd-582875b8930d", "metadata": {"aucs": [0.4014044425226867, 0.4809451987594744, 0.5321980393963808], "final_y": [5.807346730291547e-07, 7.151236816521785e-08, 1.6416566766041994e-08]}, "mutation_prompt": null}
{"id": "ec8f9bfb-3c48-40be-987e-04bf9631cf55", "solution": "import numpy as np\n\nclass HybridHarmonyDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.harmony_memory_size = 10\n        self.hmcr = 0.9  # Harmony Memory Considering Rate\n        self.par = 0.3   # Pitch Adjusting Rate\n        self.f = 0.5     # Differential weight\n        self.cr = 0.9    # Crossover probability\n\n    def __call__(self, func):\n        # Initialize harmony memory\n        harmony_memory = np.random.uniform(\n            low=func.bounds.lb, high=func.bounds.ub, size=(self.harmony_memory_size, self.dim)\n        )\n        harmony_fitness = np.array([func(hm) for hm in harmony_memory])\n        evaluations = self.harmony_memory_size\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Generate new harmony\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.hmcr:\n                    # Memory consideration\n                    new_harmony[i] = harmony_memory[np.random.randint(self.harmony_memory_size), i]\n                    if np.random.rand() < self.par:\n                        # Adaptive Pitch adjustment\n                        adapt_factor = 1 - (evaluations / self.budget)\n                        random_factor = np.random.rand()  # Added random factor for exploration\n                        new_harmony[i] += np.random.uniform(-1, 1) * (func.bounds.ub[i] - func.bounds.lb[i]) * 0.01 * adapt_factor * random_factor\n                else:\n                    # Random selection\n                    new_harmony[i] = np.random.uniform(func.bounds.lb[i], func.bounds.ub[i])\n\n            new_harmony = np.clip(new_harmony, func.bounds.lb, func.bounds.ub)\n            new_harmony_fitness = func(new_harmony)\n            evaluations += 1\n\n            # Differential Evolution\n            if evaluations < self.budget:\n                idxs = np.random.choice(self.harmony_memory_size, 3, replace=False)\n                x1, x2, x3 = harmony_memory[idxs]\n                self.f = 0.5 + 0.5 * (1 - evaluations / self.budget)  # Learning factor adjustment\n                mutant_vector = x1 + self.f * (x2 - x3)\n                trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, new_harmony)\n                trial_vector = np.clip(trial_vector, func.bounds.lb, func.bounds.ub)\n                trial_fitness = func(trial_vector)\n                evaluations += 1\n\n                # Select the best solution\n                if trial_fitness < new_harmony_fitness:\n                    new_harmony, new_harmony_fitness = trial_vector, trial_fitness\n\n            # Update harmony memory if new harmony is better\n            worst_idx = np.argmax(harmony_fitness)\n            if new_harmony_fitness < harmony_fitness[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                harmony_fitness[worst_idx] = new_harmony_fitness\n\n        # Return the best solution found\n        best_idx = np.argmin(harmony_fitness)\n        return harmony_memory[best_idx]", "name": "HybridHarmonyDifferentialEvolution", "description": "Refine the dynamic adjustment of the pitch adjusting rate (PAR) by incorporating a random factor to enhance exploration capabilities.", "configspace": "", "generation": 6, "fitness": 0.2125386489088499, "feedback": "The algorithm HybridHarmonyDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.213 with standard deviation 0.079. And the mean value of best solutions found was 0.565 (0. is the best) with standard deviation 0.467.", "error": "", "parent_id": "87cd4099-c0d4-4928-9e37-b7ad2a6bb11c", "metadata": {"aucs": [0.32329132362612145, 0.1649432592590997, 0.1493813638413286], "final_y": [0.00016872421842729394, 0.5519686475719721, 1.1437195511089777]}, "mutation_prompt": null}
{"id": "b507214c-b895-4b75-8c1f-101d55b8e3af", "solution": "import numpy as np\n\nclass HybridHarmonyDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.harmony_memory_size = 10\n        self.hmcr = 0.9  # Harmony Memory Considering Rate\n        self.par = 0.3   # Pitch Adjusting Rate\n        self.f = 0.5     # Differential weight\n        self.cr = 0.9    # Crossover probability\n\n    def __call__(self, func):\n        # Initialize harmony memory\n        harmony_memory = np.random.uniform(\n            low=func.bounds.lb, high=func.bounds.ub, size=(self.harmony_memory_size, self.dim)\n        )\n        harmony_fitness = np.array([func(hm) for hm in harmony_memory])\n        evaluations = self.harmony_memory_size\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Generate new harmony\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.hmcr:\n                    # Memory consideration\n                    new_harmony[i] = harmony_memory[np.random.randint(self.harmony_memory_size), i]\n                    if np.random.rand() < self.par:\n                        # Enhanced adaptive Pitch adjustment\n                        best_harmony = harmony_memory[np.argmin(harmony_fitness)]\n                        new_harmony[i] += np.random.uniform(-1, 1) * (best_harmony[i] - new_harmony[i]) * 0.01\n\n                else:\n                    # Random selection\n                    new_harmony[i] = np.random.uniform(func.bounds.lb[i], func.bounds.ub[i])\n\n            new_harmony = np.clip(new_harmony, func.bounds.lb, func.bounds.ub)\n            new_harmony_fitness = func(new_harmony)\n            evaluations += 1\n\n            # Differential Evolution\n            if evaluations < self.budget:\n                idxs = np.random.choice(self.harmony_memory_size, 3, replace=False)\n                x1, x2, x3 = harmony_memory[idxs]\n                self.f = 0.8 - 0.3 * (evaluations / self.budget)  # Adaptive scaling factor\n                mutant_vector = x1 + self.f * (x2 - x3)\n                trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, new_harmony)\n                trial_vector = np.clip(trial_vector, func.bounds.lb, func.bounds.ub)\n                trial_fitness = func(trial_vector)\n                evaluations += 1\n\n                # Select the best solution\n                if trial_fitness < new_harmony_fitness:\n                    new_harmony, new_harmony_fitness = trial_vector, trial_fitness\n\n            # Update harmony memory if new harmony is better\n            worst_idx = np.argmax(harmony_fitness)\n            if new_harmony_fitness < harmony_fitness[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                harmony_fitness[worst_idx] = new_harmony_fitness\n\n        # Return the best solution found\n        best_idx = np.argmin(harmony_fitness)\n        return harmony_memory[best_idx]", "name": "HybridHarmonyDifferentialEvolution", "description": "Enhance exploration-exploitation balance by incorporating adaptive mutation scaling and learning from the best harmonies.", "configspace": "", "generation": 7, "fitness": 0.23538917444956006, "feedback": "The algorithm HybridHarmonyDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.235 with standard deviation 0.173. And the mean value of best solutions found was 0.725 (0. is the best) with standard deviation 0.524.", "error": "", "parent_id": "87cd4099-c0d4-4928-9e37-b7ad2a6bb11c", "metadata": {"aucs": [0.15127233074493307, 0.07913128584374529, 0.4757639067600018], "final_y": [1.2169595279140175, 0.9585885127936598, 2.618471235160102e-06]}, "mutation_prompt": null}
{"id": "329c4033-20e7-4e3c-995c-5907688e6f22", "solution": "import numpy as np\n\nclass HybridHarmonyDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.harmony_memory_size = 10\n        self.hmcr = 0.9  # Harmony Memory Considering Rate\n        self.par = 0.3   # Pitch Adjusting Rate\n        self.f = 0.5     # Differential weight\n        self.cr = 0.9    # Crossover probability\n\n    def __call__(self, func):\n        # Initialize harmony memory\n        harmony_memory = np.random.uniform(\n            low=func.bounds.lb, high=func.bounds.ub, size=(self.harmony_memory_size, self.dim)\n        )\n        harmony_fitness = np.array([func(hm) for hm in harmony_memory])\n        evaluations = self.harmony_memory_size\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Generate new harmony\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.hmcr:\n                    # Memory consideration\n                    new_harmony[i] = harmony_memory[np.random.randint(self.harmony_memory_size), i]\n                    if np.random.rand() < self.par:\n                        # Adaptive Pitch adjustment with stochastic weighting\n                        adapt_factor = 1 - (evaluations / self.budget)\n                        stochastic_weight = np.random.uniform(0.9, 1.1)\n                        new_harmony[i] += np.random.uniform(-1, 1) * (func.bounds.ub[i] - func.bounds.lb[i]) * 0.01 * adapt_factor * stochastic_weight\n                else:\n                    # Random selection\n                    new_harmony[i] = np.random.uniform(func.bounds.lb[i], func.bounds.ub[i])\n\n            new_harmony = np.clip(new_harmony, func.bounds.lb, func.bounds.ub)\n            new_harmony_fitness = func(new_harmony)\n            evaluations += 1\n\n            # Differential Evolution\n            if evaluations < self.budget:\n                idxs = np.random.choice(self.harmony_memory_size, 3, replace=False)\n                x1, x2, x3 = harmony_memory[idxs]\n                self.f = 0.5 + 0.5 * (1 - evaluations / self.budget)  # Learning factor adjustment\n                mutant_vector = x1 + self.f * (x2 - x3)\n                trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, new_harmony)\n                trial_vector = np.clip(trial_vector, func.bounds.lb, func.bounds.ub)\n                trial_fitness = func(trial_vector)\n                evaluations += 1\n\n                # Select the best solution\n                if trial_fitness < new_harmony_fitness:\n                    new_harmony, new_harmony_fitness = trial_vector, trial_fitness\n\n            # Update harmony memory if new harmony is better\n            worst_idx = np.argmax(harmony_fitness)\n            if new_harmony_fitness < harmony_fitness[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                harmony_fitness[worst_idx] = new_harmony_fitness\n\n        # Return the best solution found\n        best_idx = np.argmin(harmony_fitness)\n        return harmony_memory[best_idx]", "name": "HybridHarmonyDifferentialEvolution", "description": "Introduce stochastic weighting to further enhance adaptive pitch adjustment in Harmony Search.", "configspace": "", "generation": 8, "fitness": 0.22817707317530408, "feedback": "The algorithm HybridHarmonyDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.228 with standard deviation 0.071. And the mean value of best solutions found was 0.216 (0. is the best) with standard deviation 0.153.", "error": "", "parent_id": "87cd4099-c0d4-4928-9e37-b7ad2a6bb11c", "metadata": {"aucs": [0.3285909511810715, 0.17763289260062265, 0.17830737574421807], "final_y": [0.00030225795638581354, 0.3119141350318964, 0.3349163797170632]}, "mutation_prompt": null}
{"id": "51371baf-6c47-4c91-bdab-b85887fa3fca", "solution": "import numpy as np\n\nclass HybridHarmonyDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.harmony_memory_size = 10\n        self.hmcr = 0.9  # Harmony Memory Considering Rate\n        self.par = 0.3   # Initial Pitch Adjusting Rate\n        self.f = 0.5     # Differential weight\n        self.cr = 0.9    # Crossover probability\n        self.opposition_based_rate = 0.2\n\n    def __call__(self, func):\n        # Initialize harmony memory\n        harmony_memory = np.random.uniform(\n            low=func.bounds.lb, high=func.bounds.ub, size=(self.harmony_memory_size, self.dim)\n        )\n        harmony_fitness = np.array([func(hm) for hm in harmony_memory])\n        evaluations = self.harmony_memory_size\n        \n        # Optimization loop\n        while evaluations < self.budget:\n            # Generate new harmony\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.hmcr:\n                    # Memory consideration\n                    new_harmony[i] = harmony_memory[np.random.randint(self.harmony_memory_size), i]\n                    if np.random.rand() < self.par:\n                        # Adaptive Pitch adjustment\n                        adapt_factor = 1 - (evaluations / self.budget)\n                        new_harmony[i] += np.random.uniform(-1, 1) * (func.bounds.ub[i] - func.bounds.lb[i]) * 0.01 * adapt_factor\n                else:\n                    # Random selection\n                    new_harmony[i] = np.random.uniform(func.bounds.lb[i], func.bounds.ub[i])\n            \n            # Opposition-based learning\n            if np.random.rand() < self.opposition_based_rate:\n                new_harmony = func.bounds.ub + func.bounds.lb - new_harmony\n\n            new_harmony = np.clip(new_harmony, func.bounds.lb, func.bounds.ub)\n            new_harmony_fitness = func(new_harmony)\n            evaluations += 1\n\n            # Differential Evolution\n            if evaluations < self.budget:\n                idxs = np.random.choice(self.harmony_memory_size, 3, replace=False)\n                x1, x2, x3 = harmony_memory[idxs]\n                self.f = 0.3 + 0.7 * np.random.rand()  # Self-adaptive learning factor\n                mutant_vector = x1 + self.f * (x2 - x3)\n                trial_vector = np.where(np.random.rand(self.dim) < self.cr, mutant_vector, new_harmony)\n                trial_vector = np.clip(trial_vector, func.bounds.lb, func.bounds.ub)\n                trial_fitness = func(trial_vector)\n                evaluations += 1\n\n                # Select the best solution\n                if trial_fitness < new_harmony_fitness:\n                    new_harmony, new_harmony_fitness = trial_vector, trial_fitness\n\n            # Update harmony memory if new harmony is better\n            worst_idx = np.argmax(harmony_fitness)\n            if new_harmony_fitness < harmony_fitness[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                harmony_fitness[worst_idx] = new_harmony_fitness\n\n        # Return the best solution found\n        best_idx = np.argmin(harmony_fitness)\n        return harmony_memory[best_idx]", "name": "HybridHarmonyDifferentialEvolution", "description": "Enhance solution diversity and convergence by introducing self-adaptive parameters and opposition-based learning.", "configspace": "", "generation": 9, "fitness": 0.3073580687291134, "feedback": "The algorithm HybridHarmonyDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.307 with standard deviation 0.147. And the mean value of best solutions found was 0.987 (0. is the best) with standard deviation 1.396.", "error": "", "parent_id": "87cd4099-c0d4-4928-9e37-b7ad2a6bb11c", "metadata": {"aucs": [0.35943060499240365, 0.10726115666748048, 0.45538244452745613], "final_y": [1.4893485942453428e-05, 2.9621672824580663, 0.0001454397950590795]}, "mutation_prompt": null}
