{"id": "74b33f93-defe-418d-b478-56ea91101eb8", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Adaptive Swarm Gradient Descent (ASGD): Combines swarm intelligence and gradient estimation to explore and exploit search space efficiently.", "configspace": "", "generation": 0, "fitness": 0.8264407036439118, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.826 with standard deviation 0.020. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": null, "metadata": {"aucs": [0.8041324604654931, 0.8227266579918514, 0.8524629924743906], "final_y": [0.1412466306774247, 0.13112094863304602, 0.12789490696654837]}, "mutation_prompt": null}
{"id": "ffdf859e-cad0-4ff5-a31a-56cb83a39812", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))  # Increased multiplier for dynamic population size\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with dynamic population size adjustment for improved exploration-exploitation balance.", "configspace": "", "generation": 1, "fitness": 0.8439184589855394, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.844 with standard deviation 0.010. And the mean value of best solutions found was 0.129 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "74b33f93-defe-418d-b478-56ea91101eb8", "metadata": {"aucs": [0.8461043564059243, 0.8552063941319717, 0.8304446264187222], "final_y": [0.1305796889599279, 0.1319318862905634, 0.12321048833668125]}, "mutation_prompt": null}
{"id": "a4aa366a-9dc0-4c88-96bd-67b7b304a904", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))  # Increased multiplier for dynamic population size\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.55 * adaptive_factor  # Slightly increased cognitive coefficient\n            social_coeff = 1.5\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Updated Enhanced Adaptive Swarm Gradient Descent with a slightly increased cognitive coefficient for improved convergence.", "configspace": "", "generation": 2, "fitness": 0.83300506703941, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.833 with standard deviation 0.022. And the mean value of best solutions found was 0.139 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "ffdf859e-cad0-4ff5-a31a-56cb83a39812", "metadata": {"aucs": [0.8291018052965154, 0.861706134892466, 0.8082072609292487], "final_y": [0.13619801051680958, 0.1286398524322212, 0.15242886418548307]}, "mutation_prompt": null}
{"id": "ec3cf339-a1f3-441e-af9c-dd6d823b3e00", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))  # Increased multiplier for dynamic population size\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.8  # Modified social coefficient for improved global convergence\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with modified social coefficient for improved global convergence.", "configspace": "", "generation": 3, "fitness": 0.8373902561199401, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.837 with standard deviation 0.028. And the mean value of best solutions found was 0.134 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "ffdf859e-cad0-4ff5-a31a-56cb83a39812", "metadata": {"aucs": [0.8501852380021109, 0.8629017673620513, 0.7990837629956581], "final_y": [0.13087309892148713, 0.13039155409719372, 0.14105701015466787]}, "mutation_prompt": null}
{"id": "1d4b3a3a-3db4-42eb-a4e7-69934020511c", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor + 0.05 * np.random.uniform(-1, 1)  # Modified line\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced dynamic inertia weight adjustment incorporating random perturbation for enhanced exploration-exploitation in the swarm.", "configspace": "", "generation": 4, "fitness": 0.8576790800963013, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.858 with standard deviation 0.008. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "ffdf859e-cad0-4ff5-a31a-56cb83a39812", "metadata": {"aucs": [0.8671011993468991, 0.8475070752690625, 0.8584289656729425], "final_y": [0.12735846308981147, 0.12869227056154608, 0.12890320921531973]}, "mutation_prompt": null}
{"id": "058039db-4b21-4be3-8979-4fc07a8ca791", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor + 0.05 * np.random.uniform(-1, 1)\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                differential_perturbation = np.random.uniform(-0.1, 0.1, self.dim)  # New line\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    differential_perturbation)  # Modified line\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced local search by introducing differential perturbation for improved personal and global best updates.", "configspace": "", "generation": 5, "fitness": 0.8072947576132368, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.807 with standard deviation 0.012. And the mean value of best solutions found was 0.136 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "1d4b3a3a-3db4-42eb-a4e7-69934020511c", "metadata": {"aucs": [0.7900941664428796, 0.8163368804872572, 0.8154532259095733], "final_y": [0.1347831806524733, 0.14606480915039766, 0.12705804789081865]}, "mutation_prompt": null}
{"id": "424db76b-33ba-45a4-b5ab-532163382318", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor + 0.05 * np.random.uniform(-1, 1)\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                # Modified line with stochastic local search\n                swarm[i] += self.velocity[i] + 0.01 * np.random.uniform(-1, 1, self.dim)  \n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced a stochastic local search mechanism to further enhance local refinement by integrating a small randomized perturbation to swarm positions.", "configspace": "", "generation": 6, "fitness": 0.8112590848726393, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.811 with standard deviation 0.014. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "1d4b3a3a-3db4-42eb-a4e7-69934020511c", "metadata": {"aucs": [0.7928494444715911, 0.8271167988818926, 0.8138110112644342], "final_y": [0.13708856194463348, 0.13242251998981436, 0.12452247625650092]}, "mutation_prompt": null}
{"id": "682850ed-f54f-4ac2-a003-f8b63788bbbb", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor ** 2 + 0.05 * np.random.uniform(-1, 1)  # Modified line\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced swarm exploration by introducing a non-linear inertia weight variation, increasing dynamic adaptability.", "configspace": "", "generation": 7, "fitness": 0.8599842638478842, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.860 with standard deviation 0.011. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "1d4b3a3a-3db4-42eb-a4e7-69934020511c", "metadata": {"aucs": [0.8698391103609444, 0.8452672252313811, 0.8648464559513268], "final_y": [0.11818688724502258, 0.1333243730867657, 0.1298968797334883]}, "mutation_prompt": null}
{"id": "30585f2e-500c-47a9-89ca-b91ca1c2e6bb", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.initial_population_size  # New line\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor ** 2 + 0.05 * np.random.uniform(-1, 1)\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n            \n            population_size = self.initial_population_size + int(adaptive_factor * 5)  # Modified line\n            swarm = np.resize(swarm, (population_size, self.dim))  # Modified line\n            self.velocity = np.resize(self.velocity, (population_size, self.dim))  # Modified line\n\n            for i in range(population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced adaptive population size adjustment to enhance exploration and exploitation dynamically.", "configspace": "", "generation": 8, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 19 is out of bounds for axis 0 with size 19').", "error": "IndexError('index 19 is out of bounds for axis 0 with size 19')", "parent_id": "682850ed-f54f-4ac2-a003-f8b63788bbbb", "metadata": {}, "mutation_prompt": null}
{"id": "d64daced-c45a-4e1c-9dd0-a0f90d176e71", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.random.rand() * adaptive_factor ** 2  # Modified line\n            cognitive_coeff = 2.0 * adaptive_factor  # Modified line\n            social_coeff = 1.5 + 0.5 * np.sin(evaluations)  # Modified line\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=3, replace=False)  # Modified line\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]  # Modified line\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))  # Modified line\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced stochastic neighborhood selection and dynamic inertia weight adjustment for enhanced convergence in multi-dimensional search spaces.", "configspace": "", "generation": 9, "fitness": 0.8628427904169733, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.863 with standard deviation 0.003. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "682850ed-f54f-4ac2-a003-f8b63788bbbb", "metadata": {"aucs": [0.8661867395337122, 0.8600467028604853, 0.8622949288567228], "final_y": [0.1129719187711995, 0.1169457770253951, 0.11550344117309086]}, "mutation_prompt": null}
{"id": "54262a9f-92c6-46f9-b4d5-7cf783e170dc", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.3 * np.random.rand() * adaptive_factor ** 3  # Modified line\n            cognitive_coeff = 2.0 * (1 - adaptive_factor)  # Modified line\n            social_coeff = 1.5 + 0.5 * np.cos(evaluations)  # Modified line\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=3, replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced convergence through variable inertia and adaptive cognitive and social coefficients with time-varying global learning factor.", "configspace": "", "generation": 10, "fitness": 0.8937330784286809, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.894 with standard deviation 0.008. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "d64daced-c45a-4e1c-9dd0-a0f90d176e71", "metadata": {"aucs": [0.8836193205694207, 0.901639663173031, 0.895940251543591], "final_y": [0.12060653144397349, 0.1120503351041433, 0.11618365056754021]}, "mutation_prompt": null}
{"id": "56059f30-8de3-4fd7-8ff9-343ff860c165", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.3 * np.random.rand() * adaptive_factor ** 3\n            cognitive_coeff = 2.0 * (1 - adaptive_factor)\n            social_coeff = 1.5 + 0.5 * np.cos(evaluations)\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random()  # Modified line\n                neighbors = np.random.choice(self.population_size, size=3, replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]) + \n                                    0.1 * r3 * (global_best - swarm[i]))  # Modified line\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced convergence through variable inertia and adaptive coefficients with a dynamic local search strategy.", "configspace": "", "generation": 11, "fitness": 0.8576367124442387, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.858 with standard deviation 0.021. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "54262a9f-92c6-46f9-b4d5-7cf783e170dc", "metadata": {"aucs": [0.8292175160755114, 0.8653045252481476, 0.878388096009057], "final_y": [0.14260174890248312, 0.12638613173482316, 0.12474493844519574]}, "mutation_prompt": null}
{"id": "4857ca84-d0e7-4434-b1d3-eb90adbe92c5", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.3 * np.random.rand() * adaptive_factor ** 3\n            cognitive_coeff = 2.0 * (1 - adaptive_factor)\n            social_coeff = 1.5 + 0.5 * np.cos(evaluations * 0.1)  # Modified line\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=3, replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced convergence through variable inertia and adaptive cognitive and social coefficients with time-varying global learning factor and sinusoidal modulation for social interaction.", "configspace": "", "generation": 12, "fitness": 0.8761501742888395, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.876 with standard deviation 0.018. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "54262a9f-92c6-46f9-b4d5-7cf783e170dc", "metadata": {"aucs": [0.8703710194952292, 0.8573078670565325, 0.9007716363147567], "final_y": [0.11908091583832459, 0.12254690304118232, 0.11158049591482211]}, "mutation_prompt": null}
{"id": "9cf01e7e-3b76-4ea8-8f06-4ac79fdef88f", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.3 * np.random.rand() * adaptive_factor ** 3\n            cognitive_coeff = 2.0 * (1 - adaptive_factor)\n            social_coeff = 1.5 + 0.5 * np.cos(evaluations)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=3, replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                levy_flight = 0.01 * np.random.standard_cauchy(self.dim)  # Added line\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]) +\n                                    levy_flight)  # Modified line\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Integration of Lévy flight for enhanced local exploration in swarm updates.", "configspace": "", "generation": 13, "fitness": 0.8722771928758695, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.872 with standard deviation 0.024. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "54262a9f-92c6-46f9-b4d5-7cf783e170dc", "metadata": {"aucs": [0.8400918067850123, 0.8985530716273913, 0.8781867002152047], "final_y": [0.12327289539654929, 0.11664137003430908, 0.12250260860595774]}, "mutation_prompt": null}
{"id": "465a9d94-3b5d-4fa1-a58d-c065a17b5d3e", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.3 * np.random.rand() * adaptive_factor ** 3\n            cognitive_coeff = 2.0 * (1 - adaptive_factor)\n            social_coeff = 1.5 + 0.5 * np.cos(evaluations)\n\n            # Adaptive population size based on evaluations\n            self.population_size = int(10 + 3 * int(np.sqrt(self.dim)) * (1 + adaptive_factor * 0.5))\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=3, replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced convergence through variable inertia and adaptive cognitive and social coefficients with time-varying global learning factor and adaptive population size based on evaluations.", "configspace": "", "generation": 14, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 20 is out of bounds for axis 0 with size 19').", "error": "IndexError('index 20 is out of bounds for axis 0 with size 19')", "parent_id": "54262a9f-92c6-46f9-b4d5-7cf783e170dc", "metadata": {}, "mutation_prompt": null}
{"id": "f55c435b-d694-4e1f-986b-493ad4b39e4f", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.3 * np.random.rand() * adaptive_factor ** 3\n            cognitive_coeff = 2.0 * (1 - adaptive_factor) \n            social_coeff = 1.5 + 0.5 * np.cos(evaluations)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=3, replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])] if np.random.rand() > 0.3 else i]  # Modified line\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Integrated self-adaptive mutation rate and selective local best strategy for improved exploration and exploitation balance.", "configspace": "", "generation": 15, "fitness": 0.8522961561921005, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.852 with standard deviation 0.014. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "54262a9f-92c6-46f9-b4d5-7cf783e170dc", "metadata": {"aucs": [0.8329367859654088, 0.8637954877975833, 0.8601561948133095], "final_y": [0.13491822400661913, 0.12179522723135938, 0.11946414737434341]}, "mutation_prompt": null}
{"id": "87035a1c-d5bc-4af2-8290-c277849ae727", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.3 * np.random.rand() * adaptive_factor ** 3\n            cognitive_coeff = 2.0 * (1 - adaptive_factor)\n            social_coeff = 1.5 + 0.5 * np.sin(evaluations / 2)  # Modified line\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=3, replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved exploration by introducing a dynamic social coefficient based on a sinusoidal function dependent on evaluations.", "configspace": "", "generation": 16, "fitness": 0.8774152942343597, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.877 with standard deviation 0.012. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "54262a9f-92c6-46f9-b4d5-7cf783e170dc", "metadata": {"aucs": [0.8898320429020483, 0.8803453865480179, 0.8620684532530132], "final_y": [0.11649889462856755, 0.11954005469999862, 0.12669529323253814]}, "mutation_prompt": null}
{"id": "8495cb72-daac-4e31-94c6-bc40e506eac8", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = (1 - evaluations / self.budget) ** 2  # Modified line\n            inertia_weight = 0.5 + 0.3 * np.random.rand() * adaptive_factor ** 3\n            cognitive_coeff = 2.0 * np.exp(-evaluations / self.budget)  # Modified line\n            social_coeff = 1.5 + 0.5 * np.cos(evaluations)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=3, replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved convergence by refining the adaptive factor and introducing a decay in the cognitive coefficient over time.", "configspace": "", "generation": 17, "fitness": 0.8787376835494012, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.879 with standard deviation 0.014. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "54262a9f-92c6-46f9-b4d5-7cf783e170dc", "metadata": {"aucs": [0.8648204750887328, 0.873350143724726, 0.8980424318347445], "final_y": [0.1234471659436347, 0.11407324058199708, 0.1150534743249183]}, "mutation_prompt": null}
{"id": "0fadc2c0-7f9c-4513-b844-03a6916df6b6", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.3 * np.random.rand() * adaptive_factor ** 3\n            cognitive_coeff = 2.0 * (1 - adaptive_factor)\n            social_coeff = 1.5 + 0.5 * np.cos(evaluations)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=5, replace=False)  # Modified line\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                random_drift = 0.1 * np.random.uniform(-1, 1, self.dim) * adaptive_factor  # Modified line\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i] + random_drift  # Modified line\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced dynamic neighborhood selection and a controlled random drift for enhanced exploration.", "configspace": "", "generation": 18, "fitness": 0.8594427223952676, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.859 with standard deviation 0.022. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "54262a9f-92c6-46f9-b4d5-7cf783e170dc", "metadata": {"aucs": [0.8301497974300518, 0.8834455742463175, 0.8647327955094333], "final_y": [0.13901715649684698, 0.11671826393341755, 0.12723925292610128]}, "mutation_prompt": null}
{"id": "7512c3f2-7d15-4828-ab45-261907403a73", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.3 * np.random.rand() * adaptive_factor ** 3\n            cognitive_coeff = 2.0 * (1 - adaptive_factor)\n            social_coeff = 1.5 + 0.5 * np.cos(evaluations)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=3, replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved swarm stability and convergence through enhanced adaptive dynamics while maintaining previous enhancements.", "configspace": "", "generation": 19, "fitness": 0.8937330784286809, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.894 with standard deviation 0.008. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "54262a9f-92c6-46f9-b4d5-7cf783e170dc", "metadata": {"aucs": [0.8836193205694207, 0.901639663173031, 0.895940251543591], "final_y": [0.12060653144397349, 0.1120503351041433, 0.11618365056754021]}, "mutation_prompt": null}
{"id": "bf1bf7d9-72f0-4d49-8c45-0927933efed1", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.3 * np.random.rand() * adaptive_factor ** 3\n            cognitive_coeff = 2.0 * (1 - adaptive_factor)\n            social_coeff = 1.5 + 0.5 * np.cos(evaluations)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=3, replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]) +\n                                    0.1 * (global_best - swarm[i]))  # Modified line\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introducing a local guidance mechanism based on neighborhood best to enhance exploration-exploitation balance.", "configspace": "", "generation": 20, "fitness": 0.8872639808836666, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.887 with standard deviation 0.017. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "54262a9f-92c6-46f9-b4d5-7cf783e170dc", "metadata": {"aucs": [0.8790090271858765, 0.8724469816964121, 0.9103359337687112], "final_y": [0.12004932160827375, 0.12439159583952397, 0.11384188031148923]}, "mutation_prompt": null}
{"id": "5fb32408-394d-4298-9db1-4cc4b9c1b982", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.35 * np.random.rand() * adaptive_factor ** 2.8  # Modified line\n            cognitive_coeff = 2.0 * (1 - adaptive_factor)\n            social_coeff = 1.5 + 0.6 * np.sin(evaluations)  # Modified line\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=3, replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced convergence with stochastic inertia weight and adaptive social influence.", "configspace": "", "generation": 21, "fitness": 0.8702281367350458, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.870 with standard deviation 0.002. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "54262a9f-92c6-46f9-b4d5-7cf783e170dc", "metadata": {"aucs": [0.8681975775794166, 0.8692612769638011, 0.8732255556619197], "final_y": [0.12241671126926557, 0.1232765782122982, 0.11784024578629904]}, "mutation_prompt": null}
{"id": "4a1376f7-1c2e-4380-823a-5d9d9df83bc1", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.3 * np.random.rand() * adaptive_factor ** 2.5  # Modified line\n            cognitive_coeff = 2.0 + 0.5 * np.sin(evaluations / 10)  # Modified line\n            social_coeff = 1.5 + 0.5 * np.cos(evaluations / 5)  # Modified line\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=3, replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Combines adaptive learning factors with neighborhood-based social influence and controlled exploration-exploitation balance.", "configspace": "", "generation": 22, "fitness": 0.850545859520143, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.851 with standard deviation 0.010. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "54262a9f-92c6-46f9-b4d5-7cf783e170dc", "metadata": {"aucs": [0.8370302375916798, 0.8579911740828691, 0.8566161668858803], "final_y": [0.12355935268046181, 0.12150583809276116, 0.12459126392234499]}, "mutation_prompt": null}
{"id": "225dad87-c713-4574-bc84-5b6a70d57426", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.3 * np.random.rand() * adaptive_factor ** 3\n            cognitive_coeff = 2.0 * (1 - adaptive_factor)\n            social_coeff = 1.5 + 0.5 * np.cos(evaluations)\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)  # Modified line\n                neighbors = np.random.choice(self.population_size, size=3, replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]) +\n                                    0.1 * r3 * (global_best - swarm[i]))  # Modified line\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Leverages local exploration via hybrid random walk for improved convergence.", "configspace": "", "generation": 23, "fitness": 0.8797965272145688, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.880 with standard deviation 0.012. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "54262a9f-92c6-46f9-b4d5-7cf783e170dc", "metadata": {"aucs": [0.8719460562071817, 0.8963378506528789, 0.8711056747836459], "final_y": [0.12107000889057629, 0.11861483424209962, 0.12664632129997666]}, "mutation_prompt": null}
{"id": "3b400372-7654-47dc-bc6a-5c3b7b464fb2", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.3 * np.random.rand() * adaptive_factor ** 3\n            # Modified lines start here\n            cognitive_coeff = 2.0 * np.random.rand()  # Stochastic cognitive coefficient\n            social_coeff = 1.5 + 0.5 * np.random.rand()  # Stochastic social coefficient\n            perturbation = 0.05 * np.random.standard_normal(self.dim)  # Random local search\n            # Modified lines end here\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=3, replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i] + perturbation  # Apply local search\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Incorporates stochastic selection of cognitive and social coefficients with a dynamic local search mechanism to enhance diversity and convergence.", "configspace": "", "generation": 24, "fitness": 0.8736444990264859, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.874 with standard deviation 0.005. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "54262a9f-92c6-46f9-b4d5-7cf783e170dc", "metadata": {"aucs": [0.866914336107714, 0.8749878618834235, 0.8790312990883201], "final_y": [0.1228318040900257, 0.12311885387142685, 0.1221978011489574]}, "mutation_prompt": null}
{"id": "cb1301e2-36b2-48fc-8080-f8ee3e0b7b1b", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.3 * np.random.rand() * adaptive_factor ** 3\n            cognitive_coeff = 2.0 * (1 - adaptive_factor)\n            social_coeff = 1.5 + 0.5 * np.cos(evaluations + np.random.rand())  # Modified line\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=3, replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce randomness in the social coefficient to enhance exploration capacity.", "configspace": "", "generation": 25, "fitness": 0.8776506340044598, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.878 with standard deviation 0.010. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "54262a9f-92c6-46f9-b4d5-7cf783e170dc", "metadata": {"aucs": [0.8749562304388484, 0.8670920246494472, 0.8909036469250836], "final_y": [0.1212506710396759, 0.1187071287667768, 0.1195788873465029]}, "mutation_prompt": null}
{"id": "c144d777-9ab4-4de8-be8c-da6e32e12016", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.4 + 0.5 * np.random.rand() * adaptive_factor ** 2  # Modified line\n            cognitive_coeff = 2.0 * (1 - adaptive_factor)  # Modified line\n            social_coeff = 1.5 + 0.5 * np.cos(evaluations)  # Modified line\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=3, replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved swarm dynamics by implementing a time-varying inertia weight and integrated local exploration.", "configspace": "", "generation": 26, "fitness": 0.8870159497042555, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.887 with standard deviation 0.004. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "54262a9f-92c6-46f9-b4d5-7cf783e170dc", "metadata": {"aucs": [0.8851416071358933, 0.883908386728538, 0.8919978552483349], "final_y": [0.12225252253919094, 0.11750085441041214, 0.11795600228180259]}, "mutation_prompt": null}
{"id": "1198ddd1-8d11-4d9b-9fbd-5c8b667158c4", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.random.rand() * adaptive_factor ** 2  # Modified line\n            cognitive_coeff = 2.0 * (1 - adaptive_factor)  # Unchanged line\n            social_coeff = 1.5 + 0.5 * np.sin(evaluations * np.pi / 50)  # Modified line\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=3, replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Refined particle dynamics with increased randomness in velocity adaptation and periodic social influence modulation.", "configspace": "", "generation": 27, "fitness": 0.8842037992847258, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.884 with standard deviation 0.008. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "54262a9f-92c6-46f9-b4d5-7cf783e170dc", "metadata": {"aucs": [0.874560508374736, 0.8834943743486556, 0.8945565151307855], "final_y": [0.12151208825049697, 0.11221230396351245, 0.11504077842928784]}, "mutation_prompt": null}
{"id": "ca99b696-1a85-462e-ad97-0b65564a56e0", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.3 * np.random.rand() * adaptive_factor ** 3\n            cognitive_coeff = 2.0 * (1 - adaptive_factor)\n            social_coeff = 1.5 + 0.5 * np.cos(evaluations)\n\n            # Adjust population size dynamically\n            self.population_size = int(10 + adaptive_factor * 3 * np.sqrt(self.dim))\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=3, replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                # Refined velocity update\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (global_best - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced dynamic population size adjustment and refined velocity update for improved exploration-exploitation balance.", "configspace": "", "generation": 28, "fitness": 0.8722981651770021, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.872 with standard deviation 0.004. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "54262a9f-92c6-46f9-b4d5-7cf783e170dc", "metadata": {"aucs": [0.8767731845127701, 0.8725860831011771, 0.8675352279170591], "final_y": [0.1268553868204495, 0.11787561650402434, 0.12931028345800732]}, "mutation_prompt": null}
{"id": "1832d796-176b-4438-8806-8d8ee2864d80", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.3 * np.random.rand() * adaptive_factor ** 3\n            cognitive_coeff = 2.0 * (1 - adaptive_factor)\n            social_coeff = 1.5 + 0.5 * np.cos(evaluations)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=3, replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced convergence through variable inertia, adaptive coefficients, and dynamic local neighborhood selection with time-varying global learning factor for improved exploration-exploitation balance.", "configspace": "", "generation": 29, "fitness": 0.8937330784286809, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.894 with standard deviation 0.008. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "54262a9f-92c6-46f9-b4d5-7cf783e170dc", "metadata": {"aucs": [0.8836193205694207, 0.901639663173031, 0.895940251543591], "final_y": [0.12060653144397349, 0.1120503351041433, 0.11618365056754021]}, "mutation_prompt": null}
{"id": "7ae08006-0f5d-4093-8119-832f8535ab23", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        chaotic_sequence = np.random.uniform(0, 1, self.population_size)  # New line\n        \n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.3 * np.random.rand() * adaptive_factor ** 3\n            cognitive_coeff = 2.0 * (1 - adaptive_factor)\n            social_coeff = 1.5 + 0.5 * np.cos(evaluations)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), chaotic_sequence[i] * np.random.random(self.dim)  # Modified line\n                neighbors = np.random.choice(self.population_size, size=3, replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Hybridizes swarm dynamics with chaotic search for enhanced exploration and convergence.", "configspace": "", "generation": 30, "fitness": 0.8662203833062957, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.866 with standard deviation 0.010. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "54262a9f-92c6-46f9-b4d5-7cf783e170dc", "metadata": {"aucs": [0.8527684864543242, 0.8733658865662605, 0.8725267768983025], "final_y": [0.12685147390295326, 0.12062298396969118, 0.1212827154380196]}, "mutation_prompt": null}
{"id": "8b41090d-2544-4849-bbb0-4114cc113ee6", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.4 + 0.4 * np.random.rand() * adaptive_factor ** 2  # Modified line\n            cognitive_coeff = 1.8 * (1 - adaptive_factor) + 0.2 * np.random.rand()  # Modified line\n            social_coeff = 1.3 + 0.7 * np.cos(evaluations + np.pi/4)  # Modified line\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=3, replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved convergence by employing dynamic adaptation of local search step size and enhanced randomization in inertia weight, cognitive, and social coefficients.", "configspace": "", "generation": 31, "fitness": 0.8795742636227789, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.880 with standard deviation 0.009. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "54262a9f-92c6-46f9-b4d5-7cf783e170dc", "metadata": {"aucs": [0.8662447839721, 0.8864990273342892, 0.8859789795619474], "final_y": [0.1243185909061788, 0.11954191480674492, 0.12053408676292365]}, "mutation_prompt": null}
{"id": "a0196ee0-53bd-4772-9b57-d025d21ddf68", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.3 * np.random.rand() * adaptive_factor ** 2.5  # Modified line\n            cognitive_coeff = 2.0 * (1 - adaptive_factor)\n            social_coeff = 1.5 + 0.5 * np.cos(evaluations)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbor_count = min(5, max(2, int(self.population_size * adaptive_factor)))  # Modified line\n                neighbors = np.random.choice(self.population_size, size=neighbor_count, replace=False)  # Modified line\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced exploration through dynamic neighborhood size and adaptive inertia scaling based on swarm convergence.", "configspace": "", "generation": 32, "fitness": 0.8794745244300491, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.879 with standard deviation 0.024. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "54262a9f-92c6-46f9-b4d5-7cf783e170dc", "metadata": {"aucs": [0.8475518272043532, 0.8861248658059913, 0.9047468802798027], "final_y": [0.13282950052905174, 0.11923188826035369, 0.11672543780521671]}, "mutation_prompt": null}
{"id": "5d373b8d-9223-423f-8c9c-65c3c18797e8", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.3 * np.random.rand() * adaptive_factor ** 3\n            cognitive_coeff = 2.0 * (1 - np.sin(adaptive_factor))  # Modified line\n            social_coeff = 1.0 + np.sin(evaluations)  # Modified line\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=3, replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved exploration-exploitation balance by dynamic update of cognitive and social coefficients and hybridized local search.", "configspace": "", "generation": 33, "fitness": 0.8613261844180862, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.861 with standard deviation 0.004. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "54262a9f-92c6-46f9-b4d5-7cf783e170dc", "metadata": {"aucs": [0.8611109599238437, 0.856472666271529, 0.866394927058886], "final_y": [0.12583000834564184, 0.12631482360259327, 0.119761402153016]}, "mutation_prompt": null}
{"id": "611682ce-f8be-4298-831e-eb83a570d5ae", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.3 * np.random.rand() * adaptive_factor ** 3\n            cognitive_coeff = 2.0 * (1 - adaptive_factor)\n            social_coeff = 1.5 + 0.5 * np.cos(evaluations)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)  # No change\n                neighbors = np.random.choice(self.population_size, size=3, replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]) +\n                                    0.05 * np.random.randn(self.dim))  # Modified line\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved swarm dynamics with self-adaptive velocity control and random perturbations for enhanced exploration.", "configspace": "", "generation": 34, "fitness": 0.8722826218010914, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.872 with standard deviation 0.018. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "54262a9f-92c6-46f9-b4d5-7cf783e170dc", "metadata": {"aucs": [0.8546047739850938, 0.8968041615507331, 0.8654389298674473], "final_y": [0.1197869607896046, 0.11237462961743905, 0.12619196094947516]}, "mutation_prompt": null}
{"id": "338744ba-eb25-4ee9-8983-15309cec6d3d", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.3 * np.random.rand() * adaptive_factor ** 3\n            cognitive_coeff = 2.0 * (1 - adaptive_factor)\n            social_coeff = 1.5 + 0.5 * np.cos(evaluations) + 0.1 * np.random.rand()  # Modified line\n\n            if evaluations % 50 == 0 and self.population_size > 5:  # Modified block\n                self.population_size = max(5, self.population_size - 1)  # Modified line\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=3, replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced exploration by incorporating randomness in the social component and improving convergence with a dynamic population size.", "configspace": "", "generation": 35, "fitness": 0.8709308123067764, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.871 with standard deviation 0.013. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "54262a9f-92c6-46f9-b4d5-7cf783e170dc", "metadata": {"aucs": [0.8585583915700603, 0.8650674557871891, 0.8891665895630798], "final_y": [0.1273787289878091, 0.12443184736571689, 0.11791629766025336]}, "mutation_prompt": null}
{"id": "b420c175-5221-4db8-be93-77f920b1c302", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.3 * np.random.rand() * adaptive_factor ** 3\n            cognitive_coeff = 2.0 * (1 - adaptive_factor)\n            social_coeff = 1.5 + 0.5 * np.sin(evaluations)  # Modified line\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=3, replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Incorporate a dynamic social coefficient with time-varying sine function for adaptive exploration.", "configspace": "", "generation": 36, "fitness": 0.872466565072286, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.872 with standard deviation 0.007. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "54262a9f-92c6-46f9-b4d5-7cf783e170dc", "metadata": {"aucs": [0.8673702146443683, 0.8819097366505428, 0.8681197439219471], "final_y": [0.11676182141159286, 0.11851796989313079, 0.11853005276828943]}, "mutation_prompt": null}
{"id": "d02ace33-15d6-47ad-b0b1-623aa6714447", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 * adaptive_factor + 0.1  # Modified line\n            cognitive_coeff = 2.0 * (1 - adaptive_factor)\n            social_coeff = 1.5 + 0.5 * np.cos(evaluations)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=3, replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - global_best))  # Modified line\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved global exploration with dynamic neighborhood influence and enhanced velocity adjustment.", "configspace": "", "generation": 37, "fitness": 0.7837786578444117, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.784 with standard deviation 0.027. And the mean value of best solutions found was 0.153 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "54262a9f-92c6-46f9-b4d5-7cf783e170dc", "metadata": {"aucs": [0.7777509469604524, 0.8198461811928281, 0.7537388453799547], "final_y": [0.15380169889001805, 0.1508144642668091, 0.15363655875610782]}, "mutation_prompt": null}
{"id": "5f001e7f-79b7-454f-8f33-3945991b7480", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.3 * np.random.rand() * adaptive_factor ** 3\n            cognitive_coeff = 2.0 * (1 - adaptive_factor)\n            social_coeff = 1.5 + 0.5 * np.cos(evaluations)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=3, replace=False)\n                local_best = personal_best[np.argmin(personal_best_value[neighbors])]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (global_best - swarm[i]) +  # Modified line\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i] + 0.01 * np.random.randn(self.dim)  # Modified line\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced convergence through adaptive random search and dynamic recombination of global and local solutions.", "configspace": "", "generation": 38, "fitness": 0.806101587591992, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.806 with standard deviation 0.070. And the mean value of best solutions found was 0.150 (0. is the best) with standard deviation 0.027.", "error": "", "parent_id": "54262a9f-92c6-46f9-b4d5-7cf783e170dc", "metadata": {"aucs": [0.7069962542556096, 0.8512890484306113, 0.8600194600897553], "final_y": [0.1891180227810575, 0.12990779687865617, 0.13193650589881456]}, "mutation_prompt": null}
{"id": "e980be55-d2c6-4417-b52b-a4fcbb03928f", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.3 * np.random.rand() * adaptive_factor ** 3\n            cognitive_coeff = 2.0 * (1 - adaptive_factor)\n            social_coeff = 1.5 + 0.5 * np.cos(evaluations)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=3, replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                local_influence = (personal_best[i] - swarm[i]) if np.random.rand() < 0.5 else (local_best - swarm[i])  # Modified line\n                self.velocity[i] = inertia_weight * self.velocity[i] + cognitive_coeff * r1 * local_influence + social_coeff * r2 * (global_best - swarm[i])  # Modified line\n                swarm[i] += 0.9 * self.velocity[i]  # Modified line\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce dynamic local search velocity adjustment and selective neighbor-based learning.", "configspace": "", "generation": 39, "fitness": 0.8621114147977315, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.862 with standard deviation 0.034. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "54262a9f-92c6-46f9-b4d5-7cf783e170dc", "metadata": {"aucs": [0.8183898460242507, 0.9013549194454227, 0.8665894789235213], "final_y": [0.13209833533154858, 0.11629245281189649, 0.12361604665115244]}, "mutation_prompt": null}
{"id": "0ce3e121-42bc-47d3-83a2-a2bb655fe8db", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.3 * np.random.rand() * adaptive_factor ** 3\n            cognitive_coeff = 2.0 * (1 - adaptive_factor)\n            social_coeff = 1.5 + 0.5 * np.cos(evaluations)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=3, replace=False)\n                local_best = swarm[neighbors[np.argmin([func(swarm[n]) for n in neighbors])]]  # Modified line\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a dynamic local search by altering the local best selection mechanism to improve exploration and exploitation balance.", "configspace": "", "generation": 40, "fitness": 0.8071424686257388, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.807 with standard deviation 0.017. And the mean value of best solutions found was 0.146 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "54262a9f-92c6-46f9-b4d5-7cf783e170dc", "metadata": {"aucs": [0.815173971969876, 0.783705200456434, 0.8225482334509063], "final_y": [0.14881250642104693, 0.15105551610954826, 0.13736556032092073]}, "mutation_prompt": null}
{"id": "c5e94e07-4c6d-4c76-b74a-f3a726b88b38", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.3 * np.random.rand() * adaptive_factor ** 3\n            cognitive_coeff = 2.0 * (1 - adaptive_factor ** 2)  # Modified line\n            social_coeff = 1.5 + 0.5 * np.cos(evaluations)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=3, replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved local exploration through dynamic adjustment of cognitive coefficient using adaptive factor based on evaluations.", "configspace": "", "generation": 41, "fitness": 0.8880967093043289, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.888 with standard deviation 0.007. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "54262a9f-92c6-46f9-b4d5-7cf783e170dc", "metadata": {"aucs": [0.8781737627678711, 0.8901442260952224, 0.8959721390498933], "final_y": [0.12406030033872262, 0.11698884638579399, 0.11579790764308318]}, "mutation_prompt": null}
{"id": "dd491edf-018a-43a5-891c-fed84705ce5b", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.3 * np.random.rand() * adaptive_factor ** 3\n            cognitive_coeff = 2.0 * (1 - adaptive_factor)\n            social_coeff = 1.5 + 0.5 * np.sin(evaluations)  # Modified line\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=5, replace=False)  # Modified line\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved exploration and convergence through dynamic local best selection and adaptive social coefficient.", "configspace": "", "generation": 42, "fitness": 0.8819046686262034, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.882 with standard deviation 0.018. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "54262a9f-92c6-46f9-b4d5-7cf783e170dc", "metadata": {"aucs": [0.8784982898454884, 0.9054000690188193, 0.8618156470143024], "final_y": [0.1171532897419385, 0.1118331981470061, 0.12564789195407022]}, "mutation_prompt": null}
{"id": "6367d6da-3221-4edf-bcf6-931cd38bca18", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = lb + (ub - lb) * np.random.uniform(size=(self.population_size, self.dim))  # Chaotic initialization\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.3 * np.random.rand() * (adaptive_factor ** 2)  # Dynamic inertia weight decay\n            cognitive_coeff = 2.0 * (1 - adaptive_factor)\n            social_coeff = 1.5 + 0.5 * np.cos(evaluations)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=3, replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved local exploration with chaotic initialization, and dynamic inertia weight decay for enhanced convergence.", "configspace": "", "generation": 43, "fitness": 0.8908025005363011, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.891 with standard deviation 0.010. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "54262a9f-92c6-46f9-b4d5-7cf783e170dc", "metadata": {"aucs": [0.8792274076242002, 0.8904082456436994, 0.9027718483410035], "final_y": [0.12079760874790257, 0.11466095298632628, 0.11386461540680437]}, "mutation_prompt": null}
{"id": "82429805-f667-4949-86a2-9984c727a257", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.3 * np.random.rand() * adaptive_factor ** 3\n            cognitive_coeff = 2.0 * (1 - adaptive_factor)\n            social_coeff = 1.5 + 0.5 * np.cos(evaluations * 0.1)  # Modified line\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=3, replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a dynamic global learning factor based on evaluations to refine exploration and exploitation balance.", "configspace": "", "generation": 44, "fitness": 0.8761501742888395, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.876 with standard deviation 0.018. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "54262a9f-92c6-46f9-b4d5-7cf783e170dc", "metadata": {"aucs": [0.8703710194952292, 0.8573078670565325, 0.9007716363147567], "final_y": [0.11908091583832459, 0.12254690304118232, 0.11158049591482211]}, "mutation_prompt": null}
{"id": "6f99b9aa-66af-4ff4-8530-ac56cfab701c", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.4 + 0.4 * np.random.rand() * adaptive_factor ** 2  # Modified line\n            cognitive_coeff = 2.5 * (1 - adaptive_factor)  # Modified line\n            social_coeff = 1.5 + 0.5 * np.cos(evaluations)  # Unchanged line\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=3, replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Optimized balance between exploration and exploitation using dynamic coefficient scaling based on evaluation progress.", "configspace": "", "generation": 45, "fitness": 0.8822314441921835, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.882 with standard deviation 0.010. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "54262a9f-92c6-46f9-b4d5-7cf783e170dc", "metadata": {"aucs": [0.8710948574476203, 0.8805717477333949, 0.8950277273955353], "final_y": [0.12711932524882952, 0.12531830194680016, 0.11611531925577045]}, "mutation_prompt": null}
{"id": "9c016a84-dd3d-4428-b142-27cc1b68f2be", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.3 * np.random.rand() * adaptive_factor ** 3\n            cognitive_coeff = 2.0 * (1 - adaptive_factor)\n            social_coeff = 1.5 + 0.5 * np.cos(evaluations)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=int(4 + adaptive_factor * 3), replace=False)  # Modified line\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved exploration through dynamic swarm topology and adaptive neighborhood selection.", "configspace": "", "generation": 46, "fitness": 0.8947951238416509, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.895 with standard deviation 0.014. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "54262a9f-92c6-46f9-b4d5-7cf783e170dc", "metadata": {"aucs": [0.8763917328824563, 0.9086355394227189, 0.8993580992197775], "final_y": [0.11729160351092649, 0.11000768413751438, 0.11723974927143999]}, "mutation_prompt": null}
{"id": "0dcaa37b-f903-4a60-8143-5d7ad403086f", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.4 + 0.4 * np.random.rand() * adaptive_factor ** 2  # Modified line\n            cognitive_coeff = 2.0 * (1 - adaptive_factor)\n            social_coeff = 1.5 + 0.5 * np.cos(evaluations)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=int(5 + adaptive_factor * 3), replace=False)  # Modified line\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced convergence speed by modifying the inertia weight and introducing a dynamic neighborhood size.", "configspace": "", "generation": 47, "fitness": 0.8944136443457048, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.894 with standard deviation 0.017. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "9c016a84-dd3d-4428-b142-27cc1b68f2be", "metadata": {"aucs": [0.8792219496603522, 0.88630578264995, 0.9177132007268122], "final_y": [0.11688049700805192, 0.12051651184797274, 0.11214614934908662]}, "mutation_prompt": null}
{"id": "5e619765-a9a3-474b-9b5b-cfdfe77764a8", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.3 * np.random.rand() * adaptive_factor ** 2.5  # Modified line\n            cognitive_coeff = 2.0 * (1 - adaptive_factor)\n            social_coeff = 1.5 + 0.5 * np.sin(evaluations)  # Modified line\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=int(4 + adaptive_factor * 3), replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    1.1 * cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +  # Modified line\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced exploration-exploitation balance through adaptive coefficients and velocity modification.", "configspace": "", "generation": 48, "fitness": 0.8898476330633045, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.890 with standard deviation 0.023. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "9c016a84-dd3d-4428-b142-27cc1b68f2be", "metadata": {"aucs": [0.8927942498658946, 0.9169990848030993, 0.8597495645209199], "final_y": [0.112795228447083, 0.11022483975806041, 0.12693275779817925]}, "mutation_prompt": null}
{"id": "0f2e09c1-2193-4ba4-aa4a-ee1e4dd9e93f", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.4 + 0.5 * np.random.rand() * adaptive_factor ** 3  # Modified line\n            cognitive_coeff = 2.0 * (1 - adaptive_factor)\n            social_coeff = 1.5 + 0.5 * np.cos(evaluations)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=int(5 + adaptive_factor * 3), replace=False)  # Modified line\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced local exploration and convergence control through dynamic inertia and neighbor adaptation.", "configspace": "", "generation": 49, "fitness": 0.8787743550536212, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.879 with standard deviation 0.018. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "9c016a84-dd3d-4428-b142-27cc1b68f2be", "metadata": {"aucs": [0.8535206217136919, 0.8901010780239365, 0.8927013654232353], "final_y": [0.12617012006006856, 0.1200768268975877, 0.1225245450807273]}, "mutation_prompt": null}
{"id": "152da587-2247-41f2-ae60-83ceec290b59", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.random.rand() * adaptive_factor ** 3  # Modified line\n            cognitive_coeff = 2.0 * (1 - adaptive_factor)\n            social_coeff = 1.5 + 0.5 * np.sin(evaluations)  # Modified line\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=int(4 + adaptive_factor * 3), replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced adaptive dynamics by refining inertia and social coefficient adjustments.", "configspace": "", "generation": 50, "fitness": 0.882390146374779, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.882 with standard deviation 0.024. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "9c016a84-dd3d-4428-b142-27cc1b68f2be", "metadata": {"aucs": [0.8964390800086515, 0.9024493406474303, 0.8482820184682553], "final_y": [0.10994656816015846, 0.11456341774550471, 0.13687484070486955]}, "mutation_prompt": null}
{"id": "00061337-3474-4242-b99f-1b065fb5694a", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.3 * np.random.rand() * adaptive_factor ** 3\n            cognitive_coeff = 2.0 * (1 - adaptive_factor)\n            social_coeff = 1.5 + 0.5 * np.cos(evaluations)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=int(4 + adaptive_factor * 3), replace=True)  # Changed to replace=True\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i] * (1 + 0.1 * adaptive_factor)  # Added adaptive velocity scaling\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced swarm exploration by incorporating dynamic neighborhood influence and adaptive inertia adjustments.", "configspace": "", "generation": 51, "fitness": 0.883564418021038, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.884 with standard deviation 0.027. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "9c016a84-dd3d-4428-b142-27cc1b68f2be", "metadata": {"aucs": [0.8452281073458582, 0.90082279066179, 0.904642356055466], "final_y": [0.13604165593370987, 0.11341343106679613, 0.11314578717139823]}, "mutation_prompt": null}
{"id": "4b3fc25c-b212-4b57-acfe-b25648cbae70", "solution": "import numpy as np\nfrom scipy.stats import norm\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def _chaotic_sequence(self, size):\n        sequence = np.random.rand(size)\n        for i in range(1, size):\n            sequence[i] = 4.0 * sequence[i-1] * (1.0 - sequence[i-1])\n        return sequence\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        chaotic_seq = self._chaotic_sequence(self.budget)\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.3 * np.random.rand() * adaptive_factor ** 3\n            cognitive_coeff = 2.0 * (1 - adaptive_factor)\n            social_coeff = 1.5 + 0.5 * np.cos(evaluations)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=int(4 + adaptive_factor * 3), replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n                \n                mutation = norm.ppf(chaotic_seq[evaluations] / self.budget) * (ub - lb) * adaptive_factor\n                swarm[i] += mutation\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced exploration and exploitation through adaptive mutation and chaotic dynamics.", "configspace": "", "generation": 52, "fitness": 0.723297120774521, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.723 with standard deviation 0.042. And the mean value of best solutions found was 0.174 (0. is the best) with standard deviation 0.035.", "error": "", "parent_id": "9c016a84-dd3d-4428-b142-27cc1b68f2be", "metadata": {"aucs": [0.6740698633506605, 0.775953740681859, 0.7198677582910435], "final_y": [0.21185908847573987, 0.12790697444190346, 0.18075863783416124]}, "mutation_prompt": null}
{"id": "a045a7b5-04c3-407f-b443-d89024196160", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.3 * np.random.rand() * adaptive_factor ** 3\n            cognitive_coeff = 2.0 * (1 - adaptive_factor)\n            social_coeff = 1.5 + 0.5 * np.cos(evaluations)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=int(5 + adaptive_factor * 4), replace=False)  # Modified line\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))  # Modified line\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Advanced dynamic neighbor selection and adaptive coefficients enhance swarm performance in complex landscapes.", "configspace": "", "generation": 53, "fitness": 0.8688402661663175, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.869 with standard deviation 0.026. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "9c016a84-dd3d-4428-b142-27cc1b68f2be", "metadata": {"aucs": [0.8425944968696061, 0.8593700047646847, 0.9045562968646617], "final_y": [0.12114329464590945, 0.13131922454059963, 0.11416978839077996]}, "mutation_prompt": null}
{"id": "8c12fa0a-cf65-4d64-83d3-9db20da8d3a6", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.3 * np.random.rand() * adaptive_factor ** 2  # Modified line\n            cognitive_coeff = 2.0 * (1 - adaptive_factor)\n            social_coeff = 1.5 + 0.5 * np.cos(evaluations)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=int(5 + adaptive_factor * 4), replace=False)  # Modified line\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced convergence through dynamic inertia tuning and additional diversity introduction in neighborhood selection.", "configspace": "", "generation": 54, "fitness": 0.8957808374067504, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.896 with standard deviation 0.020. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "9c016a84-dd3d-4428-b142-27cc1b68f2be", "metadata": {"aucs": [0.8726628516144349, 0.8932910978022177, 0.9213885628035985], "final_y": [0.11789117956362716, 0.11740710158652412, 0.11158009472575037]}, "mutation_prompt": null}
{"id": "5d82f6e9-940a-46b9-b481-a7bdcd35c0c1", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.3 * np.random.rand() * adaptive_factor ** 2\n            cognitive_coeff = 2.0 * (1 - adaptive_factor)\n            social_coeff = 1.5 + 0.5 * np.cos(evaluations)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=int(5 + 2 * adaptive_factor ** 2), replace=False)  # Modified line\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))  # Modified line\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced adaptive neighborhood size influenced by convergence speed and momentum-based velocity update to improve exploration-exploitation balance.", "configspace": "", "generation": 55, "fitness": 0.8628012895520109, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.863 with standard deviation 0.026. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "8c12fa0a-cf65-4d64-83d3-9db20da8d3a6", "metadata": {"aucs": [0.8423235189125573, 0.8467704928006932, 0.899309856942782], "final_y": [0.12052937006050979, 0.1321018483449915, 0.11447365544901433]}, "mutation_prompt": null}
{"id": "ce98130e-702a-484d-a058-26ad87e70d9b", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.3 * np.random.rand() * adaptive_factor ** 2\n            diversity_measure = np.std(swarm, axis=0).mean()  # New line\n            cognitive_coeff = 2.0 * (1 - adaptive_factor + 0.1 * diversity_measure)  # Modified line\n            social_coeff = 1.5 + 0.5 * np.cos(evaluations) * (1 + 0.1 * diversity_measure)  # Modified line\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=int(5 + adaptive_factor * 4), replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce adaptive cognitive and social coefficients based on swarm diversity to enhance exploration and exploitation balance.", "configspace": "", "generation": 56, "fitness": 0.7569785832443068, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.757 with standard deviation 0.014. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "8c12fa0a-cf65-4d64-83d3-9db20da8d3a6", "metadata": {"aucs": [0.737049773145114, 0.76890311738062, 0.7649828592071864], "final_y": [0.17272188562648072, 0.1702433386818767, 0.17140638443374367]}, "mutation_prompt": null}
{"id": "bf02b8a3-e86b-4449-bb55-69937c547de1", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - (evaluations / self.budget) ** 2  # Modified line\n            inertia_weight = 0.5 + 0.3 * np.random.rand() * adaptive_factor ** 2\n            cognitive_coeff = 2.0 * (1 - adaptive_factor)\n            social_coeff = 1.5 + 0.5 * np.cos(evaluations)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=int(5 + adaptive_factor * 4), replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                velocity_clamp = 0.1 * (ub - lb)  # Modified line\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp, velocity_clamp)  # Modified line\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Incorporate nonlinear adaptive factors and velocity constraints to further enhance swarm exploration and convergence.", "configspace": "", "generation": 57, "fitness": 0.9191434317531456, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.919 with standard deviation 0.003. And the mean value of best solutions found was 0.111 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "8c12fa0a-cf65-4d64-83d3-9db20da8d3a6", "metadata": {"aucs": [0.9161002095482096, 0.9179354274330808, 0.9233946582781465], "final_y": [0.11017351380094975, 0.11171787079985496, 0.11098137726824508]}, "mutation_prompt": null}
{"id": "643bf274-19aa-413c-943f-7aabbeb6bb47", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - (evaluations / self.budget) ** 2\n            inertia_weight = 0.5 + 0.3 * np.random.rand() * adaptive_factor ** 2\n            cognitive_coeff = 2.0 * (1 - adaptive_factor) * (1 + np.cos(evaluations / self.budget * np.pi))  # Modified line\n            social_coeff = 1.5 + 0.5 * np.cos(evaluations / self.budget * np.pi)  # Modified line\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=int(5 + adaptive_factor * 4), replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                velocity_clamp = 0.1 * (ub - lb)\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp, velocity_clamp)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce dynamic scaling of cognitive and social coefficients based on evaluation progress to enhance convergence.", "configspace": "", "generation": 58, "fitness": 0.9206179841224023, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.921 with standard deviation 0.006. And the mean value of best solutions found was 0.110 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "bf02b8a3-e86b-4449-bb55-69937c547de1", "metadata": {"aucs": [0.9169882211618835, 0.915431173390646, 0.9294345578146771], "final_y": [0.10963408246836992, 0.11162960296199242, 0.11003397429654982]}, "mutation_prompt": null}
{"id": "3b73a045-9643-495a-b4c6-9a4385a76f54", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - (evaluations / self.budget) ** 2\n            inertia_weight = 0.5 + 0.1 * np.random.rand() * (1 + adaptive_factor)  # Modified line\n            cognitive_coeff = 2.0 * (1 - adaptive_factor) * (1 + np.cos(evaluations / self.budget * np.pi))\n            social_coeff = 1.5 + 0.5 * np.cos(evaluations / self.budget * np.pi)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=int(5 + adaptive_factor * 4), replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                velocity_clamp = 0.1 * (ub - lb)\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp, velocity_clamp)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce stochastic inertia weight based on dynamic global improvements to enhance exploration and convergence.", "configspace": "", "generation": 59, "fitness": 0.9223017727997682, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.922 with standard deviation 0.005. And the mean value of best solutions found was 0.110 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "643bf274-19aa-413c-943f-7aabbeb6bb47", "metadata": {"aucs": [0.9172731079511784, 0.9213128656855273, 0.9283193447625988], "final_y": [0.10961296425653944, 0.11163922987194563, 0.10999694562298812]}, "mutation_prompt": null}
{"id": "94285476-4b23-42bf-b7b5-9df6ed69861c", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - (evaluations / self.budget) ** 2\n            inertia_weight = 0.5 + 0.1 * np.random.rand() * (1 + adaptive_factor)\n            cognitive_coeff = 2.0 * (1 - adaptive_factor) * (1 + np.cos(evaluations / self.budget * np.pi))\n            social_coeff = 1.5 + 0.5 * np.cos(evaluations / self.budget * np.pi)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=int(5 + adaptive_factor * 4), replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                velocity_clamp = 0.1 * (ub - lb)\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp, velocity_clamp)\n                swarm[i] += self.velocity[i]\n                # Introduce non-linear strategy for neighborhood influence\n                swarm[i] = np.clip(swarm[i] + adaptive_factor * 0.05 * (local_best - swarm[i]), lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce non-linear adaptive neighborhood influence to enhance precision in local search and convergence.", "configspace": "", "generation": 60, "fitness": 0.9167638135372629, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.917 with standard deviation 0.010. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "3b73a045-9643-495a-b4c6-9a4385a76f54", "metadata": {"aucs": [0.9030242193723327, 0.922232100783231, 0.9250351204562249], "final_y": [0.11684035456262187, 0.11163017451071189, 0.11003095910498617]}, "mutation_prompt": null}
{"id": "d3e4da99-4559-4329-929d-d6f1438a6048", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - (evaluations / self.budget) ** 2\n            inertia_weight = 0.5 + 0.2 * np.random.rand() * (1 + adaptive_factor)  # Modified line\n            cognitive_coeff = 2.0 * (1 - adaptive_factor) * (1 + np.cos(evaluations / self.budget * np.pi))\n            social_coeff = 1.5 + 0.5 * np.cos(evaluations / self.budget * np.pi)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors_size = int(5 + adaptive_factor * 6)  # Modified line\n                neighbors = np.random.choice(self.population_size, size=neighbors_size, replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                velocity_clamp = 0.1 * (ub - lb)\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp, velocity_clamp)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce adaptive neighborhood size and enhanced inertia to improve local exploration and convergence.", "configspace": "", "generation": 61, "fitness": 0.9129076070651582, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.913 with standard deviation 0.006. And the mean value of best solutions found was 0.111 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "3b73a045-9643-495a-b4c6-9a4385a76f54", "metadata": {"aucs": [0.9057962071887047, 0.9127565252997929, 0.9201700887069766], "final_y": [0.11284541610449594, 0.10969609600739227, 0.11022059661695738]}, "mutation_prompt": null}
{"id": "11569ff9-00a7-4743-b179-132834768d50", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - (evaluations / self.budget) ** 2\n            inertia_weight = 0.5 + 0.1 * np.random.rand() * (1 + adaptive_factor)\n            cognitive_coeff = 2.0 * (1 - adaptive_factor) * (1 + np.cos(evaluations / self.budget * np.pi))\n            social_coeff = 1.5 + 0.5 * np.cos(max(0, stagnation_counter - 10) / 10 * np.pi)  # Modified line\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=int(5 + adaptive_factor * 4), replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                velocity_clamp = 0.1 * (ub - lb)\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp, velocity_clamp)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0  # Modified line\n                else:\n                    stagnation_counter += 1  # Modified line\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Incorporate swarm diversity control by adapting cognitive and social coefficients based on dynamic improvements and stagnation detection.", "configspace": "", "generation": 62, "fitness": 0.8939000969763203, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.894 with standard deviation 0.043. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "3b73a045-9643-495a-b4c6-9a4385a76f54", "metadata": {"aucs": [0.8337062770918453, 0.9195358046545508, 0.9284582091825652], "final_y": [0.13967547504894806, 0.1116724506662633, 0.109915671015972]}, "mutation_prompt": null}
{"id": "eea1aee6-1fd4-461b-b6c5-d71cfa5e0c38", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - (evaluations / self.budget) ** 2\n            \n            # Change 1: Modified inertia weight calculation\n            inertia_weight = 0.5 + 0.1 * np.random.rand() * (np.exp(-adaptive_factor))\n            \n            cognitive_coeff = 2.0 * (1 - adaptive_factor) * (1 + np.cos(evaluations / self.budget * np.pi))\n            \n            # Change 2: Modified social coefficient calculation\n            social_coeff = 1.5 + 0.5 * np.cos((1 - adaptive_factor) * np.pi)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                \n                # Change 3: Dynamic neighborhood size\n                neighbors = np.random.choice(self.population_size, size=int(5 + adaptive_factor * 6), replace=False)\n                \n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                velocity_clamp = 0.1 * (ub - lb)\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp, velocity_clamp)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce nonlinear inertia weight decay and dynamic neighborhood size for improved exploration and convergence balance.", "configspace": "", "generation": 63, "fitness": 0.9193419211883725, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.919 with standard deviation 0.011. And the mean value of best solutions found was 0.112 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "3b73a045-9643-495a-b4c6-9a4385a76f54", "metadata": {"aucs": [0.9043527035371254, 0.9270333682224327, 0.9266396918055599], "final_y": [0.11281261150897715, 0.11162959010543028, 0.11006016182489253]}, "mutation_prompt": null}
{"id": "413fa0e0-a3d7-4be0-97ca-d27c2a424d7d", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - (evaluations / self.budget) ** 2\n            inertia_weight = 0.5 + 0.1 * np.random.rand() * (1 + adaptive_factor)\n            cognitive_coeff = 2.0 * (1 - adaptive_factor) * (1 + np.cos(evaluations / self.budget * np.pi))\n            social_coeff = 1.5 + 0.5 * np.cos(evaluations / self.budget * np.pi)\n            \n            # Change: Introduce adaptive mutation intensity based on global stagnation\n            mutation_intensity = 0.1 * (1 + np.tanh((global_best_value - np.mean(personal_best_value)) / np.std(personal_best_value)))\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=int(5 + adaptive_factor * 4), replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                velocity_clamp = 0.1 * (ub - lb)\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp, velocity_clamp)\n                swarm[i] += self.velocity[i] + mutation_intensity * np.random.normal(size=self.dim)  # Change: Add mutation\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Utilize adaptive mutation intensities based on global stagnation to enhance exploration and prevent local optima trapping.", "configspace": "", "generation": 64, "fitness": 0.9190891166899591, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.919 with standard deviation 0.005. And the mean value of best solutions found was 0.111 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "3b73a045-9643-495a-b4c6-9a4385a76f54", "metadata": {"aucs": [0.9118534859424767, 0.9212287402384954, 0.9241851238889048], "final_y": [0.1128126021419309, 0.10967531565459221, 0.1101870110078127]}, "mutation_prompt": null}
{"id": "4ff830d8-258a-4066-a56a-ad873d5614e8", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - (evaluations / self.budget) ** 2\n            inertia_weight = 0.5 + 0.1 * np.random.rand() * (1 + adaptive_factor)\n            cognitive_coeff = 2.0 * (1 - adaptive_factor) * (1 + np.cos(evaluations / self.budget * np.pi))\n            social_coeff = 1.5 + 0.5 * np.cos(evaluations / self.budget * np.pi)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dynamic_neighbors_size = int(5 + adaptive_factor * 4)\n                neighbors = np.random.choice(self.population_size, size=dynamic_neighbors_size, replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = 0.9 * self.velocity[i] + (inertia_weight * self.velocity[i] +  # Modified line\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                velocity_clamp = 0.1 * (ub - lb)\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp, velocity_clamp)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance exploration-exploitation balance by introducing velocity memory and dynamic neighborhood size.", "configspace": "", "generation": 65, "fitness": 0.8668455810875434, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.867 with standard deviation 0.003. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "3b73a045-9643-495a-b4c6-9a4385a76f54", "metadata": {"aucs": [0.8705599115972865, 0.8660693588471176, 0.8639074728182259], "final_y": [0.11849104604155036, 0.12969047142945156, 0.12738568026604835]}, "mutation_prompt": null}
{"id": "660bea92-a2d4-43e1-8592-9a334526be1b", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - (evaluations / self.budget) ** 2\n            inertia_weight = 0.5 + 0.1 * np.random.rand() * (1 + adaptive_factor)\n            cognitive_coeff = 2.0 * (1 - adaptive_factor) * (1 + np.cos(evaluations / self.budget * np.pi))\n            social_coeff = 1.5 + 0.5 * np.cos(evaluations / self.budget * np.pi) * (1 + adaptive_factor)  # Modified line\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=int(5 + adaptive_factor * 4), replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                velocity_clamp = 0.1 * (ub - lb) * (1 - adaptive_factor)  # Modified line\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp, velocity_clamp)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Utilize adaptive velocity clamping and dynamic social coefficient scaling to improve convergence precision and speed.", "configspace": "", "generation": 66, "fitness": 0.8056269994004643, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.806 with standard deviation 0.020. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "3b73a045-9643-495a-b4c6-9a4385a76f54", "metadata": {"aucs": [0.7812985193626585, 0.8304722044883929, 0.8051102743503417], "final_y": [0.11722920526645142, 0.11348615928851158, 0.11540741447987002]}, "mutation_prompt": null}
{"id": "2e38c832-75ce-40a1-9ec9-e0090cbe063e", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - (evaluations / self.budget) ** 2\n            inertia_weight = 0.5 + 0.1 * np.random.rand() * (1 + adaptive_factor)\n            cognitive_coeff = 2.0 * (1 - adaptive_factor) * (1 + np.cos(evaluations / self.budget * np.pi))\n            social_coeff = 1.5 + 0.5 * np.cos(evaluations / self.budget * np.pi)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=int(5 + adaptive_factor * 6), replace=False)  # Change 1\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                velocity_clamp = 0.1 * (ub - lb)\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp, velocity_clamp)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Leverage dynamic neighborhood size and adaptive coefficients to enhance convergence and solution quality.", "configspace": "", "generation": 67, "fitness": 0.9201330452252813, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.920 with standard deviation 0.006. And the mean value of best solutions found was 0.112 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "3b73a045-9643-495a-b4c6-9a4385a76f54", "metadata": {"aucs": [0.9128290710184109, 0.9262106768400914, 0.9213593878173415], "final_y": [0.11180547639033744, 0.11163052812884355, 0.11155015287527037]}, "mutation_prompt": null}
{"id": "42218801-d568-4c46-8b79-4e8597858c14", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - (evaluations / self.budget) ** 2\n            inertia_weight = 0.5 + 0.1 * np.random.rand() * (1 + adaptive_factor)\n            cognitive_coeff = 2.0 * (1 - adaptive_factor) * (1 + np.cos(evaluations / self.budget * np.pi))\n            social_coeff = 1.5 + 0.5 * np.cos(evaluations / self.budget * np.pi)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=int(5 + adaptive_factor * 4), replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                velocity_clamp = 0.1 * (1 - adaptive_factor) * (ub - lb)  # Modified line\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp, velocity_clamp)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a dynamic scaling factor for velocity clamping and adaptive local search to enhance fine-tuning and convergence.", "configspace": "", "generation": 68, "fitness": 0.810745248301635, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.811 with standard deviation 0.017. And the mean value of best solutions found was 0.112 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "3b73a045-9643-495a-b4c6-9a4385a76f54", "metadata": {"aucs": [0.7886401569971971, 0.8298887274992246, 0.813706860408483], "final_y": [0.11146014239804714, 0.11222586506427112, 0.11113338054054145]}, "mutation_prompt": null}
{"id": "c6d46061-dc95-41a0-b5e0-56440d29966f", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - (evaluations / self.budget) ** 2\n            inertia_weight = 0.5 + 0.1 * np.random.rand() * (1 + adaptive_factor)\n            cognitive_coeff = 2.0 * (1 - adaptive_factor) * (1 + np.cos(evaluations / self.budget * np.pi) * (global_best_value / np.max(personal_best_value)))  # Modified line\n            social_coeff = 1.5 + 0.5 * np.cos(evaluations / self.budget * np.pi)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=int(5 + adaptive_factor * 4), replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                velocity_clamp = 0.1 * (ub - lb)\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp, velocity_clamp)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce dynamic cognitive coefficient for enhanced adaptability based on global best improvements.", "configspace": "", "generation": 69, "fitness": 0.9219527433930423, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.922 with standard deviation 0.005. And the mean value of best solutions found was 0.110 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "3b73a045-9643-495a-b4c6-9a4385a76f54", "metadata": {"aucs": [0.9171033088115222, 0.9203373573910372, 0.9284175639765676], "final_y": [0.10962905370816645, 0.11163532196401382, 0.11009245696973768]}, "mutation_prompt": null}
{"id": "ff666fa5-1185-4ea7-a86d-fe0a0cd16946", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - (evaluations / self.budget) ** 2\n            inertia_weight = 0.5 + 0.1 * np.random.rand() * (1 + adaptive_factor)\n            cognitive_coeff = 2.0 * (1 - adaptive_factor) * (1 + np.cos(evaluations / self.budget * np.pi))\n            social_coeff = 1.5 + 0.5 * np.cos(evaluations / self.budget * np.pi)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_size = int(max(3, np.ceil(7 + adaptive_factor * 5)))  # Modified line\n                neighbors = np.random.choice(self.population_size, size=neighborhood_size, replace=False)  # Modified line\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                velocity_clamp = 0.2 * (ub - lb) * (1 - adaptive_factor)  # Modified line\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp, velocity_clamp)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a dynamic neighborhood size and adaptive velocity clamping for more balanced exploration and exploitation.", "configspace": "", "generation": 70, "fitness": 0.8374906017118624, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.837 with standard deviation 0.020. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "3b73a045-9643-495a-b4c6-9a4385a76f54", "metadata": {"aucs": [0.8086080045509303, 0.8535952723906399, 0.8502685281940168], "final_y": [0.117016796352293, 0.11214731225745256, 0.10975849494836254]}, "mutation_prompt": null}
{"id": "886b5088-fe9e-401f-9694-57cc4ef1abeb", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - (evaluations / self.budget) ** 2\n            inertia_weight = 0.5 + 0.1 * np.random.rand() * (1 + adaptive_factor)\n            cognitive_coeff = 2.0 * (1 - adaptive_factor) * (1 + np.cos(evaluations / self.budget * np.pi))\n            social_coeff = 1.5 + 0.5 * np.cos(evaluations / self.budget * np.pi)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=int(5 + adaptive_factor * 6), replace=False)  # Changed line\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                velocity_clamp = (0.1 + 0.05 * adaptive_factor) * (ub - lb)  # Changed line\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp, velocity_clamp)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce an adaptive neighborhood size and nonlinear velocity scaling to enhance convergence stability and precision.", "configspace": "", "generation": 71, "fitness": 0.8918295094017633, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.892 with standard deviation 0.040. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "3b73a045-9643-495a-b4c6-9a4385a76f54", "metadata": {"aucs": [0.8360350996542302, 0.9171554940440668, 0.9222979345069928], "final_y": [0.13953324907732256, 0.11523628082513504, 0.10978318907556639]}, "mutation_prompt": null}
{"id": "baacdd58-24da-4818-a8f6-4f0125f324c4", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.momentum = np.zeros((self.population_size, dim))  # Added line\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - (evaluations / self.budget) ** 2\n            inertia_weight = 0.5 + 0.1 * np.random.rand() * (1 + adaptive_factor)\n            cognitive_coeff = 2.0 * (1 - adaptive_factor) * (1 + np.cos(evaluations / self.budget * np.pi))\n            social_coeff = 1.5 + 0.5 * np.cos(evaluations / self.budget * np.pi)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=int(5 + adaptive_factor * 4), replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.momentum[i] = 0.9 * self.momentum[i] + self.velocity[i]  # Modified line\n                self.velocity[i] = (inertia_weight * self.momentum[i] +  # Modified line\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                velocity_clamp = 0.1 * (ub - lb)\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp, velocity_clamp)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Utilize momentum factor with modified update rule to improve convergence stability and precision.", "configspace": "", "generation": 72, "fitness": 0.8317126526416853, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.832 with standard deviation 0.033. And the mean value of best solutions found was 0.138 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "3b73a045-9643-495a-b4c6-9a4385a76f54", "metadata": {"aucs": [0.7844126640931369, 0.8531446502618387, 0.8575806435700802], "final_y": [0.15758576608788366, 0.12941410383395524, 0.126638275819833]}, "mutation_prompt": null}
{"id": "387dd779-87c8-4113-b755-1daf77840812", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - (evaluations / self.budget) ** 2\n            inertia_weight = 0.5 + 0.1 * np.random.rand() * (1 + adaptive_factor)\n            \n            diversity = np.mean(np.std(swarm, axis=0))  # Calculate diversity of the swarm\n            cognitive_coeff = 2.0 * (1 - adaptive_factor) * (1 + np.cos(evaluations / self.budget * np.pi * diversity))  # Changed line\n            \n            social_coeff = 1.5 + 0.5 * np.cos(evaluations / self.budget * np.pi)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=int(5 + adaptive_factor * 4), replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                velocity_clamp = 0.1 * (ub - lb)\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp, velocity_clamp)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a dynamic cognitive coefficient tuning mechanism based on swarm's diversity to enhance local search capabilities.", "configspace": "", "generation": 73, "fitness": 0.9215950749913341, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.922 with standard deviation 0.005. And the mean value of best solutions found was 0.110 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "3b73a045-9643-495a-b4c6-9a4385a76f54", "metadata": {"aucs": [0.9158269797868825, 0.9201466339591824, 0.9288116112279374], "final_y": [0.10962171781346852, 0.11165159641004474, 0.11003654842167443]}, "mutation_prompt": null}
{"id": "04e094fc-e7c5-41ac-8899-7a28bfb28f49", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - (evaluations / self.budget) ** 2\n            inertia_weight = 0.5 + 0.1 * np.random.rand() * (1 + adaptive_factor)\n            cognitive_coeff = 2.0 * (1 - adaptive_factor) * (1 + np.cos(evaluations / self.budget * np.pi))\n            social_coeff = 1.5 + 0.5 * np.cos(evaluations / self.budget * np.pi)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=int(5 + adaptive_factor * 4), replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                velocity_clamp = 0.1 * (ub - lb)\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp, velocity_clamp)\n                swarm[i] += self.velocity[i] + np.random.normal(0, 0.01, self.dim)  # Modified line\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a mutation mechanism based on Gaussian noise to enhance solution diversity and exploration.", "configspace": "", "generation": 74, "fitness": 0.9158817038895112, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.916 with standard deviation 0.005. And the mean value of best solutions found was 0.112 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "3b73a045-9643-495a-b4c6-9a4385a76f54", "metadata": {"aucs": [0.9117001906056584, 0.9133509334329528, 0.9225939876299221], "final_y": [0.11280909092620817, 0.11180500168970675, 0.1109381028135682]}, "mutation_prompt": null}
{"id": "f32296c4-1c17-432f-84ee-d38fa94f256e", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - (evaluations / self.budget) ** 2\n            inertia_weight = 0.5 + 0.1 * np.random.rand() * (1 + adaptive_factor)\n            cognitive_coeff = 2.0 * (1 - adaptive_factor) * (1 + np.cos(evaluations / self.budget * np.pi))\n            social_coeff = 1.5 + 0.5 * np.cos(evaluations / self.budget * np.pi)\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)  # Modified line\n                neighbors = np.random.choice(self.population_size, size=int(5 + adaptive_factor * 4), replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]) +\n                                    0.05 * r3 * (ub - lb) * (adaptive_factor))  # Modified line\n                velocity_clamp = 0.1 * (ub - lb)\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp, velocity_clamp)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance swarm diversity by incorporating time-varying random exploration in the velocity update.", "configspace": "", "generation": 75, "fitness": 0.8266205905349678, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.827 with standard deviation 0.029. And the mean value of best solutions found was 0.138 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "3b73a045-9643-495a-b4c6-9a4385a76f54", "metadata": {"aucs": [0.792602616810344, 0.8232918414040027, 0.8639673133905568], "final_y": [0.15175984014662447, 0.13899344683991788, 0.12452262993210572]}, "mutation_prompt": null}
{"id": "49818a22-a10d-47e2-ba4a-4e57c65713fa", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.elitism_rate = 0.1  # New line\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - (evaluations / self.budget) ** 2\n            inertia_weight = 0.5 + 0.1 * np.random.rand() * (1 + adaptive_factor)\n            cognitive_coeff = 2.0 * (1 - adaptive_factor) * (1 + np.cos(evaluations / self.budget * np.pi))\n            social_coeff = 1.5 + 0.5 * np.cos(evaluations / self.budget * np.pi)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=int(5 + adaptive_factor * 4), replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                velocity_clamp = 0.1 * (ub - lb)\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp, velocity_clamp)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                if np.random.rand() < self.elitism_rate:  # New line\n                    perturbation = np.random.normal(0, 0.1, self.dim) * (ub - lb)  # New line\n                    swarm[i] = np.clip(global_best + perturbation, lb, ub)  # New line\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Adaptive random perturbation and elitism for enhanced exploration and convergence in stochastic gradient-based swarm optimization.", "configspace": "", "generation": 76, "fitness": 0.920187678210702, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.920 with standard deviation 0.007. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "3b73a045-9643-495a-b4c6-9a4385a76f54", "metadata": {"aucs": [0.928921537358474, 0.9109226009762058, 0.920718896297426], "final_y": [0.1098156769061962, 0.11628983373827007, 0.11199548189010022]}, "mutation_prompt": null}
{"id": "b0c88149-e517-4a01-a83a-3c0bb31bda50", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - (evaluations / self.budget) ** 2\n            inertia_weight = 0.5 + 0.1 * np.random.rand() * (1 + adaptive_factor)\n            cognitive_coeff = 2.0 * (1 - adaptive_factor) * (1 + np.cos(evaluations / self.budget * np.pi))\n            social_coeff = 1.5 + 0.5 * np.cos(evaluations / self.budget * np.pi)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=int(5 + adaptive_factor * 4), replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                perturbation = 0.05 * (1 - adaptive_factor) * np.random.randn(self.dim)  # Modified line\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]) + perturbation)  # Modified line\n                velocity_clamp = 0.1 * (ub - lb)\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp, velocity_clamp)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance exploration by introducing a dynamic perturbation factor based on evaluation progress.", "configspace": "", "generation": 77, "fitness": 0.9166458074444884, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.917 with standard deviation 0.005. And the mean value of best solutions found was 0.112 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "3b73a045-9643-495a-b4c6-9a4385a76f54", "metadata": {"aucs": [0.9137042267624952, 0.9123229736691986, 0.9239102219017716], "final_y": [0.11280996671343368, 0.11165021360333738, 0.11045473769481529]}, "mutation_prompt": null}
{"id": "117733fa-dcac-4fa5-8cac-d4bf8251bd30", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - (evaluations / self.budget) ** 2\n            inertia_weight = 0.5 + 0.1 * np.random.rand() * (1 + adaptive_factor)\n            cognitive_coeff = 2.0 * (1 - adaptive_factor) * (1 + np.cos(evaluations / self.budget * np.pi))  # Modified\n            social_coeff = 1.5 + 0.5 * np.cos(global_best_value / np.mean(personal_best_value))  # Modified\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=int(5 + adaptive_factor * 4), replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))  # Modified\n                velocity_clamp = 0.1 * (ub - lb)\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp, velocity_clamp)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance global and local search balance by adjusting cognitive and social coefficients based on current solution quality.", "configspace": "", "generation": 78, "fitness": 0.9198854837322502, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.920 with standard deviation 0.007. And the mean value of best solutions found was 0.111 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "3b73a045-9643-495a-b4c6-9a4385a76f54", "metadata": {"aucs": [0.9115096525611098, 0.9191208894334074, 0.9290259092022336], "final_y": [0.11027163648963834, 0.11171412645806822, 0.11018346645256982]}, "mutation_prompt": null}
{"id": "9a31d070-0b36-402a-a82f-75026bfba203", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - (evaluations / self.budget) ** 2\n            inertia_weight = 0.5 + 0.1 * np.random.rand() * (1 + adaptive_factor)\n            cognitive_coeff = 2.0 * (1 - adaptive_factor) * (1 + np.cos(evaluations / self.budget * np.pi))\n            social_coeff = 1.5 + 0.5 * np.cos(evaluations / self.budget * np.pi)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=int(5 + adaptive_factor * 4), replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                levy_flight = np.random.standard_cauchy(self.dim) * adaptive_factor * 0.1  # Modified line\n                self.velocity[i] += levy_flight  # Modified line\n                velocity_clamp = 0.1 * (ub - lb)\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp, velocity_clamp)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Incorporate Levy flight for enhanced exploration and reduced premature convergence.", "configspace": "", "generation": 79, "fitness": 0.9111843130554815, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.911 with standard deviation 0.011. And the mean value of best solutions found was 0.112 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "3b73a045-9643-495a-b4c6-9a4385a76f54", "metadata": {"aucs": [0.8965507496680094, 0.9152751730024681, 0.9217270164959669], "final_y": [0.11513189318880546, 0.11164625785947702, 0.11026921563281222]}, "mutation_prompt": null}
{"id": "b0cfac27-ebeb-450c-87a4-a5bfa3723f49", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - (evaluations / self.budget) ** 2\n            inertia_weight = 0.6 + 0.1 * np.random.rand() * (1 + adaptive_factor)  # Modified line\n            cognitive_coeff = 1.8 * (1 - adaptive_factor) * (1 + np.cos(evaluations / self.budget * np.pi))\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=int(5 + adaptive_factor * 4), replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                velocity_clamp = 0.1 * (ub - lb)\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp, velocity_clamp)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance convergence by integrating a learning strategy with adaptive inertia and cognitive coefficients.", "configspace": "", "generation": 80, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'social_coeff' is not defined\").", "error": "NameError(\"name 'social_coeff' is not defined\")", "parent_id": "3b73a045-9643-495a-b4c6-9a4385a76f54", "metadata": {}, "mutation_prompt": null}
{"id": "87e4d8cc-df88-42ef-8b97-e5baaa6b3aa0", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - (evaluations / self.budget) ** 2\n            inertia_weight = 0.5 + 0.1 * np.random.rand() * (1 + adaptive_factor)\n            cognitive_coeff = 2.0 * (1 - adaptive_factor) * (1 + np.cos(evaluations / self.budget * np.pi))\n            social_coeff = 1.5 + 0.5 * np.cos(evaluations / self.budget * np.pi)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors_count = int(5 + adaptive_factor * 4 + np.sin(evaluations / self.budget * np.pi))  # Modified line\n                neighbors = np.random.choice(self.population_size, size=neighbors_count, replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                velocity_clamp = 0.1 * (ub - lb)\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp, velocity_clamp)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance global search by integrating a dynamic neighborhood size based on current evaluations.", "configspace": "", "generation": 81, "fitness": 0.9151321978605381, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.915 with standard deviation 0.015. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "3b73a045-9643-495a-b4c6-9a4385a76f54", "metadata": {"aucs": [0.8934843290557409, 0.9250084696250573, 0.9269037949008163], "final_y": [0.11686881584931053, 0.11162853030805475, 0.11018281881809333]}, "mutation_prompt": null}
{"id": "2a16bb74-0a77-4919-939c-407070c89601", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - (evaluations / self.budget) ** 2\n            inertia_weight = 0.5 + 0.1 * np.random.rand() * (1 + adaptive_factor)\n            diversity = np.mean(np.std(swarm, axis=0)) / (ub - lb)  # New line for diversity calculation\n            cognitive_coeff = 2.0 * (1 - adaptive_factor) * (1 + np.cos(evaluations / self.budget * np.pi)) * (1 + diversity)  # Modified line\n            social_coeff = (1.5 + 0.5 * np.cos(evaluations / self.budget * np.pi)) * (1 - diversity)  # Modified line\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=int(5 + adaptive_factor * 4), replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                velocity_clamp = 0.1 * (ub - lb)\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp, velocity_clamp)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Integrate adaptive learning rates for cognitive and social coefficients based on population diversity to enhance convergence.", "configspace": "", "generation": 82, "fitness": 0.8914617340376028, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.891 with standard deviation 0.032. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "3b73a045-9643-495a-b4c6-9a4385a76f54", "metadata": {"aucs": [0.846742899767599, 0.9051137963470492, 0.9225285059981603], "final_y": [0.12718605067345445, 0.11523488328877529, 0.1100368067921016]}, "mutation_prompt": null}
{"id": "9d321589-6079-4fa8-b0e7-63a099f2c630", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.momentum = 0.9  # Added line\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - (evaluations / self.budget) ** 2\n            inertia_weight = 0.5 + 0.1 * np.random.rand() * (1 + adaptive_factor)\n            cognitive_coeff = 2.0 * (1 - adaptive_factor) * (1 + np.cos(evaluations / self.budget * np.pi))\n            social_coeff = 1.5 + 0.5 * np.cos(evaluations / self.budget * np.pi)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=int(5 + adaptive_factor * 4), replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                previous_velocity = self.velocity[i].copy()  # Added line\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                self.velocity[i] = self.momentum * previous_velocity + (1 - self.momentum) * self.velocity[i]  # Modified line\n                velocity_clamp = 0.1 * (ub - lb)\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp, velocity_clamp)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance convergence by introducing momentum to the velocity update for smoother trajectory and improved exploitation.", "configspace": "", "generation": 83, "fitness": 0.8582159014882036, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.858 with standard deviation 0.008. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "3b73a045-9643-495a-b4c6-9a4385a76f54", "metadata": {"aucs": [0.8505699383411152, 0.8688724133664668, 0.8552053527570286], "final_y": [0.11754984463628348, 0.12540990195367596, 0.12364458024040093]}, "mutation_prompt": null}
{"id": "9f1ff983-3abc-498a-b0f1-018db6a6e0fb", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - (evaluations / self.budget) ** 2\n            inertia_weight = 0.5 + 0.1 * np.random.rand() * (1 + adaptive_factor)\n            cognitive_coeff = 2.0 * (1 - adaptive_factor) * (1 + np.cos(evaluations / self.budget * np.pi))\n            social_coeff = 1.5 + 0.5 * np.cos(evaluations / self.budget * np.pi)\n\n            global_fitness_variance = np.var(personal_best_value)  # Added line\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=int(5 + adaptive_factor * 4), replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                velocity_clamp = 0.1 * (ub - lb) * (1 + global_fitness_variance)  # Modified line\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp, velocity_clamp)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance swarm diversity by dynamically adjusting velocity clamping based on global fitness variance.", "configspace": "", "generation": 84, "fitness": 0.9222434296775806, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.922 with standard deviation 0.005. And the mean value of best solutions found was 0.110 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "3b73a045-9643-495a-b4c6-9a4385a76f54", "metadata": {"aucs": [0.9179458949174535, 0.9191403678177616, 0.9296440262975267], "final_y": [0.10961909265793923, 0.11177590531237869, 0.10999443690172528]}, "mutation_prompt": null}
{"id": "400974be-f0fd-436d-a3ca-d15969c66ac9", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - (evaluations / self.budget) ** 2\n            damping_factor = 1 - np.exp(-adaptive_factor * 5)  # Added line\n            inertia_weight = (0.5 + 0.1 * np.random.rand() * (1 + adaptive_factor) * damping_factor)  # Modified line\n            cognitive_coeff = 2.0 * (1 - adaptive_factor) * (1 + np.cos(evaluations / self.budget * np.pi))\n            social_coeff = 1.5 + 0.5 * np.cos(evaluations / self.budget * np.pi)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=int(5 + adaptive_factor * 4), replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                velocity_clamp = 0.1 * (ub - lb)\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp, velocity_clamp)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance swarm diversity by introducing a nonlinear damping factor to the inertia weight.", "configspace": "", "generation": 85, "fitness": 0.9203881791377319, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.920 with standard deviation 0.005. And the mean value of best solutions found was 0.110 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "3b73a045-9643-495a-b4c6-9a4385a76f54", "metadata": {"aucs": [0.9167370093880493, 0.9176099088199715, 0.9268176192051748], "final_y": [0.10963322190866454, 0.11169326801718948, 0.10991010450257466]}, "mutation_prompt": null}
{"id": "b8c6f409-f452-4b90-a5dd-df5db67ad3d9", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - (evaluations / self.budget) ** 2\n            inertia_weight = 0.5 + 0.1 * np.random.rand() * (1 + adaptive_factor)\n            cognitive_coeff = 2.0 * (1 - adaptive_factor) ** 2 # Modified line\n            social_coeff = 1.5 + 0.5 * np.cos(evaluations / self.budget * np.pi)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=int(5 + adaptive_factor * 4), replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                velocity_clamp = 0.1 * (ub - lb)\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp, velocity_clamp)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance convergence by incorporating a non-linear decreasing cognitive coefficient based on evaluation progression.", "configspace": "", "generation": 86, "fitness": 0.9236156130969352, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.924 with standard deviation 0.004. And the mean value of best solutions found was 0.110 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "3b73a045-9643-495a-b4c6-9a4385a76f54", "metadata": {"aucs": [0.9175682813647419, 0.9257774947065259, 0.9275010632195373], "final_y": [0.10976106650893624, 0.11168956147418452, 0.1100020355003053]}, "mutation_prompt": null}
{"id": "ec9aa987-12f5-449d-aa05-a393340aadbd", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - (evaluations / self.budget) ** 2\n            inertia_weight = 0.5 + 0.1 * np.random.rand() * (1 + adaptive_factor)\n            cognitive_coeff = 2.0 * (1 - adaptive_factor) ** 2 \n            social_coeff = 1.5 + 0.5 * np.sin(evaluations / self.budget * np.pi)  # Modified line\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=int(5 + adaptive_factor * 4), replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                velocity_clamp = 0.1 * (ub - lb)\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp, velocity_clamp)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a dynamic social coefficient adapted with sine modulation for improved exploration and convergence stability.", "configspace": "", "generation": 87, "fitness": 0.8849429336099414, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.885 with standard deviation 0.039. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "b8c6f409-f452-4b90-a5dd-df5db67ad3d9", "metadata": {"aucs": [0.8300484360598224, 0.9044884719346338, 0.9202918928353676], "final_y": [0.13961583966985336, 0.11537743246207821, 0.1123814639675157]}, "mutation_prompt": null}
{"id": "cbe46395-349f-44ba-854c-1b46974ed7a2", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - (evaluations / self.budget) ** 2\n            inertia_weight = 0.5 + 0.3 * np.sin(np.pi * evaluations / self.budget) # Modified line\n            cognitive_coeff = 2.0 * (1 - adaptive_factor) ** 2\n            social_coeff = 1.5 + 0.5 * np.cos(evaluations / self.budget * np.pi)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=int(5 + adaptive_factor * 4), replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                velocity_clamp = 0.1 * (ub - lb)\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp, velocity_clamp)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a dynamic inertia weight oscillation to enhance exploration-exploitation balance in the swarm.", "configspace": "", "generation": 88, "fitness": 0.913156311949488, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.913 with standard deviation 0.012. And the mean value of best solutions found was 0.112 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "b8c6f409-f452-4b90-a5dd-df5db67ad3d9", "metadata": {"aucs": [0.8972068402037027, 0.916927301443453, 0.9253347942013082], "final_y": [0.11375052688245524, 0.11210458073872487, 0.10988587092081525]}, "mutation_prompt": null}
{"id": "8ab74381-f64d-4154-a87d-d48883e0256e", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - (evaluations / self.budget) ** 2\n            inertia_weight = 0.5 + 0.5 * adaptive_factor # Modified line\n            cognitive_coeff = 2.0 * (1 - adaptive_factor) ** 2\n            social_coeff = 1.5 + 0.5 * np.cos(evaluations / self.budget * np.pi)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=int(5 + adaptive_factor * 4), replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                velocity_clamp = 0.1 * (ub - lb)\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp, velocity_clamp)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Amplify swarm exploration by varying the inertia weight non-linearly based on evaluations to better balance exploration and exploitation.", "configspace": "", "generation": 89, "fitness": 0.9012979521541568, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.901 with standard deviation 0.006. And the mean value of best solutions found was 0.112 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "b8c6f409-f452-4b90-a5dd-df5db67ad3d9", "metadata": {"aucs": [0.9044132110078743, 0.8930665486437224, 0.9064140968108734], "final_y": [0.11037176479991118, 0.11187560213089065, 0.11282784884502173]}, "mutation_prompt": null}
{"id": "1c2ed3c5-9b3d-40e4-afb0-06d5490fb8c9", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - (evaluations / self.budget) ** 2\n            inertia_weight = 0.5 + 0.2 * np.random.rand() * adaptive_factor  # Modified line\n            cognitive_coeff = 2.0 * (1 - adaptive_factor) ** 2\n            social_coeff = 1.5 + 0.5 * np.sin(evaluations / self.budget * np.pi)  # Modified line\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=int(5 + adaptive_factor * 4), replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                velocity_clamp = 0.1 * (ub - lb)\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp, velocity_clamp)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Incorporate a nonlinear inertia weight strategy and dynamic social coefficient adjustment to enhance swarm exploration.", "configspace": "", "generation": 90, "fitness": 0.8847715192379816, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.885 with standard deviation 0.039. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "b8c6f409-f452-4b90-a5dd-df5db67ad3d9", "metadata": {"aucs": [0.8300289552779863, 0.9037937821091124, 0.9204918203268458], "final_y": [0.1395745409154342, 0.11540854791588762, 0.1115495640227977]}, "mutation_prompt": null}
{"id": "4ebaecb9-28d8-4b6f-aca4-5fdf5f2ebe2a", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - (evaluations / self.budget) ** 2\n            inertia_weight = 0.5 + 0.1 * np.random.rand() * (1 + adaptive_factor)\n            cognitive_coeff = 2.0 * (1 - adaptive_factor) ** 2\n            social_coeff = 1.5 + 0.5 * np.sin(evaluations / self.budget * np.pi) # Modified line\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=int(5 + adaptive_factor * 4), replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i])) # Modified line\n                velocity_clamp = 0.1 * (ub - lb)\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp, velocity_clamp)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Incorporate adaptive social coefficients and alternative velocity update for enhanced exploration.", "configspace": "", "generation": 91, "fitness": 0.8775241772887901, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.878 with standard deviation 0.016. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "b8c6f409-f452-4b90-a5dd-df5db67ad3d9", "metadata": {"aucs": [0.8603838131128347, 0.8987002845647762, 0.8734884341887592], "final_y": [0.11029197382264022, 0.11508846588772703, 0.11283814916058332]}, "mutation_prompt": null}
{"id": "c12ed7d3-48bc-4d44-9c76-b8c022291838", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - (evaluations / self.budget) ** 2\n            inertia_weight = 0.5 + 0.1 * np.random.rand() * (1 + adaptive_factor)\n            cognitive_coeff = 2.0 * (1 - adaptive_factor) ** 2\n            social_coeff = 1.5 + 0.5 * np.cos(evaluations / self.budget * np.pi)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=int(5 + adaptive_factor * 4), replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                velocity_clamp = 0.1 * (ub - lb)\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp, velocity_clamp)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                # Gaussian perturbation local search\n                if evaluations % (self.budget // 10) == 0:\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    candidate = np.clip(global_best + perturbation, lb, ub)\n                    candidate_value = func(candidate)\n                    evaluations += 1\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Incorporate local-search exploration phase based on a Gaussian perturbation to the best-known solution.", "configspace": "", "generation": 92, "fitness": 0.9168745884274467, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.917 with standard deviation 0.014. And the mean value of best solutions found was 0.111 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "b8c6f409-f452-4b90-a5dd-df5db67ad3d9", "metadata": {"aucs": [0.8972080234909625, 0.9246968040185676, 0.9287189377728101], "final_y": [0.11282388610917315, 0.11163175118679258, 0.10985799510728922]}, "mutation_prompt": null}
{"id": "1123a306-e5eb-4c6e-a8f3-73d00bc76ea9", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - (evaluations / self.budget) ** 2\n            inertia_weight = 0.5 + 0.1 * np.random.rand() * (1 + adaptive_factor)\n            cognitive_coeff = 2.0 * (1 - adaptive_factor) ** 2\n            social_coeff = 1.5 + 0.5 * np.cos(evaluations / self.budget * np.pi)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=int(5 + adaptive_factor * 4), replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                velocity_clamp = 0.1 * (ub - lb) * (1 + 0.5 * adaptive_factor) # Modified line\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp, velocity_clamp)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance diversity and convergence by adapting velocity clamping based on current evaluation status.", "configspace": "", "generation": 93, "fitness": 0.9110770152676745, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.911 with standard deviation 0.007. And the mean value of best solutions found was 0.111 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "b8c6f409-f452-4b90-a5dd-df5db67ad3d9", "metadata": {"aucs": [0.9061873375069265, 0.9067577437485601, 0.9202859645475371], "final_y": [0.1118232753236631, 0.11236127650511984, 0.10977863367921348]}, "mutation_prompt": null}
{"id": "aaa9c333-0ff4-43ac-a8ab-2aeac14d109b", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - (evaluations / self.budget) ** 2\n            inertia_weight = 0.5 + 0.1 * np.random.rand() * (1 + adaptive_factor)\n            cognitive_coeff = 2.0 * (1 - adaptive_factor) ** 2\n            social_coeff = 1.5 + 0.5 * np.cos(evaluations / self.budget * np.pi) * (global_best_value / (1 + np.mean(personal_best_value)))  # Changed line\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=int(5 + adaptive_factor * 4), replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                velocity_clamp = 0.05 * (ub - lb) * (1 - adaptive_factor)  # Changed line\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp, velocity_clamp)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce an adaptive social coefficient based on individual success and dynamic velocity clamping to enhance solution diversity.", "configspace": "", "generation": 94, "fitness": 0.778930342284677, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.779 with standard deviation 0.024. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "b8c6f409-f452-4b90-a5dd-df5db67ad3d9", "metadata": {"aucs": [0.7462097382744848, 0.8036064037104445, 0.7869748848691016], "final_y": [0.12372140982847857, 0.12321454624696004, 0.11427927151021122]}, "mutation_prompt": null}
{"id": "e50fb2a8-303c-438b-a489-6466b2711905", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - (evaluations / self.budget) ** 2\n            inertia_weight = 0.5 + 0.1 * np.random.rand() * (1 + adaptive_factor)\n            cognitive_coeff = 2.0 * (1 - adaptive_factor) ** 2\n            social_coeff = 1.5 + 0.5 * (1 - np.cos(evaluations / self.budget * np.pi))  # Modified line\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=int(5 + adaptive_factor * 4), replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                velocity_clamp = 0.1 * (ub - lb)\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp, velocity_clamp)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance exploration by incorporating a dynamic social coefficient that gradually increases, promoting diversity in later stages.", "configspace": "", "generation": 95, "fitness": 0.8939122676676359, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.894 with standard deviation 0.041. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "b8c6f409-f452-4b90-a5dd-df5db67ad3d9", "metadata": {"aucs": [0.8364193382492373, 0.9162670834685704, 0.9290503812851001], "final_y": [0.13186366388772075, 0.11214643437189886, 0.11031932489693064]}, "mutation_prompt": null}
{"id": "b2c6606c-e4a1-4a5b-b877-42e67383f761", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - (evaluations / self.budget) ** 2\n            inertia_weight = 0.4 + 0.2 * np.random.rand() * (1 + adaptive_factor) # Modified line\n            cognitive_coeff = 2.0 * (1 - adaptive_factor) ** 2 \n            social_coeff = 1.3 + 0.7 * np.sin(evaluations / self.budget * np.pi) # Modified line\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=int(5 + adaptive_factor * 4), replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                velocity_clamp = 0.1 * (ub - lb)\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp, velocity_clamp)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance convergence by introducing a dynamic social coefficient influenced by a sinusoidal pattern and adjusting inertia weights based on evaluations.", "configspace": "", "generation": 96, "fitness": 0.8901585248322617, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.890 with standard deviation 0.045. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "b8c6f409-f452-4b90-a5dd-df5db67ad3d9", "metadata": {"aucs": [0.8271949788317039, 0.9182981318632222, 0.9249824638018589], "final_y": [0.1395607416525403, 0.11170988828349726, 0.11002842837157534]}, "mutation_prompt": null}
{"id": "105a4e16-6067-4dc1-a716-6aa33c2aa29c", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - (evaluations / self.budget) ** 2\n            inertia_weight = 0.5 + 0.1 * np.random.rand() * (1 + adaptive_factor)\n            cognitive_coeff = 2.0 * (1 - adaptive_factor) ** 2\n            social_coeff = 1.5 + 0.5 * np.cos(evaluations / self.budget * np.pi) * (global_best_value / (np.mean(personal_best_value) + 1e-6)) # Modified line\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=int(5 + adaptive_factor * 4), replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                velocity_clamp = 0.1 * (ub - lb)\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp, velocity_clamp)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a feedback-based adaptive social coefficient to improve convergence and exploration balance.", "configspace": "", "generation": 97, "fitness": 0.9076170181718313, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.908 with standard deviation 0.017. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "b8c6f409-f452-4b90-a5dd-df5db67ad3d9", "metadata": {"aucs": [0.8978084367999847, 0.8932862970814752, 0.9317563206340338], "final_y": [0.11720104555442057, 0.12005640809759888, 0.11000829347685537]}, "mutation_prompt": null}
{"id": "50a145bb-8c73-48b7-9b73-d4e2eccc2c5c", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - (evaluations / self.budget) ** 2\n            inertia_weight = 0.5 + 0.1 * np.random.rand() * (1 + adaptive_factor)\n            cognitive_coeff = 2.0 * (1 - adaptive_factor) ** 2\n            social_coeff = 1.5 + 0.5 * np.cos(evaluations / self.budget * np.pi) * adaptive_factor # Modified line\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors_count = int(5 + adaptive_factor * 6) # Modified line\n                neighbors = np.random.choice(self.population_size, size=neighbors_count, replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                velocity_clamp = 0.1 * (ub - lb)\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp, velocity_clamp)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a dynamic social coefficient and adaptive neighbor selection to improve solution quality and convergence.", "configspace": "", "generation": 98, "fitness": 0.9183136184778732, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.918 with standard deviation 0.007. And the mean value of best solutions found was 0.111 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "b8c6f409-f452-4b90-a5dd-df5db67ad3d9", "metadata": {"aucs": [0.9095991588319114, 0.9255766257757005, 0.9197650708260072], "final_y": [0.10972114066915972, 0.11164554445866448, 0.11155334621934965]}, "mutation_prompt": null}
{"id": "d2b7a29c-c46b-437e-bf1b-5a6569bf62ab", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - (evaluations / self.budget) ** 2\n            inertia_weight = 0.5 + 0.1 * np.random.rand() * (1 + adaptive_factor)\n            cognitive_coeff = 2.0 * (1 - adaptive_factor) ** 2\n            diversity = np.mean(np.linalg.norm(swarm - global_best, axis=1))\n            social_coeff = 1.5 + 0.5 * np.sin((diversity / (ub-lb)).mean() * np.pi) # Modified line\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=int(5 + adaptive_factor * 4), replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                velocity_clamp = 0.1 * (ub - lb)\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp, velocity_clamp)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a dynamic, nonlinear social coefficient adaptation based on population diversity to improve exploration-exploitation balance.", "configspace": "", "generation": 99, "fitness": 0.8862990441800597, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.886 with standard deviation 0.041. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "b8c6f409-f452-4b90-a5dd-df5db67ad3d9", "metadata": {"aucs": [0.8282429330064826, 0.9081811126150267, 0.9224730869186697], "final_y": [0.13963283070096555, 0.11216075778478374, 0.10971444234656846]}, "mutation_prompt": null}
{"id": "63fb8a12-8736-46fb-9dfb-39d47d40cdb6", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 3 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - (evaluations / self.budget) ** 2\n            inertia_weight = 0.4 + 0.3 * np.random.rand() * (1 + adaptive_factor) # Modified line\n            cognitive_coeff = 2.0 * (1 - adaptive_factor) ** 2\n            social_coeff = 1.5 + 0.5 * np.cos(evaluations / self.budget * np.pi)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(self.population_size, size=int(6 + adaptive_factor * 4), replace=False) # Modified line\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))\n                velocity_clamp = 0.1 * (ub - lb)\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp, velocity_clamp)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Utilize adaptive inertia and dynamic neighbor selection to improve swarm diversity and exploration capabilities.", "configspace": "", "generation": 100, "fitness": 0.9184552846708223, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.918 with standard deviation 0.007. And the mean value of best solutions found was 0.111 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "b8c6f409-f452-4b90-a5dd-df5db67ad3d9", "metadata": {"aucs": [0.9092800594090815, 0.9241310619191843, 0.921954732684201], "final_y": [0.11000486150815458, 0.11162974153621208, 0.11024972201280636]}, "mutation_prompt": null}
