{"id": "d4fc568c-ce04-4694-9b3a-d00686ec6bc7", "solution": "import numpy as np\n\nclass HybridPSOSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.temperature = 100.0\n        self.cooling_rate = 0.99\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            V = self.w * V + \\\n                self.c1 * r1 * (personal_best - X) + \\\n                self.c2 * r2 * (global_best - X)\n            X = np.clip(X + V, lb, ub)\n\n            # Simulated Annealing step\n            for i in range(self.population_size):\n                candidate = X[i] + np.random.uniform(-1, 1, self.dim) * (ub - lb) * self.temperature\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            self.temperature *= self.cooling_rate\n\n        return global_best", "name": "HybridPSOSimulatedAnnealing", "description": "A hybrid Particle Swarm Optimization and Simulated Annealing algorithm that adapts search strategies to balance exploration and exploitation for black-box optimization problems.", "configspace": "", "generation": 0, "fitness": 0.7494561386728357, "feedback": "The algorithm HybridPSOSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.749 with standard deviation 0.042. And the mean value of best solutions found was 0.178 (0. is the best) with standard deviation 0.018.", "error": "", "parent_id": null, "metadata": {"aucs": [0.6927044170144536, 0.7945901820562783, 0.7610738169477751], "final_y": [0.20241640769719016, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "f7b312a1-454b-439d-b8a8-a50fa2be124f", "solution": "import numpy as np\n\nclass HybridPSOSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.temperature = 100.0\n        self.cooling_rate = 0.99\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            self.w = 0.5 - 0.4 * (evaluations / self.budget)  # Adaptive inertia weight\n            V = self.w * V + \\\n                self.c1 * r1 * (personal_best - X) + \\\n                self.c2 * r2 * (global_best - X)\n            X = np.clip(X + V, lb, ub)\n\n            # Simulated Annealing step\n            for i in range(self.population_size):\n                candidate = X[i] + np.random.uniform(-1, 1, self.dim) * (ub - lb) * self.temperature\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            self.temperature *= self.cooling_rate\n\n        return global_best", "name": "HybridPSOSimulatedAnnealing", "description": "Introduced adaptive inertia weight updating in the PSO component to enhance convergence speed.", "configspace": "", "generation": 1, "fitness": 0.7486453595487056, "feedback": "The algorithm HybridPSOSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.749 with standard deviation 0.043. And the mean value of best solutions found was 0.178 (0. is the best) with standard deviation 0.018.", "error": "", "parent_id": "d4fc568c-ce04-4694-9b3a-d00686ec6bc7", "metadata": {"aucs": [0.6902720796420636, 0.7945901820562783, 0.7610738169477751], "final_y": [0.20241640769719016, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "5a129359-b787-44d9-b208-ec1c8a2a2519", "solution": "import numpy as np\n\nclass HybridPSOSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.temperature = 100.0\n        self.cooling_rate = 0.99\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            self.w = 0.9 - (0.5 * evaluations / self.budget)  # Adaptive inertia weight\n            V = self.w * V + \\\n                self.c1 * r1 * (personal_best - X) + \\\n                self.c2 * r2 * (global_best - X)\n            X = np.clip(X + V, lb, ub)\n\n            # Simulated Annealing step\n            for i in range(self.population_size):\n                candidate = X[i] + np.random.uniform(-1, 1, self.dim) * (ub - lb) * self.temperature\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            self.temperature *= self.cooling_rate\n\n        return global_best", "name": "HybridPSOSimulatedAnnealing", "description": "Introducing adaptive inertia weight to improve convergence speed and solution quality in HybridPSO-Simulated Annealing.", "configspace": "", "generation": 1, "fitness": 0.7483695650931615, "feedback": "The algorithm HybridPSOSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.748 with standard deviation 0.044. And the mean value of best solutions found was 0.178 (0. is the best) with standard deviation 0.018.", "error": "", "parent_id": "d4fc568c-ce04-4694-9b3a-d00686ec6bc7", "metadata": {"aucs": [0.6894446962754314, 0.7945901820562783, 0.7610738169477751], "final_y": [0.20241640769719016, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "80c77bcc-e0cc-4334-9a82-38b04f6c2fd9", "solution": "import numpy as np\n\nclass HybridPSOSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.temperature = 100.0\n        self.cooling_rate = 0.99\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            self.w = 0.9 - (0.5 * (evaluations / self.budget))  # Changed line\n            V = self.w * V + \\\n                self.c1 * r1 * (personal_best - X) + \\\n                self.c2 * r2 * (global_best - X)\n            X = np.clip(X + V, lb, ub)\n\n            # Simulated Annealing step\n            for i in range(self.population_size):\n                candidate = X[i] + np.random.uniform(-1, 1, self.dim) * (ub - lb) * self.temperature\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            self.temperature *= self.cooling_rate\n\n        return global_best", "name": "HybridPSOSimulatedAnnealing", "description": "An improved Hybrid Particle Swarm Optimization and Simulated Annealing algorithm with an adaptive inertia weight for enhanced exploration-exploitation balance.", "configspace": "", "generation": 1, "fitness": 0.7490722388591967, "feedback": "The algorithm HybridPSOSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.749 with standard deviation 0.043. And the mean value of best solutions found was 0.178 (0. is the best) with standard deviation 0.018.", "error": "", "parent_id": "d4fc568c-ce04-4694-9b3a-d00686ec6bc7", "metadata": {"aucs": [0.6915527175735363, 0.7945901820562783, 0.7610738169477751], "final_y": [0.20241640769719016, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "4c8bd5c0-d789-4a9a-b421-4e3ad2dadb5f", "solution": "import numpy as np\n\nclass HybridPSOSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.temperature = 100.0\n        self.cooling_rate = 0.99\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            V = self.w * V + \\\n                self.c1 * r1 * (personal_best - X) + \\\n                self.c2 * r2 * (global_best - X)\n            X = np.clip(X + V, lb, ub)\n\n            # Simulated Annealing step\n            for i in range(self.population_size):\n                candidate = X[i] + np.random.uniform(-1, 1, self.dim) * (ub - lb) * self.temperature\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            self.temperature *= self.cooling_rate\n            self.population_size = max(10, int(self.population_size * 0.99))  # Dynamic population adjustment\n\n        return global_best", "name": "HybridPSOSimulatedAnnealing", "description": "Incorporates a dynamic population size adjustment based on convergence rate to enhance exploration and exploitation balance.", "configspace": "", "generation": 1, "fitness": 0.7493719040218689, "feedback": "The algorithm HybridPSOSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.749 with standard deviation 0.043. And the mean value of best solutions found was 0.178 (0. is the best) with standard deviation 0.018.", "error": "", "parent_id": "d4fc568c-ce04-4694-9b3a-d00686ec6bc7", "metadata": {"aucs": [0.6924517130615531, 0.7945901820562783, 0.7610738169477751], "final_y": [0.20241640769719016, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "6268f47b-6bd0-4de9-96b4-80a9ff7a017c", "solution": "import numpy as np\n\nclass HybridPSOSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.temperature = 100.0\n        self.cooling_rate = 0.95  # Modified to adjust cooling more dynamically\n        self.w = 0.9  # Modified to enhance exploration capabilities\n        self.c1 = 1.5\n        self.c2 = 1.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            V = self.w * V + \\\n                self.c1 * r1 * (personal_best - X) + \\\n                self.c2 * r2 * (global_best - X)\n            X = np.clip(X + V, lb, ub)\n\n            # Simulated Annealing step\n            for i in range(self.population_size):\n                candidate = X[i] + np.random.uniform(-0.5, 0.5, self.dim) * (ub - lb) * self.temperature  # Adjusted to fine-tune search\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            self.temperature *= self.cooling_rate\n\n        return global_best", "name": "HybridPSOSimulatedAnnealing", "description": "An enhanced hybrid PSO and Simulated Annealing algorithm that includes adaptive velocity adjustment and dynamic temperature scaling to improve convergence in black-box optimization problems.", "configspace": "", "generation": 1, "fitness": 0.7505814993920273, "feedback": "The algorithm HybridPSOSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.751 with standard deviation 0.041. And the mean value of best solutions found was 0.175 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "d4fc568c-ce04-4694-9b3a-d00686ec6bc7", "metadata": {"aucs": [0.6960804991720287, 0.7945901820562783, 0.7610738169477751], "final_y": [0.19163124970005874, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "a1098fc1-b6df-4316-b192-04bc5cea3e3f", "solution": "import numpy as np\n\nclass HybridPSOSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.temperature = 100.0\n        self.cooling_rate = 0.92  # Line 12 modified for dynamic cooling adjustments\n        self.w = 0.85  # Line 13 modified to further improve exploration and exploitation balance\n        self.c1 = 1.5\n        self.c2 = 1.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            V = self.w * V + \\\n                self.c1 * r1 * (personal_best - X) + \\\n                self.c2 * r2 * (global_best - X)\n            X = np.clip(X + V, lb, ub)\n\n            # Simulated Annealing step\n            for i in range(self.population_size):\n                candidate = X[i] + np.random.uniform(-0.5, 0.5, self.dim) * (ub - lb) * self.temperature\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            self.temperature *= self.cooling_rate\n\n        return global_best", "name": "HybridPSOSimulatedAnnealing", "description": "Improved velocity update strategy and dynamic cooling rate modification to enhance convergence speed and solution quality in hybrid PSO-Simulated Annealing for black-box optimization.", "configspace": "", "generation": 2, "fitness": 0.7494229155118264, "feedback": "The algorithm HybridPSOSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.749 with standard deviation 0.042. And the mean value of best solutions found was 0.177 (0. is the best) with standard deviation 0.016.", "error": "", "parent_id": "6268f47b-6bd0-4de9-96b4-80a9ff7a017c", "metadata": {"aucs": [0.6926047475314256, 0.7945901820562783, 0.7610738169477751], "final_y": [0.19799421186700805, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "fa951018-8701-45b1-98e9-fce97d65962a", "solution": "import numpy as np\n\nclass HybridPSOSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.temperature = 100.0\n        self.cooling_rate = 0.9  # Modified for more gradual cooling\n        self.w = 0.8  # Reduced to improve balance between exploration and exploitation\n        self.c1 = 1.7  # Increased to enhance personal best influence\n        self.c2 = 1.3  # Decreased to reduce global best influence\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            V = self.w * V + \\\n                self.c1 * r1 * (personal_best - X) + \\\n                self.c2 * r2 * (global_best - X)\n            X = np.clip(X + V, lb, ub)\n\n            # Simulated Annealing step\n            for i in range(self.population_size):\n                candidate = X[i] + np.random.uniform(-0.5, 0.5, self.dim) * (ub - lb) * self.temperature\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            self.temperature *= self.cooling_rate\n\n        return global_best", "name": "HybridPSOSimulatedAnnealing", "description": "An enhanced hybrid PSO and Simulated Annealing algorithm with improved velocity update and adaptive cooling for better convergence in black-box optimization problems.", "configspace": "", "generation": 2, "fitness": 0.768777970350027, "feedback": "The algorithm HybridPSOSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.769 with standard deviation 0.019. And the mean value of best solutions found was 0.168 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "6268f47b-6bd0-4de9-96b4-80a9ff7a017c", "metadata": {"aucs": [0.7506699120460281, 0.7945901820562783, 0.7610738169477751], "final_y": [0.1720150251016136, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "9fe988f0-1564-46b8-89e6-3881c81473b1", "solution": "import numpy as np\n\nclass HybridPSOSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.temperature = 100.0\n        self.cooling_rate = 0.95  # Modified to adjust cooling more dynamically\n        self.w = 0.9  # Modified to enhance exploration capabilities\n        self.c1 = 1.5\n        self.c2 = 1.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            self.w *= 0.99  # Gradually decrease inertia weight to balance exploration and exploitation\n            V = self.w * V + \\\n                self.c1 * r1 * (personal_best - X) + \\\n                self.c2 * r2 * (global_best - X)\n            X = np.clip(X + V, lb, ub)\n\n            # Simulated Annealing step\n            for i in range(self.population_size):\n                candidate = X[i] + np.random.uniform(-0.5, 0.5, self.dim) * (ub - lb) * self.temperature  # Adjusted to fine-tune search\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            self.temperature *= self.cooling_rate\n\n        return global_best", "name": "HybridPSOSimulatedAnnealing", "description": "An enhanced hybrid PSO and Simulated Annealing algorithm with improved convergence via adjusted inertia weight decay.", "configspace": "", "generation": 2, "fitness": 0.7525189315515576, "feedback": "The algorithm HybridPSOSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.753 with standard deviation 0.038. And the mean value of best solutions found was 0.176 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "6268f47b-6bd0-4de9-96b4-80a9ff7a017c", "metadata": {"aucs": [0.7018927956506195, 0.7945901820562783, 0.7610738169477751], "final_y": [0.1937006192679115, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "9a0753d0-e51a-410e-8847-e65e4fd97053", "solution": "import numpy as np\n\nclass HybridPSOSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.temperature = 100.0\n        self.cooling_rate = 0.95  # Modified to adjust cooling more dynamically\n        self.w = 0.9  # Modified to enhance exploration capabilities\n        self.c1 = 1.5\n        self.c2 = 1.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            V = self.w * V + \\\n                self.c1 * r1 * (personal_best - X) + \\\n                self.c2 * r2 * (global_best - X) + np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))  # Added stochastic component\n            X = np.clip(X + V, lb, ub)\n\n            # Simulated Annealing step\n            for i in range(self.population_size):\n                candidate = X[i] + np.random.uniform(-0.5, 0.5, self.dim) * (ub - lb) * self.temperature  # Adjusted to fine-tune search\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            self.temperature *= self.cooling_rate\n\n        return global_best", "name": "HybridPSOSimulatedAnnealing", "description": "Enhanced Hybrid PSO-Simulated Annealing (HPSOA) algorithm with improved velocity update formula for better convergence in black-box optimization.", "configspace": "", "generation": 2, "fitness": 0.7470498345592814, "feedback": "The algorithm HybridPSOSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.747 with standard deviation 0.046. And the mean value of best solutions found was 0.178 (0. is the best) with standard deviation 0.018.", "error": "", "parent_id": "6268f47b-6bd0-4de9-96b4-80a9ff7a017c", "metadata": {"aucs": [0.6854855046737907, 0.7945901820562783, 0.7610738169477751], "final_y": [0.2023713446889568, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "09aa79b7-7eb4-4c72-a35a-224ebfc7e0a1", "solution": "import numpy as np\n\nclass HybridPSOSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.temperature = 100.0\n        self.cooling_rate = 0.92  # Slightly altered to improve cooling dynamics\n        self.w = 0.9\n        self.c1 = 1.5\n        self.c2 = 1.5\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            V = self.w * V + \\\n                self.c1 * r1 * (personal_best - X) + \\\n                self.c2 * r2 * (global_best - X)\n            X = np.clip(X + V, lb, ub)\n\n            # Simulated Annealing step\n            for i in range(self.population_size):\n                candidate = X[i] + np.random.uniform(-0.5, 0.5, self.dim) * (ub - lb) * self.temperature\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            self.temperature *= self.cooling_rate\n\n        return global_best", "name": "HybridPSOSimulatedAnnealing", "description": "A refined hybrid PSO and Simulated Annealing algorithm with enhanced cooling dynamics to improve convergence in black-box optimization.", "configspace": "", "generation": 2, "fitness": 0.74869868552965, "feedback": "The algorithm HybridPSOSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.749 with standard deviation 0.043. And the mean value of best solutions found was 0.176 (0. is the best) with standard deviation 0.015.", "error": "", "parent_id": "6268f47b-6bd0-4de9-96b4-80a9ff7a017c", "metadata": {"aucs": [0.690432057584897, 0.7945901820562783, 0.7610738169477751], "final_y": [0.19640902390928827, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "84e74b38-7e67-4ea8-8a2c-e28d02ca77d6", "solution": "import numpy as np\n\nclass HybridPSOSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.temperature = 100.0\n        self.cooling_rate = 0.9  # Modified for more gradual cooling\n        self.w = 0.8  # Reduced to improve balance between exploration and exploitation\n        self.c1 = 1.7  # Increased to enhance personal best influence\n        self.c2 = 1.3  # Decreased to reduce global best influence\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            V = self.w * V + \\\n                self.c1 * r1 * (personal_best - X) + \\\n                self.c2 * r2 * (global_best - X)\n            X = np.clip(X + V, lb, ub)\n\n            # Simulated Annealing step\n            for i in range(self.population_size):\n                candidate = X[i] + np.random.uniform(-1.0, 1.0, self.dim) * (ub - lb) * self.temperature  # Changed from -0.5, 0.5 to -1.0, 1.0\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            self.temperature *= self.cooling_rate\n\n        return global_best", "name": "HybridPSOSimulatedAnnealing", "description": "An improved hybrid PSO and Simulated Annealing algorithm with further enhanced exploration through increased candidate neighborhood search range for better convergence in black-box optimization problems.", "configspace": "", "generation": 3, "fitness": 0.7488888379792096, "feedback": "The algorithm HybridPSOSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.749 with standard deviation 0.043. And the mean value of best solutions found was 0.178 (0. is the best) with standard deviation 0.018.", "error": "", "parent_id": "fa951018-8701-45b1-98e9-fce97d65962a", "metadata": {"aucs": [0.691002514933575, 0.7945901820562783, 0.7610738169477751], "final_y": [0.20234098777713327, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "8b69d598-fdf3-46b0-8405-fbd2e6e447c4", "solution": "import numpy as np\n\nclass HybridPSOSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.temperature = 100.0\n        self.cooling_rate = 0.95  # Slightly adjusted for more gradual cooling\n        self.w = 0.9  # Adaptive inertia for better exploration\n        self.c1 = 1.8  # Adjusted to enhance personal best influence\n        self.c2 = 1.2  # Adjusted to balance global best influence\n        self.min_inertia = 0.4  # Minimum inertia weight\n        self.max_inertia = 0.9  # Maximum inertia weight\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight\n            self.w = self.max_inertia - ((self.max_inertia - self.min_inertia) * (evaluations / self.budget))\n\n            r1, r2 = np.random.rand(2)\n            V = self.w * V + \\\n                self.c1 * r1 * (personal_best - X) + \\\n                self.c2 * r2 * (global_best - X)\n            X = np.clip(X + V, lb, ub)\n\n            # Simulated Annealing step with mutation\n            for i in range(self.population_size):\n                candidate = X[i] + np.random.normal(0, 0.1, self.dim) * (ub - lb) * self.temperature\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            self.temperature *= self.cooling_rate\n\n        return global_best", "name": "HybridPSOSimulatedAnnealing", "description": "An advanced hybrid PSO-Simulated Annealing with adaptive inertia and mutation for improved search efficiency.", "configspace": "", "generation": 3, "fitness": 0.7496529776744224, "feedback": "The algorithm HybridPSOSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.750 with standard deviation 0.042. And the mean value of best solutions found was 0.178 (0. is the best) with standard deviation 0.017.", "error": "", "parent_id": "fa951018-8701-45b1-98e9-fce97d65962a", "metadata": {"aucs": [0.6932949340192137, 0.7945901820562783, 0.7610738169477751], "final_y": [0.20010563841089013, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "db0aab6a-b040-4420-8d54-9f54bd8dd31e", "solution": "import numpy as np\n\nclass HybridPSOSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.temperature = 100.0\n        self.cooling_rate = 0.9  # Modified for more gradual cooling\n        self.w = 0.8  # Reduced to improve balance between exploration and exploitation\n        self.c1 = 1.7  # Increased to enhance personal best influence\n        self.c2 = 1.3  # Decreased to reduce global best influence\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            V = self.w * V + \\\n                self.c1 * r1 * (personal_best - X) + \\\n                self.c2 * r2 * (global_best - X)\n            X = np.clip(X + V, lb, ub)\n\n            # Simulated Annealing step\n            for i in range(self.population_size):\n                candidate = X[i] + np.random.uniform(-0.5, 0.5, self.dim) * (ub - lb) * self.temperature\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            self.temperature *= self.cooling_rate\n            self.population_size = max(1, int(self.population_size * self.cooling_rate))  # Line modified\n\n        return global_best", "name": "HybridPSOSimulatedAnnealing", "description": "Enhanced Hybrid PSO and Simulated Annealing with dynamic population size adjustment for improved convergence.", "configspace": "", "generation": 3, "fitness": 0.7492111302669714, "feedback": "The algorithm HybridPSOSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.749 with standard deviation 0.043. And the mean value of best solutions found was 0.178 (0. is the best) with standard deviation 0.017.", "error": "", "parent_id": "fa951018-8701-45b1-98e9-fce97d65962a", "metadata": {"aucs": [0.6919693917968609, 0.7945901820562783, 0.7610738169477751], "final_y": [0.20157685830216943, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "0a794e30-411a-4710-92ad-0f2d42757f87", "solution": "import numpy as np\n\nclass HybridPSOSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.temperature = 100.0\n        self.cooling_rate = 0.9  # Modified for more gradual cooling\n        self.w = 0.8  # Reduced to improve balance between exploration and exploitation\n        self.c1 = 1.7  # Increased to enhance personal best influence\n        self.c2 = 1.3  # Decreased to reduce global best influence\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            self.w = 0.9 - (0.5 * (evaluations / self.budget))  # Dynamic inertia weight adjustment\n            V = self.w * V + \\\n                self.c1 * r1 * (personal_best - X) + \\\n                self.c2 * r2 * (global_best - X)\n            X = np.clip(X + V, lb, ub)\n\n            # Simulated Annealing step\n            for i in range(self.population_size):\n                candidate = X[i] + np.random.uniform(-0.5, 0.5, self.dim) * (ub - lb) * self.temperature\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            self.temperature *= self.cooling_rate\n\n        return global_best", "name": "HybridPSOSimulatedAnnealing", "description": "Enhanced Hybrid PSO and Simulated Annealing with dynamic inertia weight adjustment for improved convergence in black-box optimization.", "configspace": "", "generation": 3, "fitness": 0.7557378050199209, "feedback": "The algorithm HybridPSOSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.756 with standard deviation 0.034. And the mean value of best solutions found was 0.175 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "fa951018-8701-45b1-98e9-fce97d65962a", "metadata": {"aucs": [0.7115494160557095, 0.7945901820562783, 0.7610738169477751], "final_y": [0.19264262467942783, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "fb0a1285-ee07-4e00-9f2a-96241cd27ac5", "solution": "import numpy as np\n\nclass HybridPSOSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 35  # Reduced to speed up convergence\n        self.temperature = 100.0\n        self.cooling_rate = 0.9  # Modified for more gradual cooling\n        self.w = 0.8  # Reduced to improve balance between exploration and exploitation\n        self.c1 = 1.7  # Increased to enhance personal best influence\n        self.c2 = 1.3  # Decreased to reduce global best influence\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            V = self.w * V + \\\n                self.c1 * r1 * (personal_best - X) + \\\n                self.c2 * r2 * (global_best - X)\n            X = np.clip(X + V, lb, ub)\n\n            # Simulated Annealing step\n            for i in range(self.population_size):\n                candidate = X[i] + np.random.uniform(-0.5, 0.5, self.dim) * (ub - lb) * self.temperature\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            self.temperature *= self.cooling_rate\n\n        return global_best", "name": "HybridPSOSimulatedAnnealing", "description": "A refined hybrid PSO and Simulated Annealing algorithm with a reduced population size for faster convergence while maintaining solution quality.", "configspace": "", "generation": 3, "fitness": 0.7480578850612032, "feedback": "The algorithm HybridPSOSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.748 with standard deviation 0.044. And the mean value of best solutions found was 0.176 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "fa951018-8701-45b1-98e9-fce97d65962a", "metadata": {"aucs": [0.688509656179556, 0.7945901820562783, 0.7610738169477751], "final_y": [0.1939424418001905, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "5dea69d0-5991-4554-ac29-e2321edabcc8", "solution": "import numpy as np\n\nclass HybridPSOSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.temperature = 100.0\n        self.cooling_rate = 0.9\n        self.w = 0.8\n        self.c1 = 1.7\n        self.c2 = 1.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            V = self.w * V + \\\n                self.c1 * r1 * (personal_best - X) + \\\n                self.c2 * r2 * (global_best - X)\n            X = np.clip(X + V, lb, ub)\n\n            # Simulated Annealing step\n            for i in range(self.population_size):\n                candidate = X[i] + np.random.uniform(-0.5, 0.5, self.dim) * (ub - lb) * self.temperature\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            self.temperature *= self.cooling_rate\n            self.population_size = max(10, int(self.population_size * 0.95))  # Dynamic population size\n\n        return global_best", "name": "HybridPSOSimulatedAnnealing", "description": "A refined hybrid PSO and Simulated Annealing algorithm with a dynamic population size for improved adaptation and convergence.", "configspace": "", "generation": 4, "fitness": 0.7566949817535414, "feedback": "The algorithm HybridPSOSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.757 with standard deviation 0.033. And the mean value of best solutions found was 0.167 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "fa951018-8701-45b1-98e9-fce97d65962a", "metadata": {"aucs": [0.7144209462565705, 0.7945901820562783, 0.7610738169477751], "final_y": [0.16667182227139266, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "1058799f-01a8-4314-b116-cb9247da923c", "solution": "import numpy as np\n\nclass HybridPSOSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.temperature = 100.0\n        self.cooling_rate = 0.9  # Modified for more gradual cooling\n        self.w = 0.8  # Reduced to improve balance between exploration and exploitation\n        self.c1 = 1.7  # Increased to enhance personal best influence\n        self.c2 = 1.3  # Decreased to reduce global best influence\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            # Line changed to adapt inertia weight dynamically\n            self.w = 0.4 + 0.5 * (self.budget - evaluations) / self.budget\n            V = self.w * V + \\\n                self.c1 * r1 * (personal_best - X) + \\\n                self.c2 * r2 * (global_best - X)\n            X = np.clip(X + V, lb, ub)\n\n            # Simulated Annealing step\n            for i in range(self.population_size):\n                candidate = X[i] + np.random.uniform(-0.5, 0.5, self.dim) * (ub - lb) * self.temperature\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            self.temperature *= self.cooling_rate\n\n        return global_best", "name": "HybridPSOSimulatedAnnealing", "description": "An enhanced hybrid PSO and Simulated Annealing algorithm with improved velocity update and adaptive cooling for better convergence in black-box optimization problems, now includes dynamic adaptation of inertia weight to balance exploration and exploitation.", "configspace": "", "generation": 4, "fitness": 0.7473013253309423, "feedback": "The algorithm HybridPSOSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.747 with standard deviation 0.045. And the mean value of best solutions found was 0.177 (0. is the best) with standard deviation 0.016.", "error": "", "parent_id": "fa951018-8701-45b1-98e9-fce97d65962a", "metadata": {"aucs": [0.6862399769887737, 0.7945901820562783, 0.7610738169477751], "final_y": [0.19888387252678374, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "4cb72ed7-6f91-432a-ae48-16d22bdeb4af", "solution": "import numpy as np\n\nclass HybridPSOSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.temperature = 100.0\n        self.cooling_rate = 0.9\n        self.w = 0.8\n        self.c1 = 1.7\n        self.c2 = 1.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            # Adaptive inertia weight\n            self.w = 0.9 - ((0.9 - 0.4) * (evaluations / self.budget))\n            V = self.w * V + \\\n                self.c1 * r1 * (personal_best - X) + \\\n                self.c2 * r2 * (global_best - X)\n            X = np.clip(X + V, lb, ub)\n\n            # Simulated Annealing step\n            for i in range(self.population_size):\n                candidate = X[i] + np.random.uniform(-0.5, 0.5, self.dim) * (ub - lb) * self.temperature\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            self.temperature *= self.cooling_rate\n\n        return global_best", "name": "HybridPSOSimulatedAnnealing", "description": "A refined hybrid PSO with adaptive inertia weight for enhanced exploration and exploitation balance.", "configspace": "", "generation": 4, "fitness": 0.7537502211340072, "feedback": "The algorithm HybridPSOSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.754 with standard deviation 0.037. And the mean value of best solutions found was 0.169 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "fa951018-8701-45b1-98e9-fce97d65962a", "metadata": {"aucs": [0.705586664397968, 0.7945901820562783, 0.7610738169477751], "final_y": [0.17263490123127667, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "1c2112fc-01ca-4a5e-b8ef-f135c5401cac", "solution": "import numpy as np\n\nclass HybridPSOSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.temperature = 100.0\n        self.cooling_rate = 0.9\n        self.w = 0.8\n        self.c1 = 1.7\n        self.c2 = 1.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            self.w = 0.4 + 0.5 * (self.budget - evaluations) / self.budget  # Adaptive inertia weight\n            V = self.w * V + \\\n                self.c1 * r1 * (personal_best - X) + \\\n                self.c2 * r2 * (global_best - X)\n            X = np.clip(X + V, lb, ub)\n\n            # Simulated Annealing step\n            for i in range(self.population_size):\n                candidate = X[i] + np.random.uniform(-0.5, 0.5, self.dim) * (ub - lb) * self.temperature\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            self.temperature *= self.cooling_rate\n            if self.population_size > 20:  # Dynamic population size adjustment\n                self.population_size = max(20, self.population_size - 1)\n\n        return global_best", "name": "HybridPSOSimulatedAnnealing", "description": "A refined hybrid PSO and Simulated Annealing algorithm with adaptive inertia weights and dynamic population size adjustment to enhance exploration and exploitation balance.", "configspace": "", "generation": 4, "fitness": 0.7559317575521266, "feedback": "The algorithm HybridPSOSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.756 with standard deviation 0.034. And the mean value of best solutions found was 0.167 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "fa951018-8701-45b1-98e9-fce97d65962a", "metadata": {"aucs": [0.712131273652326, 0.7945901820562783, 0.7610738169477751], "final_y": [0.1688272903743444, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "b8dc9fd4-da0b-4ead-b5a7-bf26a3b345b0", "solution": "import numpy as np\n\nclass HybridPSOSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 40\n        self.temperature = 100.0\n        self.cooling_rate = 0.95  # Modified for more gradual cooling\n        self.w = 0.6  # Adjusted to enhance balance between exploration and exploitation\n        self.c1 = 1.7\n        self.c2 = 1.3\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.initial_population_size\n        X = np.random.uniform(lb, ub, (population_size, self.dim))\n        V = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            V = self.w * V + \\\n                self.c1 * r1 * (personal_best - X) + \\\n                self.c2 * r2 * (global_best - X)\n            X = np.clip(X + V, lb, ub)\n\n            # Simulated Annealing step\n            for i in range(population_size):\n                candidate = X[i] + np.random.uniform(-0.5, 0.5, self.dim) * (ub - lb) * self.temperature\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            self.temperature *= self.cooling_rate\n            population_size = int(self.initial_population_size * (1 - evaluations / self.budget)) + 1  # Dynamic population size\n\n        return global_best", "name": "HybridPSOSimulatedAnnealing", "description": "A refined hybrid PSO and Simulated Annealing algorithm with dynamic population size and improved adaptive velocity for enhanced convergence efficiency in black-box optimization problems.", "configspace": "", "generation": 4, "fitness": 0.7565838336740413, "feedback": "The algorithm HybridPSOSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.757 with standard deviation 0.033. And the mean value of best solutions found was 0.167 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "fa951018-8701-45b1-98e9-fce97d65962a", "metadata": {"aucs": [0.7140875020180699, 0.7945901820562783, 0.7610738169477751], "final_y": [0.16652280241535433, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "70e25047-6b33-4ef1-9ca5-e795a8dbc1b0", "solution": "import numpy as np\n\nclass HybridPSOSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.initial_temperature = 100.0\n        self.final_temperature = 1.0  # New final temperature for dynamic cooling\n        self.w_max = 0.9  # New maximum inertia weight\n        self.w_min = 0.4  # New minimum inertia weight\n        self.c1 = 2.0  # Increased to enhance personal best influence further\n        self.c2 = 1.0  # Decreased to reduce global best influence further\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            iteration = evaluations / self.budget\n            self.temperature = self.final_temperature + (self.initial_temperature - self.final_temperature) * (1 - iteration)\n            self.w = self.w_max - (self.w_max - self.w_min) * iteration\n            r1, r2 = np.random.rand(2)\n            V = self.w * V + \\\n                self.c1 * r1 * (personal_best - X) + \\\n                self.c2 * r2 * (global_best - X)\n            X = np.clip(X + V, lb, ub)\n\n            for i in range(self.population_size):\n                candidate = X[i] + np.random.uniform(-0.5, 0.5, self.dim) * (ub - lb) * self.temperature\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best", "name": "HybridPSOSimulatedAnnealing", "description": "A refined hybrid PSO and Simulated Annealing algorithm with adaptive inertia and dynamic cooling based on iteration progress to improve convergence efficiency.", "configspace": "", "generation": 5, "fitness": 0.7490039500685443, "feedback": "The algorithm HybridPSOSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.749 with standard deviation 0.043. And the mean value of best solutions found was 0.176 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "fa951018-8701-45b1-98e9-fce97d65962a", "metadata": {"aucs": [0.6913478512015793, 0.7945901820562783, 0.7610738169477751], "final_y": [0.19393528537636318, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "adfa111e-5418-42d6-9632-7075a1e1f074", "solution": "import numpy as np\n\nclass HybridPSOSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.temperature = 100.0\n        self.cooling_rate = 0.9  # Modified for more gradual cooling\n        self.w = 0.9  # Adjusted for better exploration\n        self.c1 = 1.7  # Increased to enhance personal best influence\n        self.c2 = 1.3  # Decreased to reduce global best influence\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            self.w = 0.9 - 0.5 * (evaluations / self.budget)  # Line 1: Variable inertia weight\n            V = self.w * V + \\\n                self.c1 * r1 * (personal_best - X) + \\\n                self.c2 * r2 * (global_best - X)\n            X = np.clip(X + V, lb, ub)\n\n            # Simulated Annealing step\n            for i in range(self.population_size):\n                candidate = X[i] + np.random.uniform(-0.5, 0.5, self.dim) * (ub - lb) * self.temperature\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            self.temperature *= 0.7 + 0.2 * np.sin(0.5 * evaluations)  # Line 2: Chaotic cooling schedule\n\n        return global_best", "name": "HybridPSOSimulatedAnnealing", "description": "An enhanced hybrid PSO and Simulated Annealing algorithm with variable inertia weight and chaotic cooling for improved exploration and convergence in black-box optimization problems.", "configspace": "", "generation": 5, "fitness": 0.7777370573316276, "feedback": "The algorithm HybridPSOSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.778 with standard deviation 0.014. And the mean value of best solutions found was 0.152 (0. is the best) with standard deviation 0.021.", "error": "", "parent_id": "fa951018-8701-45b1-98e9-fce97d65962a", "metadata": {"aucs": [0.7775471729908292, 0.7945901820562783, 0.7610738169477751], "final_y": [0.12370727622979327, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "824f6e1b-99a5-408b-a98c-71e510bdd74e", "solution": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.95  # More gradual cooling\n        self.initial_w = 0.9  # Start with higher inertia weight\n        self.max_w = 0.9\n        self.min_w = 0.4\n        self.c1 = 2.0  # Enhanced to increase personal best attraction\n        self.c2 = 1.0  # Reduced to decrease global best attraction\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        temperature = self.initial_temperature\n        w = self.initial_w\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            progress_ratio = evaluations / self.budget\n            w = self.max_w - progress_ratio * (self.max_w - self.min_w)\n            \n            V = w * V + self.c1 * r1 * (personal_best - X) + self.c2 * r2 * (global_best - X)\n            X = np.clip(X + V, lb, ub)\n\n            # Adaptive mutation strength\n            mutation_strength = 0.5 * (1 - progress_ratio)\n\n            for i in range(self.population_size):\n                candidate = X[i] + np.random.uniform(-mutation_strength, mutation_strength, self.dim) * (ub - lb)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            temperature *= self.cooling_rate\n\n        return global_best", "name": "EnhancedHybridPSOSA", "description": "Introduced adaptive mutation strength and dynamic particle inertia to enhance exploration and exploitation balance in the hybrid PSO-Simulated Annealing algorithm.", "configspace": "", "generation": 5, "fitness": 0.8091634610166958, "feedback": "The algorithm EnhancedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.809 with standard deviation 0.012. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "fa951018-8701-45b1-98e9-fce97d65962a", "metadata": {"aucs": [0.8197042038339715, 0.8150345841989051, 0.7927515950172107], "final_y": [0.12194027904672544, 0.12369875808797348, 0.1330936646932368]}, "mutation_prompt": null}
{"id": "50152083-c95e-4ee6-8186-7f5b10c6c5f4", "solution": "import numpy as np\n\nclass HybridPSOSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.temperature = 100.0\n        self.cooling_rate = 0.95  # Adjusted for more gradual cooling\n        self.w = 0.9  # Adaptive inertia weight for better exploration\n        self.c1 = 1.5  # Adjusted to enhance personal best influence\n        self.c2 = 1.5  # Adjusted for balanced global best influence\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            self.w = 0.4 + 0.5 * (1 - evaluations / self.budget)  # Adaptive inertia weight\n            V = self.w * V + \\\n                self.c1 * r1 * (personal_best - X) + \\\n                self.c2 * r2 * (global_best - X)\n            X = np.clip(X + V, lb, ub)\n\n            # Simulated Annealing step with neighborhood-based global best update\n            for i in range(self.population_size):\n                candidate = X[i] + np.random.uniform(-0.5, 0.5, self.dim) * (ub - lb) * (1 - evaluations / self.budget)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    # Introducing neighborhood-based global best\n                    if candidate_value < global_best_value and np.linalg.norm(candidate - global_best) < 0.1 * (ub - lb).mean():\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            self.temperature *= self.cooling_rate\n\n        return global_best", "name": "HybridPSOSimulatedAnnealing", "description": "A novel hybrid PSO and Simulated Annealing algorithm using adaptive inertia weight and neighborhood-based global best selection to enhance exploration and exploitation balance in black-box optimization.", "configspace": "", "generation": 5, "fitness": 0.7735799897707789, "feedback": "The algorithm HybridPSOSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.774 with standard deviation 0.015. And the mean value of best solutions found was 0.160 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "fa951018-8701-45b1-98e9-fce97d65962a", "metadata": {"aucs": [0.7650759703082831, 0.7945901820562783, 0.7610738169477751], "final_y": [0.14724168945709715, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "4f5efc54-d8c3-4bd8-933a-67e8689a816c", "solution": "import numpy as np\n\nclass HybridPSOSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.temperature = 100.0\n        self.cooling_rate = 0.9  # Modified for more gradual cooling\n        self.w = 0.8  # Reduced to improve balance between exploration and exploitation\n        self.c1 = 1.7  # Increased to enhance personal best influence\n        self.c2 = 1.3  # Decreased to reduce global best influence\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            V = self.w * V + \\\n                self.c1 * r1 * (personal_best - X) + \\\n                self.c2 * r2 * (global_best - X)\n            X = np.clip(X + V, lb, ub)\n\n            # Simulated Annealing step\n            for i in range(self.population_size):\n                candidate = X[i] + np.random.uniform(-0.5, 0.5, self.dim) * (ub - lb) * self.temperature\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / self.temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            self.temperature *= self.cooling_rate\n            \n            # Introduce diversity by replacing the worst-performing particle\n            worst_index = np.argmax(personal_best_values)\n            X[worst_index] = np.random.uniform(lb, ub, self.dim)\n\n        return global_best", "name": "HybridPSOSimulatedAnnealing", "description": "Introducing a diversity mechanism by replacing the worst particle with a random one at each iteration to enhance exploration.", "configspace": "", "generation": 5, "fitness": 0.7610379501336691, "feedback": "The algorithm HybridPSOSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.761 with standard deviation 0.027. And the mean value of best solutions found was 0.167 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "fa951018-8701-45b1-98e9-fce97d65962a", "metadata": {"aucs": [0.727449851396954, 0.7945901820562783, 0.7610738169477751], "final_y": [0.16905838789362138, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "e348248e-4d0d-44fa-b487-13a91c6ca166", "solution": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.97  # Slightly faster cooling\n        self.initial_w = 0.9\n        self.max_w = 0.9\n        self.min_w = 0.4\n        self.c1 = 2.0\n        self.c2 = 1.0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        dynamic_population_size = int(self.population_size * ((self.budget - evaluations) / self.budget) + 1)\n        X = np.random.uniform(lb, ub, (dynamic_population_size, self.dim))\n        V = np.random.uniform(-1, 1, (dynamic_population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = dynamic_population_size\n        temperature = self.initial_temperature\n        w = self.initial_w\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            progress_ratio = evaluations / self.budget\n            w = self.max_w - progress_ratio * (self.max_w - self.min_w)\n            \n            V = w * V + self.c1 * r1 * (personal_best - X) + self.c2 * r2 * (global_best - X)\n            X = np.clip(X + V, lb, ub)\n\n            mutation_strength = 0.5 * (1 - progress_ratio)\n\n            for i in range(dynamic_population_size):\n                candidate = X[i] + np.random.uniform(-mutation_strength, mutation_strength, self.dim) * (ub - lb)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            temperature *= self.cooling_rate\n\n        return global_best", "name": "EnhancedHybridPSOSA", "description": "Introduced a dynamic population size and a modified cooling strategy to enhance exploration and exploitation in the PSO-Simulated Annealing hybrid algorithm.", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"cannot access local variable 'evaluations' where it is not associated with a value\").", "error": "UnboundLocalError(\"cannot access local variable 'evaluations' where it is not associated with a value\")", "parent_id": "824f6e1b-99a5-408b-a98c-71e510bdd74e", "metadata": {}, "mutation_prompt": null}
{"id": "78a52b42-1ec4-421f-bff9-b4164d191a15", "solution": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.95  # More gradual cooling\n        self.initial_w = 0.9  # Start with higher inertia weight\n        self.max_w = 0.9\n        self.min_w = 0.4\n        self.c1 = 2.0  # Enhanced to increase personal best attraction\n        self.c2 = 1.0  # Reduced to decrease global best attraction\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        temperature = self.initial_temperature\n        w = self.initial_w\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            progress_ratio = evaluations / self.budget\n            w = self.max_w - progress_ratio * (self.max_w - self.min_w)\n            \n            V = w * V + self.c1 * r1 * (personal_best - X) + self.c2 * r2 * (global_best - X)\n            X = np.clip(X + V, lb, ub)\n\n            # Adaptive mutation strength\n            mutation_strength = 0.5 * (1 - progress_ratio)\n\n            for i in range(self.population_size):\n                candidate = X[i] + np.random.uniform(-mutation_strength, mutation_strength, self.dim) * (ub - lb)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            temperature *= self.cooling_rate * (1 - progress_ratio)  # Non-linear cooling schedule\n\n        return global_best", "name": "EnhancedHybridPSOSA", "description": "Introduced non-linear cooling schedule to adaptively control exploration and exploitation in the hybrid PSO-Simulated Annealing algorithm.", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"cannot access local variable 'evaluations' where it is not associated with a value\").", "error": "UnboundLocalError(\"cannot access local variable 'evaluations' where it is not associated with a value\")", "parent_id": "824f6e1b-99a5-408b-a98c-71e510bdd74e", "metadata": {}, "mutation_prompt": null}
{"id": "04752dd6-098d-49c7-80ba-530efbf00245", "solution": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.95  # More gradual cooling\n        self.initial_w = 0.9  # Start with higher inertia weight\n        self.max_w = 0.9\n        self.min_w = 0.4\n        self.c1 = 2.0  # Enhanced to increase personal best attraction\n        self.c2 = 1.0  # Reduced to decrease global best attraction\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        temperature = self.initial_temperature\n        w = self.initial_w\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            progress_ratio = evaluations / self.budget\n            w = self.max_w - progress_ratio * (self.max_w - self.min_w)\n            \n            V = w * V + self.c1 * r1 * (personal_best - X) + self.c2 * r2 * (global_best - X)\n            X = np.clip(X + V, lb, ub)\n\n            # Adaptive mutation strength\n            mutation_strength = 0.5 * (1 - progress_ratio)\n\n            for i in range(self.population_size):\n                candidate = X[i] + np.random.uniform(-mutation_strength, mutation_strength, self.dim) * (ub - lb)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            temperature *= 0.9 + 0.1 * progress_ratio\n\n        return global_best", "name": "EnhancedHybridPSOSA", "description": "Introduced dynamic cooling rate to enhance exploration stability in EnhancedHybridPSOSA.", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"cannot access local variable 'evaluations' where it is not associated with a value\").", "error": "UnboundLocalError(\"cannot access local variable 'evaluations' where it is not associated with a value\")", "parent_id": "824f6e1b-99a5-408b-a98c-71e510bdd74e", "metadata": {}, "mutation_prompt": null}
{"id": "7157d966-53f4-4281-9e28-ab41f13bdeed", "solution": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.95  # More gradual cooling\n        self.initial_w = 0.9  # Start with higher inertia weight\n        self.max_w = 0.9\n        self.min_w = 0.4\n        self.c1 = 2.0  # Enhanced to increase personal best attraction\n        self.c2 = 1.0  # Reduced to decrease global best attraction\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        temperature = self.initial_temperature\n        w = self.initial_w\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            progress_ratio = evaluations / self.budget\n            w = self.max_w - progress_ratio * (self.max_w - self.min_w)\n            \n            V = w * V + self.c1 * r1 * (personal_best - X) + self.c2 * r2 * (global_best - X)\n            X = np.clip(X + V, lb, ub)\n\n            # Adaptive mutation strength\n            mutation_strength = 0.5 * (1 - progress_ratio)\n\n            for i in range(self.population_size):\n                candidate = X[i] + np.random.uniform(-mutation_strength, mutation_strength, self.dim) * (ub - lb)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            temperature *= (self.cooling_rate + 0.05 * (1 - progress_ratio))\n\n        return global_best", "name": "EnhancedHybridPSOSA", "description": "Enhanced convergence by dynamically adjusting the cooling rate based on progress.", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"cannot access local variable 'evaluations' where it is not associated with a value\").", "error": "UnboundLocalError(\"cannot access local variable 'evaluations' where it is not associated with a value\")", "parent_id": "824f6e1b-99a5-408b-a98c-71e510bdd74e", "metadata": {}, "mutation_prompt": null}
{"id": "3a56967f-3a00-4714-8a2f-6f54d4d8be87", "solution": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.95  # More gradual cooling\n        self.initial_w = 0.9  # Start with higher inertia weight\n        self.max_w = 0.9\n        self.min_w = 0.4\n        self.c1 = 2.0  # Enhanced to increase personal best attraction\n        self.c2 = 1.0  # Reduced to decrease global best attraction\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        temperature = self.initial_temperature\n        w = self.initial_w\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            progress_ratio = evaluations / self.budget\n            w = self.max_w - progress_ratio * (self.max_w - self.min_w)\n            \n            V = w * V + self.c1 * r1 * (personal_best - X) + self.c2 * r2 * (global_best - X)\n            X = np.clip(X + V, lb, ub)\n\n            # Adaptive mutation strength\n            mutation_strength = 0.5 * (1 - progress_ratio)\n\n            # Randomized exploration boost\n            global_best_perturbed = global_best + np.random.uniform(-0.01, 0.01, self.dim) * (ub - lb)\n\n            for i in range(self.population_size):\n                candidate = X[i] + np.random.uniform(-mutation_strength, mutation_strength, self.dim) * (ub - lb)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            temperature *= self.cooling_rate\n\n        return global_best", "name": "EnhancedHybridPSOSA", "description": "Introduce a randomized exploration boost by slightly perturbing the global best position to enhance global search diversity.", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"cannot access local variable 'evaluations' where it is not associated with a value\").", "error": "UnboundLocalError(\"cannot access local variable 'evaluations' where it is not associated with a value\")", "parent_id": "824f6e1b-99a5-408b-a98c-71e510bdd74e", "metadata": {}, "mutation_prompt": null}
{"id": "0f3705a8-f356-4fb0-a7ab-ea88b15502f6", "solution": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.95  # More gradual cooling\n        self.initial_w = 0.9  # Start with higher inertia weight\n        self.max_w = 0.9\n        self.min_w = 0.4\n        self.c1 = 2.0  # Enhanced to increase personal best attraction\n        self.c2 = 1.0  # Reduced to decrease global best attraction\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-2, 2, (self.population_size, self.dim))  # Increased velocity range\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        temperature = self.initial_temperature\n        w = self.initial_w\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            progress_ratio = evaluations / self.budget\n            w = self.max_w - progress_ratio * (self.max_w - self.min_w)\n            \n            V = w * V + self.c1 * r1 * (personal_best - X) + self.c2 * r2 * (global_best - X)\n            X = np.clip(X + V, lb, ub)\n\n            # Adaptive mutation strength\n            mutation_strength = 0.5 * (1 - progress_ratio)\n\n            for i in range(self.population_size):\n                candidate = X[i] + np.random.uniform(-mutation_strength, mutation_strength, self.dim) * (ub - lb)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            temperature *= self.cooling_rate\n\n        return global_best", "name": "EnhancedHybridPSOSA", "description": "Improved convergence by increasing particle velocity range to enhance exploration capabilities.", "configspace": "", "generation": 7, "fitness": 0.8043292178154896, "feedback": "The algorithm EnhancedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.804 with standard deviation 0.013. And the mean value of best solutions found was 0.138 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "824f6e1b-99a5-408b-a98c-71e510bdd74e", "metadata": {"aucs": [0.786095719064579, 0.8155499873485957, 0.8113419470332939], "final_y": [0.15046217599976786, 0.13819232384078617, 0.12394144187570788]}, "mutation_prompt": null}
{"id": "df838f95-05cb-40dd-9c2d-f835222873e4", "solution": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.97  # More gradual cooling\n        self.initial_w = 0.9  # Start with higher inertia weight\n        self.max_w = 0.9\n        self.min_w = 0.4\n        self.c1 = 2.0  # Enhanced to increase personal best attraction\n        self.c2 = 1.0  # Reduced to decrease global best attraction\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        temperature = self.initial_temperature\n        w = self.initial_w\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            progress_ratio = evaluations / self.budget\n            w = self.max_w - progress_ratio * (self.max_w - self.min_w)\n            \n            V = w * V + self.c1 * r1 * (personal_best - X) + self.c2 * r2 * (global_best - X)\n            X = np.clip(X + V, lb, ub)\n\n            # Adaptive mutation strength\n            mutation_strength = 0.5 * (1 - progress_ratio)\n\n            for i in range(self.population_size):\n                candidate = X[i] + np.random.uniform(-mutation_strength, mutation_strength, self.dim) * (ub - lb)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            temperature *= self.cooling_rate\n\n        return global_best", "name": "EnhancedHybridPSOSA", "description": "Slightly increased cooling rate for better exploration-exploitation balance in EnhancedHybridPSOSA.", "configspace": "", "generation": 7, "fitness": 0.8200181977104326, "feedback": "The algorithm EnhancedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.820 with standard deviation 0.011. And the mean value of best solutions found was 0.136 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "824f6e1b-99a5-408b-a98c-71e510bdd74e", "metadata": {"aucs": [0.8214395760000577, 0.8329717669370597, 0.8056432501941804], "final_y": [0.1330570639425902, 0.1400125306895974, 0.1353033589415117]}, "mutation_prompt": null}
{"id": "53236a33-dd03-4a01-a976-7fd615f30741", "solution": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.95  # More gradual cooling\n        self.initial_w = 0.9  # Start with higher inertia weight\n        self.max_w = 0.9\n        self.min_w = 0.4\n        self.c1 = 2.0  # Enhanced to increase personal best attraction\n        self.c2 = 1.0  # Reduced to decrease global best attraction\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        temperature = self.initial_temperature\n        w = self.initial_w\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            progress_ratio = evaluations / self.budget\n            w = self.max_w - progress_ratio * (self.max_w - self.min_w)\n            \n            # Dynamic adjustment of personal best attraction coefficient\n            self.c1 = 2.0 + progress_ratio\n            \n            V = w * V + self.c1 * r1 * (personal_best - X) + self.c2 * r2 * (global_best - X)\n            X = np.clip(X + V, lb, ub)\n\n            # Adaptive mutation strength\n            mutation_strength = 0.5 * (1 - progress_ratio)\n\n            for i in range(self.population_size):\n                candidate = X[i] + np.random.uniform(-mutation_strength, mutation_strength, self.dim) * (ub - lb)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            temperature *= self.cooling_rate\n\n        return global_best", "name": "EnhancedHybridPSOSA", "description": "Introduced a dynamic adjustment of personal attraction coefficient to enhance convergence speed in the EnhancedHybridPSOSA algorithm.", "configspace": "", "generation": 7, "fitness": 0.7868106810799126, "feedback": "The algorithm EnhancedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.787 with standard deviation 0.011. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "824f6e1b-99a5-408b-a98c-71e510bdd74e", "metadata": {"aucs": [0.7716914612395163, 0.7945901820562783, 0.7941503999439434], "final_y": [0.1451425017850334, 0.1601017669387199, 0.13892759508858044]}, "mutation_prompt": null}
{"id": "cb13a161-eb7d-468d-baf4-374b9a5f20ed", "solution": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.95  # More gradual cooling\n        self.initial_w = 0.9  # Start with higher inertia weight\n        self.max_w = 0.9\n        self.min_w = 0.4\n        self.c1 = 2.0  # Enhanced to increase personal best attraction\n        self.c2 = 1.0  # Reduced to decrease global best attraction\n        self.v_max = 0.2  # Velocity clamping factor\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        temperature = self.initial_temperature\n        w = self.initial_w\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            progress_ratio = evaluations / self.budget\n            w = self.max_w - progress_ratio * (self.max_w - self.min_w)\n            \n            V = w * V + self.c1 * r1 * (personal_best - X) + self.c2 * r2 * (global_best - X)\n            V = np.clip(V, -self.v_max, self.v_max)  # Velocity clamping\n            X = np.clip(X + V, lb, ub)\n\n            # Adaptive mutation strength\n            mutation_strength = 0.5 * (1 - progress_ratio)\n\n            for i in range(self.population_size):\n                rand_idx = np.random.choice(self.population_size, size=2, replace=False)  # for crossover\n                candidate = X[i] + np.random.uniform(-mutation_strength, mutation_strength, self.dim) * (ub - lb)\n                candidate = np.clip(candidate, lb, ub)\n                candidate = np.where(np.random.rand(self.dim) < 0.5, candidate, X[rand_idx[0]])  # Crossover\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            temperature *= self.cooling_rate\n\n        return global_best", "name": "EnhancedHybridPSOSA", "description": "Introduced velocity clamping and differential evolution-inspired crossover to enhance convergence speed and solution diversity.", "configspace": "", "generation": 7, "fitness": 0.7982638848273759, "feedback": "The algorithm EnhancedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.798 with standard deviation 0.014. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "824f6e1b-99a5-408b-a98c-71e510bdd74e", "metadata": {"aucs": [0.7835600751753331, 0.7945901820562783, 0.8166413972505162], "final_y": [0.15000558137587305, 0.1601017669387199, 0.13485630668618664]}, "mutation_prompt": null}
{"id": "881cea96-ec9e-4dae-be0f-37ae554d2f9f", "solution": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.95  # More gradual cooling\n        self.initial_w = 0.9  # Start with higher inertia weight\n        self.max_w = 0.9\n        self.min_w = 0.4\n        self.c1 = 2.0  # Enhanced to increase personal best attraction\n        self.c2 = 1.0  # Reduced to decrease global best attraction\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        temperature = self.initial_temperature\n        w = self.initial_w\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            progress_ratio = evaluations / self.budget\n            w = self.max_w - progress_ratio * (self.max_w - self.min_w)\n            \n            V = w * V + self.c1 * r1 * (personal_best - X) + self.c2 * r2 * (global_best - X)\n            X = np.clip(X + V, lb, ub)\n\n            # Adaptive mutation strength\n            mutation_strength = 0.5 * (1 - progress_ratio)\n\n            for i in range(self.population_size):\n                candidate = X[i] + np.random.uniform(-mutation_strength, mutation_strength, self.dim) * (ub - lb)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            # Dynamic cooling rate\n            self.cooling_rate = 0.9 + 0.05 * progress_ratio\n            temperature *= self.cooling_rate\n\n        return global_best", "name": "EnhancedHybridPSOSA", "description": "Improved convergence by modifying the cooling rate dynamically based on progress ratio for enhanced temperature adaptation.", "configspace": "", "generation": 7, "fitness": 0.7924861277847225, "feedback": "The algorithm EnhancedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.792 with standard deviation 0.025. And the mean value of best solutions found was 0.152 (0. is the best) with standard deviation 0.022.", "error": "", "parent_id": "824f6e1b-99a5-408b-a98c-71e510bdd74e", "metadata": {"aucs": [0.821794384350114, 0.7945901820562783, 0.7610738169477751], "final_y": [0.12179977506559192, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "cf6b226e-d774-4ebf-9f5a-bb78fd35fee7", "solution": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 42  # Increased from 40 to 42 for better coverage\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.97  # More gradual cooling\n        self.initial_w = 0.9  # Start with higher inertia weight\n        self.max_w = 0.9\n        self.min_w = 0.4\n        self.c1 = 2.0  # Enhanced to increase personal best attraction\n        self.c2 = 1.0  # Reduced to decrease global best attraction\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        temperature = self.initial_temperature\n        w = self.initial_w\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            progress_ratio = evaluations / self.budget\n            w = self.max_w - progress_ratio * (self.max_w - self.min_w)\n            \n            V = w * V + self.c1 * r1 * (personal_best - X) + self.c2 * r2 * (global_best - X)\n            X = np.clip(X + V, lb, ub)\n\n            # Adaptive mutation strength\n            mutation_strength = 0.5 * (1 - progress_ratio)\n\n            for i in range(self.population_size):\n                candidate = X[i] + np.random.uniform(-mutation_strength, mutation_strength, self.dim) * (ub - lb)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            temperature *= self.cooling_rate\n\n        return global_best", "name": "EnhancedHybridPSOSA", "description": "Improved exploration by increasing the population size slightly for better coverage of the search space.", "configspace": "", "generation": 8, "fitness": 0.8029091580247022, "feedback": "The algorithm EnhancedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.803 with standard deviation 0.006. And the mean value of best solutions found was 0.145 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "df838f95-05cb-40dd-9c2d-f835222873e4", "metadata": {"aucs": [0.8102505703784062, 0.7945901820562783, 0.8038867216394219], "final_y": [0.14551561596768714, 0.1601017669387199, 0.13081387848051196]}, "mutation_prompt": null}
{"id": "f34c0ea9-65e8-4a11-84eb-41d5df93fe2f", "solution": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.97  # More gradual cooling\n        self.initial_w = 0.9  # Start with higher inertia weight\n        self.max_w = 0.9\n        self.min_w = 0.4\n        self.c1 = 2.0  # Enhanced to increase personal best attraction\n        self.c2 = 1.0  # Reduced to decrease global best attraction\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        temperature = self.initial_temperature\n        w = self.initial_w\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            progress_ratio = evaluations / self.budget\n            stochastic_w_factor = np.random.uniform(0.9, 1.1)\n            w = (self.max_w - progress_ratio * (self.max_w - self.min_w)) * stochastic_w_factor\n            \n            V = w * V + self.c1 * r1 * (personal_best - X) + self.c2 * r2 * (global_best - X)\n            X = np.clip(X + V, lb, ub)\n\n            # Adaptive mutation strength\n            mutation_strength = 0.5 * (1 - progress_ratio)\n\n            for i in range(self.population_size):\n                candidate = X[i] + np.random.uniform(-mutation_strength, mutation_strength, self.dim) * (ub - lb)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            temperature *= self.cooling_rate\n\n        return global_best", "name": "EnhancedHybridPSOSA", "description": "Introduced a stochastic component in inertia weight decay for improved exploration in EnhancedHybridPSOSA.", "configspace": "", "generation": 8, "fitness": 0.7914119421543098, "feedback": "The algorithm EnhancedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.791 with standard deviation 0.005. And the mean value of best solutions found was 0.154 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "df838f95-05cb-40dd-9c2d-f835222873e4", "metadata": {"aucs": [0.7959118666313494, 0.7945901820562783, 0.7837337777753017], "final_y": [0.15068865370649942, 0.1601017669387199, 0.1510899720364477]}, "mutation_prompt": null}
{"id": "8b68899f-47a7-403d-a97e-7d74d1cca509", "solution": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.97  # More gradual cooling\n        self.initial_w = 0.9  # Start with higher inertia weight\n        self.max_w = 0.9\n        self.min_w = 0.4\n        self.c1 = 1.9  # Fine-tuned personal best attraction\n        self.c2 = 1.1  # Fine-tuned global best attraction\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        temperature = self.initial_temperature\n        w = self.initial_w\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            progress_ratio = evaluations / self.budget\n            w = self.max_w - progress_ratio * (self.max_w - self.min_w)\n            \n            V = w * V + self.c1 * r1 * (personal_best - X) + self.c2 * r2 * (global_best - X)\n            X = np.clip(X + V, lb, ub)\n\n            # Adaptive mutation strength\n            mutation_strength = 0.5 * (1 - progress_ratio)\n\n            for i in range(self.population_size):\n                candidate = X[i] + np.random.uniform(-mutation_strength, mutation_strength, self.dim) * (ub - lb)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            temperature *= self.cooling_rate\n\n        return global_best", "name": "EnhancedHybridPSOSA", "description": "Improved balance between global and personal influences by fine-tuning the coefficients c1 and c2.", "configspace": "", "generation": 8, "fitness": 0.7965893941412038, "feedback": "The algorithm EnhancedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.797 with standard deviation 0.006. And the mean value of best solutions found was 0.147 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "df838f95-05cb-40dd-9c2d-f835222873e4", "metadata": {"aucs": [0.8050291839744345, 0.7953378393246319, 0.7894011591245453], "final_y": [0.12963945499464224, 0.15966624912005545, 0.1513664015698204]}, "mutation_prompt": null}
{"id": "b9f61806-4653-4615-be05-efde6ddfa39f", "solution": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.96  # Enhanced gradual cooling\n        self.initial_w = 0.95  # Start with higher inertia weight\n        self.max_w = 0.9\n        self.min_w = 0.2  # Lower minimum inertia weight\n        self.c1 = 2.5  # Increased personal best attraction\n        self.c2 = 1.5  # Increased global best attraction\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        temperature = self.initial_temperature\n        w = self.initial_w\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            progress_ratio = evaluations / self.budget\n            w = self.max_w - progress_ratio * (self.max_w - self.min_w)\n            \n            V = w * V + self.c1 * r1 * (personal_best - X) + self.c2 * r2 * (global_best - X)\n            X = np.clip(X + V, lb, ub)\n\n            # Adaptive mutation strength\n            mutation_strength = 0.3 * (1 - progress_ratio)\n\n            elite_idx = np.argmin(personal_best_values)  # Identify elite\n            elite = personal_best[elite_idx]\n\n            for i in range(self.population_size):\n                candidate = X[i] + np.random.uniform(-mutation_strength, mutation_strength, self.dim) * (elite - X[i])\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            temperature *= self.cooling_rate\n\n        return global_best", "name": "EnhancedHybridPSOSA", "description": "Enhanced exploration with adaptive inertia weight and elite-guided mutation in EnhancedHybridPSOSA for improved convergence.", "configspace": "", "generation": 8, "fitness": 0.7955156218490206, "feedback": "The algorithm EnhancedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.796 with standard deviation 0.007. And the mean value of best solutions found was 0.154 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "df838f95-05cb-40dd-9c2d-f835222873e4", "metadata": {"aucs": [0.8041332236949175, 0.7945901820562783, 0.7878234597958659], "final_y": [0.1496086922631541, 0.1601017669387199, 0.1520462652833845]}, "mutation_prompt": null}
{"id": "f3874949-7928-48ea-8f38-c8324ab42eca", "solution": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.97\n        self.initial_w = 0.9\n        self.max_w = 0.9\n        self.min_w = 0.4\n        self.c1 = 2.0\n        self.c2 = 1.0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        temperature = self.initial_temperature\n        w = self.initial_w\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            progress_ratio = evaluations / self.budget\n            w = self.max_w - progress_ratio * (self.max_w - self.min_w)\n\n            # Adaptive learning rates\n            self.c1 = 2.5 - progress_ratio * 1.5\n            self.c2 = 0.5 + progress_ratio * 1.5\n            \n            V = w * V + self.c1 * r1 * (personal_best - X) + self.c2 * r2 * (global_best - X)\n            X = np.clip(X + V, lb, ub)\n\n            mutation_strength = 0.5 * (1 - progress_ratio)\n\n            for i in range(self.population_size):\n                # Differential Mutation for diversity\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = X[idxs]\n                mutant = np.clip(a + 0.8 * (b - c), lb, ub)\n                candidate = mutant + np.random.uniform(-mutation_strength, mutation_strength, self.dim) * (ub - lb)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            temperature *= self.cooling_rate\n\n        return global_best", "name": "EnhancedHybridPSOSA", "description": "Introduced adaptive learning rates and enhanced diversity through differential mutation in EnhancedHybridPSOSA.", "configspace": "", "generation": 8, "fitness": 0.7723433670148533, "feedback": "The algorithm EnhancedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.772 with standard deviation 0.020. And the mean value of best solutions found was 0.163 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "df838f95-05cb-40dd-9c2d-f835222873e4", "metadata": {"aucs": [0.7508043372674793, 0.7993834391794207, 0.7668423245976599], "final_y": [0.16120664156562226, 0.15792128438546738, 0.17030396423954763]}, "mutation_prompt": null}
{"id": "e7f37b28-615f-47b5-a27d-bd10aa596a49", "solution": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.98  # Slightly increased cooling rate\n        self.initial_w = 0.9  # Start with higher inertia weight\n        self.max_w = 0.9\n        self.min_w = 0.4\n        self.c1 = 2.0  # Enhanced to increase personal best attraction\n        self.c2 = 1.0  # Reduced to decrease global best attraction\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        temperature = self.initial_temperature\n        w = self.initial_w\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            progress_ratio = evaluations / self.budget\n            w = self.max_w - progress_ratio * (self.max_w - self.min_w)\n            \n            V = w * V + self.c1 * r1 * (personal_best - X) + self.c2 * r2 * (global_best - X)\n            X = np.clip(X + V, lb, ub)\n\n            # Adaptive mutation strength\n            mutation_strength = 0.5 * (1 - progress_ratio)\n\n            for i in range(self.population_size):\n                candidate = X[i] + np.random.uniform(-mutation_strength, mutation_strength, self.dim) * (ub - lb)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            temperature *= self.cooling_rate\n\n        return global_best", "name": "EnhancedHybridPSOSA", "description": "Improved convergence by slightly increasing the cooling rate for better exploration-exploitation balance.", "configspace": "", "generation": 9, "fitness": 0.7832090350765745, "feedback": "The algorithm EnhancedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.783 with standard deviation 0.016. And the mean value of best solutions found was 0.154 (0. is the best) with standard deviation 0.019.", "error": "", "parent_id": "df838f95-05cb-40dd-9c2d-f835222873e4", "metadata": {"aucs": [0.7939631062256698, 0.7945901820562783, 0.7610738169477751], "final_y": [0.12760951367820061, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "68366d0b-6c9d-450d-9b46-62662cd5fbc3", "solution": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 45  # Increased population size\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.97  # More gradual cooling\n        self.initial_w = 0.9  # Start with higher inertia weight\n        self.max_w = 0.9\n        self.min_w = 0.4\n        self.c1 = 2.0  # Enhanced to increase personal best attraction\n        self.c2 = 1.0  # Reduced to decrease global best attraction\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        temperature = self.initial_temperature\n        w = self.initial_w\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            progress_ratio = evaluations / self.budget\n            w = self.max_w - progress_ratio * (self.max_w - self.min_w)\n            \n            V = w * V + self.c1 * r1 * (personal_best - X) + self.c2 * r2 * (global_best - X)\n            X = np.clip(X + V, lb, ub)\n\n            # Adaptive mutation strength\n            mutation_strength = 0.5 * (1 - progress_ratio)\n\n            for i in range(self.population_size):\n                candidate = X[i] + np.random.uniform(-mutation_strength, mutation_strength, self.dim) * (ub - lb)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            temperature *= self.cooling_rate\n\n        return global_best", "name": "EnhancedHybridPSOSA", "description": "Enhanced convergence by increasing the population size for broader exploration.", "configspace": "", "generation": 9, "fitness": 0.8147044125637785, "feedback": "The algorithm EnhancedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.815 with standard deviation 0.007. And the mean value of best solutions found was 0.132 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "df838f95-05cb-40dd-9c2d-f835222873e4", "metadata": {"aucs": [0.8058910634149771, 0.8164392900315258, 0.8217828842448323], "final_y": [0.1394759812369707, 0.13268605224325414, 0.12495834768141978]}, "mutation_prompt": null}
{"id": "9e5dec50-55f9-4f2a-922e-878e29c5214f", "solution": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.97  # More gradual cooling\n        self.initial_w = 0.9  # Start with higher inertia weight\n        self.max_w = 0.9\n        self.min_w = 0.4\n        self.c1 = 2.0  # Enhanced to increase personal best attraction\n        self.c2 = 1.0  # Reduced to decrease global best attraction\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        temperature = self.initial_temperature\n        w = self.initial_w\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            progress_ratio = evaluations / self.budget\n            w = self.max_w - progress_ratio * (self.max_w - self.min_w)\n            \n            V = w * V + self.c1 * r1 * (personal_best - X) + self.c2 * r2 * (global_best - X)\n            X = np.clip(X + V, lb, ub)\n\n            # Dynamic population size adjustment\n            self.population_size = max(20, int(40 * (1 - progress_ratio)))\n\n            mutation_strength = 0.5 * (1 - progress_ratio)\n\n            for i in range(self.population_size):\n                candidate = X[i] + np.random.uniform(-mutation_strength, mutation_strength, self.dim) * (ub - lb)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            temperature *= self.cooling_rate\n\n        return global_best", "name": "EnhancedHybridPSOSA", "description": "Introduced dynamic population size adjustment for improved exploration-exploitation balance in EnhancedHybridPSOSA.", "configspace": "", "generation": 9, "fitness": 0.8030036838477806, "feedback": "The algorithm EnhancedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.803 with standard deviation 0.010. And the mean value of best solutions found was 0.145 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "df838f95-05cb-40dd-9c2d-f835222873e4", "metadata": {"aucs": [0.7974127499117141, 0.7945901820562783, 0.8170081195753496], "final_y": [0.14665314500132887, 0.1601017669387199, 0.12788447620726973]}, "mutation_prompt": null}
{"id": "4c8499b4-6d9b-4e76-a736-bf837907970d", "solution": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.97  # More gradual cooling\n        self.initial_w = 0.9  # Start with higher inertia weight\n        self.max_w = 0.9\n        self.min_w = 0.4\n        self.c1 = 2.0  # Enhanced to increase personal best attraction\n        self.c2 = 1.0  # Reduced to decrease global best attraction\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        temperature = self.initial_temperature\n        w = self.initial_w\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            progress_ratio = evaluations / self.budget\n            w = self.max_w - progress_ratio * (self.max_w - self.min_w)\n            \n            V = w * V + self.c1 * r1 * (personal_best - X) + self.c2 * r2 * (global_best - X)\n            X = np.clip(X + V, lb, ub)\n\n            # Adaptive mutation strength\n            mutation_strength = 0.5 * (1 - progress_ratio)\n            \n            # Dynamic population size based on progress\n            dynamic_population_size = int(self.population_size * (1 + 0.5 * progress_ratio))\n\n            for i in range(dynamic_population_size):\n                candidate = X[i % self.population_size] + np.random.uniform(-mutation_strength, mutation_strength, self.dim) * (ub - lb)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i % self.population_size]:\n                    personal_best[i % self.population_size] = candidate\n                    personal_best_values[i % self.population_size] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i % self.population_size] - candidate_value) / temperature) > np.random.rand():\n                    personal_best[i % self.population_size] = candidate\n                    personal_best_values[i % self.population_size] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            temperature *= self.cooling_rate\n\n        return global_best", "name": "EnhancedHybridPSOSA", "description": "Introduce a dynamic population size strategy in EnhancedHybridPSOSA to improve exploration and exploitation.", "configspace": "", "generation": 9, "fitness": 0.8022910368999313, "feedback": "The algorithm EnhancedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.802 with standard deviation 0.013. And the mean value of best solutions found was 0.134 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "df838f95-05cb-40dd-9c2d-f835222873e4", "metadata": {"aucs": [0.7925027347040937, 0.8209598838534121, 0.793410492142288], "final_y": [0.13617384220964435, 0.13363928074062215, 0.1332502954576692]}, "mutation_prompt": null}
{"id": "875d011d-2c7e-4427-adc1-4c583a664566", "solution": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.97  # More gradual cooling\n        self.initial_w = 0.95  # Slightly increased initial inertia weight\n        self.max_w = 0.9\n        self.min_w = 0.4\n        self.c1 = 2.0  # Enhanced to increase personal best attraction\n        self.c2 = 1.0  # Reduced to decrease global best attraction\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        temperature = self.initial_temperature\n        w = self.initial_w\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            progress_ratio = evaluations / self.budget\n            w = self.max_w - progress_ratio * (self.max_w - self.min_w)\n            \n            V = w * V + self.c1 * r1 * (personal_best - X) + self.c2 * r2 * (global_best - X)\n            X = np.clip(X + V, lb, ub)\n\n            # Adaptive mutation strength\n            mutation_strength = 0.5 * (1 - progress_ratio)\n\n            for i in range(self.population_size):\n                candidate = X[i] + np.random.uniform(-mutation_strength, mutation_strength, self.dim) * (ub - lb)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            temperature *= self.cooling_rate\n\n        return global_best", "name": "EnhancedHybridPSOSA", "description": "Introduced a minor increase in inertia weight for improved exploration during early iterations.", "configspace": "", "generation": 9, "fitness": 0.8119376518482225, "feedback": "The algorithm EnhancedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.812 with standard deviation 0.019. And the mean value of best solutions found was 0.144 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "df838f95-05cb-40dd-9c2d-f835222873e4", "metadata": {"aucs": [0.838330468996243, 0.7945901820562783, 0.8028923044921465], "final_y": [0.1379474641109273, 0.1601017669387199, 0.13529904427541994]}, "mutation_prompt": null}
{"id": "61d5c3ae-6a33-41ba-ba82-6b1b72d6be20", "solution": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.97  # More gradual cooling\n        self.initial_w = 0.9  # Start with higher inertia weight\n        self.max_w = 0.9\n        self.min_w = 0.4\n        self.c1 = 2.0  # Enhanced to increase personal best attraction\n        self.c2 = 1.0  # Reduced to decrease global best attraction\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        temperature = self.initial_temperature\n        w = self.initial_w\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            progress_ratio = evaluations / self.budget\n            w = self.max_w - progress_ratio * (self.max_w - self.min_w)\n            \n            # Dynamic population size adjustment\n            self.population_size = int(40 + 10 * np.sin(progress_ratio * np.pi))\n            \n            V = w * V + self.c1 * r1 * (personal_best - X) + self.c2 * r2 * (global_best - X)\n            X = np.clip(X + V, lb, ub)\n\n            # Adaptive mutation strength\n            mutation_strength = 0.5 * (1 - progress_ratio)\n\n            for i in range(self.population_size):\n                candidate = X[i] + np.random.uniform(-mutation_strength, mutation_strength, self.dim) * (ub - lb)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            temperature *= self.cooling_rate\n\n        return global_best", "name": "EnhancedHybridPSOSA", "description": "Introduced a dynamic population size adjustment to enhance the balance between exploration and exploitation during optimization.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 40 is out of bounds for axis 0 with size 40').", "error": "IndexError('index 40 is out of bounds for axis 0 with size 40')", "parent_id": "df838f95-05cb-40dd-9c2d-f835222873e4", "metadata": {}, "mutation_prompt": null}
{"id": "ebb01089-684f-4ea6-91a3-2742d8407195", "solution": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 40\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.97  # More gradual cooling\n        self.initial_w = 0.9  # Start with higher inertia weight\n        self.max_w = 0.9\n        self.min_w = 0.4\n        self.c1 = 2.0  # Enhanced to increase personal best attraction\n        self.c2 = 1.0  # Reduced to decrease global best attraction\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.initial_population_size\n        X = np.random.uniform(lb, ub, (population_size, self.dim))\n        V = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = population_size\n        temperature = self.initial_temperature\n        w = self.initial_w\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            progress_ratio = evaluations / self.budget\n            w = self.max_w - progress_ratio * (self.max_w - self.min_w)\n            \n            V = w * V + self.c1 * r1 * (personal_best - X) + self.c2 * r2 * (global_best - X)\n            X = np.clip(X + V, lb, ub)\n\n            # Adaptive mutation strength\n            mutation_strength = 0.5 * (1 - progress_ratio)\n\n            for i in range(population_size):\n                candidate = X[i] + np.random.uniform(-mutation_strength, mutation_strength, self.dim) * (ub - lb)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            temperature *= self.cooling_rate ** (1 + 0.5 * progress_ratio)  # Nonlinear cooling\n            population_size = max(10, int(self.initial_population_size * (1 - progress_ratio)))  # Adaptive population size\n\n        return global_best", "name": "EnhancedHybridPSOSA", "description": "Introduce an adaptive population size and nonlinear cooling scheme for enhanced exploration-exploitation balance in EnhancedHybridPSOSA.", "configspace": "", "generation": 10, "fitness": 0.8037169695002163, "feedback": "The algorithm EnhancedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.804 with standard deviation 0.008. And the mean value of best solutions found was 0.132 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "df838f95-05cb-40dd-9c2d-f835222873e4", "metadata": {"aucs": [0.8139303913562322, 0.8037964590113669, 0.7934240581330496], "final_y": [0.11865240662609133, 0.14251580610577197, 0.13377978327259488]}, "mutation_prompt": null}
{"id": "f8fb0c59-89c6-489a-8e17-b84ad1179198", "solution": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.97  # More gradual cooling\n        self.initial_w = 0.9  # Start with higher inertia weight\n        self.max_w = 0.9\n        self.min_w = 0.4\n        self.c1 = 2.0  # Enhanced to increase personal best attraction\n        self.c2 = 1.0  # Reduced to decrease global best attraction\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        temperature = self.initial_temperature\n        w = self.initial_w\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            progress_ratio = evaluations / self.budget\n            w = self.max_w - progress_ratio * (self.max_w - self.min_w)\n            \n            V = w * V + self.c1 * r1 * (personal_best - X) + self.c2 * r2 * (global_best - X)\n            X = np.clip(X + V, lb, ub)\n\n            # Adaptive mutation strength\n            mutation_strength = 0.5 / np.sqrt(progress_ratio)  # Updated mutation strength calculation\n\n            for i in range(self.population_size):\n                candidate = X[i] + np.random.uniform(-mutation_strength, mutation_strength, self.dim) * (ub - lb)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            temperature *= self.cooling_rate\n\n        return global_best", "name": "EnhancedHybridPSOSA", "description": "Improved the mutation strength formula for better convergence by varying it inversely with the square root of progress ratio.", "configspace": "", "generation": 10, "fitness": 0.7861994028370632, "feedback": "The algorithm EnhancedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.786 with standard deviation 0.012. And the mean value of best solutions found was 0.147 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "df838f95-05cb-40dd-9c2d-f835222873e4", "metadata": {"aucs": [0.7761731317298088, 0.8028674871789832, 0.7795575896023978], "final_y": [0.15918244821156657, 0.1428882218967048, 0.139621151775148]}, "mutation_prompt": null}
{"id": "10926088-9cd2-4847-814c-107605b525f9", "solution": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.97  # More gradual cooling\n        self.initial_w = 0.95  # Start with a slightly higher inertia weight\n        self.max_w = 0.9\n        self.min_w = 0.4\n        self.c1 = 2.0  # Enhanced to increase personal best attraction\n        self.c2 = 1.0  # Reduced to decrease global best attraction\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        temperature = self.initial_temperature\n        w = self.initial_w\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            progress_ratio = evaluations / self.budget\n            w = self.max_w - progress_ratio * (self.max_w - self.min_w)\n            \n            V = w * V + self.c1 * r1 * (personal_best - X) + self.c2 * r2 * (global_best - X)\n            X = np.clip(X + V, lb, ub)\n\n            # Adaptive mutation strength\n            mutation_strength = 0.5 * (1 - progress_ratio)\n\n            for i in range(self.population_size):\n                candidate = X[i] + np.random.uniform(-mutation_strength, mutation_strength, self.dim) * (ub - lb)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            temperature *= self.cooling_rate\n\n        return global_best", "name": "EnhancedHybridPSOSA", "description": "Increased the initial inertia weight to improve early exploration, enhancing the balance between exploration and exploitation.", "configspace": "", "generation": 10, "fitness": 0.7962811503040226, "feedback": "The algorithm EnhancedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.796 with standard deviation 0.016. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "df838f95-05cb-40dd-9c2d-f835222873e4", "metadata": {"aucs": [0.7869905414518699, 0.8186858366044558, 0.783167072855742], "final_y": [0.13349547004013362, 0.11993477638223571, 0.12633252801510653]}, "mutation_prompt": null}
{"id": "a463978d-a607-453b-9e7a-8a78ed9aff0c", "solution": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.97  # More gradual cooling\n        self.initial_w = 0.9  # Start with higher inertia weight\n        self.max_w = 0.9\n        self.min_w = 0.4\n        self.c1 = 2.0  # Enhanced to increase personal best attraction\n        self.c2 = 1.0  # Reduced to decrease global best attraction\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        temperature = self.initial_temperature\n        w = self.initial_w\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            progress_ratio = evaluations / self.budget\n            w = self.max_w - progress_ratio * (self.max_w - self.min_w)\n            \n            V = w * V + self.c1 * r1 * (personal_best - X) + self.c2 * r2 * (global_best - X)\n            X = np.clip(X + V, lb, ub)\n            \n            # Dynamic population size adjustment\n            current_population_size = max(5, int(self.population_size * (1 - progress_ratio)))\n\n            # Enhanced mutation strength with noise\n            mutation_strength = 0.5 * (1 - progress_ratio) + np.random.normal(0, 0.1)\n\n            for i in range(current_population_size):\n                candidate = X[i] + np.random.uniform(-mutation_strength, mutation_strength, self.dim) * (ub - lb)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            temperature *= self.cooling_rate\n\n        return global_best", "name": "EnhancedHybridPSOSA", "description": "Introduced dynamic population size adjustment and enhanced mutation strategy for improved exploration-exploitation balance.", "configspace": "", "generation": 10, "fitness": 0.7834192721801824, "feedback": "The algorithm EnhancedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.783 with standard deviation 0.016. And the mean value of best solutions found was 0.162 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "df838f95-05cb-40dd-9c2d-f835222873e4", "metadata": {"aucs": [0.794593817536494, 0.7945901820562783, 0.7610738169477751], "final_y": [0.15252864781998487, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "aecb947b-1ea4-4615-85aa-257a80024c12", "solution": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.95  # Slightly faster cooling\n        self.initial_w = 0.9\n        self.max_w = 0.9\n        self.min_w = 0.3  # Lower minimum inertia\n        self.c1 = 2.0\n        self.c2 = 1.5  # Increased global best attraction\n        self.gradient_influence = 0.5  # New parameter for gradient influence\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        temperature = self.initial_temperature\n        w = self.initial_w\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            progress_ratio = evaluations / self.budget\n            w = self.max_w - progress_ratio * (self.max_w - self.min_w)\n            \n            grad = np.array([np.gradient(func(x)) for x in X])  # Gradient calculation\n            V = w * V + self.c1 * r1 * (personal_best - X) + self.c2 * r2 * (global_best - X) - self.gradient_influence * grad\n            X = np.clip(X + V, lb, ub)\n\n            # Adaptive dynamic mutation strength\n            mutation_strength = 1.0 / (1 + evaluations/self.budget)\n\n            for i in range(self.population_size):\n                candidate = X[i] + np.random.uniform(-mutation_strength, mutation_strength, self.dim) * (ub - lb)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            temperature *= self.cooling_rate\n\n        return global_best", "name": "EnhancedHybridPSOSA", "description": "Introduce gradient-informed velocity adjustments and dynamic mutation to refine EnhancedHybridPSOSA for better convergence and exploration.", "configspace": "", "generation": 11, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (40,10) (40,0) ').", "error": "ValueError('operands could not be broadcast together with shapes (40,10) (40,0) ')", "parent_id": "df838f95-05cb-40dd-9c2d-f835222873e4", "metadata": {}, "mutation_prompt": null}
{"id": "84f0e2eb-ceab-4e59-834a-88349ad28dac", "solution": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.97  # More gradual cooling\n        self.initial_w = 0.9  # Start with higher inertia weight\n        self.max_w = 0.9\n        self.min_w = 0.4\n        self.c1 = 2.0  # Enhanced to increase personal best attraction\n        self.c2 = 1.0  # Reduced to decrease global best attraction\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        temperature = self.initial_temperature\n        w = self.initial_w\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            progress_ratio = evaluations / self.budget\n            w = self.max_w - progress_ratio * (self.max_w - self.min_w)\n            \n            V = w * V + self.c1 * r1 * (personal_best - X) + self.c2 * r2 * (global_best - X)\n            X = np.clip(X + V, lb, ub)\n\n            # Adaptive mutation strength\n            mutation_strength = 0.5 * (1 - progress_ratio)\n\n            for i in range(self.population_size):\n                candidate = X[i] + np.random.uniform(-mutation_strength, mutation_strength, self.dim) * (ub - lb)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            temperature *= self.cooling_rate * (1 - 0.5 * progress_ratio)  # Adaptive cooling rate\n            self.population_size = int(40 * (1 - 0.5 * progress_ratio))  # Dynamic population size\n\n        return global_best", "name": "EnhancedHybridPSOSA", "description": "Introduce dynamic population size and adaptive cooling rate to enhance exploration-exploitation balance.", "configspace": "", "generation": 11, "fitness": 0.8039271400759561, "feedback": "The algorithm EnhancedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.804 with standard deviation 0.007. And the mean value of best solutions found was 0.144 (0. is the best) with standard deviation 0.015.", "error": "", "parent_id": "df838f95-05cb-40dd-9c2d-f835222873e4", "metadata": {"aucs": [0.8085031956953498, 0.7945901820562783, 0.8086880424762405], "final_y": [0.1250425079714138, 0.1601017669387199, 0.14810568430443483]}, "mutation_prompt": null}
{"id": "40f11c66-629d-4251-965c-39d3cb727983", "solution": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.97  # More gradual cooling\n        self.initial_w = 0.9  # Start with higher inertia weight\n        self.max_w = 0.9\n        self.min_w = 0.4\n        self.c1 = 2.0  # Enhanced to increase personal best attraction\n        self.c2 = 1.0  # Reduced to decrease global best attraction\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        temperature = self.initial_temperature\n        w = self.initial_w\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            progress_ratio = evaluations / self.budget\n            w = self.min_w + (self.max_w - self.min_w) * (1 - progress_ratio)  # Adjusted inertia weight update\n            \n            V = w * V + self.c1 * r1 * (personal_best - X) + self.c2 * r2 * (global_best - X)\n            X = np.clip(X + V, lb, ub)\n\n            # Adaptive mutation strength\n            mutation_strength = 0.5 * (1 - progress_ratio)\n\n            for i in range(self.population_size):\n                candidate = X[i] + np.random.uniform(-mutation_strength, mutation_strength, self.dim) * (ub - lb)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            temperature *= self.cooling_rate\n\n        return global_best", "name": "EnhancedHybridPSOSA", "description": "Adjusted inertia weight update to enhance the adaptability of search dynamics throughout the optimization process.", "configspace": "", "generation": 11, "fitness": 0.7829281792240055, "feedback": "The algorithm EnhancedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.783 with standard deviation 0.018. And the mean value of best solutions found was 0.151 (0. is the best) with standard deviation 0.017.", "error": "", "parent_id": "df838f95-05cb-40dd-9c2d-f835222873e4", "metadata": {"aucs": [0.782413342544488, 0.8052973781797532, 0.7610738169477751], "final_y": [0.1314506716511581, 0.14845825701197157, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "84ed4777-e8f7-4d2b-ab51-7e56c75918b0", "solution": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.97  # More gradual cooling\n        self.initial_w = 0.9  # Start with higher inertia weight\n        self.max_w = 0.9\n        self.min_w = 0.4\n        self.c1 = 2.0  # Enhanced to increase personal best attraction\n        self.c2 = 1.0  # Reduced to decrease global best attraction\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        temperature = self.initial_temperature\n        w = self.initial_w\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            progress_ratio = evaluations / self.budget\n            w = self.max_w - progress_ratio * (self.max_w - self.min_w)\n            \n            V = w * V + self.c1 * r1 * (personal_best - X) + self.c2 * r2 * (global_best - X)\n            X = np.clip(X + V, lb, ub)\n\n            # Adaptive mutation strength\n            mutation_strength = 0.5 * (1 - progress_ratio)\n\n            for i in range(self.population_size):\n                candidate = X[i] + np.random.uniform(-mutation_strength, mutation_strength, self.dim) * (ub - lb)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            temperature *= self.cooling_rate * (1 - 0.5 * progress_ratio)\n\n        return global_best", "name": "EnhancedHybridPSOSA", "description": "Introduced an adaptive cooling rate and varied inertia weight dynamically for enhanced exploration-exploitation in EnhancedHybridPSOSA.", "configspace": "", "generation": 11, "fitness": 0.7948203821304828, "feedback": "The algorithm EnhancedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.795 with standard deviation 0.013. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "df838f95-05cb-40dd-9c2d-f835222873e4", "metadata": {"aucs": [0.783264593854031, 0.8123838325638024, 0.7888127199736149], "final_y": [0.16064762439781133, 0.13954180441322117, 0.1443830836448995]}, "mutation_prompt": null}
{"id": "9b10de51-fb3d-4796-807b-ddaed9690d5f", "solution": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.95  # Adjusted cooling rate for improved temperature decay\n        self.initial_w = 0.9\n        self.max_w = 0.9\n        self.min_w = 0.4\n        self.c1 = 2.0\n        self.c2 = 1.0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        temperature = self.initial_temperature\n        w = self.initial_w\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            progress_ratio = evaluations / self.budget\n            w = self.max_w - progress_ratio * (self.max_w - self.min_w)\n            \n            adaptive_scale = (ub - lb) * (1 - progress_ratio / 2)\n            V = w * V + self.c1 * r1 * (personal_best - X) + self.c2 * r2 * (global_best - X)\n            X = np.clip(X + V * adaptive_scale, lb, ub)\n\n            mutation_strength = 0.3 * (1 - progress_ratio)\n\n            for i in range(self.population_size):\n                candidate = X[i] + np.random.normal(0, mutation_strength, self.dim) * (ub - lb)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            temperature *= self.cooling_rate\n\n        return global_best", "name": "EnhancedHybridPSOSA", "description": "Introduced an adaptive velocity scaling mechanism and enhanced mutation strategy for better exploration-exploitation balance in EnhancedHybridPSOSA.", "configspace": "", "generation": 11, "fitness": 0.8083457574148735, "feedback": "The algorithm EnhancedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.808 with standard deviation 0.012. And the mean value of best solutions found was 0.139 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "df838f95-05cb-40dd-9c2d-f835222873e4", "metadata": {"aucs": [0.824534898279087, 0.7963308790394001, 0.8041714949261329], "final_y": [0.14596272092668172, 0.14508052168813612, 0.12447312224343943]}, "mutation_prompt": null}
{"id": "5ffe36a2-b3ca-46fb-9fcd-36e7c8e3f037", "solution": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.97  # More gradual cooling\n        self.initial_w = 0.9  # Start with higher inertia weight\n        self.max_w = 0.9\n        self.min_w = 0.2  # Changed to allow wider inertia weight range\n        self.c1 = 2.0  # Enhanced to increase personal best attraction\n        self.c2 = 1.0  # Reduced to decrease global best attraction\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        temperature = self.initial_temperature\n        w = self.initial_w\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            progress_ratio = evaluations / self.budget\n            w = self.max_w - progress_ratio * (self.max_w - self.min_w)\n            \n            V = w * V + self.c1 * r1 * (personal_best - X) + self.c2 * r2 * (global_best - X)\n            X = np.clip(X + V, lb, ub)\n\n            # Adaptive mutation strength\n            mutation_strength = 0.6 * (1 - progress_ratio)  # Adjusted mutation strength\n\n            for i in range(self.population_size):\n                candidate = X[i] + np.random.uniform(-mutation_strength, mutation_strength, self.dim) * (ub - lb)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            temperature *= self.cooling_rate\n\n        return global_best", "name": "EnhancedHybridPSOSA", "description": "Adjusted inertia weight decay for improved convergence in EnhancedHybridPSOSA.", "configspace": "", "generation": 12, "fitness": 0.7892257145753859, "feedback": "The algorithm EnhancedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.789 with standard deviation 0.021. And the mean value of best solutions found was 0.140 (0. is the best) with standard deviation 0.024.", "error": "", "parent_id": "df838f95-05cb-40dd-9c2d-f835222873e4", "metadata": {"aucs": [0.7943498658379798, 0.8122534609404028, 0.7610738169477751], "final_y": [0.12587484419386885, 0.11977359436926738, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "64d675bf-a731-4c99-a1ea-b48e5bbea91f", "solution": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.97  # More gradual cooling\n        self.initial_w = 0.9  # Start with higher inertia weight\n        self.max_w = 0.9\n        self.min_w = 0.4\n        self.c1 = 2.0  # Enhanced to increase personal best attraction\n        self.c2 = 1.0  # Reduced to decrease global best attraction\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        temperature = self.initial_temperature\n        w = self.initial_w\n        adaptive_pop_size = int(self.population_size * 1.2)  # Line changed\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            progress_ratio = evaluations / self.budget\n            w = self.max_w - progress_ratio * (self.max_w - self.min_w)\n            \n            current_c1 = self.c1 * (1 - progress_ratio)  # Line changed\n            current_c2 = self.c2 * progress_ratio  # Line changed\n            \n            V = w * V + current_c1 * r1 * (personal_best - X) + current_c2 * r2 * (global_best - X)  # Line changed\n            X = np.clip(X + V, lb, ub)\n\n            # Adaptive mutation strength\n            mutation_strength = 0.5 * (1 - progress_ratio)\n\n            for i in range(adaptive_pop_size):  # Line changed\n                candidate = X[i % self.population_size] + np.random.uniform(-mutation_strength, mutation_strength, self.dim) * (ub - lb)  # Line changed\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i % self.population_size]:  # Line changed\n                    personal_best[i % self.population_size] = candidate  # Line changed\n                    personal_best_values[i % self.population_size] = candidate_value  # Line changed\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i % self.population_size] - candidate_value) / temperature) > np.random.rand():\n                    personal_best[i % self.population_size] = candidate  # Line changed\n                    personal_best_values[i % self.population_size] = candidate_value  # Line changed\n\n            if evaluations >= self.budget:\n                break\n\n            temperature *= self.cooling_rate\n\n        return global_best", "name": "EnhancedHybridPSOSA", "description": "EnhancedHybridPSOSA with adaptive population size and dynamic c1/c2 to improve exploration-exploitation balance.", "configspace": "", "generation": 12, "fitness": 0.7902649666948749, "feedback": "The algorithm EnhancedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.790 with standard deviation 0.008. And the mean value of best solutions found was 0.143 (0. is the best) with standard deviation 0.015.", "error": "", "parent_id": "df838f95-05cb-40dd-9c2d-f835222873e4", "metadata": {"aucs": [0.7973048430066453, 0.7945901820562783, 0.7788998750217013], "final_y": [0.1242924263299775, 0.1601017669387199, 0.14464905667956696]}, "mutation_prompt": null}
{"id": "3c70951d-c23d-4ebc-a535-8f47ac401281", "solution": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.97  # More gradual cooling\n        self.initial_w = 0.9  # Start with higher inertia weight\n        self.max_w = 0.9\n        self.min_w = 0.4\n        self.c1 = 2.0  # Enhanced to increase personal best attraction\n        self.c2 = 1.0  # Reduced to decrease global best attraction\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        temperature = self.initial_temperature\n        w = self.initial_w\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            progress_ratio = evaluations / self.budget\n            w = self.max_w - progress_ratio * (self.max_w - self.min_w)\n            \n            V = w * V + self.c1 * r1 * (personal_best - X) + self.c2 * r2 * (global_best - X)\n            X = np.clip(X + V, lb, ub)\n\n            # Adaptive mutation strength\n            mutation_strength = 0.5 * (1 - progress_ratio)\n\n            for i in range(self.population_size):\n                candidate = X[i] + np.random.uniform(-mutation_strength, mutation_strength, self.dim) * (ub - lb)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            # Replace linear cooling with nonlinear cooling\n            temperature *= (self.cooling_rate + (0.02 * np.sin(progress_ratio * np.pi)))\n            \n            # Dynamic population size adjustment\n            if evaluations % (self.budget // 4) == 0:\n                self.population_size = int(self.population_size * (0.9 + 0.2 * np.random.rand()))\n\n        return global_best", "name": "EnhancedHybridPSOSA", "description": "Introduced a dynamic population size and nonlinear cooling to improve exploration-exploitation balance.", "configspace": "", "generation": 12, "fitness": 0.787179307100233, "feedback": "The algorithm EnhancedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.787 with standard deviation 0.019. And the mean value of best solutions found was 0.153 (0. is the best) with standard deviation 0.019.", "error": "", "parent_id": "df838f95-05cb-40dd-9c2d-f835222873e4", "metadata": {"aucs": [0.8058739222966459, 0.7945901820562783, 0.7610738169477751], "final_y": [0.12727152320134516, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "0a6fac7a-b914-43c8-882b-20d3206f7407", "solution": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.97  # More gradual cooling\n        self.initial_w = 0.9  # Start with higher inertia weight\n        self.max_w = 0.85  # Reduced maximum inertia weight\n        self.min_w = 0.4\n        self.c1 = 2.0  # Enhanced to increase personal best attraction\n        self.c2 = 1.0  # Reduced to decrease global best attraction\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        temperature = self.initial_temperature\n        w = self.initial_w\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            progress_ratio = evaluations / self.budget\n            w = self.max_w - progress_ratio * (self.max_w - self.min_w)\n            \n            V = w * V + self.c1 * r1 * (personal_best - X) + self.c2 * r2 * (global_best - X)\n            X = np.clip(X + V, lb, ub)\n\n            # Adaptive mutation strength\n            mutation_strength = 0.5 * (1 - progress_ratio)\n\n            for i in range(self.population_size):\n                candidate = X[i] + np.random.uniform(-mutation_strength, mutation_strength, self.dim) * (ub - lb)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            temperature *= self.cooling_rate\n\n        return global_best", "name": "EnhancedHybridPSOSA", "description": "Slightly reduced exploration by decreasing the maximum inertia weight in EnhancedHybridPSOSA.", "configspace": "", "generation": 12, "fitness": 0.7944216903450395, "feedback": "The algorithm EnhancedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.794 with standard deviation 0.004. And the mean value of best solutions found was 0.151 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "df838f95-05cb-40dd-9c2d-f835222873e4", "metadata": {"aucs": [0.7996455948258994, 0.7945901820562783, 0.789029294152941], "final_y": [0.14261764764801066, 0.1601017669387199, 0.1495793335621587]}, "mutation_prompt": null}
{"id": "f2da01c6-34f0-4579-baf9-8a7f5d7f17e0", "solution": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.97  # More gradual cooling\n        self.initial_w = 0.9  # Start with higher inertia weight\n        self.max_w = 0.9\n        self.min_w = 0.4\n        self.c1 = 2.0  # Enhanced to increase personal best attraction\n        self.c2 = 1.0  # Reduced to decrease global best attraction\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        temperature = self.initial_temperature\n        w = self.initial_w\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            progress_ratio = evaluations / self.budget\n            w = self.max_w - progress_ratio * (self.max_w - self.min_w)\n            \n            V = w * V + self.c1 * r1 * (personal_best - X) + self.c2 * r2 * (global_best - X)\n            X = np.clip(X + V, lb, ub)\n\n            # Adaptive mutation strength\n            mutation_strength = 0.6 * (1 - progress_ratio)  # Increased slightly\n\n            for i in range(self.population_size):\n                candidate = X[i] + np.random.uniform(-mutation_strength, mutation_strength, self.dim) * (ub - lb)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            temperature *= self.cooling_rate\n\n        return global_best", "name": "EnhancedHybridPSOSA", "description": "Slightly increased mutation strength to enhance exploration in EnhancedHybridPSOSA.", "configspace": "", "generation": 12, "fitness": 0.7889975023786988, "feedback": "The algorithm EnhancedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.789 with standard deviation 0.004. And the mean value of best solutions found was 0.149 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "df838f95-05cb-40dd-9c2d-f835222873e4", "metadata": {"aucs": [0.7842396693588533, 0.7945901820562783, 0.7881626557209648], "final_y": [0.1400436090292846, 0.1601017669387199, 0.14579844302579037]}, "mutation_prompt": null}
{"id": "819e16e4-b914-4e47-bc62-0cdc7d4aa592", "solution": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.97\n        self.initial_w = 0.9\n        self.max_w = 0.9\n        self.min_w = 0.4\n        self.c1 = 2.0\n        self.c2 = 1.0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        temperature = self.initial_temperature\n        w = self.initial_w\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            progress_ratio = evaluations / self.budget\n            w = self.max_w - (progress_ratio**2) * (self.max_w - self.min_w)  # Refined this line for smoother adaptation\n            \n            V = w * V + self.c1 * r1 * (personal_best - X) + self.c2 * r2 * (global_best - X)\n            X = np.clip(X + V, lb, ub)\n\n            mutation_strength = 0.5 * (1 - progress_ratio)\n\n            for i in range(self.population_size):\n                candidate = X[i] + np.random.uniform(-mutation_strength, mutation_strength, self.dim) * (ub - lb)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            temperature *= self.cooling_rate\n\n        return global_best", "name": "EnhancedHybridPSOSA", "description": "Further refined inertia weight adaptation to enhance convergence in EnhancedHybridPSOSA.", "configspace": "", "generation": 13, "fitness": 0.7868720413256955, "feedback": "The algorithm EnhancedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.787 with standard deviation 0.019. And the mean value of best solutions found was 0.158 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "df838f95-05cb-40dd-9c2d-f835222873e4", "metadata": {"aucs": [0.8049521249730331, 0.7945901820562783, 0.7610738169477751], "final_y": [0.14025576412226948, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "83ad8b5e-356a-4f0a-a5c3-7e9e1c7ecbb2", "solution": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.97  # More gradual cooling\n        self.initial_w = 0.9  # Start with higher inertia weight\n        self.max_w = 0.9\n        self.min_w = 0.4\n        self.c1 = 2.0  # Enhanced to increase personal best attraction\n        self.c2 = 1.1  # Slightly increased to enhance global best attraction\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        temperature = self.initial_temperature\n        w = self.initial_w\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            progress_ratio = evaluations / self.budget\n            w = self.max_w - progress_ratio * (self.max_w - self.min_w)\n            \n            V = w * V + self.c1 * r1 * (personal_best - X) + self.c2 * r2 * (global_best - X)\n            X = np.clip(X + V, lb, ub)\n\n            # Adaptive mutation strength\n            mutation_strength = 0.5 * (1 - progress_ratio)\n\n            for i in range(self.population_size):\n                candidate = X[i] + np.random.uniform(-mutation_strength, mutation_strength, self.dim) * (ub - lb)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            temperature *= self.cooling_rate\n\n        return global_best", "name": "EnhancedHybridPSOSA", "description": "Improved convergence by slightly increasing the global best attraction coefficient in EnhancedHybridPSOSA.", "configspace": "", "generation": 13, "fitness": 0.7942402180274567, "feedback": "The algorithm EnhancedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.794 with standard deviation 0.017. And the mean value of best solutions found was 0.146 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "df838f95-05cb-40dd-9c2d-f835222873e4", "metadata": {"aucs": [0.7733795938203061, 0.7945901820562783, 0.8147508782057856], "final_y": [0.14491897112422647, 0.1601017669387199, 0.13366897175398662]}, "mutation_prompt": null}
{"id": "e4009185-14d2-46a2-8442-2e9daae89462", "solution": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.97  # More gradual cooling\n        self.initial_w = 0.9  # Start with higher inertia weight\n        self.max_w = 0.9\n        self.min_w = 0.4\n        self.c1 = 2.0  # Enhanced to increase personal best attraction\n        self.c2 = 1.0  # Reduced to decrease global best attraction\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        temperature = self.initial_temperature\n        w = self.initial_w\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            progress_ratio = evaluations / self.budget\n            w = self.max_w - progress_ratio * (self.max_w - self.min_w)\n            \n            # Adaptive learning factors\n            c1 = 2.5 - progress_ratio * 1.5\n            c2 = 0.5 + progress_ratio * 1.5\n\n            V = w * V + c1 * r1 * (personal_best - X) + c2 * r2 * (global_best - X)\n            X = np.clip(X + V, lb, ub)\n\n            # Adaptive mutation strength\n            mutation_strength = 0.5 * (1 - progress_ratio)\n\n            for i in range(self.population_size):\n                candidate = X[i] + np.random.uniform(-mutation_strength, mutation_strength, self.dim) * (ub - lb)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            temperature *= self.cooling_rate\n\n        return global_best", "name": "EnhancedHybridPSOSA", "description": "Implemented learning factor adaptation to dynamically adjust cognitive and social coefficients in EnhancedHybridPSOSA.", "configspace": "", "generation": 13, "fitness": 0.8287015292542165, "feedback": "The algorithm EnhancedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.829 with standard deviation 0.017. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "df838f95-05cb-40dd-9c2d-f835222873e4", "metadata": {"aucs": [0.8381855319953753, 0.8434608904356746, 0.8044581653315993], "final_y": [0.11632269941837425, 0.11876301623057617, 0.1257040849890262]}, "mutation_prompt": null}
{"id": "5b8ab63a-d063-4068-8d5d-b41c7c087acb", "solution": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.97  # More gradual cooling\n        self.initial_w = 0.9  # Start with higher inertia weight\n        self.max_w = 0.9\n        self.min_w = 0.4\n        self.c1 = 2.0  # Enhanced to increase personal best attraction\n        self.c2 = 1.0  # Reduced to decrease global best attraction\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        temperature = self.initial_temperature\n        w = self.initial_w\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            progress_ratio = evaluations / self.budget\n            w = self.max_w - progress_ratio * (self.max_w - self.min_w)\n            \n            V = w * V + self.c1 * r1 * (personal_best - X) + self.c2 * r2 * (global_best - X)\n            X = np.clip(X + V, lb, ub)\n\n            # Adaptive mutation strength\n            mutation_strength = 0.6 * (1 - progress_ratio)  # Slightly increased decay rate\n\n            for i in range(self.population_size):\n                candidate = X[i] + np.random.uniform(-mutation_strength, mutation_strength, self.dim) * (ub - lb)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            temperature *= self.cooling_rate\n\n        return global_best", "name": "EnhancedHybridPSOSA", "description": "Enhanced exploration-exploitation by slightly increasing mutation strength decay rate in EnhancedHybridPSOSA.", "configspace": "", "generation": 13, "fitness": 0.7899675503538489, "feedback": "The algorithm EnhancedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.790 with standard deviation 0.009. And the mean value of best solutions found was 0.146 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "df838f95-05cb-40dd-9c2d-f835222873e4", "metadata": {"aucs": [0.7773403895821641, 0.7945901820562783, 0.7979720794231042], "final_y": [0.13860783029397694, 0.1601017669387199, 0.1393550351769759]}, "mutation_prompt": null}
{"id": "85fb8168-c311-4aa8-a113-08c586e62ea6", "solution": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.97  # More gradual cooling\n        self.initial_w = 0.9  # Start with higher inertia weight\n        self.max_w = 0.8  # Adjusted max inertia weight for better convergence\n        self.min_w = 0.4\n        self.c1 = 2.0  # Enhanced to increase personal best attraction\n        self.c2 = 1.0  # Reduced to decrease global best attraction\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        temperature = self.initial_temperature\n        w = self.initial_w\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            progress_ratio = evaluations / self.budget\n            w = self.max_w - progress_ratio * (self.max_w - self.min_w)\n            \n            V = w * V + self.c1 * r1 * (personal_best - X) + self.c2 * r2 * (global_best - X)\n            X = np.clip(X + V, lb, ub)\n\n            # Adaptive mutation strength\n            mutation_strength = 0.5 * (1 - progress_ratio)\n\n            for i in range(self.population_size):\n                candidate = X[i] + np.random.uniform(-mutation_strength, mutation_strength, self.dim) * (ub - lb)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            temperature *= self.cooling_rate\n\n        return global_best", "name": "EnhancedHybridPSOSA", "description": "Enhanced convergence by fine-tuning the dynamic inertia weight range.", "configspace": "", "generation": 13, "fitness": 0.8141842024865257, "feedback": "The algorithm EnhancedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.814 with standard deviation 0.016. And the mean value of best solutions found was 0.141 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "df838f95-05cb-40dd-9c2d-f835222873e4", "metadata": {"aucs": [0.8333069824655901, 0.7945901820562783, 0.8146554429377086], "final_y": [0.1362615871174433, 0.1601017669387199, 0.12648844174052032]}, "mutation_prompt": null}
{"id": "1c53ffa6-6b6f-42e4-a04c-a7d5a64ea605", "solution": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.97  # More gradual cooling\n        self.initial_w = 0.9  # Start with higher inertia weight\n        self.max_w = 0.9\n        self.min_w = 0.4\n        self.c1 = 2.0  # Enhanced to increase personal best attraction\n        self.c2 = 1.0  # Reduced to decrease global best attraction\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        temperature = self.initial_temperature\n        w = self.initial_w\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            progress_ratio = evaluations / self.budget\n            w = self.max_w - (progress_ratio ** 2) * (self.max_w - self.min_w)  # Adjusted inertia weight\n\n            # Adaptive learning factors\n            c1 = 2.5 - progress_ratio * 1.5\n            c2 = 0.5 + progress_ratio * 1.5\n\n            V = w * V + c1 * r1 * (personal_best - X) + c2 * r2 * (global_best - X)\n            X = np.clip(X + V, lb, ub)\n\n            # Adaptive mutation strength\n            mutation_strength = 0.5 * (1 - progress_ratio)\n\n            for i in range(self.population_size):\n                candidate = X[i] + np.random.uniform(-mutation_strength, mutation_strength, self.dim) * (ub - lb)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            temperature *= self.cooling_rate\n\n        return global_best", "name": "EnhancedHybridPSOSA", "description": "Enhanced the balance between exploration and exploitation by tweaking the inertia weight update formula in EnhancedHybridPSOSA.", "configspace": "", "generation": 14, "fitness": 0.7958258083431407, "feedback": "The algorithm EnhancedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.796 with standard deviation 0.010. And the mean value of best solutions found was 0.139 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "e4009185-14d2-46a2-8442-2e9daae89462", "metadata": {"aucs": [0.7860816993274778, 0.8099286827224392, 0.791467042979505], "final_y": [0.13994348579961058, 0.14285923501576503, 0.13437195330834328]}, "mutation_prompt": null}
{"id": "93854682-308b-4dbb-9824-fc586d8eb348", "solution": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.97  # More gradual cooling\n        self.initial_w = 0.9  # Start with higher inertia weight\n        self.max_w = 0.9\n        self.min_w = 0.4\n        self.c1 = 2.0  # Enhanced to increase personal best attraction\n        self.c2 = 1.0  # Reduced to decrease global best attraction\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        temperature = self.initial_temperature\n        w = self.initial_w\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            progress_ratio = evaluations / self.budget\n            w = self.max_w - progress_ratio * (self.max_w - self.min_w)\n            \n            # Adaptive learning factors\n            c1 = 2.5 - progress_ratio * 1.5\n            c2 = 0.5 + progress_ratio * 1.5\n\n            V = w * V + c1 * r1 * (personal_best - X) + c2 * r2 * (global_best - X)\n            X = np.clip(X + V, lb, ub)\n\n            # Adaptive mutation strength\n            mutation_strength = 0.5 * progress_ratio  # Change to increase strength towards the end\n\n            for i in range(self.population_size):\n                candidate = X[i] + np.random.uniform(-mutation_strength, mutation_strength, self.dim) * (ub - lb)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            temperature *= self.cooling_rate\n\n        return global_best", "name": "EnhancedHybridPSOSA", "description": "Enhanced exploration by increasing mutation strength towards the end of the optimization process.", "configspace": "", "generation": 14, "fitness": 0.8120530446484877, "feedback": "The algorithm EnhancedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.812 with standard deviation 0.014. And the mean value of best solutions found was 0.143 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "e4009185-14d2-46a2-8442-2e9daae89462", "metadata": {"aucs": [0.8282614556540786, 0.7945901820562783, 0.8133074962351063], "final_y": [0.13986161980072243, 0.1601017669387199, 0.1287349090125991]}, "mutation_prompt": null}
{"id": "e1dd4248-9617-4eb1-9688-8e0a878abfbf", "solution": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.975  # Slightly faster cooling rate\n        self.initial_w = 0.9  # Start with higher inertia weight\n        self.max_w = 0.9\n        self.min_w = 0.4\n        self.c1 = 2.0  # Enhanced to increase personal best attraction\n        self.c2 = 1.0  # Reduced to decrease global best attraction\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        temperature = self.initial_temperature\n        w = self.initial_w\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            progress_ratio = evaluations / self.budget\n            w = self.max_w - progress_ratio * (self.max_w - self.min_w)\n            \n            # Adaptive learning factors\n            c1 = 2.5 - progress_ratio * 1.5\n            c2 = 0.5 + progress_ratio * 1.5\n\n            V = w * V + c1 * r1 * (personal_best - X) + c2 * r2 * (global_best - X)\n            X = np.clip(X + V, lb, ub)\n\n            # Adaptive mutation strength\n            mutation_strength = 0.5 * (1 - progress_ratio)\n\n            for i in range(self.population_size):\n                candidate = X[i] + np.random.uniform(-mutation_strength, mutation_strength, self.dim) * (ub - lb)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            temperature *= self.cooling_rate\n\n        return global_best", "name": "EnhancedHybridPSOSA", "description": "Improved convergence by slightly increasing the cooling rate for faster adaptation.", "configspace": "", "generation": 14, "fitness": 0.8051590680134714, "feedback": "The algorithm EnhancedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.805 with standard deviation 0.013. And the mean value of best solutions found was 0.130 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "e4009185-14d2-46a2-8442-2e9daae89462", "metadata": {"aucs": [0.7916992139452423, 0.8230396444020665, 0.8007383456931054], "final_y": [0.13401027839627122, 0.12714489413824825, 0.12814810197620985]}, "mutation_prompt": null}
{"id": "56ba2550-b463-4a4f-b5eb-301ffc46c189", "solution": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.97  # More gradual cooling\n        self.initial_w = 0.9  # Start with higher inertia weight\n        self.max_w = 0.9\n        self.min_w = 0.4\n        self.c1 = 2.0  # Enhanced to increase personal best attraction\n        self.c2 = 1.0  # Reduced to decrease global best attraction\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        temperature = self.initial_temperature\n        w = self.initial_w\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            progress_ratio = evaluations / self.budget\n            w = self.max_w * ((1 - progress_ratio) ** 2) + self.min_w * (progress_ratio ** 2)  # Nonlinear inertia adjustment\n            \n            # Adaptive learning factors\n            c1 = 2.5 - progress_ratio * 1.5\n            c2 = 0.5 + progress_ratio * 1.5\n\n            V = w * V + c1 * r1 * (personal_best - X) + c2 * r2 * (global_best - X)\n            X = np.clip(X + V, lb, ub)\n\n            # Enhanced mutation strategy\n            mutation_strength = 0.5 * (1 - progress_ratio)\n\n            for i in range(self.population_size):\n                candidate = X[i] + np.random.standard_normal(self.dim) * mutation_strength * (ub - lb)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            temperature *= self.cooling_rate\n\n        return global_best", "name": "EnhancedHybridPSOSA", "description": "Introduced nonlinear inertia weight adjustment and enhanced the mutation strategy for improved exploration-exploitation balance.", "configspace": "", "generation": 14, "fitness": 0.807376263109998, "feedback": "The algorithm EnhancedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.807 with standard deviation 0.028. And the mean value of best solutions found was 0.134 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "e4009185-14d2-46a2-8442-2e9daae89462", "metadata": {"aucs": [0.7722433023263615, 0.841117448250199, 0.8087680387534334], "final_y": [0.14905472116562102, 0.13181395585967626, 0.12143051645675773]}, "mutation_prompt": null}
{"id": "318d25db-eef4-44cc-a87d-8956a878b2d8", "solution": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.97  # More gradual cooling\n        self.initial_w = 0.9  # Start with higher inertia weight\n        self.max_w = 0.9\n        self.min_w = 0.4\n        self.c1 = 2.0  # Enhanced to increase personal best attraction\n        self.c2 = 1.0  # Reduced to decrease global best attraction\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        temperature = self.initial_temperature\n        w = self.initial_w\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            progress_ratio = evaluations / self.budget\n            w = self.max_w - (progress_ratio**2) * (self.max_w - self.min_w)  # Non-linear reduction\n            \n            # Adaptive learning factors\n            c1 = 2.5 - progress_ratio * 1.5\n            c2 = 0.5 + progress_ratio * 1.5\n\n            V = w * V + c1 * r1 * (personal_best - X) + c2 * r2 * (global_best - X)\n            X = np.clip(X + V, lb, ub)\n\n            # Adaptive mutation strength\n            mutation_strength = 0.5 * (1 - progress_ratio)\n\n            for i in range(self.population_size):\n                candidate = X[i] + np.random.uniform(-mutation_strength, mutation_strength, self.dim) * (ub - lb)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            temperature *= self.cooling_rate\n\n        return global_best", "name": "EnhancedHybridPSOSA", "description": "Introduced non-linear inertia weight reduction for improved exploration-exploitation balance in EnhancedHybridPSOSA.", "configspace": "", "generation": 14, "fitness": 0.8228806064184965, "feedback": "The algorithm EnhancedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.823 with standard deviation 0.020. And the mean value of best solutions found was 0.132 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "e4009185-14d2-46a2-8442-2e9daae89462", "metadata": {"aucs": [0.7940984460889142, 0.8384337197069585, 0.8361096534596169], "final_y": [0.13299066043564622, 0.14118104281720356, 0.12117227339795889]}, "mutation_prompt": null}
{"id": "d9fab572-5052-4161-9a6a-4b5f401fbebe", "solution": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.97  # More gradual cooling\n        self.initial_w = 0.9  # Start with higher inertia weight\n        self.max_w = 0.9\n        self.min_w = 0.4\n        self.c1 = 2.0  # Enhanced to increase personal best attraction\n        self.c2 = 1.0  # Reduced to decrease global best attraction\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        temperature = self.initial_temperature\n        w = self.initial_w\n\n        while evaluations < self.budget:\n            # Dynamic population resizing\n            self.population_size = int(40 + 10 * (1 - evaluations / self.budget))\n            r1, r2 = np.random.rand(2)\n            progress_ratio = evaluations / self.budget\n            w = self.max_w - progress_ratio * (self.max_w - self.min_w)\n            \n            # Adaptive learning factors\n            c1 = 2.5 - progress_ratio * 1.5\n            c2 = 0.5 + progress_ratio * 1.5\n\n            V = w * V + c1 * r1 * (personal_best - X) + c2 * r2 * (global_best - X)\n            X = np.clip(X + V, lb, ub)\n\n            # Adaptive mutation strength\n            mutation_strength = 0.5 * (1 - progress_ratio)\n\n            for i in range(self.population_size):\n                candidate = X[i] + np.random.uniform(-mutation_strength, mutation_strength, self.dim) * (ub - lb)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            temperature *= self.cooling_rate\n\n        return global_best", "name": "EnhancedHybridPSOSA", "description": "EnhancedHybridPSOSA with dynamic population resizing based on progress ratio for improved exploration-exploitation balance.", "configspace": "", "generation": 15, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 40 is out of bounds for axis 0 with size 40').", "error": "IndexError('index 40 is out of bounds for axis 0 with size 40')", "parent_id": "e4009185-14d2-46a2-8442-2e9daae89462", "metadata": {}, "mutation_prompt": null}
{"id": "4023d1ad-75ff-4dc9-b088-883ca935c90d", "solution": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.97  # More gradual cooling\n        self.initial_w = 0.9  # Start with higher inertia weight\n        self.max_w = 0.9\n        self.min_w = 0.4\n        self.c1 = 2.0  # Enhanced to increase personal best attraction\n        self.c2 = 1.0  # Reduced to decrease global best attraction\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        temperature = self.initial_temperature\n        w = self.initial_w\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            progress_ratio = evaluations / self.budget\n            w = self.max_w - progress_ratio * (self.max_w - self.min_w)\n            \n            # Adaptive learning factors\n            c1 = 2.5 - progress_ratio * 1.5\n            c2 = 0.5 + progress_ratio * 1.5\n\n            V = w * V + c1 * r1 * (personal_best - X) + c2 * r2 * (global_best - X)\n            X = np.clip(X + V, lb, ub)\n\n            # Adaptive mutation strength\n            mutation_strength = 0.3 * (1 - progress_ratio)  # Made more dynamic\n\n            for i in range(self.population_size):\n                candidate = X[i] + np.random.uniform(-mutation_strength, mutation_strength, self.dim) * (ub - lb)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            temperature *= self.cooling_rate\n            V += np.random.normal(0, 0.1, V.shape)  # Added velocity perturbation\n\n        return global_best", "name": "EnhancedHybridPSOSA", "description": "Enhanced the exploitation-exploration balance by adjusting mutation strength more dynamically and incorporating velocity perturbation.", "configspace": "", "generation": 15, "fitness": 0.8296456848078723, "feedback": "The algorithm EnhancedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.830 with standard deviation 0.009. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "e4009185-14d2-46a2-8442-2e9daae89462", "metadata": {"aucs": [0.8195214389450638, 0.8412471216808022, 0.8281684937977505], "final_y": [0.12477570004673166, 0.1255207005245893, 0.13344048086891103]}, "mutation_prompt": null}
{"id": "a131b7b8-442a-4323-9ef6-61b7cfb0ce27", "solution": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.97  # More gradual cooling\n        self.initial_w = 0.9  # Start with higher inertia weight\n        self.max_w = 0.9\n        self.min_w = 0.4\n        self.c1 = 2.0  # Enhanced to increase personal best attraction\n        self.c2 = 1.0  # Reduced to decrease global best attraction\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        temperature = self.initial_temperature\n        w = self.initial_w\n\n        while evaluations < self.budget:\n            # Dynamic population size adjustment\n            self.population_size = max(20, int(40 * (1 - evaluations / self.budget)))\n\n            r1, r2 = np.random.rand(2)\n            progress_ratio = evaluations / self.budget\n            w = self.max_w - progress_ratio * (self.max_w - self.min_w)\n            \n            # Adaptive learning factors\n            c1 = 2.5 - progress_ratio * 1.5\n            c2 = 0.5 + progress_ratio * 1.5\n\n            V = w * V + c1 * r1 * (personal_best - X) + c2 * r2 * (global_best - X)\n            X = np.clip(X + V, lb, ub)\n\n            # Adaptive mutation strength\n            mutation_strength = 0.5 * (1 - progress_ratio)\n\n            for i in range(self.population_size):\n                candidate = X[i] + np.random.uniform(-mutation_strength, mutation_strength, self.dim) * (ub - lb)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            temperature *= self.cooling_rate\n\n        return global_best", "name": "EnhancedHybridPSOSA", "description": "Introduced dynamic population size adjustment for improved exploration and exploitation balance in EnhancedHybridPSOSA.", "configspace": "", "generation": 15, "fitness": 0.8081866125819558, "feedback": "The algorithm EnhancedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.808 with standard deviation 0.013. And the mean value of best solutions found was 0.129 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "e4009185-14d2-46a2-8442-2e9daae89462", "metadata": {"aucs": [0.82332491937292, 0.8090464378890639, 0.7921884804838832], "final_y": [0.12065923593538275, 0.14167047409929368, 0.1252525014190644]}, "mutation_prompt": null}
{"id": "8b3131b7-a1db-4544-a7d3-486e032e9f42", "solution": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.97  # More gradual cooling\n        self.initial_w = 0.9  # Start with higher inertia weight\n        self.max_w = 0.9\n        self.min_w = 0.4\n        self.c1 = 2.0  # Enhanced to increase personal best attraction\n        self.c2 = 1.0  # Reduced to decrease global best attraction\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        temperature = self.initial_temperature\n        w = self.initial_w\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            progress_ratio = evaluations / self.budget\n            w = self.max_w - progress_ratio * (self.max_w - self.min_w)\n            \n            # Adaptive learning factors\n            c1 = 2.5 - progress_ratio * 1.5\n            c2 = 0.5 + progress_ratio * 1.5\n\n            V = w * V + c1 * r1 * (personal_best - X) + c2 * r2 * (global_best - X)\n            X = np.clip(X + V, lb, ub)\n\n            # Adaptive mutation strength\n            mutation_strength = 0.5 * (1 - progress_ratio)\n\n            for i in range(self.population_size):\n                candidate = X[i] + np.random.uniform(-mutation_strength, mutation_strength, self.dim) * (ub - lb)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            temperature *= (1 - progress_ratio**2)\n\n        return global_best", "name": "EnhancedHybridPSOSA", "description": "Modified cooling rate to a quadratic decay to enhance exploration in the EnhancedHybridPSOSA.", "configspace": "", "generation": 15, "fitness": 0.803477379024249, "feedback": "The algorithm EnhancedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.803 with standard deviation 0.032. And the mean value of best solutions found was 0.144 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "e4009185-14d2-46a2-8442-2e9daae89462", "metadata": {"aucs": [0.7621121691428232, 0.8080481601906537, 0.8402718077392703], "final_y": [0.15414926192674572, 0.1458389656193151, 0.13337600867538857]}, "mutation_prompt": null}
{"id": "02c19ca5-e19a-422f-be75-e637d84ca45d", "solution": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.97  # More gradual cooling\n        self.initial_w = 0.9  # Start with higher inertia weight\n        self.max_w = 0.9\n        self.min_w = 0.4\n        self.c1 = 2.0  # Enhanced to increase personal best attraction\n        self.c2 = 1.0  # Reduced to decrease global best attraction\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        temperature = self.initial_temperature\n        w = self.initial_w\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            progress_ratio = evaluations / self.budget\n            w = self.max_w - progress_ratio * (self.max_w - self.min_w)\n            \n            # Adaptive learning factors\n            c1 = 2.5 - progress_ratio * 1.5\n            c2 = 0.5 + progress_ratio * 1.5\n\n            # Dynamic population size adjustment\n            dynamic_population_size = int(self.population_size * (1 - progress_ratio))\n            V[:dynamic_population_size] = w * V[:dynamic_population_size] + c1 * r1 * (personal_best[:dynamic_population_size] - X[:dynamic_population_size]) + c2 * r2 * (global_best - X[:dynamic_population_size])\n            X[:dynamic_population_size] = np.clip(X[:dynamic_population_size] + V[:dynamic_population_size], lb, ub)\n\n            # Adaptive mutation strength\n            mutation_strength = 0.5 * (1 - progress_ratio)\n\n            for i in range(self.population_size):\n                candidate = X[i] + np.random.uniform(-mutation_strength, mutation_strength, self.dim) * (ub - lb)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            temperature *= self.cooling_rate\n\n        return global_best", "name": "EnhancedHybridPSOSA", "description": "Introducing a dynamic population size based on evaluations to improve exploration and exploitation balance.", "configspace": "", "generation": 15, "fitness": 0.8235218899841396, "feedback": "The algorithm EnhancedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.824 with standard deviation 0.023. And the mean value of best solutions found was 0.141 (0. is the best) with standard deviation 0.015.", "error": "", "parent_id": "e4009185-14d2-46a2-8442-2e9daae89462", "metadata": {"aucs": [0.824273799588473, 0.7945901820562783, 0.851701688307667], "final_y": [0.14021829129560548, 0.1601017669387199, 0.12388858679994907]}, "mutation_prompt": null}
{"id": "19ebdd2f-26ca-473d-b05b-8ad61e9ac660", "solution": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.95  # More gradual cooling\n        self.initial_w = 0.9  # Start with higher inertia weight\n        self.max_w = 0.9\n        self.min_w = 0.4\n        self.c1 = 2.0  # Enhanced to increase personal best attraction\n        self.c2 = 1.0  # Reduced to decrease global best attraction\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        temperature = self.initial_temperature\n        w = self.initial_w\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            progress_ratio = evaluations / self.budget\n            w = self.max_w - progress_ratio * (self.max_w - self.min_w)\n            \n            # Adaptive learning factors\n            c1 = 2.5 - progress_ratio * 1.5\n            c2 = 0.5 + progress_ratio * 1.5\n\n            V = w * V + c1 * r1 * (personal_best - X) + c2 * r2 * (global_best - X)\n            X = np.clip(X + V, lb, ub)\n\n            # Adaptive mutation strength\n            mutation_strength = 0.3 * (1 - progress_ratio)  # Made more dynamic\n\n            for i in range(self.population_size):\n                candidate = X[i] + np.random.uniform(-mutation_strength, mutation_strength, self.dim) * (ub - lb)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            temperature *= self.cooling_rate\n            V += np.random.normal(0, 0.1, V.shape)  # Added velocity perturbation\n\n        return global_best", "name": "EnhancedHybridPSOSA", "description": "Introduced a dynamic adjustment to cooling_rate for improved solution exploration.", "configspace": "", "generation": 16, "fitness": 0.7846534629533845, "feedback": "The algorithm EnhancedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.785 with standard deviation 0.017. And the mean value of best solutions found was 0.155 (0. is the best) with standard deviation 0.017.", "error": "", "parent_id": "4023d1ad-75ff-4dc9-b088-883ca935c90d", "metadata": {"aucs": [0.7982963898560999, 0.7945901820562783, 0.7610738169477751], "final_y": [0.13135265996525525, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "5a7aba0b-37f4-496a-808a-5b93b9c1f752", "solution": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.97  # More gradual cooling\n        self.initial_w = 0.9  # Start with higher inertia weight\n        self.max_w = 0.9\n        self.min_w = 0.4\n        self.c1 = 2.0  # Enhanced to increase personal best attraction\n        self.c2 = 1.0  # Reduced to decrease global best attraction\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        temperature = self.initial_temperature\n        w = self.initial_w\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            progress_ratio = evaluations / self.budget\n            w = self.max_w - progress_ratio * (self.max_w - self.min_w)\n            \n            # Adaptive learning factors\n            c1 = 2.5 - progress_ratio * 1.5\n            c2 = 0.5 + progress_ratio * 1.5\n\n            V = w * V + c1 * r1 * (personal_best - X) + c2 * r2 * (global_best - X)\n            X = np.clip(X + V, lb, ub)\n\n            # Adaptive mutation strength\n            mutation_strength = 0.3 * (1 - progress_ratio)  # Made more dynamic\n\n            for i in range(self.population_size):\n                candidate = X[i] + np.random.uniform(-mutation_strength, mutation_strength, self.dim) * (ub - lb)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            temperature *= self.cooling_rate\n            V += np.random.normal(0, 0.15, V.shape)  # Increased velocity perturbation\n\n        return global_best", "name": "EnhancedHybridPSOSA", "description": "Slightly increased the velocity perturbation to improve exploration capability of the algorithm.", "configspace": "", "generation": 16, "fitness": 0.8110320909859984, "feedback": "The algorithm EnhancedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.811 with standard deviation 0.049. And the mean value of best solutions found was 0.153 (0. is the best) with standard deviation 0.020.", "error": "", "parent_id": "4023d1ad-75ff-4dc9-b088-883ca935c90d", "metadata": {"aucs": [0.8774322739539419, 0.7945901820562783, 0.7610738169477751], "final_y": [0.12641907555977228, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "e0ffc597-0666-4254-b1a1-5beb4e6a2861", "solution": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.97\n        self.initial_w = 0.9\n        self.max_w = 0.9\n        self.min_w = 0.4\n        self.c1 = 2.0\n        self.c2 = 1.0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        temperature = self.initial_temperature\n        w = self.initial_w\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            progress_ratio = evaluations / self.budget\n            w = self.max_w - progress_ratio * (self.max_w - self.min_w)\n            \n            # Adaptive learning factors\n            c1 = 2.5 - progress_ratio * 1.5\n            c2 = 0.5 + progress_ratio * 1.5\n\n            V = w * V + c1 * r1 * (personal_best - X) + c2 * r2 * (global_best - X)\n            X = np.clip(X + V, lb, ub)\n\n            # Improved adaptive mutation strength\n            mutation_strength = 0.3 * (1 - progress_ratio)**2\n\n            for i in range(self.population_size):\n                candidate = X[i] + np.random.uniform(-mutation_strength, mutation_strength, self.dim) * (ub - lb)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            temperature *= self.cooling_rate\n            V += np.random.normal(0, 0.1, V.shape)\n\n            # Dynamic population resizing\n            if np.random.rand() < 0.1:\n                self.population_size = max(10, int(self.population_size * 0.9))\n\n        return global_best", "name": "EnhancedHybridPSOSA", "description": "Improved adaptive mutation and dynamic population resizing enhance the exploration and exploitation balance.", "configspace": "", "generation": 16, "fitness": 0.8396589165492614, "feedback": "The algorithm EnhancedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.840 with standard deviation 0.030. And the mean value of best solutions found was 0.132 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "4023d1ad-75ff-4dc9-b088-883ca935c90d", "metadata": {"aucs": [0.7970361587166841, 0.860358710607084, 0.8615818803240161], "final_y": [0.1483145402397259, 0.12360859353741205, 0.12298101751616919]}, "mutation_prompt": null}
{"id": "8783762b-d9fd-430d-bcdb-c8984f380eab", "solution": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.97\n        self.initial_w = 0.9\n        self.max_w = 0.9\n        self.min_w = 0.4\n        self.c1 = 2.0\n        self.c2 = 1.0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        temperature = self.initial_temperature\n        w = self.initial_w\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            progress_ratio = evaluations / self.budget\n            w = self.max_w - progress_ratio * (self.max_w - self.min_w)\n            \n            c1 = 2.5 - progress_ratio * 1.5\n            c2 = 0.5 + progress_ratio * 1.5\n\n            V = w * V + c1 * r1 * (personal_best - X) + c2 * r2 * (global_best - X)\n            V *= (1 - progress_ratio)  # Adaptive velocity scaling\n            X = np.clip(X + V, lb, ub)\n\n            mutation_strength = 0.25 * (1 - progress_ratio)  # Refined strategy\n\n            for i in range(self.population_size):\n                candidate = X[i] + np.random.uniform(-mutation_strength, mutation_strength, self.dim) * (ub - lb)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            temperature *= self.cooling_rate\n            V += np.random.normal(0, 0.1, V.shape)\n\n        return global_best", "name": "EnhancedHybridPSOSA", "description": "Enhanced the balance further by introducing adaptive velocity scaling and refined mutation strategy.", "configspace": "", "generation": 16, "fitness": 0.8163736123841273, "feedback": "The algorithm EnhancedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.816 with standard deviation 0.040. And the mean value of best solutions found was 0.142 (0. is the best) with standard deviation 0.023.", "error": "", "parent_id": "4023d1ad-75ff-4dc9-b088-883ca935c90d", "metadata": {"aucs": [0.8550469462305356, 0.8330000739740713, 0.7610738169477751], "final_y": [0.11841615701192298, 0.1350637608513583, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "5867240c-2c5e-4a67-8746-7db84ef195e1", "solution": "import numpy as np\n\nclass EnhancedHybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40\n        self.initial_temperature = 100.0\n        self.cooling_rate = 0.97  # More gradual cooling\n        self.initial_w = 0.9  # Start with higher inertia weight\n        self.max_w = 0.9\n        self.min_w = 0.4\n        self.c1 = 2.0  # Enhanced to increase personal best attraction\n        self.c2 = 1.0  # Reduced to decrease global best attraction\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        V = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = X.copy()\n        personal_best_values = np.array([func(x) for x in X])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = np.min(personal_best_values)\n        \n        evaluations = self.population_size\n        temperature = self.initial_temperature\n        w = self.initial_w\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(2)\n            progress_ratio = evaluations / self.budget\n            w = self.max_w - progress_ratio * (self.max_w - self.min_w)\n            \n            # Adaptive learning factors\n            c1 = 2.5 - progress_ratio * 1.5\n            c2 = 0.5 + progress_ratio * 1.5\n\n            adaptive_scale = 1 + 0.1 * np.sin(progress_ratio * np.pi)  # Adaptive velocity scaling\n            V = adaptive_scale * (w * V + c1 * r1 * (personal_best - X) + c2 * r2 * (global_best - X))\n            X = np.clip(X + V, lb, ub)\n\n            # Adaptive mutation strength\n            mutation_strength = 0.3 * (1 - progress_ratio)  # Made more dynamic\n\n            for i in range(self.population_size):\n                candidate = X[i] + np.random.uniform(-mutation_strength, mutation_strength, self.dim) * (ub - lb)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_value = func(candidate)\n                evaluations += 1\n\n                if candidate_value < personal_best_values[i]:\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n                elif np.exp((personal_best_values[i] - candidate_value) / temperature) > np.random.rand():\n                    personal_best[i] = candidate\n                    personal_best_values[i] = candidate_value\n\n            if evaluations >= self.budget:\n                break\n\n            temperature *= self.cooling_rate\n            V += np.random.normal(0, 0.1, V.shape)  # Added velocity perturbation\n\n        return global_best", "name": "EnhancedHybridPSOSA", "description": "Introduced adaptive velocity scaling to further enhance global search capability and prevent premature convergence.", "configspace": "", "generation": 16, "fitness": 0.8266480480456962, "feedback": "The algorithm EnhancedHybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.827 with standard deviation 0.020. And the mean value of best solutions found was 0.129 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "4023d1ad-75ff-4dc9-b088-883ca935c90d", "metadata": {"aucs": [0.8058688290791814, 0.8530103423259887, 0.8210649727319181], "final_y": [0.13896186242223363, 0.12119318293997072, 0.12698480040439952]}, "mutation_prompt": null}
