{"id": "65b3a79f-6a08-4ccb-ba40-17955397a348", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            for i in range(population_size):\n                a, b, c = population[np.random.choice(range(population_size), 3, replace=False)]\n                mutant = ensure_bounds(a + np.random.rand() * (b - c), bounds)\n                cross_points = np.random.rand(self.dim) < 0.9\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population = population[:population_size//2]\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= cooling_rate\n        return best_solution, best_score\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Introducing a Multi-Scale Adaptive Search (MSAS) algorithm, combining differential evolution and simulated annealing for efficient exploration and exploitation in complex optimization landscapes.", "configspace": "", "generation": 0, "fitness": -Infinity, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 194, in initialize_single\n    new_individual = self.evaluate_fitness(new_individual)\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 288, in evaluate_fitness\n    updated_individual = self.f(individual, self.logger)\n  File \"/home/ian/LLaMEA/benchmarks/tuto_global_optimization_photonics/exp_photonic.py\", line 149, in evaluatePhotonic\n    algorithm(problem)\n  File \"<string>\", line 59, in __call__\n  File \"<string>\", line 20, in differential_evolution\nIndexError: index 91 is out of bounds for axis 0 with size 50\n.", "error": "IndexError('index 91 is out of bounds for axis 0 with size 50')Traceback (most recent call last):\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 194, in initialize_single\n    new_individual = self.evaluate_fitness(new_individual)\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 288, in evaluate_fitness\n    updated_individual = self.f(individual, self.logger)\n  File \"/home/ian/LLaMEA/benchmarks/tuto_global_optimization_photonics/exp_photonic.py\", line 149, in evaluatePhotonic\n    algorithm(problem)\n  File \"<string>\", line 59, in __call__\n  File \"<string>\", line 20, in differential_evolution\nIndexError: index 91 is out of bounds for axis 0 with size 50\n", "parent_id": null, "metadata": {}, "mutation_prompt": null}
{"id": "3a9aa6ec-06d6-47b2-82e6-b7b24e89a40f", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            for i in range(population_size):\n                try:\n                    a, b, c = population[np.random.choice(range(population_size), 3, replace=False)]\n                except IndexError:\n                    continue\n                mutant = ensure_bounds(a + np.random.rand() * (b - c), bounds)\n                cross_points = np.random.rand(self.dim) < 0.9\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population = population[:population_size//2]\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= cooling_rate * 0.95  # Slightly enhance cooling rate\n        return best_solution, best_score\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = int(8 * self.dim)  # Reduced population for efficiency\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.5  # Slightly higher initial temperature\n        cooling_rate = 0.88  # Enhanced cooling rate\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "EnhancedAdaptiveSearch", "description": "Enhanced Adaptive Search (EAS) combines Differential Evolution and Simulated Annealing with dynamic parameters and error handling for robust optimization.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 46 is out of bounds for axis 0 with size 40').", "error": "IndexError('index 46 is out of bounds for axis 0 with size 40')", "parent_id": "65b3a79f-6a08-4ccb-ba40-17955397a348", "metadata": {}, "mutation_prompt": null}
{"id": "ef862557-13df-47ab-ade6-216530b891b6", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)  # Ensure indices are within bounds\n                a, b, c = population[indices]\n                mutant = ensure_bounds(a + np.random.rand() * (b - c), bounds)\n                cross_points = np.random.rand(self.dim) < 0.9\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population = population[:population_size//2]\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= cooling_rate\n        return best_solution, best_score\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Introducing a refined Multi-Scale Adaptive Search (MSAS) algorithm with a safeguard to prevent out-of-bounds index errors during population selection.", "configspace": "", "generation": 2, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 91 is out of bounds for axis 0 with size 50').", "error": "IndexError('index 91 is out of bounds for axis 0 with size 50')", "parent_id": "65b3a79f-6a08-4ccb-ba40-17955397a348", "metadata": {}, "mutation_prompt": null}
{"id": "be5b97d4-d15b-434e-8909-c1543fd806d6", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            for i in range(population_size):\n                a, b, c = population[np.random.choice(range(population_size), 3, replace=False)]\n                mutant = ensure_bounds(a + np.random.uniform(0.5, 1.0) * (b - c), bounds)  # Adjusted mutation factor\n                cross_points = np.random.rand(self.dim) < 0.9\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            # Ensure a minimum population size\n            if len(population) > max(4 * self.dim, population_size // 2):\n                population = population[:population_size//2]\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= cooling_rate\n        return best_solution, best_score\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.95  # Slower cooling rate for finer search\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Enhanced Multi-Scale Adaptive Search (MSAS+) to improve handling of complex landscapes by refining population control and mutation strategies.", "configspace": "", "generation": 3, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 91 is out of bounds for axis 0 with size 50').", "error": "IndexError('index 91 is out of bounds for axis 0 with size 50')", "parent_id": "65b3a79f-6a08-4ccb-ba40-17955397a348", "metadata": {}, "mutation_prompt": null}
{"id": "2350a558-b87d-4828-aed1-cf20bdc59355", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            for i in range(population_size):\n                a, b, c = population[np.random.choice(range(population_size), 3, replace=False)]\n                mutant = ensure_bounds(a + np.random.rand() * (b - c), bounds)\n                cross_points = np.random.rand(self.dim) < 0.9\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > max(4, 4 * self.dim):\n                population = population[np.argsort([func(ind) for ind in population])][:population_size//2]\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (cooling_rate + np.random.rand() * 0.05)  # Adaptive cooling\n        return best_solution, best_score\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // (population_size * 2)  # Reduce generations to fit budget\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Enhanced Multi-Scale Adaptive Search with improved population handling and adaptive cooling for better convergence.", "configspace": "", "generation": 4, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 91 is out of bounds for axis 0 with size 50').", "error": "IndexError('index 91 is out of bounds for axis 0 with size 50')", "parent_id": "65b3a79f-6a08-4ccb-ba40-17955397a348", "metadata": {}, "mutation_prompt": null}
{"id": "e61a5903-c426-4d63-ab88-38dfae62c9a0", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                mutant = ensure_bounds(a + np.random.rand() * (b - c), bounds)\n                cross_points = np.random.rand(self.dim) < 0.9\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= cooling_rate\n        return best_solution, best_score\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "A refined Multi-Scale Adaptive Search (MSAS) algorithm using improved bounds handling and adaptive population reduction for robust optimization.", "configspace": "", "generation": 5, "fitness": 0.8056244358342668, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.806 with standard deviation 0.019. And the mean value of best solutions found was 0.194 (0. is the best) with standard deviation 0.016.", "error": "", "parent_id": "65b3a79f-6a08-4ccb-ba40-17955397a348", "metadata": {"aucs": [0.8319403921804174, 0.7960997101243409, 0.7888332051980421], "final_y": [0.17483511091030357, 0.1921709293756969, 0.21480558614387302]}, "mutation_prompt": null}
{"id": "45edb3fa-2624-4e1f-ac64-5c55e3f7d98d", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            mutation_factor = 0.8 + 0.2 * (generations - g) / generations  # Dynamic mutation factor\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                mutant = ensure_bounds(a + mutation_factor * (b - c), bounds)\n                cross_points = np.random.rand(self.dim) < 0.9\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= cooling_rate * (candidate_score / (current_score + 1e-6))  # Adaptive cooling rate\n        return best_solution, best_score\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Enhancing the MSAS algorithm by introducing dynamic mutation factor and adaptive cooling in simulated annealing to improve exploration and exploitation balance.", "configspace": "", "generation": 6, "fitness": 0.5996097444606823, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.600 with standard deviation 0.006. And the mean value of best solutions found was 0.311 (0. is the best) with standard deviation 0.017.", "error": "", "parent_id": "e61a5903-c426-4d63-ab88-38dfae62c9a0", "metadata": {"aucs": [0.593255127655647, 0.5985994628140924, 0.6069746429123073], "final_y": [0.3147123657615406, 0.2887040866865548, 0.32861538408161983]}, "mutation_prompt": null}
{"id": "d15def90-a3d9-4c8b-9f3d-fbba9343bc89", "solution": "import numpy as np\nfrom scipy.optimize import approx_fprime\nfrom joblib import Parallel, delayed\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            results = Parallel(n_jobs=-1)(delayed(self.evaluate_trial)(\n                i, population, bounds, func) for i in range(population_size))\n            for i, (trial, score) in enumerate(results):\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        return best_solution, best_score\n\n    def evaluate_trial(self, i, population, bounds, func):\n        indices = np.random.choice(range(population.shape[0]), 3, replace=False)\n        a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n        mutant = np.clip(a + np.random.rand() * (b - c), bounds.lb, bounds.ub)\n        cross_points = np.random.rand(self.dim) < 0.9\n        trial = np.where(cross_points, mutant, population[i])\n        score = func(trial)\n        return trial, score\n\n    def gradient_perturbation(self, solution, bounds, func):\n        epsilon = np.sqrt(np.finfo(float).eps)\n        gradient = approx_fprime(solution, func, epsilon)\n        perturbed_solution = solution - 0.01 * gradient\n        return np.clip(perturbed_solution, bounds.lb, bounds.ub)\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = self.gradient_perturbation(current_solution, bounds, func)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= cooling_rate\n        return best_solution, best_score\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Enhanced Multi-Scale Adaptive Search with parallel execution and gradient-informed local search for improved convergence.", "configspace": "", "generation": 7, "fitness": -Infinity, "feedback": "An exception occurred: AttributeError(\"'NoneType' object has no attribute 'flush'\").", "error": "AttributeError(\"'NoneType' object has no attribute 'flush'\")", "parent_id": "e61a5903-c426-4d63-ab88-38dfae62c9a0", "metadata": {}, "mutation_prompt": null}
{"id": "96830de5-ac2a-4ded-9a43-74cda03237ef", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                mutation_factor = 0.8 + 0.2 * np.random.rand()  # Adaptive mutation factor\n                mutant = ensure_bounds(a + mutation_factor * (b - c), bounds)\n                cross_points = np.random.rand(self.dim) < 0.9\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= cooling_rate\n        return best_solution, best_score\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Enhanced Multi-Scale Adaptive Search (EMSAS) with adaptive mutation factor in Differential Evolution for improved exploration.", "configspace": "", "generation": 8, "fitness": 0.6324184475609426, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.632 with standard deviation 0.079. And the mean value of best solutions found was 0.290 (0. is the best) with standard deviation 0.062.", "error": "", "parent_id": "e61a5903-c426-4d63-ab88-38dfae62c9a0", "metadata": {"aucs": [0.7206719498081566, 0.648492357121605, 0.5280910357530662], "final_y": [0.23168759313050202, 0.262720013046183, 0.37621849969285437]}, "mutation_prompt": null}
{"id": "fb507552-b274-44e3-ae1b-a590054caba1", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                mutant = ensure_bounds(a + np.random.rand() * (b - c), bounds)\n                cross_points = np.random.rand(self.dim) < 0.9\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= 0.95  # Adjusted cooling rate\n        return best_solution, best_score\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Improved local search by adjusting the cooling rate in Simulated Annealing (SA) for better exploration.", "configspace": "", "generation": 9, "fitness": 0.8059605360218517, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.806 with standard deviation 0.019. And the mean value of best solutions found was 0.194 (0. is the best) with standard deviation 0.017.", "error": "", "parent_id": "e61a5903-c426-4d63-ab88-38dfae62c9a0", "metadata": {"aucs": [0.8329186702810298, 0.796099710124342, 0.7888632276601832], "final_y": [0.17416305666826626, 0.1921709293756969, 0.21478028806937333]}, "mutation_prompt": null}
{"id": "e1055da6-fa01-4ec9-b400-1bbf39441762", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            mutation_factor = 0.5 + 0.3 * (g / generations)  # Dynamic mutation factor\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                mutant = ensure_bounds(a + mutation_factor * (b - c), bounds)  # Use mutation_factor\n                cross_points = np.random.rand(self.dim) < 0.9\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= 0.9 + 0.05 * np.random.rand()  # Dynamic cooling rate\n        return best_solution, best_score\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Introducing a variable mutation factor and dynamic cooling schedule to improve exploration and convergence.", "configspace": "", "generation": 10, "fitness": 0.6890270341887111, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.689 with standard deviation 0.032. And the mean value of best solutions found was 0.258 (0. is the best) with standard deviation 0.027.", "error": "", "parent_id": "fb507552-b274-44e3-ae1b-a590054caba1", "metadata": {"aucs": [0.6633375395503236, 0.734785779911578, 0.6689577831042315], "final_y": [0.2775900873459862, 0.22035294992704313, 0.2766174586864273]}, "mutation_prompt": null}
{"id": "fbf1e2d5-8502-46c9-990a-7fd1ad59d4b7", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                mutant = ensure_bounds(a + 0.8 * (b - c), bounds)  # Changed mutation factor\n                cross_points = np.random.rand(self.dim) < 0.9\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= 0.95  # Adjusted cooling rate\n        return best_solution, best_score\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Hybrid strategy utilizing Differential Evolution with enhanced mutation strategy for improved exploration.", "configspace": "", "generation": 11, "fitness": 0.5898840001853832, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.590 with standard deviation 0.020. And the mean value of best solutions found was 0.324 (0. is the best) with standard deviation 0.031.", "error": "", "parent_id": "fb507552-b274-44e3-ae1b-a590054caba1", "metadata": {"aucs": [0.5615078693166504, 0.6061713820823025, 0.6019727491571969], "final_y": [0.35739678983869794, 0.28357526234927655, 0.3318347096678145]}, "mutation_prompt": null}
{"id": "4682700d-2a0a-4f01-a3d6-fcfdbb34780d", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            if g % 10 == 0:  # Re-initialize the population periodically\n                population = np.random.rand(population_size, self.dim)\n                for i in range(population_size):\n                    population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                mutant = ensure_bounds(a + np.random.rand() * (b - c), bounds)\n                cross_points = np.random.rand(self.dim) < 0.9\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= 0.95  # Adjusted cooling rate\n        return best_solution, best_score\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Introduced periodic re-initialization in Differential Evolution for enhanced exploration in optimization.", "configspace": "", "generation": 12, "fitness": 0.6839870076594224, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.684 with standard deviation 0.007. And the mean value of best solutions found was 0.256 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "fb507552-b274-44e3-ae1b-a590054caba1", "metadata": {"aucs": [0.6853985832410534, 0.6916815756282046, 0.6748808641090093], "final_y": [0.26072507652929644, 0.24532359210224397, 0.26072759773469223]}, "mutation_prompt": null}
{"id": "b9e5e20f-5f4c-46be-a7fb-3fe1ae1564fe", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                mutant = ensure_bounds(a + 0.8 * (b - c), bounds)  # Changed mutation scaling factor\n                cross_points = np.random.rand(self.dim) < 0.9\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= 0.95\n        return best_solution, best_score\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Enhanced exploration by tuning mutation scaling factor in Differential Evolution (DE).", "configspace": "", "generation": 13, "fitness": 0.5898840001853832, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.590 with standard deviation 0.020. And the mean value of best solutions found was 0.324 (0. is the best) with standard deviation 0.031.", "error": "", "parent_id": "fb507552-b274-44e3-ae1b-a590054caba1", "metadata": {"aucs": [0.5615078693166504, 0.6061713820823025, 0.6019727491571969], "final_y": [0.35739678983869794, 0.28357526234927655, 0.3318347096678145]}, "mutation_prompt": null}
{"id": "b9bcb36a-9130-4e62-9df7-414b8e37cc6e", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            mutation_factor = 0.5 + (0.9 - 0.5) * (1 - g / generations)  # Adaptive mutation scaling\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                mutant = ensure_bounds(a + mutation_factor * (b - c), bounds)\n                cross_points = np.random.rand(self.dim) < 0.9\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= 0.95  # Adjusted cooling rate\n        return best_solution, best_score\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Integrate adaptive mutation scaling in Differential Evolution for improved exploration and exploitation balance.", "configspace": "", "generation": 14, "fitness": 0.6245097784454541, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.625 with standard deviation 0.012. And the mean value of best solutions found was 0.301 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "fb507552-b274-44e3-ae1b-a590054caba1", "metadata": {"aucs": [0.635674490009871, 0.6077667401120561, 0.6300881052144351], "final_y": [0.3027965444201194, 0.31092319250670797, 0.2881792020792122]}, "mutation_prompt": null}
{"id": "d0ad9469-00c6-4b10-a5c1-7cc142b0b435", "solution": "import numpy as np\nfrom concurrent.futures import ThreadPoolExecutor\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        def mutation(population, bounds):\n            indices = np.random.choice(range(population_size), 3, replace=False)\n            a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n            F = np.random.uniform(0.5, 1.0)  # Adaptive mutation rate\n            mutant = ensure_bounds(a + F * (b - c), bounds)\n            return mutant\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            with ThreadPoolExecutor() as executor:\n                futures = []\n                for i in range(population_size):\n                    futures.append(executor.submit(self.evaluate_trial, population, i, bounds, func, mutation))\n                for future in futures:\n                    trial, score, i = future.result()\n                    if score < best_score:\n                        best_score = score\n                        best_solution = trial\n                    if score < func(population[i]):\n                        population[i] = trial\n\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        return best_solution, best_score\n\n    def evaluate_trial(self, population, i, bounds, func, mutation):\n        mutant = mutation(population, bounds)\n        cross_points = np.random.rand(self.dim) < 0.9\n        trial = np.where(cross_points, mutant, population[i])\n        score = func(trial)\n        return trial, score, i\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= 0.95  # Adjusted cooling rate\n        return best_solution, best_score\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Integrate adaptive mutation rates and parallel execution to enhance exploration and speed in a hybrid Differential Evolution and Simulated Annealing algorithm.", "configspace": "", "generation": 15, "fitness": 0.6821127865272697, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.682 with standard deviation 0.004. And the mean value of best solutions found was 0.235 (0. is the best) with standard deviation 0.017.", "error": "", "parent_id": "fb507552-b274-44e3-ae1b-a590054caba1", "metadata": {"aucs": [0.6794805202953269, 0.6790987657674363, 0.6877590735190462], "final_y": [0.23020377859530694, 0.2584220422262663, 0.21708663219395608]}, "mutation_prompt": null}
{"id": "44863192-112f-49b1-a0b0-8214595b9e54", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                mutant = ensure_bounds(a + np.random.rand() * (b - c), bounds)\n                cross_points = np.random.rand(self.dim) < 0.9\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((best_score - candidate_score) / temp)  # Modified\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= 0.95  # Adjusted cooling rate\n        return best_solution, best_score\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Enhanced local search by modifying the acceptance probability in Simulated Annealing (SA) for better exploration.", "configspace": "", "generation": 16, "fitness": 0.8059605360218517, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.806 with standard deviation 0.019. And the mean value of best solutions found was 0.194 (0. is the best) with standard deviation 0.017.", "error": "", "parent_id": "fb507552-b274-44e3-ae1b-a590054caba1", "metadata": {"aucs": [0.8329186702810298, 0.796099710124342, 0.7888632276601832], "final_y": [0.17416305666826626, 0.1921709293756969, 0.21478028806937333]}, "mutation_prompt": null}
{"id": "28c706e5-09d7-47b3-93c4-12c0b22207fc", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                mutant = ensure_bounds(a + np.random.rand() * (b - c), bounds)\n                cross_points = np.random.rand(self.dim) < (0.9 * np.sin(g / generations * np.pi))\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.95 + 0.05 * np.log1p(best_score))\n        return best_solution, best_score\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Enhancing exploration by dynamic probabilistic selection in Differential Evolution (DE) and adaptive cooling in Simulated Annealing (SA).", "configspace": "", "generation": 17, "fitness": 0.8152715422882516, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.815 with standard deviation 0.034. And the mean value of best solutions found was 0.187 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "fb507552-b274-44e3-ae1b-a590054caba1", "metadata": {"aucs": [0.8469637772187039, 0.8299854965079081, 0.7688653531381426], "final_y": [0.17861300732280838, 0.18193415433155125, 0.2006052523002535]}, "mutation_prompt": null}
{"id": "45f7c74d-b91a-458b-93d0-bd9c9cc27c27", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            F = 0.5 + 0.5 * np.cos(g / generations * np.pi)  # Adjusted mutation factor\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                mutant = ensure_bounds(a + F * (b - c), bounds)  # Updated F value\n                cross_points = np.random.rand(self.dim) < (0.9 * np.sin(g / generations * np.pi))\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.95 + 0.1 * np.log1p(best_score))  # Adjusted dynamic cooling\n        return best_solution, best_score\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Refine exploration and exploitation balance by adjusting DE's mutation and introducing SA's dynamic cooling adaptation.", "configspace": "", "generation": 18, "fitness": 0.7741083008297661, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.774 with standard deviation 0.042. And the mean value of best solutions found was 0.197 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "28c706e5-09d7-47b3-93c4-12c0b22207fc", "metadata": {"aucs": [0.8207870015337696, 0.718106001542415, 0.783431899413114], "final_y": [0.18404965335708323, 0.21675820504809906, 0.18934326719395178]}, "mutation_prompt": null}
{"id": "ab533076-a6d4-494c-92ea-1677e6e7ab15", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                mutant = ensure_bounds(a + np.random.rand() * (b - c), bounds)\n                cross_points = np.random.rand(self.dim) < (0.9 * np.sin(g / generations * np.pi))\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        best_solution = self.local_search(best_solution, bounds, func)  # Added local search refinement\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.95 + 0.05 * np.tanh(best_score))  # Modified temperature scaling\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        # Simple local search to refine DE solutions\n        perturbation = np.random.uniform(-0.01, 0.01, self.dim)\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Introducing local search refinement post-DE and energy-aware temperature scaling in SA for improved solution quality.", "configspace": "", "generation": 19, "fitness": 0.8163551137891057, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.816 with standard deviation 0.034. And the mean value of best solutions found was 0.186 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "28c706e5-09d7-47b3-93c4-12c0b22207fc", "metadata": {"aucs": [0.8497334865558772, 0.8304586010928291, 0.7688732537186108], "final_y": [0.1766813936500332, 0.18158921244708914, 0.20059904020752695]}, "mutation_prompt": null}
{"id": "bb355812-84f6-4527-ae79-ae2676424f0e", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                mutant = ensure_bounds(a + np.random.rand() * (b - c), bounds)\n                cross_points = np.random.rand(self.dim) < (0.9 * np.sin(g / generations * np.pi))\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        best_solution = self.local_search(best_solution, bounds, func)  # Added local search refinement\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.95 + 0.05 * np.tanh(best_score))  # Modified temperature scaling\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        # Simple local search to refine DE solutions\n        perturbation = np.random.uniform(-0.02, 0.02, self.dim)\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Enhance local search by increasing perturbation range for improved solution refinement.", "configspace": "", "generation": 20, "fitness": 0.8163574682349233, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.816 with standard deviation 0.034. And the mean value of best solutions found was 0.186 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "ab533076-a6d4-494c-92ea-1677e6e7ab15", "metadata": {"aucs": [0.8497334865558772, 0.8304577973900457, 0.7688811207588468], "final_y": [0.1766813936500332, 0.18158981803885432, 0.2005928546780651]}, "mutation_prompt": null}
{"id": "26bb340b-2488-4f56-b994-d30dc1d046ad", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                mutant = ensure_bounds(a + np.random.rand() * (b - c), bounds)\n                cross_points = np.random.rand(self.dim) < (0.9 * np.sin(g / generations * np.pi))\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        best_solution = self.local_search(best_solution, bounds, func)  # Added local search refinement\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.96 + 0.04 * np.tanh(best_score))  # Modified temperature scaling (minor change)\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        # Simple local search to refine DE solutions\n        perturbation = np.random.uniform(-0.02, 0.02, self.dim)\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Implement selective cooling in simulated annealing to enhance convergence speed.", "configspace": "", "generation": 21, "fitness": 0.8164202615361283, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.816 with standard deviation 0.035. And the mean value of best solutions found was 0.186 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "bb355812-84f6-4527-ae79-ae2676424f0e", "metadata": {"aucs": [0.8497520036125963, 0.8306276602369427, 0.7688811207588464], "final_y": [0.1766687188424706, 0.18146749716522548, 0.2005928546780651]}, "mutation_prompt": null}
{"id": "2d4e7448-5c20-4a5f-ba26-7cc59f2497e8", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                F = 0.5 + 0.5 * (1 - g / generations)  # Dynamic mutation factor scaling\n                mutant = ensure_bounds(a + F * (b - c), bounds)\n                cross_points = np.random.rand(self.dim) < (0.9 * np.sin(g / generations * np.pi))\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        best_solution = self.local_search(best_solution, bounds, func)  # Added local search refinement\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.96 + 0.04 * np.tanh(best_score))  # Modified temperature scaling (minor change)\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        # Simple local search to refine DE solutions\n        perturbation = np.random.uniform(-0.02, 0.02, self.dim)\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Enhance convergence by introducing dynamic mutation factor scaling in differential evolution.", "configspace": "", "generation": 22, "fitness": 0.7031109551676056, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.703 with standard deviation 0.076. And the mean value of best solutions found was 0.249 (0. is the best) with standard deviation 0.047.", "error": "", "parent_id": "26bb340b-2488-4f56-b994-d30dc1d046ad", "metadata": {"aucs": [0.7300634081520148, 0.5989766616404378, 0.780292795710364], "final_y": [0.24650677926541087, 0.3077776539891586, 0.19388104594869715]}, "mutation_prompt": null}
{"id": "bb49b7f8-6e4b-415a-a226-a1aea272d699", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                mutant = ensure_bounds(a + np.random.rand() * (b - c), bounds)\n                cross_points = np.random.rand(self.dim) < (0.9 * np.sin(g / generations * np.pi))\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]) or np.random.rand() < 0.1:  # Probabilistic jump\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        best_solution = self.local_search(best_solution, bounds, func)  # Added local search refinement\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.96 + 0.04 * np.tanh(best_score))  # Modified temperature scaling (minor change)\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        # Simple local search to refine DE solutions\n        perturbation = np.random.uniform(-0.02, 0.02, self.dim)\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Introduce probabilistic jumping mechanism to avoid local optima during differential evolution.", "configspace": "", "generation": 23, "fitness": 0.7531714165242867, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.753 with standard deviation 0.036. And the mean value of best solutions found was 0.222 (0. is the best) with standard deviation 0.024.", "error": "", "parent_id": "26bb340b-2488-4f56-b994-d30dc1d046ad", "metadata": {"aucs": [0.763094823504153, 0.7048796863564883, 0.7915397397122187], "final_y": [0.2124454793670768, 0.2544591721631654, 0.19864283487300505]}, "mutation_prompt": null}
{"id": "ea388a41-1ffb-43c9-9cf6-8e8ffbc31a98", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            mutation_factor = 0.5 + 0.5 * np.cos(g / generations * np.pi)  # Adaptive mutation factor\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                mutant = ensure_bounds(a + mutation_factor * (b - c), bounds)\n                cross_points = np.random.rand(self.dim) < (0.9 * np.sin(g / generations * np.pi))\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        best_solution = self.local_search(best_solution, bounds, func)\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.96 + 0.04 * np.tanh(best_score))\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        perturbation = np.random.uniform(-0.02, 0.02, self.dim)\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Integrate a dynamic population size and adaptive mutation strategy within the differential evolution phase.", "configspace": "", "generation": 24, "fitness": 0.769923728058688, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.770 with standard deviation 0.038. And the mean value of best solutions found was 0.200 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "26bb340b-2488-4f56-b994-d30dc1d046ad", "metadata": {"aucs": [0.810647143943151, 0.7194948683609694, 0.7796291718719439], "final_y": [0.1915422648099131, 0.21558059701468923, 0.19218865359488102]}, "mutation_prompt": null}
{"id": "56c89b86-356a-4b58-b384-844f751b2d24", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                F = 0.5 + 0.3 * np.sin(g / generations * np.pi)  # Change 1: Adjust mutation factor\n                mutant = ensure_bounds(a + F * (b - c), bounds)  # Change 2: Use adjusted mutation factor\n                cross_points = np.random.rand(self.dim) < (0.9 * np.sin(g / generations * np.pi))\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        best_solution = self.local_search(best_solution, bounds, func)  # Added local search refinement\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.96 + 0.04 * np.tanh(best_score))  # Modified temperature scaling (minor change)\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        # Simple local search to refine DE solutions\n        perturbation = np.random.uniform(-0.02, 0.02, self.dim)\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Enhance exploration by adjusting mutation strategy in differential evolution.", "configspace": "", "generation": 25, "fitness": 0.6710913846539063, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.671 with standard deviation 0.063. And the mean value of best solutions found was 0.274 (0. is the best) with standard deviation 0.029.", "error": "", "parent_id": "26bb340b-2488-4f56-b994-d30dc1d046ad", "metadata": {"aucs": [0.6683189912405648, 0.5950654832041573, 0.749889679516997], "final_y": [0.27059685628487606, 0.31101861080237403, 0.24061292676564605]}, "mutation_prompt": null}
{"id": "5c356a00-b17f-4f5d-aadc-a4e8e7806aa6", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            adaptive_mutation_factor = 0.5 + 0.5 * np.sin(0.5 * np.pi * g / generations)  # Changed line\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                mutant = ensure_bounds(a + adaptive_mutation_factor * (b - c), bounds)\n                cross_points = np.random.rand(self.dim) < (0.9 * np.sin(g / generations * np.pi))\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        best_solution = self.local_search(best_solution, bounds, func)  # Added local search refinement\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.96 + 0.04 * np.tanh(best_score))  # Modified temperature scaling (minor change)\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        # Simple local search to refine DE solutions\n        perturbation = np.random.uniform(-0.02, 0.02, self.dim)\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Integrate adaptive mutation scaling in differential evolution to enhance exploration and exploitation balance.", "configspace": "", "generation": 26, "fitness": 0.6835356770464202, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.684 with standard deviation 0.044. And the mean value of best solutions found was 0.269 (0. is the best) with standard deviation 0.018.", "error": "", "parent_id": "26bb340b-2488-4f56-b994-d30dc1d046ad", "metadata": {"aucs": [0.6761537081757977, 0.6338070898667567, 0.7406462330967056], "final_y": [0.2670364183998616, 0.2928987172563481, 0.24833141367193157]}, "mutation_prompt": null}
{"id": "4b4a4442-613f-4360-837c-0f58e676c276", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                mutant = ensure_bounds(a + np.random.rand() * (b - c), bounds)\n                cross_points = np.random.rand(self.dim) < (0.9 * np.sin(g / generations * np.pi))\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        best_solution = self.local_search(best_solution, bounds, func)  # Added local search refinement\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.96 + 0.04 * np.tanh(best_score))  # Modified temperature scaling (minor change)\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        perturbation_scale = 0.01 * (1 + np.tanh(-func(solution) + 1))  # Dynamic perturbation scale\n        perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, self.dim)\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Enhance exploitation by adjusting local search perturbation scale dynamically based on solution progress.", "configspace": "", "generation": 27, "fitness": 0.8164184095306366, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.816 with standard deviation 0.035. And the mean value of best solutions found was 0.186 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "26bb340b-2488-4f56-b994-d30dc1d046ad", "metadata": {"aucs": [0.849749120907806, 0.8306276345882067, 0.7688784730958969], "final_y": [0.1766687188424706, 0.18146719457658445, 0.2005949319180087]}, "mutation_prompt": null}
{"id": "36cd60af-ae17-4b91-ac1f-cfa26e0def1e", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                F = 0.8 * (1 + np.tanh(generations - g))  # Adaptive mutation scaling\n                mutant = ensure_bounds(a + F * (b - c), bounds)\n                cross_points = np.random.rand(self.dim) < (0.9 * np.sin(g / generations * np.pi))\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        best_solution = self.local_search(best_solution, bounds, func)  # Added local search refinement\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.96 + 0.04 * np.tanh(best_score))  # Modified temperature scaling (minor change)\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        # Simple local search to refine DE solutions\n        perturbation = np.random.uniform(-0.02, 0.02, self.dim)\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Integrate adaptive mutation scaling in Differential Evolution to handle multiple local minima more effectively.", "configspace": "", "generation": 28, "fitness": 0.554297407296131, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.554 with standard deviation 0.028. And the mean value of best solutions found was 0.348 (0. is the best) with standard deviation 0.023.", "error": "", "parent_id": "26bb340b-2488-4f56-b994-d30dc1d046ad", "metadata": {"aucs": [0.5716734154699465, 0.576055021438411, 0.5151637849800355], "final_y": [0.32837641432075904, 0.33588785193654713, 0.37986533264463296]}, "mutation_prompt": null}
{"id": "4f071d26-b2f2-46c0-9bc1-98a633714d6c", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                F = 0.5 + 0.5 * np.sin(g / generations * np.pi)  # Adaptive mutation factor\n                mutant = ensure_bounds(a + F * (b - c), bounds)\n                cross_points = np.random.rand(self.dim) < (0.9 * np.sin(g / generations * np.pi))\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        best_solution = self.local_search(best_solution, bounds, func)  # Added local search refinement\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.96 + 0.04 * np.tanh(best_score))  # Modified temperature scaling (minor change)\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        # Simple local search to refine DE solutions\n        perturbation = np.random.uniform(-0.02, 0.02, self.dim)\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Integrate adaptive mutation strategy in differential evolution to improve exploration. ", "configspace": "", "generation": 29, "fitness": 0.6774726164889486, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.677 with standard deviation 0.079. And the mean value of best solutions found was 0.268 (0. is the best) with standard deviation 0.035.", "error": "", "parent_id": "26bb340b-2488-4f56-b994-d30dc1d046ad", "metadata": {"aucs": [0.717614169721265, 0.5665692720328397, 0.7482344077127414], "final_y": [0.23990399792538208, 0.31783077448815933, 0.24619992478777075]}, "mutation_prompt": null}
{"id": "1e7ec2f5-31a2-4cc3-b419-a2541ec32e69", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                F = 0.5 + 0.5 * np.sin(g / (2 * generations) * np.pi)  # Adaptive mutation factor\n                mutant = ensure_bounds(a + F * (b - c), bounds)\n                cross_points = np.random.rand(self.dim) < (0.9 * np.sin(g / generations * np.pi))\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        best_solution = self.local_search(best_solution, bounds, func)\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.96 + 0.04 * np.tanh(best_score))\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        gradients = np.random.uniform(-0.01, 0.01, self.dim)  # Gradient-like perturbation\n        refined_solution = np.clip(solution + gradients, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Enhance local search using gradient information and introduce adaptive mutation in the crossover stage to improve exploration.", "configspace": "", "generation": 30, "fitness": 0.683534587130763, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.684 with standard deviation 0.044. And the mean value of best solutions found was 0.269 (0. is the best) with standard deviation 0.018.", "error": "", "parent_id": "26bb340b-2488-4f56-b994-d30dc1d046ad", "metadata": {"aucs": [0.6761445836799329, 0.6337998543090453, 0.7406593234033108], "final_y": [0.26704596196196295, 0.2929070214514131, 0.24831859916518817]}, "mutation_prompt": null}
{"id": "2dcaf85e-8310-4cf9-b12f-52d904de133e", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                mutant = ensure_bounds(a + np.random.rand() * (b - c), bounds)\n                cross_points = np.random.rand(self.dim) < (0.8 + 0.2 * g / generations)  # Adjusted crossover rate\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        best_solution = self.local_search(best_solution, bounds, func)\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.96 + 0.04 * np.tanh(best_score))\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        perturbation = np.random.uniform(-0.02, 0.02, self.dim)\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Introduce dynamic adjustment of the crossover rate in differential evolution to enhance exploration.", "configspace": "", "generation": 31, "fitness": 0.8196731716538093, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.820 with standard deviation 0.012. And the mean value of best solutions found was 0.186 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "26bb340b-2488-4f56-b994-d30dc1d046ad", "metadata": {"aucs": [0.8322114857277603, 0.8042296196427433, 0.8225784095909245], "final_y": [0.18145259582280215, 0.19588560900970553, 0.17950869482946719]}, "mutation_prompt": null}
{"id": "fecc9acd-7cd7-4cbd-b28c-495ca33b9f70", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                F = 0.5 + 0.5 * (1 - g / generations)  # Adaptive mutation scaling\n                mutant = ensure_bounds(a + F * (b - c), bounds)\n                cross_points = np.random.rand(self.dim) < (0.8 + 0.2 * g / generations)\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        best_solution = self.local_search(best_solution, bounds, func)\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.96 + 0.04 * np.tanh(best_score))\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        perturbation = np.random.uniform(-0.02, 0.02, self.dim)\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Introduce adaptive mutation scaling in differential evolution to improve convergence.", "configspace": "", "generation": 32, "fitness": 0.5884343457182105, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.588 with standard deviation 0.007. And the mean value of best solutions found was 0.322 (0. is the best) with standard deviation 0.015.", "error": "", "parent_id": "2dcaf85e-8310-4cf9-b12f-52d904de133e", "metadata": {"aucs": [0.5834226976853116, 0.5839279716025085, 0.5979523678668116], "final_y": [0.3227490689154179, 0.3400465200274726, 0.30318224064955823]}, "mutation_prompt": null}
{"id": "4698bd9a-29b0-4cd1-a7d4-3b5da2dbee94", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n        adapt_factor = 0.5  # Adaptive mutation factor\n\n        for g in range(generations):\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                mutant = ensure_bounds(a + adapt_factor * (b - c), bounds)  # Adaptive mutation\n                cross_points = np.random.rand(self.dim) < (0.8 + 0.2 * g / generations)\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        best_solution = self.local_search(best_solution, bounds, func)\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.96 + 0.04 * np.tanh(best_score))\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        perturbation = np.random.uniform(-0.01, 0.01, self.dim)  # Focused local search\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Incorporate adaptive mutation and focused local search in differential evolution for enhanced convergence.", "configspace": "", "generation": 33, "fitness": 0.8175504507441745, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.818 with standard deviation 0.013. And the mean value of best solutions found was 0.185 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "2dcaf85e-8310-4cf9-b12f-52d904de133e", "metadata": {"aucs": [0.8205500195792157, 0.8002697962020928, 0.8318315364512152], "final_y": [0.18276666049844348, 0.18405733512529165, 0.1881267605921395]}, "mutation_prompt": null}
{"id": "2ef69f95-eca8-403c-873e-d6fa0a341237", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            diversity = np.mean(np.std(population, axis=0))\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                mutant = ensure_bounds(a + diversity * (b - c), bounds)  # Adaptive scaling factor\n                cross_points = np.random.rand(self.dim) < (0.8 + 0.2 * g / generations)  # Adjusted crossover rate\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        best_solution = self.local_search(best_solution, bounds, func)\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.96 + 0.04 * np.tanh(best_score))\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        perturbation = np.random.uniform(-0.02, 0.02, self.dim)\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Introduce adaptive scaling factor based on population diversity to improve convergence speed in differential evolution.", "configspace": "", "generation": 34, "fitness": 0.49383590176103676, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.494 with standard deviation 0.005. And the mean value of best solutions found was 0.409 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "2dcaf85e-8310-4cf9-b12f-52d904de133e", "metadata": {"aucs": [0.4949335150123221, 0.4878237508129456, 0.4987504394578427], "final_y": [0.4073425911909888, 0.41379549904142665, 0.4051421831226424]}, "mutation_prompt": null}
{"id": "97491203-4cd7-4f3b-b858-f62a3a6cea03", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                mutation_factor = 0.5 + 0.5 * g / generations  # Adjusted mutation factor\n                mutant = ensure_bounds(a + mutation_factor * (b - c), bounds)\n                cross_points = np.random.rand(self.dim) < (0.8 + 0.2 * g / generations)  # Adjusted crossover rate\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        best_solution = self.local_search(best_solution, bounds, func)\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.96 + 0.04 * np.tanh(best_score))\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        perturbation = np.random.uniform(-0.02, 0.02, self.dim)\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Enhance mutation strategy in differential evolution by incorporating an adaptive mutation factor for improved solution diversity.", "configspace": "", "generation": 35, "fitness": 0.7062395269544756, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.706 with standard deviation 0.013. And the mean value of best solutions found was 0.254 (0. is the best) with standard deviation 0.022.", "error": "", "parent_id": "2dcaf85e-8310-4cf9-b12f-52d904de133e", "metadata": {"aucs": [0.6914993935958463, 0.7232916050349447, 0.7039275822326356], "final_y": [0.2667107194163113, 0.22384831946586725, 0.2725339393595705]}, "mutation_prompt": null}
{"id": "cafc47a8-6503-43c0-83aa-4251077c9140", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            F = 0.5 + 0.5 * np.tanh(best_score)  # Dynamic mutation factor\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                mutant = ensure_bounds(a + F * (b - c), bounds)  # Use dynamic F\n                cross_points = np.random.rand(self.dim) < (0.8 + 0.2 * g / generations)  # Adjusted crossover rate\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n            if g % 10 == 0 and g > 0:  # Adaptive restart mechanism\n                population = np.clip(population + np.random.uniform(-0.1, 0.1, population.shape), bounds.lb, bounds.ub)\n        best_solution = self.local_search(best_solution, bounds, func)\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.96 + 0.04 * np.tanh(best_score))\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        perturbation = np.random.uniform(-0.02, 0.02, self.dim)\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Enhance convergence by integrating a dynamic mutation factor and adaptive restart mechanism in differential evolution.", "configspace": "", "generation": 36, "fitness": 0.7356714675171051, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.736 with standard deviation 0.060. And the mean value of best solutions found was 0.219 (0. is the best) with standard deviation 0.026.", "error": "", "parent_id": "2dcaf85e-8310-4cf9-b12f-52d904de133e", "metadata": {"aucs": [0.7311267682475847, 0.6642411589098497, 0.8116464753938809], "final_y": [0.20882290271183845, 0.25545680627473044, 0.19404760814991395]}, "mutation_prompt": null}
{"id": "9d1f98c9-a89d-46d6-b69a-44b0dc388890", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                F = 0.5 + 0.5 * g / generations  # Non-uniform mutation factor\n                mutant = ensure_bounds(a + F * (b - c), bounds)\n                cross_points = np.random.rand(self.dim) < (0.8 + 0.2 * g / generations)  # Adjusted crossover rate\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        best_solution = self.local_search(best_solution, bounds, func)\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.96 + 0.04 * np.tanh(best_score))\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        perturbation = np.random.uniform(-0.02, 0.02, self.dim)\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Enhance MultiScaleAdaptiveSearch by incorporating non-uniform mutation in differential evolution to improve exploration and convergence.", "configspace": "", "generation": 37, "fitness": 0.7062395269544756, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.706 with standard deviation 0.013. And the mean value of best solutions found was 0.254 (0. is the best) with standard deviation 0.022.", "error": "", "parent_id": "2dcaf85e-8310-4cf9-b12f-52d904de133e", "metadata": {"aucs": [0.6914993935958463, 0.7232916050349447, 0.7039275822326356], "final_y": [0.2667107194163113, 0.22384831946586725, 0.2725339393595705]}, "mutation_prompt": null}
{"id": "80db6540-0f6e-4ca5-b2ad-1d3b7e68a862", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            mutation_factor = 0.5 + 0.5 * (g / generations)  # Adaptive mutation factor\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                mutant = ensure_bounds(a + mutation_factor * (b - c), bounds)  # Use adaptive mutation factor\n                cross_points = np.random.rand(self.dim) < (0.8 + 0.2 * g / generations)\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        best_solution = self.local_search(best_solution, bounds, func)\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.96 + 0.04 * np.tanh(best_score))\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        perturbation = np.random.uniform(-0.02, 0.02, self.dim)\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Introduce adaptive mutation based on generation progress to enhance convergence in differential evolution.", "configspace": "", "generation": 38, "fitness": 0.7062395269544756, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.706 with standard deviation 0.013. And the mean value of best solutions found was 0.254 (0. is the best) with standard deviation 0.022.", "error": "", "parent_id": "2dcaf85e-8310-4cf9-b12f-52d904de133e", "metadata": {"aucs": [0.6914993935958463, 0.7232916050349447, 0.7039275822326356], "final_y": [0.2667107194163113, 0.22384831946586725, 0.2725339393595705]}, "mutation_prompt": null}
{"id": "76dc987d-5091-4036-b055-50a46ca2db4c", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            noise = np.random.normal(0, 0.1, self.dim)  # Noise-based diversity\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                F = 0.5 + 0.5 * np.random.rand()  # Adaptive mutation scaling\n                mutant = ensure_bounds(a + F * (b - c) + noise, bounds)\n                cross_points = np.random.rand(self.dim) < (0.8 + 0.2 * g / generations)\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        best_solution = self.local_search(best_solution, bounds, func)\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.96 + 0.04 * np.tanh(best_score))\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        perturbation = np.random.uniform(-0.02, 0.02, self.dim)\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Enhance exploration by introducing noise-based diversity and adaptive mutation scaling in differential evolution.", "configspace": "", "generation": 39, "fitness": 0.6748217504094726, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.675 with standard deviation 0.065. And the mean value of best solutions found was 0.256 (0. is the best) with standard deviation 0.037.", "error": "", "parent_id": "2dcaf85e-8310-4cf9-b12f-52d904de133e", "metadata": {"aucs": [0.6006487395707955, 0.6643379720677589, 0.7594785395898636], "final_y": [0.307234737716077, 0.2383028713116313, 0.22127910607500745]}, "mutation_prompt": null}
{"id": "bc4f979c-1314-4b81-a025-d802f53add48", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n        # Introduce self-adaptive mutation factor\n        F = 0.5\n\n        for g in range(generations):\n            F = 0.4 + 0.3 * np.sin(np.pi * g / generations)  # Adaptive mutation factor\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                mutant = ensure_bounds(a + F * (b - c), bounds)\n                cross_points = np.random.rand(self.dim) < (0.8 + 0.2 * g / generations)  # Adjusted crossover rate\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            # Dynamic adjustment of population size based on convergence\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size // 2)\n                population = population[:population_size]\n        best_solution = self.local_search(best_solution, bounds, func)\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.96 + 0.04 * np.tanh(best_score))\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        perturbation = np.random.uniform(-0.02, 0.02, self.dim)\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Introduce self-adaptive mutation strategies and dynamic population sizing in differential evolution to enhance exploration and convergence.", "configspace": "", "generation": 40, "fitness": 0.7177584511940166, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.718 with standard deviation 0.067. And the mean value of best solutions found was 0.229 (0. is the best) with standard deviation 0.040.", "error": "", "parent_id": "2dcaf85e-8310-4cf9-b12f-52d904de133e", "metadata": {"aucs": [0.6459210514203475, 0.6995926809790276, 0.8077616211826746], "final_y": [0.26663597526005123, 0.24758781382917716, 0.17388807474409018]}, "mutation_prompt": null}
{"id": "31d8a10f-a486-4d04-856b-d88c9126605b", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                F = 0.5 + 0.5 * np.random.rand()  # Adaptive mutation factor\n                mutant = ensure_bounds(a + F * (b - c), bounds)\n                cross_points = np.random.rand(self.dim) < (0.8 + 0.2 * g / generations)\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        best_solution = self.local_search(best_solution, bounds, func)\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.96 + 0.04 * np.tanh(best_score))\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        perturbation = np.random.uniform(-0.02, 0.02, self.dim)\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        initial_pop = [bounds.lb + np.random.rand(self.dim) * (bounds.ub - bounds.lb) for _ in range(5)]  # Diversify starting points\n        best_solution, _ = min((self.differential_evolution(bounds, population_size, generations, func) for _ in initial_pop), key=lambda x: x[1])\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Enhance exploration by diversifying the starting points in differential evolution and employing adaptive mutation factors.", "configspace": "", "generation": 41, "fitness": 0.620573235689376, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.621 with standard deviation 0.048. And the mean value of best solutions found was 0.261 (0. is the best) with standard deviation 0.041.", "error": "", "parent_id": "2dcaf85e-8310-4cf9-b12f-52d904de133e", "metadata": {"aucs": [0.5760829933009606, 0.5989347653969638, 0.6867019483702036], "final_y": [0.22930893438453803, 0.31802645001981256, 0.2351982027361612]}, "mutation_prompt": null}
{"id": "9b241a22-2c27-48b1-b689-a77b90ec483b", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                F = 0.5 + 0.5 * np.random.rand()  # Adaptive mutation scaling\n                mutant = ensure_bounds(a + F * (b - c), bounds)\n                cross_points = np.random.rand(self.dim) < (0.8 + 0.2 * g / generations)\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        best_solution = self.local_search(best_solution, bounds, func)\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.96 + 0.04 * np.tanh(best_score))\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        for _ in range(3):  # Perform multiple neighborhood searches\n            perturbation = np.random.uniform(-0.02, 0.02, self.dim)\n            refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n            if func(refined_solution) < func(solution):\n                solution = refined_solution\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Integrate adaptive mutation scaling and neighborhood search to enhance exploration and exploitation balance in differential evolution.", "configspace": "", "generation": 42, "fitness": 0.6466016422227608, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.647 with standard deviation 0.072. And the mean value of best solutions found was 0.275 (0. is the best) with standard deviation 0.052.", "error": "", "parent_id": "2dcaf85e-8310-4cf9-b12f-52d904de133e", "metadata": {"aucs": [0.6025987943743071, 0.5894345917852031, 0.7477715405087724], "final_y": [0.3121461840147759, 0.31235266985998333, 0.20149425998900994]}, "mutation_prompt": null}
{"id": "8cad82d7-9233-4fbb-90c3-d66a50e0ece8", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            adapt_factor = 0.5 + 0.5 * np.cos(np.pi * g / generations)  # Adaptive mutation scaling\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                mutant = ensure_bounds(a + adapt_factor * (b - c), bounds)  # Changed mutation scaling\n                cross_points = np.random.rand(self.dim) < (0.8 + 0.2 * g / generations)\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        best_solution = self.local_search(best_solution, bounds, func)\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.96 + 0.04 * np.tanh(best_score))\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        perturbation = np.random.uniform(-0.02, 0.02, self.dim)\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Introduce adaptive mutation scaling in differential evolution to balance exploration and exploitation.", "configspace": "", "generation": 43, "fitness": 0.691528963017977, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.692 with standard deviation 0.075. And the mean value of best solutions found was 0.247 (0. is the best) with standard deviation 0.043.", "error": "", "parent_id": "2dcaf85e-8310-4cf9-b12f-52d904de133e", "metadata": {"aucs": [0.6419185346649374, 0.7972872915956133, 0.6353810627933802], "final_y": [0.279380791337263, 0.18650056726008246, 0.27397155412593754]}, "mutation_prompt": null}
{"id": "6d6602a7-5977-46af-9fbd-0dcfc8b519f1", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                # Change line: Introduce dynamic mutation scaling\n                mutant = ensure_bounds(a + (0.5 + 0.5 * g / generations) * (b - c), bounds)\n                cross_points = np.random.rand(self.dim) < (0.8 + 0.2 * g / generations)  # Adjusted crossover rate\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        best_solution = self.local_search(best_solution, bounds, func)\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.96 + 0.04 * np.tanh(best_score))\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        perturbation = np.random.uniform(-0.02, 0.02, self.dim)\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Introduce dynamic mutation scaling in differential evolution to enhance convergence.", "configspace": "", "generation": 44, "fitness": 0.7062395269544756, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.706 with standard deviation 0.013. And the mean value of best solutions found was 0.254 (0. is the best) with standard deviation 0.022.", "error": "", "parent_id": "2dcaf85e-8310-4cf9-b12f-52d904de133e", "metadata": {"aucs": [0.6914993935958463, 0.7232916050349447, 0.7039275822326356], "final_y": [0.2667107194163113, 0.22384831946586725, 0.2725339393595705]}, "mutation_prompt": null}
{"id": "dcc72cf8-7293-47ed-970f-790e5316c5e9", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            adaptive_mutation_scale = 0.5 + 0.5 * (1 - g / generations)\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                mutant = ensure_bounds(a + adaptive_mutation_scale * (b - c), bounds)\n                cross_points = np.random.rand(self.dim) < (0.8 + 0.2 * g / generations)\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        best_solution = self.local_search(best_solution, bounds, func)\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.96 + 0.04 * np.tanh(best_score))\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        perturbation = np.random.uniform(-0.02, 0.02, self.dim)\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Improve exploration by incorporating adaptive mutation scaling in differential evolution.", "configspace": "", "generation": 45, "fitness": 0.5884343457182105, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.588 with standard deviation 0.007. And the mean value of best solutions found was 0.322 (0. is the best) with standard deviation 0.015.", "error": "", "parent_id": "2dcaf85e-8310-4cf9-b12f-52d904de133e", "metadata": {"aucs": [0.5834226976853116, 0.5839279716025085, 0.5979523678668116], "final_y": [0.3227490689154179, 0.3400465200274726, 0.30318224064955823]}, "mutation_prompt": null}
{"id": "03d32c97-9d73-4172-ba3d-1c407823732e", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                mutant = ensure_bounds(a + np.random.rand() * (b - c), bounds)\n                cross_points = np.random.rand(self.dim) < (0.9 + 0.1 * g / generations)  # Adjusted crossover rate\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 3 * self.dim:  # Adjusted population resizing\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        best_solution = self.local_search(best_solution, bounds, func)\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.96 + 0.04 * np.tanh(best_score))\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        perturbation = np.random.uniform(-0.02, 0.02, self.dim)\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Leverage adaptive population resizing with optimistic initialization to enhance convergence in differential evolution.", "configspace": "", "generation": 46, "fitness": 0.8032189058692359, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.803 with standard deviation 0.040. And the mean value of best solutions found was 0.196 (0. is the best) with standard deviation 0.020.", "error": "", "parent_id": "2dcaf85e-8310-4cf9-b12f-52d904de133e", "metadata": {"aucs": [0.8591843682392142, 0.785278750858528, 0.7651935985099655], "final_y": [0.1683180702959326, 0.20716030414781195, 0.21325292209904667]}, "mutation_prompt": null}
{"id": "17553550-1329-4a7e-90f2-3c3ffaa48e6d", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            mutation_factor = 0.5 + 0.5 * (1 - g / generations)  # Adjusted mutation factor\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                mutant = ensure_bounds(a + mutation_factor * (b - c), bounds)\n                cross_points = np.random.rand(self.dim) < (0.8 + 0.2 * g / generations)  # Adjusted crossover rate\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        best_solution = self.local_search(best_solution, bounds, func)\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.96 + 0.04 * np.tanh(best_score))\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        perturbation = np.random.uniform(-0.02, 0.02, self.dim)\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Introduce adaptive mutation factor adjustment in differential evolution to enhance both exploration and exploitation.  ", "configspace": "", "generation": 47, "fitness": 0.5884343457182105, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.588 with standard deviation 0.007. And the mean value of best solutions found was 0.322 (0. is the best) with standard deviation 0.015.", "error": "", "parent_id": "2dcaf85e-8310-4cf9-b12f-52d904de133e", "metadata": {"aucs": [0.5834226976853116, 0.5839279716025085, 0.5979523678668116], "final_y": [0.3227490689154179, 0.3400465200274726, 0.30318224064955823]}, "mutation_prompt": null}
{"id": "47832c7c-3fda-43d8-a673-e9444497dc2c", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                F = np.random.uniform(0.5, 1.0)  # Dynamically adjust F\n                mutant = ensure_bounds(a + F * (b - c), bounds)\n                cross_points = np.random.rand(self.dim) < (0.8 + 0.2 * g / generations)  # Adjusted crossover rate\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n                else:\n                    population[i] += np.random.normal(0, 0.01, self.dim)  # Dynamic perturbation\n            if len(population) > 4 * self.dim:\n                population_size = max(5, int(population_size * 0.75))  # Increased selective pressure\n                population = population[:population_size]\n        best_solution = self.local_search(best_solution, bounds, func)\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.96 + 0.04 * np.tanh(best_score))\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        perturbation = np.random.uniform(-0.02, 0.02, self.dim)\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Integrate a dynamic perturbation strategy and enhanced selective pressure in differential evolution to improve exploration-exploitation balance.", "configspace": "", "generation": 48, "fitness": 0.6082952243272649, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.608 with standard deviation 0.012. And the mean value of best solutions found was 0.282 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "2dcaf85e-8310-4cf9-b12f-52d904de133e", "metadata": {"aucs": [0.6251247769324577, 0.6008002151939069, 0.59896068085543], "final_y": [0.2741088918810042, 0.2831801401070828, 0.28877965979764764]}, "mutation_prompt": null}
{"id": "d491b34f-2345-451d-b1a2-2c1f69ad2cdd", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                f_scale = 0.5 + 0.3 * np.sin(2 * np.pi * g / generations)  # Adaptive mutation scale\n                mutant = ensure_bounds(a + f_scale * (b - c), bounds)\n                cross_points = np.random.rand(self.dim) < (0.8 + 0.2 * g / generations)  # Adjusted crossover rate\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        best_solution = self.local_search(best_solution, bounds, func)\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.96 + 0.04 * np.tanh(best_score))\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        perturbation = np.random.uniform(-0.02, 0.02, self.dim)\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Integrate adaptive mutation scaling in differential evolution to enhance solution diversity and convergence.", "configspace": "", "generation": 49, "fitness": 0.716919668541743, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.717 with standard deviation 0.064. And the mean value of best solutions found was 0.241 (0. is the best) with standard deviation 0.032.", "error": "", "parent_id": "2dcaf85e-8310-4cf9-b12f-52d904de133e", "metadata": {"aucs": [0.6308432590880597, 0.7847167586888171, 0.7351989878483522], "final_y": [0.27819725089682834, 0.2006949521773358, 0.24522407399548185]}, "mutation_prompt": null}
{"id": "376ce468-4d56-453d-b575-f40122a23e25", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.ub)  # Changed line\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                mutant = ensure_bounds(a + np.random.rand() * (b - c), bounds)\n                cross_points = np.random.rand(self.dim) < (0.8 + 0.2 * g / generations)\n                trial = np.where(cross_points, mutant, population[i])\n                trial += np.random.normal(0, 0.01, self.dim)  # Added line\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        best_solution = self.local_search(best_solution, bounds, func)\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.96 + 0.04 * np.tanh(best_score))\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        perturbation = np.random.uniform(-0.02, 0.02, self.dim)\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Introduce a perturbation-based strategy within differential evolution to escape local minima and enhance global exploration.", "configspace": "", "generation": 50, "fitness": 0.04723058126472476, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.047 with standard deviation 0.000. And the mean value of best solutions found was 0.918 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "2dcaf85e-8310-4cf9-b12f-52d904de133e", "metadata": {"aucs": [0.04723058126631363, 0.04723058126343893, 0.0472305812644217], "final_y": [0.9183673469387754, 0.9183673469387754, 0.9183673469387754]}, "mutation_prompt": null}
{"id": "047a5470-14d3-43e6-ba60-407f07a46b25", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        F_base = 0.5  # Base mutation scaling factor\n        for g in range(generations):\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                F = F_base + (0.5 * g / generations)  # Adaptive mutation scaling\n                mutant = ensure_bounds(a + F * (b - c), bounds)\n                cross_points = np.random.rand(self.dim) < (0.8 + 0.2 * g / generations)\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                \n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n\n        best_solution = self.local_search(best_solution, bounds, func)\n        population = np.vstack((population, best_solution))  # Ensuring elitism\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.96 + 0.04 * np.tanh(best_score))\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        perturbation = np.random.uniform(-0.02, 0.02, self.dim)\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Incorporate adaptive mutation scaling and elitism in differential evolution to enhance convergence.", "configspace": "", "generation": 51, "fitness": 0.7062395269544756, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.706 with standard deviation 0.013. And the mean value of best solutions found was 0.254 (0. is the best) with standard deviation 0.022.", "error": "", "parent_id": "2dcaf85e-8310-4cf9-b12f-52d904de133e", "metadata": {"aucs": [0.6914993935958463, 0.7232916050349447, 0.7039275822326356], "final_y": [0.2667107194163113, 0.22384831946586725, 0.2725339393595705]}, "mutation_prompt": null}
{"id": "7fd5152c-568f-4622-89ff-2f3559836418", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            scaling_factor = 0.5 + 0.3 * np.cos(g * np.pi / generations)  # Adaptive scaling factor\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                mutant = ensure_bounds(a + scaling_factor * (b - c), bounds)\n                cross_points = np.random.rand(self.dim) < (0.8 + 0.2 * g / generations)  # Adjusted crossover rate\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        best_solution = self.local_search(best_solution, bounds, func)\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.96 + 0.04 * np.tanh(best_score))\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        perturbation = np.random.uniform(-0.02, 0.02, self.dim)\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Enhance exploration by introducing adaptive scaling factor adjustment in differential evolution.", "configspace": "", "generation": 52, "fitness": 0.7239177182700992, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.724 with standard deviation 0.020. And the mean value of best solutions found was 0.212 (0. is the best) with standard deviation 0.020.", "error": "", "parent_id": "2dcaf85e-8310-4cf9-b12f-52d904de133e", "metadata": {"aucs": [0.708357969246072, 0.7520305857414686, 0.7113645998227571], "final_y": [0.23002023375158365, 0.18386284921513385, 0.22239132354619495]}, "mutation_prompt": null}
{"id": "28aff020-19f4-45e3-b02f-0400a7c97cd9", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                F = 0.5 + 0.3 * (best_score / func(population[i]))  # Adaptive mutation factor\n                mutant = ensure_bounds(a + F * (b - c), bounds)\n                cross_points = np.random.rand(self.dim) < (0.8 + 0.2 * g / generations)  # Adjusted crossover rate\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        best_solution = self.local_search(best_solution, bounds, func)\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.96 + 0.04 * np.tanh(best_score))\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        perturbation = np.random.uniform(-0.02, 0.02, self.dim)\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Introduce adaptive adjustment of both crossover rate and mutation factor in differential evolution to enhance exploration and exploitation.", "configspace": "", "generation": 53, "fitness": 0.5712591047500938, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.571 with standard deviation 0.018. And the mean value of best solutions found was 0.318 (0. is the best) with standard deviation 0.029.", "error": "", "parent_id": "2dcaf85e-8310-4cf9-b12f-52d904de133e", "metadata": {"aucs": [0.5862391310982968, 0.5456468868638948, 0.5818912962880897], "final_y": [0.320159063064107, 0.35229101752667813, 0.28069802417456957]}, "mutation_prompt": null}
{"id": "9bf263c5-4360-4635-b454-b88a1f11050c", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                mutation_factor = 0.5 + 0.5 * np.random.rand()  # Adaptive mutation step size\n                mutant = ensure_bounds(a + mutation_factor * (b - c), bounds)\n                cross_points = np.random.rand(self.dim) < (0.8 + 0.2 * g / generations)  # Adjusted crossover rate\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        best_solution = self.local_search(best_solution, bounds, func)\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp*0.5, self.dim)  # Adjust path\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.96 + 0.04 * np.tanh(best_score))\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        perturbation = np.random.uniform(-0.05, 0.05, self.dim)  # Increased perturbation range\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Enhance exploration by introducing adaptive mutation step sizes in differential evolution and refining local search strategy.", "configspace": "", "generation": 54, "fitness": 0.6457778934290433, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.646 with standard deviation 0.071. And the mean value of best solutions found was 0.276 (0. is the best) with standard deviation 0.052.", "error": "", "parent_id": "2dcaf85e-8310-4cf9-b12f-52d904de133e", "metadata": {"aucs": [0.602598794374307, 0.5883648193919684, 0.7463700665208548], "final_y": [0.3121461840147759, 0.313787311204885, 0.20260780080947027]}, "mutation_prompt": null}
{"id": "8645e48c-c047-410e-9db4-381ac5066905", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                F = 0.5 + 0.3 * np.sin((np.pi * g) / generations)  # Adjusted mutation factor\n                mutant = ensure_bounds(a + F * (b - c), bounds)\n                cross_points = np.random.rand(self.dim) < (0.8 + 0.2 * g / generations)  # Adjusted crossover rate\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        best_solution = self.local_search(best_solution, bounds, func)\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.96 + 0.04 * np.tanh(best_score))\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        perturbation = np.random.uniform(-0.02, 0.02, self.dim)\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Introduce dynamic adjustment of both crossover rate and mutation factor in differential evolution to enhance exploration and exploitation balance.", "configspace": "", "generation": 55, "fitness": 0.6847397028661203, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.685 with standard deviation 0.016. And the mean value of best solutions found was 0.267 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "2dcaf85e-8310-4cf9-b12f-52d904de133e", "metadata": {"aucs": [0.6646458432482326, 0.6856456831174924, 0.7039275822326356], "final_y": [0.2699053346013771, 0.25748603752760757, 0.2725339393595705]}, "mutation_prompt": null}
{"id": "e480d0ff-0bb1-4ba3-8481-316dbfc86f04", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            F = 0.5 + 0.3 * (1 - g / generations)  # Adjusted mutation factor\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                mutant = ensure_bounds(a + F * (b - c), bounds)\n                cross_points = np.random.rand(self.dim) < (0.8 + 0.2 * g / generations)  # Adjusted crossover rate\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        best_solution = self.local_search(best_solution, bounds, func)\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.96 + 0.04 * np.tanh(best_score))\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        perturbation = np.random.uniform(-0.01, 0.01, self.dim)  # Increased precision\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Enhance exploration by dynamically adjusting mutation factor and improving local search precision in the differential evolution phase.", "configspace": "", "generation": 56, "fitness": 0.6466693882244359, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.647 with standard deviation 0.062. And the mean value of best solutions found was 0.271 (0. is the best) with standard deviation 0.042.", "error": "", "parent_id": "2dcaf85e-8310-4cf9-b12f-52d904de133e", "metadata": {"aucs": [0.7313317010761722, 0.6221787530542077, 0.5864977105429277], "final_y": [0.21300592115349282, 0.28962070552247665, 0.3109477226691916]}, "mutation_prompt": null}
{"id": "e34d0136-d774-40b7-a4e4-4ba0986e6cf4", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                mutation_scale = 0.5 + 0.5 * np.random.rand()  # Adaptive mutation scale\n                mutant = ensure_bounds(a + mutation_scale * (b - c), bounds)\n                cross_points = np.random.rand(self.dim) < (0.8 + 0.2 * g / generations)  # Adjusted crossover rate\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        best_solution = self.local_search(best_solution, bounds, func)\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.96 + 0.04 * np.tanh(best_score))\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        perturbation = np.random.uniform(-0.02, 0.02, self.dim)\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Integrate adaptive mutation scale into differential evolution to improve convergence on diverse landscapes.", "configspace": "", "generation": 57, "fitness": 0.647194817177175, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.647 with standard deviation 0.070. And the mean value of best solutions found was 0.274 (0. is the best) with standard deviation 0.051.", "error": "", "parent_id": "2dcaf85e-8310-4cf9-b12f-52d904de133e", "metadata": {"aucs": [0.602598794374307, 0.5926155906363629, 0.7463700665208548], "final_y": [0.3121461840147759, 0.3085486166938465, 0.20260780080947027]}, "mutation_prompt": null}
{"id": "db4b9f70-6683-46fa-94e9-2d2f7738b142", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            current_population_size = population_size // (1 + g // 10)  # Dynamic population size\n            for i in range(current_population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                mutant = ensure_bounds(a + np.random.rand() * (b - c), bounds)\n                cross_points = np.random.rand(self.dim) < (0.8 + 0.2 * g / generations)  # Adjusted crossover rate\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        best_solution = self.local_search(best_solution, bounds, func)\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.96 + 0.04 * np.tanh(best_score))\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        perturbation = np.random.uniform(-0.02, 0.02, self.dim)\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Enhance the diversity of solutions by incorporating a dynamic population size dependent on the iteration count.", "configspace": "", "generation": 58, "fitness": 0.6825945086998989, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.683 with standard deviation 0.050. And the mean value of best solutions found was 0.275 (0. is the best) with standard deviation 0.025.", "error": "", "parent_id": "2dcaf85e-8310-4cf9-b12f-52d904de133e", "metadata": {"aucs": [0.7521702314890459, 0.6566259343344337, 0.638987360276217], "final_y": [0.2397388670734345, 0.28961242826003397, 0.2951290472023891]}, "mutation_prompt": null}
{"id": "5fa09116-fc15-4ec4-854a-6e5d9a6a9a6c", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                F = 0.5 + 0.5 * np.tanh(best_score)  # Adaptive mutation scaling factor\n                mutant = ensure_bounds(a + F * (b - c), bounds)\n                cross_points = np.random.rand(self.dim) < (0.8 + 0.2 * g / generations)  # Adjusted crossover rate\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        best_solution = self.local_search(best_solution, bounds, func)\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.96 + 0.04 * np.tanh(best_score))\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        perturbation = np.random.uniform(-0.02, 0.02, self.dim)\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Introduce adaptive mutation scaling factor in differential evolution to balance exploration and exploitation.", "configspace": "", "generation": 59, "fitness": 0.7238732458675269, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.724 with standard deviation 0.014. And the mean value of best solutions found was 0.229 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "2dcaf85e-8310-4cf9-b12f-52d904de133e", "metadata": {"aucs": [0.7379965723578007, 0.705617159664821, 0.7280060055799591], "final_y": [0.2345769983227527, 0.24150191027023538, 0.21001616667186263]}, "mutation_prompt": null}
{"id": "4ef0143d-94f1-4940-8769-33aaf5206506", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                mutant = ensure_bounds(a + np.random.rand() * (b - c), bounds)\n                cross_points = np.random.rand(self.dim) < (0.8 + 0.2 * g / generations)  # Adjusted crossover rate\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, int(population_size * 0.9))  # Change 1: Adaptive scaling\n                population = population[:population_size]\n        best_solution = self.local_search(best_solution, bounds, func)\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.96 + 0.04 * np.tanh(best_score))  # Change 2: Reduce aggressive cooling rate\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        perturbation = np.random.uniform(-0.02, 0.02, self.dim)\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 0.9  # Change 3: Lower initial temperature for faster start\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Introduce adaptive population size scaling in differential evolution based on current solution quality to improve convergence.", "configspace": "", "generation": 60, "fitness": 0.7744865691301716, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.774 with standard deviation 0.038. And the mean value of best solutions found was 0.177 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "2dcaf85e-8310-4cf9-b12f-52d904de133e", "metadata": {"aucs": [0.7899888562122792, 0.7225929053591357, 0.8108779458190998], "final_y": [0.16640757393775218, 0.19373032251476263, 0.17045688471449716]}, "mutation_prompt": null}
{"id": "299b9e26-5517-48a9-8b5c-5b1851f8f829", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            F = 0.5 + 0.5 * (g / generations)  # Adaptive mutation factor\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                mutant = ensure_bounds(a + F * (b - c), bounds)\n                cross_points = np.random.rand(self.dim) < (0.8 + 0.2 * g / generations)  # Adjusted crossover rate\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        best_solution = self.local_search(best_solution, bounds, func)\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.96 + 0.04 * np.tanh(best_score))\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        perturbation = np.random.uniform(-0.05, 0.05, self.dim)  # Enhanced perturbation\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Enhance exploration and exploitation by incorporating an adaptive mutation factor and perturbation strategies.", "configspace": "", "generation": 61, "fitness": 0.706229752343727, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.706 with standard deviation 0.013. And the mean value of best solutions found was 0.254 (0. is the best) with standard deviation 0.022.", "error": "", "parent_id": "2dcaf85e-8310-4cf9-b12f-52d904de133e", "metadata": {"aucs": [0.6914700697636007, 0.7232916050349447, 0.7039275822326356], "final_y": [0.26674193908175914, 0.22384831946586725, 0.2725339393595705]}, "mutation_prompt": null}
{"id": "fbe4fab3-aa34-4254-b09c-89ba682f0ccf", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            elite_index = np.argmin([func(ind) for ind in population])\n            for i in range(population_size):\n                if i == elite_index:\n                    continue\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                mutant = ensure_bounds(a + np.random.rand() * (b - c), bounds)\n                cross_points = np.random.rand(self.dim) < (0.8 + 0.2 * g / generations)\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//3)  # Adjusted population size shrinking\n                population = population[:population_size]\n        best_solution = self.local_search(best_solution, bounds, func)\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.96 + 0.04 * np.tanh(best_score))\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        perturbation = np.random.uniform(-0.02, 0.02, self.dim)\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Enhance convergence by introducing adaptive population size and elite preservation in differential evolution.", "configspace": "", "generation": 62, "fitness": 0.7467719548385983, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.747 with standard deviation 0.032. And the mean value of best solutions found was 0.178 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "2dcaf85e-8310-4cf9-b12f-52d904de133e", "metadata": {"aucs": [0.715609214713556, 0.733205508722524, 0.791501141079715], "final_y": [0.18617162231288253, 0.17935563731712056, 0.1683219583793325]}, "mutation_prompt": null}
{"id": "1b03862b-0b75-466f-be8e-cec60d9fbec3", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                F = 0.5 + 0.5 * (1 - g / generations)  # Adaptive mutation scaling factor\n                mutant = ensure_bounds(a + F * (b - c), bounds)\n                cross_points = np.random.rand(self.dim) < (0.8 + 0.2 * g / generations)  # Adjusted crossover rate\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        best_solution = self.local_search(best_solution, bounds, func)\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.96 + 0.04 * np.tanh(best_score))\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        perturbation = np.random.uniform(-0.02, 0.02, self.dim)\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Introduce adaptive mutation scaling factor in differential evolution for improved exploration and exploitation.", "configspace": "", "generation": 63, "fitness": 0.5884343457182105, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.588 with standard deviation 0.007. And the mean value of best solutions found was 0.322 (0. is the best) with standard deviation 0.015.", "error": "", "parent_id": "2dcaf85e-8310-4cf9-b12f-52d904de133e", "metadata": {"aucs": [0.5834226976853116, 0.5839279716025085, 0.5979523678668116], "final_y": [0.3227490689154179, 0.3400465200274726, 0.30318224064955823]}, "mutation_prompt": null}
{"id": "ba02ca83-8434-444a-b551-71a3812a386a", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            current_diversity = np.std(population, axis=0).mean()  # Calculate diversity\n            if current_diversity < 0.01:  # If diversity is low, introduce new solutions\n                new_individual = np.random.rand(self.dim) * (bounds.ub - bounds.lb) + bounds.lb\n                population[np.random.randint(0, population_size)] = new_individual\n            \n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                mutant = ensure_bounds(a + np.random.rand() * (b - c), bounds)\n                cross_points = np.random.rand(self.dim) < (0.8 + 0.2 * g / generations)  # Adjusted crossover rate\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        best_solution = self.local_search(best_solution, bounds, func)\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.96 + 0.04 * np.tanh(best_score))\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        perturbation = np.random.uniform(-0.02, 0.02, self.dim)\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Introduce dynamic population size adjustment based on diversity to enhance exploration and exploitation balance.", "configspace": "", "generation": 64, "fitness": 0.8196731716538093, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.820 with standard deviation 0.012. And the mean value of best solutions found was 0.186 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "2dcaf85e-8310-4cf9-b12f-52d904de133e", "metadata": {"aucs": [0.8322114857277603, 0.8042296196427433, 0.8225784095909245], "final_y": [0.18145259582280215, 0.19588560900970553, 0.17950869482946719]}, "mutation_prompt": null}
{"id": "c40ee2a7-1e29-410d-88ad-f71a26f699ea", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                F = 0.5 + 0.5 * (best_score / func(population[i]))  # Fitness-based mutation rate\n                mutant = ensure_bounds(a + F * (b - c), bounds)\n                cross_points = np.random.rand(self.dim) < (0.8 + 0.2 * g / generations)  # Adjusted crossover rate\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        best_solution = self.local_search(best_solution, bounds, func)\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.96 + 0.04 * np.tanh(best_score))\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        perturbation = np.random.uniform(-0.02, 0.02, self.dim)\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Utilize fitness-based scaling for mutation rate in differential evolution for improved convergence.", "configspace": "", "generation": 65, "fitness": 0.5974805407341182, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.597 with standard deviation 0.052. And the mean value of best solutions found was 0.297 (0. is the best) with standard deviation 0.056.", "error": "", "parent_id": "2dcaf85e-8310-4cf9-b12f-52d904de133e", "metadata": {"aucs": [0.5255071185050737, 0.6198522170721685, 0.6470822866251122], "final_y": [0.3756227063956802, 0.2512703881744732, 0.26266594101067486]}, "mutation_prompt": null}
{"id": "7107abb9-5a6d-4916-8490-642f9045bf59", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                mutant = ensure_bounds(a + np.random.rand() * (b - c), bounds)\n                cross_points = np.random.rand(self.dim) < (0.8 + 0.2 * g / generations)  # Adjusted crossover rate\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        best_solution = self.local_search(best_solution, bounds, func)\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.95 + 0.05 * np.tanh(best_score))  # Adjusted temperature decay rate\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        perturbation = np.random.uniform(-0.02, 0.02, self.dim)\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Enhance convergence by refining the simulated annealing temperature decay rate.", "configspace": "", "generation": 66, "fitness": 0.8196731716538093, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.820 with standard deviation 0.012. And the mean value of best solutions found was 0.186 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "2dcaf85e-8310-4cf9-b12f-52d904de133e", "metadata": {"aucs": [0.8322114857277596, 0.8042296196427435, 0.8225784095909249], "final_y": [0.18145259582280215, 0.19588560900970553, 0.17950869482946719]}, "mutation_prompt": null}
{"id": "fd51c505-3757-4515-9c75-b0b23ae2d72b", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                mutant = ensure_bounds(a + np.random.rand() * (b - c), bounds)\n                cross_points = np.random.rand(self.dim) < (0.8 + 0.2 * g / generations)  # Adjusted crossover rate\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        best_solution = self.local_search(best_solution, bounds, func)\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.96 + 0.04 * np.tanh(best_score))\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        perturbation = np.random.uniform(-0.02, 0.02, self.dim) * (1 - func(solution))\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Introduce a dynamic reduction of perturbation range during local search for enhanced precision.", "configspace": "", "generation": 67, "fitness": 0.8196681677365486, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.820 with standard deviation 0.012. And the mean value of best solutions found was 0.186 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "2dcaf85e-8310-4cf9-b12f-52d904de133e", "metadata": {"aucs": [0.8322072810739631, 0.8042239563659104, 0.8225732657697724], "final_y": [0.18145558043650278, 0.19588994954770966, 0.17951218981838024]}, "mutation_prompt": null}
{"id": "b68c2be7-5776-40e9-aba0-1badae518bf8", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                F = 0.5 + 0.5 * (best_score / (best_score + 1))  # Adaptive mutation scaling\n                mutant = ensure_bounds(a + F * (b - c), bounds)\n                cross_points = np.random.rand(self.dim) < (0.8 + 0.2 * g / generations)  # Adjusted crossover rate\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        best_solution = self.local_search(best_solution, bounds, func)\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.96 + 0.04 * np.tanh(best_score))\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        perturbation = np.random.uniform(-0.02, 0.02, self.dim)\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Introduce adaptive mutation scaling in differential evolution to improve convergence speed.", "configspace": "", "generation": 68, "fitness": -Infinity, "feedback": "An exception occurred: TypeError(\"unsupported operand type(s) for +: 'NoneType' and 'float'\").", "error": "TypeError(\"unsupported operand type(s) for +: 'NoneType' and 'float'\")", "parent_id": "2dcaf85e-8310-4cf9-b12f-52d904de133e", "metadata": {}, "mutation_prompt": null}
{"id": "8cbe7e7d-6136-4a2d-89ec-ade970488554", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                mutant = ensure_bounds(a + np.random.rand() * (b - c), bounds)\n                cross_points = np.random.rand(self.dim) < (0.8 + 0.2 * g / generations)  # Adjusted crossover rate\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                diversity = np.std(population, axis=0).mean()  # Adaptive population size scaling\n                population_size = max(5, int(population_size * (0.5 + 0.5 * diversity)))  # Adapt size based on diversity\n                population = population[:population_size]\n        best_solution = self.local_search(best_solution, bounds, func)\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.96 + 0.04 * np.tanh(best_score))\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        perturbation = np.random.uniform(-0.02, 0.02, self.dim)\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Introduce adaptive population size scaling strategy based on diversity in differential evolution to improve exploitation.", "configspace": "", "generation": 69, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 637 is out of bounds for axis 0 with size 100').", "error": "IndexError('index 637 is out of bounds for axis 0 with size 100')", "parent_id": "2dcaf85e-8310-4cf9-b12f-52d904de133e", "metadata": {}, "mutation_prompt": null}
{"id": "db1adeff-6b24-45f6-971e-350dec8ba011", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n        memory = []\n\n        for g in range(generations):\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                mutant = ensure_bounds(a + np.random.rand() * (b - c), bounds)\n                cross_points = np.random.rand(self.dim) < (0.8 + 0.2 * g / generations)  # Adjusted crossover rate\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if len(memory) > 0:\n                    influence = np.random.choice(memory)\n                    trial = (trial + influence) / 2\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                    memory.append(trial)\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        best_solution = self.local_search(best_solution, bounds, func)\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.96 + 0.04 * np.tanh(best_score))\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        perturbation = np.random.uniform(-0.02, 0.02, self.dim)\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Integrate an adaptive memory strategy to dynamically guide search directions in differential evolution and simulated annealing for improved convergence.", "configspace": "", "generation": 70, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('a must be 1-dimensional').", "error": "ValueError('a must be 1-dimensional')", "parent_id": "2dcaf85e-8310-4cf9-b12f-52d904de133e", "metadata": {}, "mutation_prompt": null}
{"id": "24fbbf6e-d04f-4cc0-8168-fe1c2847b9b1", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                F = 0.5 + 0.3 * np.sin(np.pi * g / generations)  # Adaptive mutation scaling\n                mutant = ensure_bounds(a + F * (b - c), bounds)\n                cross_points = np.random.rand(self.dim) < (0.8 + 0.2 * g / generations)  # Adjusted crossover rate\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        best_solution = self.local_search(best_solution, bounds, func)\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.96 + 0.04 * np.tanh(best_score))\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        perturbation = np.random.uniform(-0.02, 0.02, self.dim)\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Introduce adaptive mutation scaling in differential evolution for better balance between exploration and exploitation.", "configspace": "", "generation": 71, "fitness": 0.6847397028661203, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.685 with standard deviation 0.016. And the mean value of best solutions found was 0.267 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "2dcaf85e-8310-4cf9-b12f-52d904de133e", "metadata": {"aucs": [0.6646458432482326, 0.6856456831174924, 0.7039275822326356], "final_y": [0.2699053346013771, 0.25748603752760757, 0.2725339393595705]}, "mutation_prompt": null}
{"id": "5a34896a-c95f-4650-b616-f498dad4461f", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                F = 0.5 + 0.5 * np.random.rand()  # Adaptive mutation scaling\n                mutant = ensure_bounds(a + F * (b - c) + 0.1 * (best_solution - a), bounds)  # Global best guidance\n                cross_points = np.random.rand(self.dim) < (0.8 + 0.2 * g / generations)\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        best_solution = self.local_search(best_solution, bounds, func)\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.96 + 0.04 * np.tanh(best_score))\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        perturbation = np.random.uniform(-0.02, 0.02, self.dim)\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Introduce adaptive mutation scaling and incorporate global best guidance in differential evolution for improved convergence.", "configspace": "", "generation": 72, "fitness": -Infinity, "feedback": "An exception occurred: TypeError(\"unsupported operand type(s) for -: 'NoneType' and 'float'\").", "error": "TypeError(\"unsupported operand type(s) for -: 'NoneType' and 'float'\")", "parent_id": "2dcaf85e-8310-4cf9-b12f-52d904de133e", "metadata": {}, "mutation_prompt": null}
{"id": "4c571e59-7aee-48c9-89d2-859e4c0e4452", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                beta = 0.5 + 0.5 * np.sin(np.pi * g / generations)  # Chaotic mutation factor\n                mutant = ensure_bounds(a + beta * (b - c), bounds)\n                cross_points = np.random.rand(self.dim) < (0.8 + 0.2 * g / generations)\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        best_solution = self.local_search(best_solution, bounds, func)\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.96 + 0.04 * np.tanh(best_score))\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        perturbation = np.random.uniform(-0.02, 0.02, self.dim)\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Integrate chaotic mutation strategies to enhance diversity and avoid premature convergence in differential evolution.", "configspace": "", "generation": 73, "fitness": 0.6339243308182613, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.634 with standard deviation 0.056. And the mean value of best solutions found was 0.301 (0. is the best) with standard deviation 0.025.", "error": "", "parent_id": "2dcaf85e-8310-4cf9-b12f-52d904de133e", "metadata": {"aucs": [0.5672770273932063, 0.6305683828289419, 0.7039275822326356], "final_y": [0.33427911579125436, 0.29567585465465085, 0.2725339393595705]}, "mutation_prompt": null}
{"id": "71bc9fff-06ea-4268-806e-a06b6990f6f9", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                F = 0.5 + 0.5 * (best_score / (best_score + 1))  # Adaptive mutation rate\n                mutant = ensure_bounds(a + F * (b - c), bounds)\n                cross_points = np.random.rand(self.dim) < (0.8 + 0.2 * g / generations)\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        population = sorted(population, key=func)[:population_size]  # Elite selection\n        best_solution = self.local_search(best_solution, bounds, func)\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.96 + 0.04 * np.tanh(best_score))\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        perturbation = np.random.uniform(-0.02, 0.02, self.dim)\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Introduce adaptive mutation rate and elite selection in differential evolution to enhance both exploration and exploitation.", "configspace": "", "generation": 74, "fitness": -Infinity, "feedback": "An exception occurred: TypeError(\"unsupported operand type(s) for +: 'NoneType' and 'float'\").", "error": "TypeError(\"unsupported operand type(s) for +: 'NoneType' and 'float'\")", "parent_id": "2dcaf85e-8310-4cf9-b12f-52d904de133e", "metadata": {}, "mutation_prompt": null}
{"id": "b0db41d8-e038-46e9-b169-8178d77e7e15", "solution": "import numpy as np\nfrom scipy.stats.qmc import Sobol\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        # Initialize population using Sobol sequences for better coverage\n        sobol_engine = Sobol(d=self.dim, scramble=True)\n        population = sobol_engine.random_base2(m=int(np.log2(population_size)))\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                mutant = ensure_bounds(a + np.random.rand() * (b - c), bounds)\n                cross_points = np.random.rand(self.dim) < (0.8 + 0.2 * g / generations)  # Adjusted crossover rate\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        best_solution = self.local_search(best_solution, bounds, func)\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.96 + 0.04 * np.tanh(best_score))\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        perturbation = np.random.uniform(-0.02, 0.02, self.dim)\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Enhance exploration by introducing diversity in population initialization with Sobol sequences.", "configspace": "", "generation": 75, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 64 is out of bounds for axis 0 with size 64').", "error": "IndexError('index 64 is out of bounds for axis 0 with size 64')", "parent_id": "2dcaf85e-8310-4cf9-b12f-52d904de133e", "metadata": {}, "mutation_prompt": null}
{"id": "4a502057-5cf1-46d5-afb7-117cadd4e557", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                # Hybrid mutation strategy with random factor blending\n                mutant = ensure_bounds(a + np.random.rand() * (b - c) + 0.1 * np.random.randn(self.dim), bounds)\n                cross_points = np.random.rand(self.dim) < (0.8 + 0.2 * g / generations)  # Adjusted crossover rate\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        best_solution = self.local_search(best_solution, bounds, func)\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.96 + 0.04 * np.tanh(best_score))\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        perturbation = np.random.uniform(-0.02, 0.02, self.dim)\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Incorporate a hybrid mutation strategy in differential evolution for enhanced global exploration.", "configspace": "", "generation": 76, "fitness": 0.7939524083486863, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.794 with standard deviation 0.066. And the mean value of best solutions found was 0.198 (0. is the best) with standard deviation 0.022.", "error": "", "parent_id": "2dcaf85e-8310-4cf9-b12f-52d904de133e", "metadata": {"aucs": [0.7794808455842168, 0.7207407602586253, 0.8816356192032166], "final_y": [0.20699072585901634, 0.21978914809970884, 0.1686529262152604]}, "mutation_prompt": null}
{"id": "8ed1dad7-1874-4fab-8833-0a156a91405f", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                mutant = ensure_bounds(a + np.random.rand() * (b - c), bounds)\n                cross_points = np.random.rand(self.dim) < (0.8 + 0.2 * g / generations)  # Adjusted crossover rate\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        best_solution = self.local_search(best_solution, bounds, func)\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.96 + 0.04 * np.tanh(best_score))\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        perturbation = np.random.uniform(-0.03, 0.03, self.dim)  # Increased perturbation range\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Improve local search by increasing perturbation range for better fine-tuning.", "configspace": "", "generation": 77, "fitness": 0.8196864252827076, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.820 with standard deviation 0.012. And the mean value of best solutions found was 0.186 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "2dcaf85e-8310-4cf9-b12f-52d904de133e", "metadata": {"aucs": [0.8322230355004545, 0.8042440400255263, 0.8225922003221423], "final_y": [0.1814443815306338, 0.19587453740938032, 0.1794989920608595]}, "mutation_prompt": null}
{"id": "691beadb-288b-4f97-a346-a9dd47b70653", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                mutant = ensure_bounds(a + np.random.rand() * (b - c), bounds)\n                cross_points = np.random.rand(self.dim) < (0.8 + 0.2 * g / generations)  # Adjusted crossover rate\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        best_solution = self.local_search(best_solution, bounds, func)\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            adaptive_variance = temp * (1 + np.sin(generations))\n            candidate_solution = current_solution + np.random.normal(0, adaptive_variance, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.96 + 0.04 * np.tanh(best_score))\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        perturbation = np.random.uniform(-0.03, 0.03, self.dim)  # Increased perturbation range\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Introduce adaptive learning rate with a sinusoidal function to enhance convergence.", "configspace": "", "generation": 78, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'generations' is not defined\").", "error": "NameError(\"name 'generations' is not defined\")", "parent_id": "8ed1dad7-1874-4fab-8833-0a156a91405f", "metadata": {}, "mutation_prompt": null}
{"id": "439cec73-459a-47c4-9f65-87fa389cf0ad", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                mutant = ensure_bounds(a + np.random.rand() * (b - c), bounds)\n                cross_points = np.random.rand(self.dim) < (0.8 + 0.2 * g / generations)  # Adjusted crossover rate\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        best_solution = self.local_search(best_solution, bounds, func)\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.96 + 0.04 * np.tanh(best_score))\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        perturbation = np.random.uniform(-0.03, 0.03 * (1 - np.tanh(func(solution))), self.dim)  # Dynamic perturbation\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Enhance the local search by incorporating a dynamic perturbation range based on the current iteration to better explore the solution space.", "configspace": "", "generation": 79, "fitness": 0.8196831536080408, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.820 with standard deviation 0.012. And the mean value of best solutions found was 0.186 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "8ed1dad7-1874-4fab-8833-0a156a91405f", "metadata": {"aucs": [0.8322149770749526, 0.8042433919317065, 0.8225910918174629], "final_y": [0.1814501044658875, 0.1958750207438693, 0.1794996420059567]}, "mutation_prompt": null}
{"id": "96dc5805-b4d4-410f-a9a1-e6dd3ff05098", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                mutant = ensure_bounds(a + np.random.rand() * (b - c), bounds)\n                cross_points = np.random.rand(self.dim) < (0.8 + 0.2 * g / generations)  # Adjusted crossover rate\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        best_solution = self.local_search(best_solution, bounds, func)\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.96 + 0.04 * np.tanh(best_score)) * (1 - 0.001 * best_score)  # Dynamic cooling adjustment\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        perturbation = np.random.uniform(-0.03, 0.03, self.dim)  # Increased perturbation range\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Incorporate dynamic cooling rate adjustment in simulated annealing for adaptive fine-tuning.", "configspace": "", "generation": 80, "fitness": 0.8196864252827076, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.820 with standard deviation 0.012. And the mean value of best solutions found was 0.186 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "8ed1dad7-1874-4fab-8833-0a156a91405f", "metadata": {"aucs": [0.8322230355004544, 0.8042440400255263, 0.8225922003221423], "final_y": [0.1814443815306338, 0.19587453740938032, 0.1794989920608595]}, "mutation_prompt": null}
{"id": "e05d2755-d6ec-4af4-99ca-e2dfdb9a2e20", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            for i in range(population_size):\n                if g % (generations // 5) == 0:  # Restart mechanism\n                    population = np.random.rand(population_size, self.dim)\n                    for j in range(population_size):\n                        population[j] = bounds.lb + population[j] * (bounds.ub - bounds.lb)\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                F = 0.5 + 0.5 * np.random.rand()  # Dynamic mutation factor\n                mutant = ensure_bounds(a + F * (b - c), bounds)\n                cross_points = np.random.rand(self.dim) < (0.8 + 0.2 * g / generations)\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        best_solution = self.local_search(best_solution, bounds, func)\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.96 + 0.04 * np.tanh(best_score))\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        perturbation = np.random.uniform(-0.03, 0.03, self.dim)\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Integrate a restart mechanism and modify the mutation strategy in Differential Evolution to enhance exploration and avoid local minima.", "configspace": "", "generation": 81, "fitness": 0.5862579804281894, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.586 with standard deviation 0.023. And the mean value of best solutions found was 0.332 (0. is the best) with standard deviation 0.016.", "error": "", "parent_id": "8ed1dad7-1874-4fab-8833-0a156a91405f", "metadata": {"aucs": [0.6176721736916093, 0.562645511965304, 0.5784562556276549], "final_y": [0.30903176490844697, 0.3413361832766959, 0.34578170542120257]}, "mutation_prompt": null}
{"id": "00822203-c507-4cec-9ef9-382df14b6797", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                mutation_factor = 0.5 + 0.3 * np.sin(generations * 0.05)  # Dynamic mutation factor\n                mutant = ensure_bounds(a + mutation_factor * (b - c), bounds)\n                cross_points = np.random.rand(self.dim) < (0.8 + 0.2 * g / generations)  # Adjusted crossover rate\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        best_solution = self.local_search(best_solution, bounds, func)\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.96 + 0.04 * np.tanh(best_score))\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        perturbation = np.random.uniform(-0.03, 0.03, self.dim)  # Increased perturbation range\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Enhance exploration by introducing a dynamic mutation factor in differential evolution.", "configspace": "", "generation": 82, "fitness": 0.643160052090516, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.643 with standard deviation 0.021. And the mean value of best solutions found was 0.282 (0. is the best) with standard deviation 0.016.", "error": "", "parent_id": "8ed1dad7-1874-4fab-8833-0a156a91405f", "metadata": {"aucs": [0.6712749661026547, 0.6198605057274036, 0.6383446844414895], "final_y": [0.26020335956481633, 0.28477889110201005, 0.29968511028549205]}, "mutation_prompt": null}
{"id": "e856a651-5165-447b-807a-99aae0dbb9ed", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            adaptive_factor = 0.5 + 0.5 * np.cos(np.pi * g / generations)  # New adaptive factor\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                mutant = ensure_bounds(a + np.random.rand() * adaptive_factor * (b - c), bounds)  # Modified mutation\n                cross_points = np.random.rand(self.dim) < (0.8 + 0.2 * adaptive_factor)  # Adjusted crossover rate\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        best_solution = self.local_search(best_solution, bounds, func)\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.96 + 0.04 * np.tanh(best_score))\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        perturbation = np.random.uniform(-0.03, 0.03, self.dim)\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Improve search efficiency by adapting crossover and mutation strategies, enhancing solution diversity and exploration.", "configspace": "", "generation": 83, "fitness": 0.8497872607519974, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.850 with standard deviation 0.017. And the mean value of best solutions found was 0.186 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "8ed1dad7-1874-4fab-8833-0a156a91405f", "metadata": {"aucs": [0.8731954013030773, 0.8411154049611254, 0.8350509759917895], "final_y": [0.1811553908099286, 0.18736880686376955, 0.19032722181108164]}, "mutation_prompt": null}
{"id": "d3cfddad-490b-4e90-8ea9-957044fabe7f", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            adaptive_factor = 0.5 + 0.5 * np.cos(np.pi * g / generations)  # New adaptive factor\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                mutant = ensure_bounds(a + np.random.rand() * adaptive_factor * (b - c), bounds)  # Modified mutation\n                cross_points = np.random.rand(self.dim) < (0.85 + 0.15 * adaptive_factor)  # Adjusted crossover rate\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        best_solution = self.local_search(best_solution, bounds, func)\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= 0.98   # Adjusted cooling rate\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        perturbation = np.random.uniform(-0.05, 0.05, self.dim)  # Adjusted perturbation range\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Enhance adaptive mechanisms and local search dynamics for improved exploration and exploitation.", "configspace": "", "generation": 84, "fitness": 0.834610483597998, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.835 with standard deviation 0.053. And the mean value of best solutions found was 0.195 (0. is the best) with standard deviation 0.020.", "error": "", "parent_id": "e856a651-5165-447b-807a-99aae0dbb9ed", "metadata": {"aucs": [0.8618801535303035, 0.8816205136579749, 0.7603307836057156], "final_y": [0.18597979690933497, 0.17590589893950903, 0.22351749193053017]}, "mutation_prompt": null}
{"id": "ba5c5e83-730d-4140-9065-b8eb8cce8029", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            adaptive_factor = 0.5 + 0.5 * np.cos(np.pi * g / generations)  # New adaptive factor\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                mutant = ensure_bounds(a + np.random.rand() * adaptive_factor * (b - c) * (1 - best_score), bounds)  # Modified mutation\n                cross_points = np.random.rand(self.dim) < (0.8 + 0.2 * adaptive_factor)  # Adjusted crossover rate\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        best_solution = self.local_search(best_solution, bounds, func)\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.96 + 0.04 * np.tanh(best_score))\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        perturbation = np.random.uniform(-0.03, 0.03, self.dim)\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Enhance search process by dynamically adjusting mutation scale based on the current best score for better exploration.", "configspace": "", "generation": 85, "fitness": 0.8131784724884689, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.813 with standard deviation 0.075. And the mean value of best solutions found was 0.210 (0. is the best) with standard deviation 0.029.", "error": "", "parent_id": "e856a651-5165-447b-807a-99aae0dbb9ed", "metadata": {"aucs": [0.912174980948059, 0.7949915021253017, 0.7323689343920456], "final_y": [0.17182828422909424, 0.21499725823406624, 0.24221954371855947]}, "mutation_prompt": null}
{"id": "f747de28-b059-449b-9c58-936d0e9b56cc", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            # Change: Introduce dynamic scaling factor instead of static adaptation\n            adaptive_factor = 0.5 + 0.5 * np.cos(np.pi * g / generations) + (best_score / (1 + best_score))\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                mutant = ensure_bounds(a + np.random.rand() * adaptive_factor * (b - c), bounds)  # Modified mutation\n                cross_points = np.random.rand(self.dim) < (0.8 + 0.2 * adaptive_factor)  # Adjusted crossover rate\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        best_solution = self.local_search(best_solution, bounds, func)\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.96 + 0.04 * np.tanh(best_score))\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        perturbation = np.random.uniform(-0.03, 0.03, self.dim)\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Introduce a dynamic adjustment to the mutation factor in the differential evolution process to enhance exploration and exploitation.", "configspace": "", "generation": 86, "fitness": 0.8345339276009577, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.835 with standard deviation 0.050. And the mean value of best solutions found was 0.189 (0. is the best) with standard deviation 0.021.", "error": "", "parent_id": "e856a651-5165-447b-807a-99aae0dbb9ed", "metadata": {"aucs": [0.776134107115209, 0.8299617161004188, 0.897505959587245], "final_y": [0.21776935954066223, 0.18348506659223085, 0.1662841098677078]}, "mutation_prompt": null}
{"id": "27d081dd-2752-447f-a807-4b0534c65655", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            adaptive_factor = 0.6 + 0.4 * np.cos(np.pi * g / generations)  # Changed adaptive factor\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                mutant = ensure_bounds(a + np.random.rand() * adaptive_factor * (b - c), bounds)  # Modified mutation\n                cross_points = np.random.rand(self.dim) < (0.8 + 0.2 * adaptive_factor)  # Adjusted crossover rate\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        best_solution = self.local_search(best_solution, bounds, func)\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.96 + 0.04 * np.tanh(best_score))\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        perturbation = np.random.uniform(-0.03, 0.03, self.dim)\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Enhance search performance by refining mutation's adaptive factor to better explore the solution space.", "configspace": "", "generation": 87, "fitness": 0.8566169234648674, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.857 with standard deviation 0.032. And the mean value of best solutions found was 0.182 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "e856a651-5165-447b-807a-99aae0dbb9ed", "metadata": {"aucs": [0.8873665321718666, 0.8698486368652026, 0.8126356013575329], "final_y": [0.17163522193333913, 0.1760147813545173, 0.19776226271741015]}, "mutation_prompt": null}
{"id": "8c6f4f40-3ec8-4667-8de9-3033a346a65b", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            adaptive_factor = 0.6 + 0.4 * np.cos(np.pi * g / generations)\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                mutant = ensure_bounds(a + np.random.rand() * adaptive_factor * (b - c), bounds)\n                cross_points = np.random.rand(self.dim) < (0.8 + 0.2 * adaptive_factor)\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if g % 10 == 0:  # Dynamic population update\n                population_size = min(20 * self.dim, population_size*2)\n                population = np.vstack([population, np.random.rand(population_size - len(population), self.dim)*(bounds.ub - bounds.lb) + bounds.lb])\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        best_solution = self.local_search(best_solution, bounds, func)\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.96 + 0.04 * np.tanh(best_score))\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        perturbation = np.random.uniform(-0.03, 0.03, self.dim)\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Introduce dynamic population sizing in differential evolution to enhance exploration and convergence rates.", "configspace": "", "generation": 88, "fitness": 0.8451700877207777, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.845 with standard deviation 0.049. And the mean value of best solutions found was 0.183 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "27d081dd-2752-447f-a807-4b0534c65655", "metadata": {"aucs": [0.7872948864746194, 0.907252921220691, 0.8409624554670225], "final_y": [0.198374084840228, 0.1690064155853206, 0.1817009981246822]}, "mutation_prompt": null}
{"id": "a3ca3b4b-1641-45e9-86b3-f1122657cd68", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            adaptive_factor = 0.6 + 0.4 * np.cos(np.pi * g / generations)  # Changed adaptive factor\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                mutant = ensure_bounds(a + np.random.rand() * adaptive_factor * (b - c), bounds)  # Modified mutation\n                cross_points = np.random.rand(self.dim) < (0.8 + 0.2 * adaptive_factor)  # Adjusted crossover rate\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        best_solution = self.local_search(best_solution, bounds, func)\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.96 + 0.04 * np.tanh(best_score))\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        perturbation = np.random.normal(0, 0.03, self.dim)  # Changed uniform to normal for refined search\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Improve exploitation by enhancing local search with Gaussian perturbation for better solution refinement.", "configspace": "", "generation": 89, "fitness": 0.8581694674144041, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.858 with standard deviation 0.030. And the mean value of best solutions found was 0.181 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "27d081dd-2752-447f-a807-4b0534c65655", "metadata": {"aucs": [0.8868507180420274, 0.871538061224023, 0.8161196229771619], "final_y": [0.17198343334894217, 0.17484836960486438, 0.19504732023011162]}, "mutation_prompt": null}
{"id": "663c4783-089f-4d4f-8501-6629055441b3", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            adaptive_factor = 0.6 + 0.4 * np.cos(np.pi * g / generations)\n            dynamic_crossover = 0.8 + 0.2 * np.sin(np.pi * g / generations)  # Dynamic crossover probability\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                mutant = ensure_bounds(a + np.random.rand() * adaptive_factor * (b - c), bounds)\n                cross_points = np.random.rand(self.dim) < dynamic_crossover  # Use dynamic crossover\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        best_solution = self.local_search(best_solution, bounds, func)\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.96 + 0.04 * np.tanh(best_score)) / 1.05  # Adjust cooling dynamically\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        perturbation_magnitude = 0.02 + 0.01 * np.random.rand()  # Modified perturbation magnitude\n        perturbation = np.random.normal(0, perturbation_magnitude, self.dim)  # Controlled Gaussian perturbation\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Enhance the exploration-exploitation balance by introducing a dynamic crossover probability and modified perturbation strategy.", "configspace": "", "generation": 90, "fitness": 0.7710331787089967, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.771 with standard deviation 0.031. And the mean value of best solutions found was 0.222 (0. is the best) with standard deviation 0.015.", "error": "", "parent_id": "a3ca3b4b-1641-45e9-86b3-f1122657cd68", "metadata": {"aucs": [0.7275831934044336, 0.7843946144688035, 0.8011217282537528], "final_y": [0.24282405039283506, 0.2129237687393266, 0.20953858451759322]}, "mutation_prompt": null}
{"id": "c545661a-fc53-46fe-a93e-ef6c92feb016", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            adaptive_factor = 0.6 + 0.4 * np.cos(np.pi * g / generations)\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                # Hybrid mutation strategy\n                if np.random.rand() < 0.5:\n                    mutant = ensure_bounds(a + np.random.rand() * adaptive_factor * (b - c), bounds)\n                else:\n                    mutant = ensure_bounds(a + adaptive_factor * (b - c), bounds)\n                cross_points = np.random.rand(self.dim) < (0.8 + 0.2 * adaptive_factor)\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        best_solution = self.local_search(best_solution, bounds, func)\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.96 + 0.03 * np.tanh(best_score)) # Adjusted cooling rate\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        perturbation = np.random.normal(0, 0.03, self.dim)\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Introduce a hybrid mutation strategy and adaptive cooling schedule to enhance exploration and convergence speed in the search space.", "configspace": "", "generation": 91, "fitness": 0.7713510947213201, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.771 with standard deviation 0.095. And the mean value of best solutions found was 0.215 (0. is the best) with standard deviation 0.050.", "error": "", "parent_id": "a3ca3b4b-1641-45e9-86b3-f1122657cd68", "metadata": {"aucs": [0.8561391067682314, 0.8199944362942096, 0.6379197411015196], "final_y": [0.17853153551310808, 0.1804242405488541, 0.2851917836749024]}, "mutation_prompt": null}
{"id": "929c941f-d080-427e-9b80-aedecf59ea0e", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        # Introduced logistic map to generate initial population\n        population = np.empty((population_size, self.dim))\n        x = 0.5  # Initial condition for logistic map\n        for i in range(population_size):\n            for j in range(self.dim):\n                x = 4 * x * (1 - x)  # Logistic map\n                population[i][j] = bounds.lb[j] + x * (bounds.ub[j] - bounds.lb[j])\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            adaptive_factor = 0.6 + 0.4 * np.cos(np.pi * g / generations)  # Changed adaptive factor\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                mutant = ensure_bounds(a + np.random.rand() * adaptive_factor * (b - c), bounds)  # Modified mutation\n                cross_points = np.random.rand(self.dim) < (0.8 + 0.2 * adaptive_factor)  # Adjusted crossover rate\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        best_solution = self.local_search(best_solution, bounds, func)\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.96 + 0.04 * np.tanh(best_score))\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        perturbation = np.random.normal(0, 0.03, self.dim)  # Changed uniform to normal for refined search\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Enhance the exploration phase by introducing diversity with chaotic maps in the initial population generation.", "configspace": "", "generation": 92, "fitness": 0.04723058126684443, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.047 with standard deviation 0.000. And the mean value of best solutions found was 0.918 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "a3ca3b4b-1641-45e9-86b3-f1122657cd68", "metadata": {"aucs": [0.04723058126684443, 0.04723058126684443, 0.04723058126684443], "final_y": [0.9183673469387755, 0.9183673469387755, 0.9183673469387755]}, "mutation_prompt": null}
{"id": "8bd0ffbc-bbd5-4c67-b510-ee7c37171ab7", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            adaptive_factor = 0.6 + 0.4 * np.cos(np.pi * g / generations)\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                mutant = ensure_bounds(a + np.random.rand() * adaptive_factor * (b - c), bounds)\n                cross_points = np.random.rand(self.dim) < (0.8 + 0.2 * adaptive_factor)\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 3 * self.dim:  # Adjusted from 4 to 3 for dynamic resizing\n                population_size = max(5, population_size // 2)\n                population = population[:population_size]\n        best_solution = self.local_search(best_solution, bounds, func)\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.95 + 0.05 * np.tanh(best_score))  # Modified cooling factor for exploration-exploitation balance\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        perturbation = np.random.normal(0, 0.035, self.dim)  # Adjusted perturbation for more granular search\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Improve optimization by introducing dynamic population resizing and adaptive exploration-exploitation balance.", "configspace": "", "generation": 93, "fitness": 0.8566092906994154, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.857 with standard deviation 0.032. And the mean value of best solutions found was 0.182 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "a3ca3b4b-1641-45e9-86b3-f1122657cd68", "metadata": {"aucs": [0.8868507180420279, 0.8714521829635999, 0.8115249710926185], "final_y": [0.17198343334894217, 0.17490739397966415, 0.19863044802488206]}, "mutation_prompt": null}
{"id": "42db194d-7947-4cb1-8a93-97165b85ea2e", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            adaptive_factor = 0.6 + 0.4 * np.cos(np.pi * g / generations)  # Changed adaptive factor\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                if np.random.rand() < 0.5:  # Introduced dynamic mutation strategy\n                    mutant = ensure_bounds(a - adaptive_factor * (b - c), bounds)\n                else:\n                    mutant = ensure_bounds(a + adaptive_factor * (b - c), bounds)  # Modified mutation\n                cross_points = np.random.rand(self.dim) < (0.8 + 0.2 * adaptive_factor)  # Adjusted crossover rate\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        best_solution = self.local_search(best_solution, bounds, func)\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.96 + 0.04 * np.tanh(best_score))\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        perturbation = np.random.normal(0, 0.03, self.dim)  # Changed uniform to normal for refined search\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Enhance exploration by dynamically adjusting the mutation strategy in Differential Evolution for better global search.", "configspace": "", "generation": 94, "fitness": 0.6784808024278672, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.678 with standard deviation 0.063. And the mean value of best solutions found was 0.243 (0. is the best) with standard deviation 0.039.", "error": "", "parent_id": "a3ca3b4b-1641-45e9-86b3-f1122657cd68", "metadata": {"aucs": [0.6956041717864742, 0.7458755421802186, 0.5939626933169092], "final_y": [0.21071469774698426, 0.22056371086179127, 0.29852201030746317]}, "mutation_prompt": null}
{"id": "395a5b8b-c15c-4020-9ba9-e04c673a2a75", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            adaptive_factor = 0.6 + 0.4 * np.cos(np.pi * g / generations)  # Changed adaptive factor\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                mutation_scale = np.random.normal(adaptive_factor, 0.1)  # Dynamic mutation scale\n                mutant = ensure_bounds(a + np.random.rand() * mutation_scale * (b - c), bounds)  # Modified mutation\n                cross_points = np.random.rand(self.dim) < (0.8 + 0.2 * adaptive_factor)  # Adjusted crossover rate\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        best_solution = self.local_search(best_solution, bounds, func)\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.96 + 0.04 * np.tanh(best_score))\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        perturbation = np.random.normal(0, 0.03, self.dim)  # Changed uniform to normal for refined search\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Enhance adaptation by introducing dynamic selection pressure and temporal variability in mutation scale.", "configspace": "", "generation": 95, "fitness": 0.8564048265985525, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.856 with standard deviation 0.016. And the mean value of best solutions found was 0.181 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "a3ca3b4b-1641-45e9-86b3-f1122657cd68", "metadata": {"aucs": [0.8560901723624665, 0.8767306376075531, 0.8363936698256378], "final_y": [0.17086172103996122, 0.17473276777685987, 0.19653585289172648]}, "mutation_prompt": null}
{"id": "95b5b0e1-786b-4186-90a1-c14a66d4b9d7", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            adaptive_factor = 0.6 + 0.4 * np.cos(np.pi * g / generations)\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                mutant = ensure_bounds(a + np.random.rand() * adaptive_factor * (b - c), bounds)\n                cross_points = np.random.rand(self.dim) < (0.8 + 0.2 * np.sin(np.pi * g / generations))  # Changed cosine to sine\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        best_solution = self.local_search(best_solution, bounds, func)\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.96 + 0.04 * np.tanh(best_score))\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        perturbation = np.random.normal(0, 0.03, self.dim)\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Enhance exploration by introducing a sinusoidal adaptation of the crossover rate in the differential evolution process.", "configspace": "", "generation": 96, "fitness": 0.7702224916568755, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.770 with standard deviation 0.032. And the mean value of best solutions found was 0.223 (0. is the best) with standard deviation 0.016.", "error": "", "parent_id": "a3ca3b4b-1641-45e9-86b3-f1122657cd68", "metadata": {"aucs": [0.7259929996234276, 0.7838267958397171, 0.8008476795074818], "final_y": [0.24434426523198227, 0.2133984417539342, 0.20976510961552386]}, "mutation_prompt": null}
{"id": "820bfd7d-1b49-46ca-90ef-10d5aa64009c", "solution": "import numpy as np\n\nclass MultiScaleAdaptiveSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def differential_evolution(self, bounds, population_size, generations, func):\n        def ensure_bounds(vec, bounds):\n            return np.clip(vec, bounds.lb, bounds.ub)\n\n        population = np.random.rand(population_size, self.dim)\n        for i in range(population_size):\n            population[i] = bounds.lb + population[i] * (bounds.ub - bounds.lb)\n        best_solution = None\n        best_score = float('inf')\n\n        for g in range(generations):\n            adaptive_factor = 0.75 + 0.25 * np.cos(np.pi * g / generations)  # Modified adaptive factor\n            for i in range(population_size):\n                indices = np.random.choice(range(population_size), 3, replace=False)\n                a, b, c = population[indices[0]], population[indices[1]], population[indices[2]]\n                mutant = ensure_bounds(a + np.random.rand() * adaptive_factor * (b - c), bounds)\n                cross_points = np.random.rand(self.dim) < (0.8 + 0.2 * adaptive_factor)\n                trial = np.where(cross_points, mutant, population[i])\n                score = func(trial)\n                if score < best_score:\n                    best_score = score\n                    best_solution = trial\n                if score < func(population[i]):\n                    population[i] = trial\n            if len(population) > 4 * self.dim:\n                population_size = max(5, population_size//2)\n                population = population[:population_size]\n        best_solution = self.local_search(best_solution, bounds, func)\n        return best_solution, best_score\n\n    def simulated_annealing(self, initial_solution, initial_temp, cooling_rate, bounds, func):\n        current_solution = initial_solution\n        current_score = func(current_solution)\n        best_solution = np.copy(current_solution)\n        best_score = current_score\n        temp = initial_temp\n\n        while temp > 1e-6:\n            candidate_solution = current_solution + np.random.normal(0, temp, self.dim)\n            candidate_solution = np.clip(candidate_solution, bounds.lb, bounds.ub)\n            candidate_score = func(candidate_solution)\n            if candidate_score < best_score:\n                best_score = candidate_score\n                best_solution = candidate_solution\n            acceptance_prob = np.exp((current_score - candidate_score) / temp)\n            if candidate_score < current_score or np.random.rand() < acceptance_prob:\n                current_solution = candidate_solution\n                current_score = candidate_score\n            temp *= (0.95 + 0.05 * np.tanh(best_score))  # Modified cooling rate mechanism\n        return best_solution, best_score\n\n    def local_search(self, solution, bounds, func):\n        perturbation = np.random.normal(0, 0.03, self.dim)\n        refined_solution = np.clip(solution + perturbation, bounds.lb, bounds.ub)\n        return refined_solution if func(refined_solution) < func(solution) else solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        generations = self.budget // population_size\n        best_solution, _ = self.differential_evolution(bounds, population_size, generations, func)\n        initial_temp = 1.0\n        cooling_rate = 0.9\n        best_solution, best_score = self.simulated_annealing(best_solution, initial_temp, cooling_rate, bounds, func)\n        return best_solution", "name": "MultiScaleAdaptiveSearch", "description": "Enhance the exploration and exploitation balance by modifying mutation factor and cooling mechanism.", "configspace": "", "generation": 97, "fitness": 0.8380943820723158, "feedback": "The algorithm MultiScaleAdaptiveSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.838 with standard deviation 0.055. And the mean value of best solutions found was 0.192 (0. is the best) with standard deviation 0.020.", "error": "", "parent_id": "a3ca3b4b-1641-45e9-86b3-f1122657cd68", "metadata": {"aucs": [0.8755313681366471, 0.8787794040865029, 0.7599723739937971], "final_y": [0.17739443517184372, 0.1773240032586253, 0.22065568520159273]}, "mutation_prompt": null}
