{"id": "58313f66-3ee0-4ae0-bb0b-f822d9da950b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover rate\n        self.evaluations = 0\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)  # Apply local search\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            # Optional: Reduce dimension by initializing fewer layers at first\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim))\n            self.dim = active_layers\n\n        return best_solution", "name": "AdaptiveHybridEvolutionarySearch", "description": "The algorithm, Adaptive Hybrid Evolutionary Search (AHES), dynamically combines Differential Evolution (DE) for global exploration and a hybrid local search that switches between hill climbing and pattern search, adjusting strategies based on convergence and a layer-wise optimization schedule.", "configspace": "", "generation": 0, "fitness": 0.8100082325874611, "feedback": "The algorithm AdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.810 with standard deviation 0.030. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": null, "metadata": {"aucs": [0.8371189354712839, 0.8241953198724521, 0.7687104424186473], "final_y": [0.12896873411993903, 0.1148922273157097, 0.11967222108355502]}, "mutation_prompt": null}
{"id": "6de0507f-fde7-4751-907e-5f0f7281dc3a", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.9  # DE mutation factor\n        self.cr = 0.9  # DE crossover rate\n        self.evaluations = 0\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)  # Apply local search\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            # Optional: Reduce dimension by initializing fewer layers at first\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim))\n            self.dim = active_layers\n\n        return best_solution", "name": "AdaptiveHybridEvolutionarySearch", "description": "The Adaptive Hybrid Evolutionary Search (AHES) combines Differential Evolution with hybrid local search, adjusting strategies based on convergence and layer-wise optimization, with an enhanced mutation strategy for improved exploration.", "configspace": "", "generation": 1, "fitness": 0.8226903815768409, "feedback": "The algorithm AdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.823 with standard deviation 0.073. And the mean value of best solutions found was 0.138 (0. is the best) with standard deviation 0.033.", "error": "", "parent_id": "58313f66-3ee0-4ae0-bb0b-f822d9da950b", "metadata": {"aucs": [0.8614111713582605, 0.8862458497303383, 0.7204141236419244], "final_y": [0.11264049835226242, 0.11596857390895166, 0.18503742438597293]}, "mutation_prompt": null}
{"id": "da65bd11-ca4c-4a9d-a719-a88d0f602595", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover rate\n        self.evaluations = 0\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c]) + 0.1 * (population[a] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)  # Apply local search\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            # Optional: Reduce dimension by initializing fewer layers at first\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim))\n            self.dim = active_layers\n\n        return best_solution", "name": "AdaptiveHybridEvolutionarySearch", "description": "Adaptive Hybrid Evolutionary Search (AHES) with improved mutation strategy to enhance exploration capabilities and solution quality.", "configspace": "", "generation": 1, "fitness": 0.7838708144446033, "feedback": "The algorithm AdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.784 with standard deviation 0.036. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "58313f66-3ee0-4ae0-bb0b-f822d9da950b", "metadata": {"aucs": [0.7580530608085845, 0.8342108913500026, 0.759348491175223], "final_y": [0.1369534030791998, 0.13021770838096502, 0.12665643711116914]}, "mutation_prompt": null}
{"id": "b94ac15d-3f87-499f-abeb-f31aff662c1b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover rate\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        self.f = 0.5 + np.random.rand() * 0.5\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation = np.random.normal(0, 0.01, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.robustness_check(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            self.dim = active_layers\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "The algorithm, Enhanced Adaptive Hybrid Evolutionary Search (EAHES), introduces adaptive mutation and crossover rates, integrates a robustness check, and dynamically manages active layers to enhance performance in noisy high-dimensional settings.", "configspace": "", "generation": 1, "fitness": 0.8594405291794972, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.859 with standard deviation 0.039. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "58313f66-3ee0-4ae0-bb0b-f822d9da950b", "metadata": {"aucs": [0.8070460906205784, 0.870655144940295, 0.9006203519776181], "final_y": [0.12668915884201393, 0.1260614532275921, 0.11208816691901902]}, "mutation_prompt": null}
{"id": "67642da4-1873-4389-8312-7ea8f5873a21", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8\n        self.cr = 0.9\n        self.evaluations = 0\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            population_std = np.std(population, axis=0)  # Track population diversity\n            self.f = 0.5 + 0.5 * np.median(population_std) / np.max(population_std)  # Adjust mutation rate\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim))\n            self.dim = active_layers\n\n        return best_solution", "name": "AdaptiveHybridEvolutionarySearch", "description": "Enhance Adaptive Hybrid Evolutionary Search by dynamically adjusting mutation and crossover rates based on population diversity.", "configspace": "", "generation": 1, "fitness": 0.7915500002269676, "feedback": "The algorithm AdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.792 with standard deviation 0.035. And the mean value of best solutions found was 0.151 (0. is the best) with standard deviation 0.015.", "error": "", "parent_id": "58313f66-3ee0-4ae0-bb0b-f822d9da950b", "metadata": {"aucs": [0.8416324689466954, 0.76890311738062, 0.7641144143535873], "final_y": [0.13435453994519053, 0.1702433386818767, 0.14731878338232696]}, "mutation_prompt": null}
{"id": "db274716-7b8c-4c7c-9c24-6538e8b56199", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8 \n        self.cr = 0.9\n        self.evaluations = 0\n        \n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_f = self.f * (1 - self.evaluations / self.budget)  # Dynamic mutation factor\n        mutant = population[a] + adaptive_f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)  \n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim))\n            self.dim = active_layers\n            self.population_size = max(10, int(self.population_size * (1 - self.evaluations / self.budget)))  # Adaptive population size\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "The algorithm, Enhanced Adaptive Hybrid Evolutionary Search (EAHES), introduces a dynamic mutation factor and adaptive population size to balance exploration and exploitation, optimizing resources and improving convergence toward the best solution.", "configspace": "", "generation": 1, "fitness": 0.841259638906573, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.841 with standard deviation 0.054. And the mean value of best solutions found was 0.136 (0. is the best) with standard deviation 0.025.", "error": "", "parent_id": "58313f66-3ee0-4ae0-bb0b-f822d9da950b", "metadata": {"aucs": [0.8994863783133741, 0.76890311738062, 0.8553894210257249], "final_y": [0.1101229847183659, 0.1702433386818767, 0.12740119411343231]}, "mutation_prompt": null}
{"id": "a0dfb4eb-e3fc-4871-b02e-df0809be3424", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover rate\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        self.f = 0.5 + np.random.rand() * 0.3  # Adjusted mutation factor range\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B', options={'gtol': 1e-5})  # Increased precision\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation = np.random.normal(0, 0.01, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.robustness_check(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            self.dim = active_layers\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "The Improved Enhanced Adaptive Hybrid Evolutionary Search (IEAHES) enhances local search by increasing robustness and includes diversity preservation to maintain a broader search through dynamically adjusted mutation range.", "configspace": "", "generation": 2, "fitness": 0.8254295113681337, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.825 with standard deviation 0.059. And the mean value of best solutions found was 0.129 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "b94ac15d-3f87-499f-abeb-f31aff662c1b", "metadata": {"aucs": [0.7433457245113033, 0.8520172810442302, 0.8809255285488674], "final_y": [0.13704760260538895, 0.1233145026215986, 0.12664813469585268]}, "mutation_prompt": null}
{"id": "be8dc16b-9c61-49fa-a3ab-6c54e2952ed2", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.max_population_size = 40  # Dynamically adjust population size\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover rate\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        self.f = 0.5 + np.random.rand() * 0.5\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(len(population)) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation = np.random.normal(0, 0.05, size=solution.shape)  # Increased perturbation\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(len(population)):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.robustness_check(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        # Initialize population\n        population_size = self.initial_population_size\n        population = np.random.uniform(self.lb, self.ub, (population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            population_size = min(self.max_population_size, self.initial_population_size + int((self.evaluations / self.budget) * (self.max_population_size - self.initial_population_size)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += len(population)\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            self.dim = active_layers\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "By introducing a dynamic adjustment of population size and enhanced robustness check, the Enhanced Adaptive Hybrid Evolutionary Search (EAHES) is refined to improve performance in complex, noisy optimization landscapes.", "configspace": "", "generation": 2, "fitness": 0.832167613674918, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.832 with standard deviation 0.047. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "b94ac15d-3f87-499f-abeb-f31aff662c1b", "metadata": {"aucs": [0.8876855414728066, 0.8366032611455023, 0.7722140384064448], "final_y": [0.1142040683032911, 0.13151872960626632, 0.13334223699459358]}, "mutation_prompt": null}
{"id": "5817a5c1-a7ca-44a3-8735-01c8ef8f5807", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover rate\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        self.f = 0.5 + np.random.rand() * 0.5\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation = np.random.normal(0, 0.01, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.robustness_check(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            # Dynamically adjust population size based on progress\n            self.population_size = max(10, int(20 * (1 - self.evaluations / self.budget)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            self.dim = active_layers\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "The Enhanced Adaptive Hybrid Evolutionary Search (EAHES) is refined by introducing a strategy to dynamically adjust the population size based on convergence progress, enhancing exploration and exploitation balance.", "configspace": "", "generation": 2, "fitness": 0.8743535880844124, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.874 with standard deviation 0.018. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "b94ac15d-3f87-499f-abeb-f31aff662c1b", "metadata": {"aucs": [0.8505853759398311, 0.880005617540597, 0.8924697707728091], "final_y": [0.11475806337437267, 0.12277187653683885, 0.12451990802463064]}, "mutation_prompt": null}
{"id": "a25ea196-1d41-419d-a6bd-625d02b28245", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover rate\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        self.f = 0.5 + np.random.rand() * 0.5\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def adapt_population_size(self):\n        if self.evaluations > 0.5 * self.budget:\n            self.population_size = max(5, self.population_size // 2)\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation = np.random.normal(0, 0.01, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.robustness_check(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            self.adapt_population_size()\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            self.dim = active_layers\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "The algorithm Enhanced Adaptive Hybrid Evolutionary Search (EAHES) is improved by integrating adaptive population sizing based on convergence, enhancing performance in noisy high-dimensional settings.", "configspace": "", "generation": 2, "fitness": 0.8461140700599256, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.846 with standard deviation 0.007. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "b94ac15d-3f87-499f-abeb-f31aff662c1b", "metadata": {"aucs": [0.8384721485951122, 0.8445529656462986, 0.8553170959383659], "final_y": [0.11430070502165357, 0.134019311414743, 0.13046849537979444]}, "mutation_prompt": null}
{"id": "80202f91-b637-4d3e-8a10-aeabff3a1cc4", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover rate\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        self.f = 0.5 + np.random.rand() * 0.5\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation = np.random.normal(0, 0.01, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.robustness_check(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        # Initialize population\n        self.population_size = self.initial_population_size  # Adjusted\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            self.population_size = self.initial_population_size + int(self.evaluations / self.budget * 10)  # Adjusted\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            self.dim = active_layers\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Refining EnhancedAdaptiveHybridEvolutionarySearch by introducing dynamic adjustment of population size based on budget progression to balance exploration and exploitation more effectively.", "configspace": "", "generation": 2, "fitness": 0.8401715951699495, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.840 with standard deviation 0.029. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "b94ac15d-3f87-499f-abeb-f31aff662c1b", "metadata": {"aucs": [0.8729646228586941, 0.8458693162909485, 0.8016808463602063], "final_y": [0.11707410247438099, 0.11858337051857026, 0.13038703778380512]}, "mutation_prompt": null}
{"id": "6a170307-c537-4f4d-923e-baa896d3a4a8", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover rate\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        self.f = 0.5 + np.random.rand() * 0.5\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        diversity_factor = np.std(population, axis=0).mean()  # New line\n        mutant = population[a] + self.f * diversity_factor * (population[b] - population[c])  # Modified line\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation = np.random.normal(0, 0.01, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.robustness_check(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            # Dynamically adjust population size based on progress\n            self.population_size = max(10, int(20 * (1 - self.evaluations / self.budget)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            self.dim = active_layers\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "The Enhanced Adaptive Hybrid Evolutionary Search (EAHES) is refined by incorporating diversity preservation through adaptive mutation rates, enhancing exploration with minimal code changes.", "configspace": "", "generation": 3, "fitness": 0.8031543992030189, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.803 with standard deviation 0.025. And the mean value of best solutions found was 0.150 (0. is the best) with standard deviation 0.015.", "error": "", "parent_id": "5817a5c1-a7ca-44a3-8735-01c8ef8f5807", "metadata": {"aucs": [0.8149505946432772, 0.76890311738062, 0.8256094855851595], "final_y": [0.14343072426797066, 0.1702433386818767, 0.13588602921233617]}, "mutation_prompt": null}
{"id": "a22b7c2e-36b9-4e78-a2fa-1fdf4caadc7a", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover rate\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        progress_ratio = self.evaluations / self.budget\n        self.f = 0.5 + np.random.rand() * 0.5 * (1 - progress_ratio)  # Dynamic mutation factor scaling\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation = np.random.normal(0, 0.01, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.robustness_check(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            # Dynamically adjust population size based on progress\n            self.population_size = max(10, int(20 * (1 - self.evaluations / self.budget)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            self.dim = active_layers\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Enhanced Adaptive Hybrid Evolutionary Search (EAHES) with improved robustness via dynamic mutation factor scaling to better balance exploration and exploitation.", "configspace": "", "generation": 3, "fitness": 0.8044970115994503, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.804 with standard deviation 0.031. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "5817a5c1-a7ca-44a3-8735-01c8ef8f5807", "metadata": {"aucs": [0.8052483728153517, 0.8418321235022029, 0.7664105384807964], "final_y": [0.13417951451790444, 0.13366129285675454, 0.1256796343300105]}, "mutation_prompt": null}
{"id": "f44a4c10-bf5a-466a-b78b-06f4219bcf29", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover rate\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        self.f = 0.5 + np.random.rand() * 0.5\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb + 0.005, self.ub - 0.005)  # Change 1\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B', options={'maxiter': 10})  # Change 2\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation = np.random.normal(0, 0.01, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.robustness_check(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            # Dynamically adjust population size based on progress\n            self.population_size = max(10, int(20 * (1 - self.evaluations / self.budget)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            self.dim = active_layers\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Improved robustness and exploitation balance by refining local search parameters and incorporating noise resilience.", "configspace": "", "generation": 3, "fitness": 0.8084848632857268, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.808 with standard deviation 0.025. And the mean value of best solutions found was 0.142 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "5817a5c1-a7ca-44a3-8735-01c8ef8f5807", "metadata": {"aucs": [0.8405260971024471, 0.8045445499745674, 0.7803839427801655], "final_y": [0.1234185150470507, 0.1530680768124112, 0.1504831674625451]}, "mutation_prompt": null}
{"id": "11a682d1-0695-45c0-8c22-11e1afba85c8", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover rate\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        self.f = 0.5 + np.random.rand() * 0.5\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        scale_factor = 1 - (self.evaluations / self.budget)  # New dynamic scaling\n        mutant = population[a] + scale_factor * self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation = np.random.normal(0, 0.01, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.robustness_check(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            # Dynamically adjust population size based on progress\n            self.population_size = max(10, int(20 * (1 - self.evaluations / self.budget)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            self.dim = active_layers\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Improved global exploration by adapting mutation strategy using a dynamic scaling mechanism.", "configspace": "", "generation": 3, "fitness": 0.792648329150455, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.793 with standard deviation 0.033. And the mean value of best solutions found was 0.139 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "5817a5c1-a7ca-44a3-8735-01c8ef8f5807", "metadata": {"aucs": [0.7644097603888269, 0.8384042976236037, 0.7751309294389344], "final_y": [0.13487421349019602, 0.13785995420328234, 0.14559209089773417]}, "mutation_prompt": null}
{"id": "f3904ed5-97bc-4fe7-844b-a75c956eddba", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover rate\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        self.f = 0.5 + np.random.rand() * 0.5 * (1 - self.evaluations / self.budget)\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation = np.random.normal(0, 0.01, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.robustness_check(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            # Dynamically adjust population size based on progress\n            self.population_size = max(10, int(20 * (1 - self.evaluations / self.budget)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            self.dim = active_layers\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Enhanced Adaptation Strategy: Integrate a convergence-based scaling mechanism to fine-tune mutation factor dynamically, improving exploration-exploitation balance.", "configspace": "", "generation": 3, "fitness": 0.8701845276888379, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.870 with standard deviation 0.014. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "5817a5c1-a7ca-44a3-8735-01c8ef8f5807", "metadata": {"aucs": [0.8788822966233114, 0.8508676923904641, 0.8808035940527379], "final_y": [0.11060184094893843, 0.1280501172656724, 0.1256760464877109]}, "mutation_prompt": null}
{"id": "82a69a75-7877-4f88-9239-9706cb29cf42", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover rate\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        self.f = 0.5 + np.random.rand() * 0.5 * (1 - self.evaluations / self.budget)\n        self.cr = 0.6 + np.random.rand() * 0.4 * (self.evaluations / self.budget)  # Change made here\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation = np.random.normal(0, 0.01, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.robustness_check(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            # Dynamically adjust population size based on progress\n            self.population_size = max(10, int(20 * (1 - self.evaluations / self.budget)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            self.dim = active_layers\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Incorporate a dynamic crossover rate adjustment to improve adaptability during different optimization phases.", "configspace": "", "generation": 4, "fitness": 0.8509941233666458, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.851 with standard deviation 0.048. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "f3904ed5-97bc-4fe7-844b-a75c956eddba", "metadata": {"aucs": [0.8011238777273957, 0.8353288348452419, 0.9165296575272998], "final_y": [0.12083882672216584, 0.12331454136420916, 0.11280865543536012]}, "mutation_prompt": null}
{"id": "51d20724-61af-498a-b7da-e208d0fb66b2", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover rate\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        self.f = 0.5 + np.random.rand() * 0.5 * (1 - self.evaluations / self.budget)\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='Nelder-Mead')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation = np.random.normal(0, 0.01, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.robustness_check(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            # Dynamically adjust population size based on progress\n            self.population_size = max(10, int(20 * (1 - self.evaluations / self.budget)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            self.dim = active_layers\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Enhance local search efficiency by replacing L-BFGS-B with Nelder-Mead, improving convergence speed under the 4.1% change constraint.", "configspace": "", "generation": 4, "fitness": 0.8246111343211849, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.825 with standard deviation 0.068. And the mean value of best solutions found was 0.143 (0. is the best) with standard deviation 0.027.", "error": "", "parent_id": "f3904ed5-97bc-4fe7-844b-a75c956eddba", "metadata": {"aucs": [0.7345700470705696, 0.8399695575731124, 0.8992937983198728], "final_y": [0.18149840732235178, 0.12467781591393079, 0.12282452903935448]}, "mutation_prompt": null}
{"id": "c68e2bec-56c2-4e89-a657-ef81c1ee0442", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover rate\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        self.f = 0.5 + np.random.rand() * 0.5 * (1 - self.evaluations / self.budget)\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        # Weighted recombination here\n        trial = np.where(cross_points, 0.5 * (mutant + target), target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation = np.random.normal(0, 0.01, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.robustness_check(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            # Dynamically adjust population size based on progress\n            self.population_size = max(10, int(20 * (1 - self.evaluations / self.budget)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            self.dim = active_layers\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Introduce a weighted recombination strategy during crossover to better exploit beneficial traits from multiple individuals.", "configspace": "", "generation": 4, "fitness": 0.8049996479836037, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.805 with standard deviation 0.029. And the mean value of best solutions found was 0.135 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "f3904ed5-97bc-4fe7-844b-a75c956eddba", "metadata": {"aucs": [0.8443234776368083, 0.7960222275040074, 0.7746532388099954], "final_y": [0.13039769259922662, 0.15458334166248278, 0.12080857274756529]}, "mutation_prompt": null}
{"id": "199f24b6-c966-4753-8acb-10e998cb9b77", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover rate\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        self.f = 0.5 + np.random.rand() * 0.5 * (1 - self.evaluations / self.budget)\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation = np.random.normal(0, 0.01, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.robustness_check(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            # Dynamically adjust population size based on progress\n            self.population_size = max(10, int(20 * (1 - self.evaluations / self.budget)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 10 == 0: self.f *= 0.95  # Adaptive learning rate\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Improved parameter adaptation with adaptive learning rates, enhancing convergence speed and solution quality.", "configspace": "", "generation": 4, "fitness": 0.8807797673544934, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.881 with standard deviation 0.017. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "f3904ed5-97bc-4fe7-844b-a75c956eddba", "metadata": {"aucs": [0.8603036902808494, 0.9007691746069983, 0.8812664371756324], "final_y": [0.11475806337437267, 0.11767020641627302, 0.12665594046798323]}, "mutation_prompt": null}
{"id": "1ecf1fab-4815-4bcb-8fa5-96d322d6121e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover rate\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        self.f = 0.5 + np.random.rand() * 0.5 * (1 - self.evaluations / self.budget)\n        self.cr = 0.8 + np.random.rand() * 0.2 * (1 - self.evaluations / self.budget)  # Adjusted line\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation = np.random.normal(0, 0.01, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.robustness_check(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            # Dynamically adjust population size based on progress\n            self.population_size = max(10, int(20 * (1 - self.evaluations / self.budget)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            self.dim = active_layers\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Introduce adaptive crossover rate scaling based on current evaluations to enhance exploitation capabilities.", "configspace": "", "generation": 4, "fitness": 0.8636848250844045, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.864 with standard deviation 0.018. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "f3904ed5-97bc-4fe7-844b-a75c956eddba", "metadata": {"aucs": [0.8608005890306105, 0.8873543163581272, 0.8428995698644756], "final_y": [0.1142040683032911, 0.11433368565752478, 0.12978732119168634]}, "mutation_prompt": null}
{"id": "8cc77d60-09a9-40c8-a055-cb045c7d46d9", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover rate\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        self.f = 0.5 + np.random.rand() * 0.5 * (1 - self.evaluations / self.budget)\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.01 * (1 - self.evaluations / self.budget)  # Adaptive perturbation scaling\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.robustness_check(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            # Dynamically adjust population size based on progress\n            self.population_size = max(10, int(20 * (1 - self.evaluations / self.budget)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 10 == 0: self.f *= 0.95  # Adaptive learning rate\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Introduced adaptive perturbation scaling in robustness check to enhance solution resilience with minimal code change.", "configspace": "", "generation": 5, "fitness": 0.8233661816842824, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.823 with standard deviation 0.018. And the mean value of best solutions found was 0.136 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "199f24b6-c966-4753-8acb-10e998cb9b77", "metadata": {"aucs": [0.8483560908862489, 0.8051549764942568, 0.8165874776723419], "final_y": [0.12586574566025077, 0.1451930712089834, 0.13823458377194198]}, "mutation_prompt": null}
{"id": "c26afb17-362d-49c1-862d-dd8668f9fc7a", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover rate\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        self.f = 0.5 + np.random.rand() * 0.5 * (1 - self.evaluations / self.budget)\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        active_layers = min(self.dim, max(1, int((self.evaluations / self.budget) * self.dim)))  # Incremental layer increase\n        res = minimize(self.func, x[:active_layers], bounds=self.bounds[:active_layers], method='L-BFGS-B')\n        return np.concatenate((res.x, x[active_layers:])) if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation = np.random.normal(0, 0.01, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.robustness_check(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            # Dynamically adjust population size based on progress\n            self.population_size = max(10, int(20 * (1 - self.evaluations / self.budget)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 10 == 0: self.f *= 0.95  # Adaptive learning rate\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Incorporate gradual layer increase in local search for better scalability with problem complexity.", "configspace": "", "generation": 5, "fitness": 0.8000792069983304, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.800 with standard deviation 0.009. And the mean value of best solutions found was 0.142 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "199f24b6-c966-4753-8acb-10e998cb9b77", "metadata": {"aucs": [0.8012034729075241, 0.8101844542394631, 0.7888496938480041], "final_y": [0.1379479248269333, 0.14123346492151767, 0.14632684709984334]}, "mutation_prompt": null}
{"id": "51b936af-0c96-4f81-a4d6-9e631bc3f44f", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover rate\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        self.f = 0.5 + np.random.rand() * 0.5 * (1 - self.evaluations / self.budget)\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation = np.random.normal(0, 0.01, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def diversity_selection(self, population, new_population):\n        combined = np.vstack((population, new_population))\n        unique_solutions = np.unique(combined, axis=0)\n        if len(unique_solutions) < self.population_size:\n            return unique_solutions\n        return unique_solutions[np.random.choice(len(unique_solutions), self.population_size, replace=False)]\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.robustness_check(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return self.diversity_selection(population, new_population)\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            self.population_size = max(10, int(20 * (1 - self.evaluations / self.budget)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 10 == 0: self.f *= 0.95 \n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Enhanced exploration by dynamic mutation and diversity-based selection in hybrid evolutionary search.", "configspace": "", "generation": 5, "fitness": 0.7953672019036165, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.795 with standard deviation 0.029. And the mean value of best solutions found was 0.147 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "199f24b6-c966-4753-8acb-10e998cb9b77", "metadata": {"aucs": [0.8290194274885812, 0.7986960341542981, 0.7583861440679701], "final_y": [0.1298011325335786, 0.14981593574400043, 0.16135667753261895]}, "mutation_prompt": null}
{"id": "2ab4e313-ea93-481a-bd3f-cd29d39e9d8f", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover rate\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        self.f = 0.5 + np.random.rand() * 0.5 * (1 - self.evaluations / self.budget)\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation = np.random.normal(0, 0.01, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.robustness_check(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            # Dynamically adjust population size based on progress\n            self.population_size = max(10, int(20 * (1 - self.evaluations / (2 * self.budget))))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 10 == 0: self.f *= 0.95  # Adaptive learning rate\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Introduced a decay in population size linked to evaluations to balance exploration and exploitation.", "configspace": "", "generation": 5, "fitness": 0.7996214559202999, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.800 with standard deviation 0.013. And the mean value of best solutions found was 0.140 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "199f24b6-c966-4753-8acb-10e998cb9b77", "metadata": {"aucs": [0.8173854971797843, 0.7962364189176361, 0.7852424516634793], "final_y": [0.13317546477694941, 0.135609957757735, 0.15213921605878733]}, "mutation_prompt": null}
{"id": "7d00c8a1-cb4d-44cc-98dd-235b6bc795fd", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover rate\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        self.f = 0.5 + np.random.rand() * 0.5 * (1 - self.evaluations / self.budget)\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        for _ in range(5):  # Increase robustness check samples\n            perturbation = np.random.normal(0, 0.01, size=solution.shape)\n            solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return solution\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.robustness_check(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            # Dynamically adjust population size based on progress\n            self.population_size = max(10, int(20 * (1 - self.evaluations / self.budget)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 10 == 0: self.f *= 0.95  # Adaptive learning rate\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Enhanced Adaptive Hybrid Evolutionary Search with enhanced robustness by incorporating more systematic perturbation analysis.", "configspace": "", "generation": 5, "fitness": 0.7965925716469663, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.797 with standard deviation 0.005. And the mean value of best solutions found was 0.137 (0. is the best) with standard deviation 0.015.", "error": "", "parent_id": "199f24b6-c966-4753-8acb-10e998cb9b77", "metadata": {"aucs": [0.7902795942076783, 0.8008686834827103, 0.79862943725051], "final_y": [0.11603346493435918, 0.1462584267634559, 0.14766061896837213]}, "mutation_prompt": null}
{"id": "9befa46d-7b89-42eb-a8a9-e0ceeddb35ec", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover rate\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        self.f = 0.5 + np.random.rand() * 0.5 * (1 - self.evaluations / self.budget)\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.01 * (1 - self.evaluations / self.budget)  # Adaptive perturbation scaling\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.robustness_check(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            # Dynamically adjust population size based on progress\n            self.population_size = max(10, int(20 * (1 - self.evaluations / self.budget)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            stochastic_layers = np.random.choice([0, 1], size=self.dim, p=[0.2, 0.8])\n            best_solution *= stochastic_layers  # Introduce stochastic layer activation\n            if self.evaluations % 10 == 0: self.f *= 0.95  # Adaptive learning rate\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Introduced stochastic layer activation to enhance exploration and modularity detection within solutions.", "configspace": "", "generation": 6, "fitness": 0.8330574233500245, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.833 with standard deviation 0.048. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "8cc77d60-09a9-40c8-a055-cb045c7d46d9", "metadata": {"aucs": [0.8903549704981267, 0.8366032611455023, 0.7722140384064448], "final_y": [0.11209322476763972, 0.13151872960626632, 0.13334223699459358]}, "mutation_prompt": null}
{"id": "19d2d3da-cf66-4837-ac2b-35a19573d37e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover rate\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        self.f = 0.5 + np.random.rand() * 0.5 * (1 - self.evaluations / self.budget)\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.015 * (1 - self.evaluations / self.budget)  # Enhanced perturbation scaling\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.robustness_check(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            # Dynamically adjust population size based on progress\n            self.population_size = max(10, int(20 * (1 - self.evaluations / self.budget)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 10 == 0: self.f *= 0.95  # Adaptive learning rate\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Enhance adaptability by modifying the perturbation scale calculation in robustness check for improved resilience.", "configspace": "", "generation": 6, "fitness": 0.8515412978934275, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.852 with standard deviation 0.034. And the mean value of best solutions found was 0.129 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "8cc77d60-09a9-40c8-a055-cb045c7d46d9", "metadata": {"aucs": [0.8101375983574666, 0.8520165245500069, 0.8924697707728091], "final_y": [0.13802994677410918, 0.12331443616800919, 0.12451990802463064]}, "mutation_prompt": null}
{"id": "59e84f2c-72c1-4f18-87ce-ad001ac36047", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover rate\n        self.evaluations = 0\n\n    def adapt_parameters(self, improvement):\n        self.f = 0.5 + np.random.rand() * 0.5 * (1 - improvement)\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.01 * (1 - self.evaluations / self.budget)  # Adaptive perturbation scaling\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            improvement = (self.func(population[i]) - self.func(population[np.argmin([self.func(ind) for ind in population])])) / self.func(population[i])\n            self.adapt_parameters(improvement)\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.robustness_check(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            # Dynamically adjust population size based on progress\n            self.population_size = max(10, int(20 * (1 - self.evaluations / self.budget)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 10 == 0: self.f *= 0.95  # Adaptive learning rate\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Improved convergence by dynamically adjusting mutation factor based on the best solution's improvement.", "configspace": "", "generation": 6, "fitness": 0.844335430784656, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.844 with standard deviation 0.031. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "8cc77d60-09a9-40c8-a055-cb045c7d46d9", "metadata": {"aucs": [0.8062113686528961, 0.8458693951522044, 0.8809255285488674], "final_y": [0.12949177777860255, 0.118583276488337, 0.12664813469585268]}, "mutation_prompt": null}
{"id": "5cc00340-8dc9-4566-a268-ad0e9b5ef9e5", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover rate\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        self.f = 0.5 + np.random.rand() * 0.5 * (1 - self.evaluations / self.budget)\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.01 * np.exp(-5 * self.evaluations / self.budget)  # Adaptive perturbation scaling\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.robustness_check(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            # Dynamically adjust population size based on progress\n            self.population_size = max(10, int(20 * (1 - self.evaluations / self.budget)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 10 == 0: self.f *= 0.95  # Adaptive learning rate\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Introduced adaptive perturbation scaling in robustness check to enhance solution resilience by varying perturbation scale exponentially.", "configspace": "", "generation": 6, "fitness": 0.8222493360677613, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.822 with standard deviation 0.045. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "8cc77d60-09a9-40c8-a055-cb045c7d46d9", "metadata": {"aucs": [0.7699045780032627, 0.880005617540597, 0.816837812659424], "final_y": [0.14369495040793923, 0.12277187653683885, 0.11014614773243359]}, "mutation_prompt": null}
{"id": "11b382af-5e0a-4444-8ba7-93fc95335e74", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover rate\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        temperature = 1 - self.evaluations / self.budget\n        self.f = (0.5 + np.random.rand() * 0.5) * temperature\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.01 * (1 - self.evaluations / self.budget)  # Adaptive perturbation scaling\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.robustness_check(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            # Dynamically adjust population size based on progress\n            self.population_size = max(10, int(20 * (1 - self.evaluations / self.budget)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 10 == 0: self.f *= 0.95  # Adaptive learning rate\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Introduced temperature-based adaptive factor for mutation to enhance exploration-exploitation balance.", "configspace": "", "generation": 6, "fitness": 0.8461103410877642, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.846 with standard deviation 0.007. And the mean value of best solutions found was 0.130 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "8cc77d60-09a9-40c8-a055-cb045c7d46d9", "metadata": {"aucs": [0.8384611514800487, 0.8445527758448779, 0.8553170959383659], "final_y": [0.12576193519714263, 0.13401941001913065, 0.13046849537979444]}, "mutation_prompt": null}
{"id": "1d57dd9b-62d1-4df8-8749-b886b2df442a", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover rate\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        self.f = 0.5 + np.random.rand() * 0.5 * (1 - self.evaluations / self.budget)\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.015 * (1 - self.evaluations / self.budget)\n        perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, size=solution.shape)  # Changed distribution\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.robustness_check(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            # Dynamically adjust population size based on progress\n            self.population_size = max(10, int(20 * (1 - self.evaluations / self.budget)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 10 == 0: self.f *= 0.95  # Adaptive learning rate\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Refine robustness by modifying perturbation distribution to enhance solution stability.", "configspace": "", "generation": 7, "fitness": 0.8266491079201482, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.827 with standard deviation 0.039. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "19d2d3da-cf66-4837-ac2b-35a19573d37e", "metadata": {"aucs": [0.8557166277339356, 0.8520166576200644, 0.7722140384064448], "final_y": [0.11596793592992993, 0.12331440184543974, 0.13334223699459358]}, "mutation_prompt": null}
{"id": "c98bdf33-15b7-40d9-adeb-8fb6ca44c865", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover rate\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        self.f = 0.5 + np.random.rand() * 0.5 * (1 - self.evaluations / self.budget)\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.015 * (1 - self.evaluations / self.budget)  # Enhanced perturbation scaling\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.robustness_check(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            self.f *= (1 + 0.1 * (self.budget - self.evaluations) / self.budget)  # Line modified for diversity\n            self.population_size = max(10, int(20 * (1 - self.evaluations / self.budget)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 10 == 0: self.f *= 0.95  # Adaptive learning rate\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Improve robustness by scaling the mutation factor with evaluations for better diversity throughout the optimization process.", "configspace": "", "generation": 7, "fitness": 0.8662809879774139, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.866 with standard deviation 0.024. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "19d2d3da-cf66-4837-ac2b-35a19573d37e", "metadata": {"aucs": [0.898973042350212, 0.8445528256436641, 0.8553170959383659], "final_y": [0.1106017941243812, 0.13401938414798398, 0.13046849537979444]}, "mutation_prompt": null}
{"id": "61bb8fa9-b748-47dd-8ad3-6d46427fdd21", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover rate\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        self.f = 0.5 + np.random.rand() * 0.5 * (1 - self.evaluations / self.budget)\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.02 * (1 - self.evaluations / self.budget)  # Enhanced perturbation scaling\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.robustness_check(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            # Dynamically adjust population size based on progress\n            self.population_size = max(10, int(20 * (1 - self.evaluations / self.budget)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 10 == 0: self.f *= 0.95  # Adaptive learning rate\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Fine-tune hybrid search with adaptive learning and population dynamics for enhanced robustness.", "configspace": "", "generation": 7, "fitness": 0.8891887553500927, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.889 with standard deviation 0.007. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "19d2d3da-cf66-4837-ac2b-35a19573d37e", "metadata": {"aucs": [0.895090877736872, 0.880005617540597, 0.8924697707728091], "final_y": [0.11220485105705558, 0.12277187653683885, 0.12451990802463064]}, "mutation_prompt": null}
{"id": "b6f56950-387b-4350-89a9-f88837229fa7", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover rate\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        self.f = 0.5 + np.random.rand() * 0.5 * (1 - self.evaluations / self.budget)\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.015 * (1 - self.evaluations / self.budget)  # Enhanced perturbation scaling\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.robustness_check(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            # Dynamically adjust population size based on progress\n            self.population_size = max(10, int(20 * ((self.budget - self.evaluations) / self.budget)**0.5))  # Adjusted dynamic population size\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 10 == 0: self.f *= 0.95  # Adaptive learning rate\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Refine adaptability by adjusting dynamic population size more responsively to evaluation progress for improved convergence.", "configspace": "", "generation": 7, "fitness": 0.8578612489489673, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.858 with standard deviation 0.016. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "19d2d3da-cf66-4837-ac2b-35a19573d37e", "metadata": {"aucs": [0.8467888071225994, 0.8458694111754351, 0.8809255285488674], "final_y": [0.1358074243302838, 0.1185832573830422, 0.12664813469585268]}, "mutation_prompt": null}
{"id": "e0af09ee-3e4d-4a0a-9d2a-94d01395f946", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover rate\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        self.f = 0.5 + np.random.rand() * 0.5 * (1 - self.evaluations / self.budget)\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        if np.random.rand() < 0.5:  # Strategic local search application\n            res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n            return res.x if res.success else x\n        else:\n            return x\n\n    def robustness_check(self, solution):\n        noise_level = 0.01 + 0.02 * np.sin(2 * np.pi * self.evaluations / self.budget)  # Adaptive noise handling\n        perturbation = np.random.normal(0, noise_level, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.robustness_check(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            self.population_size = max(10, int(20 * (1 - self.evaluations / self.budget)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 10 == 0: self.f *= 0.95\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Introduce adaptive noise handling and strategic local search to enhance robustness and solution quality.", "configspace": "", "generation": 7, "fitness": 0.7983581548217159, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.798 with standard deviation 0.033. And the mean value of best solutions found was 0.142 (0. is the best) with standard deviation 0.016.", "error": "", "parent_id": "19d2d3da-cf66-4837-ac2b-35a19573d37e", "metadata": {"aucs": [0.7567903214219662, 0.8366032611455023, 0.8016808818976792], "final_y": [0.1639349975011779, 0.13151872960626632, 0.13038699078241234]}, "mutation_prompt": null}
{"id": "a836d01b-8ba0-464f-b90f-f9ce92387512", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover rate\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        self.f = 0.5 + np.random.rand() * 0.5 * (1 - self.evaluations / self.budget)\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        improvement_factor = (self.func(solution) - np.min([self.func(ind) for ind in self.population])) / np.abs(self.func(solution))\n        perturbation_scale = 0.02 * improvement_factor  # Adjusted perturbation scaling\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.robustness_check(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            # Dynamically adjust population size based on progress\n            self.population_size = max(10, int(20 * (1 - self.evaluations / self.budget)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 10 == 0: self.f *= 0.95  # Adaptive learning rate\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Introduce adaptive perturbation scaling based on solution improvement for robustness enhancement.", "configspace": "", "generation": 8, "fitness": -Infinity, "feedback": "An exception occurred: AttributeError(\"'EnhancedAdaptiveHybridEvolutionarySearch' object has no attribute 'population'\").", "error": "AttributeError(\"'EnhancedAdaptiveHybridEvolutionarySearch' object has no attribute 'population'\")", "parent_id": "61bb8fa9-b748-47dd-8ad3-6d46427fdd21", "metadata": {}, "mutation_prompt": null}
{"id": "a47c2dfb-de08-49bf-84ac-f1abf951a0cc", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover rate\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        self.f = 0.4 + np.random.rand() * 0.6 * (1 - self.evaluations / self.budget)\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.02 * (1 - self.evaluations / self.budget)  # Enhanced perturbation scaling\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.robustness_check(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            # Dynamically adjust population size based on progress\n            self.population_size = max(10, int(20 * (1 - self.evaluations / self.budget)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 10 == 0: self.f *= 0.95  # Adaptive learning rate\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Enhanced adaptive hybrid search with dynamically adjusted mutation factor and crossover rate to improve solution quality.", "configspace": "", "generation": 8, "fitness": 0.8177121904776348, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.818 with standard deviation 0.026. And the mean value of best solutions found was 0.129 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "61bb8fa9-b748-47dd-8ad3-6d46427fdd21", "metadata": {"aucs": [0.7819522300677526, 0.8449346164807396, 0.8262497248844118], "final_y": [0.12593121514274475, 0.13131289725606432, 0.12964822348315275]}, "mutation_prompt": null}
{"id": "a58af7f5-4b0c-43aa-8051-99da01d122fb", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8\n        self.cr = 0.9\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        self.f = 0.5 + np.random.rand() * 0.5 * (1 - self.evaluations / self.budget)\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.02 * (1 - self.evaluations / self.budget)\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def quantum_inspired_mutation(self, solution):\n        q_mutation = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), size=solution.shape)\n        return np.clip(solution + q_mutation, self.lb, self.ub)\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.quantum_inspired_mutation(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            self.population_size = max(10, int(20 * (1 - self.evaluations / self.budget)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 10 == 0: self.f *= 0.95\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Adaptive Quantum-inspired Hybrid Evolutionary Search with dynamic layer enhancement and fine-tuned robustness for improved photovoltaic optimization.", "configspace": "", "generation": 8, "fitness": 0.8820752978466283, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.882 with standard deviation 0.025. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "61bb8fa9-b748-47dd-8ad3-6d46427fdd21", "metadata": {"aucs": [0.8514699132128871, 0.8809084588043897, 0.9138475215226085], "final_y": [0.12668915884201393, 0.11616099747061215, 0.11208816691901902]}, "mutation_prompt": null}
{"id": "43254e7e-867a-416b-a4cb-7054aa2d6238", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover rate\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        self.f = 0.5 + np.random.rand() * 0.5 * (1 - self.evaluations / self.budget)\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B', options={'maxiter': 50})\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.02 * (1 - self.evaluations / self.budget)  # Enhanced perturbation scaling\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.robustness_check(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            # Dynamically adjust population size based on progress\n            self.population_size = max(10, int(20 * (1 - self.evaluations / self.budget)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 10 == 0: self.f *= 0.95  # Adaptive learning rate\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Adjusted local exploration intensity to enhance convergence speed and robustness.", "configspace": "", "generation": 8, "fitness": 0.8435911872200278, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.844 with standard deviation 0.012. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "61bb8fa9-b748-47dd-8ad3-6d46427fdd21", "metadata": {"aucs": [0.8502145029622064, 0.853633074861738, 0.826925983836139], "final_y": [0.11707095336392259, 0.1147498373806205, 0.12594424209152133]}, "mutation_prompt": null}
{"id": "7ef8a33a-aba1-416b-a8d5-b301bbb28edc", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover rate\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        self.f = 0.5 + np.random.rand() * 0.5 * (1 - self.evaluations / self.budget)\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='TNC')  # Change method to 'TNC'\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.02 * (1 - self.evaluations / self.budget)\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.robustness_check(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            self.population_size = max(10, int(20 * (1 - self.evaluations / self.budget)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 10 == 0: self.f *= 0.95\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Enhance local search precision by switching to the 'TNC' method for better convergence in high-dimensional spaces.", "configspace": "", "generation": 8, "fitness": 0.8186833853046208, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.819 with standard deviation 0.047. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.018.", "error": "", "parent_id": "61bb8fa9-b748-47dd-8ad3-6d46427fdd21", "metadata": {"aucs": [0.8062215099843753, 0.76890311738062, 0.8809255285488674], "final_y": [0.14572919601952783, 0.1702433386818767, 0.12664813469585268]}, "mutation_prompt": null}
{"id": "275e4206-e583-40af-9956-a88d681379d2", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8\n        self.cr = 0.9\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        self.f = 0.6 + np.random.rand() * 0.4 * (1 - self.evaluations / self.budget)  # Changed line\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.03 * (1 - self.evaluations / self.budget)  # Changed line\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def quantum_inspired_mutation(self, solution):\n        q_mutation = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), size=solution.shape)\n        return np.clip(solution + q_mutation, self.lb, self.ub)\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.quantum_inspired_mutation(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            self.population_size = max(10, int(20 * (1 - self.evaluations / self.budget)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 10 == 0: self.f *= 0.95\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Enhanced Adaptive Hybrid Evolutionary Search with dynamic mutation scaling and improved robustness checks for optimized photovoltaic designs.", "configspace": "", "generation": 9, "fitness": 0.8733230765661598, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.873 with standard deviation 0.015. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "a58af7f5-4b0c-43aa-8051-99da01d122fb", "metadata": {"aucs": [0.8708225680385803, 0.8566768908870902, 0.8924697707728091], "final_y": [0.11680223171139614, 0.12261543327761382, 0.12451990802463064]}, "mutation_prompt": null}
{"id": "fd2ac394-2d88-481e-9f90-ef77978c62ba", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8\n        self.cr = 0.9\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        self.f = 0.5 + np.random.rand() * 0.5 * (1 - self.evaluations / self.budget)\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def detect_and_preserve_modular_structures(self, population):\n        modular_population = []\n        for individual in population:\n            if np.random.rand() < 0.5:\n                modular_population.append(self.robustness_check(individual))\n            else:\n                modular_population.append(individual)\n        return modular_population\n\n    def quantum_inspired_mutation(self, solution):\n        q_mutation = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), size=solution.shape)\n        return np.clip(solution + q_mutation, self.lb, self.ub)\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.quantum_inspired_mutation(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return self.detect_and_preserve_modular_structures(new_population)\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            self.population_size = max(10, int(20 * (1 - self.evaluations / self.budget)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 10 == 0: self.f *= 0.95\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Enhanced exploration and modular preservation in quantum-inspired evolutionary search with dynamic robustness for photovoltaic optimization.", "configspace": "", "generation": 9, "fitness": 0.806010384342907, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.806 with standard deviation 0.052. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "a58af7f5-4b0c-43aa-8051-99da01d122fb", "metadata": {"aucs": [0.765811497081679, 0.880005617540597, 0.7722140384064448], "final_y": [0.13760513967399068, 0.12277187653683885, 0.13334223699459358]}, "mutation_prompt": null}
{"id": "513cd9ea-0293-45a8-922e-830565fdfe47", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8\n        self.cr = 0.9\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        self.f = 0.5 + np.random.rand() * 0.5 * (1 - self.evaluations / self.budget)\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B', options={'ftol': 1e-5})\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.02 * (1 - self.evaluations / self.budget)\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def quantum_inspired_mutation(self, solution):\n        q_mutation = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), size=solution.shape)\n        return np.clip(solution + q_mutation, self.lb, self.ub)\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.quantum_inspired_mutation(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            self.population_size = max(10, int(20 * (1 - self.evaluations / self.budget)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 10 == 0: self.f *= 0.95\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Improved local search step by adjusting convergence criteria for faster convergence.", "configspace": "", "generation": 9, "fitness": 0.8689207153200701, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.869 with standard deviation 0.016. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "a58af7f5-4b0c-43aa-8051-99da01d122fb", "metadata": {"aucs": [0.8799673011203943, 0.8458693162909485, 0.8809255285488674], "final_y": [0.11060184094893843, 0.11858337051857026, 0.12664813469585268]}, "mutation_prompt": null}
{"id": "adb2957c-75dc-4bf0-bed5-d9ffa754be6e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8\n        self.cr = 0.9\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        self.f = 0.5 + np.random.rand() * 0.5 * (1 - self.evaluations / self.budget)\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.02 * (1 - self.evaluations / self.budget)\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def quantum_inspired_mutation(self, solution):\n        q_mutation = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), size=solution.shape)\n        return np.clip(solution + q_mutation, self.lb, self.ub)\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            if self.evaluations % 5 == 0: # Enhance frequent local search\n                trial = self.local_search(trial)\n            trial = self.quantum_inspired_mutation(trial)\n            if self.func(trial) < self.func(population[i]): # Enhanced selection\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            self.population_size = max(10, int(20 * (1 - self.evaluations / self.budget)))\n            if self.evaluations % 15 == 0: # Adjust engagement\n                active_layers = min(self.dim, int(0.8 * self.dim)) + 1\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            if self.evaluations % 10 == 0: self.f *= 0.95 \n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Improved Adaptive Quantum-Inspired Evolutionary Algorithm with Enhanced Layer Engagement and Perturbation Management for Optimized Photovoltaic Design.", "configspace": "", "generation": 9, "fitness": 0.8169134693368655, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.817 with standard deviation 0.016. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "a58af7f5-4b0c-43aa-8051-99da01d122fb", "metadata": {"aucs": [0.7973525343495392, 0.8365500610016334, 0.816837812659424], "final_y": [0.13464213718866935, 0.1332883383088228, 0.11014614773243359]}, "mutation_prompt": null}
{"id": "203431e3-6f80-4a26-99f5-943876684698", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8\n        self.cr = 0.9\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        self.f = 0.5 + np.random.rand() * 0.5 * (1 - self.evaluations / self.budget)\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B', options={'maxiter': 10})\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.01 * (1 - self.evaluations / self.budget)\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def quantum_inspired_mutation(self, solution):\n        q_mutation = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), size=solution.shape)\n        return np.clip(solution + q_mutation, self.lb, self.ub)\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.quantum_inspired_mutation(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            self.population_size = max(10, int(20 * (1 - self.evaluations / self.budget)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 10 == 0: self.f *= 0.95\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "EnhancedAdaptiveHybridEvolutionarySearch with improved local search dynamics and adaptive perturbation scale for better photovoltaic optimization.", "configspace": "", "generation": 9, "fitness": 0.8669216054531707, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.867 with standard deviation 0.024. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "a58af7f5-4b0c-43aa-8051-99da01d122fb", "metadata": {"aucs": [0.900822070604369, 0.8446256498167769, 0.8553170959383659], "final_y": [0.11476870262202121, 0.13083981440603643, 0.13046849537979444]}, "mutation_prompt": null}
{"id": "93048f67-3d70-40bf-ba34-c6daf3000651", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8\n        self.cr = 0.9\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        phase = self.evaluations / self.budget\n        self.f = 0.5 + 0.3 * np.cos(phase * np.pi)  # Changed line\n        self.cr = 0.9 - 0.5 * np.sin(phase * np.pi)  # Changed line\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        phase = self.evaluations / self.budget\n        prob = 0.9 * (1 - phase) + 0.1 * phase  # Changed line\n        cross_points = np.random.rand(self.dim) < prob  # Changed line\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        return solution  # Changed line\n\n    def quantum_inspired_mutation(self, solution):\n        q_mutation = np.random.normal(0, 0.05, size=solution.shape)  # Changed line\n        return np.clip(solution + q_mutation, self.lb, self.ub)  # Changed line\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.quantum_inspired_mutation(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            self.population_size = max(10, int(20 * (1 - self.evaluations / self.budget)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 10 == 0: self.f *= 0.95\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Refined Enhanced Adaptive Hybrid Evolutionary Search with multi-phase adaptation, dynamic crossover, and enhanced robustness through gaussian perturbations for photovoltaic optimization.", "configspace": "", "generation": 10, "fitness": 0.8358262223365086, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.836 with standard deviation 0.028. And the mean value of best solutions found was 0.130 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "275e4206-e583-40af-9956-a88d681379d2", "metadata": {"aucs": [0.8328446501334217, 0.872082490355118, 0.8025515265209859], "final_y": [0.1287858422653313, 0.11967324889197783, 0.14147705404801503]}, "mutation_prompt": null}
{"id": "a53ad8d4-af1e-4276-a021-320b36bed873", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8\n        self.cr = 0.9\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        self.f = 0.6 + np.random.rand() * 0.4 * (1 - self.evaluations / self.budget)  # Changed line\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.03 * (1 - self.evaluations / self.budget)  # Changed line\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def quantum_inspired_mutation(self, solution):\n        q_mutation = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), size=solution.shape)\n        return np.clip(solution + q_mutation, self.lb, self.ub)\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.quantum_inspired_mutation(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            self.population_size = max(15, int(20 * (1 - self.evaluations**0.5 / self.budget**0.5)))  # Changed line\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 10 == 0: self.f *= 0.95\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Introducing adaptive population dynamics by modifying the population size reduction to enhance exploration and exploitation balance.", "configspace": "", "generation": 10, "fitness": 0.8764145869744538, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.876 with standard deviation 0.014. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "275e4206-e583-40af-9956-a88d681379d2", "metadata": {"aucs": [0.856093263256909, 0.8862399373125152, 0.8869105603539374], "final_y": [0.11680223171139614, 0.12277550340867238, 0.1257632699143464]}, "mutation_prompt": null}
{"id": "baeb1889-cbce-4062-9061-aac1a94b0910", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8\n        self.cr = 0.9\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        self.f = 0.6 + np.random.rand() * 0.4 * (1 - self.evaluations / self.budget)\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.03 * (1 - self.evaluations / self.budget)\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def quantum_inspired_mutation(self, solution):\n        q_mutation = np.random.normal(0, 0.1 * (1 - (self.evaluations / self.budget)**2), size=solution.shape)  # Changed line\n        return np.clip(solution + q_mutation, self.lb, self.ub)\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.quantum_inspired_mutation(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            self.population_size = max(10, int(20 * (1 - self.evaluations / self.budget)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 10 == 0: self.f *= 0.95\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Enhanced Adaptive Hybrid Evolutionary Search with quantum-inspired mutation scaling for improved exploration in photovoltaic optimization.", "configspace": "", "generation": 10, "fitness": 0.8328669227337003, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.833 with standard deviation 0.047. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "275e4206-e583-40af-9956-a88d681379d2", "metadata": {"aucs": [0.8809889757142655, 0.8477377308874764, 0.769874061599359], "final_y": [0.11419321581388653, 0.11881518627981269, 0.13634399923939777]}, "mutation_prompt": null}
{"id": "f672d069-eac2-45cd-b57b-dcff7ecf1541", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8\n        self.cr = 0.9\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        self.f = 0.6 + np.random.rand() * 0.4 * (1 - self.evaluations / self.budget)\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        if np.random.rand() < 0.6:  # Changed line\n            res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n            return res.x if res.success else x\n        return x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.03 * (1 - self.evaluations / self.budget)\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def quantum_inspired_mutation(self, solution):\n        q_mutation = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), size=solution.shape)\n        return np.clip(solution + q_mutation, self.lb, self.ub)\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.quantum_inspired_mutation(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            self.population_size = max(10, int(20 * (1 - self.evaluations / self.budget)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 10 == 0: self.f *= 0.95\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Enhanced Adaptive Hybrid Evolutionary Search with a novel probability strategy for improved local search guidance in photovoltaic optimization.", "configspace": "", "generation": 10, "fitness": 0.8655563209846476, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.866 with standard deviation 0.008. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "275e4206-e583-40af-9956-a88d681379d2", "metadata": {"aucs": [0.8662475100320506, 0.8557851544782804, 0.874636298443612], "final_y": [0.1156781294171364, 0.13320568686065704, 0.1266454400764052]}, "mutation_prompt": null}
{"id": "3c562246-a7f2-4a21-9dc2-2a68e368fd46", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8\n        self.cr = 0.9\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        self.f = 0.7 + np.random.rand() * 0.3 * np.sin(np.pi * self.evaluations / (2 * self.budget))  # Changed line\n        self.cr = 0.85 + np.random.rand() * 0.15 * np.cos(np.pi * self.evaluations / (2 * self.budget))  # Changed line\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.03 * (1 - self.evaluations / self.budget)\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def quantum_inspired_mutation(self, solution):\n        q_mutation = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), size=solution.shape)\n        return np.clip(solution + q_mutation, self.lb, self.ub)\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.quantum_inspired_mutation(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            self.population_size = max(10, int(20 * (1 - self.evaluations / self.budget)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 10 == 0: self.f *= 0.95\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Improved adaptive parameter scaling for refined mutation and crossover processes in evolutionary search.", "configspace": "", "generation": 10, "fitness": 0.8418199196740064, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.842 with standard deviation 0.011. And the mean value of best solutions found was 0.132 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "275e4206-e583-40af-9956-a88d681379d2", "metadata": {"aucs": [0.8327221593747876, 0.8574978626237069, 0.8352397370235245], "final_y": [0.13834883439287382, 0.12631494508343433, 0.13038626290842925]}, "mutation_prompt": null}
{"id": "b44e5ed8-6472-4588-a458-c83cde1e4ac0", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8\n        self.cr = 0.9\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        self.f = 0.6 + np.random.rand() * 0.4 * (1 - self.evaluations / self.budget)\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.035 * (1 - self.evaluations / self.budget)  # Changed line\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def quantum_inspired_mutation(self, solution):\n        q_mutation = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), size=solution.shape)\n        return np.clip(solution + q_mutation, self.lb, self.ub)\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.quantum_inspired_mutation(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            self.population_size = max(15, int(20 * (1 - self.evaluations**0.5 / self.budget**0.5)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 10 == 0: self.f *= 0.95\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Slightly increase the perturbation scale to improve exploration near convergence.", "configspace": "", "generation": 11, "fitness": 0.8281814247571283, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.828 with standard deviation 0.047. And the mean value of best solutions found was 0.134 (0. is the best) with standard deviation 0.017.", "error": "", "parent_id": "a53ad8d4-af1e-4276-a021-320b36bed873", "metadata": {"aucs": [0.8376351956823297, 0.8799104258457386, 0.7669986527433162], "final_y": [0.12262103002233193, 0.12278127180304654, 0.15807455804500792]}, "mutation_prompt": null}
{"id": "7da076f1-cbdd-4771-bbad-6242dfc73c8e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8\n        self.cr = 0.9\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        self.f = 0.6 + np.random.rand() * 0.4 * (1 - self.evaluations / self.budget)\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        differential_weight = 0.5 + 0.3 * np.random.rand()  # Changed line\n        mutant = population[a] + differential_weight * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.03 * (1 - self.evaluations / self.budget)\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def quantum_inspired_mutation(self, solution):\n        q_mutation = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), size=solution.shape)\n        return np.clip(solution + q_mutation, self.lb, self.ub)\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.quantum_inspired_mutation(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            self.population_size = max(15, int(20 * (1 - self.evaluations**0.5 / self.budget**0.5)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 10 == 0: self.f *= 0.95\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Enhancing the mutation strategy by introducing more diversity through differential weight adaptation.", "configspace": "", "generation": 11, "fitness": 0.845543412951531, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.846 with standard deviation 0.037. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "a53ad8d4-af1e-4276-a021-320b36bed873", "metadata": {"aucs": [0.7990027027941845, 0.8470743614714312, 0.8905531745889775], "final_y": [0.1436805650699392, 0.13128484631952997, 0.12461038342939146]}, "mutation_prompt": null}
{"id": "acbc8214-d808-414d-a9ba-11e4262bb2b8", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8\n        self.cr = 0.9\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        self.f = 0.6 + np.random.rand() * 0.4 * (1 - self.evaluations / self.budget)  # Changed line\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B', options={'maxiter': 50})\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.03 * (1 - self.evaluations / self.budget)  # Changed line\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def quantum_inspired_mutation(self, solution):\n        q_mutation = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), size=solution.shape)\n        return np.clip(solution + q_mutation, self.lb, self.ub)\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.quantum_inspired_mutation(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            self.population_size = max(15, int(20 * (1 - self.evaluations**0.5 / self.budget**0.5)))  # Changed line\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 10 == 0: self.f *= 0.95\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Enhancing local search phase with algorithmic fine-tuning for improved solution refinement.", "configspace": "", "generation": 11, "fitness": 0.8290025596456255, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.829 with standard deviation 0.067. And the mean value of best solutions found was 0.141 (0. is the best) with standard deviation 0.024.", "error": "", "parent_id": "a53ad8d4-af1e-4276-a021-320b36bed873", "metadata": {"aucs": [0.7349766378467437, 0.8736311723050614, 0.8783998687850718], "final_y": [0.1753796185443407, 0.12610141487032378, 0.12271829712336046]}, "mutation_prompt": null}
{"id": "1b0f4406-7b00-4d4e-83ec-b97ca9721a3f", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8\n        self.cr = 0.9\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        self.f = 0.5 + np.random.rand() * 0.5 * (1 - self.evaluations**0.5 / self.budget**0.5)  # Changed line\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.03 * (1 - self.evaluations / self.budget)  # Changed line\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def quantum_inspired_mutation(self, solution):\n        q_mutation = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), size=solution.shape)\n        return np.clip(solution + q_mutation, self.lb, self.ub)\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            if i % 2 == 0: trial = self.local_search(trial)  # Changed line\n            trial = self.quantum_inspired_mutation(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            self.population_size = max(15, int(20 * (1 - self.evaluations**0.5 / self.budget**0.5)))  # Changed line\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 10 == 0: self.f *= 0.95\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Introduce environment-adaptive mutation scaling and enhanced local search frequency adjustment for improved convergence.", "configspace": "", "generation": 11, "fitness": 0.8363381811629244, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.836 with standard deviation 0.010. And the mean value of best solutions found was 0.132 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "a53ad8d4-af1e-4276-a021-320b36bed873", "metadata": {"aucs": [0.8331455689336004, 0.8259972680496388, 0.849871706505534], "final_y": [0.13874751621692683, 0.13329064919383737, 0.1224904362515351]}, "mutation_prompt": null}
{"id": "5be5b5d9-43b6-433c-95ce-b492ebf6e30b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8\n        self.cr = 0.9\n        self.evaluations = 0\n        self.learning_rate = 0.1\n\n    def adapt_parameters(self):\n        self.f = 0.6 + np.random.rand() * 0.4 * (1 - self.evaluations / self.budget)\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.03 * (1 - self.evaluations / self.budget)\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def quantum_inspired_mutation(self, solution):\n        q_mutation = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), size=solution.shape)\n        return np.clip(solution + q_mutation, self.lb, self.ub)\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.quantum_inspired_mutation(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i] + self.learning_rate * (trial - population[i])  # Changed line\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            self.population_size = max(15, int(20 * (1 - self.evaluations**0.5 / self.budget**0.5)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n                self.learning_rate = 0.1 + 0.4 * (1 - self.evaluations / self.budget)  # Changed line\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 10 == 0:\n                self.f *= 0.95\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Incorporating coevolutionary concepts and adaptive learning rates to enhance exploration-exploitation balance.", "configspace": "", "generation": 11, "fitness": 0.8713007605354108, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.871 with standard deviation 0.010. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "a53ad8d4-af1e-4276-a021-320b36bed873", "metadata": {"aucs": [0.8702889842551815, 0.8601049470263437, 0.8835083503247073], "final_y": [0.1242531511564654, 0.12638531564733735, 0.11209025449139354]}, "mutation_prompt": null}
{"id": "1eebd5e1-5279-4ee9-8e3d-1ed96838921b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8\n        self.cr = 0.9\n        self.evaluations = 0\n        self.learning_rate = 0.1\n\n    def adapt_parameters(self):\n        self.f = 0.6 + np.random.rand() * 0.4 * (1 - self.evaluations / self.budget)\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.03 * (1 - self.evaluations / self.budget)\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def quantum_inspired_mutation(self, solution):\n        q_mutation = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), size=solution.shape)\n        return np.clip(solution + q_mutation, self.lb, self.ub)\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.quantum_inspired_mutation(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i] + self.learning_rate * (trial - population[i])\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            self.population_size = max(15, int(20 * (1 - self.evaluations**0.5 / self.budget**0.5)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n                self.learning_rate = 0.15 + 0.35 * (1 - self.evaluations / self.budget)  # Changed line\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 10 == 0:\n                self.f *= 0.95\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Enhanced learning rate adjustment based on function evaluation progress for improved convergence.", "configspace": "", "generation": 12, "fitness": 0.77527137086045, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.775 with standard deviation 0.005. And the mean value of best solutions found was 0.138 (0. is the best) with standard deviation 0.023.", "error": "", "parent_id": "5be5b5d9-43b6-433c-95ce-b492ebf6e30b", "metadata": {"aucs": [0.7774075896708195, 0.76890311738062, 0.7795034055299102], "final_y": [0.12190519512507392, 0.1702433386818767, 0.12135295631720533]}, "mutation_prompt": null}
{"id": "e61dc33f-1d4d-4077-a7bb-f9e29eac2e84", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8\n        self.cr = 0.9\n        self.evaluations = 0\n        self.learning_rate = 0.1\n\n    def adapt_parameters(self):\n        self.f = 0.6 + np.random.rand() * 0.4 * (1 - self.evaluations / self.budget)\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.03 * (1 - self.evaluations / self.budget)\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def quantum_inspired_mutation(self, solution):\n        q_mutation = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), size=solution.shape)\n        return np.clip(solution + q_mutation, self.lb, self.ub)\n\n    def stochastic_ranking(self, population, fitness_values):\n        rank_prob = 0.45\n        num_individuals = len(population)\n        for i in range(num_individuals):\n            for j in range(num_individuals - 1):\n                if (np.random.rand() < rank_prob and fitness_values[j] > fitness_values[j + 1]) or \\\n                   (fitness_values[j] == fitness_values[j + 1] and self.func(population[j]) > self.func(population[j + 1])):\n                    population[j], population[j + 1] = population[j + 1], population[j]\n                    fitness_values[j], fitness_values[j + 1] = fitness_values[j + 1], fitness_values[j]\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        fitness_values = [self.func(ind) for ind in population]\n        self.stochastic_ranking(population, fitness_values)  # Changed line\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.quantum_inspired_mutation(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i] + self.learning_rate * (trial - population[i])\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            self.population_size = max(15, int(20 * (1 - self.evaluations**0.5 / self.budget**0.5)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n                self.learning_rate = 0.1 + 0.4 * (1 - self.evaluations / self.budget)\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 10 == 0:\n                self.f *= 0.95\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Introduce stochastic ranking to balance objective function evaluation and constraint handling, improving solution feasibility.", "configspace": "", "generation": 12, "fitness": 0.8001217764393952, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.800 with standard deviation 0.072. And the mean value of best solutions found was 0.153 (0. is the best) with standard deviation 0.023.", "error": "", "parent_id": "5be5b5d9-43b6-433c-95ce-b492ebf6e30b", "metadata": {"aucs": [0.898837801478334, 0.7712539062573233, 0.7302736215825282], "final_y": [0.12048874071849014, 0.1688943436905218, 0.17042168635577049]}, "mutation_prompt": null}
{"id": "5fa8edc8-e57d-41df-a04d-6abcf4bc8598", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8\n        self.cr = 0.9\n        self.evaluations = 0\n        self.learning_rate = 0.1\n        self.f_memory = 0.8\n\n    def adapt_parameters(self):\n        self.f = self.f_memory + np.random.rand() * 0.4 * (1 - self.evaluations / self.budget)\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.03 * (1 - self.evaluations / self.budget)\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def quantum_inspired_mutation(self, solution):\n        q_mutation = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), size=solution.shape)\n        return np.clip(solution + q_mutation, self.lb, self.ub)\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.quantum_inspired_mutation(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n                self.f_memory = 0.9 * self.f_memory + 0.1 * self.f  # Changed line\n            else:\n                new_population[i] = population[i] + self.learning_rate * (trial - population[i])\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            self.population_size = max(15, int(20 * (1 - self.evaluations**0.5 / self.budget**0.5)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n                self.learning_rate = 0.1 + 0.4 * (1 - self.evaluations / self.budget)\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 10 == 0:\n                self.f *= 0.95\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Enhanced adaptive mechanism with memory-based parameter adjustment to improve exploration-exploitation dynamics.", "configspace": "", "generation": 12, "fitness": 0.8775976590570213, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.878 with standard deviation 0.070. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.019.", "error": "", "parent_id": "5be5b5d9-43b6-433c-95ce-b492ebf6e30b", "metadata": {"aucs": [0.7788885883577374, 0.9178056421942937, 0.9360987466190328], "final_y": [0.1530710044430479, 0.11468256250582642, 0.11012105131376604]}, "mutation_prompt": null}
{"id": "eaa0effb-3218-4fc2-a413-bd62c598b7f3", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8\n        self.cr = 0.9\n        self.evaluations = 0\n        self.learning_rate = 0.1\n\n    def adapt_parameters(self):\n        self.f = 0.6 + np.random.rand() * 0.4 * (1 - self.evaluations / self.budget)\n        self.cr = 0.7 + np.random.rand() * 0.3 * (1 - self.evaluations / self.budget)  # Changed line\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.03 * (1 - self.evaluations / self.budget)\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def quantum_inspired_mutation(self, solution):\n        q_mutation = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), size=solution.shape)\n        return np.clip(solution + q_mutation, self.lb, self.ub)\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.quantum_inspired_mutation(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i] + self.learning_rate * (trial - population[i])\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            self.population_size = max(15, int(20 * (1 - self.evaluations**0.5 / self.budget**0.5)))\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim) + 2)  # Changed line\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n                self.learning_rate = 0.15 + 0.35 * (1 - self.evaluations / self.budget)  # Changed line\n\n            self.evaluations += self.population_size\n            if self.evaluations % 10 == 0:\n                self.f *= 0.95\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Introducing dynamic layer allocation and adaptive crossover rates to improve convergence and solution robustness.", "configspace": "", "generation": 12, "fitness": 0.8298066343183574, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.830 with standard deviation 0.070. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "5be5b5d9-43b6-433c-95ce-b492ebf6e30b", "metadata": {"aucs": [0.7352848860044952, 0.903614708573734, 0.8505203083768429], "final_y": [0.12313251947363468, 0.1144070627849555, 0.11210677698085747]}, "mutation_prompt": null}
{"id": "795cea9c-aa88-4353-a739-9a908f3b0ef1", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8\n        self.cr = 0.9\n        self.evaluations = 0\n        self.learning_rate = 0.1\n\n    def adapt_parameters(self):\n        self.f = 0.6 + np.random.rand() * 0.4 * (1 - self.evaluations / self.budget)\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.03 * (1 - self.evaluations / self.budget)\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def quantum_inspired_mutation(self, solution):\n        q_mutation = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), size=solution.shape)\n        return np.clip(solution + q_mutation, self.lb, self.ub)\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.quantum_inspired_mutation(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i] + self.learning_rate * (trial - population[i])\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n                self.learning_rate = 0.1 + 0.4 * (1 - self.evaluations / self.budget)\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 10 == 0:\n                self.f *= 0.95\n            self.population_size = min(25, max(15, int(20 * (1 - self.evaluations**0.5 / self.budget**0.5))))  # Changed line\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Introducing a dynamic population size adjustment based on convergence speed to enhance exploration-exploitation synergy.", "configspace": "", "generation": 12, "fitness": 0.8319699288128427, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.832 with standard deviation 0.061. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "5be5b5d9-43b6-433c-95ce-b492ebf6e30b", "metadata": {"aucs": [0.8159330669367195, 0.9136738510287619, 0.7663028684730467], "final_y": [0.13165953489369242, 0.11338969831972501, 0.13204925684669666]}, "mutation_prompt": null}
{"id": "727fdb1c-43bf-4307-b4c4-4b71b43c5a96", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8\n        self.cr = 0.9\n        self.evaluations = 0\n        self.learning_rate = 0.1\n        self.f_memory = 0.8\n\n    def adapt_parameters(self):\n        self.f = self.f_memory + np.random.uniform(-0.1, 0.3) * (1 - self.evaluations / self.budget)  # Changed line\n        self.cr = 0.8 + np.random.uniform(-0.1, 0.3)  # Changed line\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.03 * (1 - self.evaluations / self.budget)\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def quantum_inspired_mutation(self, solution):\n        q_mutation = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), size=solution.shape)\n        return np.clip(solution + q_mutation, self.lb, self.ub)\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.quantum_inspired_mutation(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n                self.f_memory = 0.9 * self.f_memory + 0.1 * self.f\n            else:\n                new_population[i] = population[i] + self.learning_rate * (trial - population[i])\n            if np.random.rand() < 0.1:  # Changed line\n                self.learning_rate *= 1.05  # Changed line\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            self.population_size = max(15, int(20 * (1 - self.evaluations**0.5 / self.budget**0.5)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n                self.learning_rate = 0.1 + 0.4 * (1 - self.evaluations / self.budget)\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 10 == 0:\n                self.f *= 0.95\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Adaptive layered refinement with diversity maintenance and enhanced robustness to optimize complex photonic structures.", "configspace": "", "generation": 13, "fitness": 0.8572670492070836, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.857 with standard deviation 0.054. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "5fa8edc8-e57d-41df-a04d-6abcf4bc8598", "metadata": {"aucs": [0.7855248820047814, 0.872002266748882, 0.9142739988675873], "final_y": [0.14133308228897634, 0.12436344156666945, 0.11209271920849762]}, "mutation_prompt": null}
{"id": "27154f49-917d-4b98-ad10-bd43724bbcfc", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8\n        self.cr = 0.9\n        self.evaluations = 0\n        self.learning_rate = 0.1\n        self.f_memory = 0.8\n\n    def adapt_parameters(self):\n        self.f = self.f_memory + np.random.rand() * 0.4 * (1 - self.evaluations / self.budget)\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.03 * (1 - self.evaluations / self.budget)\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def quantum_inspired_mutation(self, solution):\n        q_mutation = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), size=solution.shape)\n        return np.clip(solution + q_mutation, self.lb, self.ub)\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.quantum_inspired_mutation(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n                self.f_memory = 0.9 * self.f_memory + 0.1 * self.f\n            else:\n                new_population[i] = population[i] + self.learning_rate * (trial - population[i])  # Changed line\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            self.population_size = max(15, int(20 * (1 - self.evaluations**0.5 / self.budget**0.5)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n                self.learning_rate = 0.1 + 0.4 * (1 - self.evaluations / self.budget)\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 10 == 0:\n                self.f *= 0.95\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Improved exploration-exploitation dynamics via adaptive parameter tuning with memory and performance feedback.", "configspace": "", "generation": 13, "fitness": 0.8421821867578232, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.842 with standard deviation 0.039. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.021.", "error": "", "parent_id": "5fa8edc8-e57d-41df-a04d-6abcf4bc8598", "metadata": {"aucs": [0.8693847806015327, 0.7864803429969858, 0.870681436674951], "final_y": [0.11419810962700461, 0.15711670766029073, 0.11209408375346153]}, "mutation_prompt": null}
{"id": "f9783303-bf00-4a85-b043-4970a2c971f2", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8\n        self.cr = 0.9\n        self.evaluations = 0\n        self.learning_rate = 0.1\n        self.f_memory = 0.8\n\n    def adapt_parameters(self):\n        self.f = self.f_memory + np.random.rand() * 0.3 * (1 - self.evaluations / self.budget)  # Changed line\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.02 * (1 - self.evaluations / self.budget)  # Changed line\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def quantum_inspired_mutation(self, solution):\n        q_mutation = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), size=solution.shape)\n        return np.clip(solution + q_mutation, self.lb, self.ub)\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.quantum_inspired_mutation(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n                self.f_memory = 0.9 * self.f_memory + 0.1 * self.f\n            else:\n                new_population[i] = population[i] + self.learning_rate * (trial - population[i])\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            self.population_size = max(15, int(20 * (1 - self.evaluations**0.5 / self.budget**0.5)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n                self.learning_rate = 0.1 + 0.4 * (1 - self.evaluations / self.budget)\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 10 == 0:\n                self.f *= 0.95\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Modified adaptive strategy and perturbation for improved exploration-exploitation dynamics.", "configspace": "", "generation": 13, "fitness": 0.8705188167976713, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.871 with standard deviation 0.014. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "5fa8edc8-e57d-41df-a04d-6abcf4bc8598", "metadata": {"aucs": [0.8504006832862671, 0.8790349105134242, 0.8821208565933226], "final_y": [0.11707010455899225, 0.12277341207396975, 0.12740856611949603]}, "mutation_prompt": null}
{"id": "c1466513-a59e-4f67-9d2b-453d3cdbdf6a", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8\n        self.cr = 0.9\n        self.evaluations = 0\n        self.learning_rate = 0.1\n        self.f_memory = 0.8\n\n    def adapt_parameters(self):\n        self.f = self.f_memory + np.random.rand() * 0.4 * (1 - self.evaluations / self.budget)\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.03 * (1 - self.evaluations / self.budget)\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def quantum_inspired_mutation(self, solution):\n        q_mutation = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), size=solution.shape)\n        return np.clip(solution + q_mutation, self.lb, self.ub)\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.quantum_inspired_mutation(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n                self.f_memory = 0.9 * self.f_memory + 0.1 * self.f\n            else:\n                new_population[i] = population[i] + self.learning_rate * (trial - population[i])\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            self.population_size = max(15, int(20 * (1 - self.evaluations**0.5 / self.budget**0.5)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n                self.learning_rate = 0.1 + 0.4 * (1 - self.evaluations / self.budget)  # Changed line\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 10 == 0:\n                self.f *= 0.95\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Introduce dynamic updating of learning rate based on evaluation progress for better exploration-exploitation balance.", "configspace": "", "generation": 13, "fitness": 0.7649572400435707, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.765 with standard deviation 0.020. And the mean value of best solutions found was 0.159 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "5fa8edc8-e57d-41df-a04d-6abcf4bc8598", "metadata": {"aucs": [0.7761154852726524, 0.7820237915612708, 0.7367324432967892], "final_y": [0.15059060634015886, 0.1478402997467777, 0.17962084622308494]}, "mutation_prompt": null}
{"id": "9ae0bdf9-996a-4b80-9d8b-775b883e1216", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8\n        self.cr = 0.9\n        self.evaluations = 0\n        self.learning_rate = 0.1\n        self.f_memory = 0.8\n\n    def adapt_parameters(self):\n        self.f = self.f_memory + np.random.rand() * 0.4 * (1 - self.evaluations / self.budget)\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.03 * (1 - self.evaluations / self.budget)\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def quantum_inspired_mutation(self, solution):\n        q_mutation = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), size=solution.shape)\n        return np.clip(solution + q_mutation, self.lb, self.ub)\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.quantum_inspired_mutation(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n                self.f_memory = 0.95 * self.f_memory + 0.05 * self.f  # Changed line (1)\n            else:\n                new_population[i] = population[i] + self.learning_rate * (trial - population[i])\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            self.population_size = max(15, int(20 * (1 - self.evaluations**0.5 / self.budget**0.5)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n                self.learning_rate = 0.1 + 0.4 * (1 - self.evaluations / self.budget)\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 10 == 0:\n                self.f *= 0.95\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Enhanced adaptive hybrid evolutionary search with improved parameter adjustment for better convergence.", "configspace": "", "generation": 13, "fitness": 0.853678101322636, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.854 with standard deviation 0.022. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "5fa8edc8-e57d-41df-a04d-6abcf4bc8598", "metadata": {"aucs": [0.8249336299962109, 0.8594174649229295, 0.8766832090487674], "final_y": [0.11235367484538394, 0.11523463288029823, 0.1144427684528061]}, "mutation_prompt": null}
{"id": "05828aee-15d5-491e-9bd2-e0170a9607fb", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8\n        self.cr = 0.9\n        self.evaluations = 0\n        self.learning_rate = 0.1\n        self.f_memory = 0.8\n\n    def adapt_parameters(self):\n        self.f = self.f_memory + np.random.rand() * 0.2 * (1 - self.evaluations / self.budget)  # Adjusted factor\n        self.cr = 0.8 + np.random.rand() * 0.15  # Adjusted factor\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.02 * (1 - self.evaluations / self.budget)\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def quantum_inspired_mutation(self, solution):\n        q_mutation = np.random.normal(0, 0.05 * (1 - self.evaluations / self.budget), size=solution.shape)  # Adjusted scale\n        return np.clip(solution + q_mutation, self.lb, self.ub)\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.quantum_inspired_mutation(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n                self.f_memory = 0.95 * self.f_memory + 0.05 * self.f  # Adjusted weights\n            else:\n                new_population[i] = population[i] + self.learning_rate * (trial - population[i])\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            self.population_size = max(15, int(25 * (1 - self.evaluations**0.5 / self.budget**0.5)))  # Adjusted scaling\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n                self.learning_rate = 0.1 + 0.5 * (1 - self.evaluations / self.budget)  # Adjusted learning rate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 10 == 0:\n                self.f *= 0.95\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Enhanced parameter adaptation and dynamic population size regulation for improved exploration-exploitation balance.", "configspace": "", "generation": 14, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 22 is out of bounds for axis 0 with size 20').", "error": "IndexError('index 22 is out of bounds for axis 0 with size 20')", "parent_id": "f9783303-bf00-4a85-b043-4970a2c971f2", "metadata": {}, "mutation_prompt": null}
{"id": "67c2dc42-6d29-4c04-af41-e76e00baf2fb", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8\n        self.cr = 0.9\n        self.evaluations = 0\n        self.learning_rate = 0.1\n        self.f_memory = 0.8\n\n    def adapt_parameters(self):\n        self.f = self.f_memory + np.random.rand() * 0.25 * (1 - self.evaluations / self.budget)  # Changed line\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.02 * (1 - self.evaluations / self.budget)\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def quantum_inspired_mutation(self, solution):\n        q_mutation = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), size=solution.shape)\n        return np.clip(solution + q_mutation, self.lb, self.ub)\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.quantum_inspired_mutation(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n                self.f_memory = 0.95 * self.f_memory + 0.05 * self.f  # Changed line\n            else:\n                new_population[i] = population[i] + self.learning_rate * (trial - population[i])\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            self.population_size = max(15, int(25 * (1 - self.evaluations**0.5 / self.budget**0.5)))  # Changed line\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n                self.learning_rate = 0.1 + 0.4 * (1 - self.evaluations / self.budget)\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 10 == 0:\n                self.f *= 0.95\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Enhanced exploration dynamics through adaptive population size and mutation scaling.", "configspace": "", "generation": 14, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 24 is out of bounds for axis 0 with size 20').", "error": "IndexError('index 24 is out of bounds for axis 0 with size 20')", "parent_id": "f9783303-bf00-4a85-b043-4970a2c971f2", "metadata": {}, "mutation_prompt": null}
{"id": "0788f662-5a69-4ba2-9dd1-451628e646f7", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8\n        self.cr = 0.9\n        self.evaluations = 0\n        self.learning_rate = 0.1\n        self.f_memory = 0.8\n\n    def adapt_parameters(self):\n        self.f = self.f_memory + np.random.rand() * 0.3 * (1 - self.evaluations / self.budget)\n        self.cr = 0.9 + np.random.rand() * 0.1  # Changed line\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.01 * (1 - self.evaluations / self.budget)  # Changed line\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def quantum_inspired_mutation(self, solution):\n        q_mutation = np.random.normal(0, 0.05 * (1 - self.evaluations / self.budget), size=solution.shape)  # Changed line\n        return np.clip(solution + q_mutation, self.lb, self.ub)\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.quantum_inspired_mutation(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n                self.f_memory = 0.9 * self.f_memory + 0.1 * self.f\n            else:\n                new_population[i] = population[i] + self.learning_rate * (trial - population[i])\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            self.population_size = max(15, int(25 * (1 - self.evaluations**0.5 / self.budget**0.5)))  # Changed line\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n                self.learning_rate = 0.1 + 0.5 * (1 - self.evaluations / self.budget)  # Changed line\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 15 == 0:  # Changed line\n                self.f *= 0.95\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Incorporates adaptive population resizing and dynamic exploration to enhance search efficiency while maintaining the balance between exploration and exploitation.", "configspace": "", "generation": 14, "fitness": 0.849293280520451, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.849 with standard deviation 0.032. And the mean value of best solutions found was 0.130 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "f9783303-bf00-4a85-b043-4970a2c971f2", "metadata": {"aucs": [0.8435547925154268, 0.8133620130055729, 0.8909630360403538], "final_y": [0.12842380989814883, 0.1359286166875454, 0.12430328276209135]}, "mutation_prompt": null}
{"id": "f7aa4ff6-1060-4cac-bf3f-8517f3e6c1a0", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8\n        self.cr = 0.9\n        self.evaluations = 0\n        self.learning_rate = 0.1\n        self.f_memory = 0.8\n\n    def adapt_parameters(self):\n        self.f = self.f_memory + np.random.rand() * 0.3 * (1 - self.evaluations / self.budget)\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.02 * (1 - self.evaluations / self.budget)\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def quantum_inspired_mutation(self, solution):\n        q_mutation = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), size=solution.shape)\n        return np.clip(solution + q_mutation, self.lb, self.ub)\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.quantum_inspired_mutation(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n                self.f_memory = 0.9 * self.f_memory + 0.1 * self.f\n            else:\n                new_population[i] = population[i] + self.learning_rate * (trial - population[i])\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            self.population_size = max(15, int(20 * (1 - self.evaluations**0.5 / self.budget**0.5)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n                self.learning_rate = (0.1 + 0.4 * (1 - self.evaluations / self.budget)) * (1 - self.evaluations / self.budget)  # Changed line\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 10 == 0:\n                self.f *= 0.95\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Introduced a decaying memory factor to adapt the learning rate dynamically for improved convergence.", "configspace": "", "generation": 14, "fitness": 0.8099366967920659, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.810 with standard deviation 0.017. And the mean value of best solutions found was 0.136 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "f9783303-bf00-4a85-b043-4970a2c971f2", "metadata": {"aucs": [0.8344939833858325, 0.798227026784966, 0.7970890802053993], "final_y": [0.13188381037096575, 0.15417951701866173, 0.12313933764605223]}, "mutation_prompt": null}
{"id": "a2817085-541a-4b5d-b492-0f69c186ab39", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8\n        self.cr = 0.9\n        self.evaluations = 0\n        self.learning_rate = 0.1\n        self.f_memory = 0.8\n\n    def adapt_parameters(self):\n        self.f = self.f_memory + np.random.rand() * 0.3 * (0.5 - self.evaluations / self.budget)  # Changed line\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.02 * (1 - self.evaluations / self.budget)  # Changed line\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def quantum_inspired_mutation(self, solution):\n        q_mutation = np.random.normal(0, 0.1 * (1 - self.evaluations / self.budget), size=solution.shape)\n        return np.clip(solution + q_mutation, self.lb, self.ub)\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.quantum_inspired_mutation(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n                self.f_memory = 0.9 * self.f_memory + 0.1 * self.f\n            else:\n                new_population[i] = population[i] + self.learning_rate * (trial - population[i])\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            self.population_size = max(15, int(20 * (1 - self.evaluations**0.5 / self.budget**0.5)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n                self.learning_rate = 0.1 + 0.4 * (1 - self.evaluations / self.budget)\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 10 == 0:\n                self.f *= 0.95\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Enhanced exploration dynamics via mutation strategy adaptation based on budget progress.", "configspace": "", "generation": 14, "fitness": 0.8382519759795591, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.838 with standard deviation 0.045. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "f9783303-bf00-4a85-b043-4970a2c971f2", "metadata": {"aucs": [0.7760239241345688, 0.8792837778337157, 0.8594482259703932], "final_y": [0.14802615892508186, 0.11886236086746593, 0.12664777508505676]}, "mutation_prompt": null}
{"id": "b3a9947a-cd63-4425-960a-344a6441bd74", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8\n        self.cr = 0.9\n        self.evaluations = 0\n        self.learning_rate = 0.1\n        self.f_memory = 0.8\n\n    def adapt_parameters(self):\n        self.f = self.f_memory + np.random.rand() * 0.3 * (1 - self.evaluations / self.budget)\n        self.cr = 0.9 + np.random.rand() * 0.1\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.01 * (1 - self.evaluations / self.budget)\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def quantum_inspired_mutation(self, solution):\n        q_mutation = np.random.normal(0, 0.05 * (1 - self.evaluations / self.budget), size=solution.shape)\n        return np.clip(solution + q_mutation, self.lb, self.ub)\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.quantum_inspired_mutation(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n                self.f_memory = 0.9 * self.f_memory + 0.1 * self.f\n            else:\n                new_population[i] = population[i] + self.learning_rate * (trial - population[i])\n                if np.random.rand() < 0.05:  # New line (1)\n                    new_population[i] = np.random.uniform(self.lb, self.ub, self.dim)  # New line (2)\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            self.population_size = max(15, int(25 * (1 - self.evaluations**0.5 / self.budget**0.5)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n                self.learning_rate = 0.1 + 0.5 * (1 - self.evaluations / self.budget)\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 10 == 0:  # Changed condition (3)\n                self.f *= 0.92  # Changed line (4)\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Integrates a self-adaptive mechanism and improved diversity enhancement to strengthen exploration while maintaining solution quality.", "configspace": "", "generation": 15, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 22 is out of bounds for axis 0 with size 20').", "error": "IndexError('index 22 is out of bounds for axis 0 with size 20')", "parent_id": "0788f662-5a69-4ba2-9dd1-451628e646f7", "metadata": {}, "mutation_prompt": null}
{"id": "fd4e6c6c-b815-43f8-90d6-1aa788c8f035", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8\n        self.cr = 0.9\n        self.evaluations = 0\n        self.learning_rate = 0.1\n        self.f_memory = 0.8\n\n    def adapt_parameters(self):\n        self.f = self.f_memory + np.random.rand() * 0.3 * (1 - self.evaluations / self.budget)\n        self.cr = 0.9 + np.random.rand() * 0.1\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.01 * (1 - self.evaluations / self.budget)\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def quantum_inspired_mutation(self, solution):\n        q_mutation = np.random.normal(0, 0.05 * (1 - self.evaluations / self.budget), size=solution.shape)\n        return np.clip(solution + q_mutation, self.lb, self.ub)\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.quantum_inspired_mutation(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n                self.f_memory = 0.9 * self.f_memory + 0.1 * self.f\n            else:\n                new_population[i] = population[i] + self.learning_rate * (trial - population[i])\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            self.population_size = max(15, int(25 * (1 - self.evaluations**0.5 / self.budget**0.5)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n                self.learning_rate = 0.1 + 0.7 * (1 - self.evaluations / self.budget)  # Changed line\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 15 == 0:\n                self.f *= 0.95\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Introduces a dynamic learning rate adjustment based on convergence progress to enhance solution refinement.", "configspace": "", "generation": 15, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 23 is out of bounds for axis 0 with size 20').", "error": "IndexError('index 23 is out of bounds for axis 0 with size 20')", "parent_id": "0788f662-5a69-4ba2-9dd1-451628e646f7", "metadata": {}, "mutation_prompt": null}
{"id": "76e2df23-23bd-4d4c-b86c-0c49525dfa3d", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8\n        self.cr = 0.9\n        self.evaluations = 0\n        self.learning_rate = 0.1\n        self.f_memory = 0.8\n\n    def adapt_parameters(self):\n        self.f = self.f_memory + np.random.rand() * 0.3 * (1 - self.evaluations / self.budget)\n        self.cr = 0.9 + np.random.rand() * 0.1\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else np.clip(x, self.lb, self.ub)  # Changed line\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.01 * (1 - self.evaluations / self.budget)\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def quantum_inspired_mutation(self, solution):\n        q_mutation = np.random.normal(0, 0.05 * (1 - self.evaluations / self.budget), size=solution.shape)\n        return np.clip(solution + q_mutation, self.lb, self.ub)\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.quantum_inspired_mutation(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n                self.f_memory = 0.9 * self.f_memory + 0.1 * self.f\n            else:\n                new_population[i] = population[i] + self.learning_rate * (trial - population[i])\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            self.population_size = max(15, int(25 * (1 - self.evaluations**0.5 / self.budget**0.5)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n                self.learning_rate = 0.1 + 0.5 * (1 - self.evaluations / self.budget)\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 15 == 0:\n                self.f *= 0.95\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Incorporates adaptive population resizing and dynamic exploration with refined local search to enhance search efficiency while maintaining the balance between exploration and exploitation.", "configspace": "", "generation": 15, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 22 is out of bounds for axis 0 with size 20').", "error": "IndexError('index 22 is out of bounds for axis 0 with size 20')", "parent_id": "0788f662-5a69-4ba2-9dd1-451628e646f7", "metadata": {}, "mutation_prompt": null}
{"id": "bbaab007-2dc7-47fd-9078-110679cf22f9", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8\n        self.cr = 0.9\n        self.evaluations = 0\n        self.learning_rate = 0.1\n        self.f_memory = 0.8\n\n    def adapt_parameters(self):\n        self.f = self.f_memory + np.random.rand() * 0.3 * (1 - self.evaluations / self.budget)\n        self.cr = 0.9 + np.random.rand() * 0.1\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.01 * (1 - self.evaluations / self.budget)\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def quantum_inspired_mutation(self, solution):\n        q_mutation = np.random.normal(0, 0.05 * (1 - self.evaluations / self.budget), size=solution.shape)\n        return np.clip(solution + q_mutation, self.lb, self.ub)\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.quantum_inspired_mutation(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n                self.learning_rate *= 1.1  # Changed line\n                self.f_memory = 0.9 * self.f_memory + 0.1 * self.f\n            else:\n                new_population[i] = population[i] + self.learning_rate * (trial - population[i])\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            self.population_size = max(15, int(25 * (1 - self.evaluations**0.5 / self.budget**0.5)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n                self.learning_rate = 0.1 + 0.5 * (1 - self.evaluations / self.budget)\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 15 == 0:\n                self.f *= 0.95\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Introduce adaptive learning rate scaling based on improvement in solution quality to enhance convergence speed. ", "configspace": "", "generation": 15, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 21 is out of bounds for axis 0 with size 20').", "error": "IndexError('index 21 is out of bounds for axis 0 with size 20')", "parent_id": "0788f662-5a69-4ba2-9dd1-451628e646f7", "metadata": {}, "mutation_prompt": null}
{"id": "eac91719-2235-4db9-918a-a8470c05a6ad", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8\n        self.cr = 0.9\n        self.evaluations = 0\n        self.learning_rate = 0.1\n        self.f_memory = 0.8\n\n    def adapt_parameters(self):\n        self.f = self.f_memory + np.random.rand() * 0.3 * (1 - self.evaluations / self.budget)\n        self.cr = 0.9 + np.random.rand() * 0.1\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.01 * (1 - self.evaluations / self.budget)\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def quantum_inspired_mutation(self, solution):\n        q_mutation = np.random.normal(0, 0.05 * (1 - self.evaluations / self.budget), size=solution.shape)\n        return np.clip(solution + q_mutation, self.lb, self.ub)\n\n    def gradient_refinement(self, solution):\n        res = minimize(self.func, solution, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else solution\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.quantum_inspired_mutation(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = self.gradient_refinement(trial)  # Changed line\n                self.f_memory = 0.9 * self.f_memory + 0.1 * self.f\n            else:\n                new_population[i] = population[i] + self.learning_rate * (trial - population[i])\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            self.population_size = max(15, int(25 * (1 - self.evaluations**0.5 / self.budget**0.5)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n                self.learning_rate = 0.1 + 0.5 * (1 - self.evaluations / self.budget)\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 15 == 0:\n                self.f *= 0.95\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Enhances exploitation by adding a gradient-based refinement step and further balancing diversity and convergence with adaptive learning rates and population dynamics.", "configspace": "", "generation": 15, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 22 is out of bounds for axis 0 with size 20').", "error": "IndexError('index 22 is out of bounds for axis 0 with size 20')", "parent_id": "0788f662-5a69-4ba2-9dd1-451628e646f7", "metadata": {}, "mutation_prompt": null}
{"id": "fbf5e87d-c7c5-46e2-aaff-b277ef274d0e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8\n        self.cr = 0.9\n        self.evaluations = 0\n        self.learning_rate = 0.1\n        self.f_memory = 0.8\n\n    def adapt_parameters(self):\n        self.f = self.f_memory + np.random.rand() * 0.3 * (1 - self.evaluations / self.budget)\n        self.cr = 0.9 + np.random.rand() * 0.1\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.02 * (1 - self.evaluations / self.budget)  # Changed line\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def quantum_inspired_mutation(self, solution):\n        q_mutation = np.random.normal(0, 0.05 * (1 - self.evaluations / self.budget), size=solution.shape)\n        return np.clip(solution + q_mutation, self.lb, self.ub)\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.quantum_inspired_mutation(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n                self.f_memory = 0.9 * self.f_memory + 0.1 * self.f\n            else:\n                new_population[i] = population[i] + self.learning_rate * (trial - population[i])\n                if np.random.rand() < 0.05:\n                    new_population[i] = np.random.uniform(self.lb, self.ub, self.dim)\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            self.population_size = max(15, int(25 * (1 - self.evaluations**0.5 / self.budget**0.5)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n                self.learning_rate = 0.15 + 0.5 * (1 - self.evaluations / self.budget)  # Changed line\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 10 == 0:\n                self.f *= 0.94  # Changed line\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Refines parameter adaptation and local search to enhance solution diversity and robustness within tight modification constraints.", "configspace": "", "generation": 16, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 20 is out of bounds for axis 0 with size 20').", "error": "IndexError('index 20 is out of bounds for axis 0 with size 20')", "parent_id": "b3a9947a-cd63-4425-960a-344a6441bd74", "metadata": {}, "mutation_prompt": null}
{"id": "c4996ab7-bace-48fa-bb48-4144aa879221", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8\n        self.cr = 0.9\n        self.evaluations = 0\n        self.learning_rate = 0.1\n        self.f_memory = 0.8\n\n    def adapt_parameters(self):\n        self.f = self.f_memory + np.random.rand() * 0.3 * (1 - self.evaluations / self.budget)\n        self.cr = 0.9 + np.random.rand() * 0.1\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.01 * (1 - self.evaluations / self.budget)\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def quantum_inspired_mutation(self, solution):\n        q_mutation = np.random.normal(0, 0.05 * (1 - self.evaluations / self.budget), size=solution.shape)\n        return np.clip(solution + q_mutation, self.lb, self.ub)\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.quantum_inspired_mutation(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n                self.f_memory = 0.9 * self.f_memory + 0.1 * self.f\n            else:\n                new_population[i] = population[i] + self.learning_rate * (trial - population[i])\n                if np.random.rand() < 0.05:  \n                    new_population[i] = np.random.uniform(self.lb, self.ub, self.dim)  \n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            self.population_size = max(15, int(25 * (1 - self.evaluations**0.5 / self.budget**0.5)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n                self.learning_rate = 0.1 + 0.5 * (1 - self.evaluations / self.budget)\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 10 == 0:  \n                if self.evaluations % 50 == 0:  # New condition for adaptive reinitialization\n                    population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))  # New line\n                self.f *= 0.92  \n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Introduced adaptive reinitialization and enhanced exploration for improved diversity and robustness.", "configspace": "", "generation": 16, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 23 is out of bounds for axis 0 with size 20').", "error": "IndexError('index 23 is out of bounds for axis 0 with size 20')", "parent_id": "b3a9947a-cd63-4425-960a-344a6441bd74", "metadata": {}, "mutation_prompt": null}
{"id": "8b7b70b5-c103-4032-99a6-5f0257480553", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8\n        self.cr = 0.9\n        self.evaluations = 0\n        self.learning_rate = 0.1\n        self.f_memory = 0.8\n\n    def adapt_parameters(self):\n        self.f = self.f_memory + np.random.rand() * 0.3 * (1 - self.evaluations / self.budget)\n        self.cr = 0.9 + np.random.rand() * 0.1\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.01 * (1 - self.evaluations / self.budget)\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def quantum_inspired_mutation(self, solution):\n        q_mutation = np.random.normal(0, 0.05 * (1 - self.evaluations / self.budget), size=solution.shape)\n        return np.clip(solution + q_mutation, self.lb, self.ub)\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.quantum_inspired_mutation(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n                self.f_memory = 0.9 * self.f_memory + 0.1 * self.f\n            else:\n                new_population[i] = population[i] + self.learning_rate * (trial - population[i])\n                if np.random.rand() < 0.05:  # New line (1)\n                    new_population[i] = np.random.uniform(self.lb, self.ub, self.dim)  # New line (2)\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            self.population_size = max(15, int(25 * (1 - self.evaluations**0.5 / self.budget**0.5)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n                self.learning_rate = 0.1 + 0.5 * (1 - self.evaluations / self.budget)\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 10 == 0:  # Changed condition (3)\n                self.population_size = max(5, self.population_size - 1)  # New line (5)\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Enhanced diversity strategy with adaptive random initialization to improve exploration and avoid stagnation.", "configspace": "", "generation": 16, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 24 is out of bounds for axis 0 with size 20').", "error": "IndexError('index 24 is out of bounds for axis 0 with size 20')", "parent_id": "b3a9947a-cd63-4425-960a-344a6441bd74", "metadata": {}, "mutation_prompt": null}
{"id": "8acc3cbf-5719-4bf8-a1e8-5c7e014a047d", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8\n        self.cr = 0.9\n        self.evaluations = 0\n        self.learning_rate = 0.1\n        self.f_memory = 0.8\n\n    def adapt_parameters(self):\n        self.f = self.f_memory + np.random.rand() * 0.3 * (1 - self.evaluations / self.budget)\n        self.cr = 0.9 + np.random.rand() * 0.1\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.01 * (1 - self.evaluations / self.budget)\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def quantum_inspired_mutation(self, solution):\n        q_mutation = np.random.normal(0, 0.05 * (1 - self.evaluations / self.budget), size=solution.shape)\n        return np.clip(solution + q_mutation, self.lb, self.ub)\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.quantum_inspired_mutation(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n                self.f_memory = 0.9 * self.f_memory + 0.1 * self.f\n            else:\n                new_population[i] = population[i] + self.learning_rate * (trial - population[i])\n                if np.random.rand() < 0.05:  \n                    new_population[i] = np.random.uniform(self.lb, self.ub, self.dim) \n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            self.population_size = max(15, int(25 * (1 - self.evaluations**0.5 / self.budget**0.5)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n                self.learning_rate = 0.1 + 0.5 * (1 - self.evaluations / self.budget)\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 10 == 0:\n                self.f *= 0.92  \n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Introduce a boundary check to prevent IndexError by ensuring indices used in population operations are within bounds.", "configspace": "", "generation": 16, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 23 is out of bounds for axis 0 with size 20').", "error": "IndexError('index 23 is out of bounds for axis 0 with size 20')", "parent_id": "b3a9947a-cd63-4425-960a-344a6441bd74", "metadata": {}, "mutation_prompt": null}
{"id": "63e4e961-61f3-43d6-9452-be05c5752683", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8\n        self.cr = 0.9\n        self.evaluations = 0\n        self.learning_rate = 0.1\n        self.f_memory = 0.8\n\n    def adapt_parameters(self):\n        self.f = self.f_memory + np.random.rand() * 0.3 * (1 - self.evaluations / self.budget)\n        self.cr = 0.9 + np.random.rand() * 0.1\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.01 * (1 - self.evaluations / self.budget)\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def quantum_inspired_mutation(self, solution):\n        q_mutation = np.random.normal(0, 0.05 * (1 - self.evaluations / self.budget), size=solution.shape)\n        return np.clip(solution + q_mutation, self.lb, self.ub)\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.quantum_inspired_mutation(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n                self.f_memory = 0.9 * self.f_memory + 0.1 * self.f\n            else:\n                new_population[i] = population[i] + self.learning_rate * (trial - population[i])\n                if np.random.rand() < 0.05:\n                    new_population[i] = np.random.uniform(self.lb, self.ub, self.dim)\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            self.population_size = max(15, int(25 * (1 - self.evaluations**0.5 / self.budget**0.5)))\n            self.population_size = min(self.population_size, len(population))  # Change 1\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n                self.learning_rate = 0.1 + 0.5 * (1 - self.evaluations / self.budget)\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 10 == 0:\n                self.f *= 0.92\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Introduces adaptive population size adjustment and improved handling of boundary constraints to enhance robustness and avoid index errors. ", "configspace": "", "generation": 16, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 22 is out of bounds for axis 0 with size 20').", "error": "IndexError('index 22 is out of bounds for axis 0 with size 20')", "parent_id": "b3a9947a-cd63-4425-960a-344a6441bd74", "metadata": {}, "mutation_prompt": null}
{"id": "8f8e97a1-9ce7-4a33-b981-2674375846a8", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8\n        self.cr = 0.9\n        self.evaluations = 0\n        self.learning_rate = 0.1\n        self.f_memory = 0.8\n\n    def adapt_parameters(self):\n        self.f = self.f_memory + np.random.rand() * 0.3 * (1 - self.evaluations / self.budget)\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        if np.random.rand() < 0.5:  # Reduced local search frequency\n            res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n            return res.x if res.success else x\n        return x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.02 * (1 - self.evaluations / self.budget)\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def quantum_inspired_mutation(self, solution):\n        q_mutation = np.random.normal(0, 0.05 * (1 - self.evaluations / self.budget), size=solution.shape)\n        return np.clip(solution + q_mutation, self.lb, self.ub)\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            if np.random.rand() < 0.5:  # Introduce robustness check probabilistically\n                trial = self.robustness_check(trial)\n            trial = self.quantum_inspired_mutation(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n                self.f_memory = 0.9 * self.f_memory + 0.1 * self.f\n            else:\n                new_population[i] = population[i] + self.learning_rate * (trial - population[i])\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            self.population_size = max(15, int(25 * (1 - self.evaluations**0.5 / self.budget**0.5)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n                self.learning_rate = 0.15 + 0.5 * (1 - self.evaluations / self.budget)\n\n            self.evaluations += self.population_size\n            if self.evaluations % 10 == 0:\n                self.f *= 0.94\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Integrates adaptive differential evolution with selective local search and robustness-oriented population updates to enhance solution quality amid complex constraint landscapes.", "configspace": "", "generation": 17, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 20 is out of bounds for axis 0 with size 20').", "error": "IndexError('index 20 is out of bounds for axis 0 with size 20')", "parent_id": "fbf5e87d-c7c5-46e2-aaff-b277ef274d0e", "metadata": {}, "mutation_prompt": null}
{"id": "e5a2ff11-f0a5-45ef-975f-dad8e647b5f9", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8\n        self.cr = 0.9\n        self.evaluations = 0\n        self.learning_rate = 0.1\n        self.f_memory = 0.8\n\n    def adapt_parameters(self):\n        self.f = self.f_memory + np.random.rand() * 0.3 * (1 - self.evaluations / self.budget)\n        self.cr = 0.9 + np.random.rand() * 0.1\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.02 * np.exp(-self.evaluations / self.budget)  # Changed line\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def quantum_inspired_mutation(self, solution):\n        q_mutation = np.random.normal(0, 0.05 * (1 - self.evaluations / self.budget), size=solution.shape)\n        return np.clip(solution + q_mutation, self.lb, self.ub)\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.quantum_inspired_mutation(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n                self.f_memory = 0.9 * self.f_memory + 0.1 * self.f\n            else:\n                new_population[i] = population[i] + self.learning_rate * (trial - population[i])\n                if np.random.rand() < 0.05:\n                    new_population[i] = np.random.uniform(self.lb, self.ub, self.dim)\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            self.population_size = max(15, int(25 * (1 - self.evaluations**0.5 / self.budget**0.5)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n                self.learning_rate = 0.15 + 0.5 * (1 - self.evaluations / self.budget)\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 10 == 0:\n                self.f *= 0.94\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Enhance robustness by adapting perturbation scale dynamically based on evaluation ratio with slight modification for stability.", "configspace": "", "generation": 17, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 22 is out of bounds for axis 0 with size 20').", "error": "IndexError('index 22 is out of bounds for axis 0 with size 20')", "parent_id": "fbf5e87d-c7c5-46e2-aaff-b277ef274d0e", "metadata": {}, "mutation_prompt": null}
{"id": "09db384f-862f-4b18-8658-e2375c6a93d1", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8\n        self.cr = 0.9\n        self.evaluations = 0\n        self.learning_rate = 0.1\n        self.f_memory = 0.8\n\n    def adapt_parameters(self):\n        self.f = self.f_memory + np.random.rand() * 0.3 * (1 - self.evaluations / self.budget)\n        self.cr = 0.9 + np.random.rand() * 0.1\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.01 * (1 - self.evaluations / self.budget)  # Changed line\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def quantum_inspired_mutation(self, solution):\n        q_mutation = np.random.normal(0, 0.05 * (1 - self.evaluations / self.budget), size=solution.shape)\n        return np.clip(solution + q_mutation, self.lb, self.ub)\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.quantum_inspired_mutation(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n                self.f_memory = 0.9 * self.f_memory + 0.1 * self.f\n            else:\n                new_population[i] = population[i] + self.learning_rate * (trial - population[i])\n                if np.random.rand() < 0.05:\n                    new_population[i] = np.random.uniform(self.lb, self.ub, self.dim)\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            self.population_size = max(15, int(25 * (1 - self.evaluations**0.5 / self.budget**0.5)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n                self.learning_rate = 0.15 + 0.5 * (1 - self.evaluations / self.budget)  # Changed line\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 10 == 0:\n                self.f *= 0.94  # Changed line\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Optimize perturbation scale calculation to ensure robust solution adaptation.", "configspace": "", "generation": 17, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 22 is out of bounds for axis 0 with size 20').", "error": "IndexError('index 22 is out of bounds for axis 0 with size 20')", "parent_id": "fbf5e87d-c7c5-46e2-aaff-b277ef274d0e", "metadata": {}, "mutation_prompt": null}
{"id": "f8b5109c-d98b-4a17-9ad1-319829ff139b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8\n        self.cr = 0.9\n        self.evaluations = 0\n        self.learning_rate = 0.1\n        self.f_memory = 0.8\n\n    def adapt_parameters(self):\n        self.f = self.f_memory + np.random.rand() * 0.3 * (1 - self.evaluations / self.budget)\n        self.cr = 0.9 + np.random.rand() * 0.1\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.02 * (1 - self.evaluations / self.budget)  # Changed line\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def quantum_inspired_mutation(self, solution):\n        q_mutation = np.random.normal(0, 0.05 * (1 - self.evaluations / self.budget), size=solution.shape)\n        return np.clip(solution + q_mutation, self.lb, self.ub)\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.quantum_inspired_mutation(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n                self.f_memory = 0.9 * self.f_memory + 0.1 * self.f\n            else:\n                new_population[i] = population[i] + self.learning_rate * (trial - population[i])\n                if np.random.rand() < 0.05:\n                    new_population[i] = np.random.uniform(self.lb, self.ub, self.dim)\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            self.population_size = max(15, int(25 * (1 - self.evaluations**0.5 / self.budget**0.5)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n                self.learning_rate = 0.15 + 0.5 * (1 - self.evaluations / self.budget)  # Changed line\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 10 == 0:\n                self.f *= 0.94  # Changed line\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Update the mutation indices selection to prevent index out-of-bounds errors.", "configspace": "", "generation": 17, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 23 is out of bounds for axis 0 with size 20').", "error": "IndexError('index 23 is out of bounds for axis 0 with size 20')", "parent_id": "fbf5e87d-c7c5-46e2-aaff-b277ef274d0e", "metadata": {}, "mutation_prompt": null}
{"id": "fadf84d3-b6a5-4908-9403-83e8496c78b8", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8\n        self.cr = 0.9\n        self.evaluations = 0\n        self.learning_rate = 0.1\n        self.f_memory = 0.8\n\n    def adapt_parameters(self):\n        self.f = self.f_memory + np.random.rand() * 0.3 * (1 - self.evaluations / self.budget)\n        self.cr = 0.9 + np.random.rand() * 0.1\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        indices = np.random.choice(indices, 3, replace=False) if len(indices) >= 3 else [0, 1, 2]  # Changed line\n        a, b, c = indices\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.02 * (1 - self.evaluations / self.budget)\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def quantum_inspired_mutation(self, solution):\n        q_mutation = np.random.normal(0, 0.05 * (1 - self.evaluations / self.budget), size=solution.shape)\n        return np.clip(solution + q_mutation, self.lb, self.ub)\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.quantum_inspired_mutation(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n                self.f_memory = 0.9 * self.f_memory + 0.1 * self.f\n            else:\n                new_population[i] = population[i] + self.learning_rate * (trial - population[i])\n                if np.random.rand() < 0.05:\n                    new_population[i] = np.random.uniform(self.lb, self.ub, self.dim)\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            self.population_size = max(15, int(25 * (1 - self.evaluations**0.5 / self.budget**0.5)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n                self.learning_rate = 0.15 + 0.5 * (1 - self.evaluations / self.budget)\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 10 == 0:\n                self.f *= 0.94\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Added a safeguard in `mutate()` to prevent out-of-bounds errors when choosing indices for mutation.  ", "configspace": "", "generation": 17, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 23 is out of bounds for axis 0 with size 20').", "error": "IndexError('index 23 is out of bounds for axis 0 with size 20')", "parent_id": "fbf5e87d-c7c5-46e2-aaff-b277ef274d0e", "metadata": {}, "mutation_prompt": null}
{"id": "8f94c96b-4c63-48bc-8020-af72861a70a2", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8\n        self.cr = 0.9\n        self.evaluations = 0\n        self.learning_rate = 0.1\n        self.f_memory = 0.8\n\n    def adapt_parameters(self):\n        self.f = self.f_memory + np.random.rand() * 0.3 * (1 - self.evaluations / self.budget)\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.02 * (1 - self.evaluations / self.budget)\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def quantum_inspired_mutation(self, solution):\n        q_mutation = np.random.normal(0, 0.05 * (1 - self.evaluations / self.budget), size=solution.shape)\n        return np.clip(solution + q_mutation, self.lb, self.ub)\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            if np.random.rand() < 0.5:  # Introduce robustness check probabilistically\n                trial = self.robustness_check(trial)\n            trial = self.quantum_inspired_mutation(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n                self.f_memory = 0.9 * self.f_memory + 0.1 * self.f\n            else:\n                new_population[i] = population[i] + self.learning_rate * (trial - population[i])\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            self.population_size = max(15, int(25 * (1 - self.evaluations**0.5 / self.budget**0.5)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n                self.learning_rate = 0.15 + 0.5 * (1 - self.evaluations / self.budget)\n\n            self.evaluations += self.population_size\n            if self.evaluations % 10 == 0:\n                self.f *= 0.94\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Enhancing adaptive evolution with gradient-based local search and refined parameter adaptation for robust optimization.", "configspace": "", "generation": 18, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 23 is out of bounds for axis 0 with size 20').", "error": "IndexError('index 23 is out of bounds for axis 0 with size 20')", "parent_id": "8f8e97a1-9ce7-4a33-b981-2674375846a8", "metadata": {}, "mutation_prompt": null}
{"id": "0fc2a396-fcd7-4f15-b58b-973f09bd0d8a", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8\n        self.cr = 0.9\n        self.evaluations = 0\n        self.learning_rate = 0.1\n        self.f_memory = 0.8\n\n    def adapt_parameters(self):\n        self.f = self.f_memory + np.random.rand() * 0.3 * (1 - self.evaluations / self.budget)\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        if np.random.rand() < 0.5:  # Reduced local search frequency\n            res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n            return res.x if res.success else x\n        return x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.02 * (1 - self.evaluations / self.budget)\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def quantum_inspired_mutation(self, solution):\n        q_mutation = np.random.normal(0, 0.05 * (1 - self.evaluations / self.budget), size=solution.shape)\n        return np.clip(solution + q_mutation, self.lb, self.ub)\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            if np.random.rand() < 0.5:  # Introduce robustness check probabilistically\n                trial = self.robustness_check(trial)\n            trial = self.quantum_inspired_mutation(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n                self.f_memory = 0.9 * self.f_memory + 0.1 * self.f\n            else:\n                new_population[i] = population[i] + self.learning_rate * (trial - population[i])\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            self.population_size = max(15, int(25 * (1 - min(self.evaluations, self.budget-1)**0.5 / self.budget**0.5))) # Change made here\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n                self.learning_rate = 0.15 + 0.5 * (1 - self.evaluations / self.budget)\n\n            self.evaluations += self.population_size\n            if self.evaluations % 10 == 0:\n                self.f *= 0.94\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Enhances solution refinement by ensuring population boundaries are respected during evolution, reducing out-of-bound errors.", "configspace": "", "generation": 18, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 22 is out of bounds for axis 0 with size 20').", "error": "IndexError('index 22 is out of bounds for axis 0 with size 20')", "parent_id": "8f8e97a1-9ce7-4a33-b981-2674375846a8", "metadata": {}, "mutation_prompt": null}
{"id": "95a39a62-e0eb-466c-9d82-90b511495421", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8\n        self.cr = 0.9\n        self.evaluations = 0\n        self.learning_rate = 0.1\n        self.f_memory = 0.8\n\n    def adapt_parameters(self):\n        self.f = self.f_memory + np.random.rand() * 0.3 * (1 - self.evaluations / self.budget)\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        if np.random.rand() < 0.5:\n            res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n            return res.x if res.success else x\n        return x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.02 * (1 - self.evaluations / self.budget)\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def quantum_inspired_mutation(self, solution):\n        q_mutation = np.random.normal(0, 0.05 * (1 - self.evaluations / self.budget), size=solution.shape)\n        return np.clip(solution + q_mutation, self.lb, self.ub)\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            if np.random.rand() < 0.5:\n                trial = self.robustness_check(trial)\n            trial = self.quantum_inspired_mutation(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n                self.f_memory = 0.9 * self.f_memory + 0.1 * self.f\n            else:\n                new_population[i] = population[i] + self.learning_rate * (trial - population[i])\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            self.population_size = max(15, int(25 * (1 - self.evaluations**0.5 / self.budget**0.5)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n                self.learning_rate = 0.15 + 0.5 * (1 - self.evaluations / self.budget)\n\n            self.evaluations += self.population_size\n            if self.evaluations % 10 == 0:\n                self.f *= 0.94\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Refined adaptive hybrid evolution that integrates noise-resilient parameter updates and dynamic population size adjustments for improved robustness and convergence in noisy optimization landscapes.", "configspace": "", "generation": 18, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 22 is out of bounds for axis 0 with size 20').", "error": "IndexError('index 22 is out of bounds for axis 0 with size 20')", "parent_id": "8f8e97a1-9ce7-4a33-b981-2674375846a8", "metadata": {}, "mutation_prompt": null}
{"id": "1801df31-b9fe-4cd4-8781-a5c6fb139f62", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8\n        self.cr = 0.9\n        self.evaluations = 0\n        self.learning_rate = 0.1\n        self.f_memory = 0.8\n\n    def adapt_parameters(self):\n        self.f = self.f_memory + np.random.rand() * 0.3 * (1 - self.evaluations / self.budget)\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        if np.random.rand() < 0.5:\n            res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n            return res.x if res.success else x\n        return x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.03 * (1 - self.evaluations / self.budget)  # Line change #1\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def quantum_inspired_mutation(self, solution):\n        q_mutation = np.random.normal(0, 0.05 * (1 - self.evaluations / self.budget), size=solution.shape)\n        return np.clip(solution + q_mutation, self.lb, self.ub)\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.robustness_check(trial)  # Line change #2\n            trial = self.quantum_inspired_mutation(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n                self.f_memory = 0.9 * self.f_memory + 0.1 * self.f\n            else:\n                new_population[i] = population[i] + self.learning_rate * (trial - population[i])\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            self.population_size = max(15, int(25 * (1 - self.evaluations**0.5 / self.budget**0.5)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n                self.learning_rate = 0.15 + 0.5 * (1 - self.evaluations / self.budget)\n\n            self.evaluations += self.population_size\n            if self.evaluations % 10 == 0:\n                self.f *= 0.94\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Introduces adaptive fitness scaling and enhanced robustness checks to balance exploration and solution stability.", "configspace": "", "generation": 18, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 24 is out of bounds for axis 0 with size 20').", "error": "IndexError('index 24 is out of bounds for axis 0 with size 20')", "parent_id": "8f8e97a1-9ce7-4a33-b981-2674375846a8", "metadata": {}, "mutation_prompt": null}
{"id": "00ae8cdc-8329-4e72-8e61-9065d50550b2", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8\n        self.cr = 0.9\n        self.evaluations = 0\n        self.learning_rate = 0.1\n        self.f_memory = 0.8\n\n    def adapt_parameters(self):\n        self.f = self.f_memory + np.random.rand() * 0.3 * (1 - self.evaluations / self.budget)\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        if np.random.rand() < 0.5:  # Reduced local search frequency\n            res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n            return res.x if res.success else x\n        return x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.015 * (1 - self.evaluations / self.budget)  # Reduced perturbation scale\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def quantum_inspired_mutation(self, solution):\n        q_mutation = np.random.normal(0, 0.04 * (1 - self.evaluations / self.budget), size=solution.shape)  # Fine-tuned mutation\n        return np.clip(solution + q_mutation, self.lb, self.ub)\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            if np.random.rand() < 0.5:  # Introduce robustness check probabilistically\n                trial = self.robustness_check(trial)\n            trial = self.quantum_inspired_mutation(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n                self.f_memory = 0.9 * self.f_memory + 0.1 * self.f\n            else:\n                new_population[i] = population[i] + self.learning_rate * (trial - population[i])\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            self.population_size = max(15, int(25 * (1 - self.evaluations**0.5 / self.budget**0.5)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n                self.learning_rate = 0.15 + 0.5 * (1 - self.evaluations / self.budget)\n\n            self.evaluations += self.population_size\n            if self.evaluations % 10 == 0:\n                self.f *= 0.94\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Refines the mutation and robustness strategies in adaptive hybrid evolutionary search to improve solution quality and computational efficiency.", "configspace": "", "generation": 18, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 20 is out of bounds for axis 0 with size 20').", "error": "IndexError('index 20 is out of bounds for axis 0 with size 20')", "parent_id": "8f8e97a1-9ce7-4a33-b981-2674375846a8", "metadata": {}, "mutation_prompt": null}
{"id": "6da2d54c-0556-4b86-b0ee-5504efa93ab1", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8\n        self.cr = 0.9\n        self.evaluations = 0\n        self.learning_rate = 0.1\n        self.f_memory = 0.8\n\n    def adapt_parameters(self):\n        self.f = self.f_memory + np.random.rand() * 0.3 * (1 - self.evaluations / self.budget)\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.02 * (1 - self.evaluations / self.budget)\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def quantum_inspired_mutation(self, solution):\n        q_mutation = np.random.normal(0, 0.05 * (1 - self.evaluations / self.budget), size=solution.shape)\n        return np.clip(solution + q_mutation, self.lb, self.ub)\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            if np.random.rand() < 0.5:  # Introduce robustness check probabilistically\n                trial = self.robustness_check(trial)\n            trial = self.quantum_inspired_mutation(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n                self.f_memory = 0.9 * self.f_memory + 0.1 * self.f\n            else:\n                new_population[i] = population[i] + self.learning_rate * (trial - population[i])\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            self.population_size = max(15, int(30 * (1 - self.evaluations**0.5 / self.budget**0.5)))  # Adjusted\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n                self.learning_rate = 0.2 + 0.5 * (1 - self.evaluations / self.budget)  # Adjusted\n\n            self.evaluations += self.population_size\n            if self.evaluations % 10 == 0:\n                self.f *= 0.95  # Adjusted\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Improved robustness and convergence rate by fine-tuning adaptive parameters and incorporating a dynamic population size adjustment.", "configspace": "", "generation": 19, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 22 is out of bounds for axis 0 with size 20').", "error": "IndexError('index 22 is out of bounds for axis 0 with size 20')", "parent_id": "8f94c96b-4c63-48bc-8020-af72861a70a2", "metadata": {}, "mutation_prompt": null}
{"id": "1fbbf93f-6c30-4129-847a-f2c2530a3159", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8\n        self.cr = 0.9\n        self.evaluations = 0\n        self.learning_rate = 0.1\n        self.f_memory = 0.8\n\n    def adapt_parameters(self):\n        self.f = self.f_memory + np.random.rand() * 0.3 * (1 - self.evaluations / self.budget)\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.02 * (1 - self.evaluations / self.budget)\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def quantum_inspired_mutation(self, solution):\n        q_mutation = np.random.normal(0, 0.05 * (1 - self.evaluations / self.budget), size=solution.shape)\n        return np.clip(solution + q_mutation, self.lb, self.ub)\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            if np.random.rand() < 0.5:  # Introduce robustness check probabilistically\n                trial = self.robustness_check(trial)\n            trial = self.quantum_inspired_mutation(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n                self.f_memory = 0.9 * self.f_memory + 0.1 * self.f\n            else:\n                new_population[i] = population[i] + self.learning_rate * (trial - population[i])\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            self.population_size = max(15, min(25, int(25 * (1 - self.evaluations**0.5 / self.budget**0.5))))  # Fix\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n                self.learning_rate = 0.15 + 0.5 * (1 - self.evaluations / self.budget)\n\n            self.evaluations += self.population_size\n            if self.evaluations % 10 == 0:\n                self.f *= 0.94\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Refine population size adjustment to prevent out-of-bounds errors in adaptive hybrid search.", "configspace": "", "generation": 19, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 23 is out of bounds for axis 0 with size 20').", "error": "IndexError('index 23 is out of bounds for axis 0 with size 20')", "parent_id": "8f94c96b-4c63-48bc-8020-af72861a70a2", "metadata": {}, "mutation_prompt": null}
{"id": "5796c4a7-6f28-40d5-894c-1340bf1a3bed", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8\n        self.cr = 0.9\n        self.evaluations = 0\n        self.learning_rate = 0.1\n        self.f_memory = 0.8\n\n    def adapt_parameters(self):\n        self.f = self.f_memory + np.random.rand() * 0.3 * (1 - self.evaluations / self.budget)\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(min(len(population), self.population_size)) if idx != target_idx]  # Change\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.02 * (1 - self.evaluations / self.budget)\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def quantum_inspired_mutation(self, solution):\n        q_mutation = np.random.normal(0, 0.05 * (1 - self.evaluations / self.budget), size=solution.shape)\n        return np.clip(solution + q_mutation, self.lb, self.ub)\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            if np.random.rand() < 0.5:  # Introduce robustness check probabilistically\n                trial = self.robustness_check(trial)\n            trial = self.quantum_inspired_mutation(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n                self.f_memory = 0.9 * self.f_memory + 0.1 * self.f\n            else:\n                new_population[i] = population[i] + self.learning_rate * (trial - population[i])\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            self.population_size = max(15, int(25 * (1 - self.evaluations**0.5 / self.budget**0.5)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n                self.learning_rate = 0.15 + 0.5 * (1 - self.evaluations / self.budget)\n\n            self.evaluations += self.population_size\n            if self.evaluations % 10 == 0:\n                self.f *= 0.94\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Improved boundary handling in mutation to avoid index errors in high-dimensional search spaces.", "configspace": "", "generation": 19, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 24 is out of bounds for axis 0 with size 20').", "error": "IndexError('index 24 is out of bounds for axis 0 with size 20')", "parent_id": "8f94c96b-4c63-48bc-8020-af72861a70a2", "metadata": {}, "mutation_prompt": null}
{"id": "e498a7ac-41cb-461e-99ea-21e1c892a1d3", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8\n        self.cr = 0.9\n        self.evaluations = 0\n        self.learning_rate = 0.1\n        self.f_memory = 0.8\n\n    def adapt_parameters(self):\n        self.f = self.f_memory + np.random.rand() * 0.3 * (1 - self.evaluations / self.budget)\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.02 * (1 - self.evaluations / self.budget)\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def quantum_inspired_mutation(self, solution):\n        q_mutation = np.random.normal(0, 0.05 * (1 - self.evaluations / self.budget), size=solution.shape)\n        return np.clip(solution + q_mutation, self.lb, self.ub)\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            if np.random.rand() < 0.5:  # Introduce robustness check probabilistically\n                trial = self.robustness_check(trial)\n            trial = self.quantum_inspired_mutation(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n                self.f_memory = 0.9 * self.f_memory + 0.1 * self.f\n            else:\n                new_population[i] = population[i] + self.learning_rate * (trial - population[i])\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            self.population_size = max(15, int(25 * (1 - self.evaluations**0.5 / self.budget**0.5)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n                self.learning_rate = 0.15 + 0.5 * (1 - self.evaluations / self.budget)\n\n            self.evaluations += self.population_size\n            self.f *= 0.94  # Adjust frequency to ensure better exploration\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Enhance adaptive evolution with quantum-inspired mutation and dynamic population adjustment for robust, scalable optimization.", "configspace": "", "generation": 19, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 29 is out of bounds for axis 0 with size 20').", "error": "IndexError('index 29 is out of bounds for axis 0 with size 20')", "parent_id": "8f94c96b-4c63-48bc-8020-af72861a70a2", "metadata": {}, "mutation_prompt": null}
{"id": "f84f57e4-fffc-4a41-be3d-858d6374e86a", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8\n        self.cr = 0.9\n        self.evaluations = 0\n        self.learning_rate = 0.1\n        self.f_memory = 0.8\n        self.success_rate = 0.2  # New parameter for success rate\n\n    def adapt_parameters(self):\n        self.f = 0.6 + np.random.rand() * 0.4\n        self.cr = 0.7 + np.random.rand() * 0.3\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation = np.random.normal(0, 0.01, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def quantum_inspired_mutation(self, solution):\n        q_mutation = np.random.normal(0, 0.05, size=solution.shape)\n        return np.clip(solution + q_mutation, self.lb, self.ub)\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        success_count = 0  # Track successful updates\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            if np.random.rand() < 0.5:\n                trial = self.robustness_check(trial)\n            trial = self.quantum_inspired_mutation(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n                success_count += 1\n            else:\n                new_population[i] = population[i]\n\n        self.success_rate = (0.9 * self.success_rate + 0.1 * (success_count / self.population_size))\n        if self.success_rate < 0.2:\n            self.population_size = min(self.population_size + 1, 30)\n        else:\n            self.population_size = max(self.population_size - 1, 15)\n\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n                self.learning_rate = 0.15 + 0.5 * (1 - self.evaluations / self.budget)\n\n            self.evaluations += self.population_size\n            if self.evaluations % 10 == 0:\n                self.f *= 0.94\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Introducing self-adaptive mechanisms for parameter control and dynamic population resizing to enhance exploration and exploitation balance in noisy high-dimensional spaces.", "configspace": "", "generation": 19, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 25 is out of bounds for axis 0 with size 20').", "error": "IndexError('index 25 is out of bounds for axis 0 with size 20')", "parent_id": "8f94c96b-4c63-48bc-8020-af72861a70a2", "metadata": {}, "mutation_prompt": null}
{"id": "864d4649-87fe-415d-b84e-fe46ea146e2e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8\n        self.cr = 0.9\n        self.evaluations = 0\n        self.learning_rate = 0.1\n        self.f_memory = 0.8\n\n    def adapt_parameters(self):\n        self.f = self.f_memory + np.random.rand() * 0.3 * (1 - self.evaluations / self.budget)\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.02 * (1 - self.evaluations / self.budget)\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def quantum_inspired_mutation(self, solution):\n        q_mutation = np.random.normal(0, 0.05 * (1 - self.evaluations / self.budget), size=solution.shape)\n        return np.clip(solution + q_mutation, self.lb, self.ub)\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            if np.random.rand() < 0.5:  # Introduce robustness check probabilistically\n                trial = self.robustness_check(trial)\n            trial = self.quantum_inspired_mutation(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n                self.f_memory = 0.9 * self.f_memory + 0.1 * self.f\n            else:\n                new_population[i] = population[i] + self.learning_rate * (trial - population[i])\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            self.population_size = max(15, int(30 * (1 - self.evaluations**0.5 / self.budget**0.5)))  # Adjusted\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n                self.learning_rate = 0.2 + 0.5 * (1 - self.evaluations / self.budget)  # Adjusted\n\n            self.evaluations += self.population_size\n            if self.evaluations % 10 == 0:\n                self.f *= 0.95\n                self.population_size = min(30, self.population_size + 1)  # Adjusted\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Enhanced robustness and convergence with dynamic population bounds and adaptive crossover.", "configspace": "", "generation": 20, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 25 is out of bounds for axis 0 with size 20').", "error": "IndexError('index 25 is out of bounds for axis 0 with size 20')", "parent_id": "6da2d54c-0556-4b86-b0ee-5504efa93ab1", "metadata": {}, "mutation_prompt": null}
{"id": "839287c2-f3b7-4a79-a8df-dd2fbd138c59", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8\n        self.cr = 0.9\n        self.evaluations = 0\n        self.learning_rate = 0.1\n        self.f_memory = 0.8\n\n    def adapt_parameters(self):\n        self.f = self.f_memory + np.random.rand() * 0.3 * (1 - self.evaluations / self.budget)\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.02 * (1 - self.evaluations / self.budget)\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def quantum_inspired_mutation(self, solution):\n        q_mutation = np.random.normal(0, 0.05 * (1 - self.evaluations / self.budget), size=solution.shape)\n        return np.clip(solution + q_mutation, self.lb, self.ub)\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            if np.random.rand() < 0.5:  # Introduce robustness check probabilistically\n                trial = self.robustness_check(trial)\n            trial = self.quantum_inspired_mutation(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n                self.f_memory = 0.9 * self.f_memory + 0.1 * self.f\n            else:\n                new_population[i] = population[i] + self.learning_rate * (trial - population[i])\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            self.population_size = max(15, int(30 * (1 - self.evaluations**0.5 / self.budget**0.5)))  # Adjusted\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n                self.learning_rate = 0.2 + 0.5 * (1 - self.evaluations / self.budget)  # Adjusted\n\n            self.evaluations += self.population_size\n            if self.evaluations % 10 == 0:\n                self.f *= 0.95  # Adjusted\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Enhanced stability by adjusting the index selection method in the mutate function.", "configspace": "", "generation": 20, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 27 is out of bounds for axis 0 with size 20').", "error": "IndexError('index 27 is out of bounds for axis 0 with size 20')", "parent_id": "6da2d54c-0556-4b86-b0ee-5504efa93ab1", "metadata": {}, "mutation_prompt": null}
{"id": "2f1345fd-c495-4d7c-ac35-63f36387d648", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8\n        self.cr = 0.9\n        self.evaluations = 0\n        self.learning_rate = 0.1\n        self.f_memory = 0.8\n\n    def adapt_parameters(self):\n        self.f = self.f_memory + np.random.rand() * 0.3 * (1 - self.evaluations / self.budget)\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.02 * (1 - self.evaluations / self.budget)\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def quantum_inspired_mutation(self, solution):\n        q_mutation = np.random.normal(0, 0.05 * (1 - self.evaluations / self.budget), size=solution.shape)\n        return np.clip(solution + q_mutation, self.lb, self.ub)\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            if np.random.rand() < 0.5:  # Introduce robustness check probabilistically\n                trial = self.robustness_check(trial)\n            trial = self.quantum_inspired_mutation(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n                self.f_memory = 0.9 * self.f_memory + 0.1 * self.f\n            else:\n                new_population[i] = population[i] + self.learning_rate * (trial - population[i])\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            self.population_size = max(15, min(30, int(30 * (1 - self.evaluations**0.5 / self.budget**0.5))))  # Adjusted\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n                self.learning_rate = 0.2 + 0.5 * (1 - self.evaluations / self.budget)  # Adjusted\n\n            self.evaluations += self.population_size\n            if self.evaluations % 10 == 0:\n                self.f *= 0.95  # Adjusted\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Improve search robustness by updating candidate selection strategy to avoid IndexError during population adjustments.", "configspace": "", "generation": 20, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 25 is out of bounds for axis 0 with size 20').", "error": "IndexError('index 25 is out of bounds for axis 0 with size 20')", "parent_id": "6da2d54c-0556-4b86-b0ee-5504efa93ab1", "metadata": {}, "mutation_prompt": null}
{"id": "c37990b7-7736-485f-a3de-adca18e10e31", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8\n        self.cr = 0.9\n        self.evaluations = 0\n        self.learning_rate = 0.1\n        self.f_memory = 0.8\n\n    def adapt_parameters(self):\n        self.f = self.f_memory + np.random.rand() * 0.3 * (1 - self.evaluations / self.budget)\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.02 * (1 - self.evaluations / self.budget)\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def quantum_inspired_mutation(self, solution):\n        q_mutation = np.random.normal(0, 0.05 * (1 - self.evaluations / self.budget), size=solution.shape)\n        return np.clip(solution + q_mutation, self.lb, self.ub)\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            if np.random.rand() < 0.5:\n                trial = self.robustness_check(trial)\n            trial = self.quantum_inspired_mutation(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n                self.f_memory = 0.9 * self.f_memory + 0.1 * self.f\n            else:\n                new_population[i] = population[i] + self.learning_rate * (trial - population[i])\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            self.population_size = max(15, int(30 * (1 - self.evaluations**0.5 / self.budget**0.5)))  \n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n                self.learning_rate = 0.2 + 0.5 * (1 - self.evaluations / self.budget) \n\n            self.evaluations += self.population_size\n            if self.evaluations % 10 == 0:\n                self.f *= 0.95  \n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Enhanced multi-strategy evolutionary search integrating dynamic population control, local refinement, and quantum-inspired mutations to tackle noisy black-box optimization problems.", "configspace": "", "generation": 20, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 28 is out of bounds for axis 0 with size 20').", "error": "IndexError('index 28 is out of bounds for axis 0 with size 20')", "parent_id": "6da2d54c-0556-4b86-b0ee-5504efa93ab1", "metadata": {}, "mutation_prompt": null}
{"id": "7d9ca939-1c05-4d72-bf54-79d6c06e8604", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8\n        self.cr = 0.9\n        self.evaluations = 0\n        self.learning_rate = 0.1\n        self.f_memory = 0.8\n\n    def adapt_parameters(self):\n        self.f = self.f_memory + np.random.rand() * 0.3 * (1 - self.evaluations / self.budget)\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.02 * (1 - self.evaluations / self.budget)\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def quantum_inspired_mutation(self, solution):\n        q_mutation = np.random.normal(0, 0.05 * (1 - self.evaluations / self.budget), size=solution.shape)\n        return np.clip(solution + q_mutation, self.lb, self.ub)\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            if np.random.rand() < 0.5:  # Introduce robustness check probabilistically\n                trial = self.robustness_check(trial)\n            trial = self.quantum_inspired_mutation(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n                self.f_memory = 0.9 * self.f_memory + 0.1 * self.f\n            else:\n                new_population[i] = population[i] + self.learning_rate * (trial - population[i])\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            self.population_size = max(15, int(min(30, 30 * (1 - self.evaluations**0.5 / self.budget**0.5))))  # Adjusted\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n                self.learning_rate = 0.2 + 0.5 * (1 - self.evaluations / self.budget)  # Adjusted\n\n            self.evaluations += self.population_size\n            if self.evaluations % 10 == 0:\n                self.f *= 0.95  # Adjusted\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Introduced a safeguard against index errors by ensuring population size constraints are maintained.", "configspace": "", "generation": 20, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 22 is out of bounds for axis 0 with size 20').", "error": "IndexError('index 22 is out of bounds for axis 0 with size 20')", "parent_id": "6da2d54c-0556-4b86-b0ee-5504efa93ab1", "metadata": {}, "mutation_prompt": null}
