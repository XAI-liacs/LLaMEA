{"id": "58313f66-3ee0-4ae0-bb0b-f822d9da950b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover rate\n        self.evaluations = 0\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)  # Apply local search\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            # Optional: Reduce dimension by initializing fewer layers at first\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim))\n            self.dim = active_layers\n\n        return best_solution", "name": "AdaptiveHybridEvolutionarySearch", "description": "The algorithm, Adaptive Hybrid Evolutionary Search (AHES), dynamically combines Differential Evolution (DE) for global exploration and a hybrid local search that switches between hill climbing and pattern search, adjusting strategies based on convergence and a layer-wise optimization schedule.", "configspace": "", "generation": 0, "fitness": 0.8100082325874611, "feedback": "The algorithm AdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.810 with standard deviation 0.030. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": null, "metadata": {"aucs": [0.8371189354712839, 0.8241953198724521, 0.7687104424186473], "final_y": [0.12896873411993903, 0.1148922273157097, 0.11967222108355502]}, "mutation_prompt": null}
{"id": "6de0507f-fde7-4751-907e-5f0f7281dc3a", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.9  # DE mutation factor\n        self.cr = 0.9  # DE crossover rate\n        self.evaluations = 0\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)  # Apply local search\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            # Optional: Reduce dimension by initializing fewer layers at first\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim))\n            self.dim = active_layers\n\n        return best_solution", "name": "AdaptiveHybridEvolutionarySearch", "description": "The Adaptive Hybrid Evolutionary Search (AHES) combines Differential Evolution with hybrid local search, adjusting strategies based on convergence and layer-wise optimization, with an enhanced mutation strategy for improved exploration.", "configspace": "", "generation": 1, "fitness": 0.8226903815768409, "feedback": "The algorithm AdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.823 with standard deviation 0.073. And the mean value of best solutions found was 0.138 (0. is the best) with standard deviation 0.033.", "error": "", "parent_id": "58313f66-3ee0-4ae0-bb0b-f822d9da950b", "metadata": {"aucs": [0.8614111713582605, 0.8862458497303383, 0.7204141236419244], "final_y": [0.11264049835226242, 0.11596857390895166, 0.18503742438597293]}, "mutation_prompt": null}
{"id": "da65bd11-ca4c-4a9d-a719-a88d0f602595", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover rate\n        self.evaluations = 0\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c]) + 0.1 * (population[a] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)  # Apply local search\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            # Optional: Reduce dimension by initializing fewer layers at first\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim))\n            self.dim = active_layers\n\n        return best_solution", "name": "AdaptiveHybridEvolutionarySearch", "description": "Adaptive Hybrid Evolutionary Search (AHES) with improved mutation strategy to enhance exploration capabilities and solution quality.", "configspace": "", "generation": 1, "fitness": 0.7838708144446033, "feedback": "The algorithm AdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.784 with standard deviation 0.036. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "58313f66-3ee0-4ae0-bb0b-f822d9da950b", "metadata": {"aucs": [0.7580530608085845, 0.8342108913500026, 0.759348491175223], "final_y": [0.1369534030791998, 0.13021770838096502, 0.12665643711116914]}, "mutation_prompt": null}
{"id": "b94ac15d-3f87-499f-abeb-f31aff662c1b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover rate\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        self.f = 0.5 + np.random.rand() * 0.5\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation = np.random.normal(0, 0.01, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.robustness_check(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            self.dim = active_layers\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "The algorithm, Enhanced Adaptive Hybrid Evolutionary Search (EAHES), introduces adaptive mutation and crossover rates, integrates a robustness check, and dynamically manages active layers to enhance performance in noisy high-dimensional settings.", "configspace": "", "generation": 1, "fitness": 0.8594405291794972, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.859 with standard deviation 0.039. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "58313f66-3ee0-4ae0-bb0b-f822d9da950b", "metadata": {"aucs": [0.8070460906205784, 0.870655144940295, 0.9006203519776181], "final_y": [0.12668915884201393, 0.1260614532275921, 0.11208816691901902]}, "mutation_prompt": null}
{"id": "67642da4-1873-4389-8312-7ea8f5873a21", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8\n        self.cr = 0.9\n        self.evaluations = 0\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            population_std = np.std(population, axis=0)  # Track population diversity\n            self.f = 0.5 + 0.5 * np.median(population_std) / np.max(population_std)  # Adjust mutation rate\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim))\n            self.dim = active_layers\n\n        return best_solution", "name": "AdaptiveHybridEvolutionarySearch", "description": "Enhance Adaptive Hybrid Evolutionary Search by dynamically adjusting mutation and crossover rates based on population diversity.", "configspace": "", "generation": 1, "fitness": 0.7915500002269676, "feedback": "The algorithm AdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.792 with standard deviation 0.035. And the mean value of best solutions found was 0.151 (0. is the best) with standard deviation 0.015.", "error": "", "parent_id": "58313f66-3ee0-4ae0-bb0b-f822d9da950b", "metadata": {"aucs": [0.8416324689466954, 0.76890311738062, 0.7641144143535873], "final_y": [0.13435453994519053, 0.1702433386818767, 0.14731878338232696]}, "mutation_prompt": null}
{"id": "db274716-7b8c-4c7c-9c24-6538e8b56199", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8 \n        self.cr = 0.9\n        self.evaluations = 0\n        \n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        adaptive_f = self.f * (1 - self.evaluations / self.budget)  # Dynamic mutation factor\n        mutant = population[a] + adaptive_f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)  \n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim))\n            self.dim = active_layers\n            self.population_size = max(10, int(self.population_size * (1 - self.evaluations / self.budget)))  # Adaptive population size\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "The algorithm, Enhanced Adaptive Hybrid Evolutionary Search (EAHES), introduces a dynamic mutation factor and adaptive population size to balance exploration and exploitation, optimizing resources and improving convergence toward the best solution.", "configspace": "", "generation": 1, "fitness": 0.841259638906573, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.841 with standard deviation 0.054. And the mean value of best solutions found was 0.136 (0. is the best) with standard deviation 0.025.", "error": "", "parent_id": "58313f66-3ee0-4ae0-bb0b-f822d9da950b", "metadata": {"aucs": [0.8994863783133741, 0.76890311738062, 0.8553894210257249], "final_y": [0.1101229847183659, 0.1702433386818767, 0.12740119411343231]}, "mutation_prompt": null}
{"id": "a0dfb4eb-e3fc-4871-b02e-df0809be3424", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover rate\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        self.f = 0.5 + np.random.rand() * 0.3  # Adjusted mutation factor range\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B', options={'gtol': 1e-5})  # Increased precision\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation = np.random.normal(0, 0.01, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.robustness_check(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            self.dim = active_layers\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "The Improved Enhanced Adaptive Hybrid Evolutionary Search (IEAHES) enhances local search by increasing robustness and includes diversity preservation to maintain a broader search through dynamically adjusted mutation range.", "configspace": "", "generation": 2, "fitness": 0.8254295113681337, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.825 with standard deviation 0.059. And the mean value of best solutions found was 0.129 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "b94ac15d-3f87-499f-abeb-f31aff662c1b", "metadata": {"aucs": [0.7433457245113033, 0.8520172810442302, 0.8809255285488674], "final_y": [0.13704760260538895, 0.1233145026215986, 0.12664813469585268]}, "mutation_prompt": null}
{"id": "be8dc16b-9c61-49fa-a3ab-6c54e2952ed2", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.max_population_size = 40  # Dynamically adjust population size\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover rate\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        self.f = 0.5 + np.random.rand() * 0.5\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(len(population)) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation = np.random.normal(0, 0.05, size=solution.shape)  # Increased perturbation\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(len(population)):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.robustness_check(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        # Initialize population\n        population_size = self.initial_population_size\n        population = np.random.uniform(self.lb, self.ub, (population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            population_size = min(self.max_population_size, self.initial_population_size + int((self.evaluations / self.budget) * (self.max_population_size - self.initial_population_size)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += len(population)\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            self.dim = active_layers\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "By introducing a dynamic adjustment of population size and enhanced robustness check, the Enhanced Adaptive Hybrid Evolutionary Search (EAHES) is refined to improve performance in complex, noisy optimization landscapes.", "configspace": "", "generation": 2, "fitness": 0.832167613674918, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.832 with standard deviation 0.047. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "b94ac15d-3f87-499f-abeb-f31aff662c1b", "metadata": {"aucs": [0.8876855414728066, 0.8366032611455023, 0.7722140384064448], "final_y": [0.1142040683032911, 0.13151872960626632, 0.13334223699459358]}, "mutation_prompt": null}
{"id": "5817a5c1-a7ca-44a3-8735-01c8ef8f5807", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover rate\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        self.f = 0.5 + np.random.rand() * 0.5\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation = np.random.normal(0, 0.01, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.robustness_check(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            # Dynamically adjust population size based on progress\n            self.population_size = max(10, int(20 * (1 - self.evaluations / self.budget)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            self.dim = active_layers\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "The Enhanced Adaptive Hybrid Evolutionary Search (EAHES) is refined by introducing a strategy to dynamically adjust the population size based on convergence progress, enhancing exploration and exploitation balance.", "configspace": "", "generation": 2, "fitness": 0.8743535880844124, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.874 with standard deviation 0.018. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "b94ac15d-3f87-499f-abeb-f31aff662c1b", "metadata": {"aucs": [0.8505853759398311, 0.880005617540597, 0.8924697707728091], "final_y": [0.11475806337437267, 0.12277187653683885, 0.12451990802463064]}, "mutation_prompt": null}
{"id": "a25ea196-1d41-419d-a6bd-625d02b28245", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover rate\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        self.f = 0.5 + np.random.rand() * 0.5\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def adapt_population_size(self):\n        if self.evaluations > 0.5 * self.budget:\n            self.population_size = max(5, self.population_size // 2)\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation = np.random.normal(0, 0.01, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.robustness_check(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            self.adapt_population_size()\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            self.dim = active_layers\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "The algorithm Enhanced Adaptive Hybrid Evolutionary Search (EAHES) is improved by integrating adaptive population sizing based on convergence, enhancing performance in noisy high-dimensional settings.", "configspace": "", "generation": 2, "fitness": 0.8461140700599256, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.846 with standard deviation 0.007. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "b94ac15d-3f87-499f-abeb-f31aff662c1b", "metadata": {"aucs": [0.8384721485951122, 0.8445529656462986, 0.8553170959383659], "final_y": [0.11430070502165357, 0.134019311414743, 0.13046849537979444]}, "mutation_prompt": null}
{"id": "80202f91-b637-4d3e-8a10-aeabff3a1cc4", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover rate\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        self.f = 0.5 + np.random.rand() * 0.5\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation = np.random.normal(0, 0.01, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.robustness_check(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        # Initialize population\n        self.population_size = self.initial_population_size  # Adjusted\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            self.population_size = self.initial_population_size + int(self.evaluations / self.budget * 10)  # Adjusted\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            self.dim = active_layers\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Refining EnhancedAdaptiveHybridEvolutionarySearch by introducing dynamic adjustment of population size based on budget progression to balance exploration and exploitation more effectively.", "configspace": "", "generation": 2, "fitness": 0.8401715951699495, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.840 with standard deviation 0.029. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "b94ac15d-3f87-499f-abeb-f31aff662c1b", "metadata": {"aucs": [0.8729646228586941, 0.8458693162909485, 0.8016808463602063], "final_y": [0.11707410247438099, 0.11858337051857026, 0.13038703778380512]}, "mutation_prompt": null}
{"id": "6a170307-c537-4f4d-923e-baa896d3a4a8", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover rate\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        self.f = 0.5 + np.random.rand() * 0.5\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        diversity_factor = np.std(population, axis=0).mean()  # New line\n        mutant = population[a] + self.f * diversity_factor * (population[b] - population[c])  # Modified line\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation = np.random.normal(0, 0.01, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.robustness_check(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            # Dynamically adjust population size based on progress\n            self.population_size = max(10, int(20 * (1 - self.evaluations / self.budget)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            self.dim = active_layers\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "The Enhanced Adaptive Hybrid Evolutionary Search (EAHES) is refined by incorporating diversity preservation through adaptive mutation rates, enhancing exploration with minimal code changes.", "configspace": "", "generation": 3, "fitness": 0.8031543992030189, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.803 with standard deviation 0.025. And the mean value of best solutions found was 0.150 (0. is the best) with standard deviation 0.015.", "error": "", "parent_id": "5817a5c1-a7ca-44a3-8735-01c8ef8f5807", "metadata": {"aucs": [0.8149505946432772, 0.76890311738062, 0.8256094855851595], "final_y": [0.14343072426797066, 0.1702433386818767, 0.13588602921233617]}, "mutation_prompt": null}
{"id": "a22b7c2e-36b9-4e78-a2fa-1fdf4caadc7a", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover rate\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        progress_ratio = self.evaluations / self.budget\n        self.f = 0.5 + np.random.rand() * 0.5 * (1 - progress_ratio)  # Dynamic mutation factor scaling\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation = np.random.normal(0, 0.01, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.robustness_check(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            # Dynamically adjust population size based on progress\n            self.population_size = max(10, int(20 * (1 - self.evaluations / self.budget)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            self.dim = active_layers\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Enhanced Adaptive Hybrid Evolutionary Search (EAHES) with improved robustness via dynamic mutation factor scaling to better balance exploration and exploitation.", "configspace": "", "generation": 3, "fitness": 0.8044970115994503, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.804 with standard deviation 0.031. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "5817a5c1-a7ca-44a3-8735-01c8ef8f5807", "metadata": {"aucs": [0.8052483728153517, 0.8418321235022029, 0.7664105384807964], "final_y": [0.13417951451790444, 0.13366129285675454, 0.1256796343300105]}, "mutation_prompt": null}
{"id": "f44a4c10-bf5a-466a-b78b-06f4219bcf29", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover rate\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        self.f = 0.5 + np.random.rand() * 0.5\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb + 0.005, self.ub - 0.005)  # Change 1\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B', options={'maxiter': 10})  # Change 2\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation = np.random.normal(0, 0.01, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.robustness_check(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            # Dynamically adjust population size based on progress\n            self.population_size = max(10, int(20 * (1 - self.evaluations / self.budget)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            self.dim = active_layers\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Improved robustness and exploitation balance by refining local search parameters and incorporating noise resilience.", "configspace": "", "generation": 3, "fitness": 0.8084848632857268, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.808 with standard deviation 0.025. And the mean value of best solutions found was 0.142 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "5817a5c1-a7ca-44a3-8735-01c8ef8f5807", "metadata": {"aucs": [0.8405260971024471, 0.8045445499745674, 0.7803839427801655], "final_y": [0.1234185150470507, 0.1530680768124112, 0.1504831674625451]}, "mutation_prompt": null}
{"id": "11a682d1-0695-45c0-8c22-11e1afba85c8", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover rate\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        self.f = 0.5 + np.random.rand() * 0.5\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        scale_factor = 1 - (self.evaluations / self.budget)  # New dynamic scaling\n        mutant = population[a] + scale_factor * self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation = np.random.normal(0, 0.01, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.robustness_check(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            # Dynamically adjust population size based on progress\n            self.population_size = max(10, int(20 * (1 - self.evaluations / self.budget)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            self.dim = active_layers\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Improved global exploration by adapting mutation strategy using a dynamic scaling mechanism.", "configspace": "", "generation": 3, "fitness": 0.792648329150455, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.793 with standard deviation 0.033. And the mean value of best solutions found was 0.139 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "5817a5c1-a7ca-44a3-8735-01c8ef8f5807", "metadata": {"aucs": [0.7644097603888269, 0.8384042976236037, 0.7751309294389344], "final_y": [0.13487421349019602, 0.13785995420328234, 0.14559209089773417]}, "mutation_prompt": null}
{"id": "f3904ed5-97bc-4fe7-844b-a75c956eddba", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover rate\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        self.f = 0.5 + np.random.rand() * 0.5 * (1 - self.evaluations / self.budget)\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation = np.random.normal(0, 0.01, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.robustness_check(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            # Dynamically adjust population size based on progress\n            self.population_size = max(10, int(20 * (1 - self.evaluations / self.budget)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            self.dim = active_layers\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Enhanced Adaptation Strategy: Integrate a convergence-based scaling mechanism to fine-tune mutation factor dynamically, improving exploration-exploitation balance.", "configspace": "", "generation": 3, "fitness": 0.8701845276888379, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.870 with standard deviation 0.014. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "5817a5c1-a7ca-44a3-8735-01c8ef8f5807", "metadata": {"aucs": [0.8788822966233114, 0.8508676923904641, 0.8808035940527379], "final_y": [0.11060184094893843, 0.1280501172656724, 0.1256760464877109]}, "mutation_prompt": null}
{"id": "82a69a75-7877-4f88-9239-9706cb29cf42", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover rate\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        self.f = 0.5 + np.random.rand() * 0.5 * (1 - self.evaluations / self.budget)\n        self.cr = 0.6 + np.random.rand() * 0.4 * (self.evaluations / self.budget)  # Change made here\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation = np.random.normal(0, 0.01, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.robustness_check(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            # Dynamically adjust population size based on progress\n            self.population_size = max(10, int(20 * (1 - self.evaluations / self.budget)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            self.dim = active_layers\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Incorporate a dynamic crossover rate adjustment to improve adaptability during different optimization phases.", "configspace": "", "generation": 4, "fitness": 0.8509941233666458, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.851 with standard deviation 0.048. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "f3904ed5-97bc-4fe7-844b-a75c956eddba", "metadata": {"aucs": [0.8011238777273957, 0.8353288348452419, 0.9165296575272998], "final_y": [0.12083882672216584, 0.12331454136420916, 0.11280865543536012]}, "mutation_prompt": null}
{"id": "51d20724-61af-498a-b7da-e208d0fb66b2", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover rate\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        self.f = 0.5 + np.random.rand() * 0.5 * (1 - self.evaluations / self.budget)\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='Nelder-Mead')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation = np.random.normal(0, 0.01, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.robustness_check(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            # Dynamically adjust population size based on progress\n            self.population_size = max(10, int(20 * (1 - self.evaluations / self.budget)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            self.dim = active_layers\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Enhance local search efficiency by replacing L-BFGS-B with Nelder-Mead, improving convergence speed under the 4.1% change constraint.", "configspace": "", "generation": 4, "fitness": 0.8246111343211849, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.825 with standard deviation 0.068. And the mean value of best solutions found was 0.143 (0. is the best) with standard deviation 0.027.", "error": "", "parent_id": "f3904ed5-97bc-4fe7-844b-a75c956eddba", "metadata": {"aucs": [0.7345700470705696, 0.8399695575731124, 0.8992937983198728], "final_y": [0.18149840732235178, 0.12467781591393079, 0.12282452903935448]}, "mutation_prompt": null}
{"id": "c68e2bec-56c2-4e89-a657-ef81c1ee0442", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover rate\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        self.f = 0.5 + np.random.rand() * 0.5 * (1 - self.evaluations / self.budget)\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        # Weighted recombination here\n        trial = np.where(cross_points, 0.5 * (mutant + target), target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation = np.random.normal(0, 0.01, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.robustness_check(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            # Dynamically adjust population size based on progress\n            self.population_size = max(10, int(20 * (1 - self.evaluations / self.budget)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            self.dim = active_layers\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Introduce a weighted recombination strategy during crossover to better exploit beneficial traits from multiple individuals.", "configspace": "", "generation": 4, "fitness": 0.8049996479836037, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.805 with standard deviation 0.029. And the mean value of best solutions found was 0.135 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "f3904ed5-97bc-4fe7-844b-a75c956eddba", "metadata": {"aucs": [0.8443234776368083, 0.7960222275040074, 0.7746532388099954], "final_y": [0.13039769259922662, 0.15458334166248278, 0.12080857274756529]}, "mutation_prompt": null}
{"id": "199f24b6-c966-4753-8acb-10e998cb9b77", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover rate\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        self.f = 0.5 + np.random.rand() * 0.5 * (1 - self.evaluations / self.budget)\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation = np.random.normal(0, 0.01, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.robustness_check(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            # Dynamically adjust population size based on progress\n            self.population_size = max(10, int(20 * (1 - self.evaluations / self.budget)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 10 == 0: self.f *= 0.95  # Adaptive learning rate\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Improved parameter adaptation with adaptive learning rates, enhancing convergence speed and solution quality.", "configspace": "", "generation": 4, "fitness": 0.8807797673544934, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.881 with standard deviation 0.017. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "f3904ed5-97bc-4fe7-844b-a75c956eddba", "metadata": {"aucs": [0.8603036902808494, 0.9007691746069983, 0.8812664371756324], "final_y": [0.11475806337437267, 0.11767020641627302, 0.12665594046798323]}, "mutation_prompt": null}
{"id": "1ecf1fab-4815-4bcb-8fa5-96d322d6121e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover rate\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        self.f = 0.5 + np.random.rand() * 0.5 * (1 - self.evaluations / self.budget)\n        self.cr = 0.8 + np.random.rand() * 0.2 * (1 - self.evaluations / self.budget)  # Adjusted line\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation = np.random.normal(0, 0.01, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.robustness_check(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            # Dynamically adjust population size based on progress\n            self.population_size = max(10, int(20 * (1 - self.evaluations / self.budget)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            self.dim = active_layers\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Introduce adaptive crossover rate scaling based on current evaluations to enhance exploitation capabilities.", "configspace": "", "generation": 4, "fitness": 0.8636848250844045, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.864 with standard deviation 0.018. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "f3904ed5-97bc-4fe7-844b-a75c956eddba", "metadata": {"aucs": [0.8608005890306105, 0.8873543163581272, 0.8428995698644756], "final_y": [0.1142040683032911, 0.11433368565752478, 0.12978732119168634]}, "mutation_prompt": null}
{"id": "8cc77d60-09a9-40c8-a055-cb045c7d46d9", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover rate\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        self.f = 0.5 + np.random.rand() * 0.5 * (1 - self.evaluations / self.budget)\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.01 * (1 - self.evaluations / self.budget)  # Adaptive perturbation scaling\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.robustness_check(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            # Dynamically adjust population size based on progress\n            self.population_size = max(10, int(20 * (1 - self.evaluations / self.budget)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 10 == 0: self.f *= 0.95  # Adaptive learning rate\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Introduced adaptive perturbation scaling in robustness check to enhance solution resilience with minimal code change.", "configspace": "", "generation": 5, "fitness": 0.8233661816842824, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.823 with standard deviation 0.018. And the mean value of best solutions found was 0.136 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "199f24b6-c966-4753-8acb-10e998cb9b77", "metadata": {"aucs": [0.8483560908862489, 0.8051549764942568, 0.8165874776723419], "final_y": [0.12586574566025077, 0.1451930712089834, 0.13823458377194198]}, "mutation_prompt": null}
{"id": "c26afb17-362d-49c1-862d-dd8668f9fc7a", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover rate\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        self.f = 0.5 + np.random.rand() * 0.5 * (1 - self.evaluations / self.budget)\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        active_layers = min(self.dim, max(1, int((self.evaluations / self.budget) * self.dim)))  # Incremental layer increase\n        res = minimize(self.func, x[:active_layers], bounds=self.bounds[:active_layers], method='L-BFGS-B')\n        return np.concatenate((res.x, x[active_layers:])) if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation = np.random.normal(0, 0.01, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.robustness_check(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            # Dynamically adjust population size based on progress\n            self.population_size = max(10, int(20 * (1 - self.evaluations / self.budget)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 10 == 0: self.f *= 0.95  # Adaptive learning rate\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Incorporate gradual layer increase in local search for better scalability with problem complexity.", "configspace": "", "generation": 5, "fitness": 0.8000792069983304, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.800 with standard deviation 0.009. And the mean value of best solutions found was 0.142 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "199f24b6-c966-4753-8acb-10e998cb9b77", "metadata": {"aucs": [0.8012034729075241, 0.8101844542394631, 0.7888496938480041], "final_y": [0.1379479248269333, 0.14123346492151767, 0.14632684709984334]}, "mutation_prompt": null}
{"id": "51b936af-0c96-4f81-a4d6-9e631bc3f44f", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover rate\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        self.f = 0.5 + np.random.rand() * 0.5 * (1 - self.evaluations / self.budget)\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation = np.random.normal(0, 0.01, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def diversity_selection(self, population, new_population):\n        combined = np.vstack((population, new_population))\n        unique_solutions = np.unique(combined, axis=0)\n        if len(unique_solutions) < self.population_size:\n            return unique_solutions\n        return unique_solutions[np.random.choice(len(unique_solutions), self.population_size, replace=False)]\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.robustness_check(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return self.diversity_selection(population, new_population)\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            self.population_size = max(10, int(20 * (1 - self.evaluations / self.budget)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 10 == 0: self.f *= 0.95 \n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Enhanced exploration by dynamic mutation and diversity-based selection in hybrid evolutionary search.", "configspace": "", "generation": 5, "fitness": 0.7953672019036165, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.795 with standard deviation 0.029. And the mean value of best solutions found was 0.147 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "199f24b6-c966-4753-8acb-10e998cb9b77", "metadata": {"aucs": [0.8290194274885812, 0.7986960341542981, 0.7583861440679701], "final_y": [0.1298011325335786, 0.14981593574400043, 0.16135667753261895]}, "mutation_prompt": null}
{"id": "2ab4e313-ea93-481a-bd3f-cd29d39e9d8f", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover rate\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        self.f = 0.5 + np.random.rand() * 0.5 * (1 - self.evaluations / self.budget)\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation = np.random.normal(0, 0.01, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.robustness_check(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            # Dynamically adjust population size based on progress\n            self.population_size = max(10, int(20 * (1 - self.evaluations / (2 * self.budget))))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 10 == 0: self.f *= 0.95  # Adaptive learning rate\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Introduced a decay in population size linked to evaluations to balance exploration and exploitation.", "configspace": "", "generation": 5, "fitness": 0.7996214559202999, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.800 with standard deviation 0.013. And the mean value of best solutions found was 0.140 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "199f24b6-c966-4753-8acb-10e998cb9b77", "metadata": {"aucs": [0.8173854971797843, 0.7962364189176361, 0.7852424516634793], "final_y": [0.13317546477694941, 0.135609957757735, 0.15213921605878733]}, "mutation_prompt": null}
{"id": "7d00c8a1-cb4d-44cc-98dd-235b6bc795fd", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover rate\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        self.f = 0.5 + np.random.rand() * 0.5 * (1 - self.evaluations / self.budget)\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        for _ in range(5):  # Increase robustness check samples\n            perturbation = np.random.normal(0, 0.01, size=solution.shape)\n            solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return solution\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.robustness_check(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            # Dynamically adjust population size based on progress\n            self.population_size = max(10, int(20 * (1 - self.evaluations / self.budget)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 10 == 0: self.f *= 0.95  # Adaptive learning rate\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Enhanced Adaptive Hybrid Evolutionary Search with enhanced robustness by incorporating more systematic perturbation analysis.", "configspace": "", "generation": 5, "fitness": 0.7965925716469663, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.797 with standard deviation 0.005. And the mean value of best solutions found was 0.137 (0. is the best) with standard deviation 0.015.", "error": "", "parent_id": "199f24b6-c966-4753-8acb-10e998cb9b77", "metadata": {"aucs": [0.7902795942076783, 0.8008686834827103, 0.79862943725051], "final_y": [0.11603346493435918, 0.1462584267634559, 0.14766061896837213]}, "mutation_prompt": null}
{"id": "9befa46d-7b89-42eb-a8a9-e0ceeddb35ec", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover rate\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        self.f = 0.5 + np.random.rand() * 0.5 * (1 - self.evaluations / self.budget)\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.01 * (1 - self.evaluations / self.budget)  # Adaptive perturbation scaling\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.robustness_check(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            # Dynamically adjust population size based on progress\n            self.population_size = max(10, int(20 * (1 - self.evaluations / self.budget)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            stochastic_layers = np.random.choice([0, 1], size=self.dim, p=[0.2, 0.8])\n            best_solution *= stochastic_layers  # Introduce stochastic layer activation\n            if self.evaluations % 10 == 0: self.f *= 0.95  # Adaptive learning rate\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Introduced stochastic layer activation to enhance exploration and modularity detection within solutions.", "configspace": "", "generation": 6, "fitness": 0.8330574233500245, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.833 with standard deviation 0.048. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "8cc77d60-09a9-40c8-a055-cb045c7d46d9", "metadata": {"aucs": [0.8903549704981267, 0.8366032611455023, 0.7722140384064448], "final_y": [0.11209322476763972, 0.13151872960626632, 0.13334223699459358]}, "mutation_prompt": null}
{"id": "19d2d3da-cf66-4837-ac2b-35a19573d37e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover rate\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        self.f = 0.5 + np.random.rand() * 0.5 * (1 - self.evaluations / self.budget)\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.015 * (1 - self.evaluations / self.budget)  # Enhanced perturbation scaling\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.robustness_check(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            # Dynamically adjust population size based on progress\n            self.population_size = max(10, int(20 * (1 - self.evaluations / self.budget)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 10 == 0: self.f *= 0.95  # Adaptive learning rate\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Enhance adaptability by modifying the perturbation scale calculation in robustness check for improved resilience.", "configspace": "", "generation": 6, "fitness": 0.8515412978934275, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.852 with standard deviation 0.034. And the mean value of best solutions found was 0.129 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "8cc77d60-09a9-40c8-a055-cb045c7d46d9", "metadata": {"aucs": [0.8101375983574666, 0.8520165245500069, 0.8924697707728091], "final_y": [0.13802994677410918, 0.12331443616800919, 0.12451990802463064]}, "mutation_prompt": null}
{"id": "59e84f2c-72c1-4f18-87ce-ad001ac36047", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover rate\n        self.evaluations = 0\n\n    def adapt_parameters(self, improvement):\n        self.f = 0.5 + np.random.rand() * 0.5 * (1 - improvement)\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.01 * (1 - self.evaluations / self.budget)  # Adaptive perturbation scaling\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            improvement = (self.func(population[i]) - self.func(population[np.argmin([self.func(ind) for ind in population])])) / self.func(population[i])\n            self.adapt_parameters(improvement)\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.robustness_check(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            # Dynamically adjust population size based on progress\n            self.population_size = max(10, int(20 * (1 - self.evaluations / self.budget)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 10 == 0: self.f *= 0.95  # Adaptive learning rate\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Improved convergence by dynamically adjusting mutation factor based on the best solution's improvement.", "configspace": "", "generation": 6, "fitness": 0.844335430784656, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.844 with standard deviation 0.031. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "8cc77d60-09a9-40c8-a055-cb045c7d46d9", "metadata": {"aucs": [0.8062113686528961, 0.8458693951522044, 0.8809255285488674], "final_y": [0.12949177777860255, 0.118583276488337, 0.12664813469585268]}, "mutation_prompt": null}
{"id": "5cc00340-8dc9-4566-a268-ad0e9b5ef9e5", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover rate\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        self.f = 0.5 + np.random.rand() * 0.5 * (1 - self.evaluations / self.budget)\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.01 * np.exp(-5 * self.evaluations / self.budget)  # Adaptive perturbation scaling\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.robustness_check(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            # Dynamically adjust population size based on progress\n            self.population_size = max(10, int(20 * (1 - self.evaluations / self.budget)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 10 == 0: self.f *= 0.95  # Adaptive learning rate\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Introduced adaptive perturbation scaling in robustness check to enhance solution resilience by varying perturbation scale exponentially.", "configspace": "", "generation": 6, "fitness": 0.8222493360677613, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.822 with standard deviation 0.045. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "8cc77d60-09a9-40c8-a055-cb045c7d46d9", "metadata": {"aucs": [0.7699045780032627, 0.880005617540597, 0.816837812659424], "final_y": [0.14369495040793923, 0.12277187653683885, 0.11014614773243359]}, "mutation_prompt": null}
{"id": "11b382af-5e0a-4444-8ba7-93fc95335e74", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover rate\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        temperature = 1 - self.evaluations / self.budget\n        self.f = (0.5 + np.random.rand() * 0.5) * temperature\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.01 * (1 - self.evaluations / self.budget)  # Adaptive perturbation scaling\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.robustness_check(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            # Dynamically adjust population size based on progress\n            self.population_size = max(10, int(20 * (1 - self.evaluations / self.budget)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 10 == 0: self.f *= 0.95  # Adaptive learning rate\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Introduced temperature-based adaptive factor for mutation to enhance exploration-exploitation balance.", "configspace": "", "generation": 6, "fitness": 0.8461103410877642, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.846 with standard deviation 0.007. And the mean value of best solutions found was 0.130 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "8cc77d60-09a9-40c8-a055-cb045c7d46d9", "metadata": {"aucs": [0.8384611514800487, 0.8445527758448779, 0.8553170959383659], "final_y": [0.12576193519714263, 0.13401941001913065, 0.13046849537979444]}, "mutation_prompt": null}
{"id": "1d57dd9b-62d1-4df8-8749-b886b2df442a", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover rate\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        self.f = 0.5 + np.random.rand() * 0.5 * (1 - self.evaluations / self.budget)\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.015 * (1 - self.evaluations / self.budget)\n        perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, size=solution.shape)  # Changed distribution\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.robustness_check(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            # Dynamically adjust population size based on progress\n            self.population_size = max(10, int(20 * (1 - self.evaluations / self.budget)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 10 == 0: self.f *= 0.95  # Adaptive learning rate\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Refine robustness by modifying perturbation distribution to enhance solution stability.", "configspace": "", "generation": 7, "fitness": 0.8266491079201482, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.827 with standard deviation 0.039. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "19d2d3da-cf66-4837-ac2b-35a19573d37e", "metadata": {"aucs": [0.8557166277339356, 0.8520166576200644, 0.7722140384064448], "final_y": [0.11596793592992993, 0.12331440184543974, 0.13334223699459358]}, "mutation_prompt": null}
{"id": "c98bdf33-15b7-40d9-adeb-8fb6ca44c865", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover rate\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        self.f = 0.5 + np.random.rand() * 0.5 * (1 - self.evaluations / self.budget)\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.015 * (1 - self.evaluations / self.budget)  # Enhanced perturbation scaling\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.robustness_check(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            self.f *= (1 + 0.1 * (self.budget - self.evaluations) / self.budget)  # Line modified for diversity\n            self.population_size = max(10, int(20 * (1 - self.evaluations / self.budget)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 10 == 0: self.f *= 0.95  # Adaptive learning rate\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Improve robustness by scaling the mutation factor with evaluations for better diversity throughout the optimization process.", "configspace": "", "generation": 7, "fitness": 0.8662809879774139, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.866 with standard deviation 0.024. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "19d2d3da-cf66-4837-ac2b-35a19573d37e", "metadata": {"aucs": [0.898973042350212, 0.8445528256436641, 0.8553170959383659], "final_y": [0.1106017941243812, 0.13401938414798398, 0.13046849537979444]}, "mutation_prompt": null}
{"id": "61bb8fa9-b748-47dd-8ad3-6d46427fdd21", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover rate\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        self.f = 0.5 + np.random.rand() * 0.5 * (1 - self.evaluations / self.budget)\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.02 * (1 - self.evaluations / self.budget)  # Enhanced perturbation scaling\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.robustness_check(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            # Dynamically adjust population size based on progress\n            self.population_size = max(10, int(20 * (1 - self.evaluations / self.budget)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 10 == 0: self.f *= 0.95  # Adaptive learning rate\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Fine-tune hybrid search with adaptive learning and population dynamics for enhanced robustness.", "configspace": "", "generation": 7, "fitness": 0.8891887553500927, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.889 with standard deviation 0.007. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "19d2d3da-cf66-4837-ac2b-35a19573d37e", "metadata": {"aucs": [0.895090877736872, 0.880005617540597, 0.8924697707728091], "final_y": [0.11220485105705558, 0.12277187653683885, 0.12451990802463064]}, "mutation_prompt": null}
{"id": "b6f56950-387b-4350-89a9-f88837229fa7", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover rate\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        self.f = 0.5 + np.random.rand() * 0.5 * (1 - self.evaluations / self.budget)\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n        return res.x if res.success else x\n\n    def robustness_check(self, solution):\n        perturbation_scale = 0.015 * (1 - self.evaluations / self.budget)  # Enhanced perturbation scaling\n        perturbation = np.random.normal(0, perturbation_scale, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.robustness_check(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            # Dynamically adjust population size based on progress\n            self.population_size = max(10, int(20 * ((self.budget - self.evaluations) / self.budget)**0.5))  # Adjusted dynamic population size\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 10 == 0: self.f *= 0.95  # Adaptive learning rate\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Refine adaptability by adjusting dynamic population size more responsively to evaluation progress for improved convergence.", "configspace": "", "generation": 7, "fitness": 0.8578612489489673, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.858 with standard deviation 0.016. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "19d2d3da-cf66-4837-ac2b-35a19573d37e", "metadata": {"aucs": [0.8467888071225994, 0.8458694111754351, 0.8809255285488674], "final_y": [0.1358074243302838, 0.1185832573830422, 0.12664813469585268]}, "mutation_prompt": null}
{"id": "e0af09ee-3e4d-4a0a-9d2a-94d01395f946", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedAdaptiveHybridEvolutionarySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.9  # DE crossover rate\n        self.evaluations = 0\n\n    def adapt_parameters(self):\n        self.f = 0.5 + np.random.rand() * 0.5 * (1 - self.evaluations / self.budget)\n        self.cr = 0.8 + np.random.rand() * 0.2\n\n    def mutate(self, population, target_idx):\n        indices = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.f * (population[b] - population[c])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, x):\n        if np.random.rand() < 0.5:  # Strategic local search application\n            res = minimize(self.func, x, bounds=self.bounds, method='L-BFGS-B')\n            return res.x if res.success else x\n        else:\n            return x\n\n    def robustness_check(self, solution):\n        noise_level = 0.01 + 0.02 * np.sin(2 * np.pi * self.evaluations / self.budget)  # Adaptive noise handling\n        perturbation = np.random.normal(0, noise_level, size=solution.shape)\n        robust_solution = np.clip(solution + perturbation, self.lb, self.ub)\n        return robust_solution\n\n    def evolutionary_search_step(self, population):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            self.adapt_parameters()\n            mutant = self.mutate(population, i)\n            trial = self.crossover(population[i], mutant)\n            trial = self.local_search(trial)\n            trial = self.robustness_check(trial)\n            if self.func(trial) < self.func(population[i]):\n                new_population[i] = trial\n        return new_population\n\n    def __call__(self, func):\n        self.func = func\n        self.bounds = [(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)]\n        self.lb = func.bounds.lb\n        self.ub = func.bounds.ub\n\n        # Initialize population\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        best_solution = population[np.argmin([self.func(ind) for ind in population])]\n\n        while self.evaluations < self.budget:\n            self.population_size = max(10, int(20 * (1 - self.evaluations / self.budget)))\n            population = self.evolutionary_search_step(population)\n            best_candidate = population[np.argmin([self.func(ind) for ind in population])]\n            if self.func(best_candidate) < self.func(best_solution):\n                best_solution = best_candidate\n\n            self.evaluations += self.population_size\n            active_layers = min(self.dim, int((self.evaluations / self.budget) * self.dim)) + 1\n            if self.evaluations % 10 == 0: self.f *= 0.95\n\n        return best_solution", "name": "EnhancedAdaptiveHybridEvolutionarySearch", "description": "Introduce adaptive noise handling and strategic local search to enhance robustness and solution quality.", "configspace": "", "generation": 7, "fitness": 0.7983581548217159, "feedback": "The algorithm EnhancedAdaptiveHybridEvolutionarySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.798 with standard deviation 0.033. And the mean value of best solutions found was 0.142 (0. is the best) with standard deviation 0.016.", "error": "", "parent_id": "19d2d3da-cf66-4837-ac2b-35a19573d37e", "metadata": {"aucs": [0.7567903214219662, 0.8366032611455023, 0.8016808818976792], "final_y": [0.1639349975011779, 0.13151872960626632, 0.13038699078241234]}, "mutation_prompt": null}
