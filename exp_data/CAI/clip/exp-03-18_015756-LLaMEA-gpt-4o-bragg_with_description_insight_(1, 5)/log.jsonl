{"id": "821b83bb-e814-4e38-bc38-848ede9e4d3a", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        # Initialize population with quasi-oppositional solutions\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        # Local search using BFGS to fine-tune solutions\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            new_pop = np.zeros_like(pop)\n            for i in range(len(pop)):\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant = np.clip(x_1 + self.f * (x_2 - x_3), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Evaluate and select\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            # Periodic encouragement via local search\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "A hybrid metaheuristic algorithm combining Quasi-Oppositional Differential Evolution (QODE) with Local Search to exploit periodicity and optimize multilayered photonic structures.", "configspace": "", "generation": 0, "fitness": 0.9656425512823072, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.966 with standard deviation 0.005. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": null, "metadata": {"aucs": [0.9694817839602157, 0.9688223766701322, 0.9586234932165741], "final_y": [0.16485629840118055, 0.16485652506917325, 0.1648567372430758]}, "mutation_prompt": null}
{"id": "fb30dd76-101f-4844-9860-e9bb24986e3f", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        # Initialize population with quasi-oppositional solutions\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        # Local search using BFGS to fine-tune solutions\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            new_pop = np.zeros_like(pop)\n            for i in range(len(pop)):\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant = np.clip(x_1 + np.random.uniform(0.7, 0.9) * (x_2 - x_3), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Evaluate and select\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            # Periodic encouragement via local search\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "An enhanced hybrid algorithm tweaking local search and mutation dynamics to boost optimization on multilayered photonic structures.", "configspace": "", "generation": 1, "fitness": 0.9631586136039215, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.963 with standard deviation 0.004. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "821b83bb-e814-4e38-bc38-848ede9e4d3a", "metadata": {"aucs": [0.9620299709250586, 0.9688223766701322, 0.9586234932165741], "final_y": [0.16491533610984555, 0.16485652506917325, 0.1648567372430758]}, "mutation_prompt": null}
{"id": "179b989e-943f-4038-9522-bf2d6815fc36", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        # Initialize population with quasi-oppositional solutions\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        # Local search using BFGS to fine-tune solutions\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            new_pop = np.zeros_like(pop)\n            for i in range(len(pop)):\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f * (1 - evals / self.budget)  # Dynamic mutation factor\n                mutant = np.clip(x_1 + f_dynamic * (x_2 - x_3), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Evaluate and select\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            # Periodic encouragement via local search\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Enhanced HybridQODE by adjusting mutation scaling factor based on iteration to improve convergence in optimizing multilayered photonic structures.", "configspace": "", "generation": 1, "fitness": 0.9656484785126404, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.966 with standard deviation 0.005. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "821b83bb-e814-4e38-bc38-848ede9e4d3a", "metadata": {"aucs": [0.9694995656512146, 0.9688223766701322, 0.9586234932165741], "final_y": [0.16485629840118055, 0.16485652506917325, 0.1648567372430758]}, "mutation_prompt": null}
{"id": "0f81d6c3-0502-4035-a13d-3154153fc1c6", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        # Initialize population with quasi-oppositional solutions\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        # Local search using BFGS to fine-tune solutions\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            new_pop = np.zeros_like(pop)\n            for i in range(len(pop)):\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                self.f = 0.5 + np.random.rand() * 0.5  # Enhanced differential weight strategy\n                mutant = np.clip(x_1 + self.f * (x_2 - x_3), self.lb, self.ub)\n                self.cr = 0.5 + 0.5 * np.abs(np.sin(evals))  # Dynamic crossover rate\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Evaluate and select\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            # Periodic encouragement via local search\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Enhanced HybridQODE by adjusting crossover rate dynamically and refining differential weight strategy to better explore and exploit the search space.", "configspace": "", "generation": 1, "fitness": 0.9611496901537447, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.961 with standard deviation 0.006. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "821b83bb-e814-4e38-bc38-848ede9e4d3a", "metadata": {"aucs": [0.9560032005745281, 0.9688223766701322, 0.9586234932165741], "final_y": [0.16485629840118055, 0.16485652506917325, 0.1648567372430758]}, "mutation_prompt": null}
{"id": "8e125bca-84db-4853-8392-7d06462fa537", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        # Initialize population with quasi-oppositional solutions\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        # Local search using BFGS to fine-tune solutions\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            new_pop = np.zeros_like(pop)\n            self.cr = 0.9 - 0.7 * evals / self.budget  # Adaptive crossover rate\n            for i in range(len(pop)):\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant = np.clip(x_1 + self.f * (x_2 - x_3), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Evaluate and select\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            # Periodic encouragement via local search\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Enhanced HybridQODE with adaptive crossover rate to improve convergence in Bragg mirror optimization.", "configspace": "", "generation": 1, "fitness": 0.9656425512823072, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.966 with standard deviation 0.005. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "821b83bb-e814-4e38-bc38-848ede9e4d3a", "metadata": {"aucs": [0.9694817839602157, 0.9688223766701322, 0.9586234932165741], "final_y": [0.16485629840118055, 0.16485652506917325, 0.1648567372430758]}, "mutation_prompt": null}
{"id": "fadcb7db-a568-4612-9ce9-7f679fa7272d", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def adaptive_mutation(self, current_fitness, best_fitness):\n        return 0.5 + 0.3 * np.exp(-(best_fitness - current_fitness))\n\n    def enhanced_local_search(self, solution, func):\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='SLSQP')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            new_pop = np.zeros_like(pop)\n            for i in range(len(pop)):\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                current_fitness = func(pop[i])\n                self.f = self.adaptive_mutation(current_fitness, best_fitness)\n                mutant = np.clip(x_1 + self.f * (x_2 - x_3), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.enhanced_local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Enhanced HybridQODE algorithm with adaptive mutation factor and enhanced local search to improve convergence and solution quality.", "configspace": "", "generation": 1, "fitness": 0.9305341582175187, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.931 with standard deviation 0.047. And the mean value of best solutions found was 0.167 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "821b83bb-e814-4e38-bc38-848ede9e4d3a", "metadata": {"aucs": [0.8641566047658499, 0.9688223766701322, 0.9586234932165741], "final_y": [0.17205737646900532, 0.16485652506917325, 0.1648567372430758]}, "mutation_prompt": null}
{"id": "32913a1e-e1c0-45a4-b364-a215b6a7fad2", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        # Initialize population with quasi-oppositional solutions\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        # Local search using BFGS to fine-tune solutions\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            new_pop = np.zeros_like(pop)\n            for i in range(len(pop)):\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f * (1 - evals / self.budget)  # Dynamic mutation factor\n                mutant = np.clip(x_1 + f_dynamic * (x_2 - x_3), self.lb, self.ub)\n                cr_dynamic = self.cr * (1 - evals / self.budget)  # Changed line: Adaptive crossover probability\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Evaluate and select\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            # Periodic encouragement via local search\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Optimized HybridQODE by introducing adaptive crossover probability for enhanced diversity in solution search.", "configspace": "", "generation": 2, "fitness": 0.9666007073439857, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.967 with standard deviation 0.002. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "179b989e-943f-4038-9522-bf2d6815fc36", "metadata": {"aucs": [0.9694995656512146, 0.9665521766333838, 0.9637503797473588], "final_y": [0.16485629840118055, 0.16486110310223723, 0.16485603836432328]}, "mutation_prompt": null}
{"id": "64d7b24c-3c97-4d75-a0f9-41eb826c873a", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        # Initialize population with quasi-oppositional solutions\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        # Local search using BFGS to fine-tune solutions\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            new_pop = np.zeros_like(pop)\n            for i in range(len(pop)):\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f * (1 - evals / self.budget)  # Dynamic mutation factor\n                mutant = np.clip(x_1 + f_dynamic * (x_2 - x_3), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Evaluate and select\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            # Periodic encouragement via local search\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    pop[i] = np.tile(pop[i][:self.dim//2], 2)  # Enforce periodic boundary conditions\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Refined HybridQODE by integrating periodic boundary conditions to enforce periodicity and improve solution quality.", "configspace": "", "generation": 2, "fitness": 0.94919846324783, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.949 with standard deviation 0.011. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "179b989e-943f-4038-9522-bf2d6815fc36", "metadata": {"aucs": [0.9366744762205877, 0.9471705337755432, 0.9637503797473588], "final_y": [0.16485600417433388, 0.16485652506917325, 0.16485603836432328]}, "mutation_prompt": null}
{"id": "b1dd5bde-6843-42ab-99b9-752dc2db38cb", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        # Initialize population with quasi-oppositional solutions\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        # Local search using BFGS to fine-tune solutions\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def chaos_based_adaptation(self, iter_num):\n        return 0.7 * (0.5 * (1 + np.cos(2 * np.pi * iter_num / self.budget)))\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            new_pop = np.zeros_like(pop)\n            for i in range(len(pop)):\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.chaos_based_adaptation(evals)  # Use chaos-based adaptation\n                mutant = np.clip(x_1 + f_dynamic * (x_2 - x_3), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Evaluate and select\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            # Periodic encouragement via local search\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Improved HybridQODE by introducing chaos-based parameter adaptation and periodicity-promoting mutation to enhance solution quality in multilayer photonic structure optimization.", "configspace": "", "generation": 2, "fitness": 0.9601168224727118, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.960 with standard deviation 0.009. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "179b989e-943f-4038-9522-bf2d6815fc36", "metadata": {"aucs": [0.969429553895233, 0.9471705337755432, 0.9637503797473588], "final_y": [0.1648559542086958, 0.16485652506917325, 0.16485603836432328]}, "mutation_prompt": null}
{"id": "b7fa9b8b-7e47-4235-bd50-e0d24fa16a0e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        # Initialize population with quasi-oppositional solutions\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        # Local search using BFGS to fine-tune solutions\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            new_pop = np.zeros_like(pop)\n            for i in range(len(pop)):\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f * (1 - evals / self.budget)  # Dynamic mutation factor\n                mutant = np.clip(x_1 + f_dynamic * (x_2 - x_3), self.lb, self.ub)\n                adaptive_cr = self.cr * (0.5 + 0.5 * np.random.rand())  # Adaptive crossover\n                cross_points = np.random.rand(self.dim) < adaptive_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Evaluate and select\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            # Periodic encouragement via local search\n            for i in range(len(pop)):\n                if evals < self.budget and np.random.rand() < 0.5:  # Stochastic local search trigger\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Enhanced HybridQODE by introducing adaptive crossover probability and employing a stochastic local search trigger to further refine solution exploration.", "configspace": "", "generation": 2, "fitness": 0.9581954915963302, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.958 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "179b989e-943f-4038-9522-bf2d6815fc36", "metadata": {"aucs": [0.9636655612660887, 0.9471705337755432, 0.9637503797473588], "final_y": [0.16485751130789705, 0.16485652506917325, 0.16485603836432328]}, "mutation_prompt": null}
{"id": "08d9c88b-c1f9-4f02-94f8-2eeb87c09107", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            new_pop = np.zeros_like(pop)\n            for i in range(len(pop)):\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f * (1 - evals / self.budget)\n                mutant = np.clip(x_1 + f_dynamic * (x_2 - x_3), self.lb, self.ub)\n                cr_dynamic = self.cr * (1 - evals / self.budget) + 0.1  # Dynamic crossover probability\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]) or trial_fitness < best_fitness:  # Elitism in selection\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Improved search space exploration by dynamically adjusting crossover probability and introducing elitism in selection.", "configspace": "", "generation": 2, "fitness": 0.9348047248340287, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.935 with standard deviation 0.030. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "179b989e-943f-4038-9522-bf2d6815fc36", "metadata": {"aucs": [0.893493260979184, 0.9471705337755432, 0.9637503797473588], "final_y": [0.1818795698434228, 0.16485652506917325, 0.16485603836432328]}, "mutation_prompt": null}
{"id": "4f36907b-2665-41e3-a53b-0436277676ea", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        # Initialize population with quasi-oppositional solutions\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        # Local search using BFGS to fine-tune solutions\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            # Adaptive population size based on remaining budget\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (2 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):  # Adjusting loop according to new pop_size\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f * (1 - evals / self.budget)  # Dynamic mutation factor\n                mutant = np.clip(x_1 + f_dynamic * (x_2 - x_3), self.lb, self.ub)\n                cr_dynamic = self.cr * (1 - evals / self.budget)  # Changed line: Adaptive crossover probability\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Evaluate and select\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            # Periodic encouragement via local search\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Introduced adaptive population size to maintain diversity and improve convergence.", "configspace": "", "generation": 3, "fitness": 0.9678131374628647, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.968 with standard deviation 0.007. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "32913a1e-e1c0-45a4-b364-a215b6a7fad2", "metadata": {"aucs": [0.975355404359952, 0.9694554151058693, 0.9586285929227727], "final_y": [0.16485629840118055, 0.16485652506917325, 0.16485603836432328]}, "mutation_prompt": null}
{"id": "7ac81d4a-9b6a-4766-8f46-d37bff1b005c", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        # Initialize population with quasi-oppositional solutions\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        # Local search using BFGS to fine-tune solutions\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def reinforce_periodicity(self, solution):\n        # Encourage periodic patterns\n        avg_layer_thickness = np.mean(solution.reshape(-1, 2), axis=0)\n        return np.tile(avg_layer_thickness, self.dim // 2)\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            new_pop = np.zeros_like(pop)\n            for i in range(len(pop)):\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f * (1 - evals / self.budget)  # Dynamic mutation factor\n                mutant = np.clip(x_1 + f_dynamic * (x_2 - x_3), self.lb, self.ub)\n                cr_dynamic = self.cr * (1 - evals / self.budget)  # Changed line: Adaptive crossover probability\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Evaluate and select\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            # Periodic encouragement via local search\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_solution = self.reinforce_periodicity(refined_solution)  # Reinforce periodic structure\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Enhanced HybridQODE with periodic reinforcement of constructive interference patterns for improved reflectivity optimization.", "configspace": "", "generation": 3, "fitness": 0.9658619298565959, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.966 with standard deviation 0.005. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "32913a1e-e1c0-45a4-b364-a215b6a7fad2", "metadata": {"aucs": [0.9695017815411457, 0.9694554151058693, 0.9586285929227727], "final_y": [0.16485594899964107, 0.16485652506917325, 0.16485603836432328]}, "mutation_prompt": null}
{"id": "ebcf8d46-3445-4ab8-833c-e0288ba35a16", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        # Initialize population with quasi-oppositional solutions\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        # Local search using BFGS to fine-tune solutions\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            new_pop = np.zeros_like(pop)\n            for i in range(len(pop)):\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f * (1 - evals / self.budget)  # Dynamic mutation factor\n                mutant = np.clip(x_1 + f_dynamic * (x_2 - x_3), self.lb, self.ub)\n                \n                # Changed line: Apply periodic layer grouping strategy\n                trial = mutant if i % 2 == 0 else pop[i]\n\n                cr_dynamic = self.cr * (1 - evals / self.budget)  # Adaptive crossover probability\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Evaluate and select\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            # Periodic encouragement via local search\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Enhanced HybridQODE by introducing periodic layer grouping to preserve modular characteristics in solutions.", "configspace": "", "generation": 3, "fitness": 0.9658611912266188, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.966 with standard deviation 0.005. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "32913a1e-e1c0-45a4-b364-a215b6a7fad2", "metadata": {"aucs": [0.9694995656512146, 0.9694554151058693, 0.9586285929227727], "final_y": [0.16485629840118055, 0.16485652506917325, 0.16485603836432328]}, "mutation_prompt": null}
{"id": "2e3a5e52-a22b-47c4-9cb4-e3a89fda3a9d", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        # Initialize population with quasi-oppositional solutions\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        # Improved local search using BFGS with periodicity constraint\n        def periodic_cost(x):\n            return func(x) + 0.01 * np.sum((x - np.roll(x, 2))**2)\n        result = minimize(periodic_cost, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            new_pop = np.zeros_like(pop)\n            for i in range(len(pop)):\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f * (1 - evals / self.budget)  # Dynamic mutation factor\n                mutant = np.clip(x_1 + f_dynamic * (x_2 - x_3), self.lb, self.ub)\n                cr_dynamic = self.cr * (1 - evals / self.budget)  # Adaptive crossover probability\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Evaluate and select\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            # Periodic encouragement via local search\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Enhanced HybridQODE by incorporating a periodicity constraint and improved local search strategy for layered structure optimization.", "configspace": "", "generation": 3, "fitness": 0.9594572725202167, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.959 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "32913a1e-e1c0-45a4-b364-a215b6a7fad2", "metadata": {"aucs": [0.9502878095320084, 0.9694554151058693, 0.9586285929227727], "final_y": [0.16485577191149925, 0.16485652506917325, 0.16485603836432328]}, "mutation_prompt": null}
{"id": "a45bedc1-4bc2-43db-a394-148277b763ed", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        # Initialize population with quasi-oppositional solutions\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        # Local search using BFGS to fine-tune solutions\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            new_pop = np.zeros_like(pop)\n            for i in range(len(pop)):\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f * (1 - evals / self.budget)  # Dynamic mutation factor\n                mutant = np.clip(x_1 + f_dynamic * (x_2 - x_3), self.lb, self.ub)\n                cr_dynamic = self.cr * (1 - evals / self.budget)  # Changed line: Adaptive crossover probability\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Evaluate and select\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            if evals < self.budget * 0.8:  # Add periodic resampling to escape local minima\n                random_resample_idx = np.random.choice(len(pop), size=int(0.1 * len(pop)), replace=False)\n                for idx in random_resample_idx:\n                    new_pop[idx] = self.lb + (self.ub - self.lb) * np.random.rand(self.dim)\n\n            pop = new_pop\n\n            # Periodic encouragement via local search\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Enhanced HybridQODE by incorporating periodic resampling to escape local minima more effectively.", "configspace": "", "generation": 3, "fitness": 0.9585018118617654, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.959 with standard deviation 0.009. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "32913a1e-e1c0-45a4-b364-a215b6a7fad2", "metadata": {"aucs": [0.947421427556654, 0.9694554151058693, 0.9586285929227727], "final_y": [0.1648561149266684, 0.16485652506917325, 0.16485603836432328]}, "mutation_prompt": null}
{"id": "bbf6a795-0c6e-4fe2-bb1c-c5849e1cac7d", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        # Initialize population with quasi-oppositional solutions\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        # Local search using BFGS to fine-tune solutions\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            # Adaptive population size based on remaining budget\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (2 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):  # Adjusting loop according to new pop_size\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f * (1 - evals / self.budget)  # Dynamic mutation factor\n                mutant = np.clip(x_1 + f_dynamic * (x_2 - x_3), self.lb, self.ub)\n                cr_dynamic = self.cr * (1 - evals / self.budget)  # Changed line: Adaptive crossover probability\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[np.random.randint(len(pop))])  # Changed line\n\n                # Evaluate and select\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            # Periodic encouragement via local search\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Enhanced crossover strategy for increased population diversity and exploration efficiency.", "configspace": "", "generation": 4, "fitness": 0.8974296114033193, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.897 with standard deviation 0.086. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "4f36907b-2665-41e3-a53b-0436277676ea", "metadata": {"aucs": [0.9505787534350965, 0.7762278852448368, 0.9654821955300248], "final_y": [0.16485629840118055, 0.1648561480224663, 0.16485603836432328]}, "mutation_prompt": null}
{"id": "ec4a1d98-2e09-4560-aafc-623c8bf62cb7", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        # Initialize population with quasi-oppositional solutions\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        # Local search using BFGS to fine-tune solutions\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            # Aggressively adaptive population size based on remaining budget\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / self.budget) ** 1.5))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):  # Adjusting loop according to new pop_size\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f * (1 - evals / self.budget)  # Dynamic mutation factor\n                mutant = np.clip(x_1 + f_dynamic * (x_2 - x_3), self.lb, self.ub)\n                cr_dynamic = self.cr * (1 - evals / self.budget)  # Adaptive crossover probability\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Evaluate and select\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            # Periodic encouragement via local search\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Introduced a dynamic population size strategy to further maintain diversity and improve convergence, adapting more aggressively with budget exhaustion.", "configspace": "", "generation": 4, "fitness": 0.9628163212564096, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.963 with standard deviation 0.011. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "4f36907b-2665-41e3-a53b-0436277676ea", "metadata": {"aucs": [0.975355404359952, 0.9476113638792519, 0.9654821955300248], "final_y": [0.16485629840118055, 0.1648571041277802, 0.16485603836432328]}, "mutation_prompt": null}
{"id": "a518732d-4031-4c42-baa6-3df35755666c", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        # Initialize population with quasi-oppositional solutions\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        # Local search using BFGS to fine-tune solutions\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            # Adaptive population size based on remaining budget\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (2 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):  # Adjusting loop according to new pop_size\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f * (1 - evals / self.budget)  # Dynamic mutation factor\n                chaotic_factor = 0.7 + 0.3 * np.sin(3.14 * evals / self.budget)  # Added line: Chaotic mapping\n                mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)  # Modified line\n                cr_dynamic = self.cr * (1 - evals / self.budget)  # Changed line: Adaptive crossover probability\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Evaluate and select\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            # Periodic encouragement via local search\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Introduced chaotic mapping for mutation vector scaling to enhance exploration and exploitation balance in DE.", "configspace": "", "generation": 4, "fitness": 0.9724219553271699, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.972 with standard deviation 0.005. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "4f36907b-2665-41e3-a53b-0436277676ea", "metadata": {"aucs": [0.9734104881758365, 0.9783731822756482, 0.9654821955300248], "final_y": [0.16485629840118055, 0.16485652506917325, 0.16485603836432328]}, "mutation_prompt": null}
{"id": "43a30e58-7ffc-4b73-9ab7-607f88a5abe0", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        # Initialize population with quasi-oppositional solutions\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        # Local search using BFGS to fine-tune solutions\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            # Adaptive population size based on remaining budget\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (2 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):  # Adjusting loop according to new pop_size\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f * (1 - evals / self.budget)  # Dynamic mutation factor\n                mutant = np.clip(x_1 + f_dynamic * (x_2 - x_3), self.lb, self.ub)\n                cr_dynamic = self.cr * (1 - evals / self.budget)  # Changed line: Adaptive crossover probability\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Evaluate and select\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            # Adjust local search frequency dynamically\n            if evals < self.budget and evals % int(0.1 * self.budget) == 0:  # Changed line: Adjusting frequency\n                for i in range(len(pop)):\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Integrated dynamic local search frequency based on the progress of evaluations to enhance convergence.", "configspace": "", "generation": 4, "fitness": 0.8998276912004194, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.900 with standard deviation 0.098. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "4f36907b-2665-41e3-a53b-0436277676ea", "metadata": {"aucs": [0.7616284404485948, 0.9723724376226385, 0.9654821955300248], "final_y": [0.1818794420920785, 0.16485652506917325, 0.16485603836432328]}, "mutation_prompt": null}
{"id": "e5a5da3b-cbbe-4620-a577-fafe91ff279b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n        self.best_memory = []  # Memory to store best solutions\n\n    def quasi_oppositional_initialization(self):\n        # Initialize population with quasi-oppositional solutions\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        # Local search using BFGS to fine-tune solutions\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            # Adaptive population size based on remaining budget\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (2 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):  # Adjusting loop according to new pop_size\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f * (1 - evals / self.budget)  # Dynamic mutation factor\n                mutant = np.clip(x_1 + f_dynamic * (x_2 - x_3), self.lb, self.ub)\n                cr_dynamic = self.cr * (1 - evals / self.budget)  # Changed line: Adaptive crossover probability\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Evaluate and select\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                        self.best_memory.append(best_solution)  # Store best solution\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            # Periodic encouragement via local search\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n                        self.best_memory.append(best_solution)  # Store best solution\n\n        # Use memory of best solutions to further refine\n        for sol in self.best_memory:\n            refined_solution = self.local_search(sol, func)\n            refined_fitness = func(refined_solution)\n            evals += 1\n            if refined_fitness < best_fitness:\n                best_fitness = refined_fitness\n                best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Enhanced HybridQODE by introducing memory of previous best solutions to boost convergence efficiency.", "configspace": "", "generation": 4, "fitness": 0.9698281621301398, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.970 with standard deviation 0.003. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "4f36907b-2665-41e3-a53b-0436277676ea", "metadata": {"aucs": [0.971629853237756, 0.9723724376226385, 0.9654821955300248], "final_y": [0.16485629840118055, 0.16485652506917325, 0.16485603836432328]}, "mutation_prompt": null}
{"id": "45df6b06-9583-41b8-958e-fa2e0b73e028", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def chaotic_mapping(self, evals):\n        return 0.7 + 0.3 * np.sin(6.28 * evals / self.budget)  # Adjusted frequency for dynamic changes\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (2 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f * (1 - evals / self.budget)\n                chaotic_factor = self.chaotic_mapping(evals)  # Dynamic chaotic factor from separate function\n                mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                cr_dynamic = self.cr * (1 - evals / self.budget)\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            if evals % (self.budget // 10) == 0:  # Periodic reinforcement\n                for i in range(len(pop)):\n                    if evals < self.budget:\n                        refined_solution = self.local_search(pop[i], func)\n                        refined_fitness = func(refined_solution)\n                        evals += 1\n                        if refined_fitness < best_fitness:\n                            best_fitness = refined_fitness\n                            best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Enhanced HybridQODE with dynamic chaotic mapping and periodic reinforcement for improved convergence.", "configspace": "", "generation": 5, "fitness": 0.9140772059637602, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.914 with standard deviation 0.081. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "a518732d-4031-4c42-baa6-3df35755666c", "metadata": {"aucs": [0.7999185119092063, 0.9797646978057666, 0.9625484081763077], "final_y": [0.1648601667899714, 0.16485600070702955, 0.16485841692191905]}, "mutation_prompt": null}
{"id": "faa19282-8cfc-439b-842a-f855257e1547", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        # Initialize population with quasi-oppositional solutions\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        # Local search using BFGS to fine-tune solutions\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            # Adaptive population size based on remaining budget\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (2 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):  # Adjusting loop according to new pop_size\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f * (1 - evals / self.budget)  # Dynamic mutation factor\n                chaotic_factor = 0.7 + 0.15 * (np.sin(3.14 * evals / self.budget) + np.sin(6.28 * evals / self.budget))  # Modified line: Chaotic mapping\n                mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                cr_dynamic = self.cr * (1 - evals / self.budget)  # Changed line: Adaptive crossover probability\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Evaluate and select\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            # Periodic encouragement via local search\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Introduced time-varying chaotic sine mix to enhance population diversity and improve convergence dynamics.", "configspace": "", "generation": 5, "fitness": 0.9683765098806957, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.968 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "a518732d-4031-4c42-baa6-3df35755666c", "metadata": {"aucs": [0.962816423660013, 0.9797646978057666, 0.9625484081763077], "final_y": [0.16485629840118055, 0.16485600070702955, 0.16485841692191905]}, "mutation_prompt": null}
{"id": "5b247b14-fffb-4141-b057-8b52387b9569", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        # Initialize population with quasi-oppositional solutions\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        # Local search using BFGS to fine-tune solutions\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        if not result.success:  # If not successful, introduce random restart\n            perturbation = np.random.uniform(-0.1, 0.1, self.dim)  # One line change\n            return np.clip(solution + perturbation, self.lb, self.ub)\n        return result.x\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            # Adaptive population size based on remaining budget\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (2 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):  # Adjusting loop according to new pop_size\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f * (1 - evals / self.budget)  # Dynamic mutation factor\n                chaotic_factor = 0.7 + 0.3 * np.sin(3.14 * evals / self.budget)  # Added line: Chaotic mapping\n                mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)  # Modified line\n                cr_dynamic = self.cr * (1 - evals / self.budget)  # Changed line: Adaptive crossover probability\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Evaluate and select\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            # Periodic encouragement via local search\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Enhanced local search strategy by introducing random restart in the BFGS optimization step to escape local minima.", "configspace": "", "generation": 5, "fitness": 0.971028612983754, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.971 with standard deviation 0.007. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "a518732d-4031-4c42-baa6-3df35755666c", "metadata": {"aucs": [0.9707727329691878, 0.9797646978057666, 0.9625484081763077], "final_y": [0.16485751130789705, 0.16485600070702955, 0.16485841692191905]}, "mutation_prompt": null}
{"id": "bb754638-a467-4c3d-9325-9abc1f594cd7", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        # Initialize population with quasi-oppositional solutions\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        # Local search using BFGS to fine-tune solutions\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            # Adaptive population size based on remaining budget\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (2 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):  # Adjusting loop according to new pop_size\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f * (1 - evals / self.budget)  # Dynamic mutation factor\n                chaotic_factor = 0.7 + 0.3 * np.sin(3.14 * evals / self.budget)  # Added line: Chaotic mapping\n                sigmoid_factor = 1 / (1 + np.exp(-0.1 * (evals - self.budget / 2)))  # Added line: Sigmoid modulation\n                mutant = np.clip(x_1 + f_dynamic * chaotic_factor * sigmoid_factor * (x_2 - x_3), self.lb, self.ub)  # Modified line\n                cr_dynamic = self.cr / (1 + np.exp(-0.1 * (evals - self.budget / 2)))  # Changed line: Sigmoid-based adaptive crossover \n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Evaluate and select\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            # Periodic encouragement via local search\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Enhanced HybridQODE by introducing a sigmoid-based adaptive crossover probability and a dynamic chaotic weight adjustment.", "configspace": "", "generation": 5, "fitness": 0.9595016766257142, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.960 with standard deviation 0.003. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "a518732d-4031-4c42-baa6-3df35755666c", "metadata": {"aucs": [0.9558701562791023, 0.9600864654217324, 0.9625484081763077], "final_y": [0.16485629840118055, 0.16485652506917325, 0.16485841692191905]}, "mutation_prompt": null}
{"id": "463f3751-2dda-4603-a222-d49b88b33f83", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        # Initialize population with quasi-oppositional solutions\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        # Local search using BFGS to fine-tune solutions\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            # Adaptive population size based on remaining budget\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (2 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):  # Adjusting loop according to new pop_size\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f * (1 - evals / self.budget)  # Dynamic mutation factor\n                chaotic_factor = 0.7 + 0.3 * np.sin(3.14 * evals / self.budget) * np.cos(3.14 * evals / self.budget)  # Modified line\n                mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)  # Modified line\n                cr_dynamic = self.cr * (1 - evals / self.budget)  # Changed line: Adaptive crossover probability\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Evaluate and select\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            # Periodic encouragement via local search\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Enhanced mutation by introducing a cosine function for more diverse exploration.", "configspace": "", "generation": 5, "fitness": 0.9724206875523199, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.972 with standard deviation 0.007. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "a518732d-4031-4c42-baa6-3df35755666c", "metadata": {"aucs": [0.9749489566748855, 0.9797646978057666, 0.9625484081763077], "final_y": [0.16485629840118055, 0.16485600070702955, 0.16485841692191905]}, "mutation_prompt": null}
{"id": "8aa6f94e-901c-4d44-bdb1-2061341b3309", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (2 * self.budget) * (best_fitness / (0.1 + best_fitness)))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f * (1 - evals / self.budget)\n                chaotic_factor = 0.5 + 0.3 * np.sin(5 * np.pi * evals / self.budget)\n                f_chaos = f_dynamic * chaotic_factor\n                mutant = np.clip(x_1 + f_chaos * (x_2 - x_3), self.lb, self.ub)\n                cr_dynamic = self.cr * (1 - evals / self.budget)\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Introducing chaos-enhanced dynamic scaling and differential fitness-based population reduction in HybridQODE.", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('cannot convert float NaN to integer').", "error": "ValueError('cannot convert float NaN to integer')", "parent_id": "463f3751-2dda-4603-a222-d49b88b33f83", "metadata": {}, "mutation_prompt": null}
{"id": "4263aede-f72d-4af4-b827-8445d7cc21e1", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        # Initialize population with quasi-oppositional solutions\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        # Local search using BFGS to fine-tune solutions\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            # Adaptive population size based on remaining budget\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (2 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):  # Adjusting loop according to new pop_size\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f * (1 - evals / self.budget)  # Dynamic mutation factor\n                chaotic_factor = 0.7 + 0.5 * np.sin(3.14 * evals / (2 * self.budget)) * np.cos(3.14 * evals / (2 * self.budget))  # Modified line (enhanced)\n                mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)  # Modified line\n                cr_dynamic = self.cr * (1 - evals / self.budget)  # Changed line: Adaptive crossover probability\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Evaluate and select\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            # Periodic encouragement via local search\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Enhanced with adaptive chaotic factors to improve exploration and convergence.", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('cannot convert float NaN to integer').", "error": "ValueError('cannot convert float NaN to integer')", "parent_id": "463f3751-2dda-4603-a222-d49b88b33f83", "metadata": {}, "mutation_prompt": null}
{"id": "c5425345-a23a-455b-bae5-9f0588bf4c6b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        # Initialize population with quasi-oppositional solutions\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        # Local search using BFGS to fine-tune solutions\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            # Adaptive population size based on remaining budget\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (2 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):  # Adjusting loop according to new pop_size\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f * (1 - evals / self.budget)  # Dynamic mutation factor\n                chaotic_factor = 0.7 + 0.3 * np.sin(3.14 * evals / self.budget) * np.cos(3.14 * evals / self.budget)  # Modified line\n                mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)  # Modified line\n                cr_dynamic = self.cr * (1 - evals / self.budget)  # Changed line: Adaptive crossover probability\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i]) + np.random.normal(0, 0.1, self.dim)  # Added Gaussian perturbation\n\n                # Evaluate and select\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n\n            pop = new_pop\n\n            # Periodic encouragement via local search\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Enhanced population diversity by adding a Gaussian perturbation to the trial vector.", "configspace": "", "generation": 6, "fitness": 0.9726608655403531, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.973 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "463f3751-2dda-4603-a222-d49b88b33f83", "metadata": {"aucs": [0.9620464655196082, 0.9803856684816544, 0.975550462619797], "final_y": [0.16485629840118055, 0.16485620050124516, 0.16485685793583182]}, "mutation_prompt": null}
{"id": "8d369112-2e5e-4cb7-aa0b-cdef97d1c8f3", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        # Initialize population with quasi-oppositional solutions\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        # Local search using BFGS to fine-tune solutions\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))  # Modified line\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):  # Adjusting loop according to new pop_size\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f * (1 - evals / self.budget)  # Dynamic mutation factor\n                chaotic_factor = 0.6 + 0.4 * np.sin(3.14 * evals / self.budget) * np.cos(3.14 * evals / self.budget)  # Modified line\n                mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)  # Modified line\n                cr_dynamic = self.cr * (1 - evals / self.budget)  # Changed line: Adaptive crossover probability\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Evaluate and select\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            # Periodic encouragement via local search\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Introduced adaptive learning rate and dynamic population size scaling to improve exploration and convergence balance.", "configspace": "", "generation": 6, "fitness": 0.9767235998157169, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.977 with standard deviation 0.003. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "463f3751-2dda-4603-a222-d49b88b33f83", "metadata": {"aucs": [0.9742346683456989, 0.9803856684816544, 0.975550462619797], "final_y": [0.16485626480181526, 0.16485620050124516, 0.16485685793583182]}, "mutation_prompt": null}
{"id": "bd38b7d9-7625-4ed8-bc44-2fa20589ca7c", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        # Initialize population with quasi-oppositional solutions\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        # Local search using BFGS to fine-tune solutions\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            # Adaptive population size based on remaining budget\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (2 * self.budget / 0.9))))  # Modified line\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):  # Adjusting loop according to new pop_size\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f * (1 - evals / self.budget)  # Dynamic mutation factor\n                chaotic_factor = 0.7 + 0.3 * np.sin(3.14 * evals / self.budget) * np.cos(3.14 * evals / self.budget)  # Modified line\n                mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)  # Modified line\n                cr_dynamic = self.cr * (1 - evals / self.budget)  # Changed line: Adaptive crossover probability\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Evaluate and select\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            # Periodic encouragement via local search\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Introduced adaptive population contraction to enhance convergence speed without compromising exploration. ", "configspace": "", "generation": 6, "fitness": 0.96664795895546, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.967 with standard deviation 0.015. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "463f3751-2dda-4603-a222-d49b88b33f83", "metadata": {"aucs": [0.9734104252978427, 0.9803856684816544, 0.9461477830868825], "final_y": [0.16485629840118055, 0.16485620050124516, 0.1648594403046183]}, "mutation_prompt": null}
{"id": "d3ca672a-dcc5-4418-b79e-0b180891dccc", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f * (1 - evals / self.budget)\n                chaotic_factor = 0.6 + 0.4 * np.sin(3.14 * evals / self.budget) * np.cos(3.14 * evals / self.budget)\n                mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                cr_dynamic = self.cr * (1 - evals / self.budget)\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget and i % 2 == 0:  # Perform local search every alternate iteration\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Enhanced HybridQODE by integrating periodic modulation and a multi-phase local search for improved convergence accuracy.", "configspace": "", "generation": 7, "fitness": 0.9660851148143951, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.966 with standard deviation 0.010. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "8d369112-2e5e-4cb7-aa0b-cdef97d1c8f3", "metadata": {"aucs": [0.9617862436543566, 0.9802650862980826, 0.9562040144907459], "final_y": [0.16485618987775974, 0.16485652506917325, 0.16485730168119728]}, "mutation_prompt": null}
{"id": "5247527b-0f18-47e7-93e1-7f584c794e7e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.3 * self.budget))))  # Changed line\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f * (0.5 + 0.5 * np.sin(evals * np.pi / self.budget))  # Changed line\n                chaotic_factor = 0.6 + 0.4 * np.sin(3.14 * evals / self.budget)  # Changed line\n                mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                cr_dynamic = self.cr * (0.5 + 0.5 * np.cos(evals * np.pi / self.budget))  # Changed line\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n\n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Enhanced HybridQODE with chaotic dynamics and periodicity reinforcement for improved exploration and convergence. ", "configspace": "", "generation": 7, "fitness": 0.9630191423620239, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.963 with standard deviation 0.012. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "8d369112-2e5e-4cb7-aa0b-cdef97d1c8f3", "metadata": {"aucs": [0.9525883262972431, 0.9802650862980826, 0.9562040144907459], "final_y": [0.16485641090464975, 0.16485652506917325, 0.16485730168119728]}, "mutation_prompt": null}
{"id": "9d8f9525-f4e5-4591-ab53-cef4801ea90c", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        # Initialize population with quasi-oppositional solutions\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        # Local search using BFGS to fine-tune solutions\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))  # Modified line\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):  # Adjusting loop according to new pop_size\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f * (1 - evals / self.budget)  # Dynamic mutation factor\n                chaotic_factor = 0.7 + 0.3 * np.sin(2 * 3.14 * evals / self.budget)  # Modified line\n                mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)  # Modified line\n                cr_dynamic = self.cr * (1 - evals / (1.2 * self.budget))  # Changed line: Adaptive crossover probability\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Evaluate and select\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            # Periodic encouragement via local search\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Enhanced global search by modifying chaotic factor and crossover probability dynamics for better diversity.", "configspace": "", "generation": 7, "fitness": 0.9699627298010817, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.970 with standard deviation 0.010. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "8d369112-2e5e-4cb7-aa0b-cdef97d1c8f3", "metadata": {"aucs": [0.9734190886144167, 0.9802650862980826, 0.9562040144907459], "final_y": [0.16485629840118055, 0.16485652506917325, 0.16485730168119728]}, "mutation_prompt": null}
{"id": "b4a7d55f-fafb-412c-b03c-72086d1ae047", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        # Initialize population with quasi-oppositional solutions\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        # Local search using BFGS to fine-tune solutions\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))  # Modified line\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):  # Adjusting loop according to new pop_size\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f * (1 - evals / self.budget)  # Dynamic mutation factor\n                chaotic_factor = 0.6 + 0.4 * np.sin(np.pi * evals / self.budget) * np.cos(np.pi * evals / self.budget)  # Modified line\n                mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)  # Modified line\n                cr_dynamic = self.cr * (1 - evals / self.budget)  # Changed line: Adaptive crossover probability\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Evaluate and select\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            # Periodic encouragement via local search\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Enhanced mutation strategy by using a sinusoidal chaotic factor for improved exploration.", "configspace": "", "generation": 7, "fitness": 0.970250638028569, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.970 with standard deviation 0.010. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "8d369112-2e5e-4cb7-aa0b-cdef97d1c8f3", "metadata": {"aucs": [0.9742828132968784, 0.9802650862980826, 0.9562040144907459], "final_y": [0.16485627853351514, 0.16485652506917325, 0.16485730168119728]}, "mutation_prompt": null}
{"id": "0bf2278a-2a7d-42e9-b2a9-0451f576004e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f * (1 - evals / self.budget)\n                chaotic_factor = 0.6 + 0.4 * np.sin(2 * np.pi * evals / self.budget)  # Modified line\n                mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                cr_dynamic = self.cr * (1 - evals / self.budget) + 0.1 * np.random.rand()  # Modified line\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Introduced chaotic perturbation and adaptive crossover to enhance exploration and convergence in hybrid global-local optimization.", "configspace": "", "generation": 7, "fitness": 0.9661717485060728, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.966 with standard deviation 0.010. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "8d369112-2e5e-4cb7-aa0b-cdef97d1c8f3", "metadata": {"aucs": [0.9620461447293898, 0.9802650862980826, 0.9562040144907459], "final_y": [0.16485629840118055, 0.16485652506917325, 0.16485730168119728]}, "mutation_prompt": null}
{"id": "565908a3-fd97-4a86-a8d4-3e7f41893554", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        # Initialize population with quasi-oppositional solutions\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        # Local search using BFGS to fine-tune solutions\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))  # Modified line\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):  # Adjusting loop according to new pop_size\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f * (0.5 + 0.5 * np.sin(np.pi * evals / self.budget))  # Modified line\n                chaotic_factor = 0.6 + 0.4 * np.sin(np.pi * evals / self.budget) * np.cos(np.pi * evals / self.budget)  # Modified line\n                mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)  # Modified line\n                cr_dynamic = self.cr * (1 - evals / self.budget)  # Changed line: Adaptive crossover probability\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Evaluate and select\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            # Periodic encouragement via local search\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Introduce adaptive scaling of self.f and integrate sinusoidal asymmetric factor to enhance exploration and exploitation balance.", "configspace": "", "generation": 8, "fitness": 0.9648021818930644, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.965 with standard deviation 0.010. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "b4a7d55f-fafb-412c-b03c-72086d1ae047", "metadata": {"aucs": [0.9518721610835252, 0.9770810304291805, 0.965453354166488], "final_y": [0.16485768354858754, 0.16485601377698877, 0.16485817338893138]}, "mutation_prompt": null}
{"id": "603b7ecb-4742-4909-8060-1dccf848576a", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        # Initialize population with quasi-oppositional solutions\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        # Local search using BFGS to fine-tune solutions\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            # Change: Adjust population size using fitness variance\n            fitness_values = np.array([func(ind) for ind in pop])\n            fitness_variance = np.var(fitness_values)\n            self.pop_size = max(5, int(self.pop_size * (1 + fitness_variance / (1.5 * self.budget))))\n            \n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):  # Adjusting loop according to new pop_size\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f * (1 - evals / self.budget)  # Dynamic mutation factor\n                chaotic_factor = 0.6 + 0.4 * np.sin(np.pi * evals / self.budget) * np.cos(np.pi * evals / self.budget)\n                mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                cr_dynamic = self.cr * (1 - evals / self.budget)  # Changed line: Adaptive crossover probability\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Evaluate and select\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            # Periodic encouragement via local search\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Improved exploration by dynamically adjusting the population size based on fitness variance.", "configspace": "", "generation": 8, "fitness": 0.9611159462911129, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.961 with standard deviation 0.010. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "b4a7d55f-fafb-412c-b03c-72086d1ae047", "metadata": {"aucs": [0.9713461511205156, 0.9639419986679183, 0.9480596890849047], "final_y": [0.16485627853351514, 0.16485964280847687, 0.16485609252473576]}, "mutation_prompt": null}
{"id": "e1f70b58-b5ca-441d-aaf0-e7d935ff0669", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        # Initialize population with quasi-oppositional solutions\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        # Local search using BFGS to fine-tune solutions\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (2 * self.budget))))  # Modified line\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):  # Adjusting loop according to new pop_size\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f * (1 - evals / self.budget)  # Dynamic mutation factor\n                chaotic_factor = 0.6 + 0.4 * np.sin(2 * np.pi * evals / self.budget) * np.cos(np.pi * evals / self.budget)  # Modified line\n                mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)  \n                cr_dynamic = self.cr * (1 - evals / self.budget)  # Changed line: Adaptive crossover probability\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Evaluate and select\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            # Periodic encouragement via local search\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Introduced time-varying chaotic factor and adaptive population reduction to enhance exploration and convergence.", "configspace": "", "generation": 8, "fitness": 0.9623028138017178, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.962 with standard deviation 0.011. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "b4a7d55f-fafb-412c-b03c-72086d1ae047", "metadata": {"aucs": [0.9749067536523306, 0.9639419986679183, 0.9480596890849047], "final_y": [0.16485629840118055, 0.16485964280847687, 0.16485609252473576]}, "mutation_prompt": null}
{"id": "fe220da1-5f7b-46c9-b347-64a0482eba53", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        # Initialize population with quasi-oppositional solutions\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        # Local search using BFGS to fine-tune solutions\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))  # Modified line\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):  # Adjusting loop according to new pop_size\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                # Modify dynamic mutation factor to consider budget's square root to adapt exploration\n                f_dynamic = self.f * (1 - np.sqrt(evals) / np.sqrt(self.budget))  # Modified line\n                # Introduce a dynamically adjusted chaotic factor using a cosine modulation\n                chaotic_factor = 0.6 + 0.4 * np.cos(np.pi * evals / self.budget)  # Modified line\n                mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                cr_dynamic = self.cr * (1 - evals / self.budget)\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Evaluate and select\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            # Periodic encouragement via local search\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Adaptive population and dynamic chaos factor were incorporated to enhance exploration and convergence balance.", "configspace": "", "generation": 8, "fitness": 0.9624529750927279, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.962 with standard deviation 0.011. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "b4a7d55f-fafb-412c-b03c-72086d1ae047", "metadata": {"aucs": [0.975357237525361, 0.9639419986679183, 0.9480596890849047], "final_y": [0.16485629840118055, 0.16485964280847687, 0.16485609252473576]}, "mutation_prompt": null}
{"id": "0c90993e-797f-49ee-adfd-247c4aeda9ba", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=60, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def levy_flight(self, step_size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                (np.math.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / abs(v)**(1 / beta)\n        return step_size * step\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / self.budget)))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f * (1 - evals / self.budget)\n                levy_step = self.levy_flight(f_dynamic)  # Added line\n                mutant = np.clip(x_1 + levy_step * (x_2 - x_3), self.lb, self.ub)  # Modified line\n                cr_dynamic = self.cr * (1 - evals / self.budget)\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Introduced adaptive population size and chaotic Levy flight mutation for enhanced exploration and exploitation balance.", "configspace": "", "generation": 8, "fitness": 0.9539509028140373, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.954 with standard deviation 0.007. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "b4a7d55f-fafb-412c-b03c-72086d1ae047", "metadata": {"aucs": [0.9498510206892888, 0.9639419986679183, 0.9480596890849047], "final_y": [0.1648578354368162, 0.16485964280847687, 0.16485609252473576]}, "mutation_prompt": null}
{"id": "d5bd284a-45d3-403e-83dd-036350645cae", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def levy_flight(self, solution):\n        beta = 1.5\n        sigma = (np.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return solution + 0.01 * step\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                if np.random.rand() < 0.5:\n                    indices = np.random.choice(len(pop), 3, replace=False)\n                    x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                    f_dynamic = self.f * (0.5 + 0.5 * np.sin(np.pi * evals / self.budget))\n                    chaotic_factor = 0.6 + 0.4 * np.sin(np.pi * evals / self.budget) * np.cos(np.pi * evals / self.budget)\n                    mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                else:\n                    mutant = self.levy_flight(pop[i])\n                \n                cr_dynamic = self.cr * (1 - evals / self.budget)\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Enhance adaptiveness by incorporating Levy flights for exploration and dynamic mutation strategies to balance exploration and exploitation.", "configspace": "", "generation": 9, "fitness": -Infinity, "feedback": "An exception occurred: AttributeError(\"module 'numpy' has no attribute 'gamma'\").", "error": "AttributeError(\"module 'numpy' has no attribute 'gamma'\")", "parent_id": "565908a3-fd97-4a86-a8d4-3e7f41893554", "metadata": {}, "mutation_prompt": null}
{"id": "6aa56b5a-6124-46ec-b189-e2d40bb3108c", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f * (0.5 + 0.5 * np.sin(np.pi * evals / self.budget))\n                chaotic_factor = 0.5 + 0.3 * np.sin(2 * np.pi * evals / self.budget)  # Modified line\n                f_dynamic *= (1 + 0.1 * np.cos(np.pi * evals / self.budget))  # Modified line\n                mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                cr_dynamic = self.cr * (1 - evals / self.budget)\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            if evals < self.budget:  # Modified condition\n                for i in range(len(pop)):\n                    if evals < self.budget:\n                        refined_solution = self.local_search(pop[i], func)\n                        refined_fitness = func(refined_solution)\n                        evals += 1\n                        if refined_fitness < best_fitness:\n                            best_fitness = refined_fitness\n                            best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Enhance HybridQODE by introducing adaptive chaotic factors and improving exploitation balance through dynamic scaling and periodic local searches.", "configspace": "", "generation": 9, "fitness": -Infinity, "feedback": "An exception occurred: AttributeError(\"module 'numpy' has no attribute 'gamma'\").", "error": "AttributeError(\"module 'numpy' has no attribute 'gamma'\")", "parent_id": "565908a3-fd97-4a86-a8d4-3e7f41893554", "metadata": {}, "mutation_prompt": null}
{"id": "5f127740-1116-44be-935f-c722d6784e40", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        # Initialize population with quasi-oppositional solutions\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        # Local search using BFGS to fine-tune solutions\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))  # Modified line\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):  # Adjusting loop according to new pop_size\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f * (0.5 + 0.5 * np.sin(np.pi * evals / self.budget))  # Modified line\n                chaotic_factor = 0.6 + 0.4 * np.sin(np.pi * evals / self.budget) * np.cos(np.pi * evals / self.budget)  # Modified line\n                periodic_factor = np.sin(2 * np.pi * np.sum(x_1) / self.dim)  # New line\n                mutant = np.clip(x_1 + f_dynamic * chaotic_factor * periodic_factor * (x_2 - x_3), self.lb, self.ub)  # Modified line\n                cr_dynamic = self.cr * (1 - evals / self.budget)  # Changed line: Adaptive crossover probability\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Evaluate and select\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            # Periodic encouragement via local search\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Enhance adaptive crossover strategy and integrate a periodic solution mechanism for improved convergence.", "configspace": "", "generation": 9, "fitness": -Infinity, "feedback": "An exception occurred: AttributeError(\"module 'numpy' has no attribute 'gamma'\").", "error": "AttributeError(\"module 'numpy' has no attribute 'gamma'\")", "parent_id": "565908a3-fd97-4a86-a8d4-3e7f41893554", "metadata": {}, "mutation_prompt": null}
{"id": "b5b7cedc-4547-42ce-9a1d-0759d6c046d5", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        # Initialize population with quasi-oppositional solutions\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        # Local search using BFGS to fine-tune solutions\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - (evals * 0.9) / (1.5 * self.budget))))  # Modified line\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):  # Adjusting loop according to new pop_size\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f * (0.5 + 0.5 * np.sin(np.pi * evals / self.budget))  # Modified line\n                chaotic_factor = 0.6 + 0.4 * np.sin(np.pi * evals / self.budget) * np.cos(np.pi * evals / self.budget)  # Modified line\n                mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)  # Modified line\n                cr_dynamic = self.cr * (1 - evals / self.budget)  # Changed line: Adaptive crossover probability\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Evaluate and select\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            # Periodic encouragement via local search\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Introduce a dynamic adjustment to the population size reduction factor, enhancing diversity and exploration.", "configspace": "", "generation": 9, "fitness": -Infinity, "feedback": "An exception occurred: AttributeError(\"module 'numpy' has no attribute 'gamma'\").", "error": "AttributeError(\"module 'numpy' has no attribute 'gamma'\")", "parent_id": "565908a3-fd97-4a86-a8d4-3e7f41893554", "metadata": {}, "mutation_prompt": null}
{"id": "9241780e-ed88-4b09-9c42-dbf37b7643a4", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.3 * self.budget))))  # Modified line (1)\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f * (0.5 + 0.5 * np.sin(2 * np.pi * evals / self.budget))  # Modified line (2)\n                chaotic_factor = 0.6 + 0.4 * np.sin(np.pi * evals / self.budget) * np.cos(2 * np.pi * evals / self.budget)  # Modified line (3)\n                mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                cr_dynamic = self.cr * (1 - evals / self.budget)\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Integrate periodic modulation of self.f with dynamic chaotic factors and adapt population size for improved exploration.", "configspace": "", "generation": 9, "fitness": -Infinity, "feedback": "An exception occurred: AttributeError(\"module 'numpy' has no attribute 'gamma'\").", "error": "AttributeError(\"module 'numpy' has no attribute 'gamma'\")", "parent_id": "565908a3-fd97-4a86-a8d4-3e7f41893554", "metadata": {}, "mutation_prompt": null}
{"id": "b11e7472-f68d-4a24-bb77-0cf0f346d612", "solution": "import numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.stats import levy_stable\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def levy_flight(self, solution):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return solution + 0.01 * step\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                if np.random.rand() < 0.5:\n                    indices = np.random.choice(len(pop), 3, replace=False)\n                    x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                    f_dynamic = self.f * (0.5 + 0.5 * np.sin(np.pi * evals / self.budget))\n                    chaotic_factor = 0.6 + 0.4 * np.sin(np.pi * evals / self.budget) * np.cos(np.pi * evals / self.budget)\n                    mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                else:\n                    mutant = self.levy_flight(pop[i])\n                \n                cr_dynamic = self.cr * (1 - evals / self.budget)\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Enhance adaptiveness by incorporating Levy flights for exploration and dynamic mutation strategies to balance exploration and exploitation, with corrected use of the gamma function.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "An exception occurred: AttributeError(\"'HybridQODE' object has no attribute 'local_search'\").", "error": "AttributeError(\"'HybridQODE' object has no attribute 'local_search'\")", "parent_id": "d5bd284a-45d3-403e-83dd-036350645cae", "metadata": {}, "mutation_prompt": null}
{"id": "d7828ac5-7a81-4dae-9c16-a2bb539214a5", "solution": "import numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.special import gamma  # Correct import for gamma function\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def levy_flight(self, solution):\n        beta = 1.5\n        sigma = (gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return solution + 0.01 * step\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                if np.random.rand() < 0.5:\n                    indices = np.random.choice(len(pop), 3, replace=False)\n                    x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                    f_dynamic = self.f * (0.5 + 0.5 * np.sin(np.pi * evals / self.budget))\n                    chaotic_factor = 0.6 + 0.4 * np.sin(np.pi * evals / self.budget) * np.cos(np.pi * evals / self.budget)\n                    mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                else:\n                    mutant = self.levy_flight(pop[i])\n                \n                cr_dynamic = self.cr * (1 - evals / self.budget)\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Enhance adaptiveness by incorporating Levy flights for exploration and dynamic mutation strategies to balance exploration and exploitation, while ensuring correct function calls and imports.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "An exception occurred: AttributeError(\"'HybridQODE' object has no attribute 'local_search'\").", "error": "AttributeError(\"'HybridQODE' object has no attribute 'local_search'\")", "parent_id": "d5bd284a-45d3-403e-83dd-036350645cae", "metadata": {}, "mutation_prompt": null}
{"id": "1afaabce-79a0-4d6f-a8c3-a1be3c1d2422", "solution": "import numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.special import gamma\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def levy_flight(self, solution):\n        beta = 1.5\n        sigma = (gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return solution + 0.01 * step\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                if np.random.rand() < 0.5:\n                    indices = np.random.choice(len(pop), 3, replace=False)\n                    x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                    f_dynamic = self.f * (0.5 + 0.5 * np.sin(np.pi * evals / self.budget))\n                    chaotic_factor = 0.6 + 0.4 * np.sin(np.pi * evals / self.budget) * np.cos(np.pi * evals / self.budget)\n                    mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                else:\n                    mutant = self.levy_flight(pop[i])\n                \n                cr_dynamic = self.cr * (1 - evals / self.budget)\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "HybridQODE refines Levy flight calculation by replacing `np.gamma` with `scipy.special.gamma`.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "An exception occurred: AttributeError(\"'HybridQODE' object has no attribute 'local_search'\").", "error": "AttributeError(\"'HybridQODE' object has no attribute 'local_search'\")", "parent_id": "d5bd284a-45d3-403e-83dd-036350645cae", "metadata": {}, "mutation_prompt": null}
{"id": "86deb002-6024-4834-9dd6-0c3dc96e020d", "solution": "import numpy as np\nfrom scipy.special import gamma\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def levy_flight(self, solution):\n        beta = 1.5\n        sigma = (gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return solution + 0.01 * step\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                if np.random.rand() < 0.5:\n                    indices = np.random.choice(len(pop), 3, replace=False)\n                    x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                    f_dynamic = self.f * (0.5 + 0.5 * np.sin(np.pi * evals / self.budget))\n                    chaotic_factor = 0.6 + 0.4 * np.sin(np.pi * evals / self.budget) * np.cos(np.pi * evals / self.budget)\n                    mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                else:\n                    mutant = self.levy_flight(pop[i])\n                \n                cr_dynamic = self.cr * (1 - evals / self.budget)\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Improve solution by correcting numpy gamma function access and refining local search step size.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "An exception occurred: AttributeError(\"'HybridQODE' object has no attribute 'local_search'\").", "error": "AttributeError(\"'HybridQODE' object has no attribute 'local_search'\")", "parent_id": "d5bd284a-45d3-403e-83dd-036350645cae", "metadata": {}, "mutation_prompt": null}
{"id": "06396903-0364-45ce-8f65-1996b1f290de", "solution": "import numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.special import gamma as gamma_func\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def levy_flight(self, solution):\n        beta = 1.5\n        sigma = (gamma_func(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (gamma_func((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return solution + 0.01 * step\n\n    def local_search(self, solution, func):\n        result = minimize(func, solution, bounds=list(zip(self.lb, self.ub)), method='L-BFGS-B')\n        return result.x\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                if np.random.rand() < 0.5:\n                    indices = np.random.choice(len(pop), 3, replace=False)\n                    x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                    f_dynamic = self.f * (0.5 + 0.5 * np.sin(np.pi * evals / self.budget))\n                    chaotic_factor = 0.6 + 0.4 * np.sin(np.pi * evals / self.budget) * np.cos(np.pi * evals / self.budget)\n                    mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                else:\n                    mutant = self.levy_flight(pop[i])\n\n                cr_dynamic = self.cr * (1 - evals / self.budget)\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n\n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Adaptive Hybrid QODE using Symmetric Strategies with Chaotic Dynamics for Enhanced Exploration.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "An exception occurred: AttributeError(\"'HybridQODE' object has no attribute 'local_search'\").", "error": "AttributeError(\"'HybridQODE' object has no attribute 'local_search'\")", "parent_id": "d5bd284a-45d3-403e-83dd-036350645cae", "metadata": {}, "mutation_prompt": null}
{"id": "67e7c695-823d-4963-b27f-1fc7ab25b1a9", "solution": "import numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.stats import levy_stable\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def levy_flight(self, solution):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return solution + 0.01 * step\n\n    def local_search(self, solution, func):  # Added missing local_search method\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                if np.random.rand() < 0.5:\n                    indices = np.random.choice(len(pop), 3, replace=False)\n                    x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                    f_dynamic = self.f * (0.5 + 0.5 * np.sin(np.pi * evals / self.budget))\n                    chaotic_factor = 0.6 + 0.4 * np.sin(np.pi * evals / self.budget) * np.cos(np.pi * evals / self.budget)\n                    mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                else:\n                    mutant = self.levy_flight(pop[i])\n                \n                cr_dynamic = self.cr * (1 - evals / self.budget)\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Improve the HybridQODE algorithm by including a basic local search method, fixing the previous exception while maintaining the overall design structure.", "configspace": "", "generation": 11, "fitness": 0.8845942113377508, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.885 with standard deviation 0.114. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "b11e7472-f68d-4a24-bb77-0cf0f346d612", "metadata": {"aucs": [0.9526719515811796, 0.9769226206179344, 0.7241880618141385], "final_y": [0.16485670131798424, 0.16485652506917325, 0.18464993856964962]}, "mutation_prompt": null}
{"id": "7a0139be-6533-4238-8bbd-bbfb99fb4d93", "solution": "import numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.stats import levy_stable\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def levy_flight(self, solution):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return solution + 0.01 * step\n\n    def local_search(self, solution, func):\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                if np.random.rand() < 0.5:\n                    indices = np.random.choice(len(pop), 3, replace=False)\n                    x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                    f_dynamic = self.f * (0.5 + 0.5 * np.sin(np.pi * evals / self.budget))\n                    chaotic_factor = 0.6 + 0.4 * np.sin(np.pi * evals / self.budget) * np.cos(np.pi * evals / self.budget)\n                    mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                else:\n                    mutant = self.levy_flight(pop[i])\n                \n                cr_dynamic = self.cr * (1 - evals / self.budget)\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Incorporate a simple local search method to enhance fine-tuning of solutions close to promising regions while respecting the modification limit.", "configspace": "", "generation": 11, "fitness": 0.8656568960379302, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.866 with standard deviation 0.101. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "b11e7472-f68d-4a24-bb77-0cf0f346d612", "metadata": {"aucs": [0.9526719515811796, 0.9201106747184726, 0.7241880618141385], "final_y": [0.16485670131798424, 0.16485757522474254, 0.18464993856964962]}, "mutation_prompt": null}
{"id": "b1907515-42bc-48be-87f1-dd43e35f6c88", "solution": "import numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.stats import levy_stable\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def levy_flight(self, solution):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return solution + 0.01 * step\n\n    def local_search(self, solution, func):\n        result = minimize(func, solution, method='L-BFGS-B', bounds=np.stack((self.lb, self.ub), axis=1))\n        return result.x\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                if np.random.rand() < 0.5:\n                    indices = np.random.choice(len(pop), 3, replace=False)\n                    x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                    f_dynamic = self.f * (0.5 + 0.5 * np.sin(np.pi * evals / self.budget))\n                    chaotic_factor = 0.6 + 0.4 * np.sin(np.pi * evals / self.budget) * np.cos(np.pi * evals / self.budget)\n                    mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                else:\n                    mutant = self.levy_flight(pop[i])\n                \n                cr_dynamic = self.cr * (1 - evals / self.budget)\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "A hybrid optimization algorithm combining differential evolution and Levy flights with an adaptive local search mechanism to exploit promising regions.", "configspace": "", "generation": 11, "fitness": 0.8658194309128491, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.866 with standard deviation 0.101. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "b11e7472-f68d-4a24-bb77-0cf0f346d612", "metadata": {"aucs": [0.9526719515811796, 0.920598279343229, 0.7241880618141385], "final_y": [0.16485670131798424, 0.16485758057673716, 0.18464993856964962]}, "mutation_prompt": null}
{"id": "b48f7466-18e3-48bd-a819-dc1e0c163119", "solution": "import numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.stats import levy_stable\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def levy_flight(self, solution):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return solution + 0.01 * step\n\n    def local_search(self, solution, func):\n        res = minimize(func, solution, method='BFGS', bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)])\n        return res.x\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                if np.random.rand() < 0.5:\n                    indices = np.random.choice(len(pop), 3, replace=False)\n                    x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                    f_dynamic = self.f * (0.5 + 0.5 * np.sin(np.pi * evals / self.budget))\n                    chaotic_factor = 0.6 + 0.4 * np.sin(np.pi * evals / self.budget) * np.cos(np.pi * evals / self.budget)\n                    mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                else:\n                    mutant = self.levy_flight(pop[i])\n                \n                cr_dynamic = self.cr * (1 - evals / self.budget)\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Enhance adaptiveness by incorporating Levy flights for exploration and dynamic mutation strategies with improved local search using BFGS optimization.", "configspace": "", "generation": 11, "fitness": 0.8277680424829715, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.828 with standard deviation 0.080. And the mean value of best solutions found was 0.179 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "b11e7472-f68d-4a24-bb77-0cf0f346d612", "metadata": {"aucs": [0.8390053909163033, 0.9201106747184726, 0.7241880618141385], "final_y": [0.18813128582889427, 0.16485757522474254, 0.18464993856964962]}, "mutation_prompt": null}
{"id": "10111afe-ad72-4412-8ca1-17665a69067f", "solution": "import numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.stats import levy_stable\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def levy_flight(self, solution):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return solution + 0.01 * step\n\n    def local_search(self, solution, func):\n        res = minimize(func, solution, method='BFGS', bounds=[(l, u) for l, u in zip(self.lb, self.ub)])\n        return res.x\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                if np.random.rand() < 0.5:\n                    indices = np.random.choice(len(pop), 3, replace=False)\n                    x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                    f_dynamic = self.f * (0.5 + 0.5 * np.sin(np.pi * evals / self.budget))\n                    chaotic_factor = 0.6 + 0.4 * np.sin(np.pi * evals / self.budget) * np.cos(np.pi * evals / self.budget)\n                    mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                else:\n                    mutant = self.levy_flight(pop[i])\n                \n                cr_dynamic = self.cr * (1 - evals / self.budget)\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Enhance adaptiveness by incorporating Levy flights for exploration and dynamic mutation strategies to balance exploration and exploitation, with corrected use of the gamma function, and apply BFGS for local search refinements.", "configspace": "", "generation": 11, "fitness": 0.8277680424829715, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.828 with standard deviation 0.080. And the mean value of best solutions found was 0.179 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "b11e7472-f68d-4a24-bb77-0cf0f346d612", "metadata": {"aucs": [0.8390053909163033, 0.9201106747184726, 0.7241880618141385], "final_y": [0.18813128582889427, 0.16485757522474254, 0.18464993856964962]}, "mutation_prompt": null}
{"id": "3496edc9-0388-4bd0-92ae-5a85bd643e03", "solution": "import numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.stats import levy_stable\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def levy_flight(self, solution):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return solution + 0.01 * step\n\n    def local_search(self, solution, func):\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B', options={'maxiter': 150})\n        return result.x\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                if np.random.rand() < 0.5:\n                    indices = np.random.choice(len(pop), 3, replace=False)\n                    x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                    f_dynamic = self.f * (0.5 + 0.5 * np.sin(np.pi * evals / self.budget))\n                    chaotic_factor = 0.6 + 0.4 * np.sin(np.pi * evals / self.budget) * np.cos(np.pi * evals / self.budget)\n                    mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                else:\n                    mutant = self.levy_flight(pop[i])\n                \n                cr_dynamic = self.cr * (1 - evals / self.budget)\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Enhance local search intensity by increasing iterations when refining solutions.", "configspace": "", "generation": 12, "fitness": 0.952998639460917, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.953 with standard deviation 0.020. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "67e7c695-823d-4963-b27f-1fc7ab25b1a9", "metadata": {"aucs": [0.9526719515811796, 0.9778299066441565, 0.9284940601574149], "final_y": [0.16485670131798424, 0.16485588447342558, 0.1648566114723854]}, "mutation_prompt": null}
{"id": "2f8c5418-8c08-4cbe-a882-74240e1dbd62", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def levy_flight(self, solution):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return solution + 0.01 * step\n\n    def local_search(self, solution, func):\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                if np.random.rand() < (0.3 + 0.7 * evals / self.budget):  # Dynamic strategy selection\n                    indices = np.random.choice(len(pop), 3, replace=False)\n                    x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                    f_dynamic = self.f * (0.5 + 0.5 * np.sin(np.pi * evals / self.budget))\n                    chaotic_factor = 0.6 + 0.4 * np.sin(np.pi * evals / self.budget) * np.cos(np.pi * evals / self.budget)\n                    mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                else:\n                    mutant = self.levy_flight(pop[i])\n                \n                cr_dynamic = self.cr * (1 - evals / self.budget)\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Enhanced HybridQODE by integrating dynamic multi-strategy selection and improved adaptivity for balancing exploration and exploitation.", "configspace": "", "generation": 12, "fitness": 0.9668783792585013, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.967 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "67e7c695-823d-4963-b27f-1fc7ab25b1a9", "metadata": {"aucs": [0.9618393035621945, 0.9778286199306891, 0.9609672142826202], "final_y": [0.16485629840118055, 0.16485652506917325, 0.16485766939479451]}, "mutation_prompt": null}
{"id": "af7eb5de-0c4a-4c05-91fa-f4d00121328f", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def levy_flight(self, solution, evals):  # Adjusted line\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return solution + 0.01 * step * (1 - evals / self.budget)  # Adjusted line\n\n    def local_search(self, solution, func):\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                if np.random.rand() < 0.5:\n                    indices = np.random.choice(len(pop), 3, replace=False)\n                    x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                    f_dynamic = self.f * (0.5 + 0.5 * np.sin(np.pi * evals / self.budget))\n                    chaotic_factor = 0.6 + 0.4 * np.sin(np.pi * evals / self.budget) * np.cos(np.pi * evals / self.budget)\n                    mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                else:\n                    mutant = self.levy_flight(pop[i], evals)\n\n                cr_dynamic = self.cr * (1 - evals / self.budget)\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n\n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Slightly increase the exploration capability by dynamically adjusting the Levy flight step size based on the evaluation budget.", "configspace": "", "generation": 12, "fitness": 0.9583347479531765, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.958 with standard deviation 0.021. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "67e7c695-823d-4963-b27f-1fc7ab25b1a9", "metadata": {"aucs": [0.931365597320623, 0.9826714322562866, 0.9609672142826202], "final_y": [0.16485629840118055, 0.16485652506917325, 0.16485766939479451]}, "mutation_prompt": null}
{"id": "402bebdf-8822-4dfa-95ef-6d8e78196ffe", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def adaptive_mutation(self, solution, evals):  # Changed from levy_flight to adaptive_mutation\n        factor = 0.01 + (0.99 * evals / self.budget)\n        return solution + factor * np.random.normal(0, 1, size=self.dim)\n\n    def local_search_with_periodicity(self, solution, func):  # Enhanced local search\n        periodic_solution = np.mean(solution.reshape(-1, 2), axis=1).repeat(2)\n        result = minimize(func, periodic_solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                if np.random.rand() < 0.5:\n                    indices = np.random.choice(len(pop), 3, replace=False)\n                    x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                    f_dynamic = self.f * (0.5 + 0.5 * np.sin(np.pi * evals / self.budget))\n                    chaotic_factor = 0.6 + 0.4 * np.sin(np.pi * evals / self.budget) * np.cos(np.pi * evals / self.budget)\n                    mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                else:\n                    mutant = self.adaptive_mutation(pop[i], evals)  # Use adaptive_mutation\n                \n                cr_dynamic = self.cr * (1 - evals / self.budget)\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search_with_periodicity(pop[i], func)  # Use enhanced local search\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Refine HybridQODE by integrating an adaptive mutation strategy and enhancing the local search with periodicity constraints.", "configspace": "", "generation": 12, "fitness": 0.9517919778247954, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.952 with standard deviation 0.017. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "67e7c695-823d-4963-b27f-1fc7ab25b1a9", "metadata": {"aucs": [0.9665391859520654, 0.9278695332397005, 0.9609672142826202], "final_y": [0.1648570606567613, 0.1648612599590933, 0.16485766939479451]}, "mutation_prompt": null}
{"id": "3b060463-3c59-44dc-8935-c6f90bd6829f", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def levy_flight(self, solution):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return solution + 0.01 * step\n\n    def local_search(self, solution, func):\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x\n\n    def adapt_parameters(self, evals):\n        adapt_rate = evals / self.budget\n        self.f = 0.5 + 0.4 * np.sin(2 * np.pi * adapt_rate)\n        self.cr = 0.9 - 0.5 * adapt_rate\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.adapt_parameters(evals)\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                if np.random.rand() < 0.5:\n                    indices = np.random.choice(len(pop), 3, replace=False)\n                    x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                    f_dynamic = self.f\n                    chaotic_factor = 0.6 + 0.4 * np.sin(np.pi * evals / self.budget) * np.cos(np.pi * evals / self.budget)\n                    mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                else:\n                    mutant = self.levy_flight(pop[i])\n                \n                cr_dynamic = self.cr\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Introduce adaptive control of crossover and mutation parameters to improve exploration and exploitation balance in the HybridQODE algorithm.", "configspace": "", "generation": 12, "fitness": 0.9530550574629874, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.953 with standard deviation 0.013. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "67e7c695-823d-4963-b27f-1fc7ab25b1a9", "metadata": {"aucs": [0.9630237505393348, 0.9351742075670071, 0.9609672142826202], "final_y": [0.16485670131798424, 0.16485657887493044, 0.16485766939479451]}, "mutation_prompt": null}
{"id": "5dd0b2aa-6549-41ca-be30-b47e94fa540c", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def levy_flight(self, solution):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return solution + 0.01 * step\n\n    def local_search(self, solution, func):\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                if np.random.rand() < (0.3 + 0.7 * evals / self.budget):  # Dynamic strategy selection\n                    indices = np.random.choice(len(pop), 3, replace=False)\n                    x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                    f_dynamic = self.f * (0.5 + 0.5 * np.sin(np.pi * evals / self.budget))\n                    chaotic_factor = 0.6 + 0.4 * np.sin(np.pi * evals / self.budget) * np.cos(np.pi * evals / self.budget)\n                    mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                else:\n                    mutant = self.levy_flight(pop[i])\n                \n                cr_dynamic = self.cr * (1 - evals / self.budget)\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Introduced adaptive mutation rate scaling based on budget usage to improve exploration-exploitation balance.", "configspace": "", "generation": 13, "fitness": 0.9218627724350755, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.922 with standard deviation 0.035. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "2f8c5418-8c08-4cbe-a882-74240e1dbd62", "metadata": {"aucs": [0.9618424597414492, 0.9265194804122251, 0.8772263771515525], "final_y": [0.16485629840118055, 0.16485757522474254, 0.18188219681393325]}, "mutation_prompt": null}
{"id": "9264559c-6742-4355-b818-7e2343db10e8", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def levy_flight(self, solution):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return solution + 0.01 * step\n\n    def local_search(self, solution, func):\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='BFGS')\n        return result.x\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.2 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                if np.random.rand() < (0.4 + 0.6 * evals / self.budget):  # Dynamic strategy selection\n                    indices = np.random.choice(len(pop), 3, replace=False)\n                    x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                    f_dynamic = self.f * (0.6 + 0.4 * np.sin(np.pi * evals / self.budget))\n                    chaotic_factor = 0.7 + 0.3 * np.sin(np.pi * evals / self.budget) * np.cos(np.pi * evals / self.budget)\n                    mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                else:\n                    mutant = self.levy_flight(pop[i])\n                \n                cr_dynamic = self.cr * (1 - evals / self.budget)\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Refined HybridQODE with enhanced adaptive parameter control and improved local search strategy for better convergence.", "configspace": "", "generation": 13, "fitness": 0.8484679332197906, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.848 with standard deviation 0.078. And the mean value of best solutions found was 0.176 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "2f8c5418-8c08-4cbe-a882-74240e1dbd62", "metadata": {"aucs": [0.7416579420955944, 0.9265194804122251, 0.8772263771515525], "final_y": [0.1818830840566681, 0.16485757522474254, 0.18188219681393325]}, "mutation_prompt": null}
{"id": "3b82c890-fa61-4892-95af-6bffaafd9e36", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def levy_flight(self, solution):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return solution + 0.01 * step\n\n    def local_search(self, solution, func):\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                if np.random.rand() < (0.3 + 0.7 * evals / self.budget):  # Dynamic strategy selection\n                    indices = np.random.choice(len(pop), 3, replace=False)\n                    x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                    f_dynamic = self.f * (0.5 + 0.5 * np.sin(np.pi * evals / self.budget))\n                    chaotic_factor = 0.7 + 0.3 * np.sin(np.pi * evals / self.budget) * np.cos(np.pi * evals / self.budget)\n                    mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                else:\n                    mutant = self.levy_flight(pop[i])\n                \n                cr_dynamic = self.cr * (1 - evals / self.budget)\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Improved exploration by optimal tuning of the chaotic factor within the mutation strategy.", "configspace": "", "generation": 13, "fitness": 0.970858854906227, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.971 with standard deviation 0.007. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "2f8c5418-8c08-4cbe-a882-74240e1dbd62", "metadata": {"aucs": [0.9618426970274704, 0.9785774320658959, 0.9721564356253148], "final_y": [0.16485592951659345, 0.16485652506917325, 0.1648576631807792]}, "mutation_prompt": null}
{"id": "231e3cf9-262d-4273-932c-7bb02fdfc7c2", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def levy_flight(self, solution):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return solution + 0.01 * step\n\n    def local_search(self, solution, func):\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x\n\n    def encourage_periodicity(self, solution):\n        half_dim = self.dim // 2\n        return np.tile(solution[:half_dim], 2)\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                if np.random.rand() < (0.3 + 0.7 * evals / self.budget):\n                    indices = np.random.choice(len(pop), 3, replace=False)\n                    x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                    f_dynamic = self.f * (0.5 + 0.5 * np.sin(np.pi * evals / self.budget))\n                    chaotic_factor = 0.6 + 0.4 * np.sin(np.pi * evals / self.budget) * np.cos(np.pi * evals / self.budget)\n                    mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                else:\n                    mutant = self.levy_flight(pop[i])\n\n                if np.random.rand() < 0.5:\n                    mutant = self.encourage_periodicity(mutant)\n                \n                cr_dynamic = self.cr * (1 - evals / self.budget)\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Incorporate adaptive periodicity encouragement and dynamic opposition in crossover to enhance solution exploration and convergence.", "configspace": "", "generation": 13, "fitness": 0.9677355304993301, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.968 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "2f8c5418-8c08-4cbe-a882-74240e1dbd62", "metadata": {"aucs": [0.9620884680219655, 0.9788050690618287, 0.9623130544141962], "final_y": [0.16485629840118055, 0.16485652506917325, 0.16485730168119728]}, "mutation_prompt": null}
{"id": "ae4d795f-242a-48ce-b5f0-4489dc226191", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def levy_flight(self, solution):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return solution + 0.005 * step  # Minor adjustment for finer steps\n\n    def local_search(self, solution, func):\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        if result.success:  # Improve local search by considering success\n            return result.x\n        return solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                if np.random.rand() < (0.4 + 0.6 * evals / self.budget):  # Slightly adjusted for exploration\n                    indices = np.random.choice(len(pop), 3, replace=False)\n                    x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                    f_dynamic = self.f * (0.6 + 0.4 * np.sin(np.pi * evals / self.budget))\n                    chaotic_factor = 0.7 + 0.3 * np.sin(np.pi * evals / self.budget) * np.cos(np.pi * evals / self.budget)\n                    mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                else:\n                    mutant = self.levy_flight(pop[i])\n                \n                cr_dynamic = self.cr * (1 - evals / self.budget)\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "HybridQODE with enhanced local refinement and adaptive crossover to improve convergence and solution quality.", "configspace": "", "generation": 13, "fitness": 0.9592352358964081, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.959 with standard deviation 0.017. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "2f8c5418-8c08-4cbe-a882-74240e1dbd62", "metadata": {"aucs": [0.9365875842131993, 0.9788050690618287, 0.9623130544141962], "final_y": [0.1648563795441571, 0.16485652506917325, 0.16485730168119728]}, "mutation_prompt": null}
