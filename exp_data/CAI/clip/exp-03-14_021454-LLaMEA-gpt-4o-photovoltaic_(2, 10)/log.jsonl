{"id": "435fb679-b954-4ad8-aef6-90a81b8e6f0b", "solution": "import numpy as np\n\nclass HybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, dim * 5)\n        self.F = 0.8  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.temp_start = 1.0  # Initial temperature for Simulated Annealing\n        self.temp_end = 0.01  # Final temperature for Simulated Annealing\n\n    def _differential_evolution(self, func, population, scores):\n        new_population = []\n        for i, target in enumerate(population):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), func.bounds.lb, func.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, target)\n            trial_score = func(trial)\n            if trial_score < scores[i]:\n                new_population.append(trial)\n                scores[i] = trial_score\n            else:\n                new_population.append(target)\n        \n        return np.array(new_population), scores\n\n    def _simulated_annealing(self, func, best_solution, best_score, temp):\n        candidate = best_solution + np.random.uniform(-1, 1, self.dim)\n        candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n        candidate_score = func(candidate)\n        if candidate_score < best_score:\n            return candidate, candidate_score\n        else:\n            acceptance_prob = np.exp(-(candidate_score - best_score) / temp)\n            if np.random.rand() < acceptance_prob:\n                return candidate, candidate_score\n        return best_solution, best_score\n\n    def __call__(self, func):\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n        best_score = scores[best_idx]\n\n        num_evaluations = self.population_size\n        temp_decay = (self.temp_start - self.temp_end) / self.budget\n\n        while num_evaluations < self.budget:\n            population, scores = self._differential_evolution(func, population, scores)\n            best_idx = np.argmin(scores)\n            if scores[best_idx] < best_score:\n                best_solution = population[best_idx]\n                best_score = scores[best_idx]\n\n            temp = self.temp_start - num_evaluations * temp_decay\n            best_solution, best_score = self._simulated_annealing(func, best_solution, best_score, temp)\n            num_evaluations += 1\n\n        return best_solution, best_score", "name": "HybridDESA", "description": "This algorithm employs a hybrid strategy combining Differential Evolution (DE) and Simulated Annealing (SA) for exploring and exploiting the search space efficiently under a limited budget.", "configspace": "", "generation": 0, "fitness": 0.8162509399676354, "feedback": "The algorithm HybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.816 with standard deviation 0.017. And the mean value of best solutions found was 0.139 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": null, "metadata": {"aucs": [0.8045011806503151, 0.80336964716313, 0.840881992089461], "final_y": [0.1435915306928418, 0.14183293129169883, 0.132572370261416]}, "mutation_prompt": null}
{"id": "2ed8ea1b-5ef5-4042-b06d-fd698d46d76a", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population))\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            for i in range(self.population_size):\n                if np.random.rand() < self.mutation_rate:\n                    mutation_vector = np.random.uniform(lb, ub, self.dim)\n                    population[i] = 0.5 * (population[i] + mutation_vector)\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "A hybrid metaheuristic combining swarm intelligence and evolutionary strategies for efficient exploration and exploitation of black-box optimization landscapes.", "configspace": "", "generation": 0, "fitness": 0.877553917209557, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.878 with standard deviation 0.002. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": null, "metadata": {"aucs": [0.8758434561379819, 0.8805394950477136, 0.8762788004429753], "final_y": [0.12732533303981297, 0.12185431940879043, 0.12844979698004888]}, "mutation_prompt": null}
{"id": "9e71b92b-3205-4912-9e11-50ba0db1accb", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population))\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            for i in range(self.population_size):\n                if np.random.rand() < self.mutation_rate * (1 - np.tanh(personal_best_scores[i])):\n                    mutation_vector = np.random.uniform(lb, ub, self.dim)\n                    population[i] = 0.5 * (population[i] + mutation_vector)\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "The algorithm introduces adaptive mutation based on fitness to refine exploration and exploitation balance.", "configspace": "", "generation": 1, "fitness": 0.8685942419600323, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.869 with standard deviation 0.019. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "2ed8ea1b-5ef5-4042-b06d-fd698d46d76a", "metadata": {"aucs": [0.8491789376353094, 0.8944489331956582, 0.8621548550491295], "final_y": [0.12248814114275508, 0.11869949134890456, 0.1343978023180109]}, "mutation_prompt": null}
{"id": "a9edef00-826e-45cd-8eda-56d0f579e763", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population))\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            for i in range(self.population_size):\n                # Dynamic mutation rate adjustment\n                dynamic_mutation_rate = self.mutation_rate * (1 - evaluations / self.budget)\n                if np.random.rand() < dynamic_mutation_rate:\n                    mutation_vector = np.random.uniform(lb, ub, self.dim)\n                    population[i] = 0.5 * (population[i] + mutation_vector)\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Introducing a dynamic mutation rate adjustment to enhance exploration and exploitation balance over iterations.", "configspace": "", "generation": 1, "fitness": 0.833107431010947, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.833 with standard deviation 0.023. And the mean value of best solutions found was 0.140 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "2ed8ea1b-5ef5-4042-b06d-fd698d46d76a", "metadata": {"aucs": [0.8111221274611553, 0.8228114993014518, 0.8653886662702339], "final_y": [0.14146008583125125, 0.1498531338806388, 0.12933383514484065]}, "mutation_prompt": null}
{"id": "20142cae-46bb-4dae-bc57-ef7f335a1879", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.inertia_weight *= 0.99  # Adjusted line for inertia weight decay\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population))\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            for i in range(self.population_size):\n                if np.random.rand() < self.mutation_rate:\n                    mutation_vector = np.random.uniform(lb, ub, self.dim)\n                    population[i] = 0.5 * (population[i] + mutation_vector)\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced the inertia weight decay strategy to improve convergence speed and exploration-exploitation balance.", "configspace": "", "generation": 1, "fitness": 0.8801673325919376, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.880 with standard deviation 0.017. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "2ed8ea1b-5ef5-4042-b06d-fd698d46d76a", "metadata": {"aucs": [0.8622870623959878, 0.9035282046995644, 0.8746867306802603], "final_y": [0.12327230785942078, 0.1186111658506479, 0.1162802267836528]}, "mutation_prompt": null}
{"id": "0d3cf12f-6c5c-4feb-ac5b-3491116340d7", "solution": "import numpy as np\n\nclass HybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, dim * 5)\n        self.F = 0.8  # Differential weight\n        self.CR = 0.5  # Crossover probability\n        self.temp_start = 1.0  # Initial temperature for Simulated Annealing\n        self.temp_end = 0.01  # Final temperature for Simulated Annealing\n\n    def _differential_evolution(self, func, population, scores):\n        new_population = []\n        for i, target in enumerate(population):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), func.bounds.lb, func.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, target)\n            trial_score = func(trial)\n            if trial_score < scores[i]:\n                new_population.append(trial)\n                scores[i] = trial_score\n            else:\n                new_population.append(target)\n        \n        return np.array(new_population), scores\n\n    def _simulated_annealing(self, func, best_solution, best_score, temp):\n        candidate = best_solution + np.random.uniform(-1, 1, self.dim)\n        candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n        candidate_score = func(candidate)\n        if candidate_score < best_score:\n            return candidate, candidate_score\n        else:\n            acceptance_prob = np.exp(-(candidate_score - best_score) / temp)\n            if np.random.rand() < acceptance_prob:\n                return candidate, candidate_score\n        return best_solution, best_score\n\n    def __call__(self, func):\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n        best_score = scores[best_idx]\n\n        num_evaluations = self.population_size\n        temp_decay = (self.temp_start - self.temp_end) / self.budget\n\n        while num_evaluations < self.budget:\n            population, scores = self._differential_evolution(func, population, scores)\n            best_idx = np.argmin(scores)\n            if scores[best_idx] < best_score:\n                best_solution = population[best_idx]\n                best_score = scores[best_idx]\n\n            temp = self.temp_start - num_evaluations * temp_decay\n            best_solution, best_score = self._simulated_annealing(func, best_solution, best_score, temp)\n            num_evaluations += 1\n\n        return best_solution, best_score", "name": "HybridDESA", "description": "A refined hybrid algorithm combining Differential Evolution and Simulated Annealing with an adaptive crossover probability to efficiently explore and exploit the search space.", "configspace": "", "generation": 1, "fitness": 0.8017275977669192, "feedback": "The algorithm HybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.802 with standard deviation 0.013. And the mean value of best solutions found was 0.149 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "435fb679-b954-4ad8-aef6-90a81b8e6f0b", "metadata": {"aucs": [0.786557171508745, 0.801229588586021, 0.8173960332059915], "final_y": [0.1497673104807702, 0.15093164763538713, 0.14491316830900147]}, "mutation_prompt": null}
{"id": "efb56f41-ed6b-4aa9-8139-12216210b986", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.9  # Increased initial inertia weight\n        self.mutation_rate = 0.15  # Increased mutation rate\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population))\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            for i in range(self.population_size):\n                if np.random.rand() < self.mutation_rate:\n                    mutation_vector = np.random.uniform(lb, ub, self.dim)\n                    population[i] = 0.3 * (population[i] + mutation_vector)  # Adjust mutation effect\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n            self.inertia_weight = max(0.4, self.inertia_weight * 0.99)  # Dynamic adjustment of inertia weight\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "A refined hybrid metaheuristic using dynamic adaptation of inertia weight and enhanced mutation for improved exploration and convergence.", "configspace": "", "generation": 1, "fitness": 0.8580170597488869, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.858 with standard deviation 0.027. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "2ed8ea1b-5ef5-4042-b06d-fd698d46d76a", "metadata": {"aucs": [0.8223506689455738, 0.8883603792472851, 0.8633401310538016], "final_y": [0.12617161755004258, 0.12254931135013436, 0.12364984848822469]}, "mutation_prompt": null}
{"id": "ea3dbd5c-9a22-4a5c-90e4-0af31199133f", "solution": "import numpy as np\n\nclass HybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, dim * 5)\n        self.F = 0.8  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.temp_start = 1.0  # Initial temperature for Simulated Annealing\n        self.temp_end = 0.01  # Final temperature for Simulated Annealing\n\n    def _differential_evolution(self, func, population, scores):\n        new_population = []\n        for i, target in enumerate(population):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            improvement_rate = (scores[i] - np.min(scores)) / (np.max(scores) - np.min(scores) + 1e-9)\n            dynamic_F = self.F * (1 + improvement_rate)  # Adjusted differential weight\n            mutant = np.clip(a + dynamic_F * (b - c), func.bounds.lb, func.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, target)\n            trial_score = func(trial)\n            if trial_score < scores[i]:\n                new_population.append(trial)\n                scores[i] = trial_score\n            else:\n                new_population.append(target)\n        \n        return np.array(new_population), scores\n\n    def _simulated_annealing(self, func, best_solution, best_score, temp):\n        candidate = best_solution + np.random.uniform(-1, 1, self.dim)\n        candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n        candidate_score = func(candidate)\n        if candidate_score < best_score:\n            return candidate, candidate_score\n        else:\n            acceptance_prob = np.exp(-(candidate_score - best_score) / temp)\n            if np.random.rand() < acceptance_prob:\n                return candidate, candidate_score\n        return best_solution, best_score\n\n    def __call__(self, func):\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n        best_score = scores[best_idx]\n\n        num_evaluations = self.population_size\n        temp_decay = (self.temp_start - self.temp_end) / self.budget\n\n        while num_evaluations < self.budget:\n            population, scores = self._differential_evolution(func, population, scores)\n            best_idx = np.argmin(scores)\n            if scores[best_idx] < best_score:\n                best_solution = population[best_idx]\n                best_score = scores[best_idx]\n\n            temp = self.temp_start - num_evaluations * temp_decay\n            best_solution, best_score = self._simulated_annealing(func, best_solution, best_score, temp)\n            num_evaluations += 1\n\n        return best_solution, best_score", "name": "HybridDESA", "description": "Enhanced the mutation strategy in DE by adjusting the differential weight dynamically based on the improvement rate to refine sampling.", "configspace": "", "generation": 1, "fitness": 0.7878529187718359, "feedback": "The algorithm HybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.788 with standard deviation 0.025. And the mean value of best solutions found was 0.152 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "435fb679-b954-4ad8-aef6-90a81b8e6f0b", "metadata": {"aucs": [0.7522740084904381, 0.8021742325264833, 0.8091105152985865], "final_y": [0.16466700786637034, 0.1487975754420312, 0.143638467421495]}, "mutation_prompt": null}
{"id": "4349d71e-5e11-488c-b432-48c4d803b9a9", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.9  # Updated initial inertia weight\n        self.inertia_weight_min = 0.4  # New minimum inertia weight\n        self.mutation_rate = 0.1\n        self.restart_threshold = int(budget * 0.1)  # New restart threshold\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = self.population_size\n        no_improvement_count = 0  # New counter for restart strategy\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population))\n            population += velocities\n            population = np.clip(population, lb, ub)\n\n            # Adaptive inertia weight update\n            self.inertia_weight = max(self.inertia_weight * 0.99, self.inertia_weight_min)\n\n            for i in range(self.population_size):\n                if np.random.rand() < self.mutation_rate:\n                    mutation_vector = np.random.uniform(lb, ub, self.dim)\n                    population[i] = 0.5 * (population[i] + mutation_vector)\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n                    no_improvement_count = 0  # Reset counter if improvement\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n                no_improvement_count = 0  # Reset counter if improvement\n\n            no_improvement_count += 1\n            if no_improvement_count > self.restart_threshold:  # Restart mechanism trigger\n                population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                no_improvement_count = 0\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "An enhanced hybrid metaheuristic optimizer that integrates adaptive inertia weight and a strategic restart mechanism for improved convergence in black-box optimization tasks.", "configspace": "", "generation": 1, "fitness": 0.8541986475475926, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.854 with standard deviation 0.044. And the mean value of best solutions found was 0.132 (0. is the best) with standard deviation 0.015.", "error": "", "parent_id": "2ed8ea1b-5ef5-4042-b06d-fd698d46d76a", "metadata": {"aucs": [0.7925601635586934, 0.8773266976596366, 0.8927090814244477], "final_y": [0.15090510648136168, 0.12833132325499508, 0.11537930457723611]}, "mutation_prompt": null}
{"id": "5ad5e948-113e-49d6-80d1-a73e0084fda7", "solution": "import numpy as np\n\nclass HybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, dim * 5)\n        self.F_lower = 0.5\n        self.F_upper = 0.9\n        self.CR = 0.9\n        self.temp_start = 1.0\n        self.temp_end = 0.01\n        self.dynamic_population_reduction = True\n\n    def _adaptive_differential_evolution(self, func, population, scores):\n        new_population = []\n        for i, target in enumerate(population):\n            F = np.random.uniform(self.F_lower, self.F_upper)\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), func.bounds.lb, func.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, target)\n            trial_score = func(trial)\n            if trial_score < scores[i]:\n                new_population.append(trial)\n                scores[i] = trial_score\n            else:\n                new_population.append(target)\n        return np.array(new_population), scores\n\n    def _simulated_annealing(self, func, best_solution, best_score, temp):\n        candidate = best_solution + np.random.uniform(-0.5, 0.5, self.dim)\n        candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n        candidate_score = func(candidate)\n        if candidate_score < best_score or np.random.rand() < np.exp(-(candidate_score - best_score) / temp):\n            return candidate, candidate_score\n        return best_solution, best_score\n\n    def __call__(self, func):\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n        best_score = scores[best_idx]\n\n        num_evaluations = self.population_size\n        temp_decay = (self.temp_start - self.temp_end) / self.budget\n\n        while num_evaluations < self.budget:\n            population, scores = self._adaptive_differential_evolution(func, population, scores)\n            best_idx = np.argmin(scores)\n            if scores[best_idx] < best_score:\n                best_solution = population[best_idx]\n                best_score = scores[best_idx]\n\n            temp = self.temp_start - num_evaluations * temp_decay\n            best_solution, best_score = self._simulated_annealing(func, best_solution, best_score, temp)\n            num_evaluations += 1\n\n            if self.dynamic_population_reduction and num_evaluations > self.budget * 0.5:\n                self.population_size = max(4, self.population_size // 2)\n\n        return best_solution, best_score", "name": "HybridDESA", "description": "A refined hybrid strategy that integrates Adaptive Differential Evolution and Simulated Annealing with dynamic population control for enhanced exploration and exploitation under a constrained budget.", "configspace": "", "generation": 1, "fitness": 0.8045453869123397, "feedback": "The algorithm HybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.805 with standard deviation 0.015. And the mean value of best solutions found was 0.146 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "435fb679-b954-4ad8-aef6-90a81b8e6f0b", "metadata": {"aucs": [0.7836543430524755, 0.8115073021636368, 0.8184745155209071], "final_y": [0.15371118495003955, 0.14380500530854, 0.14193975393358593]}, "mutation_prompt": null}
{"id": "6debd6c3-2c9b-40d5-b0fe-3a2bb3347c7f", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            # Dynamically adjust inertia weight for improved convergence\n            self.inertia_weight = 0.4 + 0.3 * (self.budget - evaluations) / self.budget\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population))\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            for i in range(self.population_size):\n                if np.random.rand() < self.mutation_rate:\n                    mutation_vector = np.random.uniform(lb, ub, self.dim)\n                    population[i] = 0.5 * (population[i] + mutation_vector)\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "A refined hybrid metaheuristic that enhances swarm intelligence by dynamically adjusting the inertia weight for improved convergence.", "configspace": "", "generation": 1, "fitness": 0.8600927612809475, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.860 with standard deviation 0.018. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "2ed8ea1b-5ef5-4042-b06d-fd698d46d76a", "metadata": {"aucs": [0.8732960081536958, 0.8342627091906463, 0.8727195664985006], "final_y": [0.11528876777671737, 0.14558412454855063, 0.1176399828542507]}, "mutation_prompt": null}
{"id": "0f8cbea1-2396-4d2f-bf7f-7f2721ed506f", "solution": "import numpy as np\n\nclass HybridDESA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, dim * 5)\n        self.F = 0.8  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.temp_start = 1.0  # Initial temperature for Simulated Annealing\n        self.temp_end = 0.01  # Final temperature for Simulated Annealing\n\n    def _calculate_diversity(self, population):\n        return np.std(population, axis=0).mean()\n\n    def _differential_evolution(self, func, population, scores):\n        diversity = self._calculate_diversity(population)\n        adaptive_F = self.F + 0.2 * (1 - diversity)\n        adaptive_CR = self.CR * diversity\n        new_population = []\n        for i, target in enumerate(population):\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + adaptive_F * (b - c), func.bounds.lb, func.bounds.ub)\n            cross_points = np.random.rand(self.dim) < adaptive_CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, target)\n            trial_score = func(trial)\n            if trial_score < scores[i]:\n                new_population.append(trial)\n                scores[i] = trial_score\n            else:\n                new_population.append(target)\n        \n        return np.array(new_population), scores\n\n    def _simulated_annealing(self, func, best_solution, best_score, temp):\n        candidate = best_solution + np.random.uniform(-1, 1, self.dim)\n        candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n        candidate_score = func(candidate)\n        if candidate_score < best_score:\n            return candidate, candidate_score\n        else:\n            acceptance_prob = np.exp(-(candidate_score - best_score) / temp)\n            if np.random.rand() < acceptance_prob:\n                return candidate, candidate_score\n        return best_solution, best_score\n\n    def __call__(self, func):\n        population = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        scores = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(scores)\n        best_solution = population[best_idx]\n        best_score = scores[best_idx]\n\n        num_evaluations = self.population_size\n        temp_decay = (self.temp_start - self.temp_end) / self.budget\n\n        while num_evaluations < self.budget:\n            population, scores = self._differential_evolution(func, population, scores)\n            best_idx = np.argmin(scores)\n            if scores[best_idx] < best_score:\n                best_solution = population[best_idx]\n                best_score = scores[best_idx]\n\n            temp = self.temp_start - num_evaluations * temp_decay\n            best_solution, best_score = self._simulated_annealing(func, best_solution, best_score, temp)\n            num_evaluations += 1\n\n        return best_solution, best_score", "name": "HybridDESA", "description": "This algorithm enhances the HybridDESA by incorporating adaptive control of parameters F and CR based on population diversity, balancing exploration and exploitation dynamically.", "configspace": "", "generation": 1, "fitness": 0.7854627728819871, "feedback": "The algorithm HybridDESA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.785 with standard deviation 0.014. And the mean value of best solutions found was 0.155 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "435fb679-b954-4ad8-aef6-90a81b8e6f0b", "metadata": {"aucs": [0.7734097086908487, 0.8053341253020454, 0.7776444846530672], "final_y": [0.16087932775641256, 0.1504193213514412, 0.15510797039068036]}, "mutation_prompt": null}
{"id": "4fac703f-dbbd-4bef-948c-83d16035b272", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population_size = self.initial_population_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            self.inertia_weight *= 0.99  # Adjusted line for inertia weight decay\n            r1, r2 = np.random.rand(population_size, self.dim), np.random.rand(population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population))\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            for i in range(population_size):\n                if np.random.rand() < self.mutation_rate:\n                    mutation_vector = np.random.uniform(lb, ub, self.dim)\n                    population[i] = 0.5 * (population[i] + mutation_vector)\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += population_size\n\n            for i in range(population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n            if evaluations % (self.budget // 4) == 0:  # Dynamic population resizing\n                population_size = max(10, population_size // 2)\n                self.mutation_rate *= 0.9  # Adaptive mutation rate\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Introduced dynamic population resizing and adaptive mutation rate to enhance the exploration-exploitation trade-off.", "configspace": "", "generation": 2, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (10,10) (20,10) ').", "error": "ValueError('operands could not be broadcast together with shapes (10,10) (20,10) ')", "parent_id": "20142cae-46bb-4dae-bc57-ef7f335a1879", "metadata": {}, "mutation_prompt": null}
{"id": "7cdf53ec-9e99-42ab-a6f0-3a7460a55a2a", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.inertia_weight *= 0.99  # Adjusted line for inertia weight decay\n            self.mutation_rate = 0.1 * (1 - evaluations / self.budget)  # Adjust mutation rate dynamically\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population))\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            for i in range(self.population_size):\n                if np.random.rand() < self.mutation_rate:\n                    mutation_vector = np.random.uniform(lb, ub, self.dim)\n                    population[i] = 0.5 * (population[i] + mutation_vector)\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Introduce adaptive mutation rate based on iteration progress to enhance exploration-exploitation balance.", "configspace": "", "generation": 2, "fitness": 0.8768395576717197, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.877 with standard deviation 0.025. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "20142cae-46bb-4dae-bc57-ef7f335a1879", "metadata": {"aucs": [0.8799436995598311, 0.8451610974667289, 0.9054138759885993], "final_y": [0.11585658420537537, 0.13758325568412888, 0.11629027299231831]}, "mutation_prompt": null}
{"id": "f6cd82e7-70a3-42a9-97f2-c07ff16281d0", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.inertia_weight *= 0.99  # Adjusted line for inertia weight decay\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population))\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            for i in range(self.population_size):\n                if np.random.rand() < self.mutation_rate:\n                    mutation_vector = np.random.uniform(lb, ub, self.dim)\n                    population[i] = 0.5 * (population[i] + mutation_vector)\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n            if evaluations > self.budget * 0.5:\n                self.population_size = max(5, int(self.population_size * 0.9))  # Dynamic reduction of population size\n                population = population[:self.population_size]\n                personal_best_positions = personal_best_positions[:self.population_size]\n                personal_best_scores = personal_best_scores[:self.population_size]\n                velocities = velocities[:self.population_size]\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Utilize dynamic population size reduction to enhance convergence efficiency and control exploration-exploitation balance.  ", "configspace": "", "generation": 2, "fitness": 0.8787091903742219, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.879 with standard deviation 0.032. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "20142cae-46bb-4dae-bc57-ef7f335a1879", "metadata": {"aucs": [0.8436392894665903, 0.8719276724078305, 0.9205606092482448], "final_y": [0.124665338687452, 0.13082489207122983, 0.11186281012195454]}, "mutation_prompt": null}
{"id": "42f62111-8c4f-4f90-b9cf-d6ef2c5042c8", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population))\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            dynamic_mutation_rate = self.mutation_rate * (0.5 + 0.5 * np.tanh(global_best_score))\n            for i in range(self.population_size):\n                if np.random.rand() < dynamic_mutation_rate * (1 - np.tanh(personal_best_scores[i])):\n                    mutation_vector = np.random.uniform(lb, ub, self.dim)\n                    population[i] = 0.5 * (population[i] + mutation_vector)\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n            self.inertia_weight = 0.4 + 0.3 * (1 - evaluations / self.budget)\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Enhancing exploration by dynamic mutation rate adjustment and improving convergence with adaptive inertia weight.", "configspace": "", "generation": 2, "fitness": 0.8717889155399385, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.872 with standard deviation 0.014. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "9e71b92b-3205-4912-9e11-50ba0db1accb", "metadata": {"aucs": [0.8577733297676634, 0.8910487128009409, 0.8665447040512115], "final_y": [0.1294514824302112, 0.12274155367641248, 0.11689734078908665]}, "mutation_prompt": null}
{"id": "bc856b1e-3dc8-48f5-b104-d1fc37cca026", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            # Adjust inertia weight dynamically based on the global best score\n            self.inertia_weight = 0.4 + 0.3 * (1 - np.tanh(global_best_score))\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population))\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            for i in range(self.population_size):\n                if np.random.rand() < self.mutation_rate * (1 - np.tanh(personal_best_scores[i])):\n                    mutation_vector = np.random.uniform(lb, ub, self.dim)\n                    population[i] = 0.5 * (population[i] + mutation_vector)\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Introduced dynamic inertia weight adjustment based on the global best score to enhance convergence precision.", "configspace": "", "generation": 2, "fitness": 0.8563898003083991, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.856 with standard deviation 0.007. And the mean value of best solutions found was 0.129 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "9e71b92b-3205-4912-9e11-50ba0db1accb", "metadata": {"aucs": [0.8592331199149844, 0.8468983301451876, 0.8630379508650253], "final_y": [0.12180454421275877, 0.13228040941562458, 0.1323498401333536]}, "mutation_prompt": null}
{"id": "07d2269d-3c5e-4d11-8ea3-c72de8d380e4", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            iteration_ratio = evaluations / self.budget  # New line for calculating iteration ratio\n            self.cognitive_coefficient = 1.5 + 0.5 * iteration_ratio  # New line for self-adapting cognitive coefficient\n            self.social_coefficient = 1.5 - 0.5 * iteration_ratio  # New line for self-adapting social coefficient\n            self.inertia_weight *= 0.99\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population))\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            for i in range(self.population_size):\n                if np.random.rand() < self.mutation_rate:\n                    mutation_vector = np.random.uniform(lb, ub, self.dim)\n                    population[i] = 0.5 * (population[i] + mutation_vector)\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "The algorithm introduces self-adapting cognitive and social coefficients based on iteration count to better balance exploration and exploitation.", "configspace": "", "generation": 2, "fitness": 0.8895691079209856, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.890 with standard deviation 0.011. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "20142cae-46bb-4dae-bc57-ef7f335a1879", "metadata": {"aucs": [0.8792554370833634, 0.8846939482556179, 0.9047579384239753], "final_y": [0.11947724137750293, 0.12274660947653482, 0.11338884510063008]}, "mutation_prompt": null}
{"id": "856e91b7-9d98-488d-bdd6-f47c5dcf59d0", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population))\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            for i in range(self.population_size):\n                adaptive_mutation_rate = self.mutation_rate * (1 - np.tanh(personal_best_scores[i]))\n                if np.random.rand() < adaptive_mutation_rate:\n                    mutation_vector = np.random.uniform(lb, ub, self.dim)\n                    population[i] = 0.5 * (population[i] + mutation_vector)\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Introduced an adaptive strategy for mutation rate to enhance exploration and convergence.", "configspace": "", "generation": 2, "fitness": 0.8806870181820851, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.881 with standard deviation 0.022. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "9e71b92b-3205-4912-9e11-50ba0db1accb", "metadata": {"aucs": [0.8567399448923056, 0.8761387030813618, 0.9091824065725874], "final_y": [0.12570331782332977, 0.1225077916014361, 0.11261235970517391]}, "mutation_prompt": null}
{"id": "eb0b095c-bec2-46bc-b00e-33b061a9d74c", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.inertia_weight *= 0.99  # Adjusted line for inertia weight decay\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            # Change: Adapt cognitive and social coefficients based on the current best score\n            adaptive_factor = global_best_score / (np.mean(personal_best_scores) + 1e-9)\n            velocities = (self.inertia_weight * velocities +\n                          adaptive_factor * self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          adaptive_factor * self.social_coefficient * r2 * (global_best_position - population))\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            for i in range(self.population_size):\n                if np.random.rand() < self.mutation_rate:\n                    mutation_vector = np.random.uniform(lb, ub, self.dim)\n                    population[i] = 0.5 * (population[i] + mutation_vector)\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Introduced adaptive cognitive and social coefficients to enhance exploration and exploitation dynamically.", "configspace": "", "generation": 2, "fitness": 0.8522619891056363, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.852 with standard deviation 0.027. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "20142cae-46bb-4dae-bc57-ef7f335a1879", "metadata": {"aucs": [0.81946820254613, 0.8867164957892497, 0.8506012689815294], "final_y": [0.12224316077167807, 0.11897771085126119, 0.13263200463397584]}, "mutation_prompt": null}
{"id": "fbd5c422-792b-4844-9aec-ecd323205e54", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.inertia_weight *= 0.99  # Adjusted line for inertia weight decay\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population))\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            current_mutation_rate = self.mutation_rate * (1 - evaluations / self.budget)  # Line 1: Dynamic mutation rate\n            \n            for i in range(self.population_size):\n                if np.random.rand() < current_mutation_rate:  # Line 2: Using dynamic mutation rate\n                    mutation_vector = np.random.uniform(lb, ub, self.dim)\n                    population[i] = 0.5 * (population[i] + mutation_vector)\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Implemented a dynamic mutation rate adjustment based on evaluations to enhance exploration in early stages and exploitation in later stages.", "configspace": "", "generation": 2, "fitness": 0.8546487171251913, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.855 with standard deviation 0.029. And the mean value of best solutions found was 0.132 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "20142cae-46bb-4dae-bc57-ef7f335a1879", "metadata": {"aucs": [0.8164246076501197, 0.8623640366034481, 0.8851575071220059], "final_y": [0.14261029692886606, 0.13265450332900397, 0.12110845097049572]}, "mutation_prompt": null}
{"id": "85cde2dd-b1e6-4b8a-93df-5db86e347ea6", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population))\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            for i in range(self.population_size):\n                if np.random.rand() < self.mutation_rate * (1 - np.tanh(personal_best_scores[i])):\n                    mutation_vector = np.random.uniform(lb, ub, self.dim)\n                    population[i] = 0.5 * (population[i] + mutation_vector)\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n            self.mutation_rate = 0.1 + 0.2 * (1 - evaluations / self.budget)  # Dynamic mutation rate\n            self.inertia_weight = 0.4 + 0.3 * (evaluations / self.budget)  # Dynamic inertia weight\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Improved exploration-exploitation balance by dynamically adjusting mutation rate and inertia weight based on convergence progress.", "configspace": "", "generation": 2, "fitness": 0.8876496303708348, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.888 with standard deviation 0.026. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "9e71b92b-3205-4912-9e11-50ba0db1accb", "metadata": {"aucs": [0.8655681459907576, 0.8737983046144402, 0.9235824405073065], "final_y": [0.13148407992409794, 0.12761983651336695, 0.11253179145926451]}, "mutation_prompt": null}
{"id": "f5daed65-2c6e-4e5c-97e9-9ba61fe71e6a", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population))\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            for i in range(self.population_size):\n                if np.random.rand() < self.mutation_rate * (1 - np.tanh(personal_best_scores[i])):\n                    mutation_vector = np.random.uniform(lb, ub, self.dim)\n                    population[i] = 0.5 * (population[i] + mutation_vector)\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n            self.mutation_rate = 0.1 + 0.2 * (1 - evaluations / self.budget)  # Dynamic mutation rate\n            self.inertia_weight = 0.4 + 0.3 * (evaluations / self.budget)  # Dynamic inertia weight\n            self.population_size = min(int(20 + 10 * (evaluations / self.budget)), 50)  # Adaptive population size\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced exploration-exploitation balance using adaptive population size and multi-elite selection.", "configspace": "", "generation": 3, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (21,10) (20,10) ').", "error": "ValueError('operands could not be broadcast together with shapes (21,10) (20,10) ')", "parent_id": "85cde2dd-b1e6-4b8a-93df-5db86e347ea6", "metadata": {}, "mutation_prompt": null}
{"id": "cd8d46c8-2ddd-46c6-aa24-33c79509d264", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            iteration_ratio = evaluations / self.budget  # New line for calculating iteration ratio\n            self.cognitive_coefficient = 1.5 + 0.5 * iteration_ratio  # New line for self-adapting cognitive coefficient\n            self.social_coefficient = 1.5 - 0.5 * iteration_ratio  # New line for self-adapting social coefficient\n            self.inertia_weight *= 0.99 ** (1 + iteration_ratio)  # Changed line for non-linear adaptation of inertia weight\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population))\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            for i in range(self.population_size):\n                if np.random.rand() < self.mutation_rate:\n                    mutation_vector = np.random.uniform(lb, ub, self.dim)\n                    population[i] = 0.5 * (population[i] + mutation_vector)\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Introduce non-linear adaptation for inertia weight to enhance convergence dynamics.", "configspace": "", "generation": 3, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (21,10) (20,10) ').", "error": "ValueError('operands could not be broadcast together with shapes (21,10) (20,10) ')", "parent_id": "07d2269d-3c5e-4d11-8ea3-c72de8d380e4", "metadata": {}, "mutation_prompt": null}
{"id": "d911ff62-36be-4255-9f46-76b377a9bc9f", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population))\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            for i in range(self.population_size):\n                if np.random.rand() < self.mutation_rate * (1 - np.tanh(personal_best_scores[i])):\n                    mutation_vector = np.random.uniform(lb, ub, self.dim)\n                    population[i] = 0.5 * (population[i] + mutation_vector)\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n            self.mutation_rate = 0.1 + 0.2 * (1 - evaluations / self.budget)\n            self.inertia_weight = 0.4 + 0.3 * (evaluations / self.budget)\n            \n            self.social_coefficient = 1.5 + 0.5 * (evaluations / self.budget)  # Adaptive acceleration factor\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Integrate an adaptive acceleration factor to further enhance the balance between exploration and exploitation.", "configspace": "", "generation": 3, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (21,10) (20,10) ').", "error": "ValueError('operands could not be broadcast together with shapes (21,10) (20,10) ')", "parent_id": "85cde2dd-b1e6-4b8a-93df-5db86e347ea6", "metadata": {}, "mutation_prompt": null}
{"id": "0309a9b2-95ef-4a33-ba40-ce8133807f9d", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            iteration_ratio = evaluations / self.budget\n            self.cognitive_coefficient = 1.5 + 0.5 * iteration_ratio\n            self.social_coefficient = 1.5 - 0.5 * iteration_ratio\n            self.inertia_weight *= 0.99\n            self.mutation_rate = 0.05 + 0.05 * (1.0 - global_best_score / np.mean(personal_best_scores))  # Line modified for dynamic mutation rate\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population))\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            for i in range(self.population_size):\n                if np.random.rand() < self.mutation_rate:\n                    mutation_vector = np.random.uniform(lb, ub, self.dim)\n                    population[i] = 0.5 * (population[i] + mutation_vector)\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Enhance the algorithm by introducing a dynamic mutation rate that decreases as the global best score improves.", "configspace": "", "generation": 3, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (21,10) (20,10) ').", "error": "ValueError('operands could not be broadcast together with shapes (21,10) (20,10) ')", "parent_id": "07d2269d-3c5e-4d11-8ea3-c72de8d380e4", "metadata": {}, "mutation_prompt": null}
{"id": "9796ada8-f060-4c49-9f1d-6b41357308b2", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            iteration_ratio = evaluations / self.budget\n            self.cognitive_coefficient = 1.5 + 0.5 * iteration_ratio\n            self.social_coefficient = 1.5 - 0.5 * iteration_ratio\n            self.inertia_weight *= 0.99\n            self.mutation_rate = max(0.01, 0.1 * (1 - iteration_ratio))  # New line for dynamic mutation rate\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population))\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            for i in range(self.population_size):\n                if np.random.rand() < self.mutation_rate:\n                    mutation_vector = np.random.uniform(lb, ub, self.dim)\n                    population[i] = 0.5 * (population[i] + mutation_vector)\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "This refined algorithm introduces a dynamic mutation rate that decreases over time to enhance exploitation as the optimization progresses.", "configspace": "", "generation": 3, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (21,10) (20,10) ').", "error": "ValueError('operands could not be broadcast together with shapes (21,10) (20,10) ')", "parent_id": "07d2269d-3c5e-4d11-8ea3-c72de8d380e4", "metadata": {}, "mutation_prompt": null}
{"id": "dc3dd82c-f1e2-4d58-8070-c48ca647b83c", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            iteration_ratio = evaluations / self.budget\n            self.cognitive_coefficient = 1.5 + 0.5 * iteration_ratio\n            self.social_coefficient = 1.5 - 0.5 * iteration_ratio\n            self.inertia_weight *= 0.99\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population))\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            # Modified line for adaptive mutation\n            adaptive_mutation_rate = self.mutation_rate * (1 - iteration_ratio)  # Adaptive mutation strength\n            for i in range(self.population_size):\n                if np.random.rand() < adaptive_mutation_rate:\n                    mutation_vector = np.random.uniform(lb, ub, self.dim)\n                    population[i] = 0.5 * (population[i] + mutation_vector)\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Introduce adaptive mutation strength based on iteration ratio to enhance exploration in early stages of optimization.", "configspace": "", "generation": 3, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (21,10) (20,10) ').", "error": "ValueError('operands could not be broadcast together with shapes (21,10) (20,10) ')", "parent_id": "07d2269d-3c5e-4d11-8ea3-c72de8d380e4", "metadata": {}, "mutation_prompt": null}
{"id": "420f2180-2d20-4edb-9cb3-2fa18f2550b9", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            iteration_ratio = evaluations / self.budget  \n            self.cognitive_coefficient = 1.5 + 0.5 * iteration_ratio  \n            self.social_coefficient = 1.5 - 0.5 * iteration_ratio  \n            self.inertia_weight *= 0.99\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population))\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            self.mutation_rate = 0.1 + 0.3 * (1 - iteration_ratio)  # Adaptive mutation rate based on convergence progress\n            for i in range(self.population_size):\n                if np.random.rand() < self.mutation_rate:\n                    mutation_vector = np.random.uniform(lb, ub, self.dim)\n                    population[i] = 0.5 * (population[i] + mutation_vector)\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Introducing adaptive mutation strategy based on the convergence progress to enhance diversity and exploration.", "configspace": "", "generation": 3, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (21,10) (20,10) ').", "error": "ValueError('operands could not be broadcast together with shapes (21,10) (20,10) ')", "parent_id": "07d2269d-3c5e-4d11-8ea3-c72de8d380e4", "metadata": {}, "mutation_prompt": null}
{"id": "fb4d1bd6-bc2e-4682-bbed-88ae3f1e8098", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n        self.no_improvement_limit = 50  # New line for no improvement limit\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = self.population_size\n        no_improvement_counter = 0\n\n        while evaluations < self.budget:\n            iteration_ratio = evaluations / self.budget\n            self.cognitive_coefficient = 1.5 + 0.5 * iteration_ratio\n            self.social_coefficient = 1.5 - 0.5 * iteration_ratio\n            self.inertia_weight *= 0.99\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population))\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            for i in range(self.population_size):\n                if np.random.rand() < self.mutation_rate:\n                    mutation_vector = np.random.uniform(lb, ub, self.dim)\n                    population[i] = 0.5 * (population[i] + mutation_vector)\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n                no_improvement_counter = 0  # Reset counter\n            else:\n                no_improvement_counter += 1\n            \n            if no_improvement_counter >= self.no_improvement_limit:\n                population = np.random.uniform(lb, ub, (self.population_size, self.dim))  # Restart\n                no_improvement_counter = 0\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "The algorithm introduces a novel restart mechanism that triggers when no improvement is found over a set number of iterations to escape local optima.", "configspace": "", "generation": 3, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (21,10) (20,10) ').", "error": "ValueError('operands could not be broadcast together with shapes (21,10) (20,10) ')", "parent_id": "07d2269d-3c5e-4d11-8ea3-c72de8d380e4", "metadata": {}, "mutation_prompt": null}
{"id": "920ec696-2847-41e6-a0f0-1857d8d48102", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            iteration_ratio = evaluations / self.budget\n            self.cognitive_coefficient = 1.5 + 0.5 * iteration_ratio\n            self.social_coefficient = 1.5 - 0.5 * iteration_ratio\n            self.inertia_weight *= 0.985  # Changed inertia weight decay factor\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population))\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            for i in range(self.population_size):\n                if np.random.rand() < self.mutation_rate * (1 - iteration_ratio):  # Dynamic mutation rate\n                    mutation_vector = np.random.uniform(lb, ub, self.dim)\n                    population[i] = 0.5 * (population[i] + mutation_vector)\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Introduced dynamic mutation rate and adjusted inertia weight decay to enhance balance between exploration and exploitation.", "configspace": "", "generation": 3, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (21,10) (20,10) ').", "error": "ValueError('operands could not be broadcast together with shapes (21,10) (20,10) ')", "parent_id": "07d2269d-3c5e-4d11-8ea3-c72de8d380e4", "metadata": {}, "mutation_prompt": null}
{"id": "374ffd24-9e37-4f79-920c-1c858a7d4a4c", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population))\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            for i in range(self.population_size):\n                if np.random.rand() < self.mutation_rate * (1 - np.tanh(personal_best_scores[i])):\n                    mutation_vector = np.random.uniform(lb, ub, self.dim)\n                    population[i] = 0.5 * (population[i] + mutation_vector)\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n            self.mutation_rate = 0.1 + 0.2 * (1 - evaluations / self.budget)  # Dynamic mutation rate\n            self.inertia_weight = 0.4 + 0.3 * (evaluations / self.budget)  # Dynamic inertia weight\n            self.social_coefficient = 1.5 + 0.5 * (evaluations / self.budget)  # Dynamic social coefficient\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced social coefficient adaptation based on convergence to improve exploitation during late optimization stages.", "configspace": "", "generation": 3, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (21,10) (20,10) ').", "error": "ValueError('operands could not be broadcast together with shapes (21,10) (20,10) ')", "parent_id": "85cde2dd-b1e6-4b8a-93df-5db86e347ea6", "metadata": {}, "mutation_prompt": null}
{"id": "41a087e3-ff9b-46b5-88c4-816c5fca007a", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            iteration_ratio = evaluations / self.budget  \n            self.cognitive_coefficient = 1.5 + 0.5 * iteration_ratio\n            self.social_coefficient = 1.5 - 0.5 * iteration_ratio\n            self.inertia_weight *= 0.99 ** (1 + iteration_ratio)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population))\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            for i in range(self.population_size):\n                if np.random.rand() < self.mutation_rate:\n                    mutation_vector = np.random.uniform(lb, ub, self.dim)\n                    population[i] = 0.5 * (population[i] + mutation_vector)\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n            self.population_size += 1  # Change to incrementally increase population size.\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Enhance convergence by incrementally increasing population size during iterations.", "configspace": "", "generation": 4, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (21,10) (20,10) ').", "error": "ValueError('operands could not be broadcast together with shapes (21,10) (20,10) ')", "parent_id": "cd8d46c8-2ddd-46c6-aa24-33c79509d264", "metadata": {}, "mutation_prompt": null}
{"id": "07cb1be8-606f-48dc-b9ca-26ddc8512023", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population))\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            for i in range(self.population_size):\n                if np.random.rand() < self.mutation_rate * (1 - np.tanh(personal_best_scores[i])):\n                    mutation_vector = np.random.uniform(lb, ub, self.dim)\n                    population[i] = 0.5 * (population[i] + mutation_vector)\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += self.population_size\n\n            for i in range(len(population)):  # Corrected line: Use `len(population)` instead of `self.population_size`\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n            self.mutation_rate = 0.1 + 0.2 * (1 - evaluations / self.budget)\n            self.inertia_weight = 0.4 + 0.3 * (evaluations / self.budget)\n            self.population_size = min(int(20 + 10 * (evaluations / self.budget)), 50)\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced exploration-exploitation balance using adaptive population size and multi-elite selection, with corrected index handling for dynamic population changes.", "configspace": "", "generation": 4, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (21,10) (20,10) ').", "error": "ValueError('operands could not be broadcast together with shapes (21,10) (20,10) ')", "parent_id": "f5daed65-2c6e-4e5c-97e9-9ba61fe71e6a", "metadata": {}, "mutation_prompt": null}
{"id": "96877f9d-a5cf-4f6c-b489-e16c1d5c176a", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population))\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            for i in range(self.population_size):\n                if np.random.rand() < self.mutation_rate * (1 - np.tanh(personal_best_scores[i])):\n                    mutation_vector = np.random.uniform(lb, ub, self.dim)\n                    population[i] = 0.5 * (population[i] + mutation_vector)\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n            self.mutation_rate = 0.1 + 0.2 * (1 - evaluations / self.budget)  # Dynamic mutation rate\n            self.inertia_weight = 0.4 + 0.3 * (evaluations / self.budget)  # Dynamic inertia weight\n            self.population_size = min(int(20 + 10 * (evaluations / self.budget)), 50)  # Adaptive population size\n            velocities = velocities[:self.population_size]  # Adjust velocities' size\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Improved handling of adaptive population size adjustments to maintain consistent array operations.", "configspace": "", "generation": 4, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (21,10) (20,10) ').", "error": "ValueError('operands could not be broadcast together with shapes (21,10) (20,10) ')", "parent_id": "f5daed65-2c6e-4e5c-97e9-9ba61fe71e6a", "metadata": {}, "mutation_prompt": null}
{"id": "ffee83d6-eaa4-41f7-afd7-6a55af434d28", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population))\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            for i in range(self.population_size):\n                if np.random.rand() < self.mutation_rate * (1 - np.tanh(personal_best_scores[i])):\n                    mutation_vector = np.random.uniform(lb, ub, self.dim)\n                    population[i] = 0.5 * (population[i] + mutation_vector)\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n            self.mutation_rate = 0.1 + 0.2 * (1 - evaluations / self.budget)  # Dynamic mutation rate\n            self.inertia_weight = 0.4 + 0.3 * (evaluations / self.budget)  # Dynamic inertia weight\n            self.population_size = min(int(20 + 10 * (evaluations // self.budget)), 50)  # Adaptive population size\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Utilize enhanced adaptive control for population updating to maintain solution diversity in varying dimensions.", "configspace": "", "generation": 4, "fitness": 0.8680046016060796, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.868 with standard deviation 0.007. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "f5daed65-2c6e-4e5c-97e9-9ba61fe71e6a", "metadata": {"aucs": [0.8685023374507379, 0.8593506831375711, 0.87616078422993], "final_y": [0.12612929762086944, 0.11963066967642566, 0.12268069711371365]}, "mutation_prompt": null}
{"id": "53204356-b43b-4716-ac3d-1bf02474e57a", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            iteration_ratio = evaluations / self.budget\n            self.cognitive_coefficient = 1.5 + 0.5 * iteration_ratio\n            self.social_coefficient = 1.5 - 0.5 * iteration_ratio\n            self.inertia_weight *= 0.99 ** (1 + iteration_ratio)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population))\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            dynamic_mutation_rate = self.mutation_rate * (1 - iteration_ratio)  # Changed line for dynamic mutation rate\n            for i in range(self.population_size):\n                if np.random.rand() < dynamic_mutation_rate:  # Changed line to use dynamic mutation rate\n                    mutation_vector = np.random.uniform(lb, ub, self.dim)\n                    population[i] = 0.5 * (population[i] + mutation_vector)\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Introduce dynamic mutation rate based on iteration progress to enhance population diversity.", "configspace": "", "generation": 4, "fitness": 0.8722305985813956, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.872 with standard deviation 0.024. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "cd8d46c8-2ddd-46c6-aa24-33c79509d264", "metadata": {"aucs": [0.8390522515584955, 0.8839710071737603, 0.8936685370119312], "final_y": [0.13048804609655673, 0.12154569648769775, 0.11472681219192171]}, "mutation_prompt": null}
{"id": "cc8c602c-6b69-4788-9d2d-f1dd301bb6e6", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population))\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            for i in range(self.population_size):\n                if np.random.rand() < self.mutation_rate * (1 - np.tanh(personal_best_scores[i])):\n                    mutation_vector = np.random.uniform(lb, ub, self.dim)\n                    population[i] = 0.5 * (population[i] + mutation_vector)\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n            self.mutation_rate = 0.1 + 0.2 * (1 - evaluations / self.budget)  # Dynamic mutation rate\n            self.inertia_weight = 0.4 + 0.3 * (evaluations / self.budget)  # Dynamic inertia weight\n            self.population_size = len(population)  # Ensure population size consistency\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Enhance algorithm by ensuring population size consistency during update operations.", "configspace": "", "generation": 4, "fitness": 0.858544364944669, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.859 with standard deviation 0.017. And the mean value of best solutions found was 0.129 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "f5daed65-2c6e-4e5c-97e9-9ba61fe71e6a", "metadata": {"aucs": [0.8511399465216729, 0.8420627211420433, 0.8824304271702911], "final_y": [0.1308234950421503, 0.14309367995323607, 0.11387476619453496]}, "mutation_prompt": null}
{"id": "bc3920a0-d91e-4020-96a5-a07de5ee88e7", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n        self.de_mutation_factor = 0.8  # New parameter for DE\n        self.de_crossover_rate = 0.7  # New parameter for DE\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            diversity = np.std(population, axis=0).mean()\n            self.inertia_weight *= 0.99 ** (1 + diversity)  # Adapt inertia based on diversity\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population))\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            for i in range(self.population_size):\n                if np.random.rand() < self.mutation_rate:\n                    indices = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                    mutant_vector = np.clip(a + self.de_mutation_factor * (b - c), lb, ub)\n                    crossover = np.random.rand(self.dim) < self.de_crossover_rate\n                    trial_vector = np.where(crossover, mutant_vector, population[i])\n                    population[i] = trial_vector\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Integrate differential evolution for enhanced global search and adaptively update parameters based on population diversity.", "configspace": "", "generation": 4, "fitness": 0.9025909798658316, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.903 with standard deviation 0.012. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "cd8d46c8-2ddd-46c6-aa24-33c79509d264", "metadata": {"aucs": [0.9128236116738339, 0.8851015749925695, 0.9098477529310912], "final_y": [0.1151888329224049, 0.12004487704350753, 0.11342529549391334]}, "mutation_prompt": null}
{"id": "4fcc4aab-49a1-4c3b-b167-2877b56c8eba", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            iteration_ratio = evaluations / self.budget  # New line for calculating iteration ratio\n            self.cognitive_coefficient = 1.5 + 0.5 * iteration_ratio  # New line for self-adapting cognitive coefficient\n            self.social_coefficient = 1.5 - 0.5 * iteration_ratio  # New line for self-adapting social coefficient\n            self.inertia_weight *= 0.99 ** (1 + iteration_ratio)  # Changed line for non-linear adaptation of inertia weight\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population))\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            for i in range(self.population_size):\n                if np.random.rand() < self.mutation_rate:\n                    mutation_vector = np.random.uniform(lb, ub, self.dim)\n                    population[i] = 0.5 * (population[i] + mutation_vector)\n                else:\n                    population[i] = np.random.uniform(lb, ub, self.dim)  # Ensures diversity with uniform fallback\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Introduce a uniform mutation as a fallback when mutation conditions aren't met to ensure diversity.", "configspace": "", "generation": 4, "fitness": 0.8652672567337459, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.865 with standard deviation 0.032. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "cd8d46c8-2ddd-46c6-aa24-33c79509d264", "metadata": {"aucs": [0.8250547188395876, 0.8673636219992089, 0.9033834293624411], "final_y": [0.13352832415698623, 0.12811253276095502, 0.11098139576229593]}, "mutation_prompt": null}
{"id": "9a8e6695-39db-4d72-aed6-434a6af1149a", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n        self.dynamic_mutation = True  # New line for enabling dynamic mutation rate\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            iteration_ratio = evaluations / self.budget\n            self.cognitive_coefficient = 1.5 + 0.5 * iteration_ratio\n            self.social_coefficient = 1.5 - 0.5 * iteration_ratio\n            self.inertia_weight *= 0.99 ** (1 + iteration_ratio)\n            if self.dynamic_mutation:  # New block for dynamic mutation rate adjustment\n                self.mutation_rate = 0.1 + 0.4 * (1 - iteration_ratio)\n\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population))\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            for i in range(self.population_size):\n                if np.random.rand() < self.mutation_rate:\n                    neighbor_idx = (i + 1) % self.population_size  # New line for dynamic neighborhood selection\n                    mutation_vector = population[neighbor_idx]  # Changed mutation strategy to use neighbor\n                    population[i] = 0.5 * (population[i] + mutation_vector)\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Integrate self-adaptive mutation rate and dynamic neighborhood learning to enhance solution diversity and convergence speed.", "configspace": "", "generation": 4, "fitness": 0.8667487693215614, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.867 with standard deviation 0.021. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "cd8d46c8-2ddd-46c6-aa24-33c79509d264", "metadata": {"aucs": [0.8823667175560237, 0.8806831373063657, 0.8371964531022948], "final_y": [0.11899746438926206, 0.11826455619895426, 0.11683658141649622]}, "mutation_prompt": null}
{"id": "75fcc16a-3594-4da3-88ed-6ae8be187e1f", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n        \n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = self.population_size\n\n        memory_size = self.budget // 10  # New line for memory size\n        memory = np.full((memory_size, self.dim), np.inf)  # New line for memory initialization\n        memory_scores = np.full(memory_size, np.inf)  # New line for memory scores\n\n        while evaluations < self.budget:\n            iteration_ratio = evaluations / self.budget\n            self.cognitive_coefficient = 1.5 + 0.5 * iteration_ratio\n            self.social_coefficient = 1.5 - 0.5 * iteration_ratio\n            self.inertia_weight *= 0.99 ** (1 + iteration_ratio)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population))\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            for i in range(self.population_size):\n                if np.random.rand() < self.mutation_rate:\n                    mutation_vector = np.random.uniform(lb, ub, self.dim)\n                    population[i] = 0.5 * (population[i] + mutation_vector)\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n            # New lines to update memory\n            memory_idx = evaluations % memory_size\n            memory[memory_idx] = global_best_position\n            memory_scores[memory_idx] = global_best_score\n            # New line to use best memory position if better\n            best_memory_idx = np.argmin(memory_scores)\n            if memory_scores[best_memory_idx] < global_best_score:\n                global_best_position = memory[best_memory_idx]\n                global_best_score = memory_scores[best_memory_idx]\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Integration of adaptive memory strategies with non-linear inertia weighting for improved convergence in diverse search spaces.", "configspace": "", "generation": 4, "fitness": 0.8712142424432056, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.871 with standard deviation 0.009. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "cd8d46c8-2ddd-46c6-aa24-33c79509d264", "metadata": {"aucs": [0.882008128355914, 0.8725942939870548, 0.859040304986648], "final_y": [0.12027923924447903, 0.11801941545691685, 0.12633611146523593]}, "mutation_prompt": null}
{"id": "ef56b0a4-58fe-4b50-9222-e116db9173f9", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            iteration_ratio = evaluations / self.budget\n            self.cognitive_coefficient = 1.5 + 0.5 * iteration_ratio\n            self.social_coefficient = 1.5 - 0.5 * iteration_ratio\n            self.inertia_weight *= 0.99 ** (1 + iteration_ratio)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population))\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            dynamic_mutation_rate = self.mutation_rate * (1 - iteration_ratio)\n            for i in range(self.population_size):\n                if np.random.rand() < dynamic_mutation_rate:\n                    mutation_vector = np.random.uniform(lb, ub, self.dim)\n                    population[i] = 0.5 * (population[i] + mutation_vector)\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n            self.population_size = int(20 * (1 - 0.5 * iteration_ratio))  # Changed line for dynamic population size\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Introduce a dynamic population size that decreases over time to balance exploration and exploitation.", "configspace": "", "generation": 5, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (19,10) (20,10) ').", "error": "ValueError('operands could not be broadcast together with shapes (19,10) (20,10) ')", "parent_id": "53204356-b43b-4716-ac3d-1bf02474e57a", "metadata": {}, "mutation_prompt": null}
{"id": "633130f8-d985-4cc4-b8c5-aeee956ce53a", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            iteration_ratio = evaluations / self.budget\n            self.cognitive_coefficient = 1.5 + 0.5 * iteration_ratio\n            self.social_coefficient = 1.5 - 0.5 * iteration_ratio\n            self.inertia_weight = 0.9 - 0.5 * iteration_ratio  # Changed line for adaptive inertia weight\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population))\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            dynamic_mutation_rate = self.mutation_rate * (1 - iteration_ratio)  \n            for i in range(self.population_size):\n                if np.random.rand() < dynamic_mutation_rate:\n                    mutation_vector = np.random.uniform(lb, ub, self.dim)\n                    neighbors = [population[(i+j) % self.population_size] for j in range(-1, 2)]  # Changed for neighborhood\n                    population[i] = 0.5 * (neighbors[np.random.randint(0, 3)] + mutation_vector)  # Changed to use neighborhood-based crossover\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Introduce adaptive inertia weight and neighborhood-based crossover to enhance exploration and exploitation balance.", "configspace": "", "generation": 5, "fitness": 0.8286603812463054, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.829 with standard deviation 0.017. And the mean value of best solutions found was 0.143 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "53204356-b43b-4716-ac3d-1bf02474e57a", "metadata": {"aucs": [0.8119989865813924, 0.8524317360274677, 0.8215504211300559], "final_y": [0.14751276332590313, 0.13810343935059344, 0.1426782129784483]}, "mutation_prompt": null}
{"id": "85460744-9147-44bd-ae4e-890b5ea804b3", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            iteration_ratio = evaluations / self.budget\n            self.cognitive_coefficient = 1.5 + 0.5 * iteration_ratio\n            self.social_coefficient = 1.5 - 0.5 * iteration_ratio\n            self.inertia_weight *= np.exp(-0.01 * (1 + iteration_ratio))  # Changed line for exponential decay\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population))\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            dynamic_mutation_rate = self.mutation_rate * (1 - iteration_ratio)\n            for i in range(self.population_size):\n                if np.random.rand() < dynamic_mutation_rate:\n                    mutation_vector = np.random.uniform(lb, ub, self.dim)\n                    population[i] = 0.5 * (population[i] + mutation_vector)\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Adjust the inertia weight decay by incorporating an exponential function for balancing exploration and exploitation during optimization.", "configspace": "", "generation": 5, "fitness": 0.841421486266776, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.841 with standard deviation 0.013. And the mean value of best solutions found was 0.130 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "53204356-b43b-4716-ac3d-1bf02474e57a", "metadata": {"aucs": [0.8596510111501703, 0.834204593026458, 0.8304088546236994], "final_y": [0.11438951826597266, 0.13592195360779513, 0.13934654834485694]}, "mutation_prompt": null}
{"id": "defd091f-8b1d-42dd-9f3a-75351ca10d77", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            iteration_ratio = evaluations / self.budget\n            self.cognitive_coefficient = 1.5 + 0.5 * iteration_ratio\n            self.social_coefficient = 1.5 - 0.5 * iteration_ratio\n            self.inertia_weight *= 0.995 ** (1 + iteration_ratio)  # Changed line for adjusted inertia decay strategy\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population))\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            dynamic_mutation_rate = self.mutation_rate * (1 - iteration_ratio)\n            for i in range(self.population_size):\n                if np.random.rand() < dynamic_mutation_rate:\n                    mutation_vector = np.random.uniform(lb, ub, self.dim)\n                    population[i] = 0.5 * (population[i] + mutation_vector)\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Adjust inertia decay strategy to adaptively enhance exploration and exploitation balance.", "configspace": "", "generation": 5, "fitness": 0.8472876721858098, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.847 with standard deviation 0.013. And the mean value of best solutions found was 0.136 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "53204356-b43b-4716-ac3d-1bf02474e57a", "metadata": {"aucs": [0.8616632445722243, 0.8298831810857726, 0.8503165908994326], "final_y": [0.1338428533374555, 0.13887173058165925, 0.13403059388375294]}, "mutation_prompt": null}
{"id": "e2453a42-8c09-41cd-aeee-dc50517ae25a", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.9  # Changed line for adaptive inertia weight\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            iteration_ratio = evaluations / self.budget\n            self.cognitive_coefficient = 1.5 + 0.5 * iteration_ratio\n            self.social_coefficient = 1.5 - 0.5 * iteration_ratio\n            self.inertia_weight = 0.9 * (0.5 ** iteration_ratio)  # Changed line for adaptive inertia weight decay\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population))\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            dynamic_mutation_rate = self.mutation_rate * (1 - iteration_ratio)\n            for i in range(self.population_size):\n                if np.random.rand() < dynamic_mutation_rate:\n                    mutation_vector = np.random.uniform(lb, ub, self.dim)\n                    population[i] = 0.5 * (population[i] + mutation_vector)\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Integrate adaptive inertia weight decay based on function evaluation ratio to balance exploration and exploitation.", "configspace": "", "generation": 5, "fitness": 0.8328338901719166, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.833 with standard deviation 0.011. And the mean value of best solutions found was 0.132 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "53204356-b43b-4716-ac3d-1bf02474e57a", "metadata": {"aucs": [0.8475302436617234, 0.8281676957568196, 0.822803731097207], "final_y": [0.12020071744315919, 0.1446401134989248, 0.13080162043937227]}, "mutation_prompt": null}
{"id": "5b6b7a41-1e56-4b4c-bef3-769f0003774b", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            iteration_ratio = evaluations / self.budget\n            self.cognitive_coefficient = 1.5 + 0.5 * iteration_ratio\n            self.social_coefficient = 1.5 - 0.5 * iteration_ratio\n            self.inertia_weight *= 0.99 ** (1 + iteration_ratio)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population))\n            velocities *= 1 - iteration_ratio  # Changed line for scaling velocities\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            dynamic_mutation_rate = self.mutation_rate * (1 - iteration_ratio)\n            for i in range(self.population_size):\n                if np.random.rand() < dynamic_mutation_rate:\n                    mutation_vector = np.random.uniform(lb, ub, self.dim)\n                    population[i] = 0.5 * (population[i] + mutation_vector)\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Introduce velocity scaling based on iteration progress to improve exploration-exploitation balance.", "configspace": "", "generation": 5, "fitness": 0.823112107081082, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.823 with standard deviation 0.004. And the mean value of best solutions found was 0.144 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "53204356-b43b-4716-ac3d-1bf02474e57a", "metadata": {"aucs": [0.8181821058590939, 0.8246619660578988, 0.8264922493262534], "final_y": [0.14946260039849557, 0.13810895093098474, 0.14547965609456093]}, "mutation_prompt": null}
{"id": "0b34fc33-7152-4179-8a06-a20f12ebdf7e", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n        self.de_mutation_factor = 0.8  # New parameter for DE\n        self.de_crossover_rate = 0.7  # New parameter for DE\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            diversity = np.std(population, axis=0).mean()\n            self.inertia_weight *= 0.99 ** (1 + diversity)  # Adapt inertia based on diversity\n            self.mutation_rate = 0.1 + 0.9 * diversity  # Adaptive mutation rate based on convergence\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population))\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            for i in range(self.population_size):\n                if np.random.rand() < self.mutation_rate:\n                    indices = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                    mutant_vector = np.clip(a + self.de_mutation_factor * (b - c), lb, ub)\n                    crossover = np.random.rand(self.dim) < self.de_crossover_rate\n                    trial_vector = np.where(crossover, mutant_vector, population[i])\n                    population[i] = trial_vector\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Implement adaptive mutation rate based on population convergence to enhance exploration.", "configspace": "", "generation": 5, "fitness": 0.828882642132684, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.829 with standard deviation 0.012. And the mean value of best solutions found was 0.144 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "bc3920a0-d91e-4020-96a5-a07de5ee88e7", "metadata": {"aucs": [0.8127066848103759, 0.8353231640186449, 0.8386180775690315], "final_y": [0.14858967967106773, 0.14378342208136008, 0.14008979830574586]}, "mutation_prompt": null}
{"id": "2f2461fb-f275-459c-b907-bca76a784990", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n        self.de_mutation_factor = 0.8  # New parameter for DE\n        self.de_crossover_rate = 0.7  # New parameter for DE\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            diversity = np.std(population, axis=0).mean()\n            self.inertia_weight *= 0.99 ** (1 + diversity)  # Adapt inertia based on diversity\n            self.de_mutation_factor = 0.5 + 0.3 * diversity  # Dynamic DE mutation factor\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population))\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            for i in range(self.population_size):\n                if np.random.rand() < self.mutation_rate:\n                    indices = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                    mutant_vector = np.clip(a + self.de_mutation_factor * (b - c), lb, ub)\n                    crossover = np.random.rand(self.dim) < self.de_crossover_rate\n                    trial_vector = np.where(crossover, mutant_vector, population[i])\n                    population[i] = trial_vector\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Enhance exploration by adjusting DE mutation factor dynamically based on population diversity.", "configspace": "", "generation": 5, "fitness": 0.8444332509143555, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.844 with standard deviation 0.026. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "bc3920a0-d91e-4020-96a5-a07de5ee88e7", "metadata": {"aucs": [0.8807167041077797, 0.8290048776156957, 0.823578171019591], "final_y": [0.12518540090015906, 0.13042632224323547, 0.14368639419248175]}, "mutation_prompt": null}
{"id": "9f39c255-3280-46f9-8a59-fda275256ee6", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            iteration_ratio = evaluations / self.budget\n            self.cognitive_coefficient = 1.5 + 0.5 * iteration_ratio\n            self.social_coefficient = 1.5 - 0.5 * iteration_ratio\n            self.inertia_weight *= 0.95 ** (1 + iteration_ratio)  # Changed line for more aggressive inertia weight adaptation\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population))\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            dynamic_mutation_rate = self.mutation_rate * (1 - iteration_ratio)\n            for i in range(self.population_size):\n                if np.random.rand() < dynamic_mutation_rate:\n                    mutation_vector = np.random.uniform(lb, ub, self.dim)\n                    population[i] = 0.5 * (population[i] + mutation_vector)\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Enhance convergence speed by incorporating an adaptive inertia weight that decreases more aggressively with iteration progress.", "configspace": "", "generation": 5, "fitness": 0.8469564575476598, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.847 with standard deviation 0.027. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "53204356-b43b-4716-ac3d-1bf02474e57a", "metadata": {"aucs": [0.8797424654464326, 0.8137291519571573, 0.8473977552393894], "final_y": [0.11580145749745863, 0.14502262292078216, 0.13360367957701302]}, "mutation_prompt": null}
{"id": "65052e18-ed87-487e-8c98-b5a84f71126b", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n        self.de_mutation_factor = 0.8  # New parameter for DE\n        self.de_crossover_rate = 0.7  # New parameter for DE\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            diversity = np.std(population, axis=0).mean()\n            self.inertia_weight *= 0.99 ** (1 + diversity) * ((self.budget - evaluations) / self.budget)  # Adjust inertia\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population))\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            for i in range(self.population_size):\n                if np.random.rand() < self.mutation_rate:\n                    indices = [idx for idx in range(self.population_size) if idx != i]\n                    a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                    mutant_vector = np.clip(a + self.de_mutation_factor * (b - c), lb, ub)\n                    crossover = np.random.rand(self.dim) < self.de_crossover_rate\n                    trial_vector = np.where(crossover, mutant_vector, population[i])\n                    population[i] = trial_vector\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Enhance solution diversity by varying inertia weight dynamically based on iteration count.", "configspace": "", "generation": 5, "fitness": 0.8361435946464165, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.836 with standard deviation 0.035. And the mean value of best solutions found was 0.140 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "bc3920a0-d91e-4020-96a5-a07de5ee88e7", "metadata": {"aucs": [0.8243716352662442, 0.8007094635374491, 0.8833496851355563], "final_y": [0.14360012923165522, 0.14901011607949022, 0.1273369555874464]}, "mutation_prompt": null}
{"id": "2921b165-8b36-4ae8-b0c6-e290677b990c", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            iteration_ratio = evaluations / self.budget\n            self.cognitive_coefficient = 1.5 + 0.5 * iteration_ratio\n            self.social_coefficient = 1.5 - 0.5 * iteration_ratio\n            self.inertia_weight *= 0.995 ** (1 + iteration_ratio)\n            self.population_size = int(20 * (1 - iteration_ratio)) + 1  # Changed line for adaptive population size\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population))\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            dynamic_mutation_rate = self.mutation_rate * (1 - iteration_ratio)\n            for i in range(self.population_size):\n                if np.random.rand() < dynamic_mutation_rate:\n                    mutation_vector = np.random.uniform(lb, ub, self.dim)\n                    population[i] = 0.5 * (population[i] + mutation_vector)\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Introduced adaptive population size strategy to dynamically adjust exploration and exploitation balance.", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (19,10) (20,10) ').", "error": "ValueError('operands could not be broadcast together with shapes (19,10) (20,10) ')", "parent_id": "defd091f-8b1d-42dd-9f3a-75351ca10d77", "metadata": {}, "mutation_prompt": null}
{"id": "2385d99c-6d82-42f3-80c1-f96b42aab070", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            iteration_ratio = evaluations / self.budget\n            self.cognitive_coefficient = 1.5 + 0.5 * iteration_ratio\n            self.social_coefficient = 1.5 - 0.5 * iteration_ratio\n            self.inertia_weight *= 0.95 ** (1 + iteration_ratio)  # Changed line for more aggressive inertia weight adaptation\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population))\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            dynamic_mutation_rate = self.mutation_rate * (1 - iteration_ratio) ** 2  # Modified line: Adjusted mutation rate for better exploration\n            for i in range(self.population_size):\n                if np.random.rand() < dynamic_mutation_rate:\n                    mutation_vector = np.random.uniform(lb, ub, self.dim)\n                    population[i] = 0.5 * (population[i] + mutation_vector)\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Introduce adaptive dynamic mutation to enhance exploration as the algorithm progresses.", "configspace": "", "generation": 6, "fitness": 0.8687040895151497, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.869 with standard deviation 0.012. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "9f39c255-3280-46f9-8a59-fda275256ee6", "metadata": {"aucs": [0.8535493256052751, 0.8693675571786242, 0.8831953857615494], "final_y": [0.1258361393538543, 0.12719791284313453, 0.12787899282409687]}, "mutation_prompt": null}
{"id": "1f6d919d-6c7b-4452-982d-492700c790e8", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            iteration_ratio = evaluations / self.budget\n            self.cognitive_coefficient = 1.5 + 0.5 * iteration_ratio\n            self.social_coefficient = 1.5 - 0.5 * iteration_ratio\n            \n            self.inertia_weight = 0.7 * (0.995 ** (1 + iteration_ratio))  # Changed line for refined inertia strategy\n            velocity_scaling = np.exp(-iteration_ratio)  # Changed line for adaptive velocity scaling\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population)) * velocity_scaling\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            dynamic_mutation_rate = self.mutation_rate * (1 - iteration_ratio)\n            for i in range(self.population_size):\n                if np.random.rand() < dynamic_mutation_rate:\n                    mutation_vector = np.random.uniform(lb, ub, self.dim)\n                    population[i] = 0.5 * (population[i] + mutation_vector)\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Refine inertia strategy and enhance exploration using adaptive velocity scaling.", "configspace": "", "generation": 6, "fitness": 0.8925930853037064, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.893 with standard deviation 0.010. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "defd091f-8b1d-42dd-9f3a-75351ca10d77", "metadata": {"aucs": [0.9049955424407765, 0.891080178276851, 0.8817035351934916], "final_y": [0.11279879655015157, 0.11790935818924397, 0.11513835678705875]}, "mutation_prompt": null}
{"id": "e7d5c049-9f85-45d1-930e-89ec255f9e0d", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            iteration_ratio = evaluations / self.budget\n            self.cognitive_coefficient = 1.5 + 0.5 * iteration_ratio\n            self.social_coefficient = 1.5 - 0.5 * iteration_ratio\n            self.inertia_weight *= np.exp(-0.05 * iteration_ratio)  # Changed line for exponential decay in inertia weight\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population))\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            dynamic_mutation_rate = self.mutation_rate * (1 - iteration_ratio)\n            for i in range(self.population_size):\n                if np.random.rand() < dynamic_mutation_rate:\n                    mutation_vector = np.random.uniform(lb, ub, self.dim)\n                    population[i] = 0.5 * (population[i] + mutation_vector)\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Introduce exponential decay in inertia weight for more nuanced balance between exploration and exploitation.", "configspace": "", "generation": 6, "fitness": 0.8869709698022924, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.887 with standard deviation 0.018. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "9f39c255-3280-46f9-8a59-fda275256ee6", "metadata": {"aucs": [0.8624668550598518, 0.9039821516587907, 0.8944639026882347], "final_y": [0.11617484709368209, 0.11744509944929526, 0.11326812488658056]}, "mutation_prompt": null}
{"id": "164b61d7-dd03-4ec9-a398-aa695fa83403", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            iteration_ratio = evaluations / self.budget\n            self.cognitive_coefficient = 1.5 + 0.3 * np.sin(2 * np.pi * iteration_ratio)  # Changed line for dynamic scaling\n            self.social_coefficient = 1.5 - 0.3 * np.sin(2 * np.pi * iteration_ratio)  # Changed line for dynamic scaling\n            self.inertia_weight *= 0.995 ** (1 + iteration_ratio)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population))\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            dynamic_mutation_rate = self.mutation_rate * (1 - iteration_ratio)\n            for i in range(self.population_size):\n                if np.random.rand() < dynamic_mutation_rate:\n                    mutation_vector = np.random.uniform(lb, ub, self.dim)\n                    population[i] = 0.5 * (population[i] + mutation_vector)\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Introduce dynamic scaling to the cognitive and social coefficients for improved adaptive response to search landscape variations.", "configspace": "", "generation": 6, "fitness": 0.8781203785583108, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.878 with standard deviation 0.007. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "defd091f-8b1d-42dd-9f3a-75351ca10d77", "metadata": {"aucs": [0.8697086453230759, 0.8785015513199289, 0.8861509390319275], "final_y": [0.12978007865182328, 0.11668656392833487, 0.11559653552829274]}, "mutation_prompt": null}
{"id": "31525d1b-6af0-43f7-9762-58120a57e03d", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            iteration_ratio = evaluations / self.budget\n            self.cognitive_coefficient = 1.5 + 0.5 * iteration_ratio\n            self.social_coefficient = 1.5 - 0.5 * iteration_ratio\n            self.inertia_weight *= 0.995 ** (1 + iteration_ratio)  # Changed line for adjusted inertia decay strategy\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population))\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            dynamic_mutation_rate = self.mutation_rate * (1 - iteration_ratio)\n            scale = (ub - lb) * iteration_ratio  # Added line for adaptive mutation scaling\n            for i in range(self.population_size):\n                if np.random.rand() < dynamic_mutation_rate:\n                    mutation_vector = np.random.uniform(lb, ub, self.dim)\n                    population[i] = 0.5 * (population[i] + mutation_vector * scale)\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Integrate adaptive mutation scaling to enhance exploration by adjusting mutation impact dynamically.", "configspace": "", "generation": 6, "fitness": 0.8730984993968218, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.873 with standard deviation 0.028. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "defd091f-8b1d-42dd-9f3a-75351ca10d77", "metadata": {"aucs": [0.8603844357948881, 0.8473257710666573, 0.9115852913289202], "final_y": [0.1234021067180785, 0.13144371364907603, 0.11310425056718498]}, "mutation_prompt": null}
{"id": "9e4b5d82-06c7-4e3e-a845-2b1a327f4919", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            iteration_ratio = evaluations / self.budget\n            self.cognitive_coefficient = 1.5 + 0.5 * iteration_ratio\n            self.social_coefficient = 1.5 - 0.5 * iteration_ratio\n            self.inertia_weight *= (0.995 ** ((1 + iteration_ratio) ** 2))  # Nonlinear decay factor applied\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population))\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            dynamic_mutation_rate = self.mutation_rate * (1 - iteration_ratio)\n            for i in range(self.population_size):\n                if np.random.rand() < dynamic_mutation_rate:\n                    mutation_vector = np.random.uniform(lb, ub, self.dim)\n                    population[i] = 0.5 * (population[i] + mutation_vector)\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Enhance adaptive inertia decay strategy by incorporating a nonlinear decay factor based on evaluations.", "configspace": "", "generation": 6, "fitness": 0.8603559621004289, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.860 with standard deviation 0.040. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.015.", "error": "", "parent_id": "defd091f-8b1d-42dd-9f3a-75351ca10d77", "metadata": {"aucs": [0.8053281228048481, 0.8791745061207183, 0.8965652573757203], "final_y": [0.15210807015674366, 0.11956010021799168, 0.12102847206637624]}, "mutation_prompt": null}
{"id": "5326d283-6f83-4299-a977-5ba3ec0594f9", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            iteration_ratio = evaluations / self.budget\n            self.cognitive_coefficient = 1.5 + 0.5 * iteration_ratio\n            self.social_coefficient = 1.5 - 0.5 * iteration_ratio\n            self.inertia_weight *= 0.95 ** (1 + iteration_ratio)  # Changed line for more aggressive inertia weight adaptation\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population))\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            dynamic_mutation_rate = self.mutation_rate * (1 - iteration_ratio)\n            mutation_scaling_factor = iteration_ratio  # New line for introducing time-varying mutation scaling\n            for i in range(self.population_size):\n                if np.random.rand() < dynamic_mutation_rate:\n                    mutation_vector = np.random.uniform(lb, ub, self.dim)\n                    population[i] = 0.5 * (population[i] + mutation_scaling_factor * mutation_vector)  # Modified line for mutation scaling\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Further enhance convergence by introducing a time-varying mutation scaling factor to adaptively balance exploration and exploitation.", "configspace": "", "generation": 6, "fitness": 0.8927886122132707, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.893 with standard deviation 0.024. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "9f39c255-3280-46f9-8a59-fda275256ee6", "metadata": {"aucs": [0.8986342353142321, 0.8607756177763497, 0.9189559835492302], "final_y": [0.114569169708712, 0.11889756550222874, 0.11414932481706053]}, "mutation_prompt": null}
{"id": "c7dab79a-6810-42a4-95aa-4aaa3e2668fb", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            iteration_ratio = evaluations / self.budget\n            self.cognitive_coefficient = 1.5 + 0.5 * (iteration_ratio ** 0.5)\n            self.social_coefficient = 1.5 - 0.5 * (iteration_ratio ** 0.5)\n            self.inertia_weight *= 0.95 ** (1 + iteration_ratio ** 2)   # Changed for non-linear adaptation\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population))\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            dynamic_mutation_rate = self.mutation_rate * (1 - iteration_ratio)\n            for i in range(self.population_size):\n                if np.random.rand() < dynamic_mutation_rate:\n                    mutation_vector = np.random.uniform(lb, ub, self.dim)\n                    population[i] = 0.5 * (population[i] + mutation_vector)\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Introduce non-linear adaptive inertia and dynamically adjusted cognitive and social coefficients for enhanced convergence. ", "configspace": "", "generation": 6, "fitness": 0.8632200037951773, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.863 with standard deviation 0.015. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "9f39c255-3280-46f9-8a59-fda275256ee6", "metadata": {"aucs": [0.8511313196653935, 0.884071166595273, 0.8544575251248654], "final_y": [0.11808346171162287, 0.1170176844484907, 0.12696725457316782]}, "mutation_prompt": null}
{"id": "52b9d2e2-4d13-4874-980e-19b3158978d6", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            iteration_ratio = evaluations / self.budget\n            self.cognitive_coefficient = 1.5 + 0.5 * iteration_ratio\n            self.social_coefficient = 1.5 - 0.5 * iteration_ratio\n            self.inertia_weight *= 0.95 ** (1 + iteration_ratio**2)  # Changed line for non-linear inertia weight adaptation\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population))\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            dynamic_mutation_rate = self.mutation_rate * (1 - iteration_ratio)\n            for i in range(self.population_size):\n                if np.random.rand() < dynamic_mutation_rate:\n                    mutation_vector = np.random.uniform(lb, ub, self.dim)\n                    population[i] = 0.5 * (population[i] + mutation_vector)\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Introduce non-linear inertia weight reduction for enhanced exploration-exploitation balance in optimization.", "configspace": "", "generation": 6, "fitness": 0.8606889575271383, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.861 with standard deviation 0.019. And the mean value of best solutions found was 0.129 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "9f39c255-3280-46f9-8a59-fda275256ee6", "metadata": {"aucs": [0.8656467492351262, 0.835812560061665, 0.8806075632846239], "final_y": [0.12243232289850592, 0.14031748897439866, 0.12281914614300316]}, "mutation_prompt": null}
{"id": "ba185cf9-2148-471c-a3ac-ddb31cb428a3", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            iteration_ratio = evaluations / self.budget\n            self.cognitive_coefficient = 1.5 + 0.5 * iteration_ratio\n            self.social_coefficient = 1.5 - 0.5 * iteration_ratio\n            \n            self.inertia_weight = 0.7 * (0.995 ** (1 + iteration_ratio)) + (0.3 * (1 - (global_best_score / np.min(scores))))  # Changed line for refined inertia strategy\n            velocity_scaling = np.exp(-iteration_ratio)  # Changed line for adaptive velocity scaling\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population)) * velocity_scaling\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            dynamic_mutation_rate = self.mutation_rate * (1 - iteration_ratio)\n            for i in range(self.population_size):\n                if np.random.rand() < dynamic_mutation_rate:\n                    mutation_vector = np.random.uniform(lb, ub, self.dim)\n                    population[i] = 0.5 * (population[i] + mutation_vector)\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Enhance convergence by introducing a dynamic inertia weight adjustment based on the global best improvement rate.", "configspace": "", "generation": 7, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'scores' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'scores' referenced before assignment\")", "parent_id": "1f6d919d-6c7b-4452-982d-492700c790e8", "metadata": {}, "mutation_prompt": null}
{"id": "c87fa177-1ade-4c5d-801c-aa613559b0ec", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.base_population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population_size = self.base_population_size + int(0.1 * (self.budget / self.dim))  # Adjust population size dynamically\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            iteration_ratio = evaluations / self.budget\n            self.cognitive_coefficient = 1.5 + 0.5 * iteration_ratio\n            self.social_coefficient = 1.5 - 0.5 * iteration_ratio\n            self.inertia_weight *= 0.95 ** (1 + iteration_ratio)\n            r1, r2 = np.random.rand(population_size, self.dim), np.random.rand(population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population))\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            dynamic_mutation_rate = self.mutation_rate * (1 - iteration_ratio)\n            mutation_scaling_factor = iteration_ratio\n            for i in range(population_size):\n                if np.random.rand() < dynamic_mutation_rate:\n                    mutation_vector = np.random.uniform(-0.1, 0.1, self.dim)  # Use a diversity-promoting mutation operator\n                    population[i] += mutation_scaling_factor * mutation_vector  # Apply mutation scaling\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += population_size\n\n            for i in range(population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Enhance exploration by introducing a diversity-promoting mutation operator and dynamically adjusting population size.", "configspace": "", "generation": 7, "fitness": 0.9025436619577377, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.903 with standard deviation 0.013. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "5326d283-6f83-4299-a977-5ba3ec0594f9", "metadata": {"aucs": [0.8835157825149593, 0.9124209572480586, 0.9116942461101953], "final_y": [0.11688313139745243, 0.11628062947155227, 0.11578448883138281]}, "mutation_prompt": null}
{"id": "53091a8f-6510-47a7-b197-2d29189f5c27", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            iteration_ratio = evaluations / self.budget\n            self.cognitive_coefficient = 1.5 + 0.5 * iteration_ratio\n            self.social_coefficient = 1.5 - 0.5 * iteration_ratio\n            \n            self.inertia_weight = 0.7 * (0.995 ** (1 + iteration_ratio))  # Changed line for refined inertia strategy\n            velocity_scaling = np.exp(-iteration_ratio)  # Changed line for adaptive velocity scaling\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population)) * velocity_scaling\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            dynamic_mutation_rate = self.mutation_rate * (1 - iteration_ratio)\n            mutation_scaling = 1 + 0.5 * iteration_ratio  # New line for adaptive mutation scaling\n            for i in range(self.population_size):\n                if np.random.rand() < dynamic_mutation_rate:\n                    mutation_vector = np.random.uniform(lb, ub, self.dim)\n                    population[i] = 0.5 * (population[i] + mutation_vector * mutation_scaling)\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Introduce an adaptive dynamic mutation scaling to better balance exploration and exploitation.", "configspace": "", "generation": 7, "fitness": 0.9136659647352382, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.914 with standard deviation 0.015. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "1f6d919d-6c7b-4452-982d-492700c790e8", "metadata": {"aucs": [0.8926618281839244, 0.9269669514712686, 0.9213691145505215], "final_y": [0.11486543890086343, 0.11295584633639644, 0.11359968502877316]}, "mutation_prompt": null}
{"id": "0e9a1be9-b92c-4f66-ab76-72e045825fb0", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            iteration_ratio = evaluations / self.budget\n            self.cognitive_coefficient = 1.5 + 0.5 * iteration_ratio\n            self.social_coefficient = 1.5 - 0.5 * iteration_ratio\n            self.inertia_weight *= 0.95 ** (1 + iteration_ratio)  # Changed line for more aggressive inertia weight adaptation\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population))\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            dynamic_mutation_rate = self.mutation_rate * (1 - iteration_ratio)\n            mutation_scaling_factor = 1 - iteration_ratio  # Modified line for better mutation scaling\n            for i in range(self.population_size):\n                if np.random.rand() < dynamic_mutation_rate:\n                    mutation_vector = np.random.uniform(lb, ub, self.dim)\n                    population[i] = 0.5 * (population[i] + mutation_scaling_factor * mutation_vector)\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Enhance exploration-exploitation balance by modifying the mutation vector scaling factor for improved convergence.", "configspace": "", "generation": 7, "fitness": 0.8996412625010372, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.900 with standard deviation 0.014. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "5326d283-6f83-4299-a977-5ba3ec0594f9", "metadata": {"aucs": [0.9096354876009674, 0.9093409934898865, 0.8799473064122576], "final_y": [0.11419751492444197, 0.11664818060298177, 0.12980308510264404]}, "mutation_prompt": null}
{"id": "e647797e-95f9-46b3-abf8-cf6e562372ed", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            iteration_ratio = evaluations / self.budget\n            self.cognitive_coefficient = 1.5 + 0.3 * np.sin(np.pi * iteration_ratio)  # Modified line for adaptive cognitive coefficient\n            self.social_coefficient = 1.5 - 0.3 * np.cos(np.pi * iteration_ratio)  # Modified line for adaptive social coefficient\n            self.inertia_weight *= 0.95 ** (1 + iteration_ratio)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population))\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            dynamic_mutation_rate = self.mutation_rate * (1 - iteration_ratio)\n            for i in range(self.population_size):\n                if np.random.rand() < dynamic_mutation_rate:\n                    mutation_vector = np.random.uniform(-0.5, 0.5, self.dim)  # Modified line for enhanced mutation diversity\n                    population[i] += mutation_vector  # Modified line for direct mutation addition\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Enhance solution exploitation by adaptive acceleration coefficients and improved mutation diversity.", "configspace": "", "generation": 7, "fitness": 0.9004604275047189, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.900 with standard deviation 0.015. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "5326d283-6f83-4299-a977-5ba3ec0594f9", "metadata": {"aucs": [0.9066825752933609, 0.8802899942028972, 0.9144087130178986], "final_y": [0.11145249055313411, 0.12349821633582736, 0.1141347976808974]}, "mutation_prompt": null}
{"id": "45f56be5-7762-4309-94ac-7aaa19196d7d", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            iteration_ratio = evaluations / self.budget\n            self.cognitive_coefficient = 1.5 + 0.5 * iteration_ratio\n            self.social_coefficient = 1.5 - 0.5 * iteration_ratio\n            \n            self.inertia_weight = 0.7 * (0.995 ** (1 + iteration_ratio))\n            velocity_scaling = np.exp(-iteration_ratio)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            differential_perturbation = 0.1 * (population - global_best_position)  # Introduced differential perturbation\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population) + differential_perturbation) * velocity_scaling\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            dynamic_mutation_rate = self.mutation_rate * (1 - iteration_ratio)\n            for i in range(self.population_size):\n                if np.random.rand() < dynamic_mutation_rate:\n                    mutation_vector = np.random.uniform(lb, ub, self.dim)\n                    population[i] = 0.5 * (population[i] + mutation_vector)\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Introduce differential perturbation in velocity update to maintain diversity and enhance convergence.", "configspace": "", "generation": 7, "fitness": 0.8680571248095119, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.868 with standard deviation 0.032. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.015.", "error": "", "parent_id": "1f6d919d-6c7b-4452-982d-492700c790e8", "metadata": {"aucs": [0.8809356429278132, 0.8245166890662803, 0.8987190424344421], "final_y": [0.11865847040351107, 0.149016680989432, 0.11494638378741018]}, "mutation_prompt": null}
{"id": "50f8f44d-35ef-488e-ad37-7b671f3f039e", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            iteration_ratio = evaluations / self.budget\n            self.cognitive_coefficient = 1.5 + 0.5 * iteration_ratio\n            self.social_coefficient = 1.5 - 0.5 * iteration_ratio\n            \n            self.inertia_weight = 0.7 * (0.995 ** (1 + iteration_ratio))\n            velocity_scaling = np.exp(-iteration_ratio)\n            dynamic_learning_factor = (1 + np.sin(iteration_ratio * np.pi)) / 2  # Changed line for dynamic learning factor\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          dynamic_learning_factor * self.cognitive_coefficient * r1 * (personal_best_positions - population) +  # Adjusted line\n                          self.social_coefficient * r2 * (global_best_position - population)) * velocity_scaling\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            dynamic_mutation_rate = self.mutation_rate * (1 - iteration_ratio)\n            for i in range(self.population_size):\n                if np.random.rand() < dynamic_mutation_rate:\n                    mutation_vector = np.random.uniform(lb, ub, self.dim)\n                    population[i] = 0.5 * (population[i] + mutation_vector)\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Introduce a dynamic learning factor that adjusts based on iteration progress to balance exploration and exploitation.", "configspace": "", "generation": 7, "fitness": 0.8579759888870462, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.858 with standard deviation 0.034. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "1f6d919d-6c7b-4452-982d-492700c790e8", "metadata": {"aucs": [0.8100084426379331, 0.8780294112301315, 0.8858901127930737], "final_y": [0.13720695277851913, 0.12636896892215288, 0.11661394578971429]}, "mutation_prompt": null}
{"id": "6c7fa6d0-391d-4089-a654-4dc6670f9515", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            iteration_ratio = evaluations / self.budget\n            self.cognitive_coefficient = 1.5 + np.sin(np.pi * iteration_ratio)  # Changed line for non-linear scaling\n            self.social_coefficient = 1.5 - np.cos(np.pi * iteration_ratio)  # Changed line for adaptive balancing\n            \n            self.inertia_weight = 0.7 * (0.995 ** (1 + iteration_ratio))\n            velocity_scaling = np.exp(-iteration_ratio ** 2)  # Changed line for improved velocity scaling\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population)) * velocity_scaling\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            dynamic_mutation_rate = self.mutation_rate * (1 - np.sqrt(iteration_ratio))  # Changed line for dynamic mutation\n            for i in range(self.population_size):\n                if np.random.rand() < dynamic_mutation_rate:\n                    mutation_vector = np.random.uniform(lb, ub, self.dim)\n                    population[i] = 0.5 * (population[i] + mutation_vector)\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Enhance exploration by introducing a non-linear scaling factor and adaptive cognitive-social balancing.", "configspace": "", "generation": 7, "fitness": 0.8997582750284044, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.900 with standard deviation 0.007. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "1f6d919d-6c7b-4452-982d-492700c790e8", "metadata": {"aucs": [0.8956492272744313, 0.8942891294235152, 0.909336468387267], "final_y": [0.11104589836616596, 0.11984259385666363, 0.11331443279390785]}, "mutation_prompt": null}
{"id": "560c40c2-43fd-4f4c-b1e5-fe392b16cac4", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            iteration_ratio = evaluations / self.budget\n            self.cognitive_coefficient = 1.5 + 0.5 * iteration_ratio\n            self.social_coefficient = 1.5 - 0.5 * iteration_ratio\n            self.inertia_weight = 0.7 * (1 - iteration_ratio) + 0.3 * iteration_ratio  # Changed line for dynamic inertia weight strategy\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population))\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            dynamic_mutation_rate = self.mutation_rate * (1 - iteration_ratio)\n            mutation_scaling_factor = iteration_ratio  # New line for introducing time-varying mutation scaling\n            for i in range(self.population_size):\n                if np.random.rand() < dynamic_mutation_rate:\n                    mutation_vector = np.random.uniform(lb, ub, self.dim)\n                    population[i] = 0.5 * (population[i] + mutation_scaling_factor * mutation_vector)  # Modified line for mutation scaling\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Introduce a dynamic inertia weight strategy to further balance exploration and exploitation.", "configspace": "", "generation": 7, "fitness": 0.8810256414247228, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.881 with standard deviation 0.033. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "5326d283-6f83-4299-a977-5ba3ec0594f9", "metadata": {"aucs": [0.8430269809740939, 0.8765008215128915, 0.923549121787183], "final_y": [0.12344654922514009, 0.12134434747619927, 0.11331188474686793]}, "mutation_prompt": null}
{"id": "450e42ae-d1fb-463d-9a30-58b2b708856a", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            iteration_ratio = evaluations / self.budget\n            self.cognitive_coefficient = 1.5 + 0.5 * iteration_ratio\n            self.social_coefficient = 1.5 - 0.5 * iteration_ratio\n            \n            self.inertia_weight = 0.9 - 0.5 * np.std(personal_best_scores) / np.mean(personal_best_scores)  # Changed line for dynamic inertia weight\n            velocity_scaling = np.exp(-iteration_ratio)  \n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population)) * velocity_scaling\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            dynamic_mutation_rate = self.mutation_rate * np.std(personal_best_scores)  # Changed line for adaptive mutation\n            for i in range(self.population_size):\n                if np.random.rand() < dynamic_mutation_rate:\n                    mutation_vector = np.random.uniform(lb, ub, self.dim)\n                    population[i] = 0.5 * (population[i] + mutation_vector)\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Enhance convergence via dynamic inertia weighting and adaptive mutation based on fitness diversity.", "configspace": "", "generation": 7, "fitness": 0.8680514954820531, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.868 with standard deviation 0.048. And the mean value of best solutions found was 0.130 (0. is the best) with standard deviation 0.017.", "error": "", "parent_id": "1f6d919d-6c7b-4452-982d-492700c790e8", "metadata": {"aucs": [0.8045895264075446, 0.8795101692616731, 0.9200547907769417], "final_y": [0.15240546931397048, 0.12432477604644776, 0.11258051440839156]}, "mutation_prompt": null}
{"id": "0871f91e-7c6b-49af-80fb-043d68748b56", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.base_population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population_size = self.base_population_size + int(0.1 * (self.budget / self.dim))\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            iteration_ratio = evaluations / self.budget\n            self.cognitive_coefficient = 1.5 + 0.5 * iteration_ratio\n            self.social_coefficient = 1.5 - 0.5 * iteration_ratio\n            self.inertia_weight *= 0.95 ** (1 + iteration_ratio)\n            r1, r2 = np.random.rand(population_size, self.dim), np.random.rand(population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population))\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            dynamic_mutation_rate = self.mutation_rate * (1 - iteration_ratio) * np.random.rand()\n            mutation_scaling_factor = 0.05 + 0.95 * iteration_ratio\n            for i in range(population_size):\n                if np.random.rand() < dynamic_mutation_rate:\n                    mutation_vector = np.random.uniform(-0.1, 0.1, self.dim)\n                    population[i] += mutation_scaling_factor * mutation_vector\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += population_size\n\n            for i in range(population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Introduce adaptive mutation rates and stochastic elitism for enhanced exploration and convergence.", "configspace": "", "generation": 8, "fitness": 0.8828736175794325, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.883 with standard deviation 0.027. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "c87fa177-1ade-4c5d-801c-aa613559b0ec", "metadata": {"aucs": [0.8889618065177481, 0.8473099233010539, 0.9123491229194952], "final_y": [0.11692048123868737, 0.1413171845663891, 0.11353720952554847]}, "mutation_prompt": null}
{"id": "f5166fb2-efea-46de-acf8-b884b5af7f57", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.base_population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population_size = self.base_population_size + int(0.1 * (self.budget / self.dim))\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = population_size\n        last_global_best_score = global_best_score\n\n        while evaluations < self.budget:\n            iteration_ratio = evaluations / self.budget\n            self.cognitive_coefficient = 1.5 + 0.5 * iteration_ratio\n            self.social_coefficient = 1.5 - 0.5 * iteration_ratio\n            self.inertia_weight *= 0.95 ** (1 + iteration_ratio)\n            r1, r2 = np.random.rand(population_size, self.dim), np.random.rand(population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population))\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            dynamic_mutation_rate = self.mutation_rate * (1 - iteration_ratio)\n            convergence_speed = abs(last_global_best_score - global_best_score)\n            mutation_scaling_factor = iteration_ratio * (1 + convergence_speed)\n            last_global_best_score = global_best_score\n\n            for i in range(population_size):\n                if np.random.rand() < dynamic_mutation_rate:\n                    mutation_vector = np.random.uniform(-0.1, 0.1, self.dim)\n                    population[i] += mutation_scaling_factor * mutation_vector\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += population_size\n\n            for i in range(population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Introduce adaptive mutation scaling based on convergence speed to improve exploration-exploitation balance.", "configspace": "", "generation": 8, "fitness": 0.8770339403665153, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.877 with standard deviation 0.014. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "c87fa177-1ade-4c5d-801c-aa613559b0ec", "metadata": {"aucs": [0.8948981690470431, 0.8757536845642753, 0.8604499674882273], "final_y": [0.11668247133977105, 0.11793891869893036, 0.12943775897349463]}, "mutation_prompt": null}
{"id": "5ff49348-6ba6-4adb-bdf7-62024eafe653", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.base_population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population_size = self.base_population_size + int(0.1 * (self.budget / self.dim))  # Adjust population size dynamically\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            iteration_ratio = evaluations / self.budget\n            self.cognitive_coefficient = 1.5 + 0.5 * iteration_ratio\n            self.social_coefficient = 1.5 - 0.5 * iteration_ratio\n            self.inertia_weight *= 0.95 ** (1 + iteration_ratio)\n            r1, r2 = np.random.rand(population_size, self.dim), np.random.rand(population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population))\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            dynamic_mutation_rate = self.mutation_rate * (1 - iteration_ratio)\n            mutation_scaling_factor = iteration_ratio\n            for i in range(population_size):\n                if np.random.rand() < dynamic_mutation_rate:\n                    mutation_vector = np.random.uniform(-0.1 * (1 - iteration_ratio), 0.1 * (1 - iteration_ratio), self.dim)  # Adjust mutation vector range dynamically\n                    population[i] += mutation_scaling_factor * mutation_vector  # Apply mutation scaling\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += population_size\n\n            for i in range(population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Improve convergence by adjusting the mutation vector range dynamically based on iteration ratio.", "configspace": "", "generation": 8, "fitness": 0.864374031747641, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.864 with standard deviation 0.025. And the mean value of best solutions found was 0.130 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "c87fa177-1ade-4c5d-801c-aa613559b0ec", "metadata": {"aucs": [0.886131847325208, 0.8769115613297949, 0.8300786865879201], "final_y": [0.1215483876946396, 0.12267620610835206, 0.1463015052644534]}, "mutation_prompt": null}
{"id": "13f23b8d-0196-4529-b52e-af1ba13b6d3a", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.base_population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population_size = self.base_population_size + int(0.1 * (self.budget / self.dim))  # Adjust population size dynamically\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            iteration_ratio = evaluations / self.budget\n            self.cognitive_coefficient = 1.5 + 0.5 * iteration_ratio\n            self.social_coefficient = 1.5 - 0.5 * iteration_ratio\n            self.inertia_weight *= 0.95 ** (1 + iteration_ratio)\n            r1, r2 = np.random.rand(population_size, self.dim), np.random.rand(population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population))\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            dynamic_mutation_rate = self.mutation_rate * (1 - iteration_ratio)\n            mutation_scaling_factor = iteration_ratio\n            for i in range(population_size):\n                if np.random.rand() < dynamic_mutation_rate:\n                    levy_step = np.random.standard_cauchy(self.dim)  # Lévy Flight for mutation\n                    population[i] += mutation_scaling_factor * levy_step  # Apply Lévy Flight\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += population_size\n\n            for i in range(population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Incorporate Lévy Flight for mutation to enhance exploration by simulating random search paths, improving convergence rate.", "configspace": "", "generation": 8, "fitness": 0.8914654650463171, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.891 with standard deviation 0.011. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "c87fa177-1ade-4c5d-801c-aa613559b0ec", "metadata": {"aucs": [0.8883549506795589, 0.8804193447424262, 0.9056220997169661], "final_y": [0.11500748712355424, 0.12531831968821583, 0.11411596139158187]}, "mutation_prompt": null}
{"id": "2a4e84c1-68f5-4cd7-8a1c-505eea98cc56", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            iteration_ratio = evaluations / self.budget\n            self.cognitive_coefficient = 1.4 + 0.6 * iteration_ratio  # Changed line for refined cognitive strategy\n            self.social_coefficient = 1.5 - 0.5 * iteration_ratio\n            \n            self.inertia_weight = 0.7 * (0.995 ** (1 + iteration_ratio))\n            velocity_scaling = np.exp(-iteration_ratio)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population)) * velocity_scaling\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            dynamic_mutation_rate = self.mutation_rate * (1 - iteration_ratio)\n            mutation_scaling = 1 + 0.5 * iteration_ratio\n            for i in range(self.population_size):\n                if np.random.rand() < dynamic_mutation_rate:\n                    mutation_vector = np.random.uniform(lb, ub, self.dim)\n                    population[i] = 0.5 * (population[i] + mutation_vector * mutation_scaling)\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Refine the cognitive and social coefficients to further enhance the balance between exploration and exploitation.", "configspace": "", "generation": 8, "fitness": 0.8764993196621808, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.876 with standard deviation 0.040. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "53091a8f-6510-47a7-b197-2d29189f5c27", "metadata": {"aucs": [0.9009521640625913, 0.8198460898523019, 0.908699705071649], "final_y": [0.11387383235525217, 0.13326684710663772, 0.115384746699977]}, "mutation_prompt": null}
{"id": "ffd5c904-13d3-4b59-b6d7-85e34501ced6", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            iteration_ratio = evaluations / self.budget\n            self.cognitive_coefficient = 1.5 + 0.5 * iteration_ratio\n            self.social_coefficient = 1.5 - 0.5 * iteration_ratio\n            \n            self.inertia_weight = 0.9 - 0.2 * iteration_ratio  # Changed line for improved inertia weight strategy\n            velocity_scaling = np.exp(-iteration_ratio)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population)) * velocity_scaling\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            dynamic_mutation_rate = self.mutation_rate * (1 - iteration_ratio)\n            mutation_scaling = 1 + 0.5 * iteration_ratio\n            for i in range(self.population_size):\n                if np.random.rand() < dynamic_mutation_rate:\n                    mutation_vector = np.random.uniform(lb, ub, self.dim)\n                    population[i] = 0.5 * (population[i] + mutation_vector * mutation_scaling)\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Introduce a diversity-promoting inertia weight strategy to enhance exploration during early iterations.", "configspace": "", "generation": 8, "fitness": 0.8564111582320962, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.856 with standard deviation 0.060. And the mean value of best solutions found was 0.129 (0. is the best) with standard deviation 0.015.", "error": "", "parent_id": "53091a8f-6510-47a7-b197-2d29189f5c27", "metadata": {"aucs": [0.7747856440661987, 0.8779529046768241, 0.9164949259532658], "final_y": [0.148091531766826, 0.12696254983899635, 0.11053520657688598]}, "mutation_prompt": null}
{"id": "48eeedee-8851-4c35-92e3-c08e1aaf7708", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.base_population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.9  # Increased initial inertia weight\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population_size = self.base_population_size + int(0.1 * (self.budget / self.dim))  # Adjust population size dynamically\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            iteration_ratio = evaluations / self.budget\n            self.cognitive_coefficient = 2.0 - iteration_ratio  # Adaptive cognitive coefficient\n            self.social_coefficient = 1.0 + iteration_ratio\n            self.inertia_weight *= 0.95 ** (1 + iteration_ratio)\n            r1, r2 = np.random.rand(population_size, self.dim), np.random.rand(population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population))\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            dynamic_mutation_rate = self.mutation_rate * (1 - iteration_ratio)\n            mutation_scaling_factor = iteration_ratio\n            for i in range(population_size):\n                if np.random.rand() < dynamic_mutation_rate:\n                    mutation_vector = np.random.uniform(-0.1, 0.1, self.dim)  # Use a diversity-promoting mutation operator\n                    population[i] += mutation_scaling_factor * mutation_vector  # Apply mutation scaling\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += population_size\n\n            for i in range(population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Introduce a time-varying inertia weight and adaptive cognitive-social balancing to enhance convergence and solution quality.", "configspace": "", "generation": 8, "fitness": 0.8649429537654995, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.865 with standard deviation 0.018. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "c87fa177-1ade-4c5d-801c-aa613559b0ec", "metadata": {"aucs": [0.8891944834810128, 0.8467408056078897, 0.8588935722075955], "final_y": [0.11102362002545596, 0.12941828231428032, 0.13494024809013438]}, "mutation_prompt": null}
{"id": "d20a0951-4ca2-4c3b-b75c-241365b79716", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = self.population_size\n\n        elite_fraction = 0.1  # New line for elite strategy\n        adaptive_lr = 0.1  # New line for self-adaptive learning rate\n\n        while evaluations < self.budget:\n            iteration_ratio = evaluations / self.budget\n            self.cognitive_coefficient = 1.5 + 0.5 * iteration_ratio\n            self.social_coefficient = 1.5 - 0.5 * iteration_ratio\n            \n            self.inertia_weight = 0.7 * (0.995 ** (1 + iteration_ratio))\n            velocity_scaling = np.exp(-iteration_ratio)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population)) * velocity_scaling\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            dynamic_mutation_rate = self.mutation_rate * (1 - iteration_ratio)\n            mutation_scaling = 1 + 0.5 * iteration_ratio\n            for i in range(self.population_size):\n                if np.random.rand() < dynamic_mutation_rate:\n                    mutation_vector = np.random.uniform(lb, ub, self.dim)\n                    population[i] = 0.5 * (population[i] + mutation_vector * mutation_scaling)\n\n            top_elite_idx = np.argsort(personal_best_scores)[:int(elite_fraction * self.population_size)]  # Elite selection\n            for idx in top_elite_idx:\n                population[idx] = personal_best_positions[idx]  # Preserve elites\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n                    adaptive_lr *= 1.02  # Increase learning rate on improvement  # Added line\n                else:\n                    adaptive_lr *= 0.98  # Decrease learning rate on stagnation  # Added line\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Introduce self-adaptive learning rates and elite strategy to enhance solution precision and convergence speed.", "configspace": "", "generation": 8, "fitness": 0.8948592659644344, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.895 with standard deviation 0.003. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "53091a8f-6510-47a7-b197-2d29189f5c27", "metadata": {"aucs": [0.898772732065842, 0.8924881620619673, 0.893316903765494], "final_y": [0.11266015216715863, 0.11960808471729234, 0.11394009225704693]}, "mutation_prompt": null}
{"id": "1a058bb2-847c-412a-8f76-bdad6910c28e", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.base_population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population_size = self.base_population_size + int(0.1 * (self.budget / self.dim))\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            iteration_ratio = evaluations / self.budget\n            self.cognitive_coefficient = 1.5 + 0.5 * iteration_ratio\n            self.social_coefficient = 1.5 - 0.5 * iteration_ratio\n            self.inertia_weight *= 0.95 ** (1 + iteration_ratio)\n            r1, r2 = np.random.rand(population_size, self.dim), np.random.rand(population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population))\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            dynamic_mutation_rate = self.mutation_rate * (1 - iteration_ratio)\n            mutation_scaling_factor = iteration_ratio\n            for i in range(population_size):\n                if np.random.rand() < dynamic_mutation_rate:\n                    mutation_vector = np.random.uniform(-0.1, 0.1, self.dim)\n                    population[i] += mutation_scaling_factor * mutation_vector\n\n            # Introduce differential evolution-inspired crossover\n            for i in range(population_size):\n                idxs = np.random.choice(population_size, 3, replace=False)\n                donor_vector = population[idxs[0]] + 0.8 * (population[idxs[1]] - population[idxs[2]])\n                trial_vector = np.where(np.random.rand(self.dim) < 0.9, donor_vector, population[i])\n                trial_vector = np.clip(trial_vector, lb, ub)\n                if func(trial_vector) < func(population[i]):\n                    population[i] = trial_vector\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += population_size\n\n            for i in range(population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Introduce differential evolution-inspired crossover for enhanced exploration and exploitation balance.", "configspace": "", "generation": 8, "fitness": 0.8588938532422553, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.859 with standard deviation 0.027. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "c87fa177-1ade-4c5d-801c-aa613559b0ec", "metadata": {"aucs": [0.8227426058189168, 0.8855373745984593, 0.8684015793093902], "final_y": [0.1253859095178248, 0.12516348955293088, 0.1263905428275769]}, "mutation_prompt": null}
{"id": "46f0fa1a-45e9-4e2d-87ce-10fd03498fcb", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.base_population_size = 20\n        self.cognitive_coefficient = 1.7  # Adjusted for better exploration\n        self.social_coefficient = 1.3  # Adjusted for better exploration\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population_size = self.base_population_size + int(0.1 * (self.budget / self.dim))\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            iteration_ratio = evaluations / self.budget\n            self.cognitive_coefficient = 1.7 + 0.5 * iteration_ratio\n            self.social_coefficient = 1.3 - 0.5 * iteration_ratio\n            self.inertia_weight *= 0.95 ** (1 + iteration_ratio)\n            r1, r2 = np.random.rand(population_size, self.dim), np.random.rand(population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population))\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            dynamic_mutation_rate = self.mutation_rate * (1 - iteration_ratio)\n            mutation_scaling_factor = iteration_ratio\n            for i in range(population_size):\n                if np.random.rand() < dynamic_mutation_rate:\n                    mutation_vector = np.random.uniform(-0.2, 0.2, self.dim)  # Increased mutation diversity\n                    population[i] += mutation_scaling_factor * mutation_vector\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += population_size\n\n            for i in range(population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Improve convergence speed by increasing mutation diversity and adjusting cognitive and social coefficients.", "configspace": "", "generation": 8, "fitness": 0.8609836495444153, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.861 with standard deviation 0.031. And the mean value of best solutions found was 0.130 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "c87fa177-1ade-4c5d-801c-aa613559b0ec", "metadata": {"aucs": [0.8949578450170403, 0.8191773148019823, 0.8688157888142235], "final_y": [0.11793166075114425, 0.13847192133663844, 0.1322311202969303]}, "mutation_prompt": null}
{"id": "9069f05c-44a9-4205-b1d2-768e6c0fcd45", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = self.population_size\n\n        elite_fraction = 0.1\n        adaptive_lr = 0.1\n\n        initial_population_size = self.population_size  # Added line\n        max_population_size = 40  # Added line\n\n        while evaluations < self.budget:\n            iteration_ratio = evaluations / self.budget\n            self.cognitive_coefficient = 1.5 + 0.5 * iteration_ratio\n            self.social_coefficient = 1.5 - 0.5 * iteration_ratio\n            \n            self.inertia_weight = 0.7 * (0.995 ** (1 + iteration_ratio))\n            velocity_scaling = np.exp(-iteration_ratio)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population)) * velocity_scaling\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            dynamic_mutation_rate = self.mutation_rate * (1 - iteration_ratio)\n            mutation_scaling = 1 + 0.5 * iteration_ratio\n            for i in range(self.population_size):\n                if np.random.rand() < dynamic_mutation_rate:\n                    mutation_vector = np.random.uniform(lb, ub, self.dim)\n                    population[i] = 0.5 * (population[i] + mutation_vector * mutation_scaling)\n\n            top_elite_idx = np.argsort(personal_best_scores)[:int(elite_fraction * self.population_size)]\n            for idx in top_elite_idx:\n                population[idx] = personal_best_positions[idx]\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += self.population_size\n\n            if evaluations / self.budget > 0.5 and self.population_size < max_population_size:  # Added line\n                self.population_size = int(initial_population_size + (max_population_size - initial_population_size) * (evaluations / self.budget))  # Added line\n                new_individuals = np.random.uniform(lb, ub, (self.population_size - len(population), self.dim))  # Added line\n                population = np.vstack((population, new_individuals))  # Added line\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n                    adaptive_lr *= 1.02\n                else:\n                    adaptive_lr *= 0.98\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Introduce dynamic population resizing and adaptive mutation to enhance exploration and exploitation balance.", "configspace": "", "generation": 9, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 20 is out of bounds for axis 0 with size 20').", "error": "IndexError('index 20 is out of bounds for axis 0 with size 20')", "parent_id": "d20a0951-4ca2-4c3b-b75c-241365b79716", "metadata": {}, "mutation_prompt": null}
{"id": "81c63990-1098-43bf-9d02-826dade417d7", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.base_population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population_size = self.base_population_size + int(0.1 * (self.budget / self.dim))  # Adjust population size dynamically\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            iteration_ratio = evaluations / self.budget\n            self.cognitive_coefficient = 1.5 + 0.5 * iteration_ratio\n            self.social_coefficient = 1.5 - 0.5 * iteration_ratio\n            self.inertia_weight = 0.7 * (1 - iteration_ratio) + 0.3 * iteration_ratio  # Dynamic inertia weight adjustment\n            r1, r2 = np.random.rand(population_size, self.dim), np.random.rand(population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population))\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            dynamic_mutation_rate = self.mutation_rate * (1 - iteration_ratio)\n            mutation_scaling_factor = iteration_ratio\n            for i in range(population_size):\n                if np.random.rand() < dynamic_mutation_rate:\n                    levy_step = np.random.standard_cauchy(self.dim)  # Lévy Flight for mutation\n                    population[i] += mutation_scaling_factor * levy_step  # Apply Lévy Flight\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += population_size\n\n            for i in range(population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Integrate a time-weighted adaptive inertia weight to balance exploration and exploitation more effectively.", "configspace": "", "generation": 9, "fitness": 0.898123164809255, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.898 with standard deviation 0.008. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "13f23b8d-0196-4529-b52e-af1ba13b6d3a", "metadata": {"aucs": [0.8949711528818262, 0.8898771857502936, 0.9095211557956452], "final_y": [0.11613083054928774, 0.11667643389231341, 0.11361100199510987]}, "mutation_prompt": null}
{"id": "b3b2a7c5-95b4-4ea3-ae1f-e2af39377c21", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = self.population_size\n\n        adaptive_lr = 0.1  # New line for self-adaptive learning rate\n\n        while evaluations < self.budget:\n            iteration_ratio = evaluations / self.budget\n            self.cognitive_coefficient = 1.5 + 0.5 * iteration_ratio\n            self.social_coefficient = 1.5 - 0.5 * iteration_ratio\n            \n            self.inertia_weight = 0.7 * (0.995 ** (1 + iteration_ratio))\n            velocity_scaling = np.exp(-iteration_ratio)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population)) * velocity_scaling\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            dynamic_mutation_rate = self.mutation_rate * (1 - iteration_ratio)\n            mutation_scaling = 1 + 0.5 * iteration_ratio\n            for i in range(self.population_size):\n                if np.random.rand() < dynamic_mutation_rate:\n                    mutation_vector = np.random.uniform(lb, ub, self.dim)\n                    population[i] = 0.5 * (population[i] + mutation_vector * mutation_scaling)\n\n            elite_fraction = 0.1 + 0.4 * iteration_ratio  # Introduce dynamic elite fraction  \n            top_elite_idx = np.argsort(personal_best_scores)[:int(elite_fraction * self.population_size)]\n            for idx in top_elite_idx:\n                population[idx] = personal_best_positions[idx]  # Preserve elites\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n                    adaptive_lr *= 1.02  # Increase learning rate on improvement\n                else:\n                    adaptive_lr *= 0.98  # Decrease learning rate on stagnation\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Introduce a dynamic elite fraction that increases over time to enhance convergence stability and exploit promising regions.", "configspace": "", "generation": 9, "fitness": 0.8765223888499598, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.877 with standard deviation 0.029. And the mean value of best solutions found was 0.129 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "d20a0951-4ca2-4c3b-b75c-241365b79716", "metadata": {"aucs": [0.8668246255105447, 0.8473099233010539, 0.915432617738281], "final_y": [0.13174186737392712, 0.1413171845663891, 0.11282643409801085]}, "mutation_prompt": null}
{"id": "2e1be0d8-62be-47ca-a8f1-316db0a70e8f", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = self.population_size\n\n        elite_fraction = 0.1  # New line for elite strategy\n        adaptive_lr = 0.1  # New line for self-adaptive learning rate\n\n        while evaluations < self.budget:\n            iteration_ratio = evaluations / self.budget\n            self.cognitive_coefficient = 1.5 + 0.5 * iteration_ratio\n            self.social_coefficient = 1.5 - 0.5 * iteration_ratio\n            \n            self.inertia_weight = 0.9 - 0.5 * iteration_ratio  # Adjusted inertia weight\n            velocity_scaling = np.exp(-iteration_ratio)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population)) * velocity_scaling\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            dynamic_mutation_rate = self.mutation_rate * (1 - iteration_ratio)\n            mutation_scaling = 1 + 0.5 * iteration_ratio\n            for i in range(self.population_size):\n                if np.random.rand() < dynamic_mutation_rate:\n                    mutation_vector = np.random.uniform(lb, ub, self.dim)\n                    population[i] = 0.5 * (population[i] + mutation_vector * mutation_scaling)\n\n            top_elite_idx = np.argsort(personal_best_scores)[:int(elite_fraction * self.population_size)]  # Elite selection\n            for idx in top_elite_idx:\n                population[idx] = personal_best_positions[idx]  # Preserve elites\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n                    adaptive_lr *= 1.02  # Increase learning rate on improvement\n                else:\n                    adaptive_lr *= 0.98  # Decrease learning rate on stagnation\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Enhance solution precision and convergence by using time-varying inertia and dynamic elite strategy to balance exploration and exploitation.", "configspace": "", "generation": 9, "fitness": 0.8697300352086924, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.870 with standard deviation 0.032. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "d20a0951-4ca2-4c3b-b75c-241365b79716", "metadata": {"aucs": [0.8418960075394145, 0.8533656312690534, 0.9139284668176093], "final_y": [0.13769404863753243, 0.12932843335050748, 0.11381300781046444]}, "mutation_prompt": null}
{"id": "90262364-cac1-4cba-91ef-52bc5a97d55c", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.base_population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population_size = self.base_population_size + int(0.1 * (self.budget / self.dim))  # Adjust population size dynamically\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            iteration_ratio = evaluations / self.budget\n            self.cognitive_coefficient = 1.5 + 0.5 * iteration_ratio\n            self.social_coefficient = 1.5 - 0.5 * iteration_ratio\n            self.inertia_weight *= 0.95 ** (1 + iteration_ratio)\n            r1, r2 = np.random.rand(population_size, self.dim), np.random.rand(population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population))\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            dynamic_mutation_rate = self.mutation_rate * (1 - iteration_ratio)\n            mutation_scaling_factor = iteration_ratio ** 2  # Modified mutation scaling factor\n            for i in range(population_size):\n                if np.random.rand() < dynamic_mutation_rate:\n                    levy_step = np.random.standard_cauchy(self.dim)  # Lévy Flight for mutation\n                    population[i] += mutation_scaling_factor * levy_step  # Apply Lévy Flight\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += population_size\n\n            for i in range(population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Dynamically adjust the mutation scaling factor with respect to iteration progress to enhance solution diversity and convergence.", "configspace": "", "generation": 9, "fitness": 0.8873523770372008, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.887 with standard deviation 0.013. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "13f23b8d-0196-4529-b52e-af1ba13b6d3a", "metadata": {"aucs": [0.8756155614120851, 0.8810533414236177, 0.9053882282758998], "final_y": [0.12095019199367318, 0.1230555003684286, 0.1163397287083815]}, "mutation_prompt": null}
{"id": "c6e7d9dd-8fad-4269-8705-5ae6b21f67bf", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = self.population_size\n\n        elite_fraction = 0.1\n        adaptive_lr = 0.1\n        momentum = 0.9  # New line added for momentum mechanism\n\n        while evaluations < self.budget:\n            iteration_ratio = evaluations / self.budget\n            self.cognitive_coefficient = 1.5 + 0.5 * iteration_ratio\n            self.social_coefficient = 1.5 - 0.5 * iteration_ratio\n            \n            self.inertia_weight = 0.7 * (0.995 ** (1 + iteration_ratio))\n            velocity_scaling = np.exp(-iteration_ratio)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population)) * velocity_scaling\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            dynamic_mutation_rate = self.mutation_rate * (1 - iteration_ratio)\n            mutation_scaling = 1 + 0.5 * iteration_ratio\n            for i in range(self.population_size):\n                if np.random.rand() < dynamic_mutation_rate:\n                    mutation_vector = np.random.uniform(lb, ub, self.dim)\n                    population[i] = 0.5 * (population[i] + mutation_vector * mutation_scaling)\n\n            top_elite_idx = np.argsort(personal_best_scores)[:int(elite_fraction * self.population_size)]\n            for idx in top_elite_idx:\n                population[idx] = personal_best_positions[idx] * momentum + population[idx] * (1 - momentum)  # Updated line\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n                    adaptive_lr *= 1.02\n                else:\n                    adaptive_lr *= 0.98\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Integrate a momentum mechanism into elite strategy to further stabilize and enhance convergence speed.", "configspace": "", "generation": 9, "fitness": 0.8993207785122747, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.899 with standard deviation 0.013. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "d20a0951-4ca2-4c3b-b75c-241365b79716", "metadata": {"aucs": [0.9051506615463619, 0.8811067245657207, 0.9117049494247413], "final_y": [0.11289007505255144, 0.1268977702896098, 0.11211768177655945]}, "mutation_prompt": null}
{"id": "6e3e0772-24a4-402e-b092-abbab2ea5f38", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = self.population_size\n\n        elite_fraction = 0.1\n        adaptive_lr = 0.1\n\n        while evaluations < self.budget:\n            iteration_ratio = evaluations / self.budget\n            self.cognitive_coefficient = 1.5 + 0.5 * iteration_ratio\n            self.social_coefficient = 1.5 - 0.5 * iteration_ratio\n            \n            self.inertia_weight = 0.9 - 0.5 * iteration_ratio  # Change line: dynamic inertia weight\n            velocity_scaling = np.exp(-iteration_ratio)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population)) * velocity_scaling\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            dynamic_mutation_rate = self.mutation_rate * (1 - iteration_ratio)\n            mutation_scaling = 1 + 0.5 * iteration_ratio\n            for i in range(self.population_size):\n                if np.random.rand() < dynamic_mutation_rate:\n                    mutation_vector = np.random.uniform(lb, ub, self.dim)\n                    population[i] = 0.5 * (population[i] + mutation_vector * mutation_scaling)\n\n            # Change line: Use tournament selection for elite preservation\n            for idx in np.random.choice(self.population_size, int(elite_fraction * self.population_size), replace=False):\n                tournament_candidates = np.random.choice(self.population_size, 2, replace=False)\n                winner = tournament_candidates[np.argmin(personal_best_scores[tournament_candidates])]\n                population[idx] = personal_best_positions[winner]\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n                    adaptive_lr *= 1.02\n                else:\n                    adaptive_lr *= 0.98\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Introduce tournament selection for elite preservation and dynamic inertia weight for improved exploration-exploitation balance.", "configspace": "", "generation": 9, "fitness": 0.8706591802256473, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.871 with standard deviation 0.034. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "d20a0951-4ca2-4c3b-b75c-241365b79716", "metadata": {"aucs": [0.8586497668599063, 0.8366597128400839, 0.9166680609769514], "final_y": [0.11912418733673447, 0.13008093530721565, 0.11353750671055052]}, "mutation_prompt": null}
{"id": "e700fbe8-152b-4796-ab59-ac521ed5e811", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.base_population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population_size = self.base_population_size + int(0.1 * (self.budget / self.dim))\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = population_size\n        chaotic_map_factor = 0.7\n        \n        while evaluations < self.budget:\n            iteration_ratio = evaluations / self.budget\n            self.cognitive_coefficient = 1.5 + 0.5 * iteration_ratio\n            self.social_coefficient = 1.5 - 0.5 * iteration_ratio\n            self.inertia_weight *= 0.95 ** (1 + iteration_ratio)\n            r1, r2 = np.random.rand(population_size, self.dim), np.random.rand(population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population))\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            dynamic_mutation_rate = self.mutation_rate * (1 - iteration_ratio)\n            mutation_scaling_factor = iteration_ratio + chaotic_map_factor * (1 - iteration_ratio)\n            for i in range(population_size):\n                if np.random.rand() < dynamic_mutation_rate:\n                    levy_step = np.random.standard_cauchy(self.dim)\n                    population[i] += mutation_scaling_factor * levy_step\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += population_size\n\n            for i in range(population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Enhance exploration and exploitation balance using adaptive mutation and chaotic maps to improve convergence speed and accuracy.", "configspace": "", "generation": 9, "fitness": 0.8995566185643705, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.900 with standard deviation 0.013. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "13f23b8d-0196-4529-b52e-af1ba13b6d3a", "metadata": {"aucs": [0.8938462735131325, 0.886968417843128, 0.9178551643368509], "final_y": [0.11704975482102542, 0.11816941379742363, 0.11333993339021542]}, "mutation_prompt": null}
{"id": "e4c2b0a3-10d7-4c7d-9784-bd385cb8ed8a", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.base_population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population_size = self.base_population_size + int(0.1 * (self.budget / self.dim))  # Adjust population size dynamically\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            iteration_ratio = evaluations / self.budget\n            self.cognitive_coefficient = 1.5 + 0.5 * iteration_ratio\n            self.social_coefficient = 1.5 - 0.5 * iteration_ratio\n            self.inertia_weight *= 0.95 ** (1 + iteration_ratio)\n            r1, r2 = np.random.rand(population_size, self.dim), np.random.rand(population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population))\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            dynamic_mutation_rate = self.mutation_rate * (1 - iteration_ratio)\n            mutation_scaling_factor = 1 + iteration_ratio  # Changed from mutation_scaling_factor = iteration_ratio\n            for i in range(population_size):\n                if np.random.rand() < dynamic_mutation_rate:\n                    levy_step = np.random.standard_cauchy(self.dim)  # Lévy Flight for mutation\n                    population[i] += mutation_scaling_factor * levy_step  # Apply Lévy Flight\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += population_size\n\n            for i in range(population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Enhance exploration by integrating adaptive mutation scaling with Lévy Flight and dynamic population resizing.", "configspace": "", "generation": 9, "fitness": 0.8584158024560873, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.858 with standard deviation 0.022. And the mean value of best solutions found was 0.130 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "13f23b8d-0196-4529-b52e-af1ba13b6d3a", "metadata": {"aucs": [0.8279345544546624, 0.8687765959668033, 0.878536256946796], "final_y": [0.13974726875140997, 0.12746486613414987, 0.12278844635663155]}, "mutation_prompt": null}
{"id": "6c9eea62-e929-48f6-9522-c16a032584a7", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n        self.inertia_weight = 0.7\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.array([func(individual) for individual in population])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        evaluations = self.population_size\n\n        # Modification: Dynamic elite fraction\n        elite_fraction = 0.1  # Initial fraction for elite strategy\n        adaptive_lr = 0.1  # New line for self-adaptive learning rate\n\n        while evaluations < self.budget:\n            iteration_ratio = evaluations / self.budget\n            self.cognitive_coefficient = 1.5 + 0.5 * iteration_ratio\n            self.social_coefficient = 1.5 - 0.5 * iteration_ratio\n            \n            self.inertia_weight = 0.7 * (0.995 ** (1 + iteration_ratio))\n            velocity_scaling = np.exp(-iteration_ratio)\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_coefficient * r1 * (personal_best_positions - population) +\n                          self.social_coefficient * r2 * (global_best_position - population)) * velocity_scaling\n            population += velocities\n            population = np.clip(population, lb, ub)\n            \n            dynamic_mutation_rate = self.mutation_rate * (1 - iteration_ratio)\n            mutation_scaling = 1 + 0.5 * iteration_ratio\n            for i in range(self.population_size):\n                if np.random.rand() < dynamic_mutation_rate:\n                    mutation_vector = np.random.uniform(lb, ub, self.dim)\n                    population[i] = 0.5 * (population[i] + mutation_vector * mutation_scaling)\n\n            elite_fraction = 0.1 + 0.1 * (1 - iteration_ratio)  # Dynamic elite fraction adjustment\n            top_elite_idx = np.argsort(personal_best_scores)[:int(elite_fraction * self.population_size)]\n            for idx in top_elite_idx:\n                population[idx] = personal_best_positions[idx]  # Preserve elites\n\n            scores = np.array([func(individual) for individual in population])\n            evaluations += self.population_size\n\n            for i in range(self.population_size):\n                if scores[i] < personal_best_scores[i]:\n                    personal_best_scores[i] = scores[i]\n                    personal_best_positions[i] = population[i]\n                    adaptive_lr *= 1.02  # Increase learning rate on improvement\n                else:\n                    adaptive_lr *= 0.98  # Decrease learning rate on stagnation\n\n            if np.min(scores) < global_best_score:\n                global_best_idx = np.argmin(scores)\n                global_best_position = population[global_best_idx]\n                global_best_score = scores[global_best_idx]\n\n        return global_best_position, global_best_score", "name": "HybridMetaheuristicOptimizer", "description": "Introduce dynamic elite fraction to enhance exploration-exploitation balance.", "configspace": "", "generation": 9, "fitness": 0.8899603096056979, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.890 with standard deviation 0.011. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "d20a0951-4ca2-4c3b-b75c-241365b79716", "metadata": {"aucs": [0.8773158909470251, 0.887506867192054, 0.9050581706780148], "final_y": [0.12132565960662445, 0.11852313782027746, 0.1158248338233826]}, "mutation_prompt": null}
