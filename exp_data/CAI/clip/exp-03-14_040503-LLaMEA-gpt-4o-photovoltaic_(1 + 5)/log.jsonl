{"id": "23c7bf53-c889-4d22-b899-09bc56c62a49", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Adaptive Swarm Gradient Descent (ASGD): Combines swarm intelligence and gradient estimation to explore and exploit search space efficiently.", "configspace": "", "generation": 0, "fitness": 0.8264407036439118, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.826 with standard deviation 0.020. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": null, "metadata": {"aucs": [0.8041324604654931, 0.8227266579918514, 0.8524629924743906], "final_y": [0.1412466306774247, 0.13112094863304602, 0.12789490696654837]}, "mutation_prompt": null}
{"id": "2173a926-ec02-4067-9038-bc63c5f94e00", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.0 + np.random.random()  # Modified line\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance exploration by incorporating randomness in the social coefficient.", "configspace": "", "generation": 1, "fitness": 0.8437846327926756, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.844 with standard deviation 0.020. And the mean value of best solutions found was 0.129 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "23c7bf53-c889-4d22-b899-09bc56c62a49", "metadata": {"aucs": [0.8151543795789249, 0.8549181335642587, 0.8612813852348431], "final_y": [0.1384430473052679, 0.12638161685926697, 0.1223694575564066]}, "mutation_prompt": null}
{"id": "fed787a1-d272-4593-a39b-2308fbb9ae8f", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = (1 - evaluations / self.budget) ** 2  # Modified line\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved Adaptive Swarm Gradient Descent (IASGD) with enhanced adaptive factor for more effective exploration-exploitation balance.", "configspace": "", "generation": 1, "fitness": 0.8542571141412227, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.854 with standard deviation 0.020. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "23c7bf53-c889-4d22-b899-09bc56c62a49", "metadata": {"aucs": [0.8285600483662764, 0.876217478248249, 0.8579938158091429], "final_y": [0.13636975440476296, 0.12312352734594612, 0.11466629885494717]}, "mutation_prompt": null}
{"id": "e53f71fd-0d92-4fe5-a3a0-d708182cdf44", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor  # Adjusted line\n            social_coeff = 1.5 * (1 - adaptive_factor)  # Adjusted line\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent (ASGD+): Refines solution exploration with dynamic cognitive and social coefficients based on iteration progress.", "configspace": "", "generation": 1, "fitness": 0.8650832236509517, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.865 with standard deviation 0.021. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "23c7bf53-c889-4d22-b899-09bc56c62a49", "metadata": {"aucs": [0.8350788708909408, 0.8804766602622347, 0.8796941397996796], "final_y": [0.12596067806035938, 0.11840564202487969, 0.11758753174736458]}, "mutation_prompt": null}
{"id": "d91adb41-0aee-4228-a005-3c551b9347f7", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * np.sin(0.1 * evaluations)  # Adaptive social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced ASGD by introducing an adaptive social coefficient for refined exploration and exploitation balance.", "configspace": "", "generation": 1, "fitness": 0.8567448939059744, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.857 with standard deviation 0.025. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "23c7bf53-c889-4d22-b899-09bc56c62a49", "metadata": {"aucs": [0.8217416312531746, 0.8723212335655084, 0.87617181689924], "final_y": [0.14138766503215328, 0.12490643938737922, 0.11761142564229365]}, "mutation_prompt": null}
{"id": "80716b2d-1706-4b3e-81b7-5d236038a8a6", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * adaptive_factor # Updated line\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced ASGD with time-varying social coefficients for improved search space exploitation.", "configspace": "", "generation": 1, "fitness": 0.8417807176367064, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.842 with standard deviation 0.041. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.020.", "error": "", "parent_id": "23c7bf53-c889-4d22-b899-09bc56c62a49", "metadata": {"aucs": [0.7855888264907305, 0.8569316680039646, 0.8828216584154237], "final_y": [0.15968683600995837, 0.1233951724959883, 0.11459630512727093]}, "mutation_prompt": null}
{"id": "e334af85-6224-4908-acde-0977b641509a", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * (1 - adaptive_factor)\n\n            mutation_factor = 0.1 * (1 - adaptive_factor)  # New line\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i] + mutation_factor * np.random.randn(self.dim), lb, ub)  # Modified line\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Incorporate adaptive mutation strategy to enhance exploration and exploitation balance in ASGD+.", "configspace": "", "generation": 2, "fitness": 0.872085306134065, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.872 with standard deviation 0.017. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "e53f71fd-0d92-4fe5-a3a0-d708182cdf44", "metadata": {"aucs": [0.8488540711759972, 0.8777884631467034, 0.8896133840794944], "final_y": [0.12134888520485432, 0.11216027391415284, 0.11192038406426097]}, "mutation_prompt": null}
{"id": "e68d5431-95d3-4f12-9c31-1c7b36efaa4f", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * (1 - adaptive_factor)\n\n            # Dynamic population size adjustment\n            self.population_size = int((10 + 2 * int(np.sqrt(self.dim))) * adaptive_factor) + 1\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced a dynamic population size adjustment based on evaluation progress to enhance exploration-exploitation balance.", "configspace": "", "generation": 2, "fitness": 0.8605113373768356, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.861 with standard deviation 0.009. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e53f71fd-0d92-4fe5-a3a0-d708182cdf44", "metadata": {"aucs": [0.8726738805764247, 0.8563617145259047, 0.8524984170281776], "final_y": [0.1211362304318816, 0.12100166637616594, 0.12093552515692352]}, "mutation_prompt": null}
{"id": "e93e39f9-6e90-4b53-990f-aa3c155ddab8", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor  # Adjusted line\n            social_coeff = 1.5 * (1 - adaptive_factor)  # Adjusted line\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                \n                # Apply velocity clamping\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with Velocity Clamping (ASGD-VC): Introduces velocity clamping to improve convergence stability and solution refinement by preventing excessive exploration.", "configspace": "", "generation": 2, "fitness": 0.8764111416039743, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.876 with standard deviation 0.011. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "e53f71fd-0d92-4fe5-a3a0-d708182cdf44", "metadata": {"aucs": [0.8614862750132797, 0.8853017563724164, 0.8824453934262266], "final_y": [0.11788534559732466, 0.11829425922192316, 0.11362565072688924]}, "mutation_prompt": null}
{"id": "ec2d5864-0586-4c2f-a369-32fae8ab11a8", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - (evaluations / self.budget) ** 2  # Modified line\n            inertia_weight = 0.9 - 0.5 * adaptive_factor  # Modified line\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * (1 - adaptive_factor)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Dynamic Inertia Swarm (EDIS): Refines AdaptiveSwarmGradientDescent by introducing a non-linear decay in inertia weight based on evaluations for improved balance between exploration and exploitation.", "configspace": "", "generation": 2, "fitness": 0.8524282984343555, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.852 with standard deviation 0.043. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "e53f71fd-0d92-4fe5-a3a0-d708182cdf44", "metadata": {"aucs": [0.7918010554082653, 0.8881677021024809, 0.8773161377923201], "final_y": [0.12245382456907217, 0.11451441388394867, 0.11321110168705495]}, "mutation_prompt": null}
{"id": "ff8be127-a348-4022-affb-a7e09da366c4", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - (evaluations / self.budget)**2  # Adjusted line\n            inertia_weight = 0.5 + 0.5 * adaptive_factor  # Adjusted line\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * (1 - adaptive_factor)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved Adaptive Swarm Gradient Descent with Nonlinear Inertia and Cognitive-Social Scaling.", "configspace": "", "generation": 2, "fitness": 0.8511477503638828, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.851 with standard deviation 0.003. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "e53f71fd-0d92-4fe5-a3a0-d708182cdf44", "metadata": {"aucs": [0.8494441903452283, 0.855527663575868, 0.8484713971705521], "final_y": [0.113216470562298, 0.1223106380102944, 0.12103599325994185]}, "mutation_prompt": null}
{"id": "3cdbe4c4-44aa-44da-b9d5-d89d2d8ce5ba", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.5 * adaptive_factor  # Adjusted line\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * (1 - adaptive_factor)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                \n                # Apply velocity clamping\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce dynamic inertia weight adjustment for improved exploration-exploitation balance in ASGD-VC.", "configspace": "", "generation": 3, "fitness": 0.8757053721468641, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.876 with standard deviation 0.016. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "e93e39f9-6e90-4b53-990f-aa3c155ddab8", "metadata": {"aucs": [0.8579211195073569, 0.8733209783243903, 0.895874018608845], "final_y": [0.12334734285948379, 0.12008121854227272, 0.11061094654007753]}, "mutation_prompt": null}
{"id": "0de13c96-df04-42f0-8e7d-83f563301352", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * (global_best_value / np.mean(personal_best_value))\n            cognitive_coeff = 1.5 * adaptive_factor  # Adjusted line\n            social_coeff = 1.5 * (1 - adaptive_factor)  # Adjusted line\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                \n                # Apply velocity clamping\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Incorporate dynamic inertia weight based on swarm convergence to enhance exploration-exploitation balance.", "configspace": "", "generation": 3, "fitness": 0.8707030114063933, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.871 with standard deviation 0.007. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "e93e39f9-6e90-4b53-990f-aa3c155ddab8", "metadata": {"aucs": [0.8638058726075794, 0.8688108676301102, 0.87949229398149], "final_y": [0.11339133910140131, 0.11631834544539466, 0.11336724911508844]}, "mutation_prompt": null}
{"id": "7b56822b-3d02-42ad-8bf2-fedd78992afe", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            # Dynamic adjustment of social coefficient based on convergence rate\n            social_coeff = 1.5 * (1 - adaptive_factor + 0.1 * np.std(personal_best_value))  # Adjusted line\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                \n                # Apply velocity clamping\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Integrate a dynamic social influence mechanism that adapts based on the convergence rate to balance global and local search.", "configspace": "", "generation": 3, "fitness": 0.867002999347088, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.867 with standard deviation 0.013. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "e93e39f9-6e90-4b53-990f-aa3c155ddab8", "metadata": {"aucs": [0.8509538198599187, 0.8662914351835393, 0.8837637429978061], "final_y": [0.11459421169845085, 0.12397321607834455, 0.11385659038367013]}, "mutation_prompt": null}
{"id": "8a9c108e-4a57-4b94-a3da-c02498988552", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor  \n            social_coeff = 1.5 * (1 - adaptive_factor)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                \n                # Apply velocity clamping\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Add diversity improvement: reintroduce random individuals if diversity is low\n            if np.std(swarm) < 0.001:  # Change made here\n                swarm[np.random.randint(self.population_size)] = np.random.uniform(lb, ub, self.dim)  # Change made here\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved Adaptive Swarm Gradient Descent with Velocity Clamping and Diversity Maintenance (ASGD-VC-DM): Enhances exploration by re-introducing random individuals when diversity falls below a threshold.", "configspace": "", "generation": 3, "fitness": 0.8765363264213851, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.877 with standard deviation 0.014. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "e93e39f9-6e90-4b53-990f-aa3c155ddab8", "metadata": {"aucs": [0.8569496159495218, 0.8891649154725473, 0.8834944478420863], "final_y": [0.12069948693898813, 0.11314516631978999, 0.11514571336749713]}, "mutation_prompt": null}
{"id": "4b9a0d8e-6a60-4e1f-9805-f1810dd3f441", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * (1 - adaptive_factor)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n\n                # Apply velocity clamping\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Reallocate population to promising regions\n                if np.random.random() < 0.05:  # Changed line (1.9% change)\n                    swarm[i] = np.random.uniform(lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Adaptive Swarm Gradient Descent with Dynamic Population Reallocation (ASGD-DPR): Improves exploration by reallocating population members to promising regions based on their performance.", "configspace": "", "generation": 3, "fitness": 0.8714666259384914, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.871 with standard deviation 0.013. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "e93e39f9-6e90-4b53-990f-aa3c155ddab8", "metadata": {"aucs": [0.8527545650239818, 0.8775449680633036, 0.8841003447281887], "final_y": [0.1268645744772514, 0.11270626098867553, 0.11112368328585964]}, "mutation_prompt": null}
{"id": "5732d935-ed42-4068-9d16-b58ea5e6d629", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor  \n            social_coeff = 1.5 * (1 - adaptive_factor)\n\n            # Dynamically scale population size\n            current_population_size = self.population_size - int(0.2 * self.population_size * evaluations / self.budget)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                \n                # Apply velocity clamping\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Add diversity improvement: reintroduce random individuals if diversity is low\n            if np.std(swarm) < 0.001:\n                swarm[np.random.randint(current_population_size)] = np.random.uniform(lb, ub, self.dim)\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with Dynamic Population Scaling based on Evaluation Progress.", "configspace": "", "generation": 4, "fitness": 0.8804238079879672, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.880 with standard deviation 0.004. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "8a9c108e-4a57-4b94-a3da-c02498988552", "metadata": {"aucs": [0.8758575940326518, 0.8857527165667375, 0.879661113364512], "final_y": [0.116428859633816, 0.11378456506267498, 0.11326736371603474]}, "mutation_prompt": null}
{"id": "43076db7-f02e-40e3-b389-410c604d5380", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor  \n            social_coeff = 1.5 * (1 - adaptive_factor)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                \n                # Apply velocity clamping\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Add diversity improvement: reintroduce random individuals if diversity is low\n            if np.std(swarm) < 0.001 * (1 + 0.5 * (self.budget - evaluations) / self.budget):  # Change made here\n                swarm[np.random.randint(self.population_size)] = np.random.uniform(lb, ub, self.dim)\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent introduces a dynamic diversity threshold based on budget utilization to improve exploration efficacy.", "configspace": "", "generation": 4, "fitness": 0.8624544634412343, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.862 with standard deviation 0.016. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "8a9c108e-4a57-4b94-a3da-c02498988552", "metadata": {"aucs": [0.8465651046886891, 0.856938437476586, 0.883859848158428], "final_y": [0.12729308178716803, 0.12168360098213715, 0.1146862134603106]}, "mutation_prompt": null}
{"id": "aee95ac4-7bfc-4a76-ab09-ddb71e8b2500", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor  \n            social_coeff = 1.5 * (1 - adaptive_factor)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                \n                # Apply velocity clamping\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Add diversity improvement: dynamically adjust population size\n            if np.std(swarm) < 0.001:\n                self.population_size = min(self.population_size + 1, int(0.1 * self.budget))  # Change made here\n                swarm = np.vstack([swarm, np.random.uniform(lb, ub, (1, self.dim))])  # Change made here\n                personal_best = np.vstack([personal_best, np.random.uniform(lb, ub, (1, self.dim))])  # Change made here\n                personal_best_value = np.append(personal_best_value, np.inf)  # Change made here\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with Dynamic Population Adjustments (ASGD-DPA): Dynamically adjusts population size based on current diversity to maintain effective exploration and exploitation balance.", "configspace": "", "generation": 4, "fitness": 0.8746030449806933, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.875 with standard deviation 0.007. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "8a9c108e-4a57-4b94-a3da-c02498988552", "metadata": {"aucs": [0.8665006466153913, 0.8738292837065006, 0.8834792046201877], "final_y": [0.12427935485925734, 0.11447504153796739, 0.11439118808203985]}, "mutation_prompt": null}
{"id": "3a67e8ce-9069-43ae-bc89-9041c5f9ca44", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor  \n            social_coeff = 1.5 * (1 - adaptive_factor)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                \n                # Apply adaptive velocity clamping\n                clamp_bound = 0.1 * (ub - lb) * (1 - adaptive_factor)  # Change made here\n                self.velocity[i] = np.clip(self.velocity[i], -clamp_bound, clamp_bound)\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Add diversity improvement: reintroduce random individuals if diversity is low\n            if np.std(swarm) < 0.001:\n                swarm[np.random.randint(self.population_size)] = np.random.uniform(lb, ub, self.dim)\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance velocity clamping by incorporating adaptive bounds based on the current best performance.", "configspace": "", "generation": 4, "fitness": 0.8620301611960576, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.862 with standard deviation 0.023. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "8a9c108e-4a57-4b94-a3da-c02498988552", "metadata": {"aucs": [0.8322124537487168, 0.864796440109378, 0.8890815897300778], "final_y": [0.11820226286688595, 0.12053306584525159, 0.11209052057109625]}, "mutation_prompt": null}
{"id": "38ca218c-6fb9-4d4d-8154-4fd69792e8fb", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor  \n            social_coeff = 1.5 * (1 - adaptive_factor)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                \n                # Apply velocity clamping\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Add diversity improvement: reintroduce random individuals if diversity is low\n            if np.std(swarm) < 0.001 * adaptive_factor:  # Change made here\n                swarm[np.random.randint(self.population_size)] = np.random.uniform(lb, ub, self.dim)\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with Dynamic Diversity Threshold for Improved Exploration.", "configspace": "", "generation": 4, "fitness": 0.8633183652678573, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.863 with standard deviation 0.009. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "8a9c108e-4a57-4b94-a3da-c02498988552", "metadata": {"aucs": [0.8530707401390386, 0.8756539635266057, 0.8612303921379276], "final_y": [0.12616916273611523, 0.11644507341190014, 0.11882405982146815]}, "mutation_prompt": null}
{"id": "e9660968-d960-482b-9cca-6d9399e1373b", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor  \n            social_coeff = 1.5 * (1 - adaptive_factor)\n\n            current_population_size = self.population_size - int(0.2 * self.population_size * evaluations / self.budget)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                \n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n            if np.std(swarm) < 0.001:\n                swarm[np.random.randint(current_population_size)] = np.random.uniform(lb, ub, self.dim)\n\n            # Local Search Intensification near Global Best\n            if evaluations < self.budget - 1:\n                neighbor = global_best + np.random.uniform(-0.01, 0.01, self.dim) * (ub - lb)\n                neighbor = np.clip(neighbor, lb, ub)\n                neighbor_value = func(neighbor)\n                evaluations += 1\n                if neighbor_value < global_best_value:\n                    global_best = neighbor\n                    global_best_value = neighbor_value\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with Local Search Intensification near Global Best.", "configspace": "", "generation": 5, "fitness": 0.8586276642314769, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.859 with standard deviation 0.013. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "5732d935-ed42-4068-9d16-b58ea5e6d629", "metadata": {"aucs": [0.8399589692636342, 0.8705548372494564, 0.8653691861813401], "final_y": [0.11836178623572569, 0.12392770940245224, 0.11409794482919056]}, "mutation_prompt": null}
{"id": "045843d8-9f07-4b96-852f-a77d65a2d115", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor  \n            social_coeff = 1.5 * (1 - adaptive_factor)\n\n            # Dynamically scale population size\n            current_population_size = self.population_size - int(0.2 * self.population_size * evaluations / self.budget)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                \n                # Apply velocity clamping\n                self.velocity[i] = np.clip(self.velocity[i], -0.2 * (ub - lb), 0.2 * (ub - lb))  # Changed\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Add diversity improvement: reintroduce random individuals if diversity is low\n            if np.std(swarm) < 0.001:\n                swarm[np.random.randint(current_population_size)] = np.random.uniform(lb, ub, self.dim)\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved Adaptive Swarm Gradient Descent with Enhanced Velocity Clamping for Better Convergence.", "configspace": "", "generation": 5, "fitness": 0.8713863676932222, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.871 with standard deviation 0.012. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "5732d935-ed42-4068-9d16-b58ea5e6d629", "metadata": {"aucs": [0.8623682454087007, 0.8885788265121058, 0.86321203115886], "final_y": [0.11251719665909377, 0.11186472839417494, 0.12051947438948529]}, "mutation_prompt": null}
{"id": "06e6f1cb-d1fe-4d04-af17-92985798f6d4", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)  # Modified line\n            social_coeff = 1.5 * (1 - adaptive_factor)\n\n            # Dynamically scale population size\n            current_population_size = self.population_size - int(0.2 * self.population_size * evaluations / self.budget)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                \n                # Apply velocity clamping\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Add diversity improvement: reintroduce random individuals if diversity is low\n            if np.std(swarm) < 0.001:\n                swarm[np.random.randint(current_population_size)] = np.random.uniform(lb, ub, self.dim)\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved Adaptive Swarm Gradient Descent with Time-Varying Coefficients for Enhanced Convergence Stability.", "configspace": "", "generation": 5, "fitness": 0.8847586395615935, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.885 with standard deviation 0.007. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "5732d935-ed42-4068-9d16-b58ea5e6d629", "metadata": {"aucs": [0.8796652665822364, 0.8943753561391512, 0.8802352959633929], "final_y": [0.11089159753431965, 0.11419177020923499, 0.11378001714230568]}, "mutation_prompt": null}
{"id": "97a3ed9c-0526-44ac-8b98-aec9ab171768", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor  \n            social_coeff = 1.5 * (1 - adaptive_factor)\n\n            # Dynamically scale population size\n            current_population_size = self.population_size - int(0.2 * self.population_size * evaluations / self.budget)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                \n                # Apply velocity clamping\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Add diversity improvement: reintroduce random individuals based on diversity and performance\n            if np.std(swarm) < 0.001 or evaluations / self.budget > 0.8:\n                swarm[np.random.randint(current_population_size)] = np.random.uniform(lb, ub, self.dim)\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with improved reintroduction strategy based on both diversity and performance.", "configspace": "", "generation": 5, "fitness": 0.8775028157151209, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.878 with standard deviation 0.014. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "5732d935-ed42-4068-9d16-b58ea5e6d629", "metadata": {"aucs": [0.8605617846627212, 0.8772540475746505, 0.8946926149079909], "final_y": [0.12181798306773683, 0.11423832044206816, 0.11066566972021075]}, "mutation_prompt": null}
{"id": "f3570ac3-02fe-4e8f-ac3b-8e3abc89cb93", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * (1 - adaptive_factor)\n            learning_rate = 0.01 + 0.04 * adaptive_factor\n            \n            # Dynamically scale population size\n            current_population_size = self.population_size - int(0.2 * self.population_size * evaluations / self.budget)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n\n                # Apply velocity clamping\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n\n                swarm[i] += self.velocity[i] * learning_rate\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Add diversity improvement: reintroduce random individuals if diversity is low\n            if np.std(swarm) < 0.001:\n                swarm[np.random.randint(current_population_size)] = np.random.uniform(lb, ub, self.dim)\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Integrate a dynamic learning rate with adaptive mutation injection to improve exploration and convergence.", "configspace": "", "generation": 5, "fitness": 0.8156184958292432, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.816 with standard deviation 0.088. And the mean value of best solutions found was 0.142 (0. is the best) with standard deviation 0.038.", "error": "", "parent_id": "5732d935-ed42-4068-9d16-b58ea5e6d629", "metadata": {"aucs": [0.6910215674404301, 0.8844388298691896, 0.87139509017811], "final_y": [0.1965997957132246, 0.11762425416344457, 0.11270054253602968]}, "mutation_prompt": null}
{"id": "71cdfcf8-dac7-4640-b4b1-cf2a8c372cc2", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (1 - adaptive_factor)\n\n            current_population_size = self.population_size - int(0.2 * self.population_size * evaluations / self.budget)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                \n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n            if np.std(swarm) < 0.001:\n                neighbor_index = np.random.randint(current_population_size)  # Added line\n                swarm[neighbor_index] = np.random.uniform(lb, ub, self.dim)\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with Time-Varying Dynamic Neighborhoods for Improved Solution Diversity.", "configspace": "", "generation": 6, "fitness": 0.8735679831848538, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.874 with standard deviation 0.003. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "06e6f1cb-d1fe-4d04-af17-92985798f6d4", "metadata": {"aucs": [0.8779103706249397, 0.8727743900309349, 0.8700191888986869], "final_y": [0.11426826088524134, 0.11418161761209966, 0.11215253932313873]}, "mutation_prompt": null}
{"id": "e6fe9914-8fac-40d7-bbe7-5e07ac295a9e", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 + 0.1 * adaptive_factor  # Modified line\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (1 - adaptive_factor)\n\n            # Dynamically scale population size\n            current_population_size = self.population_size - int(0.2 * self.population_size * evaluations / self.budget)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                \n                # Apply velocity clamping\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Add diversity improvement: reintroduce random individuals if diversity is low\n            if np.std(swarm) < 0.001:\n                swarm[np.random.randint(current_population_size)] = np.random.uniform(lb, ub, self.dim)\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Refined Adaptive Swarm Gradient Descent with Dynamic Inertia Weight Adjustment for Improved Exploration-Exploitation Balance.", "configspace": "", "generation": 6, "fitness": 0.8675096085791064, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.868 with standard deviation 0.003. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "06e6f1cb-d1fe-4d04-af17-92985798f6d4", "metadata": {"aucs": [0.8652553911362594, 0.8652245860661069, 0.8720488485349532], "final_y": [0.11827309953708598, 0.11521618119197496, 0.11183969363173363]}, "mutation_prompt": null}
{"id": "d08c8572-4803-4203-b907-2ded5f817db0", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(1, self.population_size // 5)  # Added line\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)  \n            social_coeff = 1.5 * (1 - adaptive_factor)\n\n            current_population_size = self.population_size - int(0.2 * self.population_size * evaluations / self.budget)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbors = np.random.choice(np.arange(self.population_size), self.neighborhood_size, replace=False)  # Added line\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]  # Added line\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))  # Modified line\n                \n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n            \n            if np.std(swarm) < 0.001:\n                for _ in range(self.neighborhood_size):  # Modified line\n                    idx = np.random.randint(current_population_size)\n                    swarm[idx] += np.random.uniform(-0.01, 0.01, self.dim)  # Modified line\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with Perturbation-Based Diversity Boost and Dynamic Topology for Improved Exploration and Exploitation Balance.", "configspace": "", "generation": 6, "fitness": 0.8653874992900192, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.865 with standard deviation 0.021. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "06e6f1cb-d1fe-4d04-af17-92985798f6d4", "metadata": {"aucs": [0.8380068370330414, 0.8693853871003857, 0.8887702737366309], "final_y": [0.12010705340520489, 0.11424050785671891, 0.11264051637309191]}, "mutation_prompt": null}
{"id": "a620c943-7c10-4928-b9fb-95c0cc5ed91a", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (1 - adaptive_factor)\n\n            # Dynamically scale population size\n            current_population_size = self.population_size - int(0.2 * self.population_size * evaluations / self.budget)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n\n                # Apply velocity clamping\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n\n                # Introduce dynamic mutation rate to enhance exploration\n                mutation_rate = 0.01 + 0.09 * adaptive_factor\n                if np.random.random() < mutation_rate:\n                    swarm[i] = np.random.uniform(lb, ub, self.dim)\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Add diversity improvement: reintroduce random individuals if diversity is low\n            if np.std(swarm) < 0.001:\n                swarm[np.random.randint(current_population_size)] = np.random.uniform(lb, ub, self.dim)\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent by Integrating a Dynamic Mutation Rate for Better Exploration.", "configspace": "", "generation": 6, "fitness": 0.8761429855487148, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.876 with standard deviation 0.010. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "06e6f1cb-d1fe-4d04-af17-92985798f6d4", "metadata": {"aucs": [0.8629335172434267, 0.8862116008326999, 0.879283838570018], "final_y": [0.12154381069442866, 0.11273117030761703, 0.1119095651321117]}, "mutation_prompt": null}
{"id": "f9ace63f-fa88-4309-870c-f7bf11123ba4", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.lb = None\n        self.ub = None\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        def nonlinear_inertia_weight(t, T):\n            return 0.9 - (0.5 * (t / T) ** 2)\n\n        def diversity_metric(swarm):\n            return np.mean(np.std(swarm, axis=0))\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = nonlinear_inertia_weight(evaluations, self.budget)\n            cognitive_coeff = 2.0 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 2.0 * (1 - adaptive_factor)\n            \n            current_population_size = self.population_size - int(0.2 * self.population_size * evaluations / self.budget)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (self.ub - self.lb), 0.1 * (self.ub - self.lb))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], self.lb, self.ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n            \n            if diversity_metric(swarm) < 0.01:\n                num_reintroduce = max(1, int(0.1 * current_population_size))\n                for _ in range(num_reintroduce):\n                    idx = np.random.randint(current_population_size)\n                    swarm[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with Diversity Control and Non-linear Inertia Weight for Improved Global Search.", "configspace": "", "generation": 6, "fitness": 0.8942141467600916, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.894 with standard deviation 0.013. And the mean value of best solutions found was 0.111 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "06e6f1cb-d1fe-4d04-af17-92985798f6d4", "metadata": {"aucs": [0.8776656470710561, 0.89587950185266, 0.9090972913565587], "final_y": [0.11158831470541308, 0.11181197931573927, 0.11002070582221501]}, "mutation_prompt": null}
{"id": "609427a4-1b63-4469-9b25-d1f5eaf186f2", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.lb = None\n        self.ub = None\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        def nonlinear_inertia_weight(t, T):\n            return 0.9 - (0.5 * (t / T) ** 2)\n\n        def diversity_metric(swarm):\n            return np.mean(np.std(swarm, axis=0))\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = nonlinear_inertia_weight(evaluations, self.budget)\n            cognitive_coeff = 2.0 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 2.0 * (1 - adaptive_factor)\n            \n            current_population_size = self.population_size - int(0.2 * self.population_size * evaluations / self.budget)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (self.ub - self.lb), 0.1 * (self.ub - self.lb))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], self.lb, self.ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n            \n            if diversity_metric(swarm) < 0.01:\n                num_reintroduce = max(1, int(0.1 * current_population_size))\n                for _ in range(num_reintroduce):\n                    idx = np.random.randint(current_population_size)\n                    perturbation = np.random.normal(0, 0.1, self.dim)  # Added perturbation strategy\n                    swarm[idx] = np.clip(swarm[idx] + perturbation, self.lb, self.ub)  # Apply perturbation\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with Perturbation Strategy for Escaping Local Minima and Improved Convergence.", "configspace": "", "generation": 7, "fitness": 0.8813522545103515, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.881 with standard deviation 0.011. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "f9ace63f-fa88-4309-870c-f7bf11123ba4", "metadata": {"aucs": [0.8872627417350636, 0.8660737274681418, 0.8907202943278489], "final_y": [0.1112802280637617, 0.11705364549690489, 0.1108842460255477]}, "mutation_prompt": null}
{"id": "babaa2dc-9492-4fd5-b36c-34f04ab454ef", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.lb = None\n        self.ub = None\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        def nonlinear_inertia_weight(t, T):\n            return 0.9 - (0.5 * (t / T) ** 2)\n\n        def diversity_metric(swarm):\n            return np.mean(np.std(swarm, axis=0))\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = nonlinear_inertia_weight(evaluations, self.budget)\n            # Changed cognitive_coeff factor for enhanced exploration\n            cognitive_coeff = 2.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 2.0 * (1 - adaptive_factor)\n            \n            current_population_size = self.population_size - int(0.2 * self.population_size * evaluations / self.budget)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (self.ub - self.lb), 0.1 * (self.ub - self.lb))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], self.lb, self.ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n            \n            if diversity_metric(swarm) < 0.01:\n                num_reintroduce = max(1, int(0.1 * current_population_size))\n                for _ in range(num_reintroduce):\n                    idx = np.random.randint(current_population_size)\n                    swarm[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with Modified Cognitive Coefficient for Enhanced Exploration.", "configspace": "", "generation": 7, "fitness": 0.883154304384274, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.883 with standard deviation 0.008. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "f9ace63f-fa88-4309-870c-f7bf11123ba4", "metadata": {"aucs": [0.8780853438287618, 0.877218519073521, 0.8941590502505392], "final_y": [0.1107842568436257, 0.1205978541613647, 0.11202249131497555]}, "mutation_prompt": null}
{"id": "b3fd52d7-5450-4d7e-af73-e87d9d5e2ee2", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.lb = None\n        self.ub = None\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        def nonlinear_inertia_weight(t, T):\n            return 0.9 - (0.5 * (t / T) ** 2)\n\n        def diversity_metric(swarm):\n            return np.mean(np.std(swarm, axis=0))\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = nonlinear_inertia_weight(evaluations, self.budget)\n            cognitive_coeff = 2.0 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 2.0 * (1 - adaptive_factor)\n            \n            current_population_size = self.population_size - int(0.2 * self.population_size * evaluations / self.budget)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n\n                self.velocity[i] = np.clip(self.velocity[i], -0.15 * (self.ub - self.lb), 0.15 * (self.ub - self.lb))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], self.lb, self.ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n            \n            if diversity_metric(swarm) < 0.015:\n                num_reintroduce = max(1, int(0.15 * current_population_size))\n                for _ in range(num_reintroduce):\n                    idx = np.random.randint(current_population_size)\n                    swarm[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Improved swarm diversity control and adaptive learning rates for enhanced global search efficiency.", "configspace": "", "generation": 7, "fitness": 0.87729072830044, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.877 with standard deviation 0.019. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "f9ace63f-fa88-4309-870c-f7bf11123ba4", "metadata": {"aucs": [0.85286323210025, 0.8800059333225533, 0.8990030194785168], "final_y": [0.12020452187535657, 0.12133980012235401, 0.1104136962050255]}, "mutation_prompt": null}
{"id": "9f39589f-3d84-401b-a982-9ec35c2ea54e", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.lb = None\n        self.ub = None\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        def nonlinear_inertia_weight(t, T):\n            return 0.9 - (0.5 * (t / T) ** 2)\n\n        def diversity_metric(swarm):\n            return np.mean(np.std(swarm, axis=0))\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = nonlinear_inertia_weight(evaluations, self.budget)\n            cognitive_coeff = 2.0 * (0.75 + 0.25 * adaptive_factor)  # Modified line\n            social_coeff = 2.0 * (1 - adaptive_factor)\n            \n            current_population_size = self.population_size - int(0.2 * self.population_size * evaluations / self.budget)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (self.ub - self.lb), 0.1 * (self.ub - self.lb))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], self.lb, self.ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n            \n            if diversity_metric(swarm) < 0.01:\n                num_reintroduce = max(1, int(0.1 * current_population_size))\n                for _ in range(num_reintroduce):\n                    idx = np.random.randint(current_population_size)\n                    swarm[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Increment the adaptive factor's impact on cognitive and social coefficients for sharper focus on global and personal bests.", "configspace": "", "generation": 7, "fitness": 0.8871116378652789, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.887 with standard deviation 0.005. And the mean value of best solutions found was 0.111 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "f9ace63f-fa88-4309-870c-f7bf11123ba4", "metadata": {"aucs": [0.8852726586180946, 0.8819555625495876, 0.8941066924281548], "final_y": [0.1118231100998116, 0.11225470921931868, 0.10986709548388807]}, "mutation_prompt": null}
{"id": "f8240b00-83a5-4d8c-84c0-7a8fc452679e", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.lb = None\n        self.ub = None\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        def nonlinear_inertia_weight(t, T):\n            return 0.9 - (0.5 * (t / T) ** 2)\n\n        def diversity_metric(swarm):\n            return np.mean(np.std(swarm, axis=0))\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = nonlinear_inertia_weight(evaluations, self.budget)\n            cognitive_coeff = 2.0 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 2.0 * (1.1 - adaptive_factor)  # Modified line\n\n            current_population_size = self.population_size - int(0.15 * self.population_size * evaluations / self.budget)  # Modified line\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n\n                self.velocity[i] = np.clip(self.velocity[i], -0.2 * (self.ub - self.lb), 0.2 * (self.ub - self.lb))  # Modified line\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], self.lb, self.ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n            \n            if diversity_metric(swarm) < 0.01:\n                num_reintroduce = max(1, int(0.1 * current_population_size))\n                for _ in range(num_reintroduce):\n                    idx = np.random.randint(current_population_size)\n                    swarm[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Refined Adaptive Swarm Gradient Descent with Enhanced Exploration and Dynamic Population Resizing for Superior Convergence Performance.", "configspace": "", "generation": 7, "fitness": 0.8949829308397805, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.895 with standard deviation 0.009. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "f9ace63f-fa88-4309-870c-f7bf11123ba4", "metadata": {"aucs": [0.8824089402139226, 0.9019380342113376, 0.9006018180940812], "final_y": [0.11439481153700704, 0.11222726343134304, 0.11162487060276449]}, "mutation_prompt": null}
{"id": "e6ef7b74-c00e-4388-af06-2acd4e39e607", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.lb = None\n        self.ub = None\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        def nonlinear_inertia_weight(t, T):\n            return 0.9 - (0.5 * (t / T) ** 2)\n\n        def diversity_metric(swarm):\n            return np.mean(np.std(swarm, axis=0))\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = nonlinear_inertia_weight(evaluations, self.budget)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)  # Modified line\n            social_coeff = 2.0 * (1.1 - adaptive_factor)  # Modified line\n\n            current_population_size = self.population_size - int(0.15 * self.population_size * evaluations / self.budget)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n\n                self.velocity[i] = np.clip(self.velocity[i], -0.2 * (self.ub - self.lb), 0.2 * (self.ub - self.lb))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], self.lb, self.ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n            \n            if diversity_metric(swarm) < 0.01:\n                num_reintroduce = max(1, int(0.1 * current_population_size))\n                for _ in range(num_reintroduce):\n                    idx = np.random.randint(current_population_size)\n                    swarm[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Improved Adaptive Swarm Gradient Descent with enhanced exploitation through adaptive cognitive coefficient adjustment.", "configspace": "", "generation": 8, "fitness": 0.8941161380654697, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.894 with standard deviation 0.007. And the mean value of best solutions found was 0.112 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f8240b00-83a5-4d8c-84c0-7a8fc452679e", "metadata": {"aucs": [0.8847888086217557, 0.8956013199625373, 0.9019582856121163], "final_y": [0.1117995556830571, 0.11183741689524385, 0.11171158227795819]}, "mutation_prompt": null}
{"id": "27eec909-6304-4af9-87ac-bd2e4bb1837f", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.lb = None\n        self.ub = None\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        def nonlinear_inertia_weight(t, T):\n            return 0.9 - (0.5 * (t / T) ** 2)\n\n        def diversity_metric(swarm):\n            return np.mean(np.std(swarm, axis=0))\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = nonlinear_inertia_weight(evaluations, self.budget)\n            cognitive_coeff = 2.0 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 2.0 * (1.1 - adaptive_factor)  # Modified line\n\n            current_population_size = self.population_size - int(0.15 * self.population_size * evaluations / self.budget)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n\n                self.velocity[i] = np.clip(self.velocity[i], -0.2 * (self.ub - self.lb), 0.2 * (self.ub - self.lb))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], self.lb, self.ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n            \n            if diversity_metric(swarm) < 0.01:\n                num_reintroduce = max(1, int(0.1 * current_population_size))\n                for _ in range(num_reintroduce):\n                    idx = np.random.randint(current_population_size)\n                    swarm[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with Nonlinear Cognitive and Social Coefficients for Improved Convergence.", "configspace": "", "generation": 8, "fitness": 0.8871468805334057, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.887 with standard deviation 0.009. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "f8240b00-83a5-4d8c-84c0-7a8fc452679e", "metadata": {"aucs": [0.890486144510735, 0.8753211682978798, 0.8956333287916026], "final_y": [0.11002698068311245, 0.11744426315764311, 0.11113351444820374]}, "mutation_prompt": null}
{"id": "c07e8a91-b960-473a-aebd-2a20f4c8111b", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.lb = None\n        self.ub = None\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        def nonlinear_inertia_weight(t, T):\n            return 0.9 - (0.5 * (t / T) ** 2)\n\n        def diversity_metric(swarm):\n            return np.mean(np.std(swarm, axis=0))\n\n        last_improvement = 0  # Added line\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = nonlinear_inertia_weight(evaluations, self.budget)\n            cognitive_coeff = 2.0 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 2.0 * (1.2 - adaptive_factor)  # Modified line\n\n            current_population_size = self.population_size - int(0.15 * self.population_size * evaluations / self.budget)  # Modified line\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n\n                self.velocity[i] = np.clip(self.velocity[i], -0.25 * (self.ub - self.lb), 0.25 * (self.ub - self.lb))  # Modified line\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], self.lb, self.ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n                    last_improvement = evaluations  # Added line\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    last_improvement = evaluations  # Added line\n\n                if evaluations >= self.budget:\n                    break\n            \n            if evaluations - last_improvement > 0.02 * self.budget:  # Added line\n                num_reintroduce = max(1, int(0.1 * current_population_size))\n                for _ in range(num_reintroduce):\n                    idx = np.random.randint(current_population_size)\n                    swarm[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Adaptive Swarm Gradient Descent with Improved Social Dynamics, Velocity Capping, and Early Stagnation Detection for Enhanced Optimization.", "configspace": "", "generation": 8, "fitness": 0.8821656188940468, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.882 with standard deviation 0.019. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "f8240b00-83a5-4d8c-84c0-7a8fc452679e", "metadata": {"aucs": [0.8707032773563962, 0.8672270438604318, 0.9085665354653124], "final_y": [0.11580364065579896, 0.11814182219707925, 0.11479669496925393]}, "mutation_prompt": null}
{"id": "51393069-683b-4295-aca5-480b9ca809ab", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.lb = None\n        self.ub = None\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        def nonlinear_inertia_weight(t, T):\n            return 0.9 - (0.5 * (t / T) ** 2)\n\n        def diversity_metric(swarm):\n            return np.mean(np.std(swarm, axis=0))\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = nonlinear_inertia_weight(evaluations, self.budget)\n            cognitive_coeff = 2.0 * (0.5 + 0.5 * adaptive_factor**2)  # Modified line\n            social_coeff = 2.0 * (1.1 - adaptive_factor**2)  # Modified line\n\n            current_population_size = self.population_size - int(0.15 * self.population_size * evaluations / self.budget)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n\n                self.velocity[i] = np.clip(self.velocity[i], -0.2 * (self.ub - self.lb), 0.2 * (self.ub - self.lb))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], self.lb, self.ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n            \n            if diversity_metric(swarm) < 0.01:\n                num_reintroduce = max(1, int(0.1 * current_population_size))\n                for _ in range(num_reintroduce):\n                    idx = np.random.randint(current_population_size)\n                    swarm[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Further enhanced swarm intelligence with nonlinear cognitive and social coefficients for improved exploration-exploitation balance.", "configspace": "", "generation": 8, "fitness": 0.8850645909070999, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.885 with standard deviation 0.006. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "f8240b00-83a5-4d8c-84c0-7a8fc452679e", "metadata": {"aucs": [0.876060116504291, 0.8887093146649067, 0.8904243415521017], "final_y": [0.11412146634688092, 0.11678763478512422, 0.11215478555733094]}, "mutation_prompt": null}
{"id": "ebc8a196-ba24-400c-9801-0836441a5f81", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.lb = None\n        self.ub = None\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        def nonlinear_inertia_weight(t, T):\n            return 0.9 - (0.5 * (t / T) ** 3)  # Modified line\n\n        def diversity_metric(swarm):\n            return np.mean(np.std(swarm, axis=0))\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = nonlinear_inertia_weight(evaluations, self.budget)\n            cognitive_coeff = 2.0 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 2.0 * (1.1 - adaptive_factor)\n\n            current_population_size = self.population_size - int(0.15 * self.population_size * evaluations / self.budget)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n\n                self.velocity[i] = np.clip(self.velocity[i], -0.2 * (self.ub - self.lb), 0.2 * (self.ub - self.lb))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], self.lb, self.ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n            \n            if diversity_metric(swarm) < 0.01:\n                num_reintroduce = max(1, int(0.1 * current_population_size))\n                for _ in range(num_reintroduce):\n                    idx = np.random.randint(current_population_size)\n                    swarm[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Further refined Enhanced Adaptive Swarm Gradient Descent with dynamic inertia adjustment for improved convergence stability.", "configspace": "", "generation": 8, "fitness": 0.873356368506269, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.873 with standard deviation 0.015. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "f8240b00-83a5-4d8c-84c0-7a8fc452679e", "metadata": {"aucs": [0.8677538212786674, 0.8589409752848506, 0.8933743089552891], "final_y": [0.11636237306845232, 0.12680224839018428, 0.11062794392286568]}, "mutation_prompt": null}
{"id": "43e87050-03d9-4b1e-a547-e2e621130f3d", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.lb = None\n        self.ub = None\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        def nonlinear_inertia_weight(t, T):\n            return 0.9 - (0.5 * (t / T) ** 2)\n\n        def diversity_metric(swarm):\n            return np.mean(np.std(swarm, axis=0))\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = nonlinear_inertia_weight(evaluations, self.budget)\n            cognitive_coeff = 2.0 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 2.0 * (1.1 - adaptive_factor)\n\n            current_population_size = self.population_size - int(0.15 * self.population_size * evaluations / self.budget)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n\n                self.velocity[i] *= (0.5 + 0.5 * adaptive_factor)  # Modified line\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], self.lb, self.ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n            \n            if diversity_metric(swarm) < 0.01:\n                num_reintroduce = max(1, int(0.1 * current_population_size))\n                for _ in range(num_reintroduce):\n                    idx = np.random.randint(current_population_size)\n                    swarm[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                    swarm[idx] += np.random.normal(0, 0.1, self.dim)  # Modified line\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Improved algorithm by introducing local search enhancement and adaptive velocity scaling to maintain diversity and intensify search.", "configspace": "", "generation": 9, "fitness": 0.8343833652282159, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.834 with standard deviation 0.047. And the mean value of best solutions found was 0.138 (0. is the best) with standard deviation 0.019.", "error": "", "parent_id": "f8240b00-83a5-4d8c-84c0-7a8fc452679e", "metadata": {"aucs": [0.8952432543968435, 0.8280111381889537, 0.7798957030988503], "final_y": [0.11289131484206627, 0.14381011379215147, 0.1580858781246326]}, "mutation_prompt": null}
{"id": "baa6f27c-d84b-4fad-8a3b-95868b433b6a", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.lb = None\n        self.ub = None\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        def nonlinear_inertia_weight(t, T):\n            return 0.9 - (0.4 * (t / T) ** 2)  # Modified line\n\n        def diversity_metric(swarm):\n            return np.mean(np.std(swarm, axis=0))\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = nonlinear_inertia_weight(evaluations, self.budget)\n            cognitive_coeff = 2.0 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 2.0 * (1.1 - adaptive_factor)\n\n            current_population_size = self.population_size - int(0.15 * self.population_size * evaluations / self.budget)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n\n                self.velocity[i] = np.clip(self.velocity[i], -0.2 * (self.ub - self.lb), 0.2 * (self.ub - self.lb))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], self.lb, self.ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n            \n            if diversity_metric(swarm) < 0.015:  # Modified line\n                num_reintroduce = max(1, int(0.15 * current_population_size))  # Modified line\n                for _ in range(num_reintroduce):\n                    idx = np.random.randint(current_population_size)\n                    swarm[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with Improved Nonlinear Inertia and Diversity-Driven Reintroduction for Optimized Convergence Performance.", "configspace": "", "generation": 9, "fitness": 0.8290789995491025, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.829 with standard deviation 0.043. And the mean value of best solutions found was 0.138 (0. is the best) with standard deviation 0.020.", "error": "", "parent_id": "f8240b00-83a5-4d8c-84c0-7a8fc452679e", "metadata": {"aucs": [0.8829869408307288, 0.827376571511988, 0.7768734863045907], "final_y": [0.11037900192812633, 0.14382324170274763, 0.15898384269219867]}, "mutation_prompt": null}
{"id": "c51857a8-8d7a-4c5e-99c1-8e7ede4f73ba", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.lb = None\n        self.ub = None\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        def nonlinear_inertia_weight(t, T):\n            return 0.9 - (0.5 * (t / T) ** 2)\n\n        def diversity_metric(swarm):\n            return np.mean(np.std(swarm, axis=0))\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = nonlinear_inertia_weight(evaluations, self.budget)\n            cognitive_coeff = 2.0 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 2.0 * (1.1 - adaptive_factor)\n\n            current_population_size = self.population_size - int(0.15 * self.population_size * evaluations / self.budget)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n\n                # Updated line: Adaptive velocity limits\n                velocity_limit = 0.2 * (self.ub - self.lb) * (1 - evaluations / self.budget)\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_limit, velocity_limit)\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], self.lb, self.ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n            \n            if diversity_metric(swarm) < 0.01:\n                num_reintroduce = max(1, int(0.1 * current_population_size))\n                for _ in range(num_reintroduce):\n                    idx = np.random.randint(current_population_size)\n                    swarm[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Incorporating adaptive velocity limits in the Refined Adaptive Swarm Gradient Descent to enhance convergence rates while respecting the 1.5% code change constraint.", "configspace": "", "generation": 9, "fitness": 0.8160657561702352, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.816 with standard deviation 0.031. And the mean value of best solutions found was 0.146 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "f8240b00-83a5-4d8c-84c0-7a8fc452679e", "metadata": {"aucs": [0.8482443321352193, 0.8262894119764919, 0.7736635243989943], "final_y": [0.1321578954715854, 0.14251072680651344, 0.1626275399952235]}, "mutation_prompt": null}
{"id": "54725a96-5749-4c1f-8c62-b6bb7ccd12f9", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.lb = None\n        self.ub = None\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        def nonlinear_inertia_weight(t, T):\n            return 0.9 - (0.5 * (t / T) ** 2)\n\n        def diversity_metric(swarm):\n            return np.mean(np.std(swarm, axis=0))\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = nonlinear_inertia_weight(evaluations, self.budget)\n            cognitive_coeff = 2.0 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 2.0 * (1.1 - adaptive_factor)\n\n            current_population_size = self.population_size - int(0.15 * self.population_size * evaluations / self.budget)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n\n                self.velocity[i] = np.clip(self.velocity[i], -0.3 * (self.ub - self.lb), 0.3 * (self.ub - self.lb))  # Modified line\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], self.lb, self.ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n            \n            if diversity_metric(swarm) < 0.01:\n                num_reintroduce = max(1, int(0.1 * current_population_size))\n                for _ in range(num_reintroduce):\n                    idx = np.random.randint(current_population_size)\n                    swarm[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Improved velocity clipping to enhance exploration capabilities while maintaining stability.", "configspace": "", "generation": 9, "fitness": 0.8386145661882752, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.839 with standard deviation 0.028. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "f8240b00-83a5-4d8c-84c0-7a8fc452679e", "metadata": {"aucs": [0.8782678261194381, 0.8146412609804776, 0.8229346114649102], "final_y": [0.1156331184384547, 0.14702871444283783, 0.1376395267254623]}, "mutation_prompt": null}
{"id": "c5bc66dd-666f-4e9f-be40-17cd552904b9", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.lb = None\n        self.ub = None\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        def nonlinear_inertia_weight(t, T):\n            return 0.9 - (0.5 * (t / T) ** 2)\n\n        def diversity_metric(swarm):\n            return np.mean(np.std(swarm, axis=0))\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = nonlinear_inertia_weight(evaluations, self.budget)\n            cognitive_coeff = 2.0 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 2.0 * (1.1 - adaptive_factor)  # Modified line\n\n            current_population_size = self.population_size - int(0.15 * self.population_size * evaluations / self.budget)  # Modified line\n            learning_rate = 0.1 + 0.4 * adaptive_factor  # New Line\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n\n                self.velocity[i] *= learning_rate  # Adjust learning rate\n\n                self.velocity[i] = np.clip(self.velocity[i], -0.2 * (self.ub - self.lb), 0.2 * (self.ub - self.lb))  # Modified line\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], self.lb, self.ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n            \n            if diversity_metric(swarm) < 0.01:\n                num_reintroduce = max(1, int(0.1 * current_population_size))\n                for _ in range(num_reintroduce):\n                    idx = np.random.randint(current_population_size)\n                    swarm[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Integrated Adaptive Learning Rate with Momentum to Further Enhance Convergence Speed and Stability in Swarm Dynamics.", "configspace": "", "generation": 9, "fitness": 0.7922102997133639, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.792 with standard deviation 0.026. And the mean value of best solutions found was 0.156 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "f8240b00-83a5-4d8c-84c0-7a8fc452679e", "metadata": {"aucs": [0.7973186598611562, 0.8211127436938098, 0.7581994955851259], "final_y": [0.15175925185522754, 0.14686670048270878, 0.16822112148566015]}, "mutation_prompt": null}
{"id": "5bb9b3a9-8627-4cb6-bcb8-ca598764b378", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.lb = None\n        self.ub = None\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        def nonlinear_inertia_weight(t, T):\n            return 0.9 - (0.5 * (t / T) ** 2)\n\n        def diversity_metric(swarm):\n            return np.mean(np.std(swarm, axis=0))\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = nonlinear_inertia_weight(evaluations, self.budget)\n            cognitive_coeff = 2.0 * (0.5 + 0.5 * adaptive_factor * np.sin(np.pi * evaluations / self.budget))  # Modified line\n            social_coeff = 2.0 * (1.1 - adaptive_factor)\n\n            current_population_size = self.population_size - int(0.15 * self.population_size * evaluations / self.budget)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n\n                self.velocity[i] = np.clip(self.velocity[i], -0.2 * (self.ub - self.lb), 0.2 * (self.ub - self.lb))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], self.lb, self.ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n            \n            if diversity_metric(swarm) < 0.01:\n                num_reintroduce = max(1, int(0.1 * current_population_size))\n                for _ in range(num_reintroduce):\n                    idx = np.random.randint(current_population_size)\n                    swarm[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Introduced a dynamic cognitive coefficient to balance exploration and exploitation for improved convergence in black box optimization.", "configspace": "", "generation": 10, "fitness": 0.8762171162976443, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.876 with standard deviation 0.021. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "f8240b00-83a5-4d8c-84c0-7a8fc452679e", "metadata": {"aucs": [0.8891550026219572, 0.8928714469182258, 0.8466248993527501], "final_y": [0.11155487857870527, 0.11632681353796148, 0.12544135255319544]}, "mutation_prompt": null}
{"id": "f96b22ac-ecc2-4f59-b51c-73517b46d2f0", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.lb = None\n        self.ub = None\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        def nonlinear_inertia_weight(t, T):\n            return 0.9 - (0.5 * (t / T) ** 2)\n\n        def diversity_metric(swarm):\n            return np.mean(np.std(swarm, axis=0))\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = nonlinear_inertia_weight(evaluations, self.budget)\n            cognitive_coeff = 2.0 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 2.0 * (1.1 - adaptive_factor)  # Modified line\n\n            current_population_size = self.population_size - int(0.15 * self.population_size * evaluations / self.budget)  # Modified line\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (self.ub - self.lb), 0.1 * (self.ub - self.lb))  # Modified line\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], self.lb, self.ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n            \n            if diversity_metric(swarm) < 0.01:\n                num_reintroduce = max(1, int(0.1 * current_population_size))\n                for _ in range(num_reintroduce):\n                    idx = np.random.randint(current_population_size)\n                    swarm[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Refined Adaptive Swarm Gradient Descent with Optimized Velocity Clipping for Enhanced Convergence Performance.", "configspace": "", "generation": 10, "fitness": 0.8887149629392915, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.889 with standard deviation 0.014. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "f8240b00-83a5-4d8c-84c0-7a8fc452679e", "metadata": {"aucs": [0.9080134841305786, 0.8760358082243938, 0.8820955964629023], "final_y": [0.11175523962124567, 0.1166665620707017, 0.1117379690358078]}, "mutation_prompt": null}
{"id": "7fd4dbd8-bcd4-4db7-bb4d-640b02da84da", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.lb = None\n        self.ub = None\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        def nonlinear_inertia_weight(t, T):\n            return 0.9 - (0.5 * (t / T) ** 2)\n\n        def diversity_metric(swarm):\n            return np.mean(np.std(swarm, axis=0))\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = nonlinear_inertia_weight(evaluations, self.budget)\n            cognitive_coeff = 2.5 * (0.5 + 0.5 * adaptive_factor)  # Modified line\n            social_coeff = 1.5 * (1.1 - adaptive_factor)  # Modified line\n\n            current_population_size = self.population_size - int(0.15 * self.population_size * evaluations / self.budget)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n\n                self.velocity[i] = np.clip(self.velocity[i], -0.2 * (self.ub - self.lb), 0.2 * (self.ub - self.lb))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], self.lb, self.ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n            \n            if diversity_metric(swarm) < 0.02:  # Modified line\n                num_reintroduce = max(1, int(0.1 * current_population_size))\n                for _ in range(num_reintroduce):\n                    idx = np.random.randint(current_population_size)\n                    swarm[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Improved Adaptive Swarm Gradient Descent with Enhanced Diversity Retention and Optimized Cognitive-Social Coefficients for Better Convergence.", "configspace": "", "generation": 10, "fitness": 0.8952843201734839, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.895 with standard deviation 0.014. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "f8240b00-83a5-4d8c-84c0-7a8fc452679e", "metadata": {"aucs": [0.8799501280895673, 0.891638884492657, 0.9142639479382276], "final_y": [0.1157587644944944, 0.11289566670543993, 0.11024778760786846]}, "mutation_prompt": null}
{"id": "ac1d2e17-04d3-4580-9f42-d8e07094aea8", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.lb = None\n        self.ub = None\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        def nonlinear_inertia_weight(t, T):\n            return 0.9 - (0.5 * (t / T) ** 2)\n\n        def diversity_metric(swarm):\n            return np.mean(np.std(swarm, axis=0))\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = nonlinear_inertia_weight(evaluations, self.budget)\n            cognitive_coeff = 2.0 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 2.0 * (1.1 - adaptive_factor)\n\n            current_population_size = self.population_size - int(0.15 * self.population_size * evaluations / self.budget)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n\n                self.velocity[i] = np.clip(self.velocity[i], -adaptive_factor * (self.ub - self.lb), adaptive_factor * (self.ub - self.lb))  # Modified line\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], self.lb, self.ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n            \n            if diversity_metric(swarm) < 0.02:  # Modified line\n                num_reintroduce = max(1, int(0.15 * current_population_size))  # Modified line\n                for _ in range(num_reintroduce):\n                    idx = np.random.randint(current_population_size)\n                    swarm[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Enhanced Swarm Gradient Descent with Adaptive Velocity Clipping and Population Diversity Boost for Optimized Convergence.", "configspace": "", "generation": 10, "fitness": 0.889926120212006, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.890 with standard deviation 0.023. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "f8240b00-83a5-4d8c-84c0-7a8fc452679e", "metadata": {"aucs": [0.857638144679191, 0.9013937587478668, 0.91074645720896], "final_y": [0.11723205197728881, 0.11206831435413378, 0.11261899231204187]}, "mutation_prompt": null}
{"id": "1bcbb69f-d196-4e41-97a3-00ce8314455f", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.lb = None\n        self.ub = None\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        def nonlinear_inertia_weight(t, T):\n            return 0.9 - (0.5 * (t / T) ** 2)\n\n        def diversity_metric(swarm):\n            return np.mean(np.std(swarm, axis=0))\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = nonlinear_inertia_weight(evaluations, self.budget)\n            cognitive_coeff = 1.8 * (0.5 + 0.5 * adaptive_factor)  # Modified line\n            social_coeff = 2.0 * (1.1 - adaptive_factor)\n\n            current_population_size = self.population_size - int(0.15 * self.population_size * evaluations / self.budget)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n\n                self.velocity[i] = np.clip(self.velocity[i], -0.2 * (self.ub - self.lb), 0.2 * (self.ub - self.lb))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], self.lb, self.ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n            \n            if diversity_metric(swarm) < 0.01:\n                num_reintroduce = max(1, int(0.1 * current_population_size))\n                for _ in range(num_reintroduce):\n                    idx = np.random.randint(current_population_size)\n                    swarm[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Modified Cognitive Coefficient for Adaptive Learning to Enhance Solution Convergence and Exploration Balance.", "configspace": "", "generation": 10, "fitness": 0.8827198027446009, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.883 with standard deviation 0.024. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "f8240b00-83a5-4d8c-84c0-7a8fc452679e", "metadata": {"aucs": [0.8489682158840848, 0.8928454772629426, 0.9063457150867753], "final_y": [0.12105958577370735, 0.11651661573006455, 0.11080054896449731]}, "mutation_prompt": null}
{"id": "632213c7-497a-4319-85a1-9fb565e7dc5f", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.lb = None\n        self.ub = None\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        def nonlinear_inertia_weight(t, T):\n            return 0.9 - (0.5 * (t / T) ** 2)\n\n        def diversity_metric(swarm):\n            return np.mean(np.std(swarm, axis=0))\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = nonlinear_inertia_weight(evaluations, self.budget)\n            cognitive_coeff = 2.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (1.2 - 0.7 * adaptive_factor)  # Modified line\n\n            current_population_size = self.population_size - int(0.15 * self.population_size * evaluations / self.budget)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n\n                self.velocity[i] = np.clip(self.velocity[i], -0.2 * (self.ub - self.lb), 0.2 * (self.ub - self.lb))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], self.lb, self.ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n            \n            if diversity_metric(swarm) < 0.02:\n                num_reintroduce = max(1, int(0.1 * current_population_size))\n                for _ in range(num_reintroduce):\n                    idx = np.random.randint(current_population_size)\n                    swarm[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Modified social coefficient dynamics to enhance exploration-exploitation balance for improved solution accuracy.", "configspace": "", "generation": 11, "fitness": 0.8790692352031763, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.879 with standard deviation 0.015. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "7fd4dbd8-bcd4-4db7-bb4d-640b02da84da", "metadata": {"aucs": [0.8579232096592102, 0.887257051926799, 0.8920274440235195], "final_y": [0.11461222343248012, 0.12013893885292082, 0.11230632275149066]}, "mutation_prompt": null}
{"id": "60f5808d-2e03-4b39-97e2-6bbd983bec03", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.lb = None\n        self.ub = None\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        def nonlinear_inertia_weight(t, T):\n            return 0.9 - (0.5 * (t / T) ** 2)\n\n        def diversity_metric(swarm):\n            return np.mean(np.std(swarm, axis=0))\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = nonlinear_inertia_weight(evaluations, self.budget)\n            cognitive_coeff = 2.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (1.1 - adaptive_factor)\n\n            current_population_size = self.population_size - int(0.15 * self.population_size * evaluations / self.budget)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dynamic_coeff = 1.2 + 0.3 * np.sin(np.pi * evaluations / self.budget)  # Modified line\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n\n                self.velocity[i] = np.clip(self.velocity[i], -0.2 * (self.ub - self.lb), 0.2 * (self.ub - self.lb))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], self.lb, self.ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n            \n            if diversity_metric(swarm) < 0.02:\n                num_reintroduce = max(1, int(0.1 * current_population_size))\n                for _ in range(num_reintroduce):\n                    idx = np.random.randint(current_population_size)\n                    swarm[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Enhanced convergence by introducing a dynamic adaptive coefficient in velocity update.", "configspace": "", "generation": 11, "fitness": 0.8782079363996611, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.878 with standard deviation 0.006. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "7fd4dbd8-bcd4-4db7-bb4d-640b02da84da", "metadata": {"aucs": [0.8857375741127628, 0.8702993917758484, 0.8785868433103722], "final_y": [0.11062499936833126, 0.1162770797281788, 0.11525581083819292]}, "mutation_prompt": null}
{"id": "87b776c2-ca35-4ce3-b6cf-6b91840f63bf", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.lb = None\n        self.ub = None\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        def nonlinear_inertia_weight(t, T):\n            return 0.9 - (0.3 * (t / T) ** 2)  # Modified line\n\n        def diversity_metric(swarm):\n            return np.mean(np.std(swarm, axis=0))\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = nonlinear_inertia_weight(evaluations, self.budget)\n            cognitive_coeff = 2.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (1.1 - adaptive_factor)\n\n            current_population_size = self.population_size - int(0.15 * self.population_size * evaluations / self.budget)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n\n                self.velocity[i] = np.clip(self.velocity[i], -0.2 * (self.ub - self.lb), 0.2 * (self.ub - self.lb))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], self.lb, self.ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n            \n            if diversity_metric(swarm) < 0.02:\n                num_reintroduce = max(1, int(0.1 * current_population_size))\n                for _ in range(num_reintroduce):\n                    idx = np.random.randint(current_population_size)\n                    swarm[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with Fine-Tuned Inertia Weight for Improved Exploration-Exploitation Balance.", "configspace": "", "generation": 11, "fitness": 0.8753986357257704, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.875 with standard deviation 0.030. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "7fd4dbd8-bcd4-4db7-bb4d-640b02da84da", "metadata": {"aucs": [0.8351215863406287, 0.8837387326006878, 0.9073355882359944], "final_y": [0.13225596187056432, 0.1197286271826079, 0.11210679924884381]}, "mutation_prompt": null}
{"id": "1980e7f8-3763-4fd4-ab94-c153a11d5e27", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.lb = None\n        self.ub = None\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        def nonlinear_inertia_weight(t, T):\n            return 0.9 - (0.5 * (t / T) ** 2)\n\n        def diversity_metric(swarm):\n            return np.mean(np.std(swarm, axis=0))\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = nonlinear_inertia_weight(evaluations, self.budget)\n            cognitive_coeff = 2.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (1.1 - adaptive_factor)\n\n            current_population_size = self.population_size - int(0.15 * self.population_size * evaluations / self.budget)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n\n                self.velocity[i] = np.clip(self.velocity[i], -0.2 * (self.ub - self.lb), 0.2 * (self.ub - self.lb))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], self.lb, self.ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n            \n            if diversity_metric(swarm) < 0.03:  # Changed line\n                num_reintroduce = max(1, int(0.2 * current_population_size))  # Changed line\n                for _ in range(num_reintroduce):\n                    idx = np.random.randint(current_population_size)\n                    swarm[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with Dynamic Reintroduction and Adjusted Convergence Pressure for Improved Diversity and Exploration.", "configspace": "", "generation": 11, "fitness": 0.885628899086957, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.886 with standard deviation 0.010. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "7fd4dbd8-bcd4-4db7-bb4d-640b02da84da", "metadata": {"aucs": [0.8974103052173161, 0.885434335891359, 0.8740420561521958], "final_y": [0.1108005007062135, 0.12029952407124522, 0.11956684417256835]}, "mutation_prompt": null}
{"id": "7b0944b4-60f7-485c-ae48-a27c52caf51b", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.lb = None\n        self.ub = None\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        def nonlinear_inertia_weight(t, T):\n            return 0.9 - (0.5 * (t / T) ** 2)\n\n        def diversity_metric(swarm):\n            return np.mean(np.std(swarm, axis=0))\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = nonlinear_inertia_weight(evaluations, self.budget)\n            cognitive_coeff = 2.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (1.1 - adaptive_factor)\n\n            current_population_size = self.population_size - int(0.15 * self.population_size * evaluations / self.budget)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n\n                velocity_clamp_factor = 0.2 * (1 - (evaluations / self.budget))  # Modified line\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp_factor * (self.ub - self.lb), velocity_clamp_factor * (self.ub - self.lb))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], self.lb, self.ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n            \n            if diversity_metric(swarm) < 0.03:  # Modified line\n                num_reintroduce = max(1, int(0.1 * current_population_size))\n                for _ in range(num_reintroduce):\n                    idx = np.random.randint(current_population_size)\n                    swarm[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Refined Enhanced Adaptive Swarm Gradient Descent with Nonlinear Adaptive Velocity Clamping and Modified Diversity Trigger for Improved Exploration and Convergence.", "configspace": "", "generation": 11, "fitness": 0.89573941511737, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.896 with standard deviation 0.019. And the mean value of best solutions found was 0.111 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "7fd4dbd8-bcd4-4db7-bb4d-640b02da84da", "metadata": {"aucs": [0.9122606436992047, 0.8698166422492986, 0.9051409594036064], "final_y": [0.10968996906067263, 0.1148123145417912, 0.10982911459198286]}, "mutation_prompt": null}
{"id": "e39c5899-8301-4988-9874-b90f9c4f3857", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.lb = None\n        self.ub = None\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        def nonlinear_inertia_weight(t, T):\n            return 0.9 - (0.5 * (t / T) ** 2)\n\n        def diversity_metric(swarm):\n            return np.mean(np.std(swarm, axis=0))\n\n        def adaptive_learning_rate(evaluations, budget):\n            return 0.8 + 0.2 * np.sin((evaluations / budget) * np.pi)\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = nonlinear_inertia_weight(evaluations, self.budget)\n            cognitive_coeff = 2.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (1.1 - adaptive_factor)\n\n            current_population_size = self.population_size - int(0.15 * self.population_size * evaluations / self.budget)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n\n                velocity_clamp_factor = adaptive_learning_rate(evaluations, self.budget)\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp_factor * (self.ub - self.lb), velocity_clamp_factor * (self.ub - self.lb))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], self.lb, self.ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n            \n            if diversity_metric(swarm) < 0.03:\n                num_reintroduce = max(1, int(0.1 * current_population_size))\n                for _ in range(num_reintroduce):\n                    idx = np.random.randint(current_population_size)\n                    swarm[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n\n            # Hierarchical clustering\n            cluster_centers = np.mean(swarm, axis=0)\n            for i in range(current_population_size):\n                dist = np.linalg.norm(swarm[i] - cluster_centers)\n                if dist < 0.1 * (self.ub - self.lb).mean():\n                    swarm[i] = np.random.uniform(self.lb, self.ub, self.dim)\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Introduced Hierarchical Swarm Clustering with Adaptive Learning for Enhanced Convergence and Diversity Maintenance in High-Dimensional Spaces.", "configspace": "", "generation": 12, "fitness": 0.8573042204080273, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.857 with standard deviation 0.035. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "7b0944b4-60f7-485c-ae48-a27c52caf51b", "metadata": {"aucs": [0.8124719032148067, 0.861408182433897, 0.8980325755753783], "final_y": [0.14560453064132262, 0.12041002285173896, 0.11193316264889186]}, "mutation_prompt": null}
{"id": "e561bcc8-bec8-4bb5-82c9-cca3cebe257d", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.lb = None\n        self.ub = None\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        def nonlinear_inertia_weight(t, T):\n            return 0.9 - (0.5 * (t / T) ** 2)\n\n        def diversity_metric(swarm):\n            return np.mean(np.std(swarm, axis=0))\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = nonlinear_inertia_weight(evaluations, self.budget)\n            cognitive_coeff = 2.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (1.1 - adaptive_factor * 0.8)  # Modified line\n\n            current_population_size = self.population_size - int(0.15 * self.population_size * evaluations / self.budget)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n\n                velocity_clamp_factor = 0.2 * (1 - (evaluations / self.budget))\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp_factor * (self.ub - self.lb), velocity_clamp_factor * (self.ub - self.lb))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], self.lb, self.ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n            \n            if diversity_metric(swarm) < 0.03:\n                num_reintroduce = max(1, int(0.1 * current_population_size))\n                for _ in range(num_reintroduce):\n                    idx = np.random.randint(current_population_size)\n                    swarm[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Improved convergence by adapting social coefficient calculation to emphasize later-stage swarm collaboration, enhancing balance between exploration and exploitation.", "configspace": "", "generation": 12, "fitness": 0.8733541356824581, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.873 with standard deviation 0.022. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "7b0944b4-60f7-485c-ae48-a27c52caf51b", "metadata": {"aucs": [0.9007951728230192, 0.8712733893713737, 0.8479938448529816], "final_y": [0.11022353750785285, 0.11893702555669083, 0.1292425995994172]}, "mutation_prompt": null}
{"id": "1cbca271-71c7-4c0f-bdde-585cd9181348", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.lb = None\n        self.ub = None\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        def nonlinear_inertia_weight(t, T):\n            return 0.9 - (0.5 * (t / T) ** 2)\n\n        def diversity_metric(swarm):\n            return np.mean(np.std(swarm, axis=0))\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = nonlinear_inertia_weight(evaluations, self.budget)\n            cognitive_coeff = 2.5 * (0.5 + 0.5 * adaptive_factor) * (0.5 + 0.5 * (1 - evaluations / self.budget))  # Modified line\n            social_coeff = 1.5 * (1.1 - adaptive_factor)\n\n            current_population_size = self.population_size - int(0.15 * self.population_size * evaluations / self.budget)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n\n                velocity_clamp_factor = 0.2 * (1 - (evaluations / self.budget))\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp_factor * (self.ub - self.lb), velocity_clamp_factor * (self.ub - self.lb))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], self.lb, self.ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n            \n            if diversity_metric(swarm) < 0.03:\n                num_reintroduce = max(1, int(0.1 * current_population_size))\n                for _ in range(num_reintroduce):\n                    idx = np.random.randint(current_population_size)\n                    swarm[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Further refine the velocity update rule by introducing a decay factor to the cognitive coefficient for enhanced convergence speed.", "configspace": "", "generation": 12, "fitness": 0.8833278827097573, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.883 with standard deviation 0.025. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "7b0944b4-60f7-485c-ae48-a27c52caf51b", "metadata": {"aucs": [0.849996904624001, 0.8916669774606817, 0.9083197660445891], "final_y": [0.11551719074688171, 0.11626047695711028, 0.11094586778927151]}, "mutation_prompt": null}
{"id": "6c2361d5-a6da-45bb-bd57-ff901f1bced1", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.lb = None\n        self.ub = None\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        def nonlinear_inertia_weight(t, T):\n            return 0.9 - (0.5 * (t / T) ** 2)\n\n        def diversity_metric(swarm):\n            return np.mean(np.std(swarm, axis=0))\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = nonlinear_inertia_weight(evaluations, self.budget)\n            cognitive_coeff = 2.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (1.1 - adaptive_factor)\n\n            current_population_size = self.population_size - int(0.15 * self.population_size * evaluations / self.budget)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n\n                velocity_clamp_factor = 0.2 * (1 - (evaluations / self.budget))\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp_factor * (self.ub - self.lb), velocity_clamp_factor * (self.ub - self.lb))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], self.lb, self.ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value * adaptive_factor  # Modified line\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n            \n            if diversity_metric(swarm) < 0.05:  # Modified line\n                num_reintroduce = max(1, int(0.1 * current_population_size))\n                for _ in range(num_reintroduce):\n                    idx = np.random.randint(current_population_size)\n                    swarm[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Introduced a dynamic personal-best updating strategy and an adaptive re-initialization threshold to enhance exploration and convergence robustness.", "configspace": "", "generation": 12, "fitness": 0.8757449188394496, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.876 with standard deviation 0.021. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "7b0944b4-60f7-485c-ae48-a27c52caf51b", "metadata": {"aucs": [0.8496006897674893, 0.8764348741864005, 0.9011991925644591], "final_y": [0.12769126126423413, 0.12037505753158584, 0.1099368037075793]}, "mutation_prompt": null}
{"id": "680b599f-73ad-46ff-b529-29dc536a2da7", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.lb = None\n        self.ub = None\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        def nonlinear_inertia_weight(t, T):\n            return 0.9 - (0.5 * (t / T) ** 2)\n\n        def diversity_metric(swarm):\n            return np.mean(np.std(swarm, axis=0))\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = nonlinear_inertia_weight(evaluations, self.budget)\n            cognitive_coeff = 2.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (1.1 - adaptive_factor)\n\n            current_population_size = int(self.population_size * (0.5 + 0.5 * adaptive_factor))  # Modified line\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n\n                velocity_clamp_factor = 0.2 * (1 - (evaluations / self.budget))  # Modified line\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp_factor * (self.ub - self.lb), velocity_clamp_factor * (self.ub - self.lb))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], self.lb, self.ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n            \n            if diversity_metric(swarm) < 0.02:  # Modified line\n                num_reintroduce = max(1, int(0.1 * current_population_size))\n                for _ in range(num_reintroduce):\n                    idx = np.random.randint(current_population_size)\n                    swarm[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n\n                # Symbiotic Learning modification\n                if np.random.random() < 0.05:  # Modified line\n                    partner_idx = np.random.choice(current_population_size, 2, replace=False)\n                    swarm[partner_idx[0]], swarm[partner_idx[1]] = swarm[partner_idx[1]], swarm[partner_idx[0]]\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Refined Enhanced Adaptive Swarm Gradient Descent with Dynamic Population Resizing and Symbiotic Learning for Improved Exploration-Exploitation Balance.", "configspace": "", "generation": 12, "fitness": 0.886109855776034, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.886 with standard deviation 0.006. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "7b0944b4-60f7-485c-ae48-a27c52caf51b", "metadata": {"aucs": [0.8805434013833112, 0.8949635169049371, 0.8828226490398534], "final_y": [0.11109520083202207, 0.1117997613279158, 0.11842295497975108]}, "mutation_prompt": null}
{"id": "51bd6e3b-4b3d-4627-acde-858e9d696f46", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.lb = None\n        self.ub = None\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        def nonlinear_inertia_weight(t, T):\n            return 0.9 - (0.5 * (t / T) ** 2)\n\n        def diversity_metric(swarm):\n            return np.mean(np.std(swarm, axis=0))\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = nonlinear_inertia_weight(evaluations, self.budget) * (0.5 + 0.5 * adaptive_factor)  # Modified line\n            cognitive_coeff = 2.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (1.1 - adaptive_factor)\n\n            current_population_size = self.population_size - int(0.15 * self.population_size * evaluations / self.budget)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n\n                velocity_clamp_factor = 0.2 * (1 - (evaluations / self.budget))\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp_factor * (self.ub - self.lb), velocity_clamp_factor * (self.ub - self.lb))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], self.lb, self.ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n            \n            if diversity_metric(swarm) < 0.03:\n                num_reintroduce = max(1, int(0.1 * current_population_size))\n                for _ in range(num_reintroduce):\n                    idx = np.random.randint(current_population_size)\n                    swarm[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Introduced adaptive inertia weight scaling for enhanced exploration and convergence balance.", "configspace": "", "generation": 13, "fitness": 0.9005388683019137, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.901 with standard deviation 0.010. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "7b0944b4-60f7-485c-ae48-a27c52caf51b", "metadata": {"aucs": [0.89332196226457, 0.9140284101744531, 0.8942662324667177], "final_y": [0.11198007362972484, 0.11181070770362511, 0.11699980679577915]}, "mutation_prompt": null}
{"id": "3f573acf-80f1-415e-a107-05ee216e617c", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.lb = None\n        self.ub = None\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        def nonlinear_inertia_weight(t, T):\n            return 0.9 - (0.5 * (t / T) ** 2)\n\n        def diversity_metric(swarm):\n            return np.mean(np.std(swarm, axis=0))\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = nonlinear_inertia_weight(evaluations, self.budget)\n            cognitive_coeff = 2.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)  # Modified line\n\n            current_population_size = self.population_size - int(0.15 * self.population_size * evaluations / self.budget)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n\n                velocity_clamp_factor = 0.2 * (1 - (evaluations / self.budget))  # Modified line\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp_factor * (self.ub - self.lb), velocity_clamp_factor * (self.ub - self.lb))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], self.lb, self.ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n            \n            if diversity_metric(swarm) < 0.03:  # Modified line\n                num_reintroduce = max(1, int(0.1 * current_population_size))\n                for _ in range(num_reintroduce):\n                    idx = np.random.randint(current_population_size)\n                    swarm[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Improved Enhanced Adaptive Swarm Gradient Descent with Time-Varying Social-Cognitive Coefficients for Enhanced Solution Exploration and Exploitation Balance.", "configspace": "", "generation": 13, "fitness": 0.9007336370315309, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.901 with standard deviation 0.020. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "7b0944b4-60f7-485c-ae48-a27c52caf51b", "metadata": {"aucs": [0.9160731997655565, 0.8728682034841531, 0.913259507844883], "final_y": [0.11082250329056054, 0.12047258437262798, 0.11086546980330236]}, "mutation_prompt": null}
{"id": "3267c4e2-aecb-48a4-89b4-b6b063da359d", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.lb = None\n        self.ub = None\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        def nonlinear_inertia_weight(t, T):\n            return 0.9 - (0.5 * (t / T) ** 2)\n\n        def diversity_metric(swarm):\n            return np.mean(np.std(swarm, axis=0))\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = nonlinear_inertia_weight(evaluations, self.budget)\n            cognitive_coeff = 2.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.8 * (1.2 - adaptive_factor)  # Modified line\n\n            current_population_size = self.population_size - int(0.15 * self.population_size * evaluations / self.budget)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n\n                velocity_clamp_factor = 0.15 * (1 - (evaluations / self.budget))  # Modified line\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp_factor * (self.ub - self.lb), velocity_clamp_factor * (self.ub - self.lb))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], self.lb, self.ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n            \n            if diversity_metric(swarm) < 0.03:\n                num_reintroduce = max(1, int(0.1 * current_population_size))\n                for _ in range(num_reintroduce):\n                    idx = np.random.randint(current_population_size)\n                    swarm[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with Dynamic Velocity Clamping and Improved Social Learning for Optimal Convergence.", "configspace": "", "generation": 13, "fitness": 0.8950571097763501, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.895 with standard deviation 0.009. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "7b0944b4-60f7-485c-ae48-a27c52caf51b", "metadata": {"aucs": [0.8982989619758067, 0.8827793022004631, 0.9040930651527807], "final_y": [0.11015907863497432, 0.11632095712562873, 0.11189381699389145]}, "mutation_prompt": null}
{"id": "96baa706-3b0c-414f-a34f-6bf9ad1d043c", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.lb = None\n        self.ub = None\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        def nonlinear_inertia_weight(t, T):\n            return 0.9 - (0.5 * (t / T) ** 2)\n\n        def diversity_metric(swarm):\n            return np.mean(np.std(swarm, axis=0))\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = nonlinear_inertia_weight(evaluations, self.budget)\n            cognitive_coeff = 2.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (1.5 - adaptive_factor)  # Modified line\n\n            current_population_size = self.population_size - int(0.15 * self.population_size * evaluations / self.budget)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n\n                velocity_clamp_factor = 0.2 * (1 - (evaluations / self.budget))\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp_factor * (self.ub - self.lb), velocity_clamp_factor * (self.ub - self.lb))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], self.lb, self.ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n            \n            if diversity_metric(swarm) < 0.05:  # Modified line\n                num_reintroduce = max(1, int(0.1 * current_population_size))\n                for _ in range(num_reintroduce):\n                    idx = np.random.randint(current_population_size)\n                    swarm[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Improved Enhanced Adaptive Swarm Gradient Descent by dynamically adjusting social coefficient and increasing diversity trigger threshold for better exploration and convergence.", "configspace": "", "generation": 13, "fitness": 0.8903952257636161, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.890 with standard deviation 0.011. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "7b0944b4-60f7-485c-ae48-a27c52caf51b", "metadata": {"aucs": [0.8876659702528857, 0.8783593489383641, 0.9051603580995984], "final_y": [0.11414277722639876, 0.12026797637825437, 0.11254808827893625]}, "mutation_prompt": null}
{"id": "fbd5b66c-aaf6-493e-a4c5-e337e2dfc627", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.lb = None\n        self.ub = None\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        def nonlinear_inertia_weight(t, T):\n            return 0.9 - (0.5 * (t / T) ** 2)\n\n        def diversity_metric(swarm):\n            return np.mean(np.std(swarm, axis=0))\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = nonlinear_inertia_weight(evaluations, self.budget)\n            cognitive_coeff = 2.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (1.1 - adaptive_factor)\n\n            current_population_size = self.population_size - int(0.15 * self.population_size * evaluations / self.budget)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n\n                velocity_clamp_factor = 0.2 * (1 - (evaluations / self.budget))\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp_factor * (self.ub - self.lb), velocity_clamp_factor * (self.ub - self.lb))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], self.lb, self.ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n            \n            if diversity_metric(swarm) < 0.03:\n                num_reintroduce = max(1, int(0.15 * current_population_size))  # Modified line\n                for _ in range(num_reintroduce):\n                    idx = np.random.randint(current_population_size)\n                    swarm[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Introducing adaptive reinitialization based on diversity metric improvement to enhance exploration capabilities.", "configspace": "", "generation": 13, "fitness": 0.8835312561051444, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.884 with standard deviation 0.007. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "7b0944b4-60f7-485c-ae48-a27c52caf51b", "metadata": {"aucs": [0.8735402177433123, 0.887539032552417, 0.8895145180197043], "final_y": [0.11348590161388727, 0.11052000604939471, 0.1136014225556019]}, "mutation_prompt": null}
{"id": "2942efc2-a281-4254-8a15-043c0278789c", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.lb = None\n        self.ub = None\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        def nonlinear_inertia_weight(t, T):\n            return 0.9 - (0.5 * (t / T) ** 2)\n\n        def diversity_metric(swarm):\n            return np.mean(np.std(swarm, axis=0))\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = nonlinear_inertia_weight(evaluations, self.budget)\n            diversity = diversity_metric(swarm)\n            cognitive_coeff = 2.5 * (0.5 + 0.5 * adaptive_factor * (1 - diversity))  # Modified line\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n\n            current_population_size = self.population_size - int(0.15 * self.population_size * evaluations / self.budget)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n\n                velocity_clamp_factor = 0.2 * (1 - (evaluations / self.budget))\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp_factor * (self.ub - self.lb), velocity_clamp_factor * (self.ub - self.lb))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], self.lb, self.ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n            \n            if diversity < 0.03:\n                num_reintroduce = max(1, int(0.1 * current_population_size))\n                for _ in range(num_reintroduce):\n                    idx = np.random.randint(current_population_size)\n                    swarm[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Introduce dynamic social and cognitive coefficients based on the diversity metric to balance global and local search adaptability.", "configspace": "", "generation": 14, "fitness": 0.8553084326288481, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.855 with standard deviation 0.039. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.020.", "error": "", "parent_id": "3f573acf-80f1-415e-a107-05ee216e617c", "metadata": {"aucs": [0.7998889998995943, 0.8839411445012374, 0.8820951534857125], "final_y": [0.1561115001983744, 0.11750438124037788, 0.1112909205998337]}, "mutation_prompt": null}
{"id": "b84ed206-770a-4ebb-a01d-dba9f1720763", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.lb = None\n        self.ub = None\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        def nonlinear_inertia_weight(t, T):\n            return 0.9 - (0.5 * (t / T) ** 2)\n\n        def diversity_metric(swarm):\n            return np.mean(np.std(swarm, axis=0))\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = nonlinear_inertia_weight(evaluations, self.budget)\n            cognitive_coeff = 2.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n\n            current_population_size = self.population_size - int(0.15 * self.population_size * evaluations / self.budget)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n\n                velocity_clamp_factor = 0.5 * (1 - (evaluations / self.budget))  # Modified line\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp_factor * (self.ub - self.lb), velocity_clamp_factor * (self.ub - self.lb))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], self.lb, self.ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n            \n            if diversity_metric(swarm) < 0.05:  # Modified line\n                num_reintroduce = max(1, int(0.2 * current_population_size))  # Modified line\n                for _ in range(num_reintroduce):\n                    idx = np.random.randint(current_population_size)\n                    swarm[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                    personal_best[idx] = swarm[idx]  # Modified line\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Enhanced Swarm Gradient Descent with Dynamic Reinitialization and Adaptive Velocity Clamping for Improved Global Convergence.", "configspace": "", "generation": 14, "fitness": 0.8683395875605026, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.868 with standard deviation 0.018. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "3f573acf-80f1-415e-a107-05ee216e617c", "metadata": {"aucs": [0.8431835649005776, 0.8753728164968363, 0.8864623812840938], "final_y": [0.11860966091088199, 0.1167283445847247, 0.11498533784771103]}, "mutation_prompt": null}
{"id": "5637171e-e10d-42a1-995e-eb40df4e68f5", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.lb = None\n        self.ub = None\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        def nonlinear_inertia_weight(t, T):\n            return 0.9 - (0.5 * (t / T) ** 2)\n\n        def diversity_metric(swarm):\n            return np.mean(np.std(swarm, axis=0))\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = nonlinear_inertia_weight(evaluations, self.budget)\n            cognitive_coeff = 2.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n\n            current_population_size = self.population_size - int(0.20 * self.population_size * evaluations / self.budget)  # Modified line\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n\n                velocity_clamp_factor = 0.2 * (1 - (evaluations / self.budget))\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp_factor * (self.ub - self.lb), velocity_clamp_factor * (self.ub - self.lb))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], self.lb, self.ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n            \n            if diversity_metric(swarm) < 0.03:\n                num_reintroduce = max(1, int(0.1 * current_population_size))\n                for _ in range(num_reintroduce):\n                    idx = np.random.randint(current_population_size)\n                    swarm[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Refined Adaptive Swarm Gradient Descent with Dynamic Population Size Adjustments for Improved Convergence and Diversity.", "configspace": "", "generation": 14, "fitness": 0.8853168376406867, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.885 with standard deviation 0.011. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "3f573acf-80f1-415e-a107-05ee216e617c", "metadata": {"aucs": [0.8930904368175407, 0.869680934619204, 0.8931791414853154], "final_y": [0.11001313691735382, 0.11645375385427259, 0.11261829864673434]}, "mutation_prompt": null}
{"id": "f03b9eba-1c27-48cc-bcdd-f74f80e47fc1", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.lb = None\n        self.ub = None\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        def nonlinear_inertia_weight(t, T):\n            return 0.9 - (0.5 * (t / T) ** 2)\n\n        def diversity_metric(swarm):\n            return np.mean(np.std(swarm, axis=0))\n\n        def adaptive_population_size(evals):\n            return self.population_size - int(0.2 * self.population_size * evals / self.budget)\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = nonlinear_inertia_weight(evaluations, self.budget)\n            cognitive_coeff = 2.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.8 * (0.5 + 0.5 * adaptive_factor)  # Modified line\n\n            current_population_size = adaptive_population_size(evaluations)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n\n                velocity_clamp_factor = 0.3 * (1 - (evaluations / self.budget))  # Modified line\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp_factor * (self.ub - self.lb), velocity_clamp_factor * (self.ub - self.lb))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], self.lb, self.ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n            if diversity_metric(swarm) < 0.05:  # Modified line\n                num_reintroduce = max(1, int(0.15 * current_population_size))  # Modified line\n                for _ in range(num_reintroduce):\n                    idx = np.random.randint(current_population_size)\n                    swarm[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Advanced Adaptive Swarm Gradient Descent with Dynamic Population and Enhanced Velocity Clamping for Optimal Convergence Stability.", "configspace": "", "generation": 14, "fitness": 0.8840434242417876, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.884 with standard deviation 0.018. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "3f573acf-80f1-415e-a107-05ee216e617c", "metadata": {"aucs": [0.8704227845578978, 0.8721412304346565, 0.9095662577328086], "final_y": [0.11770895306336082, 0.12065583735740137, 0.11387144210317224]}, "mutation_prompt": null}
{"id": "4c025b94-9cde-4f7f-8ae8-4aa5c6cc1dff", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.lb = None\n        self.ub = None\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        def nonlinear_inertia_weight(t, T):\n            return 0.9 - (0.5 * (t / T) ** 2)\n\n        def diversity_metric(swarm):\n            return np.mean(np.std(swarm, axis=0))\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = nonlinear_inertia_weight(evaluations, self.budget)\n            cognitive_coeff = 2.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n\n            current_population_size = self.population_size - int(0.15 * self.population_size * evaluations / self.budget)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n\n                velocity_clamp_factor = 0.2 * (1 - (evaluations / self.budget))\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp_factor * (self.ub - self.lb), velocity_clamp_factor * (self.ub - self.lb))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], self.lb, self.ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n            \n            if diversity_metric(swarm) < 0.04:  # Modified line\n                num_reintroduce = max(1, int(0.1 * current_population_size))\n                for _ in range(num_reintroduce):\n                    idx = np.random.randint(current_population_size)\n                    swarm[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with Dynamic Diversity-Based Reinitialization for Improved Global Exploration.", "configspace": "", "generation": 14, "fitness": 0.8977736242897972, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.898 with standard deviation 0.005. And the mean value of best solutions found was 0.111 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "3f573acf-80f1-415e-a107-05ee216e617c", "metadata": {"aucs": [0.9035394146563162, 0.8977064784900312, 0.8920749797230443], "final_y": [0.10978829776074606, 0.1119376468911435, 0.11039900112185375]}, "mutation_prompt": null}
{"id": "bb8bfd2d-f63a-4b89-b259-9d4ecaf5291d", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.lb = None\n        self.ub = None\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        def nonlinear_inertia_weight(t, T):\n            return 0.9 - (0.5 * (t / T) ** 2)\n\n        def diversity_metric(swarm):\n            return np.mean(np.std(swarm, axis=0))\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = nonlinear_inertia_weight(evaluations, self.budget)\n            cognitive_coeff = 2.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n\n            current_population_size = self.population_size - int(0.15 * self.population_size * evaluations / self.budget)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n\n                velocity_clamp_factor = 0.2 * (1 - (evaluations / self.budget))\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp_factor * (self.ub - self.lb), velocity_clamp_factor * (self.ub - self.lb))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], self.lb, self.ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n            \n            if diversity_metric(swarm) < 0.03:  # Modified line\n                num_reintroduce = max(1, int(0.1 * current_population_size * (1 - diversity_metric(swarm))))  # Modified line\n                for _ in range(num_reintroduce):\n                    idx = np.random.randint(current_population_size)\n                    swarm[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Further enhanced swarm exploration by adjusting reintroduction strategy to dynamically adapt based on swarm diversity.", "configspace": "", "generation": 15, "fitness": 0.8846434326341478, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.885 with standard deviation 0.003. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "3f573acf-80f1-415e-a107-05ee216e617c", "metadata": {"aucs": [0.8832460162084058, 0.8888598325943462, 0.8818244490996915], "final_y": [0.11136405125665683, 0.11625812164304705, 0.11802143063958581]}, "mutation_prompt": null}
{"id": "a9e87c9a-b1c1-4539-9e8a-c3ffbfb60b92", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.lb = None\n        self.ub = None\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        def nonlinear_inertia_weight(t, T):\n            return 0.9 - (0.5 * (t / T) ** 2)\n\n        def diversity_metric(swarm):\n            return np.mean(np.std(swarm, axis=0))\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = nonlinear_inertia_weight(evaluations, self.budget)\n            cognitive_coeff = 2.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n\n            current_population_size = self.population_size - int(0.15 * self.population_size * evaluations / self.budget)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n\n                velocity_clamp_factor = 0.2 * (1 - (evaluations / self.budget))\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp_factor * (self.ub - self.lb), velocity_clamp_factor * (self.ub - self.lb))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], self.lb, self.ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n            \n            if diversity_metric(swarm) < 0.03:\n                num_reintroduce = max(1, int(0.15 * current_population_size))  # Modified line\n                for _ in range(num_reintroduce):\n                    idx = np.random.randint(current_population_size)\n                    swarm[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with Increased Population Reintroduction for Improved Diversity and Convergence.", "configspace": "", "generation": 15, "fitness": 0.8989678783373213, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.899 with standard deviation 0.010. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "3f573acf-80f1-415e-a107-05ee216e617c", "metadata": {"aucs": [0.9062560909703037, 0.9054641806378789, 0.8851833634037809], "final_y": [0.11071544645593723, 0.113637824409754, 0.11778105582531706]}, "mutation_prompt": null}
{"id": "0605b452-4649-431f-a694-1b06b0282b1d", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.lb = None\n        self.ub = None\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        def nonlinear_inertia_weight(t, T):\n            return 0.9 - (0.5 * (t / T) ** 2)\n\n        def diversity_metric(swarm):\n            return np.mean(np.std(swarm, axis=0))\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = nonlinear_inertia_weight(evaluations, self.budget)\n            cognitive_coeff = 2.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n\n            current_population_size = self.population_size - int(0.15 * self.population_size * evaluations / self.budget)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n\n                velocity_clamp_factor = 0.2 * (1 - (evaluations / self.budget))\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp_factor * (self.ub - self.lb), velocity_clamp_factor * (self.ub - self.lb))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], self.lb, self.ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n            \n            if diversity_metric(swarm) < 0.05:  # Modified line\n                num_reintroduce = max(1, int(0.2 * current_population_size))  # Modified line\n                for _ in range(num_reintroduce):\n                    idx = np.random.randint(current_population_size)\n                    swarm[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Improved Enhanced Adaptive Swarm Gradient Descent with Dynamic Diversity Injection for Better Exploration and Exploitation.", "configspace": "", "generation": 15, "fitness": 0.8928460931639076, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.893 with standard deviation 0.002. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "3f573acf-80f1-415e-a107-05ee216e617c", "metadata": {"aucs": [0.891822211314114, 0.8907417321995538, 0.8959743359780548], "final_y": [0.1172478358815644, 0.11501627414651427, 0.11764540790198041]}, "mutation_prompt": null}
{"id": "3d62c4e6-7f60-489c-bc1c-c16839cf7c78", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.lb = None\n        self.ub = None\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        def nonlinear_inertia_weight(t, T):\n            return 0.9 - (0.5 * (t / T) ** 2)\n\n        def diversity_metric(swarm):\n            return np.mean(np.std(swarm, axis=0))\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = nonlinear_inertia_weight(evaluations, self.budget)\n            cognitive_coeff = 2.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)  # Modified line\n\n            current_population_size = self.population_size - int(0.15 * self.population_size * evaluations / self.budget)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n\n                velocity_clamp_factor = 0.2 * (1 - (evaluations / self.budget))  # Modified line\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp_factor * (self.ub - self.lb), velocity_clamp_factor * (self.ub - self.lb))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], self.lb, self.ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n            \n            if diversity_metric(swarm) < 0.03:  # Modified line\n                num_reintroduce = max(1, int(0.1 * current_population_size))\n                for _ in range(num_reintroduce):\n                    idx = np.random.randint(current_population_size)\n                    swarm[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n            \n            if evaluations / self.budget > 0.75:  # New line\n                self.population_size = max(5, int(self.population_size * 0.9))\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with Dynamic Population Management for Improved Convergence. ", "configspace": "", "generation": 15, "fitness": 0.8901031114987396, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.890 with standard deviation 0.005. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "3f573acf-80f1-415e-a107-05ee216e617c", "metadata": {"aucs": [0.8956689080970872, 0.8903290180882645, 0.8843114083108672], "final_y": [0.11245059419174819, 0.11555174701880844, 0.11635554913379731]}, "mutation_prompt": null}
{"id": "1dac8a20-ef00-4031-b521-260ae629ca9b", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.lb = None\n        self.ub = None\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        def nonlinear_inertia_weight(t, T):\n            return 0.9 - (0.5 * (t / T) ** 2)\n\n        def diversity_metric(swarm):\n            return np.mean(np.std(swarm, axis=0))\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = nonlinear_inertia_weight(evaluations, self.budget)\n            cognitive_coeff = 2.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor) \n\n            current_population_size = self.population_size - int(0.15 * self.population_size * evaluations / self.budget)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n\n                velocity_clamp_factor = 0.25 * (1 - (evaluations / self.budget))  # Modified line\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp_factor * (self.ub - self.lb), velocity_clamp_factor * (self.ub - self.lb))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], self.lb, self.ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n            \n            if diversity_metric(swarm) < 0.02:  # Modified line\n                num_reintroduce = max(1, int(0.2 * current_population_size))  # Modified line\n                for _ in range(num_reintroduce):\n                    idx = np.random.randint(current_population_size)\n                    swarm[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Introducing dynamic velocity adjustment and swarm regrouping for improved convergence in Enhanced Adaptive Swarm Gradient Descent.", "configspace": "", "generation": 15, "fitness": 0.8781637738859986, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.878 with standard deviation 0.016. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "3f573acf-80f1-415e-a107-05ee216e617c", "metadata": {"aucs": [0.8930707269651292, 0.8847584610573813, 0.8566621336354856], "final_y": [0.11216845842844714, 0.11623748111886878, 0.12586873942205612]}, "mutation_prompt": null}
{"id": "f00a5389-89ec-4862-a42c-8e79433cdb3e", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.lb = None\n        self.ub = None\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        def nonlinear_inertia_weight(t, T):\n            return 0.9 - (0.5 * (t / T) ** 2)\n\n        def diversity_metric(swarm):\n            return np.mean(np.std(swarm, axis=0))\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = nonlinear_inertia_weight(evaluations, self.budget)\n            cognitive_coeff = 2.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)  # Modified line\n\n            current_population_size = self.population_size - int(0.15 * self.population_size * evaluations / self.budget)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n\n                velocity_clamp_factor = 0.2 * (1 - (evaluations / self.budget))  # Modified line\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp_factor * (self.ub - self.lb), velocity_clamp_factor * (self.ub - self.lb))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], self.lb, self.ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n            \n            if diversity_metric(swarm) < 0.04:  # Modified line\n                num_reintroduce = max(1, int(0.1 * current_population_size))\n                for _ in range(num_reintroduce):\n                    idx = np.random.randint(current_population_size)\n                    swarm[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Further enhance exploration and exploitation balance by increasing the diversity threshold slightly.", "configspace": "", "generation": 16, "fitness": 0.8737849966040594, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.874 with standard deviation 0.027. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "3f573acf-80f1-415e-a107-05ee216e617c", "metadata": {"aucs": [0.905237059506, 0.8766299179877184, 0.8394880123184598], "final_y": [0.11198997794932852, 0.11660232727049102, 0.13520383843791695]}, "mutation_prompt": null}
{"id": "e21f4637-ce66-489d-ba15-5dbbb02259a1", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.lb = None\n        self.ub = None\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        def nonlinear_inertia_weight(t, T):\n            return 0.9 - (0.5 * (t / T) ** 2)\n\n        def diversity_metric(swarm):\n            return np.mean(np.std(swarm, axis=0))\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = nonlinear_inertia_weight(evaluations, self.budget)\n            cognitive_coeff = 2.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n\n            current_population_size = self.population_size - int(0.15 * self.population_size * evaluations / self.budget)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n\n                velocity_clamp_factor = 0.2 * (1 - (evaluations / self.budget))\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp_factor * (self.ub - self.lb), velocity_clamp_factor * (self.ub - self.lb))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], self.lb, self.ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n            \n            if diversity_metric(swarm) < 0.03:\n                num_reintroduce = max(1, int(0.1 * current_population_size))\n                for _ in range(num_reintroduce):\n                    idx = np.random.randint(current_population_size)\n                    swarm[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n\n                # Additional change for dynamic personal best reset (1 line modified)\n                personal_best_value = np.array([func(x) for x in swarm])\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Introduced a dynamic personal best resetting mechanism when swarm stagnation is detected to enhance diversity and exploration.", "configspace": "", "generation": 16, "fitness": 0.887214309067304, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.887 with standard deviation 0.012. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "3f573acf-80f1-415e-a107-05ee216e617c", "metadata": {"aucs": [0.9019818123939203, 0.8721897980903569, 0.8874713167176348], "final_y": [0.11323429395670115, 0.11652082313710022, 0.11326661071954391]}, "mutation_prompt": null}
{"id": "503d450e-5a68-47fd-837c-66c387f32cfb", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.lb = None\n        self.ub = None\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        def nonlinear_inertia_weight(t, T):\n            return 0.9 - (0.5 * (t / T) ** 2)\n\n        def diversity_metric(swarm):\n            return np.mean(np.std(swarm, axis=0))\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = nonlinear_inertia_weight(evaluations, self.budget)\n            cognitive_coeff = 2.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n\n            current_population_size = self.population_size - int(0.15 * self.population_size * evaluations / self.budget)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n\n                velocity_clamp_factor = 0.2 * (1 - (evaluations / self.budget))\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp_factor * (self.ub - self.lb), velocity_clamp_factor * (self.ub - self.lb))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], self.lb, self.ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n            \n            if diversity_metric(swarm) < 0.03:\n                num_reintroduce = max(1, int(0.1 * current_population_size))\n                for _ in range(num_reintroduce):\n                    idx = np.random.randint(current_population_size)\n                    swarm[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n                    \n            for i in range(current_population_size):  # New line\n                local_search_step = 0.01 * (self.ub - self.lb)  # New line\n                candidate = np.clip(swarm[i] + np.random.uniform(-local_search_step, local_search_step, self.dim), self.lb, self.ub)  # New line\n                candidate_value = func(candidate)  # New line\n                evaluations += 1  # New line\n                if candidate_value < personal_best_value[i]:  # New line\n                    personal_best[i] = candidate  # New line\n                    personal_best_value[i] = candidate_value  # New line\n                if candidate_value < global_best_value:  # New line\n                    global_best = candidate  # New line\n                    global_best_value = candidate_value  # New line\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Adaptive Local Search Integration in Swarm Optimization for Improved Convergence Precision.", "configspace": "", "generation": 16, "fitness": 0.8803287862803408, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.880 with standard deviation 0.012. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "3f573acf-80f1-415e-a107-05ee216e617c", "metadata": {"aucs": [0.8640707086183093, 0.8938784384046756, 0.8830372118180375], "final_y": [0.11822500432940108, 0.1164778645666994, 0.12138811760964319]}, "mutation_prompt": null}
{"id": "626075d6-b9e3-47d7-83a2-8332865add49", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.lb = None\n        self.ub = None\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        # Modified line\n        def nonlinear_inertia_weight(t, T):\n            return 0.9 - (0.5 * (t / T) ** 3)\n\n        def diversity_metric(swarm):\n            return np.mean(np.std(swarm, axis=0))\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = nonlinear_inertia_weight(evaluations, self.budget)\n            cognitive_coeff = 2.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n\n            current_population_size = self.population_size - int(0.15 * self.population_size * evaluations / self.budget)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n\n                velocity_clamp_factor = 0.2 * (1 - (evaluations / self.budget))\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp_factor * (self.ub - self.lb), velocity_clamp_factor * (self.ub - self.lb))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], self.lb, self.ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n            \n            if diversity_metric(swarm) < 0.03:\n                num_reintroduce = max(1, int(0.1 * current_population_size))\n                for _ in range(num_reintroduce):\n                    idx = np.random.randint(current_population_size)\n                    swarm[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Refine the strategy by enhancing the inertia weight decay for better balance between exploration and exploitation.", "configspace": "", "generation": 16, "fitness": 0.8724696605021629, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.872 with standard deviation 0.010. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "3f573acf-80f1-415e-a107-05ee216e617c", "metadata": {"aucs": [0.8617465888100252, 0.8703840833458484, 0.8852783093506149], "final_y": [0.11596313903818378, 0.11799006871522977, 0.11531162897201908]}, "mutation_prompt": null}
{"id": "d961fd19-723a-40c4-bf89-9eb32a017058", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.lb = None\n        self.ub = None\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        def nonlinear_inertia_weight(t, T):\n            return 0.9 - (0.5 * (t / T) ** 2)\n\n        def diversity_metric(swarm):\n            return np.mean(np.std(swarm, axis=0))\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = nonlinear_inertia_weight(evaluations, self.budget)\n            cognitive_coeff = 2.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n\n            current_population_size = self.population_size - int(0.15 * self.population_size * evaluations / self.budget)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n\n                velocity_clamp_factor = 0.2 * (1 - (evaluations / self.budget))\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp_factor * (self.ub - self.lb), velocity_clamp_factor * (self.ub - self.lb))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], self.lb, self.ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n            if diversity_metric(swarm) < 0.03:\n                num_reintroduce = max(1, int(0.15 * current_population_size))  # Modified line\n                for _ in range(num_reintroduce):\n                    idx = np.random.randint(current_population_size)\n                    swarm[idx] = 0.5 * (swarm[idx] + np.random.uniform(self.lb, self.ub, self.dim))  # Modified line\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Refined Enhanced Adaptive Swarm Gradient Descent optimizes exploration-exploitation balance by dynamically adjusting population based on diversity metric and incorporating memory-based perturbations.", "configspace": "", "generation": 16, "fitness": 0.8750791775752798, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.875 with standard deviation 0.016. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "3f573acf-80f1-415e-a107-05ee216e617c", "metadata": {"aucs": [0.8596344560177039, 0.867822655935869, 0.8977804207722664], "final_y": [0.12663998631047912, 0.126993049972432, 0.1124388923480727]}, "mutation_prompt": null}
{"id": "4ff4cc28-a8e0-438f-ae70-96db94836aab", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.lb = None\n        self.ub = None\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        def nonlinear_inertia_weight(t, T):\n            return 0.9 - (0.5 * (t / T) ** 2)\n\n        def diversity_metric(swarm):\n            return np.mean(np.std(swarm, axis=0))\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = nonlinear_inertia_weight(evaluations, self.budget)\n            cognitive_coeff = 2.0 * (0.5 + 0.8 * adaptive_factor)  # Modified line\n            social_coeff = 1.7 * (0.5 + 0.8 * adaptive_factor)  # Modified line\n\n            current_population_size = self.population_size - int(0.15 * self.population_size * evaluations / self.budget)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n\n                velocity_clamp_factor = 0.2 * (1 - (evaluations / self.budget))  # Modified line\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp_factor * (self.ub - self.lb), velocity_clamp_factor * (self.ub - self.lb))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], self.lb, self.ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n            \n            if diversity_metric(swarm) < 0.03:  # Modified line\n                num_reintroduce = max(1, int(0.1 * current_population_size))\n                for _ in range(num_reintroduce):\n                    idx = np.random.randint(current_population_size)\n                    swarm[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Enhanced particle diversity through dynamic cognitive and social coefficients for balanced search exploration and exploitation.", "configspace": "", "generation": 17, "fitness": 0.913809585539525, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.914 with standard deviation 0.011. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "3f573acf-80f1-415e-a107-05ee216e617c", "metadata": {"aucs": [0.9100287982779216, 0.9032316595970249, 0.9281682987436286], "final_y": [0.11038959748893662, 0.11665739412072651, 0.11196401364844832]}, "mutation_prompt": null}
{"id": "5f6dce22-f385-4fb4-ad08-52e12e849f9a", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.lb = None\n        self.ub = None\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        def nonlinear_inertia_weight(t, T):\n            return 0.9 - (0.9 * (t / T) ** 0.5)  # Modified line\n\n        def diversity_metric(swarm):\n            return np.mean(np.std(swarm, axis=0))\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = nonlinear_inertia_weight(evaluations, self.budget)\n            cognitive_coeff = 2.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n\n            current_population_size = self.population_size - int(0.15 * self.population_size * evaluations / self.budget)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n\n                velocity_clamp_factor = 0.2 * (1 - (evaluations / self.budget))\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp_factor * (self.ub - self.lb), velocity_clamp_factor * (self.ub - self.lb))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], self.lb, self.ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n            \n            if diversity_metric(swarm) < 0.05:  # Modified line\n                num_reintroduce = max(1, int(0.15 * current_population_size))  # Modified line\n                for _ in range(num_reintroduce):\n                    idx = np.random.randint(current_population_size)\n                    swarm[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Introducing adaptive reinitialization and dynamic inertia weight decay for improved diversity and convergence.", "configspace": "", "generation": 17, "fitness": 0.925098210275543, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.925 with standard deviation 0.005. And the mean value of best solutions found was 0.112 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "3f573acf-80f1-415e-a107-05ee216e617c", "metadata": {"aucs": [0.9280582392812259, 0.9182159291938523, 0.929020462351551], "final_y": [0.11044521789454742, 0.11257462413457298, 0.11187561327574935]}, "mutation_prompt": null}
{"id": "32341627-2989-4d77-9a8f-b0ded9f81e00", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.lb = None\n        self.ub = None\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        def nonlinear_inertia_weight(t, T):\n            return 0.9 - (0.5 * (t / T) ** 2)\n\n        def diversity_metric(swarm):\n            return np.mean(np.std(swarm, axis=0))\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = nonlinear_inertia_weight(evaluations, self.budget)\n            cognitive_coeff = 2.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n\n            current_population_size = self.population_size - int(0.15 * self.population_size * evaluations / self.budget)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                \n                self.velocity[i] = (inertia_weight * self.velocity[i] + \n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) + \n                                    social_coeff * r2 * (global_best - swarm[i]))\n\n                velocity_clamp_factor = 0.2 * adaptive_factor  # Modified line\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp_factor * (self.ub - self.lb), velocity_clamp_factor * (self.ub - self.lb))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], self.lb, self.ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n            \n            if diversity_metric(swarm) < 0.05:  # Modified line\n                num_reintroduce = max(2, int(0.15 * current_population_size))  # Modified line\n                for _ in range(num_reintroduce):\n                    idx = np.random.randint(current_population_size)\n                    swarm[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Fine-tuned Enhanced Adaptive Swarm Gradient Descent by introducing adaptive velocity scaling and dynamic swarm reintroduction to improve convergence speed and robustness.", "configspace": "", "generation": 17, "fitness": 0.9031126093217458, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.903 with standard deviation 0.016. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "3f573acf-80f1-415e-a107-05ee216e617c", "metadata": {"aucs": [0.8861680341900038, 0.8981541729425059, 0.9250156208327278], "final_y": [0.11966864767605123, 0.11467457525473135, 0.11169669266478144]}, "mutation_prompt": null}
{"id": "7e6fd47f-4eb5-4010-9d3d-c0666f071680", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.lb = None\n        self.ub = None\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        def nonlinear_inertia_weight(t, T):\n            return 0.9 - (0.5 * (t / T) ** 2)\n\n        def diversity_metric(swarm):\n            return np.mean(np.std(swarm, axis=0))\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = nonlinear_inertia_weight(evaluations, self.budget)\n            cognitive_coeff = 2.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)  # Modified line\n\n            current_population_size = self.population_size - int(0.15 * self.population_size * evaluations / self.budget)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n\n                velocity_clamp_factor = 0.25 * (1 - (evaluations / self.budget))  # Changed line to improve convergence\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp_factor * (self.ub - self.lb), velocity_clamp_factor * (self.ub - self.lb))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], self.lb, self.ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n            \n            if diversity_metric(swarm) < 0.03:  # Modified line\n                num_reintroduce = max(1, int(0.1 * current_population_size))\n                for _ in range(num_reintroduce):\n                    idx = np.random.randint(current_population_size)\n                    swarm[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with Time-Varying Social-Cognitive Coefficients and Improved Velocity Clamping for Better Solution Convergence.", "configspace": "", "generation": 17, "fitness": 0.9094595938552091, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.909 with standard deviation 0.010. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "3f573acf-80f1-415e-a107-05ee216e617c", "metadata": {"aucs": [0.8950074697763766, 0.9162491594603115, 0.9171221523289395], "final_y": [0.1119551100452224, 0.11635676712344967, 0.11177051297092422]}, "mutation_prompt": null}
{"id": "1a123654-5175-4874-a434-4df5375e695a", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.lb = None\n        self.ub = None\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        def nonlinear_inertia_weight(t, T):\n            return 0.9 - (0.5 * (t / T) ** 2)\n\n        def diversity_metric(swarm):\n            return np.mean(np.std(swarm, axis=0))\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = nonlinear_inertia_weight(evaluations, self.budget)\n            cognitive_coeff = 2.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n\n            current_population_size = self.population_size - int(0.15 * self.population_size * evaluations / self.budget)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n\n                velocity_clamp_factor = 0.2 * (1 - (evaluations / self.budget))\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp_factor * (self.ub - self.lb), velocity_clamp_factor * (self.ub - self.lb))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], self.lb, self.ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n            \n            if diversity_metric(swarm) < 0.05:  # Modified line\n                num_reintroduce = max(1, int(0.1 * current_population_size))\n                for _ in range(num_reintroduce):\n                    idx = np.random.randint(current_population_size)\n                    swarm[idx] = global_best + np.random.normal(0, 0.1, self.dim)  # Modified line\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with improved reinitialization based on elite perturbation and diversity threshold adjustment for superior exploration efficiency.", "configspace": "", "generation": 17, "fitness": 0.9017815770146805, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.902 with standard deviation 0.024. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "3f573acf-80f1-415e-a107-05ee216e617c", "metadata": {"aucs": [0.8692213755176474, 0.911145018785101, 0.924978336741293], "final_y": [0.12578827133687698, 0.11632783577027217, 0.11226725694544404]}, "mutation_prompt": null}
{"id": "a48bcb71-24b1-4b29-a1d4-ed0cda36cb80", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.lb = None\n        self.ub = None\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        def nonlinear_inertia_weight(t, T):\n            return 0.9 - (0.9 * (t / T) ** 0.5)\n\n        def diversity_metric(swarm):\n            return np.mean(np.std(swarm, axis=0))\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = nonlinear_inertia_weight(evaluations, self.budget)\n            cognitive_coeff = 2.0 + 2.5 * adaptive_factor  # Modified line\n            social_coeff = 1.0 + 1.5 * adaptive_factor  # Modified line\n\n            current_population_size = self.population_size - int(0.15 * self.population_size * evaluations / self.budget)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n\n                velocity_clamp_factor = 0.2 * (1 - (evaluations / self.budget))\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp_factor * (self.ub - self.lb), velocity_clamp_factor * (self.ub - self.lb))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], self.lb, self.ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n            \n            if diversity_metric(swarm) < 0.05:\n                num_reintroduce = max(1, int(0.15 * current_population_size))\n                for _ in range(num_reintroduce):\n                    idx = np.random.randint(current_population_size)\n                    swarm[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Enhanced swarm dynamics using time-varying cognitive and social coefficients for finer exploration-exploitation balance.", "configspace": "", "generation": 18, "fitness": 0.920305598039322, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.920 with standard deviation 0.002. And the mean value of best solutions found was 0.112 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "5f6dce22-f385-4fb4-ad08-52e12e849f9a", "metadata": {"aucs": [0.9204824277360595, 0.9226203829062335, 0.9178139834756733], "final_y": [0.11014769948829128, 0.11218611560205094, 0.11250063648275666]}, "mutation_prompt": null}
{"id": "61198a4a-6b16-41a4-b430-0150b9c4b6f8", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.lb = None\n        self.ub = None\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        def nonlinear_inertia_weight(t, T):\n            return 0.9 - (0.9 * (t / T) ** 0.5)  # Modified line\n\n        def diversity_metric(swarm):\n            return np.mean(np.std(swarm, axis=0))\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = nonlinear_inertia_weight(evaluations, self.budget)\n            # Modified line\n            cognitive_coeff = 2.5 - (2.5 * (evaluations / self.budget))  # Time-varying cognitive coefficient\n            social_coeff = 1.5 + (1.0 * (evaluations / self.budget))  # Time-varying social coefficient\n\n            current_population_size = self.population_size - int(0.15 * self.population_size * evaluations / self.budget)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n\n                velocity_clamp_factor = 0.2 * (1 - (evaluations / self.budget))\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp_factor * (self.ub - self.lb), velocity_clamp_factor * (self.ub - self.lb))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], self.lb, self.ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n            \n            if diversity_metric(swarm) < 0.05:  # Modified line\n                num_reintroduce = max(1, int(0.15 * current_population_size))  # Modified line\n                for _ in range(num_reintroduce):\n                    idx = np.random.randint(current_population_size)\n                    swarm[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Introducing time-varying acceleration coefficients for enhanced balance between exploration and exploitation.", "configspace": "", "generation": 18, "fitness": 0.919621437242876, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.920 with standard deviation 0.003. And the mean value of best solutions found was 0.111 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "5f6dce22-f385-4fb4-ad08-52e12e849f9a", "metadata": {"aucs": [0.9197051694998595, 0.9154348470052893, 0.9237242952234795], "final_y": [0.10960654587378205, 0.11205353290483011, 0.11087437915269749]}, "mutation_prompt": null}
{"id": "24ee7683-0bb6-4402-aea7-70d234d9597c", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.lb = None\n        self.ub = None\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        def nonlinear_inertia_weight(t, T):\n            return 0.9 - (0.9 * (t / T) ** 0.5)\n\n        def diversity_metric(swarm):\n            return np.mean(np.std(swarm, axis=0))\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = nonlinear_inertia_weight(evaluations, self.budget)\n            cognitive_coeff = 2.7 * (0.5 + 0.5 * adaptive_factor)  # Modified line\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n\n            current_population_size = self.population_size - int(0.15 * self.population_size * evaluations / self.budget)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n\n                velocity_clamp_factor = 0.2 * (1 - (evaluations / self.budget))\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp_factor * (self.ub - self.lb), velocity_clamp_factor * (self.ub - self.lb))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], self.lb, self.ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n            \n            if diversity_metric(swarm) < 0.05:\n                num_reintroduce = max(1, int(0.15 * current_population_size))\n                for _ in range(num_reintroduce):\n                    idx = np.random.randint(current_population_size)\n                    swarm[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Introducing a slight increase in cognitive coefficient scaling for enhanced exploration capabilities.", "configspace": "", "generation": 18, "fitness": 0.9126142486007028, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.913 with standard deviation 0.007. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "5f6dce22-f385-4fb4-ad08-52e12e849f9a", "metadata": {"aucs": [0.9034229518471164, 0.9173999439935127, 0.9170198499614794], "final_y": [0.11692398709793395, 0.11228814385695562, 0.11298114493523936]}, "mutation_prompt": null}
{"id": "5b8fe51d-2c0e-4912-8164-032da5ab8b2d", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.lb = None\n        self.ub = None\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        def nonlinear_inertia_weight(t, T):\n            return 0.9 - (0.9 * (t / T) ** 0.5)\n\n        def diversity_metric(swarm):\n            return np.mean(np.std(swarm, axis=0))\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = nonlinear_inertia_weight(evaluations, self.budget)\n            cognitive_coeff = 2.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n\n            current_population_size = self.population_size - int(0.15 * self.population_size * evaluations / self.budget)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n\n                velocity_clamp_factor = 0.2 * (1 - (evaluations / self.budget))\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp_factor * (self.ub - self.lb), velocity_clamp_factor * (self.ub - self.lb))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], self.lb, self.ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n            \n            if diversity_metric(swarm) < 0.07:  # Changed value\n                num_reintroduce = max(1, int(0.2 * current_population_size))  # Changed value\n                for _ in range(num_reintroduce):\n                    idx = np.random.randint(current_population_size)\n                    swarm[idx] = np.random.uniform(self.lb, self.ub, self.dim) + 0.05 * np.random.randn(self.dim)  # Changed operation\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Introduces adaptive neighborhood search and dynamic diversity control for enhanced exploration and exploitation balance.", "configspace": "", "generation": 18, "fitness": 0.9122092781447915, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.912 with standard deviation 0.012. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "5f6dce22-f385-4fb4-ad08-52e12e849f9a", "metadata": {"aucs": [0.9167094075953036, 0.8961545661934122, 0.9237638606456586], "final_y": [0.11126317931472796, 0.12049873137177447, 0.11269711604927957]}, "mutation_prompt": null}
{"id": "e3a52e4d-2123-4159-938b-d63f1831285f", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.lb = None\n        self.ub = None\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        def nonlinear_inertia_weight(t, T):\n            return 0.9 - (0.9 * (t / T) ** 0.5)\n\n        def diversity_metric(swarm):\n            return np.mean(np.std(swarm, axis=0))\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = nonlinear_inertia_weight(evaluations, self.budget)\n            cognitive_coeff = 2.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n\n            current_population_size = self.population_size - int(0.15 * self.population_size * evaluations / self.budget)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n\n                velocity_clamp_factor = 0.2 * (1 - (evaluations / self.budget))\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp_factor * (self.ub - self.lb), velocity_clamp_factor * (self.ub - self.lb))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], self.lb, self.ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n            \n            if diversity_metric(swarm) < 0.05:\n                num_reintroduce = max(1, int(0.15 * current_population_size))\n                for _ in range(num_reintroduce):\n                    idx = np.random.randint(current_population_size)\n                    swarm[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n            \n            if evaluations % int(0.3 * self.budget) == 0:  # New line\n                idx = np.random.randint(current_population_size)\n                swarm[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Implement a hyperjump mechanism to escape local optima and enhance global exploration capabilities.", "configspace": "", "generation": 18, "fitness": 0.9050729045954858, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.905 with standard deviation 0.022. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "5f6dce22-f385-4fb4-ad08-52e12e849f9a", "metadata": {"aucs": [0.8740141305478338, 0.9257781389589441, 0.91542644427968], "final_y": [0.12132959409843058, 0.11094222200398107, 0.1131352060301114]}, "mutation_prompt": null}
{"id": "7f263cab-4079-4d90-b06f-8f75e91852a8", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.lb = None\n        self.ub = None\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        def nonlinear_inertia_weight(t, T):\n            return 0.9 - (0.9 * (t / T) ** 0.5)\n\n        def diversity_metric(swarm):\n            return np.mean(np.std(swarm, axis=0))\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = nonlinear_inertia_weight(evaluations, self.budget)\n            cognitive_coeff = 2.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n\n            current_population_size = self.population_size - int(0.15 * self.population_size * evaluations / self.budget)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n\n                velocity_clamp_factor = 0.2 * (1 - (evaluations / self.budget))\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp_factor * (self.ub - self.lb), velocity_clamp_factor * (self.ub - self.lb))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], self.lb, self.ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n            if diversity_metric(swarm) < 0.05 * np.sqrt(evaluations / self.budget):  # Modified line\n                num_reintroduce = max(1, int(0.15 * current_population_size))\n                for _ in range(num_reintroduce):\n                    idx = np.random.randint(current_population_size)\n                    swarm[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Introducing a nonlinear diversity threshold for better reinitialization timing and improved convergence.", "configspace": "", "generation": 19, "fitness": 0.8935449213926517, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.894 with standard deviation 0.030. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "5f6dce22-f385-4fb4-ad08-52e12e849f9a", "metadata": {"aucs": [0.8546845424381571, 0.8980363799261508, 0.9279138418136474], "final_y": [0.129190561045471, 0.12050390747608397, 0.11018601232417147]}, "mutation_prompt": null}
{"id": "8ce9d73f-d8fb-4323-aae8-43f4597b1560", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.lb = None\n        self.ub = None\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        def nonlinear_inertia_weight(t, T):\n            return 0.9 - (0.9 * (t / T) ** 0.5)\n\n        def diversity_metric(swarm):\n            return np.mean(np.std(swarm, axis=0))\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = nonlinear_inertia_weight(evaluations, self.budget)\n            cognitive_coeff = 2.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)  # Modified line\n\n            current_population_size = self.population_size - int(0.15 * self.population_size * evaluations / self.budget)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n\n                velocity_clamp_factor = 0.2 * (1 - (evaluations / self.budget))\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp_factor * (self.ub - self.lb), velocity_clamp_factor * (self.ub - self.lb))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], self.lb, self.ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n            if diversity_metric(swarm) < 0.05:\n                num_reintroduce = max(1, int(0.15 * current_population_size))\n                for _ in range(num_reintroduce):\n                    idx = np.random.randint(current_population_size)\n                    swarm[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Introducing adaptive social coefficient re-scaling to enhance convergence speed without sacrificing diversity.", "configspace": "", "generation": 19, "fitness": 0.9034821585007856, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.903 with standard deviation 0.011. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "5f6dce22-f385-4fb4-ad08-52e12e849f9a", "metadata": {"aucs": [0.8907534812237659, 0.9018759830650065, 0.9178170112135842], "final_y": [0.12153865359320881, 0.11794389871708166, 0.11477628154433261]}, "mutation_prompt": null}
{"id": "0b4c1d93-b778-456c-9c41-f40fc85613c8", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.lb = None\n        self.ub = None\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        def nonlinear_inertia_weight(t, T):\n            return 0.9 - (0.9 * (t / T) ** 0.5)\n\n        def diversity_metric(swarm):\n            return np.mean(np.std(swarm, axis=0))\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = nonlinear_inertia_weight(evaluations, self.budget)\n            cognitive_coeff = 2.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n\n            current_population_size = self.population_size - int(0.15 * self.population_size * evaluations / self.budget)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n\n                velocity_clamp_factor = 0.2 * (1 - (evaluations / self.budget))\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp_factor * (self.ub - self.lb), velocity_clamp_factor * (self.ub - self.lb))\n\n                swarm[i] += 0.9 * self.velocity[i]  # Modified line\n\n                swarm[i] = np.clip(swarm[i], self.lb, self.ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n            \n            if diversity_metric(swarm) < 0.05:\n                num_reintroduce = max(1, int(0.15 * current_population_size))\n                for _ in range(num_reintroduce):\n                    idx = np.random.randint(current_population_size)\n                    swarm[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Enhanced particle position adjustment via velocity damping to improve convergence accuracy.", "configspace": "", "generation": 19, "fitness": 0.9201530730634212, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.920 with standard deviation 0.006. And the mean value of best solutions found was 0.112 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "5f6dce22-f385-4fb4-ad08-52e12e849f9a", "metadata": {"aucs": [0.911534274255354, 0.9249946804579599, 0.9239302644769498], "final_y": [0.1116384187885775, 0.11181438201594462, 0.11112161015436184]}, "mutation_prompt": null}
{"id": "3d425d0a-59a5-49af-b616-f4db537ce58c", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.lb = None\n        self.ub = None\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        def nonlinear_inertia_weight(t, T):\n            return 0.9 - (0.9 * (t / T) ** 0.5)\n\n        def diversity_metric(swarm):\n            return np.mean(np.std(swarm, axis=0))\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = nonlinear_inertia_weight(evaluations, self.budget)\n            cognitive_coeff = 2.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * np.sin(np.pi * adaptive_factor / 2)  # Modified line\n\n            current_population_size = self.population_size - int(0.15 * self.population_size * evaluations / self.budget)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n\n                velocity_clamp_factor = 0.3 * (1 - (evaluations / self.budget))  # Modified line\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp_factor * (self.ub - self.lb), velocity_clamp_factor * (self.ub - self.lb))  # Modified line\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], self.lb, self.ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n            \n            if diversity_metric(swarm) < 0.05:\n                num_reintroduce = max(1, int(0.15 * current_population_size))\n                for _ in range(num_reintroduce):\n                    idx = np.random.randint(current_population_size)\n                    swarm[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Introducing a nonlinear social coefficient and a more precise velocity clamping strategy for enhanced convergence and exploration.", "configspace": "", "generation": 19, "fitness": 0.9053234962960627, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.905 with standard deviation 0.013. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "5f6dce22-f385-4fb4-ad08-52e12e849f9a", "metadata": {"aucs": [0.8899071626591315, 0.9039573366161487, 0.9221059896129077], "final_y": [0.1201627546941606, 0.11694133366941128, 0.11340167552484803]}, "mutation_prompt": null}
{"id": "e5b8851c-8e66-4f9f-bd02-382774d29b63", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.lb = None\n        self.ub = None\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        def nonlinear_inertia_weight(t, T):\n            return 0.9 - (0.9 * (t / T) ** 0.5)\n\n        def diversity_metric(swarm):\n            return np.mean(np.std(swarm, axis=0))\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = nonlinear_inertia_weight(evaluations, self.budget)\n            cognitive_coeff = 2.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n\n            current_population_size = self.population_size - int(0.15 * self.population_size * evaluations / self.budget)\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    2.0 * (0.5 + np.random.rand()) * r1 * (personal_best[i] - swarm[i]) +  # Changed line\n                                    social_coeff * r2 * (global_best - swarm[i]))\n\n                velocity_clamp_factor = 0.3 * (1 - (evaluations / self.budget))  # Changed line\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp_factor * (self.ub - self.lb), velocity_clamp_factor * (self.ub - self.lb))\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], self.lb, self.ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n            \n            if diversity_metric(swarm) < 0.05:\n                num_reintroduce = max(1, int(0.15 * current_population_size))\n                for _ in range(num_reintroduce):\n                    idx = np.random.randint(current_population_size)\n                    swarm[idx] = np.random.uniform(self.lb, self.ub, self.dim)\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Introduce self-adaptive learning factors and improved velocity clamping to enhance exploration and exploitation balance in swarm optimization.", "configspace": "", "generation": 19, "fitness": 0.9143726187142925, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.914 with standard deviation 0.010. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "5f6dce22-f385-4fb4-ad08-52e12e849f9a", "metadata": {"aucs": [0.9093183123413077, 0.9054941414399874, 0.9283054023615827], "final_y": [0.11306383486512606, 0.11641307918564603, 0.11014255788527916]}, "mutation_prompt": null}
