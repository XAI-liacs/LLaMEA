{"id": "d3710950-3ae8-46d9-aec5-b18d5b4a44b4", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialization\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = min(50, self.budget // 10)\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        while evaluations < self.budget:\n            # Selection\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n            elite = population[:population_size // 5]\n            \n            # Crossover and Mutation (Evolutionary Strategy)\n            offspring = []\n            for i in range(population_size):\n                parent1, parent2 = np.random.choice(elite, 2, replace=False)\n                child = self.crossover(parent1, parent2)\n                child = self.mutate(child, lb, ub)\n                offspring.append(child)\n            \n            # Evaluation\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n            \n            # Adaptive Neighborhood Search (Local Exploitation)\n            for i in range(len(offspring)):\n                if evaluations >= self.budget:\n                    break\n                neighbor = self.adaptive_neighbor_search(offspring[i], lb, ub, func)\n                offspring[i] = neighbor\n                offspring_fitness[i] = func(neighbor)\n                evaluations += 1\n            \n            # Selection for Next Generation\n            combined_population = np.vstack((population, offspring))\n            combined_fitness = np.hstack((fitness, offspring_fitness))\n            sorted_indices = np.argsort(combined_fitness)\n            best_indices = sorted_indices[:population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n        return population[0]\n\n    def crossover(self, parent1, parent2):\n        alpha = np.random.uniform(0, 1, self.dim)\n        return alpha * parent1 + (1 - alpha) * parent2\n\n    def mutate(self, individual, lb, ub):\n        mutation_strength = 0.1 * (ub - lb)\n        mutation_vector = np.random.normal(0, mutation_strength, self.dim)\n        mutated = individual + mutation_vector\n        return np.clip(mutated, lb, ub)\n\n    def adaptive_neighbor_search(self, individual, lb, ub, func):\n        step_size = (ub - lb) * 0.05\n        for _ in range(3):  # Try multiple small steps\n            neighbor = individual + np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(neighbor, lb, ub)\n            if func(neighbor) < func(individual):\n                individual = neighbor\n        return individual", "name": "HybridMetaheuristicOptimizer", "description": "A novel hybrid metaheuristic combining evolutionary strategies with adaptive neighborhood search to efficiently explore and exploit the search space.", "configspace": "", "generation": 0, "fitness": -Infinity, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 194, in initialize_single\n    new_individual = self.evaluate_fitness(new_individual)\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 288, in evaluate_fitness\n    updated_individual = self.f(individual, self.logger)\n  File \"/home/ian/LLaMEA/benchmarks/tuto_global_optimization_photonics/exp_photonic.py\", line 149, in evaluatePhotonic\n    algorithm(problem)\n  File \"<string>\", line 26, in __call__\n  File \"numpy/random/mtrand.pyx\", line 947, in numpy.random.mtrand.RandomState.choice\nValueError: a must be 1-dimensional\n.", "error": "ValueError('a must be 1-dimensional')Traceback (most recent call last):\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 194, in initialize_single\n    new_individual = self.evaluate_fitness(new_individual)\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 288, in evaluate_fitness\n    updated_individual = self.f(individual, self.logger)\n  File \"/home/ian/LLaMEA/benchmarks/tuto_global_optimization_photonics/exp_photonic.py\", line 149, in evaluatePhotonic\n    algorithm(problem)\n  File \"<string>\", line 26, in __call__\n  File \"numpy/random/mtrand.pyx\", line 947, in numpy.random.mtrand.RandomState.choice\nValueError: a must be 1-dimensional\n", "parent_id": null, "metadata": {}, "mutation_prompt": null}
{"id": "211bea0e-76d9-47ce-af47-4701d5ed6586", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx].copy()\n        best_fitness = fitness[best_idx]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Differential Evolution Mutation\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(population[a] + 0.8 * (population[b] - population[c]), lb, ub)\n                \n                # Simulated Annealing Crossover\n                trial = np.where(np.random.rand(self.dim) < self.temperature, mutant, population[i])\n                \n                # Evaluate new candidate\n                trial_fitness = func(trial)\n                evaluations += 1\n                \n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial.copy()\n                        best_fitness = trial_fitness\n            \n            # Cooling schedule for Simulated Annealing\n            self.temperature *= self.cooling_rate\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "A novel hybrid metaheuristic combining Differential Evolution and Simulated Annealing for efficient exploration and exploitation in high-dimensional black box optimization.", "configspace": "", "generation": 0, "fitness": 0.7942754979440295, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.794 with standard deviation 0.013. And the mean value of best solutions found was 0.147 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": null, "metadata": {"aucs": [0.7787504127240688, 0.8101076925512778, 0.793968388556742], "final_y": [0.1480584970039146, 0.14106367310069778, 0.1517989508739207]}, "mutation_prompt": null}
{"id": "6ec86e71-29f8-43a7-b4de-21a38615f0e9", "solution": "import numpy as np\n\nclass AntSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, self.budget // 10)  # Ensure enough evaluations\n        self.ants = np.random.uniform(0, 1, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.5, 0.5, (self.population_size, self.dim))\n        self.personal_best_positions = self.ants.copy()\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        if not hasattr(func, 'bounds') or not hasattr(func.bounds, 'lb') or not hasattr(func.bounds, 'ub'):\n            raise ValueError(\"Function must have 'bounds' with 'lb' and 'ub' attributes\")\n\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        evaluations = 0\n        while evaluations < self.budget:\n            # Evaluate current positions\n            scores = np.array([func(ant) for ant in self.ants])\n            evaluations += len(self.ants)\n\n            # Update personal bests\n            better_mask = scores < self.personal_best_scores\n            self.personal_best_positions[better_mask] = self.ants[better_mask]\n            self.personal_best_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            min_score_idx = np.argmin(scores)\n            if scores[min_score_idx] < self.global_best_score:\n                self.global_best_score = scores[min_score_idx]\n                self.global_best_position = self.ants[min_score_idx]\n\n            # Update velocities and positions\n            inertia = 0.7\n            cognitive = 1.5\n            social = 1.5\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.velocities = (inertia * self.velocities +\n                               cognitive * r1 * (self.personal_best_positions - self.ants) +\n                               social * r2 * (self.global_best_position - self.ants))\n            self.ants += self.velocities\n\n            # Clip positions to bounds\n            self.ants = np.clip(self.ants, lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "AntSwarmOptimization", "description": "A novel metaheuristic algorithm inspired by the foraging behavior of ants and the efficient search strategies of particle swarms to balance exploration and exploitation in high-dimensional optimization tasks.", "configspace": "", "generation": 0, "fitness": 0.660056797745749, "feedback": "The algorithm AntSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.660 with standard deviation 0.000. And the mean value of best solutions found was 0.219 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": null, "metadata": {"aucs": [0.660056797745749, 0.660056797745749, 0.660056797745749], "final_y": [0.21891901516198964, 0.21891901516198964, 0.21891901516198964]}, "mutation_prompt": null}
{"id": "cec0df4f-27be-4720-a26d-797e5f08b76f", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim  # Adaptive based on dimension\n        self.harmony_memory_size = max(5, dim)  # Size of harmony memory\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.phi = 0.5  # Harmony memory consideration rate\n        self.beta = 1.0  # Parameter to control randomization\n        self.gamma = 0.5  # Parameter to control local search\n\n    def __call__(self, func):\n        # Initialize harmony memory with random solutions\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        eval_count = self.harmony_memory_size\n\n        while eval_count < self.budget:\n            # Generate a new harmony vector\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.phi:\n                    idx = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = self.harmony_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n                # Adjust new harmony using pitch adjustment\n                if np.random.rand() < self.gamma:\n                    new_harmony[i] += self.beta * (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n\n            # Ensure new harmony is within bounds\n            new_harmony = np.clip(new_harmony, lb, ub)\n\n            # Evaluate the new harmony\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            # Update harmony memory if the new solution is better\n            worst_idx = np.argmax(func_values)\n            if new_value < func_values[worst_idx]:\n                self.harmony_memory[worst_idx] = new_harmony\n                func_values[worst_idx] = new_value\n\n        # Return the best found solution and its value\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Introducing the Adaptive Swarm Harmony Optimization (ASHO), which combines swarm intelligence and harmony search principles to dynamically balance exploration and exploitation for effective black box optimization.", "configspace": "", "generation": 0, "fitness": 0.8086976606738013, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.809 with standard deviation 0.005. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": null, "metadata": {"aucs": [0.8143544938537121, 0.8100733556453086, 0.801665132522383], "final_y": [0.14725751602245363, 0.14961069472816702, 0.1483165764241312]}, "mutation_prompt": null}
{"id": "c558093f-3998-4a4a-9752-b1d1031090dc", "solution": "import numpy as np\n\nclass QuantumInspiredGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20  # Population size for genetic algorithm\n        self.quantum_size = 10  # Quantum-inspired solutions\n        self.quantum_angle = np.pi / 4  # Quantum rotation angle\n        self.mutation_rate = 0.1  # Mutation rate\n        self.cross_prob = 0.7  # Crossover probability\n\n    def initialize_population(self, lb, ub):\n        # Initialize a classical population\n        classical_pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        # Initialize a quantum-inspired population\n        quantum_pop = np.random.uniform(0, 1, (self.quantum_size, self.dim))\n        return classical_pop, quantum_pop\n\n    def quantum_to_classical(self, quantum_pop, lb, ub):\n        # Convert quantum-inspired individuals to classical domain\n        return lb + (ub - lb) * (np.sin(quantum_pop * self.quantum_angle) ** 2)\n\n    def evaluate_population(self, pop, func):\n        return np.array([func(ind) for ind in pop])\n\n    def select_parents(self, classical_pop, fitness):\n        idx = np.random.choice(range(self.population_size), size=2, p=fitness / fitness.sum())\n        return classical_pop[idx]\n\n    def crossover(self, parents):\n        if np.random.rand() < self.cross_prob:\n            alpha = np.random.rand(self.dim)\n            return parents[0] * alpha + parents[1] * (1 - alpha)\n        else:\n            return parents[np.random.randint(0, 2)]\n\n    def mutate(self, individual, lb, ub):\n        if np.random.rand() < self.mutation_rate:\n            mutation_vector = np.random.uniform(-0.1, 0.1, self.dim)\n            mutated = individual + mutation_vector\n            return np.clip(mutated, lb, ub)\n        else:\n            return individual\n\n    def update_quantum_population(self, quantum_pop, best_individual, lb, ub):\n        classical_best = self.quantum_to_classical(quantum_pop, lb, ub)\n        best_index = np.argmin(np.array([np.linalg.norm(ind - best_individual) for ind in classical_best]))\n        quantum_pop[best_index] += np.random.normal(0, 0.1, self.dim)\n        return np.clip(quantum_pop, 0, 1)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        classical_pop, quantum_pop = self.initialize_population(lb, ub)\n        evaluations = 0\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evaluations < self.budget:\n            # Convert and evaluate populations\n            classical_solutions = classical_pop\n            quantum_solutions = self.quantum_to_classical(quantum_pop, lb, ub)\n            total_population = np.vstack((classical_solutions, quantum_solutions))\n            fitness = self.evaluate_population(total_population, func)\n            evaluations += len(total_population)\n\n            # Find best solution\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < best_fitness:\n                best_fitness = fitness[min_idx]\n                best_solution = total_population[min_idx]\n\n            # Genetic operations\n            classical_fitness = fitness[:self.population_size]\n            new_classical_pop = []\n            for _ in range(self.population_size):\n                parents = self.select_parents(classical_pop, classical_fitness)\n                offspring = self.crossover(parents)\n                offspring = self.mutate(offspring, lb, ub)\n                new_classical_pop.append(offspring)\n            classical_pop = np.array(new_classical_pop)\n\n            # Update quantum population\n            quantum_pop = self.update_quantum_population(quantum_pop, best_solution, lb, ub)\n\n        return best_solution", "name": "QuantumInspiredGA", "description": "Hybrid Quantum-Inspired Genetic Algorithm combines quantum-inspired solutions with classic genetic operations for efficient exploration and exploitation of search space.", "configspace": "", "generation": 0, "fitness": 0.7409129713159913, "feedback": "The algorithm QuantumInspiredGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.741 with standard deviation 0.021. And the mean value of best solutions found was 0.181 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": null, "metadata": {"aucs": [0.7346652793975723, 0.76890311738062, 0.7191705171697818], "final_y": [0.18307426899157564, 0.1702433386818767, 0.19103396660959382]}, "mutation_prompt": null}
{"id": "8566ed64-a42f-4819-bfff-f5e493cd3f61", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialization\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = min(50, self.budget // 10)\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        while evaluations < self.budget:\n            # Selection\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n            elite = population[:population_size // 5]\n            \n            # Crossover and Mutation (Evolutionary Strategy)\n            offspring = []\n            for i in range(population_size):\n                parents = np.random.choice(len(elite), 2, replace=False, p=self.selection_probabilities(fitness))\n                parent1, parent2 = elite[parents[0]], elite[parents[1]]\n                child = self.crossover(parent1, parent2)\n                child = self.mutate(child, lb, ub)\n                offspring.append(child)\n            \n            # Evaluation\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n            \n            # Adaptive Neighborhood Search (Local Exploitation)\n            for i in range(len(offspring)):\n                if evaluations >= self.budget:\n                    break\n                if np.random.rand() < 0.3:  # Elitist selection for neighborhood search\n                    neighbor = self.adaptive_neighbor_search(offspring[i], lb, ub, func)\n                    offspring[i] = neighbor\n                    offspring_fitness[i] = func(neighbor)\n                    evaluations += 1\n            \n            # Selection for Next Generation\n            combined_population = np.vstack((population, offspring))\n            combined_fitness = np.hstack((fitness, offspring_fitness))\n            sorted_indices = np.argsort(combined_fitness)\n            best_indices = sorted_indices[:population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n        return population[0]\n\n    def selection_probabilities(self, fitness):\n        rank = np.argsort(np.argsort(fitness))\n        max_rank = len(fitness)\n        return (max_rank - rank) / max_rank\n\n    def crossover(self, parent1, parent2):\n        alpha = np.random.uniform(0, 1, self.dim)\n        return alpha * parent1 + (1 - alpha) * parent2\n\n    def mutate(self, individual, lb, ub):\n        mutation_strength = 0.1 * (ub - lb)\n        mutation_vector = np.random.normal(0, mutation_strength, self.dim)\n        mutated = individual + mutation_vector\n        return np.clip(mutated, lb, ub)\n\n    def adaptive_neighbor_search(self, individual, lb, ub, func):\n        step_size = (ub - lb) * 0.05\n        for _ in range(3):  # Try multiple small steps\n            neighbor = individual + np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(neighbor, lb, ub)\n            if func(neighbor) < func(individual):\n                individual = neighbor\n        return individual", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced Hybrid Metaheuristic Optimizer combining strength-based selection and elitist adaptive neighborhood search for robust exploration and exploitation.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "An exception occurred: ValueError(\"'a' and 'p' must have same size\").", "error": "ValueError(\"'a' and 'p' must have same size\")", "parent_id": "d3710950-3ae8-46d9-aec5-b18d5b4a44b4", "metadata": {}, "mutation_prompt": null}
{"id": "dd218c01-4bb8-4ed9-85fc-5dc4afb34d77", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialization\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        population_size = min(50, self.budget // 10)\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        while evaluations < self.budget:\n            # Selection\n            sorted_indices = np.argsort(fitness)\n            population = population[sorted_indices]\n            fitness = fitness[sorted_indices]\n            elite = population[:population_size // 5]\n            \n            # Crossover and Mutation (Evolutionary Strategy)\n            offspring = []\n            for i in range(population_size):\n                parents_indices = np.random.choice(len(elite), 2, replace=False)\n                parent1, parent2 = elite[parents_indices[0]], elite[parents_indices[1]]\n                child = self.crossover(parent1, parent2)\n                child = self.mutate(child, lb, ub)\n                offspring.append(child)\n            \n            # Evaluation\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            evaluations += len(offspring)\n            \n            # Adaptive Neighborhood Search (Local Exploitation)\n            for i in range(len(offspring)):\n                if evaluations >= self.budget:\n                    break\n                neighbor = self.adaptive_neighbor_search(offspring[i], lb, ub, func)\n                offspring[i] = neighbor\n                offspring_fitness[i] = func(neighbor)\n                evaluations += 1\n            \n            # Selection for Next Generation\n            combined_population = np.vstack((population, offspring))\n            combined_fitness = np.hstack((fitness, offspring_fitness))\n            sorted_indices = np.argsort(combined_fitness)\n            best_indices = sorted_indices[:population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n        return population[0]\n\n    def crossover(self, parent1, parent2):\n        alpha = np.random.uniform(0, 1, self.dim)\n        return alpha * parent1 + (1 - alpha) * parent2\n\n    def mutate(self, individual, lb, ub):\n        mutation_strength = 0.1 * (ub - lb)\n        mutation_vector = np.random.normal(0, mutation_strength, self.dim)\n        mutated = individual + mutation_vector\n        return np.clip(mutated, lb, ub)\n\n    def adaptive_neighbor_search(self, individual, lb, ub, func):\n        step_size = (ub - lb) * 0.05\n        for _ in range(3):  # Try multiple small steps\n            neighbor = individual + np.random.uniform(-step_size, step_size, self.dim)\n            neighbor = np.clip(neighbor, lb, ub)\n            if func(neighbor) < func(individual):\n                individual = neighbor\n        return individual", "name": "HybridMetaheuristicOptimizer", "description": "A novel hybrid metaheuristic combining evolutionary strategies with adaptive neighborhood search to efficiently explore and exploit the search space.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "An exception occurred: ValueError(\"'a' and 'p' must have same size\").", "error": "ValueError(\"'a' and 'p' must have same size\")", "parent_id": "d3710950-3ae8-46d9-aec5-b18d5b4a44b4", "metadata": {}, "mutation_prompt": null}
{"id": "d8858d62-2522-49fd-804a-95ce1a3499ab", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim  # Adjusted population size from 10 * dim to 8 * dim\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx].copy()\n        best_fitness = fitness[best_idx]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Differential Evolution Mutation\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(population[a] + 0.8 * (population[b] - population[c]), lb, ub)\n                \n                # Simulated Annealing Crossover\n                trial = np.where(np.random.rand(self.dim) < self.temperature, mutant, population[i])\n                \n                # Evaluate new candidate\n                trial_fitness = func(trial)\n                evaluations += 1\n                \n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial.copy()\n                        best_fitness = trial_fitness\n            \n            # Cooling schedule for Simulated Annealing\n            self.temperature *= self.cooling_rate\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "Refined hybrid metaheuristic by adjusting population size for better balance between exploration and computational efficiency.", "configspace": "", "generation": 1, "fitness": 0.7920968086835108, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.792 with standard deviation 0.018. And the mean value of best solutions found was 0.146 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "211bea0e-76d9-47ce-af47-4701d5ed6586", "metadata": {"aucs": [0.773957254033184, 0.816103179987183, 0.7862299920301656], "final_y": [0.14751088019606196, 0.13842560370318313, 0.15130946940756762]}, "mutation_prompt": null}
{"id": "f7a9f811-5fe9-4dca-a179-441250532841", "solution": "import numpy as np\n\nclass QuantumInspiredGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20  # Population size for genetic algorithm\n        self.quantum_size = 10  # Quantum-inspired solutions\n        self.quantum_angle = np.pi / 6  # Quantum rotation angle\n        self.mutation_rate = 0.1  # Mutation rate\n        self.cross_prob = 0.7  # Crossover probability\n\n    def initialize_population(self, lb, ub):\n        # Initialize a classical population\n        classical_pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        # Initialize a quantum-inspired population\n        quantum_pop = np.random.uniform(0, 1, (self.quantum_size, self.dim))\n        return classical_pop, quantum_pop\n\n    def quantum_to_classical(self, quantum_pop, lb, ub):\n        # Convert quantum-inspired individuals to classical domain\n        return lb + (ub - lb) * (np.sin(quantum_pop * self.quantum_angle) ** 2)\n\n    def evaluate_population(self, pop, func):\n        return np.array([func(ind) for ind in pop])\n\n    def select_parents(self, classical_pop, fitness):\n        idx = np.random.choice(range(self.population_size), size=2, replace=False, p=fitness / fitness.sum())\n        return classical_pop[idx]\n\n    def crossover(self, parents):\n        if np.random.rand() < self.cross_prob:\n            alpha = np.random.rand(self.dim)\n            return parents[0] * alpha + parents[1] * (1 - alpha)\n        else:\n            return parents[np.random.randint(0, 2)]\n\n    def mutate(self, individual, lb, ub):\n        if np.random.rand() < self.mutation_rate:\n            mutation_vector = np.random.uniform(-0.1, 0.1, self.dim)\n            mutated = individual + mutation_vector\n            return np.clip(mutated, lb, ub)\n        else:\n            return individual\n\n    def update_quantum_population(self, quantum_pop, best_individual, lb, ub):\n        classical_best = self.quantum_to_classical(quantum_pop, lb, ub)\n        best_index = np.argmin(np.array([np.linalg.norm(ind - best_individual) for ind in classical_best]))\n        quantum_pop[best_index] += np.random.normal(0, 0.1, self.dim)\n        return np.clip(quantum_pop, 0, 1)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        classical_pop, quantum_pop = self.initialize_population(lb, ub)\n        evaluations = 0\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evaluations < self.budget:\n            # Convert and evaluate populations\n            classical_solutions = classical_pop\n            quantum_solutions = self.quantum_to_classical(quantum_pop, lb, ub)\n            total_population = np.vstack((classical_solutions, quantum_solutions))\n            fitness = self.evaluate_population(total_population, func)\n            evaluations += len(total_population)\n\n            # Find best solution\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < best_fitness:\n                best_fitness = fitness[min_idx]\n                best_solution = total_population[min_idx]\n\n            # Genetic operations\n            classical_fitness = fitness[:self.population_size]\n            new_classical_pop = []\n            for _ in range(self.population_size):\n                parents = self.select_parents(classical_pop, classical_fitness)\n                offspring = self.crossover(parents)\n                offspring = self.mutate(offspring, lb, ub)\n                new_classical_pop.append(offspring)\n            classical_pop = np.array(new_classical_pop)\n\n            # Update quantum population\n            quantum_pop = self.update_quantum_population(quantum_pop, best_solution, lb, ub)\n\n        return best_solution", "name": "QuantumInspiredGA", "description": "Refined Quantum-Inspired Genetic Algorithm with an updated selection mechanism and enhanced quantum angle adjustment for improved exploration and exploitation.", "configspace": "", "generation": 1, "fitness": 0.7598070650482951, "feedback": "The algorithm QuantumInspiredGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.760 with standard deviation 0.021. And the mean value of best solutions found was 0.169 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "c558093f-3998-4a4a-9752-b1d1031090dc", "metadata": {"aucs": [0.7538478397642514, 0.7875254656765085, 0.7380478897041256], "final_y": [0.17533820047631332, 0.15986834733148236, 0.17280713233285994]}, "mutation_prompt": null}
{"id": "4311c0fe-f210-4955-b941-73d362d05740", "solution": "import numpy as np\n\nclass QuantumInspiredGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20  # Population size for genetic algorithm\n        self.quantum_size = 10  # Quantum-inspired solutions\n        self.quantum_angle = np.pi / 4  # Quantum rotation angle\n        self.mutation_rate = 0.1  # Mutation rate\n        self.cross_prob = 0.7  # Crossover probability\n\n    def initialize_population(self, lb, ub):\n        # Initialize a classical population\n        classical_pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        # Initialize a quantum-inspired population\n        quantum_pop = np.random.uniform(0, 1, (self.quantum_size, self.dim))\n        return classical_pop, quantum_pop\n\n    def quantum_to_classical(self, quantum_pop, lb, ub):\n        # Convert quantum-inspired individuals to classical domain\n        return lb + (ub - lb) * (np.sin(quantum_pop * self.quantum_angle) ** 2)\n\n    def evaluate_population(self, pop, func):\n        return np.array([func(ind) for ind in pop])\n\n    def select_parents(self, classical_pop, fitness):\n        idx = np.random.choice(range(self.population_size), size=2, p=fitness / fitness.sum())\n        return classical_pop[idx]\n\n    def crossover(self, parents):\n        if np.random.rand() < self.cross_prob:\n            alpha = np.random.rand(self.dim) * 0.5 + 0.5  # Ensure more diversity\n            return parents[0] * alpha + parents[1] * (1 - alpha)\n        else:\n            return parents[np.random.randint(0, 2)]\n\n    def mutate(self, individual, lb, ub):\n        if np.random.rand() < self.mutation_rate:\n            mutation_vector = np.random.uniform(-0.2, 0.2, self.dim)  # Increase mutation range\n            mutated = individual + mutation_vector\n            return np.clip(mutated, lb, ub)\n        else:\n            return individual\n\n    def update_quantum_population(self, quantum_pop, best_individual, lb, ub):\n        classical_best = self.quantum_to_classical(quantum_pop, lb, ub)\n        best_index = np.argmin(np.array([np.linalg.norm(ind - best_individual) for ind in classical_best]))\n        quantum_pop[best_index] += np.random.normal(0, 0.1, self.dim)\n        return np.clip(quantum_pop, 0, 1)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        classical_pop, quantum_pop = self.initialize_population(lb, ub)\n        evaluations = 0\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evaluations < self.budget:\n            # Convert and evaluate populations\n            classical_solutions = classical_pop\n            quantum_solutions = self.quantum_to_classical(quantum_pop, lb, ub)\n            total_population = np.vstack((classical_solutions, quantum_solutions))\n            fitness = self.evaluate_population(total_population, func)\n            evaluations += len(total_population)\n\n            # Find best solution\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < best_fitness:\n                best_fitness = fitness[min_idx]\n                best_solution = total_population[min_idx]\n\n            # Genetic operations\n            classical_fitness = fitness[:self.population_size]\n            new_classical_pop = []\n            for _ in range(self.population_size):\n                parents = self.select_parents(classical_pop, classical_fitness)\n                offspring = self.crossover(parents)\n                offspring = self.mutate(offspring, lb, ub)\n                new_classical_pop.append(offspring)\n            classical_pop = np.array(new_classical_pop)\n\n            # Update quantum population\n            quantum_pop = self.update_quantum_population(quantum_pop, best_solution, lb, ub)\n\n        return best_solution", "name": "QuantumInspiredGA", "description": "Enhanced Quantum-Inspired GA with improved crossover diversity and dynamic mutation for better exploration.", "configspace": "", "generation": 1, "fitness": 0.7438484923282781, "feedback": "The algorithm QuantumInspiredGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.744 with standard deviation 0.020. And the mean value of best solutions found was 0.170 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "c558093f-3998-4a4a-9752-b1d1031090dc", "metadata": {"aucs": [0.7431184620256401, 0.7691657371059721, 0.7192612778532221], "final_y": [0.1519444493729395, 0.1692271079214639, 0.18743885481077915]}, "mutation_prompt": null}
{"id": "0d9b8ff8-7513-4e54-a94f-8e6afca3960f", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx].copy()\n        best_fitness = fitness[best_idx]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Differential Evolution Mutation\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutation_factor = 0.5 + 0.3 * (np.random.rand() - 0.5)  # Dynamically adjust mutation factor\n                mutant = np.clip(population[a] + mutation_factor * (population[b] - population[c]), lb, ub)\n                \n                # Simulated Annealing Crossover\n                trial = np.where(np.random.rand(self.dim) < self.temperature, mutant, population[i])\n                \n                # Evaluate new candidate\n                trial_fitness = func(trial)\n                evaluations += 1\n                \n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial.copy()\n                        best_fitness = trial_fitness\n            \n            # Cooling schedule for Simulated Annealing\n            self.temperature *= self.cooling_rate\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "Improved exploration-exploitation balance by adjusting mutation factor dynamically in the HybridMetaheuristic.", "configspace": "", "generation": 2, "fitness": 0.8166003887980896, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.817 with standard deviation 0.009. And the mean value of best solutions found was 0.137 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "211bea0e-76d9-47ce-af47-4701d5ed6586", "metadata": {"aucs": [0.8042673934549622, 0.8221004970669414, 0.8234332758723655], "final_y": [0.14499455761239566, 0.13674979405192444, 0.12807880546678563]}, "mutation_prompt": null}
{"id": "b31fd5c4-1f42-4dd8-b8b3-ae9757cf6077", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim  # Adaptive based on dimension\n        self.harmony_memory_size = max(5, dim)  # Size of harmony memory\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.phi = 0.5  # Harmony memory consideration rate\n        self.beta = 1.0  # Parameter to control randomization\n        self.gamma = 0.5  # Parameter to control local search\n\n    def __call__(self, func):\n        # Initialize harmony memory with random solutions\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        eval_count = self.harmony_memory_size\n\n        while eval_count < self.budget:\n            # Generate a new harmony vector\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.phi:\n                    idx = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = self.harmony_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n                # Adjust new harmony using pitch adjustment\n                if np.random.rand() < self.gamma:\n                    self.beta = np.random.uniform(0.5, 1.5)  # Adaptive pitch adjustment\n                    new_harmony[i] += self.beta * (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n\n            # Ensure new harmony is within bounds\n            new_harmony = np.clip(new_harmony, lb, ub)\n\n            # Evaluate the new harmony\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            # Update harmony memory if the new solution is better\n            worst_idx = np.argmax(func_values)\n            if new_value < func_values[worst_idx]:\n                self.harmony_memory[worst_idx] = new_harmony\n                func_values[worst_idx] = new_value\n\n        # Return the best found solution and its value\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Introducing a novel adaptive pitch adjustment mechanism to enhance local search and exploitation capabilities in Adaptive Swarm Harmony Optimization.", "configspace": "", "generation": 2, "fitness": 0.8466097910904044, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.847 with standard deviation 0.020. And the mean value of best solutions found was 0.135 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "cec0df4f-27be-4720-a26d-797e5f08b76f", "metadata": {"aucs": [0.847697738840123, 0.8708577003441091, 0.8212739340869808], "final_y": [0.12977927666832456, 0.13053267276412628, 0.14364562715473728]}, "mutation_prompt": null}
{"id": "651a065a-8f9d-4b6f-92c0-0ddcecd85913", "solution": "import numpy as np\n\nclass QuantumInspiredGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20  # Population size for genetic algorithm\n        self.quantum_size = 10  # Quantum-inspired solutions\n        self.quantum_angle = np.pi / 6  # Quantum rotation angle\n        self.mutation_rate = 0.1  # Mutation rate\n        self.cross_prob = 0.7  # Crossover probability\n\n    def initialize_population(self, lb, ub):\n        classical_pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        quantum_pop = np.random.uniform(0, 1, (self.quantum_size, self.dim))\n        return classical_pop, quantum_pop\n\n    def quantum_to_classical(self, quantum_pop, lb, ub):\n        return lb + (ub - lb) * (np.sin(quantum_pop * self.quantum_angle) ** 2)\n\n    def evaluate_population(self, pop, func):\n        return np.array([func(ind) for ind in pop])\n\n    def select_parents(self, classical_pop, fitness):\n        idx = np.random.choice(range(self.population_size), size=2, replace=False, p=fitness / fitness.sum())\n        return classical_pop[idx]\n\n    def crossover(self, parents):\n        if np.random.rand() < self.cross_prob:\n            alpha = np.random.rand(self.dim)\n            return parents[0] * alpha + parents[1] * (1 - alpha)\n        else:\n            return parents[np.random.randint(0, 2)]\n\n    def mutate(self, individual, lb, ub):\n        if np.random.rand() < self.mutation_rate:\n            mutation_vector = np.random.uniform(-0.1, 0.1, self.dim)\n            mutated = individual + mutation_vector\n            return np.clip(mutated, lb, ub)\n        else:\n            return individual\n\n    def update_quantum_population(self, quantum_pop, best_individual, lb, ub):\n        classical_best = self.quantum_to_classical(quantum_pop, lb, ub)\n        best_index = np.argmin(np.array([np.linalg.norm(ind - best_individual) for ind in classical_best]))\n        quantum_pop[best_index] += np.random.normal(0, 0.1, self.dim)\n        self.quantum_angle = max(self.quantum_angle * 0.95, 0.1)  # Adaptive quantum angle adjustment\n        return np.clip(quantum_pop, 0, 1)\n\n    def resize_population(self, fitness, threshold=0.2):\n        if np.mean(fitness) < threshold:\n            self.population_size += 1\n        else:\n            self.population_size = max(self.population_size - 1, 10)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        classical_pop, quantum_pop = self.initialize_population(lb, ub)\n        evaluations = 0\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evaluations < self.budget:\n            classical_solutions = classical_pop\n            quantum_solutions = self.quantum_to_classical(quantum_pop, lb, ub)\n            total_population = np.vstack((classical_solutions, quantum_solutions))\n            fitness = self.evaluate_population(total_population, func)\n            evaluations += len(total_population)\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < best_fitness:\n                best_fitness = fitness[min_idx]\n                best_solution = total_population[min_idx]\n\n            classical_fitness = fitness[:self.population_size]\n            new_classical_pop = []\n            for _ in range(self.population_size):\n                parents = self.select_parents(classical_pop, classical_fitness)\n                offspring = self.crossover(parents)\n                offspring = self.mutate(offspring, lb, ub)\n                new_classical_pop.append(offspring)\n            classical_pop = np.array(new_classical_pop)\n\n            quantum_pop = self.update_quantum_population(quantum_pop, best_solution, lb, ub)\n            self.resize_population(classical_fitness)\n\n        return best_solution", "name": "QuantumInspiredGA", "description": "Improved Quantum-Inspired Genetic Algorithm featuring adaptive quantum angle adjustment and dynamic population resizing for enhanced convergence performance.", "configspace": "", "generation": 2, "fitness": 0.7584222912324373, "feedback": "The algorithm QuantumInspiredGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.758 with standard deviation 0.011. And the mean value of best solutions found was 0.173 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "f7a9f811-5fe9-4dca-a179-441250532841", "metadata": {"aucs": [0.7628998976191622, 0.7689349761758214, 0.7434319999023282], "final_y": [0.1712428377022921, 0.17022989611196415, 0.17808613861899003]}, "mutation_prompt": null}
{"id": "ce7c779b-3f42-43b4-b55c-4e965d9c0d2b", "solution": "import numpy as np\n\nclass QuantumInspiredGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.quantum_size = 10\n        self.quantum_angle = np.pi / 6\n        self.mutation_rate = 0.1 \n        self.cross_prob = 0.7\n\n    def initialize_population(self, lb, ub):\n        classical_pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        quantum_pop = np.random.uniform(0, 1, (self.quantum_size, self.dim))\n        return classical_pop, quantum_pop\n\n    def quantum_to_classical(self, quantum_pop, lb, ub):\n        return lb + (ub - lb) * (np.sin(quantum_pop * self.quantum_angle) ** 2)\n\n    def evaluate_population(self, pop, func):\n        return np.array([func(ind) for ind in pop])\n\n    def select_parents(self, classical_pop, fitness):\n        idx = np.random.choice(range(self.population_size), size=2, replace=False, p=fitness / fitness.sum())\n        return classical_pop[idx]\n\n    def crossover(self, parents):\n        alpha = np.random.rand(self.dim)\n        if np.random.rand() < self.cross_prob:\n            return parents[0] * alpha + parents[1] * (1 - alpha)\n        else:\n            return parents[np.random.randint(0, 2)]\n\n    def mutate(self, individual, lb, ub, best_fitness):\n        mutation_vector = np.random.uniform(-0.1, 0.1, self.dim)\n        adaptive_rate = self.mutation_rate + (1 - best_fitness) * 0.1\n        if np.random.rand() < adaptive_rate:\n            mutated = individual + mutation_vector\n            return np.clip(mutated, lb, ub)\n        else:\n            return individual\n\n    def update_quantum_population(self, quantum_pop, best_individual, lb, ub):\n        classical_best = self.quantum_to_classical(quantum_pop, lb, ub)\n        best_index = np.argmin(np.array([np.linalg.norm(ind - best_individual) for ind in classical_best]))\n        quantum_pop[best_index] += np.random.normal(0, 0.1, self.dim)\n        return np.clip(quantum_pop, 0, 1)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        classical_pop, quantum_pop = self.initialize_population(lb, ub)\n        evaluations = 0\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evaluations < self.budget:\n            classical_solutions = classical_pop\n            quantum_solutions = self.quantum_to_classical(quantum_pop, lb, ub)\n            total_population = np.vstack((classical_solutions, quantum_solutions))\n            fitness = self.evaluate_population(total_population, func)\n            evaluations += len(total_population)\n\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < best_fitness:\n                best_fitness = fitness[min_idx]\n                best_solution = total_population[min_idx]\n\n            classical_fitness = fitness[:self.population_size]\n            new_classical_pop = []\n            for _ in range(self.population_size):\n                parents = self.select_parents(classical_pop, classical_fitness)\n                offspring = self.crossover(parents)\n                self.cross_prob = 0.5 + 0.5 * np.random.rand() * (1 - best_fitness)\n                offspring = self.mutate(offspring, lb, ub, best_fitness)\n                new_classical_pop.append(offspring)\n            classical_pop = np.array(new_classical_pop)\n\n            quantum_pop = self.update_quantum_population(quantum_pop, best_solution, lb, ub)\n\n        return best_solution", "name": "QuantumInspiredGA", "description": "Enhanced Quantum-Inspired Genetic Algorithm by integrating adaptive mutation and dynamic crossover rate adjustments to improve convergence in complex search spaces.", "configspace": "", "generation": 2, "fitness": 0.7727408952168465, "feedback": "The algorithm QuantumInspiredGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.773 with standard deviation 0.014. And the mean value of best solutions found was 0.164 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "f7a9f811-5fe9-4dca-a179-441250532841", "metadata": {"aucs": [0.7910133369803574, 0.76890311738062, 0.7583062312895619], "final_y": [0.1490367512760049, 0.1702433386818767, 0.17406957122698596]}, "mutation_prompt": null}
{"id": "724de0d2-9173-4a25-a439-53aeb59391aa", "solution": "import numpy as np\n\nclass QuantumInspiredGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20  # Population size for genetic algorithm\n        self.quantum_size = 10  # Quantum-inspired solutions\n        self.quantum_angle = np.pi / 4  # Adjusted Quantum rotation angle\n        self.mutation_rate = 0.1  # Mutation rate\n        self.cross_prob = 0.7  # Crossover probability\n\n    def initialize_population(self, lb, ub):\n        # Initialize a classical population\n        classical_pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        # Initialize a quantum-inspired population\n        quantum_pop = np.random.uniform(0, 1, (self.quantum_size, self.dim))\n        return classical_pop, quantum_pop\n\n    def quantum_to_classical(self, quantum_pop, lb, ub):\n        # Convert quantum-inspired individuals to classical domain\n        return lb + (ub - lb) * (np.sin(quantum_pop * self.quantum_angle) ** 2)\n\n    def evaluate_population(self, pop, func):\n        return np.array([func(ind) for ind in pop])\n\n    def select_parents(self, classical_pop, fitness):\n        idx = np.random.choice(range(self.population_size), size=2, replace=False, p=fitness / fitness.sum())\n        return classical_pop[idx]\n\n    def crossover(self, parents):\n        if np.random.rand() < self.cross_prob:\n            alpha = np.random.rand(self.dim)\n            return parents[0] * alpha + parents[1] * (1 - alpha)\n        else:\n            return parents[np.random.randint(0, 2)]\n\n    def mutate(self, individual, lb, ub):\n        if np.random.rand() < self.mutation_rate:\n            mutation_vector = np.random.uniform(-0.1, 0.1, self.dim)\n            mutated = individual + mutation_vector\n            return np.clip(mutated, lb, ub)\n        else:\n            return individual\n\n    def update_quantum_population(self, quantum_pop, best_individual, lb, ub):\n        classical_best = self.quantum_to_classical(quantum_pop, lb, ub)\n        best_index = np.argmin(np.array([np.linalg.norm(ind - best_individual) for ind in classical_best]))\n        quantum_pop[best_index] += np.random.normal(0, 0.1, self.dim)\n        return np.clip(quantum_pop, 0, 1)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        classical_pop, quantum_pop = self.initialize_population(lb, ub)\n        evaluations = 0\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evaluations < self.budget:\n            # Convert and evaluate populations\n            classical_solutions = classical_pop\n            quantum_solutions = self.quantum_to_classical(quantum_pop, lb, ub)\n            total_population = np.vstack((classical_solutions, quantum_solutions))\n            fitness = self.evaluate_population(total_population, func)\n            evaluations += len(total_population)\n\n            # Find best solution\n            min_idx = np.argmin(fitness)\n            if fitness[min_idx] < best_fitness:\n                best_fitness = fitness[min_idx]\n                best_solution = total_population[min_idx]\n\n            # Genetic operations\n            classical_fitness = fitness[:self.population_size]\n            new_classical_pop = []\n            for _ in range(self.population_size):\n                parents = self.select_parents(classical_pop, classical_fitness)\n                offspring = self.crossover(parents)\n                offspring = self.mutate(offspring, lb, ub)\n                new_classical_pop.append(offspring)\n            classical_pop = np.array(new_classical_pop)\n\n            # Update quantum population\n            quantum_pop = self.update_quantum_population(quantum_pop, best_solution, lb, ub)\n\n        return best_solution", "name": "QuantumInspiredGA", "description": "Enhanced Quantum-Inspired Genetic Algorithm by optimizing quantum rotation angle to improve solution diversity and convergence.", "configspace": "", "generation": 2, "fitness": 0.7824574805338563, "feedback": "The algorithm QuantumInspiredGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.782 with standard deviation 0.054. And the mean value of best solutions found was 0.163 (0. is the best) with standard deviation 0.023.", "error": "", "parent_id": "f7a9f811-5fe9-4dca-a179-441250532841", "metadata": {"aucs": [0.7241933076906528, 0.76890311738062, 0.8542760165302963], "final_y": [0.18689362140392274, 0.1702433386818767, 0.13198077583255352]}, "mutation_prompt": null}
{"id": "85ee0a09-2067-4045-8fbb-5ad2a4362786", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx].copy()\n        best_fitness = fitness[best_idx]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Differential Evolution Mutation\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutation_factor = 0.5 + 0.3 * (np.random.rand() - 0.5)  # Dynamically adjust mutation factor\n                mutant = np.clip(population[a] + mutation_factor * (population[b] - population[c]), lb, ub)\n                \n                # Simulated Annealing Crossover\n                trial = np.where(np.random.rand(self.dim) < self.temperature, mutant, population[i])\n                \n                # Evaluate new candidate\n                trial_fitness = func(trial)\n                evaluations += 1\n                \n                # Selection with diversity preservation\n                if trial_fitness < fitness[i] or np.random.rand() < 0.1:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial.copy()\n                        best_fitness = trial_fitness\n            \n            # Cooling schedule for Simulated Annealing\n            self.temperature *= self.cooling_rate\n            # Adaptive population size adjustment\n            if self.temperature < 0.5:\n                self.population_size = min(int(self.population_size * 1.1), self.budget - evaluations)\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced exploration-exploitation balance by introducing adaptive population size and diversity preservation in the HybridMetaheuristic.", "configspace": "", "generation": 3, "fitness": 0.8018835424920084, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.802 with standard deviation 0.021. And the mean value of best solutions found was 0.135 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "0d9b8ff8-7513-4e54-a94f-8e6afca3960f", "metadata": {"aucs": [0.7806959671190277, 0.8303648027242672, 0.7945898576327306], "final_y": [0.13410990721545013, 0.1293555932820738, 0.14060228191367752]}, "mutation_prompt": null}
{"id": "c3caa3a3-1ad1-4969-836c-5755080bf7da", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 15 + 3 * dim  # Adaptive based on dimension for better exploration\n        self.harmony_memory_size = max(5, dim)  # Size of harmony memory\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.phi = 0.5  # Harmony memory consideration rate\n        self.beta = 1.0  # Parameter to control randomization\n        self.gamma = 0.5  # Parameter to control local search\n\n    def __call__(self, func):\n        # Initialize harmony memory with random solutions\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        eval_count = self.harmony_memory_size\n\n        while eval_count < self.budget:\n            # Generate a new harmony vector\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.phi:\n                    idx = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = self.harmony_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n                # Adjust new harmony using pitch adjustment\n                if np.random.rand() < self.gamma:\n                    new_harmony[i] += self.beta * (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n\n            # Ensure new harmony is within bounds\n            new_harmony = np.clip(new_harmony, lb, ub)\n\n            # Evaluate the new harmony\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            # Update harmony memory if the new solution is better\n            worst_idx = np.argmax(func_values)\n            if new_value < func_values[worst_idx]:\n                self.harmony_memory[worst_idx] = new_harmony\n                func_values[worst_idx] = new_value\n\n        # Return the best found solution and its value\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Enhanced the Adaptive Swarm Harmony Optimization by increasing the population size adaptively based on dimension for improved exploration-exploitation balance.", "configspace": "", "generation": 3, "fitness": 0.8248689288325242, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.825 with standard deviation 0.022. And the mean value of best solutions found was 0.139 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "cec0df4f-27be-4720-a26d-797e5f08b76f", "metadata": {"aucs": [0.8207926661834183, 0.800660655705658, 0.8531534646084962], "final_y": [0.13904031751707857, 0.1403223232339751, 0.1367057838710828]}, "mutation_prompt": null}
{"id": "bf1c15c7-7543-4c73-a41c-59fe0f2afff4", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx].copy()\n        best_fitness = fitness[best_idx]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Differential Evolution Mutation\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutation_factor = 0.5 + 0.3 * np.sin(np.random.rand() * np.pi)  # Use sinusoidal function for mutation factor\n                mutant = np.clip(population[a] + mutation_factor * (population[b] - population[c]), lb, ub)\n                \n                # Simulated Annealing Crossover\n                trial = np.where(np.random.rand(self.dim) < self.temperature, mutant, population[i])\n                \n                # Evaluate new candidate\n                trial_fitness = func(trial)\n                evaluations += 1\n                \n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial.copy()\n                        best_fitness = trial_fitness\n            \n            # Cooling schedule for Simulated Annealing\n            self.temperature *= self.cooling_rate\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced the mutation factor adaptation by utilizing a sinusoidal function to improve the balance between exploration and exploitation.", "configspace": "", "generation": 3, "fitness": 0.8071525767169835, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.807 with standard deviation 0.008. And the mean value of best solutions found was 0.141 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "0d9b8ff8-7513-4e54-a94f-8e6afca3960f", "metadata": {"aucs": [0.8181000441283575, 0.8037009625490595, 0.7996567234735339], "final_y": [0.1429824299393575, 0.14740817245687665, 0.134051769892521]}, "mutation_prompt": null}
{"id": "3981b810-3006-40cb-af93-ca07e5ae9e74", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.temperature = 1.0\n        self.cooling_rate = 0.98  # Modified line\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx].copy()\n        best_fitness = fitness[best_idx]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Differential Evolution Mutation\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutation_factor = 0.5 + 0.3 * (np.random.rand() - 0.5)  # Dynamically adjust mutation factor\n                mutant = np.clip(population[a] + mutation_factor * (population[b] - population[c]), lb, ub)\n                \n                # Simulated Annealing Crossover\n                trial = np.where(np.random.rand(self.dim) < self.temperature, mutant, population[i])\n                \n                # Evaluate new candidate\n                trial_fitness = func(trial)\n                evaluations += 1\n                \n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial.copy()\n                        best_fitness = trial_fitness\n            \n            # Cooling schedule for Simulated Annealing\n            self.temperature *= self.cooling_rate\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhance exploration-exploitation balance by introducing adaptive cooling schedule in HybridMetaheuristic.", "configspace": "", "generation": 3, "fitness": 0.8050479430131453, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.805 with standard deviation 0.022. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "0d9b8ff8-7513-4e54-a94f-8e6afca3960f", "metadata": {"aucs": [0.7750400818821719, 0.8249479113612235, 0.8151558357960407], "final_y": [0.15516157079144344, 0.144104204766209, 0.14382925025382343]}, "mutation_prompt": null}
{"id": "688ab52f-1290-424a-8768-45d2c61dc5ae", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim  # Adaptive based on dimension\n        self.harmony_memory_size = max(5, dim)  # Size of harmony memory\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.phi = 0.5  # Harmony memory consideration rate\n        self.beta = 1.0  # Parameter to control randomization\n        self.gamma = 0.5  # Parameter to control local search\n\n    def __call__(self, func):\n        # Initialize harmony memory with random solutions\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        eval_count = self.harmony_memory_size\n\n        while eval_count < self.budget:\n            # Generate a new harmony vector\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.phi:\n                    idx = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = self.harmony_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n                # Adjust new harmony using pitch adjustment\n                if np.random.rand() < self.gamma:\n                    self.beta = np.random.uniform(0.5, 1.5) * np.std(self.harmony_memory[:, i])  # Dynamic adaptive pitch adjustment\n                    new_harmony[i] += self.beta * (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n\n            # Ensure new harmony is within bounds\n            new_harmony = np.clip(new_harmony, lb, ub)\n\n            # Evaluate the new harmony\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            # Update harmony memory if the new solution is better\n            worst_idx = np.argmax(func_values)\n            if new_value < func_values[worst_idx]:\n                self.harmony_memory[worst_idx] = new_harmony\n                func_values[worst_idx] = new_value\n\n        # Return the best found solution and its value\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Enhanced adaptive pitch adjustment by introducing dynamic bounds based on current harmony variance to improve exploitation in Adaptive Swarm Harmony Optimization.", "configspace": "", "generation": 3, "fitness": 0.803196673211873, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.803 with standard deviation 0.017. And the mean value of best solutions found was 0.145 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "b31fd5c4-1f42-4dd8-b8b3-ae9757cf6077", "metadata": {"aucs": [0.780013685544489, 0.8181700313321192, 0.8114063027590106], "final_y": [0.1527999337679582, 0.14471339843068198, 0.13615205303117128]}, "mutation_prompt": null}
{"id": "cc941653-2f2c-4bb9-a40d-8f9ec12207bb", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx].copy()\n        best_fitness = fitness[best_idx]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Differential Evolution Mutation\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutation_factor = 0.5 + 0.3 * np.sin(np.random.rand() * np.pi)\n                mutant = np.clip(population[a] + mutation_factor * (population[b] - population[c]), lb, ub)\n                mutant += self._levy_flight()  # Levy Flight integration\n                \n                # Simulated Annealing Crossover\n                trial = np.where(np.random.rand(self.dim) < self.temperature, mutant, population[i])\n                \n                # Evaluate new candidate\n                trial_fitness = func(trial)\n                evaluations += 1\n                \n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial.copy()\n                        best_fitness = trial_fitness\n            \n            # Dynamic Cooling Schedule\n            self.temperature *= self.cooling_rate * (1 - evaluations / self.budget)\n        \n        return best_solution\n\n    def _levy_flight(self, beta=1.5):\n        sigma = (np.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.randn(self.dim) * sigma\n        v = np.random.randn(self.dim)\n        step = u / abs(v)**(1 / beta)\n        return step", "name": "HybridMetaheuristic", "description": "Enhanced HybridMetaheuristic's exploration capabilities by integrating a Levy flight mechanism and adjusting the cooling rate dynamically based on evaluation progression.", "configspace": "", "generation": 4, "fitness": -Infinity, "feedback": "An exception occurred: AttributeError(\"module 'numpy' has no attribute 'gamma'\").", "error": "AttributeError(\"module 'numpy' has no attribute 'gamma'\")", "parent_id": "bf1c15c7-7543-4c73-a41c-59fe0f2afff4", "metadata": {}, "mutation_prompt": null}
{"id": "f64518a0-ba76-4a68-a12a-b9617ff5610a", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_temperature = 1.0\n        self.cooling_rate = 0.95  # Adjusted cooling rate for slower convergence\n        self.temperature = self.initial_temperature\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx].copy()\n        best_fitness = fitness[best_idx]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Lévy flight Mutation\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                beta = 1.5  # Lévy flight exponent\n                scale = (np.random.rand(self.dim) ** (-1.0 / beta))\n                mutation_step = scale * (population[b] - population[c])\n                mutant = np.clip(population[a] + mutation_step, lb, ub)\n                \n                # Crossover with adaptive threshold\n                trial = np.where(np.random.rand(self.dim) < self.temperature, mutant, population[i])\n                \n                # Evaluate new candidate\n                trial_fitness = func(trial)\n                evaluations += 1\n                \n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial.copy()\n                        best_fitness = trial_fitness\n            \n            # Adaptive cooling based on improvement\n            self.temperature = self.initial_temperature * (0.99 ** (evaluations / self.population_size))\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced exploration and exploitation by introducing Lévy flight-based mutation and adaptive cooling in the HybridMetaheuristic framework.", "configspace": "", "generation": 4, "fitness": -Infinity, "feedback": "An exception occurred: AttributeError(\"module 'numpy' has no attribute 'gamma'\").", "error": "AttributeError(\"module 'numpy' has no attribute 'gamma'\")", "parent_id": "bf1c15c7-7543-4c73-a41c-59fe0f2afff4", "metadata": {}, "mutation_prompt": null}
{"id": "a57c75c4-2d0c-4a85-855b-59fd81b382ca", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx].copy()\n        best_fitness = fitness[best_idx]\n        \n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            # Differential Evolution Mutation\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutation_factor = 0.5 + 0.3 * (np.random.rand() - 0.5)  # Dynamically adjust mutation factor\n                mutant = np.clip(population[a] + mutation_factor * (population[b] - population[c]), lb, ub)\n                \n                # Simulated Annealing Crossover\n                trial = np.where(np.random.rand(self.dim) < self.temperature, mutant, population[i])\n                \n                # Evaluate new candidate\n                trial_fitness = func(trial)\n                evaluations += 1\n                \n                # Selection\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_solution = trial.copy()\n                        best_fitness = trial_fitness\n                        self.cooling_rate = 0.98  # Adapt cooling rate based on fitness improvement\n            \n            # Cooling schedule for Simulated Annealing\n            self.temperature *= self.cooling_rate\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced exploration by introducing a dynamic cooling schedule that adapts based on fitness improvements during optimization.", "configspace": "", "generation": 4, "fitness": -Infinity, "feedback": "An exception occurred: AttributeError(\"module 'numpy' has no attribute 'gamma'\").", "error": "AttributeError(\"module 'numpy' has no attribute 'gamma'\")", "parent_id": "0d9b8ff8-7513-4e54-a94f-8e6afca3960f", "metadata": {}, "mutation_prompt": null}
{"id": "2b91eff9-570d-4137-8a0d-a695c2e02525", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim  # Adaptive based on dimension\n        self.harmony_memory_size = max(5, dim)  # Size of harmony memory\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.phi = 0.5  # Harmony memory consideration rate\n        self.beta = 1.0  # Parameter to control randomization\n        self.gamma = 0.5  # Parameter to control local search\n\n    def __call__(self, func):\n        # Initialize harmony memory with random solutions\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        eval_count = self.harmony_memory_size\n\n        while eval_count < self.budget:\n            # Generate a new harmony vector\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.phi:\n                    idx = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = self.harmony_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n                # Adjust new harmony using pitch adjustment\n                if np.random.rand() < self.gamma:\n                    new_harmony[i] += self.beta * (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n\n            # Ensure new harmony is within bounds\n            new_harmony = np.clip(new_harmony, lb, ub)\n\n            # Evaluate the new harmony\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            # Update harmony memory if the new solution is better\n            worst_idx = np.argmax(func_values)\n            if new_value < func_values[worst_idx]:\n                self.harmony_memory[worst_idx] = new_harmony\n                func_values[worst_idx] = new_value\n                self.beta *= 0.95  # Adjust the beta parameter\n\n        # Return the best found solution and its value\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Introduced dynamic adaptation of pitch adjustment parameter `beta` based on the harmonic improvement to fine-tune exploration-exploitation balance.", "configspace": "", "generation": 4, "fitness": 0.8323971570660736, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.832 with standard deviation 0.010. And the mean value of best solutions found was 0.136 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "cec0df4f-27be-4720-a26d-797e5f08b76f", "metadata": {"aucs": [0.827810278039044, 0.8225939222369665, 0.8467872709222104], "final_y": [0.1369574602949576, 0.13541707298877503, 0.13661390293583175]}, "mutation_prompt": null}
{"id": "851e00f4-7cbb-4548-bd21-f42886aab149", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim  # Adaptive based on dimension\n        self.harmony_memory_size = max(5, dim)  # Size of harmony memory\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.phi = 0.5  # Harmony memory consideration rate\n        self.beta = 1.0  # Parameter to control randomization\n        self.gamma = 0.5  # Parameter to control local search\n\n    def __call__(self, func):\n        # Initialize harmony memory with random solutions\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        eval_count = self.harmony_memory_size\n\n        while eval_count < self.budget:\n            # Generate a new harmony vector\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.phi:\n                    idx = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = self.harmony_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n                # Adjust new harmony using pitch adjustment\n                if np.random.rand() < self.gamma:\n                    adaptive_beta = self.beta * (1 - eval_count / self.budget)\n                    new_harmony[i] += adaptive_beta * (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n\n            # Ensure new harmony is within bounds\n            new_harmony = np.clip(new_harmony, lb, ub)\n\n            # Evaluate the new harmony\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            # Update harmony memory if the new solution is better\n            worst_idx = np.argmax(func_values)\n            if new_value < func_values[worst_idx]:\n                self.harmony_memory[worst_idx] = new_harmony\n                func_values[worst_idx] = new_value\n\n        # Return the best found solution and its value\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Introduced adaptive pitch adjustment influenced by the iteration count to enhance the exploration-exploitation balance in Adaptive Swarm Harmony Optimization.", "configspace": "", "generation": 4, "fitness": 0.8341435426886399, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.834 with standard deviation 0.006. And the mean value of best solutions found was 0.135 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "cec0df4f-27be-4720-a26d-797e5f08b76f", "metadata": {"aucs": [0.8266025304733192, 0.8411640789930719, 0.8346640185995288], "final_y": [0.13636167879605143, 0.13296612912292416, 0.13420099117591744]}, "mutation_prompt": null}
{"id": "8a9300d7-2978-4b75-b193-2fa01758e1db", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim  # Adaptive based on dimension\n        self.harmony_memory_size = max(5, dim)  # Size of harmony memory\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.phi = 0.5  # Harmony memory consideration rate\n        self.beta = 1.0  # Parameter to control randomization\n        self.gamma = 0.5  # Parameter to control local search\n\n    def __call__(self, func):\n        # Initialize harmony memory with random solutions\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        eval_count = self.harmony_memory_size\n\n        while eval_count < self.budget:\n            # Generate a new harmony vector\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.phi:\n                    idx = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = self.harmony_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n                # Adjust new harmony using pitch adjustment\n                if np.random.rand() < self.gamma:\n                    new_harmony[i] += self.beta * (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n\n            # Ensure new harmony is within bounds\n            new_harmony = np.clip(new_harmony, lb, ub)\n\n            # Evaluate the new harmony\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            # Update harmony memory if the new solution is better\n            worst_idx = np.argmax(func_values)\n            if new_value < func_values[worst_idx]:\n                self.harmony_memory[worst_idx] = new_harmony\n                func_values[worst_idx] = new_value\n                self.beta *= 0.95 * (1 - eval_count/self.budget)  # Adjust the beta parameter\n\n        # Return the best found solution and its value\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Introduced dynamic adaptation of pitch adjustment parameter `beta` based on both harmonic improvement and function evaluation progress to fine-tune exploration-exploitation balance.", "configspace": "", "generation": 5, "fitness": 0.8293863366853295, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.829 with standard deviation 0.011. And the mean value of best solutions found was 0.142 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "2b91eff9-570d-4137-8a0d-a695c2e02525", "metadata": {"aucs": [0.8228348777989989, 0.8198630132720814, 0.8454611189849084], "final_y": [0.1417441818587598, 0.14706576241438096, 0.13862259969050184]}, "mutation_prompt": null}
{"id": "3be3f2e7-43db-4a20-9946-76f53041cf62", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim  # Adaptive based on dimension\n        self.harmony_memory_size = max(5, dim)  # Size of harmony memory\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.phi = 0.5  # Harmony memory consideration rate\n        self.beta = 1.0  # Parameter to control randomization\n        self.gamma = 0.5  # Parameter to control local search\n\n    def __call__(self, func):\n        # Initialize harmony memory with random solutions\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        eval_count = self.harmony_memory_size\n\n        while eval_count < self.budget:\n            # Generate a new harmony vector\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.phi:\n                    idx = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = self.harmony_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n                # Adjust new harmony using pitch adjustment\n                if np.random.rand() < self.gamma:\n                    self.beta = np.random.uniform(0.5, 1.5)  # Adaptive pitch adjustment\n                    new_harmony[i] += self.beta * (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n\n            # Ensure new harmony is within bounds\n            new_harmony = np.clip(new_harmony, lb, ub)\n\n            # Evaluate the new harmony\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            # Update harmony memory if the new solution is better\n            if new_value < np.median(func_values):  # Selective update\n                worst_idx = np.argmax(func_values)\n                if new_value < func_values[worst_idx]:\n                    self.harmony_memory[worst_idx] = new_harmony\n                    func_values[worst_idx] = new_value\n\n        # Return the best found solution and its value\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Introducing a selective harmony memory update mechanism to enhance the quality of solutions in Adaptive Swarm Harmony Optimization.", "configspace": "", "generation": 5, "fitness": 0.8196362068514739, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.820 with standard deviation 0.019. And the mean value of best solutions found was 0.142 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "b31fd5c4-1f42-4dd8-b8b3-ae9757cf6077", "metadata": {"aucs": [0.8157174384920793, 0.7984036028504823, 0.8447875792118601], "final_y": [0.13893701631132493, 0.14750706269671798, 0.1392384714589866]}, "mutation_prompt": null}
{"id": "90fbfaeb-3de9-4187-b128-bedddb86a1f9", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim  # Adaptive based on dimension\n        self.harmony_memory_size = max(5, dim)  # Size of harmony memory\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.phi = 0.5  # Harmony memory consideration rate\n        self.beta = 1.0  # Parameter to control randomization\n        self.gamma = 0.5  # Parameter to control local search\n\n    def __call__(self, func):\n        # Initialize harmony memory with random solutions\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        eval_count = self.harmony_memory_size\n\n        while eval_count < self.budget:\n            # Generate a new harmony vector\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                self.phi = np.random.uniform(0.3, 0.7)  # Adaptive harmony memory consideration rate\n                if np.random.rand() < self.phi:\n                    idx = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = self.harmony_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n                # Adjust new harmony using pitch adjustment\n                if np.random.rand() < self.gamma:\n                    self.beta = np.random.uniform(0.5, 1.5)  # Adaptive pitch adjustment\n                    new_harmony[i] += self.beta * (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n\n            # Ensure new harmony is within bounds\n            new_harmony = np.clip(new_harmony, lb, ub)\n\n            # Evaluate the new harmony\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            # Update harmony memory if the new solution is better\n            worst_idx = np.argmax(func_values)\n            if new_value < func_values[worst_idx]:\n                self.harmony_memory[worst_idx] = new_harmony\n                func_values[worst_idx] = new_value\n\n        # Return the best found solution and its value\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Enhanced exploration-exploitation balance with adaptive harmony memory consideration rate and mutation strategy in Adaptive Swarm Harmony Optimization.", "configspace": "", "generation": 5, "fitness": 0.8177835118646467, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.818 with standard deviation 0.003. And the mean value of best solutions found was 0.142 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "b31fd5c4-1f42-4dd8-b8b3-ae9757cf6077", "metadata": {"aucs": [0.8207958093708265, 0.819478507343172, 0.8130762188799416], "final_y": [0.13968282037947388, 0.14179663144021848, 0.1446296258504135]}, "mutation_prompt": null}
{"id": "f96f2d5b-9abf-4fcb-b8d4-ab605b133d7e", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 15 + 3 * dim  # Adaptive based on dimension for better exploration\n        self.harmony_memory_size = max(5, dim)  # Size of harmony memory\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.phi = 0.5  # Harmony memory consideration rate\n        self.beta = 1.0  # Parameter to control randomization\n        self.gamma = 0.5  # Parameter to control local search\n\n    def __call__(self, func):\n        # Initialize harmony memory with random solutions\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        eval_count = self.harmony_memory_size\n\n        while eval_count < self.budget:\n            # Update phi based on the iteration progress for better exploration-exploitation balance\n            self.phi = 0.5 + 0.5 * (eval_count / self.budget)\n\n            # Generate a new harmony vector\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.phi:\n                    idx = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = self.harmony_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n                # Adjust new harmony using pitch adjustment\n                if np.random.rand() < self.gamma:\n                    new_harmony[i] += self.beta * (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n\n            # Ensure new harmony is within bounds\n            new_harmony = np.clip(new_harmony, lb, ub)\n\n            # Evaluate the new harmony\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            # Update harmony memory if the new solution is better\n            worst_idx = np.argmax(func_values)\n            if new_value < func_values[worst_idx]:\n                self.harmony_memory[worst_idx] = new_harmony\n                func_values[worst_idx] = new_value\n\n        # Return the best found solution and its value\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Enhanced exploration-exploitation balance by dynamically varying the harmony memory consideration rate (`phi`) with iterations.", "configspace": "", "generation": 5, "fitness": 0.808033038734246, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.808 with standard deviation 0.006. And the mean value of best solutions found was 0.143 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "c3caa3a3-1ad1-4969-836c-5755080bf7da", "metadata": {"aucs": [0.8161815225985961, 0.8029634311203796, 0.8049541624837622], "final_y": [0.13631198588245907, 0.1452845673208384, 0.14665983321591392]}, "mutation_prompt": null}
{"id": "39bcea82-0bde-48cd-80d8-a1faee7c8d99", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 15 + 3 * dim\n        self.harmony_memory_size = max(5, dim)\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.phi = 0.5\n        self.beta = 1.0\n        self.gamma = 0.5\n        self.diversity_threshold = 0.1  # Diversity threshold for adaptive control\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        eval_count = self.harmony_memory_size\n\n        while eval_count < self.budget:\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.phi:\n                    idx = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = self.harmony_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n                if np.random.rand() < self.gamma:\n                    new_harmony[i] += self.beta * (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n\n            new_harmony = np.clip(new_harmony, lb, ub)\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            diversity = np.std(self.harmony_memory, axis=0).mean()\n            if diversity < self.diversity_threshold:\n                self.beta *= 1.1\n                self.gamma *= 0.9\n            else:\n                self.beta *= 0.9\n                self.gamma *= 1.1\n\n            worst_idx = np.argmax(func_values)\n            if new_value < func_values[worst_idx]:\n                self.harmony_memory[worst_idx] = new_harmony\n                func_values[worst_idx] = new_value\n\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Enhanced exploration and exploitation by introducing diversity-based adaptive parameter control in Adaptive Swarm Harmony Optimization.", "configspace": "", "generation": 5, "fitness": 0.8341213811279505, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.834 with standard deviation 0.026. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "c3caa3a3-1ad1-4969-836c-5755080bf7da", "metadata": {"aucs": [0.8711508235531691, 0.8188077220648673, 0.8124055977658153], "final_y": [0.12468574350805461, 0.12524325085603383, 0.14416181284091956]}, "mutation_prompt": null}
{"id": "c3444421-08ba-4c6a-8da3-3d2b0a584159", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim  # Adaptive based on dimension\n        self.harmony_memory_size = max(5, dim)  # Size of harmony memory\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.phi = 0.5  # Harmony memory consideration rate\n        self.beta = 1.0  # Parameter to control randomization\n        self.gamma = 0.5  # Parameter to control local search\n\n    def __call__(self, func):\n        # Initialize harmony memory with random solutions\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        eval_count = self.harmony_memory_size\n\n        while eval_count < self.budget:\n            # Generate a new harmony vector\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                dynamic_phi = self.phi * (1 - eval_count / self.budget)  # Dynamic adjustment\n                if np.random.rand() < dynamic_phi:\n                    idx = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = self.harmony_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n                # Adjust new harmony using pitch adjustment\n                if np.random.rand() < self.gamma:\n                    adaptive_beta = self.beta * (1 - eval_count / self.budget)\n                    new_harmony[i] += adaptive_beta * (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n\n            # Ensure new harmony is within bounds\n            new_harmony = np.clip(new_harmony, lb, ub)\n\n            # Evaluate the new harmony\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            # Update harmony memory if the new solution is better\n            worst_idx = np.argmax(func_values)\n            if new_value < func_values[worst_idx]:\n                self.harmony_memory[worst_idx] = new_harmony\n                func_values[worst_idx] = new_value\n\n        # Return the best found solution and its value\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Enhanced adaptive pitch adjustment by dynamically modifying the harmony memory consideration rate based on evaluation progress in Adaptive Swarm Harmony Optimization.", "configspace": "", "generation": 6, "fitness": 0.8335303890265662, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.834 with standard deviation 0.019. And the mean value of best solutions found was 0.135 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "851e00f4-7cbb-4548-bd21-f42886aab149", "metadata": {"aucs": [0.8141372410625662, 0.8276948263856228, 0.8587590996315094], "final_y": [0.14470449552618725, 0.13365077626226474, 0.12667989921598388]}, "mutation_prompt": null}
{"id": "5b883c6e-fc1e-4db0-9128-9aa57fe25d6c", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim  # Adaptive based on dimension\n        self.harmony_memory_size = max(5, dim)  # Size of harmony memory\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.phi = 0.5  # Harmony memory consideration rate\n        self.beta = 1.0  # Parameter to control randomization\n        self.gamma = 0.5  # Parameter to control local search\n\n    def __call__(self, func):\n        # Initialize harmony memory with random solutions\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        eval_count = self.harmony_memory_size\n\n        while eval_count < self.budget:\n            # Generate a new harmony vector\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.phi:\n                    idx = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = self.harmony_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n                # Adjust new harmony using pitch adjustment\n                if np.random.rand() < self.gamma * (1 - eval_count / self.budget):  # Adaptive gamma\n                    new_harmony[i] += self.beta * (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n\n            # Ensure new harmony is within bounds\n            new_harmony = np.clip(new_harmony, lb, ub)\n\n            # Evaluate the new harmony\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            # Update harmony memory if the new solution is better\n            worst_idx = np.argmax(func_values)\n            if new_value < func_values[worst_idx]:\n                self.harmony_memory[worst_idx] = new_harmony\n                func_values[worst_idx] = new_value\n                self.beta *= 0.95  # Adjust the beta parameter\n\n        # Return the best found solution and its value\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Introduced adaptive scaling of `gamma` based on function evaluation progress for fine-tuned exploration-exploitation balance.", "configspace": "", "generation": 6, "fitness": 0.8555326053321936, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.856 with standard deviation 0.015. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "2b91eff9-570d-4137-8a0d-a695c2e02525", "metadata": {"aucs": [0.8336931744209903, 0.8651860503970282, 0.8677185911785622], "final_y": [0.13942472688641494, 0.12148438684690821, 0.12272191530310206]}, "mutation_prompt": null}
{"id": "91a00faa-48eb-4a7d-8464-dff587909f8c", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim  # Adaptive based on dimension\n        self.harmony_memory_size = max(5, dim)  # Size of harmony memory\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.phi = 0.5  # Harmony memory consideration rate\n        self.beta = 1.0  # Parameter to control randomization\n        self.gamma = 0.5  # Parameter to control local search\n\n    def __call__(self, func):\n        # Initialize harmony memory with random solutions\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        eval_count = self.harmony_memory_size\n\n        while eval_count < self.budget:\n            # Generate a new harmony vector\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.phi:\n                    idx = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = self.harmony_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n                # Adjust new harmony using pitch adjustment\n                if np.random.rand() < self.gamma:\n                    self.beta = np.random.uniform(0.5, 1.5)  # Adaptive pitch adjustment\n                    new_harmony[i] += self.beta * (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n\n            # Ensure new harmony is within bounds\n            new_harmony = np.clip(new_harmony, lb, ub)\n\n            # Evaluate the new harmony\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            # Update harmony memory if the new solution is better\n            worst_idx = np.argmax(func_values)\n            if new_value < func_values[worst_idx]:\n                self.harmony_memory[worst_idx] = new_harmony\n                func_values[worst_idx] = new_value\n                self.phi = min(1.0, self.phi + 0.01)  # Increase phi\n\n        # Return the best found solution and its value\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Introduced an adaptive memory consideration rate `phi` influenced by successful harmonies to dynamically balance exploration and exploitation in Adaptive Swarm Harmony Optimization.", "configspace": "", "generation": 6, "fitness": 0.8502735280066137, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.850 with standard deviation 0.007. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "b31fd5c4-1f42-4dd8-b8b3-ae9757cf6077", "metadata": {"aucs": [0.850915543459577, 0.8418377778941253, 0.8580672626661392], "final_y": [0.1220517464050046, 0.13178186482117993, 0.1269540356013571]}, "mutation_prompt": null}
{"id": "713d9d53-dc6f-4052-9d66-2556b8795328", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim  # Adaptive based on dimension\n        self.harmony_memory_size = max(5, dim)  # Size of harmony memory\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.phi = 0.5  # Harmony memory consideration rate\n        self.beta = 1.0  # Parameter to control randomization\n        self.gamma = 0.5  # Parameter to control local search\n\n    def __call__(self, func):\n        # Initialize harmony memory with random solutions\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        eval_count = self.harmony_memory_size\n\n        while eval_count < self.budget:\n            # Generate a new harmony vector\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                # Introduced a nonlinear decay for phi\n                self.phi = 0.5 * (1 - (eval_count / self.budget)**2)\n                if np.random.rand() < self.phi:\n                    idx = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = self.harmony_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n                # Adjust new harmony using pitch adjustment\n                if np.random.rand() < self.gamma:\n                    self.beta = np.random.uniform(0.5, 1.5)  # Adaptive pitch adjustment\n                    new_harmony[i] += self.beta * (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n\n            # Ensure new harmony is within bounds\n            new_harmony = np.clip(new_harmony, lb, ub)\n\n            # Evaluate the new harmony\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            # Update harmony memory if the new solution is better\n            worst_idx = np.argmax(func_values)\n            if new_value < func_values[worst_idx]:\n                self.harmony_memory[worst_idx] = new_harmony\n                func_values[worst_idx] = new_value\n\n        # Return the best found solution and its value\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Introduced a nonlinear decay strategy for the harmony memory consideration rate `phi` to balance exploration and exploitation dynamically.", "configspace": "", "generation": 6, "fitness": 0.8402277007763344, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.840 with standard deviation 0.036. And the mean value of best solutions found was 0.136 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "b31fd5c4-1f42-4dd8-b8b3-ae9757cf6077", "metadata": {"aucs": [0.8128925224816379, 0.8171549901931661, 0.890635589654199], "final_y": [0.15022933845387765, 0.13579610328493852, 0.12066994698589961]}, "mutation_prompt": null}
{"id": "2db0c335-9845-4032-9725-dd0629322d37", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim  # Adaptive based on dimension\n        self.harmony_memory_size = max(5, dim)  # Size of harmony memory\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.phi = 0.5  # Harmony memory consideration rate\n        self.beta = 1.0  # Parameter to control randomization\n        self.gamma = 0.5  # Parameter to control local search\n\n    def __call__(self, func):\n        # Initialize harmony memory with random solutions\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        eval_count = self.harmony_memory_size\n\n        while eval_count < self.budget:\n            # Generate a new harmony vector\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                self.phi = 0.4 + 0.2 * (eval_count / self.budget)  # Dynamic adjustment of phi\n                if np.random.rand() < self.phi:\n                    idx = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = self.harmony_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n                # Adjust new harmony using pitch adjustment\n                if np.random.rand() < self.gamma:\n                    self.beta = np.random.uniform(0.5, 1.5)  # Adaptive pitch adjustment\n                    new_harmony[i] += self.beta * (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n\n            # Ensure new harmony is within bounds\n            new_harmony = np.clip(new_harmony, lb, ub)\n\n            # Evaluate the new harmony\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            # Update harmony memory if the new solution is better\n            worst_idx = np.argmax(func_values)\n            if new_value < func_values[worst_idx]:\n                self.harmony_memory[worst_idx] = new_harmony\n                func_values[worst_idx] = new_value\n\n        # Return the best found solution and its value\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Introducing a dynamic adjustment for the harmony memory consideration rate (`phi`) to balance exploration and exploitation in Adaptive Swarm Harmony Optimization.", "configspace": "", "generation": 6, "fitness": 0.8297092817257267, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.830 with standard deviation 0.024. And the mean value of best solutions found was 0.134 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "b31fd5c4-1f42-4dd8-b8b3-ae9757cf6077", "metadata": {"aucs": [0.7988915541204691, 0.8315978781091422, 0.8586384129475689], "final_y": [0.14518425085297637, 0.1270643552963835, 0.1301204921029696]}, "mutation_prompt": null}
{"id": "2bf775ab-7e06-476a-9751-1df485e75195", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim  # Adaptive based on dimension\n        self.harmony_memory_size = max(5, dim)  # Size of harmony memory\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.phi = 0.5  # Harmony memory consideration rate\n        self.beta = 1.0  # Parameter to control randomization\n        self.gamma = 0.5  # Parameter to control local search\n\n    def __call__(self, func):\n        # Initialize harmony memory with random solutions\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        eval_count = self.harmony_memory_size\n\n        while eval_count < self.budget:\n            # Generate a new harmony vector\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.phi:\n                    idx = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = self.harmony_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n                # Adjust new harmony using pitch adjustment\n                if np.random.rand() < self.gamma * (1 - eval_count / self.budget):  # Adaptive gamma\n                    new_harmony[i] += self.beta * (1 - eval_count / self.budget) * (ub[i] - lb[i]) * (np.random.rand() - 0.5)  # Changed line\n\n            # Ensure new harmony is within bounds\n            new_harmony = np.clip(new_harmony, lb, ub)\n\n            # Evaluate the new harmony\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            # Update harmony memory if the new solution is better\n            worst_idx = np.argmax(func_values)\n            if new_value < func_values[worst_idx]:\n                self.harmony_memory[worst_idx] = new_harmony\n                func_values[worst_idx] = new_value\n                self.beta *= 0.95  # Adjust the beta parameter\n\n        # Return the best found solution and its value\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Enhanced local search by dynamically updating `beta` based on the number of function evaluations to improve convergence.", "configspace": "", "generation": 7, "fitness": 0.8749801448066687, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.875 with standard deviation 0.019. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "5b883c6e-fc1e-4db0-9128-9aa57fe25d6c", "metadata": {"aucs": [0.855707918614504, 0.8683237863465678, 0.9009087294589346], "final_y": [0.12851218842879264, 0.12838930864187692, 0.11975389977169237]}, "mutation_prompt": null}
{"id": "77945ac2-5492-4dd9-a573-1d63fd86d352", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim  # Adaptive based on dimension\n        self.harmony_memory_size = max(5, dim)  # Size of harmony memory\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.phi = 0.5  # Harmony memory consideration rate\n        self.beta = 1.0  # Parameter to control randomization\n        self.gamma = 0.5  # Parameter to control local search\n\n    def __call__(self, func):\n        # Initialize harmony memory with random solutions\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        eval_count = self.harmony_memory_size\n\n        while eval_count < self.budget:\n            # Generate a new harmony vector\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                # Introduced a nonlinear decay for phi\n                self.phi = 0.5 * (1 - (eval_count / self.budget)**2)\n                if np.random.rand() < self.phi:\n                    idx = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = self.harmony_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n                # Adjust new harmony using pitch adjustment\n                self.gamma = 0.5 * (1 - (eval_count / self.budget)**2)  # Adaptive gamma decay\n                if np.random.rand() < self.gamma:\n                    self.beta = np.random.uniform(0.5, 1.5)  # Adaptive pitch adjustment\n                    new_harmony[i] += self.beta * (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n\n            # Ensure new harmony is within bounds\n            new_harmony = np.clip(new_harmony, lb, ub)\n\n            # Evaluate the new harmony\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            # Update harmony memory if the new solution is better\n            worst_idx = np.argmax(func_values)\n            if new_value < func_values[worst_idx]:\n                self.harmony_memory[worst_idx] = new_harmony\n                func_values[worst_idx] = new_value\n\n        # Return the best found solution and its value\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Introduced adaptive gamma decay based on evaluation progress to enhance the local search capability dynamically.", "configspace": "", "generation": 7, "fitness": 0.8669721631735445, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.867 with standard deviation 0.041. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "713d9d53-dc6f-4052-9d66-2556b8795328", "metadata": {"aucs": [0.8096505843996766, 0.8979358471730683, 0.8933300579478887], "final_y": [0.14303028150442232, 0.11737677505816113, 0.1204185332330201]}, "mutation_prompt": null}
{"id": "bb6f5eea-2810-4a26-9b07-9141e4ae339a", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim  # Adaptive based on dimension\n        self.harmony_memory_size = max(5, dim)  # Size of harmony memory\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.phi = 0.5  # Harmony memory consideration rate\n        self.beta = 1.0  # Parameter to control randomization\n        self.gamma = 0.5  # Parameter to control local search\n\n    def __call__(self, func):\n        # Initialize harmony memory with random solutions\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        eval_count = self.harmony_memory_size\n\n        while eval_count < self.budget:\n            # Generate a new harmony vector\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.phi:\n                    idx = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = self.harmony_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n                # Adjust new harmony using pitch adjustment\n                if np.random.rand() < self.gamma:\n                    self.beta = np.random.uniform(0.5, 1.5)  # Adaptive pitch adjustment\n                    new_harmony[i] += self.beta * (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n\n            # Ensure new harmony is within bounds\n            new_harmony = np.clip(new_harmony, lb, ub)\n\n            # Evaluate the new harmony\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            # Update harmony memory if the new solution is better\n            worst_idx = np.argmax(func_values)\n            if new_value < func_values[worst_idx]:\n                self.harmony_memory[worst_idx] = new_harmony\n                func_values[worst_idx] = new_value\n                self.phi = min(1.0, self.phi + 0.005)  # Adjusted phi increment\n\n        # Return the best found solution and its value\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Refined the adaptive memory consideration rate `phi` update mechanism to enhance exploration-exploitation balance in Adaptive Swarm Harmony Optimization.", "configspace": "", "generation": 7, "fitness": 0.8617175455261449, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.862 with standard deviation 0.024. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "91a00faa-48eb-4a7d-8464-dff587909f8c", "metadata": {"aucs": [0.8279110214282306, 0.8778879058387307, 0.8793537093114735], "final_y": [0.13780541112422395, 0.1261461763191184, 0.12914991428596634]}, "mutation_prompt": null}
{"id": "f5698e46-afc9-48a0-868d-720a25779eef", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim  # Adaptive based on dimension\n        self.harmony_memory_size = max(5, dim)  # Size of harmony memory\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.phi = 0.5  # Harmony memory consideration rate\n        self.beta = 1.0  # Parameter to control randomization\n        self.gamma = 0.5  # Parameter to control local search\n\n    def __call__(self, func):\n        # Initialize harmony memory with random solutions\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        eval_count = self.harmony_memory_size\n\n        while eval_count < self.budget:\n            # Generate a new harmony vector\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.phi:\n                    idx = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = self.harmony_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n                # Adjust new harmony using pitch adjustment\n                if np.random.rand() < self.gamma:\n                    self.beta = np.random.uniform(0.5, 1.5)  # Adaptive pitch adjustment\n                    new_harmony[i] += self.beta * (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n\n            # Ensure new harmony is within bounds\n            new_harmony = np.clip(new_harmony, lb, ub)\n\n            # Evaluate the new harmony\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            # Update harmony memory if the new solution is better\n            worst_idx = np.argmax(func_values)\n            if new_value < func_values[worst_idx]:\n                self.harmony_memory[worst_idx] = new_harmony\n                func_values[worst_idx] = new_value\n                self.phi = min(1.0, self.phi + 0.01)  # Increase phi\n\n            self.gamma *= 0.99  # Decay strategy for gamma\n\n        # Return the best found solution and its value\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Enhanced Adaptive Swarm Harmony Optimization by introducing a dynamic harmony memory size and a decay strategy for gamma to improve convergence.", "configspace": "", "generation": 7, "fitness": 0.8818430683308643, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.882 with standard deviation 0.004. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "91a00faa-48eb-4a7d-8464-dff587909f8c", "metadata": {"aucs": [0.8855942867910651, 0.8767518377700342, 0.8831830804314938], "final_y": [0.12172597331838131, 0.12398206134539203, 0.12234416119251945]}, "mutation_prompt": null}
{"id": "93cd048f-a4a6-4d4c-a2fd-98a84a5850c3", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim  # Adaptive based on dimension\n        self.harmony_memory_size = max(5, dim)  # Size of harmony memory\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.phi = 0.5  # Harmony memory consideration rate\n        self.beta = 1.0  # Parameter to control randomization\n        self.gamma = 0.5  # Parameter to control local search\n\n    def __call__(self, func):\n        # Initialize harmony memory with random solutions\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        eval_count = self.harmony_memory_size\n\n        while eval_count < self.budget:\n            # Generate a new harmony vector\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                # Introduced a nonlinear decay for phi\n                self.phi = 0.5 * (1 - (eval_count / self.budget)**2)\n                if np.random.rand() < self.phi:\n                    idx = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = self.harmony_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n                # Adjust new harmony using pitch adjustment\n                # Dynamic adjustment for gamma\n                self.gamma = 0.5 * (1 - (eval_count / self.budget)**0.5)\n                if np.random.rand() < self.gamma:\n                    self.beta = np.random.uniform(0.5, 1.5)  # Adaptive pitch adjustment\n                    new_harmony[i] += self.beta * (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n\n            # Ensure new harmony is within bounds\n            new_harmony = np.clip(new_harmony, lb, ub)\n\n            # Evaluate the new harmony\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            # Update harmony memory if the new solution is better\n            worst_idx = np.argmax(func_values)\n            if new_value < func_values[worst_idx]:\n                self.harmony_memory[worst_idx] = new_harmony\n                func_values[worst_idx] = new_value\n\n        # Return the best found solution and its value\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Introduced a dynamic adjustment of `gamma` based on the evaluation progress to enhance local search in Adaptive Swarm Harmony Optimization.", "configspace": "", "generation": 7, "fitness": 0.855682512205774, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.856 with standard deviation 0.025. And the mean value of best solutions found was 0.132 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "713d9d53-dc6f-4052-9d66-2556b8795328", "metadata": {"aucs": [0.8240854451555775, 0.8859516994424836, 0.8570103920192607], "final_y": [0.13892407084439207, 0.12271893783331156, 0.13393474238716463]}, "mutation_prompt": null}
{"id": "2eabfcff-7a2d-40ff-8ceb-220ee4496263", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(10 + 2 * dim * (1 + (budget / 100)**0.1))  # Non-linear increase\n        self.harmony_memory_size = max(5, dim)\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.phi = 0.5\n        self.beta = 1.0\n        self.gamma = 0.5\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        eval_count = self.harmony_memory_size\n\n        while eval_count < self.budget:\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                self.phi = 0.5 * (1 - (eval_count / self.budget)**2)\n                if np.random.rand() < self.phi:\n                    idx = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = self.harmony_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n                self.gamma = 0.5 * (1 - (eval_count / self.budget)**0.5)\n                if np.random.rand() < self.gamma:\n                    self.beta = np.random.uniform(0.5, 1.5) * (1 + (eval_count / self.budget)**0.3)  # Dynamic learning rate\n                    new_harmony[i] += self.beta * (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n\n            new_harmony = np.clip(new_harmony, lb, ub)\n\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(func_values)\n            if new_value < func_values[worst_idx]:\n                self.harmony_memory[worst_idx] = new_harmony\n                func_values[worst_idx] = new_value\n\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Improved Adaptive Swarm Harmony Optimization by introducing a non-linear increase of the population size and dynamic adaptive learning rates for better exploration and faster convergence.", "configspace": "", "generation": 8, "fitness": 0.854765694359104, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.855 with standard deviation 0.013. And the mean value of best solutions found was 0.132 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "93cd048f-a4a6-4d4c-a2fd-98a84a5850c3", "metadata": {"aucs": [0.841790570936927, 0.8505687599262386, 0.8719377522141463], "final_y": [0.13942924207144747, 0.1326401711910986, 0.12305741394741643]}, "mutation_prompt": null}
{"id": "baef7ce0-0428-4d87-96d7-c821d4ddc94c", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim  # Adaptive based on dimension\n        self.harmony_memory_size = max(5, dim)  # Size of harmony memory\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.phi = 0.5  # Harmony memory consideration rate\n        self.beta = 1.0  # Parameter to control randomization\n        self.gamma = 0.5  # Parameter to control local search\n\n    def __call__(self, func):\n        # Initialize harmony memory with random solutions\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        eval_count = self.harmony_memory_size\n\n        while eval_count < self.budget:\n            # Generate a new harmony vector\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.phi * (1 - eval_count / self.budget):  # Adjusted line\n                    idx = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = self.harmony_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n                # Adjust new harmony using pitch adjustment\n                if np.random.rand() < self.gamma * (1 - eval_count / self.budget):  # Adaptive gamma\n                    new_harmony[i] += self.beta * (1 - eval_count / self.budget) * (ub[i] - lb[i]) * (np.random.rand() - 0.5)  # Changed line\n\n            # Ensure new harmony is within bounds\n            new_harmony = np.clip(new_harmony, lb, ub)\n\n            # Evaluate the new harmony\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            # Update harmony memory if the new solution is better\n            worst_idx = np.argmax(func_values)\n            if new_value < func_values[worst_idx]:\n                self.harmony_memory[worst_idx] = new_harmony\n                func_values[worst_idx] = new_value\n                self.beta *= 0.95  # Adjust the beta parameter\n\n        # Return the best found solution and its value\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Improved the exploration-exploitation balance by introducing a decay factor for both `phi` and `gamma` over the iterations.", "configspace": "", "generation": 8, "fitness": 0.8457862278811419, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.846 with standard deviation 0.018. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "2bf775ab-7e06-476a-9751-1df485e75195", "metadata": {"aucs": [0.8277144171780283, 0.8387310511789262, 0.870913215286471], "final_y": [0.13919011738808185, 0.13588894557514297, 0.12435759269219138]}, "mutation_prompt": null}
{"id": "1cf08042-5b9f-432f-96d9-9ff6f9ac6f3b", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim  # Adaptive based on dimension\n        self.harmony_memory_size = max(5, dim)  # Size of harmony memory\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.phi = 0.5  # Harmony memory consideration rate\n        self.beta = 1.0  # Parameter to control randomization\n        self.gamma = 0.5  # Parameter to control local search\n\n    def __call__(self, func):\n        # Initialize harmony memory with random solutions\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        eval_count = self.harmony_memory_size\n\n        while eval_count < self.budget:\n            # Generate a new harmony vector\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                # Introduced a nonlinear decay for phi\n                self.phi = 0.5 * (1 - (eval_count / self.budget)**2)\n                if np.random.rand() < self.phi:\n                    idx = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = self.harmony_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n                # Adjust new harmony using pitch adjustment\n                # Dynamic adjustment for gamma\n                self.gamma = 0.5 * (1 - (eval_count / self.budget)**0.5)\n                if np.random.rand() < self.gamma:\n                    # Dynamic adjustment for beta\n                    self.beta = np.random.uniform(0.5, 1.5) * (1 - (eval_count / self.budget)**0.5)\n                    new_harmony[i] += self.beta * (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n\n            # Ensure new harmony is within bounds\n            new_harmony = np.clip(new_harmony, lb, ub)\n\n            # Evaluate the new harmony\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            # Update harmony memory if the new solution is better\n            worst_idx = np.argmax(func_values)\n            if new_value < func_values[worst_idx]:\n                self.harmony_memory[worst_idx] = new_harmony\n                func_values[worst_idx] = new_value\n\n        # Return the best found solution and its value\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Introduced a dynamic adjustment of `beta` based on the evaluation progress to improve exploration-exploitation balance.", "configspace": "", "generation": 8, "fitness": 0.8521773810559652, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.852 with standard deviation 0.004. And the mean value of best solutions found was 0.130 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "93cd048f-a4a6-4d4c-a2fd-98a84a5850c3", "metadata": {"aucs": [0.8468468126644126, 0.8537354668723124, 0.8559498636311704], "final_y": [0.134697569043001, 0.12544242237335712, 0.13011447444695523]}, "mutation_prompt": null}
{"id": "d27749f7-1ac8-402f-a7ba-f2a6c6936ed3", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim\n        self.harmony_memory_size = max(5, dim)\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.secondary_memory_size = max(3, dim // 2)  # Additional secondary memory\n        self.secondary_memory = np.random.rand(self.secondary_memory_size, dim)\n        self.phi = 0.5\n        self.beta = 1.0\n        self.gamma = 0.5\n        self.dynamic_adaptation_rate = 0.005  # New parameter for adaptive phi\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        self.secondary_memory = lb + (ub - lb) * np.random.rand(self.secondary_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        secondary_values = np.array([func(sm) for sm in self.secondary_memory])\n        eval_count = self.harmony_memory_size + self.secondary_memory_size\n\n        while eval_count < self.budget:\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.phi:\n                    if np.random.rand() < 0.5:  # Use dual memory approach\n                        idx = np.random.randint(self.harmony_memory_size)\n                        new_harmony[i] = self.harmony_memory[idx, i]\n                    else:\n                        idx = np.random.randint(self.secondary_memory_size)\n                        new_harmony[i] = self.secondary_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n                if np.random.rand() < self.gamma:\n                    self.beta = np.random.uniform(0.5, 1.5)\n                    new_harmony[i] += self.beta * (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n\n            new_harmony = np.clip(new_harmony, lb, ub)\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            if new_value < max(func_values.max(), secondary_values.max()):  # Compare with both memories\n                if new_value < func_values.max():\n                    worst_idx = np.argmax(func_values)\n                    self.harmony_memory[worst_idx] = new_harmony\n                    func_values[worst_idx] = new_value\n                else:\n                    worst_idx = np.argmax(secondary_values)\n                    self.secondary_memory[worst_idx] = new_harmony\n                    secondary_values[worst_idx] = new_value\n\n                self.phi = min(1.0, self.phi + self.dynamic_adaptation_rate)\n\n            self.gamma *= 0.99\n\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Improved Adaptive Swarm Harmony Optimization by implementing dual memory strategy and adaptive memory consideration, enhancing exploration and exploitation balance.", "configspace": "", "generation": 8, "fitness": 0.8728240448182004, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.873 with standard deviation 0.010. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "f5698e46-afc9-48a0-868d-720a25779eef", "metadata": {"aucs": [0.8692694660140374, 0.8623343070450953, 0.8868683613954688], "final_y": [0.1268037402913631, 0.12822794966093032, 0.12125869008806323]}, "mutation_prompt": null}
{"id": "31347753-e6f8-4ba1-aade-9c9935a81d6c", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim  # Adaptive based on dimension\n        self.harmony_memory_size = max(5, dim)  # Size of harmony memory\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.phi = 0.5  # Harmony memory consideration rate\n        self.beta = 1.0  # Parameter to control randomization\n        self.gamma = 0.5  # Parameter to control local search\n\n    def __call__(self, func):\n        # Initialize harmony memory with random solutions\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        eval_count = self.harmony_memory_size\n\n        while eval_count < self.budget:\n            # Generate a new harmony vector\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.phi * (1 - eval_count / self.budget):  # Adjusted line\n                    idx = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = self.harmony_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n                # Adjust new harmony using pitch adjustment\n                if np.random.rand() < self.gamma * (1 - eval_count / self.budget):  # Adaptive gamma\n                    new_harmony[i] += self.beta * (1 - eval_count / self.budget) * (ub[i] - lb[i]) * (np.random.rand() - 0.5)  # Changed line\n\n            # Ensure new harmony is within bounds\n            new_harmony = np.clip(new_harmony, lb, ub)\n\n            # Evaluate the new harmony\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            # Update harmony memory if the new solution is better\n            worst_idx = np.argmax(func_values)\n            if new_value < func_values[worst_idx]:\n                self.harmony_memory[worst_idx] = new_harmony\n                func_values[worst_idx] = new_value\n                self.beta *= 0.95  # Adjust the beta parameter\n\n        # Return the best found solution and its value\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Improved convergence by introducing a dynamic adjustment of the harmony memory consideration rate `phi` based on the evaluation progress.", "configspace": "", "generation": 8, "fitness": 0.8582446453018427, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.858 with standard deviation 0.007. And the mean value of best solutions found was 0.130 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "2bf775ab-7e06-476a-9751-1df485e75195", "metadata": {"aucs": [0.8480481650189393, 0.8642906893066856, 0.8623950815799036], "final_y": [0.13762660115182934, 0.12564081674129457, 0.12787335584727721]}, "mutation_prompt": null}
{"id": "ccfb53ca-565e-45d0-a35f-b902d2ec85b7", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim\n        self.harmony_memory_size = max(5, dim)\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.phi = 0.5\n        self.beta = 1.0\n        self.gamma = 0.5\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        eval_count = self.harmony_memory_size\n\n        while eval_count < self.budget:\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.phi * (1 - eval_count / self.budget):  # Adaptive phi\n                    idx = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = self.harmony_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n                if np.random.rand() < self.gamma * (1 - eval_count / self.budget):\n                    new_harmony[i] += self.beta * (1 - eval_count / self.budget) * (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n\n                if np.random.rand() < 0.1:  # Mutation strategy\n                    new_harmony[i] += 0.1 * (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n\n            new_harmony = np.clip(new_harmony, lb, ub)\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(func_values)\n            if new_value < func_values[worst_idx]:\n                self.harmony_memory[worst_idx] = new_harmony\n                func_values[worst_idx] = new_value\n                self.beta *= 0.95\n\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Improved exploration by adaptive adjustment of `phi` and integrated a mutation strategy to enhance diversity.", "configspace": "", "generation": 9, "fitness": 0.8181584437661961, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.818 with standard deviation 0.011. And the mean value of best solutions found was 0.144 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "2bf775ab-7e06-476a-9751-1df485e75195", "metadata": {"aucs": [0.802750480017268, 0.8260921706187994, 0.8256326806625208], "final_y": [0.14933854710760608, 0.1396651166930012, 0.14375520578710543]}, "mutation_prompt": null}
{"id": "1a78f020-9cf7-4f49-8bca-d87428717224", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim  # Adaptive based on dimension\n        self.harmony_memory_size = max(5, dim)  # Size of harmony memory\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.phi = 0.5  # Harmony memory consideration rate\n        self.beta = 1.0  # Parameter to control randomization\n        self.gamma = 0.5  # Parameter to control local search\n\n    def __call__(self, func):\n        # Initialize harmony memory with random solutions\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        eval_count = self.harmony_memory_size\n\n        while eval_count < self.budget:\n            # Generate a new harmony vector\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.phi * (1 - eval_count / self.budget):  # Adaptive phi\n                    idx = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = self.harmony_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n                # Adjust new harmony using pitch adjustment\n                if np.random.rand() < self.gamma * (1 - eval_count / self.budget):  # Adaptive gamma\n                    new_harmony[i] += self.beta * (1 - eval_count / self.budget) * (ub[i] - lb[i]) * (np.random.rand() - 0.5)  # Changed line\n\n            # Ensure new harmony is within bounds\n            new_harmony = np.clip(new_harmony, lb, ub)\n\n            # Evaluate the new harmony\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            # Update harmony memory if the new solution is better\n            worst_idx = np.argmax(func_values)\n            if new_value < func_values[worst_idx]:\n                self.harmony_memory[worst_idx] = new_harmony\n                func_values[worst_idx] = new_value\n                self.beta *= 0.95  # Adjust the beta parameter\n\n        # Return the best found solution and its value\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Enhanced exploration by introducing an adaptive phi which decreases as evaluations progress, improving balance.", "configspace": "", "generation": 9, "fitness": 0.8316365369857892, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.832 with standard deviation 0.020. And the mean value of best solutions found was 0.142 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "2bf775ab-7e06-476a-9751-1df485e75195", "metadata": {"aucs": [0.8549621747755072, 0.8071961134657615, 0.8327513227160989], "final_y": [0.1320541286614041, 0.1515588335222844, 0.1427485610096746]}, "mutation_prompt": null}
{"id": "e532e733-b140-4713-9184-b363321f03bf", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim  # Adaptive based on dimension\n        self.harmony_memory_size = max(5, dim)  # Size of harmony memory\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.phi = 0.5  # Harmony memory consideration rate\n        self.beta = 1.0  # Parameter to control randomization\n        self.gamma = 0.5  # Parameter to control local search\n\n    def __call__(self, func):\n        # Initialize harmony memory with random solutions\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        eval_count = self.harmony_memory_size\n\n        while eval_count < self.budget:\n            # Generate a new harmony vector\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.phi * (1 - eval_count / self.budget):  # Adaptive phi\n                    idx = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = self.harmony_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n                # Adjust new harmony using pitch adjustment\n                if np.random.rand() < self.gamma * (1 - eval_count / self.budget):  # Adaptive gamma\n                    new_harmony[i] += self.beta * (1 - eval_count / self.budget) * (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n\n            # Ensure new harmony is within bounds\n            new_harmony = np.clip(new_harmony, lb, ub)\n\n            # Evaluate the new harmony\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            # Update harmony memory if the new solution is better\n            worst_idx = np.argmax(func_values)\n            if new_value < func_values[worst_idx]:\n                self.harmony_memory[worst_idx] = new_harmony\n                func_values[worst_idx] = new_value\n                self.beta *= 0.95  # Adjust the beta parameter\n\n        # Return the best found solution and its value\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Enhanced exploration-exploitation balance by incorporating a dynamic adjustment to the harmony memory consideration rate `phi` based on the number of function evaluations.", "configspace": "", "generation": 9, "fitness": 0.823087778808851, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.823 with standard deviation 0.009. And the mean value of best solutions found was 0.142 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "2bf775ab-7e06-476a-9751-1df485e75195", "metadata": {"aucs": [0.8277588986854473, 0.830825093996084, 0.8106793437450218], "final_y": [0.13311463593428696, 0.14384448637636815, 0.1495258804679256]}, "mutation_prompt": null}
{"id": "66870fa9-072b-400d-9ea4-595d754b4bdf", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim  # Adaptive based on dimension\n        self.harmony_memory_size = max(5, dim)  # Size of harmony memory\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.phi = 0.5  # Harmony memory consideration rate\n        self.beta = 1.0  # Parameter to control randomization\n        self.gamma = 0.5  # Parameter to control local search\n\n    def __call__(self, func):\n        # Initialize harmony memory with random solutions\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        eval_count = self.harmony_memory_size\n\n        while eval_count < self.budget:\n            # Generate a new harmony vector\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.phi:\n                    idx = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = self.harmony_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n                # Adjust new harmony using pitch adjustment\n                if np.random.rand() < self.gamma:\n                    self.beta = np.random.uniform(0.5, 1.5)  # Adaptive pitch adjustment\n                    new_harmony[i] += self.beta * (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n\n            # Ensure new harmony is within bounds\n            new_harmony = np.clip(new_harmony, lb, ub)\n\n            # Evaluate the new harmony\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            # Update harmony memory if the new solution is better\n            worst_idx = np.argmax(func_values)\n            if new_value < func_values[worst_idx]:\n                self.harmony_memory[worst_idx] = new_harmony\n                func_values[worst_idx] = new_value\n                self.phi = min(1.0, self.phi + 0.01)  # Increase phi\n                self.beta = min(2.0, self.beta + 0.1)  # Dynamic beta adjustment\n\n            self.gamma *= 0.99  # Decay strategy for gamma\n\n        # Return the best found solution and its value\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Enhanced Adaptive Swarm Harmony Optimization by introducing a dynamic beta adjustment based on function value improvements to accelerate convergence.", "configspace": "", "generation": 9, "fitness": 0.8296954279765063, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.830 with standard deviation 0.042. And the mean value of best solutions found was 0.139 (0. is the best) with standard deviation 0.015.", "error": "", "parent_id": "f5698e46-afc9-48a0-868d-720a25779eef", "metadata": {"aucs": [0.8897592334157655, 0.8002496214232232, 0.7990774290905303], "final_y": [0.11864024342082824, 0.1446656422472994, 0.15285571085457972]}, "mutation_prompt": null}
{"id": "5e79086b-0b96-4707-b470-cad5c5222c41", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim  # Adaptive based on dimension\n        self.harmony_memory_size = max(5, dim)  # Size of harmony memory\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.phi = 0.5  # Harmony memory consideration rate\n        self.beta = 1.0  # Parameter to control randomization\n        self.gamma = 0.5  # Parameter to control local search\n\n    def __call__(self, func):\n        # Initialize harmony memory with random solutions\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        eval_count = self.harmony_memory_size\n        best_value = np.min(func_values)\n\n        while eval_count < self.budget:\n            # Generate a new harmony vector\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.phi:\n                    idx = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = self.harmony_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n                # Adjust new harmony using pitch adjustment\n                if np.random.rand() < self.gamma:\n                    self.beta = np.random.uniform(0.5, 1.5)  # Adaptive pitch adjustment\n                    new_harmony[i] += self.beta * (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n\n            # Ensure new harmony is within bounds\n            new_harmony = np.clip(new_harmony, lb, ub)\n\n            # Evaluate the new harmony\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            # Update harmony memory if the new solution is better\n            worst_idx = np.argmax(func_values)\n            if new_value < func_values[worst_idx]:\n                self.harmony_memory[worst_idx] = new_harmony\n                func_values[worst_idx] = new_value\n                self.phi = min(1.0, self.phi + 0.005)  # Adjusted phi increment\n\n            # Dynamically adjust gamma based on improvement\n            if new_value < best_value:\n                best_value = new_value\n                self.gamma = min(1.0, self.gamma + 0.01)\n\n        # Return the best found solution and its value\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Enhanced Adaptive Swarm Harmony Optimization by implementing a dynamic `gamma` rate based on the improvement of solutions to enhance local search adaptation.", "configspace": "", "generation": 9, "fitness": 0.8323579427818387, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.832 with standard deviation 0.005. And the mean value of best solutions found was 0.137 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "bb6f5eea-2810-4a26-9b07-9141e4ae339a", "metadata": {"aucs": [0.8347924616843247, 0.8368865023384503, 0.8253948643227412], "final_y": [0.13006139034863873, 0.13616459462887842, 0.1442053802525497]}, "mutation_prompt": null}
{"id": "10fff79d-9711-4d97-9e1e-3305b512bf73", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim  # Adaptive based on dimension\n        self.harmony_memory_size = max(5, dim)  # Size of harmony memory\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.phi = 0.5  # Harmony memory consideration rate\n        self.beta = 1.0  # Parameter to control randomization\n        self.gamma = 0.5  # Parameter to control local search\n\n    def __call__(self, func):\n        # Initialize harmony memory with random solutions\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        eval_count = self.harmony_memory_size\n\n        while eval_count < self.budget:\n            # Generate a new harmony vector\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.phi:\n                    idx = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = self.harmony_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n                # Adjust new harmony using pitch adjustment\n                if np.random.rand() < self.gamma * (1 - eval_count / self.budget):  # Adaptive gamma\n                    new_harmony[i] += self.beta * (1 - eval_count / self.budget) * (ub[i] - lb[i]) * (np.random.rand() - 0.5)  # Changed line\n\n            # Ensure new harmony is within bounds\n            new_harmony = np.clip(new_harmony, lb, ub)\n\n            # Evaluate the new harmony\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            # Update harmony memory if the new solution is better\n            worst_idx = np.argmax(func_values)\n            if new_value < func_values[worst_idx]:\n                self.harmony_memory[worst_idx] = new_harmony\n                func_values[worst_idx] = new_value\n                self.beta *= 0.95 * np.random.uniform(0.95, 1.05)  # Adjusting beta with stochastic variance\n\n        # Return the best found solution and its value\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Improved exploration-exploitation balance by introducing stochastic variance in beta adjustment, allowing more diverse search behavior.", "configspace": "", "generation": 10, "fitness": 0.8541452367250523, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.854 with standard deviation 0.012. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "2bf775ab-7e06-476a-9751-1df485e75195", "metadata": {"aucs": [0.850707456534566, 0.8410475267754041, 0.8706807268651867], "final_y": [0.13640115767267758, 0.1358422321964725, 0.12642384410947438]}, "mutation_prompt": null}
{"id": "0c0e1c9f-51b7-4fe1-95eb-f00b84996086", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim  # Adaptive based on dimension\n        self.harmony_memory_size = max(5, dim)  # Size of harmony memory\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.phi = 0.5  # Harmony memory consideration rate\n        self.beta = 1.0  # Parameter to control randomization\n        self.gamma = 0.5  # Parameter to control local search\n\n    def __call__(self, func):\n        # Initialize harmony memory with random solutions\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        eval_count = self.harmony_memory_size\n\n        while eval_count < self.budget:\n            # Generate a new harmony vector\n            new_harmony = np.zeros(self.dim)\n            self.phi = 0.9 * (1 - eval_count / self.budget)  # Adjusting phi\n            \n            for i in range(self.dim):\n                if np.random.rand() < self.phi:\n                    idx = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = self.harmony_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n                # Adjust new harmony using pitch adjustment\n                if np.random.rand() < self.gamma * (1 - eval_count / self.budget):  # Adaptive gamma\n                    new_harmony[i] += self.beta * (1 - eval_count / self.budget) * (ub[i] - lb[i]) * (np.random.rand() - 0.5)  # Changed line\n\n            # Ensure new harmony is within bounds\n            new_harmony = np.clip(new_harmony, lb, ub)\n\n            # Evaluate the new harmony\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            # Update harmony memory if the new solution is better\n            worst_idx = np.argmax(func_values)\n            if new_value < func_values[worst_idx]:\n                self.harmony_memory[worst_idx] = new_harmony\n                func_values[worst_idx] = new_value\n                self.beta *= 0.95  # Adjust the beta parameter\n\n        # Return the best found solution and its value\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Enhanced exploration by dynamically adjusting the phi parameter based on evaluation progress to improve convergence.", "configspace": "", "generation": 10, "fitness": 0.8611435073144716, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.861 with standard deviation 0.020. And the mean value of best solutions found was 0.129 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "2bf775ab-7e06-476a-9751-1df485e75195", "metadata": {"aucs": [0.8715533499155977, 0.8327648648431443, 0.8791123071846729], "final_y": [0.1250497765421924, 0.1403055093698896, 0.12307689022497492]}, "mutation_prompt": null}
{"id": "47fbbcce-b260-4e94-b353-b664ba018f48", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim  # Adaptive based on dimension\n        self.harmony_memory_size = max(5, dim)  # Size of harmony memory\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.phi = 0.5  # Harmony memory consideration rate\n        self.beta = 1.0  # Parameter to control randomization\n        self.gamma = 0.5  # Parameter to control local search\n\n    def __call__(self, func):\n        # Initialize harmony memory with random solutions\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        eval_count = self.harmony_memory_size\n\n        while eval_count < self.budget:\n            # Generate a new harmony vector\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                # Introduced a nonlinear decay for phi\n                self.phi = 0.5 * (1 - (eval_count / self.budget)**2)\n                if np.random.rand() < self.phi:\n                    idx = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = self.harmony_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n                # Adjust new harmony using pitch adjustment\n                self.gamma = 0.5 * (1 - (eval_count / self.budget)**2)  # Adaptive gamma decay\n                if np.random.rand() < self.gamma:\n                    self.beta = np.random.uniform(0.5, 2.0)  # Adaptive pitch adjustment, range increased\n                    new_harmony[i] += self.beta * (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n\n            # Ensure new harmony is within bounds\n            new_harmony = np.clip(new_harmony, lb, ub)\n\n            # Evaluate the new harmony\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            # Update harmony memory if the new solution is better\n            worst_idx = np.argmax(func_values)\n            if new_value < func_values[worst_idx]:\n                self.harmony_memory[worst_idx] = new_harmony\n                func_values[worst_idx] = new_value\n\n        # Return the best found solution and its value\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Improved the exploration phase by scaling the pitch adjustment range based on current performance, enhancing adaptability.", "configspace": "", "generation": 10, "fitness": 0.8410428160225626, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.841 with standard deviation 0.023. And the mean value of best solutions found was 0.135 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "77945ac2-5492-4dd9-a573-1d63fd86d352", "metadata": {"aucs": [0.8084388854095663, 0.8525402783024735, 0.862149284355648], "final_y": [0.14808647017063659, 0.13106588208946846, 0.12671725735633255]}, "mutation_prompt": null}
{"id": "c3a0717a-d6da-4401-9e16-96102b1fb94a", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim\n        self.harmony_memory_size = max(5, dim)\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.secondary_memory_size = max(3, dim // 2)  # Additional secondary memory\n        self.secondary_memory = np.random.rand(self.secondary_memory_size, dim)\n        self.phi = 0.5\n        self.beta = 1.0\n        self.gamma = 0.5\n        self.dynamic_adaptation_rate = 0.005  # New parameter for adaptive phi\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        self.secondary_memory = lb + (ub - lb) * np.random.rand(self.secondary_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        secondary_values = np.array([func(sm) for sm in self.secondary_memory])\n        eval_count = self.harmony_memory_size + self.secondary_memory_size\n\n        while eval_count < self.budget:\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.phi:\n                    if np.random.rand() < 0.5:  # Use dual memory approach\n                        idx = np.random.randint(self.harmony_memory_size)\n                        new_harmony[i] = self.harmony_memory[idx, i]\n                    else:\n                        idx = np.random.randint(self.secondary_memory_size)\n                        new_harmony[i] = self.secondary_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n                if np.random.rand() < self.gamma:\n                    self.beta = np.random.uniform(0.5, 1.5)\n                    new_harmony[i] += self.beta * (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n\n            new_harmony = np.clip(new_harmony, lb, ub)\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            if new_value < max(func_values.max(), secondary_values.max()):  # Compare with both memories\n                if new_value < func_values.max():\n                    worst_idx = np.argmax(func_values)\n                    self.harmony_memory[worst_idx] = new_harmony\n                    func_values[worst_idx] = new_value\n                else:\n                    worst_idx = np.argmax(secondary_values)\n                    self.secondary_memory[worst_idx] = new_harmony\n                    secondary_values[worst_idx] = new_value\n\n                self.phi = min(1.0, self.phi + self.dynamic_adaptation_rate)\n\n            self.gamma *= 0.99\n            # Resize memory if needed\n            if eval_count % (self.budget // 10) == 0:\n                self.harmony_memory_size = max(5, int(self.harmony_memory_size * 0.9))\n                self.secondary_memory_size = max(3, int(self.secondary_memory_size * 1.1))\n\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Introduced dynamic memory resizing based on convergence to improve exploration and exploitation balance.", "configspace": "", "generation": 10, "fitness": 0.8514729315932238, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.851 with standard deviation 0.006. And the mean value of best solutions found was 0.132 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "d27749f7-1ac8-402f-a7ba-f2a6c6936ed3", "metadata": {"aucs": [0.8468603090580782, 0.8605672376790934, 0.8469912480424998], "final_y": [0.13238056939670417, 0.12782351075453846, 0.13449530241835905]}, "mutation_prompt": null}
{"id": "6f87b3ee-6352-45a4-8cec-c26ba8931eb1", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim  # Adaptive based on dimension\n        self.harmony_memory_size = max(5, dim)  # Size of harmony memory\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.phi = 0.5  # Harmony memory consideration rate\n        self.beta = 1.0  # Parameter to control randomization\n        self.gamma = 0.5  # Parameter to control local search\n\n    def __call__(self, func):\n        # Initialize harmony memory with random solutions\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        eval_count = self.harmony_memory_size\n\n        while eval_count < self.budget:\n            # Generate a new harmony vector\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.phi:\n                    idx = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = self.harmony_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n                # Adjust new harmony using pitch adjustment\n                if np.random.rand() < self.gamma:\n                    self.beta = np.random.uniform(0.5, 1.5)  # Adaptive pitch adjustment\n                    new_harmony[i] += self.beta * (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n\n            # Ensure new harmony is within bounds\n            new_harmony = np.clip(new_harmony, lb, ub)\n\n            # Evaluate the new harmony\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            # Update harmony memory if the new solution is better\n            worst_idx = np.argmax(func_values)\n            if new_value < func_values[worst_idx]:\n                self.harmony_memory[worst_idx] = new_harmony\n                func_values[worst_idx] = new_value\n                self.phi = min(1.0, self.phi + 0.01)  # Increase phi\n\n            self.gamma *= 0.99  # Decay strategy for gamma\n            self.population_size = min(self.population_size + 1, self.budget - eval_count)  # Dynamic adjustment\n\n        # Return the best found solution and its value\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Enhanced diversity by introducing a dynamic population size adjustment based on convergence progress.", "configspace": "", "generation": 10, "fitness": 0.8709342026673964, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.871 with standard deviation 0.011. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "f5698e46-afc9-48a0-868d-720a25779eef", "metadata": {"aucs": [0.8858965187136505, 0.860394794057362, 0.8665112952311768], "final_y": [0.12231291988317095, 0.1276710422032249, 0.13087233462116354]}, "mutation_prompt": null}
{"id": "416d4422-9b5b-48ab-88f7-d281b8ec0cf8", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim  # Adaptive based on dimension\n        self.harmony_memory_size = max(5, dim)  # Size of harmony memory\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.phi = 0.8 - dim * 0.01  # Adaptive consideration rate based on dimension\n        self.beta = 1.0  # Parameter to control randomization\n        self.gamma = 0.5  # Parameter to control local search\n\n    def __call__(self, func):\n        # Initialize harmony memory with random solutions\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        eval_count = self.harmony_memory_size\n\n        while eval_count < self.budget:\n            # Generate a new harmony vector\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.phi:\n                    idx = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = self.harmony_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n                # Adjust new harmony using pitch adjustment\n                dynamic_gamma = self.gamma * (1 - eval_count / (2 * self.budget))  # Adjusted gamma\n                if np.random.rand() < dynamic_gamma:  # Adaptive gamma\n                    new_harmony[i] += self.beta * (1 - eval_count / self.budget) * (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n\n            # Ensure new harmony is within bounds\n            new_harmony = np.clip(new_harmony, lb, ub)\n\n            # Evaluate the new harmony\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            # Update harmony memory if the new solution is better\n            worst_idx = np.argmax(func_values)\n            if new_value < func_values[worst_idx]:\n                self.harmony_memory[worst_idx] = new_harmony\n                func_values[worst_idx] = new_value\n                self.beta *= 0.95  # Adjust the beta parameter\n\n        # Return the best found solution and its value\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Improve convergence by incorporating an adaptive harmony memory consideration rate and a position-based gamma adjustment.", "configspace": "", "generation": 11, "fitness": 0.8292424200673026, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.829 with standard deviation 0.031. And the mean value of best solutions found was 0.142 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "2bf775ab-7e06-476a-9751-1df485e75195", "metadata": {"aucs": [0.8631769731360961, 0.7874814722373848, 0.8370688148284272], "final_y": [0.12540045806806532, 0.15798162358259882, 0.14374872771581815]}, "mutation_prompt": null}
{"id": "20e24472-3634-4057-9249-e711277e98c3", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim  # Adaptive based on dimension\n        self.harmony_memory_size = max(5, dim)  # Size of harmony memory\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.phi = 0.5  # Harmony memory consideration rate\n        self.beta = 1.0  # Parameter to control randomization\n        self.gamma = 0.5  # Parameter to control local search\n\n    def __call__(self, func):\n        # Initialize harmony memory with random solutions\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        eval_count = self.harmony_memory_size\n\n        while eval_count < self.budget:\n            # Generate a new harmony vector\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.phi:\n                    idx = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = self.harmony_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n                # Adjust new harmony using pitch adjustment\n                if np.random.rand() < self.gamma:\n                    self.beta = np.random.uniform(0.5, 1.5)  # Adaptive pitch adjustment\n                    new_harmony[i] += self.beta * (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n\n            # Ensure new harmony is within bounds\n            new_harmony = np.clip(new_harmony, lb, ub)\n\n            # Evaluate the new harmony\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            # Update harmony memory if the new solution is better\n            worst_idx = np.argmax(func_values)\n            if new_value < func_values[worst_idx]:\n                self.harmony_memory[worst_idx] = new_harmony\n                func_values[worst_idx] = new_value\n                self.phi = min(1.0, self.phi + np.random.uniform(0.005, 0.02))  # Increase phi with randomness\n\n            self.gamma *= 0.99  # Decay strategy for gamma\n            self.population_size = min(self.population_size + 1, self.budget - eval_count)  # Dynamic adjustment\n\n        # Return the best found solution and its value\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Enhanced exploration by introducing randomness to `phi` for better diversity in solutions.", "configspace": "", "generation": 11, "fitness": 0.8326598533396181, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.833 with standard deviation 0.027. And the mean value of best solutions found was 0.140 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "6f87b3ee-6352-45a4-8cec-c26ba8931eb1", "metadata": {"aucs": [0.8700372249140889, 0.8225977220668672, 0.8053446130378982], "final_y": [0.127584374356282, 0.13928358556486875, 0.15231320305730223]}, "mutation_prompt": null}
{"id": "5b55595f-09de-49de-8880-db5e6ed3ccdc", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim\n        self.harmony_memory_size = max(5, dim)\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.secondary_memory_size = max(3, dim // 2)\n        self.secondary_memory = np.random.rand(self.secondary_memory_size, dim)\n        self.phi = 0.5\n        self.beta = 1.0\n        self.gamma = 0.5\n        self.dynamic_adaptation_rate = 0.005\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        self.secondary_memory = lb + (ub - lb) * np.random.rand(self.secondary_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        secondary_values = np.array([func(sm) for sm in self.secondary_memory])\n        eval_count = self.harmony_memory_size + self.secondary_memory_size\n\n        while eval_count < self.budget:\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.phi:\n                    idx = np.random.randint(self.harmony_memory_size + self.secondary_memory_size)\n                    if idx < self.harmony_memory_size:\n                        new_harmony[i] = self.harmony_memory[idx, i]\n                    else:\n                        new_harmony[i] = self.secondary_memory[idx - self.harmony_memory_size, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n                if np.random.rand() < self.gamma:\n                    self.beta = np.random.uniform(0.5, 1.5)\n                    new_harmony[i] += self.beta * (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n\n            new_harmony = np.clip(new_harmony, lb, ub)\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            if new_value < func_values.max():\n                worst_idx = np.argmax(func_values)\n                self.harmony_memory[worst_idx] = new_harmony\n                func_values[worst_idx] = new_value\n\n            elif new_value < secondary_values.max():\n                worst_idx = np.argmax(secondary_values)\n                self.secondary_memory[worst_idx] = new_harmony\n                secondary_values[worst_idx] = new_value\n\n            self.phi = min(1.0, self.phi + self.dynamic_adaptation_rate)\n            self.gamma *= 0.98\n\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Improved Adaptive Swarm Harmony Optimization by introducing progressive memory consideration and adaptive mutation, enhancing convergence speed and solution quality.", "configspace": "", "generation": 11, "fitness": 0.8201990561686512, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.820 with standard deviation 0.034. And the mean value of best solutions found was 0.145 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "d27749f7-1ac8-402f-a7ba-f2a6c6936ed3", "metadata": {"aucs": [0.868486670073774, 0.7913040823587427, 0.8008064160734367], "final_y": [0.12840281531309172, 0.1558826337221142, 0.15130543435228616]}, "mutation_prompt": null}
{"id": "b045cde9-e929-4303-834c-c01ed9b9c02e", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim  # Adaptive based on dimension\n        self.harmony_memory_size = max(5, dim)  # Size of harmony memory\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.phi = 0.5  # Harmony memory consideration rate\n        self.beta = 1.0  # Parameter to control randomization\n        self.gamma = 0.5  # Parameter to control local search\n\n    def __call__(self, func):\n        # Initialize harmony memory with random solutions\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        eval_count = self.harmony_memory_size\n\n        while eval_count < self.budget:\n            # Generate a new harmony vector\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.phi:\n                    idx = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = self.harmony_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n                # Adjust new harmony using pitch adjustment\n                if np.random.rand() < self.gamma:\n                    self.beta = np.random.uniform(0.3, 1.7)  # Adaptive pitch adjustment\n                    new_harmony[i] += self.beta * (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n\n            # Ensure new harmony is within bounds\n            new_harmony = np.clip(new_harmony, lb, ub)\n\n            # Evaluate the new harmony\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            # Update harmony memory if the new solution is better\n            worst_idx = np.argmax(func_values)\n            if new_value < func_values[worst_idx]:\n                self.harmony_memory[worst_idx] = new_harmony\n                func_values[worst_idx] = new_value\n                self.phi = min(1.0, self.phi + 0.02)  # Increase phi faster\n\n            self.gamma *= 0.98  # Slightly faster decay for gamma\n            self.population_size = min(self.population_size + 1, self.budget - eval_count)  # Dynamic adjustment\n\n        # Return the best found solution and its value\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Improved the balance between exploration and exploitation by introducing an adaptive beta strategy and fine-tuning the harmony memory consideration rate and decay strategy.", "configspace": "", "generation": 11, "fitness": 0.8104626443122941, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.810 with standard deviation 0.010. And the mean value of best solutions found was 0.146 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "6f87b3ee-6352-45a4-8cec-c26ba8931eb1", "metadata": {"aucs": [0.8149634048731736, 0.7970871842687031, 0.8193373437950057], "final_y": [0.14856804825407632, 0.14136480958811382, 0.14849133542917925]}, "mutation_prompt": null}
{"id": "fb612407-4848-416a-b798-43a873c28ee4", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim  # Adaptive based on dimension\n        self.harmony_memory_size = max(5, dim)  # Size of harmony memory\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.phi = 0.5  # Harmony memory consideration rate\n        self.beta = 1.0  # Parameter to control randomization\n        self.gamma = 0.5  # Parameter to control local search\n\n    def __call__(self, func):\n        # Initialize harmony memory with random solutions\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        eval_count = self.harmony_memory_size\n\n        while eval_count < self.budget:\n            # Generate a new harmony vector\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.phi:\n                    idx = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = self.harmony_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n                # Adjust new harmony using pitch adjustment\n                if np.random.rand() < self.gamma:\n                    self.beta = np.random.uniform(0.5, 1.5)  # Adaptive pitch adjustment\n                    new_harmony[i] += self.beta * (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n\n            # Ensure new harmony is within bounds\n            new_harmony = np.clip(new_harmony, lb, ub)\n\n            # Evaluate the new harmony\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            # Update harmony memory if the new solution is better\n            worst_idx = np.argmax(func_values)\n            if new_value < func_values[worst_idx]:\n                self.harmony_memory[worst_idx] = new_harmony\n                func_values[worst_idx] = new_value\n                self.phi = min(1.0, self.phi + 0.01)  # Increase phi\n\n            self.phi *= 0.99  # Decay strategy for phi\n            self.population_size = min(self.population_size + 1, self.budget - eval_count)  # Dynamic adjustment\n\n        # Return the best found solution and its value\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Enhanced the exploration by dynamically adjusting the harmony memory consideration rate `phi` based on evaluation progress to improve the diversity of solutions.", "configspace": "", "generation": 11, "fitness": 0.8019330020869649, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.802 with standard deviation 0.022. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "6f87b3ee-6352-45a4-8cec-c26ba8931eb1", "metadata": {"aucs": [0.832563121422232, 0.78591308889812, 0.7873227959405427], "final_y": [0.13951530569490145, 0.14403383334214592, 0.16041855258189863]}, "mutation_prompt": null}
{"id": "da06e821-e98e-4678-a136-8428dae2cd92", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim\n        self.harmony_memory_size = max(5, dim)\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.secondary_memory_size = max(3, dim // 2)  # Additional secondary memory\n        self.secondary_memory = np.random.rand(self.secondary_memory_size, dim)\n        self.phi = 0.5\n        self.beta = 1.0\n        self.gamma = 0.5\n        self.dynamic_adaptation_rate = 0.005  # New parameter for adaptive phi\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        self.secondary_memory = lb + (ub - lb) * np.random.rand(self.secondary_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        secondary_values = np.array([func(sm) for sm in self.secondary_memory])\n        eval_count = self.harmony_memory_size + self.secondary_memory_size\n\n        while eval_count < self.budget:\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.phi:\n                    if np.random.rand() < 0.5:  # Use dual memory approach\n                        idx = np.random.randint(self.harmony_memory_size)\n                        new_harmony[i] = self.harmony_memory[idx, i]\n                    else:\n                        idx = np.random.randint(self.secondary_memory_size)\n                        new_harmony[i] = self.secondary_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n                if np.random.rand() < self.gamma:\n                    self.beta = np.random.uniform(0.5, 1.5)\n                    new_harmony[i] += self.beta * (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n\n            new_harmony = np.clip(new_harmony, lb, ub)\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            if new_value < max(func_values.max(), secondary_values.max()):  # Compare with both memories\n                if new_value < func_values.max():\n                    worst_idx = np.argmax(func_values)\n                    self.harmony_memory[worst_idx] = new_harmony\n                    func_values[worst_idx] = new_value\n                else:\n                    worst_idx = np.argmax(secondary_values)\n                    self.secondary_memory[worst_idx] = new_harmony\n                    secondary_values[worst_idx] = new_value\n\n                self.phi = min(1.0, self.phi + self.dynamic_adaptation_rate)\n                self.secondary_memory_size = min(self.secondary_memory_size + 1, self.harmony_memory_size)  # Adapt size\n\n            self.gamma *= 0.99\n\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Introduced adaptive secondary memory size based on convergence rate to enhance exploration and exploitation balance.", "configspace": "", "generation": 12, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 6 is out of bounds for axis 0 with size 5').", "error": "IndexError('index 6 is out of bounds for axis 0 with size 5')", "parent_id": "d27749f7-1ac8-402f-a7ba-f2a6c6936ed3", "metadata": {}, "mutation_prompt": null}
{"id": "948c3ff3-db3b-4edb-abfd-b4eb4c2fe1c2", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim  # Adaptive based on dimension\n        self.harmony_memory_size = max(5, dim)  # Size of harmony memory\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.phi = 0.5  # Harmony memory consideration rate\n        self.beta = 1.0  # Parameter to control randomization\n        self.gamma = 0.5  # Parameter to control local search\n\n    def __call__(self, func):\n        # Initialize harmony memory with random solutions\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        eval_count = self.harmony_memory_size\n\n        while eval_count < self.budget:\n            # Generate a new harmony vector\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.phi * (1 - eval_count / self.budget):  # Dynamic phi adjustment\n                    idx = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = self.harmony_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n                # Adjust new harmony using pitch adjustment\n                if np.random.rand() < self.gamma * (1 - eval_count / self.budget):  # Adaptive gamma\n                    new_harmony[i] += self.beta * (1 - eval_count / self.budget) * (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n\n            # Ensure new harmony is within bounds\n            new_harmony = np.clip(new_harmony, lb, ub)\n\n            # Evaluate the new harmony\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            # Update harmony memory if the new solution is better\n            worst_idx = np.argmax(func_values)\n            if new_value < func_values[worst_idx]:\n                self.harmony_memory[worst_idx] = new_harmony\n                func_values[worst_idx] = new_value\n                self.beta *= 0.98  # Refined beta decay for better convergence\n\n        # Return the best found solution and its value\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Enhanced solution quality by refining beta decay strategy and introducing a dynamic phi adjustment based on convergence progress.", "configspace": "", "generation": 12, "fitness": 0.806691047705446, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.807 with standard deviation 0.007. And the mean value of best solutions found was 0.146 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "2bf775ab-7e06-476a-9751-1df485e75195", "metadata": {"aucs": [0.8122574484783209, 0.7966076169468125, 0.8112080776912044], "final_y": [0.14773372468443347, 0.1467526501624432, 0.1438300079355902]}, "mutation_prompt": null}
{"id": "781373bc-0e9a-4054-b0d2-214dbb25510e", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim  # Adaptive based on dimension\n        self.harmony_memory_size = max(5, dim)  # Size of harmony memory\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.phi = 0.5  # Harmony memory consideration rate\n        self.beta = 1.0  # Parameter to control randomization\n        self.gamma = 0.5  # Parameter to control local search\n\n    def __call__(self, func):\n        # Initialize harmony memory with random solutions\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        eval_count = self.harmony_memory_size\n\n        while eval_count < self.budget:\n            # Generate a new harmony vector\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.phi:\n                    idx = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = self.harmony_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n                # Adjust new harmony using pitch adjustment\n                if np.random.rand() < self.gamma:\n                    self.beta = 1 + 0.5 * np.sin(2 * np.pi * eval_count / self.budget)  # Adaptive oscillation for beta\n                    new_harmony[i] += self.beta * (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n\n            # Ensure new harmony is within bounds\n            new_harmony = np.clip(new_harmony, lb, ub)\n\n            # Evaluate the new harmony\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            # Update harmony memory if the new solution is better\n            worst_idx = np.argmax(func_values)\n            if new_value < func_values[worst_idx]:\n                self.harmony_memory[worst_idx] = new_harmony\n                func_values[worst_idx] = new_value\n                self.phi = min(1.0, self.phi + 0.01)  # Increase phi\n\n            self.gamma *= 0.99  # Decay strategy for gamma\n            self.population_size = min(self.population_size + 1, self.budget - eval_count)  # Dynamic adjustment\n\n        # Return the best found solution and its value\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Introduced adaptive oscillation for beta, dynamically adjusting its value based on the current number of evaluations to enhance exploration-exploitation balance.", "configspace": "", "generation": 12, "fitness": 0.8491166249364618, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.849 with standard deviation 0.025. And the mean value of best solutions found was 0.136 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "6f87b3ee-6352-45a4-8cec-c26ba8931eb1", "metadata": {"aucs": [0.8844414464101834, 0.8345947323498162, 0.8283136960493855], "final_y": [0.12362851109065442, 0.14133776512296337, 0.1424187376899726]}, "mutation_prompt": null}
{"id": "778bbeaf-6426-447f-82fe-59d8a4916120", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim  # Adaptive based on dimension\n        self.harmony_memory_size = max(5, dim)  # Size of harmony memory\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.phi = 0.5  # Harmony memory consideration rate\n        self.beta = 1.0  # Parameter to control randomization\n        self.gamma = 0.5  # Parameter to control local search\n\n    def __call__(self, func):\n        # Initialize harmony memory with random solutions\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        eval_count = self.harmony_memory_size\n\n        while eval_count < self.budget:\n            # Generate a new harmony vector\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                # Introduced a nonlinear decay for phi\n                self.phi = 0.5 * (1 - (eval_count / self.budget)**2)\n                if np.random.rand() < self.phi:\n                    idx = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = self.harmony_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n                # Adjust new harmony using pitch adjustment\n                self.gamma = 0.5 * (1 - eval_count / self.budget)  # Linear decay for gamma\n                if np.random.rand() < self.gamma:\n                    self.beta = np.random.uniform(0.5, 1.5)  # Adaptive pitch adjustment\n                    new_harmony[i] += self.beta * (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n\n            # Ensure new harmony is within bounds\n            new_harmony = np.clip(new_harmony, lb, ub)\n\n            # Evaluate the new harmony\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            # Update harmony memory if the new solution is better\n            worst_idx = np.argmax(func_values)\n            if new_value < func_values[worst_idx]:\n                self.harmony_memory[worst_idx] = new_harmony\n                func_values[worst_idx] = new_value\n\n        # Return the best found solution and its value\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Refined gamma decay strategy with linear decay to enhance convergence. ", "configspace": "", "generation": 12, "fitness": 0.8245699907160656, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.825 with standard deviation 0.004. And the mean value of best solutions found was 0.144 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "77945ac2-5492-4dd9-a573-1d63fd86d352", "metadata": {"aucs": [0.8233356331303159, 0.83035766622193, 0.8200166727959515], "final_y": [0.1461569875128771, 0.13888079454971225, 0.1468809653220281]}, "mutation_prompt": null}
{"id": "516ad8c2-e494-4c4a-ba60-7b8636df6fe0", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim  # Adaptive based on dimension\n        self.harmony_memory_size = max(5, dim)  # Size of harmony memory\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.phi = 0.5  # Harmony memory consideration rate\n        self.beta = 1.0  # Parameter to control randomization\n        self.gamma = 0.5  # Parameter to control local search\n\n    def __call__(self, func):\n        # Initialize harmony memory with random solutions\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        eval_count = self.harmony_memory_size\n\n        while eval_count < self.budget:\n            # Adjust phi based on the evaluation progress\n            self.phi = 0.5 * (1 - eval_count / self.budget)  # Changed line\n\n            # Generate a new harmony vector\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.phi:\n                    idx = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = self.harmony_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n                # Adjust new harmony using pitch adjustment\n                if np.random.rand() < self.gamma * (1 - eval_count / self.budget):  # Adaptive gamma\n                    new_harmony[i] += self.beta * (1 - eval_count / self.budget) * (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n\n            # Ensure new harmony is within bounds\n            new_harmony = np.clip(new_harmony, lb, ub)\n\n            # Evaluate the new harmony\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            # Update harmony memory if the new solution is better\n            worst_idx = np.argmax(func_values)\n            if new_value < func_values[worst_idx]:\n                self.harmony_memory[worst_idx] = new_harmony\n                func_values[worst_idx] = new_value\n                self.beta *= 0.95  # Adjust the beta parameter\n\n        # Return the best found solution and its value\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Improved convergence by introducing a dynamic adjustment of harmony memory consideration rate based on evaluation progress.  ", "configspace": "", "generation": 12, "fitness": 0.8250438569281102, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.825 with standard deviation 0.021. And the mean value of best solutions found was 0.144 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "2bf775ab-7e06-476a-9751-1df485e75195", "metadata": {"aucs": [0.8347374132645569, 0.7956670471040659, 0.844727110415708], "final_y": [0.13927690248877878, 0.14990460915141057, 0.14191658510331884]}, "mutation_prompt": null}
{"id": "a74bb6d0-3d6c-4713-9c2b-585a444083c8", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim\n        self.harmony_memory_size = max(5, dim)\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.secondary_memory_size = max(3, dim // 2)  # Additional secondary memory\n        self.secondary_memory = np.random.rand(self.secondary_memory_size, dim)\n        self.phi = 0.5\n        self.beta = 1.0\n        self.gamma = 0.5\n        self.dynamic_adaptation_rate = 0.005  # New parameter for adaptive phi\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        self.secondary_memory = lb + (ub - lb) * np.random.rand(self.secondary_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        secondary_values = np.array([func(sm) for sm in self.secondary_memory])\n        eval_count = self.harmony_memory_size + self.secondary_memory_size\n\n        while eval_count < self.budget:\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.phi:\n                    if np.random.rand() < 0.5:  # Use dual memory approach\n                        idx = np.random.randint(self.harmony_memory_size)\n                        new_harmony[i] = self.harmony_memory[idx, i]\n                    else:\n                        idx = np.random.randint(self.secondary_memory_size)\n                        new_harmony[i] = self.secondary_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n                if np.random.rand() < self.gamma:\n                    self.beta = np.random.uniform(0.5, 1.5)\n                    new_harmony[i] += self.beta * (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n\n            new_harmony = np.clip(new_harmony, lb, ub)\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            if new_value < max(func_values.max(), secondary_values.max()):  # Compare with both memories\n                if new_value < func_values.max():\n                    worst_idx = np.argmax(func_values)\n                    self.harmony_memory[worst_idx] = new_harmony\n                    func_values[worst_idx] = new_value\n                else:\n                    worst_idx = np.argmax(secondary_values)\n                    self.secondary_memory[worst_idx] = new_harmony\n                    secondary_values[worst_idx] = new_value\n\n                self.phi = min(1.0, self.phi + self.dynamic_adaptation_rate) * (1 - 0.1 * (eval_count / self.budget))\n\n            self.gamma *= 0.99\n\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Improved balance between exploration and exploitation by dynamically adjusting `phi` based on the convergence rate.", "configspace": "", "generation": 13, "fitness": 0.8527489219927876, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.853 with standard deviation 0.038. And the mean value of best solutions found was 0.132 (0. is the best) with standard deviation 0.015.", "error": "", "parent_id": "d27749f7-1ac8-402f-a7ba-f2a6c6936ed3", "metadata": {"aucs": [0.798747559449889, 0.8799393935173367, 0.8795598130111373], "final_y": [0.1521050241447075, 0.11914442341337927, 0.12338168746850997]}, "mutation_prompt": null}
{"id": "78eaa883-60a3-4fca-9804-7a326fda381e", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim\n        self.harmony_memory_size = max(5, dim)\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.secondary_memory_size = max(3, dim // 2)\n        self.secondary_memory = np.random.rand(self.secondary_memory_size, dim)\n        self.phi = 0.5\n        self.beta = 1.0\n        self.gamma = 0.5\n        self.dynamic_adaptation_rate = 0.005\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        self.secondary_memory = lb + (ub - lb) * np.random.rand(self.secondary_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        secondary_values = np.array([func(sm) for sm in self.secondary_memory])\n        eval_count = self.harmony_memory_size + self.secondary_memory_size\n\n        while eval_count < self.budget:\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.phi:\n                    if np.random.rand() < 0.5:\n                        idx = np.random.randint(self.harmony_memory_size)\n                        new_harmony[i] = self.harmony_memory[idx, i]\n                    else:\n                        idx = np.random.randint(self.secondary_memory_size)\n                        new_harmony[i] = self.secondary_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n                if np.random.rand() < self.gamma:\n                    self.beta = np.random.uniform(0.5, 1.5)\n                    new_harmony[i] += self.beta * (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n\n            new_harmony = np.clip(new_harmony, lb, ub)\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            if new_value < max(func_values.max(), secondary_values.max()):\n                if new_value < func_values.max():\n                    worst_idx = np.argmax(func_values)\n                    self.harmony_memory[worst_idx] = new_harmony\n                    func_values[worst_idx] = new_value\n                else:\n                    worst_idx = np.argmax(secondary_values)\n                    self.secondary_memory[worst_idx] = new_harmony\n                    secondary_values[worst_idx] = new_value\n\n                self.phi = min(1.0, self.phi + self.dynamic_adaptation_rate)\n                self.harmony_memory_size = min(self.population_size, int(self.harmony_memory_size * 1.05))  # Adaptive memory size\n\n            self.gamma = max(0.1, self.gamma * 0.97)  # Self-tuning gamma\n\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Improved Adaptive Swarm Harmony Optimization by incorporating an adaptive dynamic memory size and self-tuning gamma to enhance convergence speed and solution quality.", "configspace": "", "generation": 13, "fitness": 0.8812489997529273, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.881 with standard deviation 0.008. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "d27749f7-1ac8-402f-a7ba-f2a6c6936ed3", "metadata": {"aucs": [0.8877131647152869, 0.8702903376576683, 0.8857434968858262], "final_y": [0.11857275424788616, 0.12377953811132603, 0.11993759954270622]}, "mutation_prompt": null}
{"id": "722723cf-e45b-4373-a7ff-d469777bf630", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim  # Adaptive based on dimension\n        self.harmony_memory_size = max(5, dim)  # Size of harmony memory\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.phi = 0.5  # Harmony memory consideration rate\n        self.beta = 1.0  # Parameter to control randomization\n        self.gamma = 0.5  # Parameter to control local search\n\n    def __call__(self, func):\n        # Initialize harmony memory with random solutions\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        eval_count = self.harmony_memory_size\n\n        while eval_count < self.budget:\n            # Generate a new harmony vector\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.phi:\n                    idx = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = self.harmony_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n                # Adjust new harmony using pitch adjustment\n                if np.random.rand() < self.gamma:\n                    self.beta = 0.5 + 1.0 * (self.budget - eval_count) / self.budget  # Adaptive pitch adjustment\n                    new_harmony[i] += self.beta * (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n\n            # Ensure new harmony is within bounds\n            new_harmony = np.clip(new_harmony, lb, ub)\n\n            # Evaluate the new harmony\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            # Update harmony memory if the new solution is better\n            worst_idx = np.argmax(func_values)\n            if new_value < func_values[worst_idx]:\n                self.harmony_memory[worst_idx] = new_harmony\n                func_values[worst_idx] = new_value\n                self.phi = min(1.0, self.phi + 0.01)  # Increase phi\n\n            self.gamma *= 0.99  # Decay strategy for gamma\n            self.population_size = min(self.population_size + 1, self.budget - eval_count)  # Dynamic adjustment\n\n        # Return the best found solution and its value\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Introduced adaptive pitch adjustment by modifying `beta` based on evaluation progress to enhance convergence.", "configspace": "", "generation": 13, "fitness": 0.8800451445487605, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.880 with standard deviation 0.013. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "6f87b3ee-6352-45a4-8cec-c26ba8931eb1", "metadata": {"aucs": [0.8900760109145319, 0.8889629382551404, 0.8610964844766091], "final_y": [0.1179570955268947, 0.11597296962980208, 0.12538593926528552]}, "mutation_prompt": null}
{"id": "05d46d83-2230-4bb9-894e-8b7d4bdfe391", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim  # Adaptive based on dimension\n        self.harmony_memory_size = max(5, dim)  # Size of harmony memory\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.phi = 0.5  # Harmony memory consideration rate\n        self.beta = 1.0  # Parameter to control randomization\n        self.gamma = 0.5  # Parameter to control local search\n\n    def __call__(self, func):\n        # Initialize harmony memory with random solutions\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        eval_count = self.harmony_memory_size\n\n        while eval_count < self.budget:\n            # Generate a new harmony vector\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.phi:\n                    idx = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = self.harmony_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n                # Adjust new harmony using pitch adjustment\n                if np.random.rand() < self.gamma:\n                    self.beta = np.random.uniform(0.5, 1.5)  # Adaptive pitch adjustment\n                    new_harmony[i] += self.beta * (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n\n            # Ensure new harmony is within bounds\n            new_harmony = np.clip(new_harmony, lb, ub)\n\n            # Evaluate the new harmony\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            # Update harmony memory if the new solution is better\n            worst_idx = np.argmax(func_values)\n            if new_value < func_values[worst_idx]:\n                self.harmony_memory[worst_idx] = new_harmony\n                func_values[worst_idx] = new_value\n                self.phi = min(1.0, self.phi + 0.01 * np.std(func_values))  # Increase phi\n\n            self.gamma *= 0.99  # Decay strategy for gamma\n\n        # Return the best found solution and its value\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Improved convergence by introducing a dynamic adjustment for harmony memory consideration rate `phi` based on the standard deviation of function values.", "configspace": "", "generation": 13, "fitness": 0.8630958204688318, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.863 with standard deviation 0.033. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "f5698e46-afc9-48a0-868d-720a25779eef", "metadata": {"aucs": [0.8171098078050374, 0.8910015963618965, 0.8811760572395616], "final_y": [0.13575772214931203, 0.11790587549538889, 0.12037074955075189]}, "mutation_prompt": null}
{"id": "f61eb4f3-a9d6-4992-9a33-cc9e4036d150", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim  # Adaptive based on dimension\n        self.harmony_memory_size = max(5, dim)  # Size of harmony memory\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.phi = 0.5  # Harmony memory consideration rate\n        self.beta = 1.0  # Parameter to control randomization\n        self.gamma = 0.5  # Parameter to control local search\n\n    def __call__(self, func):\n        # Initialize harmony memory with random solutions\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        eval_count = self.harmony_memory_size\n\n        while eval_count < self.budget:\n            # Generate a new harmony vector\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                # Introduced a nonlinear decay for phi\n                self.phi = 0.5 * (1 - (eval_count / self.budget)**2)\n                if np.random.rand() < self.phi:\n                    idx = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = self.harmony_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n                # Adjust new harmony using pitch adjustment\n                self.gamma = 0.5 * (1 - (eval_count / self.budget)**3)  # Cubic adaptive gamma decay\n                if np.random.rand() < self.gamma:\n                    self.beta = np.random.uniform(0.5, 1.5)  # Adaptive pitch adjustment\n                    new_harmony[i] += self.beta * (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n\n            # Ensure new harmony is within bounds\n            new_harmony = np.clip(new_harmony, lb, ub)\n\n            # Evaluate the new harmony\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            # Update harmony memory if the new solution is better\n            worst_idx = np.argmax(func_values)\n            if new_value < func_values[worst_idx]:\n                self.harmony_memory[worst_idx] = new_harmony\n                func_values[worst_idx] = new_value\n\n        # Return the best found solution and its value\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Enhanced the adaptive gamma decay strategy with cubic decay to improve local search capabilities.", "configspace": "", "generation": 13, "fitness": 0.8617779366166601, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.862 with standard deviation 0.023. And the mean value of best solutions found was 0.129 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "77945ac2-5492-4dd9-a573-1d63fd86d352", "metadata": {"aucs": [0.8288761089068986, 0.8769062968222158, 0.8795514041208657], "final_y": [0.14385728791344488, 0.12121777146645518, 0.12208003735792117]}, "mutation_prompt": null}
{"id": "354e0ab2-55d5-4453-af8a-8fd9009b0a62", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim\n        self.harmony_memory_size = max(5, dim)\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.secondary_memory_size = max(3, dim // 2)  # Additional secondary memory\n        self.secondary_memory = np.random.rand(self.secondary_memory_size, dim)\n        self.phi = 0.5\n        self.beta = 1.0\n        self.gamma = 0.5\n        self.dynamic_adaptation_rate = 0.005  # New parameter for adaptive phi\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        self.secondary_memory = lb + (ub - lb) * np.random.rand(self.secondary_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        secondary_values = np.array([func(sm) for sm in self.secondary_memory])\n        eval_count = self.harmony_memory_size + self.secondary_memory_size\n\n        while eval_count < self.budget:\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.phi:\n                    if np.random.rand() < 0.5:  # Use dual memory approach\n                        idx = np.random.randint(self.harmony_memory_size)\n                        new_harmony[i] = self.harmony_memory[idx, i]\n                    else:\n                        idx = np.random.randint(self.secondary_memory_size)\n                        new_harmony[i] = self.secondary_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n                self.beta = np.random.uniform(0.5, 1.5)  # Adapt beta each iteration\n                if np.random.rand() < self.gamma:\n                    new_harmony[i] += self.beta * (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n\n            new_harmony = np.clip(new_harmony, lb, ub)\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            if new_value < max(func_values.max(), secondary_values.max()):  # Compare with both memories\n                if new_value < func_values.max():\n                    worst_idx = np.argmax(func_values)\n                    self.harmony_memory[worst_idx] = new_harmony\n                    func_values[worst_idx] = new_value\n                else:\n                    worst_idx = np.argmax(secondary_values)\n                    self.secondary_memory[worst_idx] = new_harmony\n                    secondary_values[worst_idx] = new_value\n\n                self.phi = min(1.0, self.phi + self.dynamic_adaptation_rate)\n\n            self.gamma *= 0.99\n\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Enhanced exploration by adapting `beta` more frequently to improve the balance between exploration and exploitation.", "configspace": "", "generation": 14, "fitness": 0.8607021802176537, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.861 with standard deviation 0.014. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "d27749f7-1ac8-402f-a7ba-f2a6c6936ed3", "metadata": {"aucs": [0.8542199488667339, 0.8475395143121507, 0.8803470774740763], "final_y": [0.13124534715515523, 0.12812809482193, 0.1191794716747333]}, "mutation_prompt": null}
{"id": "9fae9bbe-505d-4c84-9d10-de2ec05aa5ad", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim\n        self.harmony_memory_size = max(5, dim)\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.secondary_memory_size = max(3, dim // 2)\n        self.secondary_memory = np.random.rand(self.secondary_memory_size, dim)\n        self.phi = 0.5\n        self.beta = 1.0\n        self.gamma = 0.5\n        self.dynamic_adaptation_rate = 0.007  # Adjusted adaptation rate\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        self.secondary_memory = lb + (ub - lb) * np.random.rand(self.secondary_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        secondary_values = np.array([func(sm) for sm in self.secondary_memory])\n        eval_count = self.harmony_memory_size + self.secondary_memory_size\n\n        while eval_count < self.budget:\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.phi:\n                    if np.random.rand() < 0.5:\n                        idx = np.random.randint(self.harmony_memory_size)\n                        new_harmony[i] = self.harmony_memory[idx, i]\n                    else:\n                        idx = np.random.randint(self.secondary_memory_size)\n                        new_harmony[i] = self.secondary_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n                if np.random.rand() < self.gamma:\n                    self.beta = np.random.uniform(0.5, 1.5)\n                    new_harmony[i] += self.beta * (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n\n            new_harmony = np.clip(new_harmony, lb, ub)\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            if new_value < max(func_values.max(), secondary_values.max()):\n                if new_value < func_values.max():\n                    worst_idx = np.argmax(func_values)\n                    self.harmony_memory[worst_idx] = new_harmony\n                    func_values[worst_idx] = new_value\n                else:\n                    worst_idx = np.argmax(secondary_values)\n                    self.secondary_memory[worst_idx] = new_harmony\n                    secondary_values[worst_idx] = new_value\n\n                self.phi = min(1.0, self.phi + self.dynamic_adaptation_rate)\n                self.harmony_memory_size = min(self.population_size, int(self.harmony_memory_size * 1.05))  # Adaptive memory size\n\n            self.gamma = max(0.1, self.gamma * 0.95)  # Adjusted gamma decay\n\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Enhanced solution by fine-tuning the dynamic adaptation rate and gamma decay for improved convergence.", "configspace": "", "generation": 14, "fitness": 0.874515108064721, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.875 with standard deviation 0.006. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "78eaa883-60a3-4fca-9804-7a326fda381e", "metadata": {"aucs": [0.8740328053303146, 0.8678662683551915, 0.8816462505086567], "final_y": [0.12296364025663564, 0.12054776952888091, 0.11991824773802451]}, "mutation_prompt": null}
{"id": "8f452827-23db-403f-9250-ec9a8f5b359f", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim  # Adaptive based on dimension\n        self.harmony_memory_size = max(5, dim)  # Size of harmony memory\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.phi = 0.5  # Harmony memory consideration rate\n        self.beta = 1.0  # Parameter to control randomization\n        self.gamma = 0.5  # Parameter to control local search\n\n    def __call__(self, func):\n        # Initialize harmony memory with random solutions\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        eval_count = self.harmony_memory_size\n\n        while eval_count < self.budget:\n            # Generate a new harmony vector\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.phi:\n                    idx = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = self.harmony_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n                # Adjust new harmony using pitch adjustment\n                if np.random.rand() < self.gamma:\n                    self.beta = 0.5 + 1.0 * (self.budget - eval_count) / self.budget  # Adaptive pitch adjustment\n                    new_harmony[i] += np.random.uniform(-self.beta, self.beta) * (ub[i] - lb[i])  # Changed line\n\n            # Ensure new harmony is within bounds\n            new_harmony = np.clip(new_harmony, lb, ub)\n\n            # Evaluate the new harmony\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            # Update harmony memory if the new solution is better\n            worst_idx = np.argmax(func_values)\n            if new_value < func_values[worst_idx]:\n                self.harmony_memory[worst_idx] = new_harmony\n                func_values[worst_idx] = new_value\n                self.phi = min(1.0, self.phi + 0.01)  # Increase phi\n\n            self.gamma *= 0.99  # Decay strategy for gamma\n            self.population_size = min(self.population_size + 1, self.budget - eval_count)  # Dynamic adjustment\n\n        # Return the best found solution and its value\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Improved convergence by introducing dynamic pitch adjustment range based on evaluation progress.", "configspace": "", "generation": 14, "fitness": 0.8782207558621035, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.878 with standard deviation 0.003. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "722723cf-e45b-4373-a7ff-d469777bf630", "metadata": {"aucs": [0.8745607447688404, 0.8787639599056246, 0.8813375629118454], "final_y": [0.1257586609867859, 0.11636102356976996, 0.12068577326054619]}, "mutation_prompt": null}
{"id": "145006ca-45af-455c-83ad-b2064012d75d", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim\n        self.harmony_memory_size = max(5, dim)\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.secondary_memory_size = max(3, dim // 2)\n        self.secondary_memory = np.random.rand(self.secondary_memory_size, dim)\n        self.elite_memory_size = max(2, dim // 3)\n        self.elite_memory = np.random.rand(self.elite_memory_size, dim)\n        self.phi = 0.5\n        self.beta = 1.0\n        self.gamma = 0.5\n        self.dynamic_adaptation_rate = 0.005\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        self.secondary_memory = lb + (ub - lb) * np.random.rand(self.secondary_memory_size, self.dim)\n        self.elite_memory = lb + (ub - lb) * np.random.rand(self.elite_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        secondary_values = np.array([func(sm) for sm in self.secondary_memory])\n        elite_values = np.array([func(em) for em in self.elite_memory])\n        eval_count = self.harmony_memory_size + self.secondary_memory_size + self.elite_memory_size\n\n        while eval_count < self.budget:\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.phi:\n                    rand_choice = np.random.rand()\n                    if rand_choice < 0.33:\n                        idx = np.random.randint(self.harmony_memory_size)\n                        new_harmony[i] = self.harmony_memory[idx, i]\n                    elif rand_choice < 0.66:\n                        idx = np.random.randint(self.secondary_memory_size)\n                        new_harmony[i] = self.secondary_memory[idx, i]\n                    else:\n                        idx = np.random.randint(self.elite_memory_size)\n                        new_harmony[i] = self.elite_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n                if np.random.rand() < self.gamma:\n                    self.beta = np.random.uniform(0.25, 1.75)  # Expanded beta range\n                    new_harmony[i] += self.beta * (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n\n            new_harmony = np.clip(new_harmony, lb, ub)\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            if new_value < max(func_values.max(), secondary_values.max(), elite_values.max()):\n                if new_value < func_values.max():\n                    worst_idx = np.argmax(func_values)\n                    self.harmony_memory[worst_idx] = new_harmony\n                    func_values[worst_idx] = new_value\n                elif new_value < secondary_values.max():\n                    worst_idx = np.argmax(secondary_values)\n                    self.secondary_memory[worst_idx] = new_harmony\n                    secondary_values[worst_idx] = new_value\n                else:\n                    worst_idx = np.argmax(elite_values)\n                    self.elite_memory[worst_idx] = new_harmony\n                    elite_values[worst_idx] = new_value\n\n                self.phi = min(1.0, self.phi + self.dynamic_adaptation_rate)\n                self.harmony_memory_size = min(self.population_size, int(self.harmony_memory_size * 1.05))\n\n            self.gamma = max(0.1, self.gamma * 0.97)\n\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Introduced an elite memory mechanism and dynamic parameter tuning to balance exploration and exploitation more effectively.", "configspace": "", "generation": 14, "fitness": 0.8650040222070695, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.865 with standard deviation 0.030. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "78eaa883-60a3-4fca-9804-7a326fda381e", "metadata": {"aucs": [0.8808763138871822, 0.8228360780429506, 0.8912996746910762], "final_y": [0.118919254552314, 0.13713892900800628, 0.11504942773082738]}, "mutation_prompt": null}
{"id": "debcc78d-5aa9-4135-a1d3-bc19d4c3738d", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim  # Adaptive based on dimension\n        self.harmony_memory_size = max(5, dim)  # Size of harmony memory\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.phi = 0.5  # Harmony memory consideration rate\n        self.beta = 1.0  # Parameter to control randomization\n        self.gamma = 0.5  # Parameter to control local search\n\n    def __call__(self, func):\n        # Initialize harmony memory with random solutions\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        eval_count = self.harmony_memory_size\n\n        while eval_count < self.budget:\n            # Generate a new harmony vector\n            new_harmony = np.zeros(self.dim)\n            diversity = np.std(self.harmony_memory, axis=0).mean()  # Calculate harmony memory diversity\n\n            for i in range(self.dim):\n                if np.random.rand() < self.phi:\n                    idx = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = self.harmony_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n                # Adjust new harmony using dynamic pitch adjustment\n                if np.random.rand() < self.gamma:\n                    self.beta = 0.5 + 1.0 * (1 - eval_count / self.budget)  # Dynamic pitch adjustment\n                    new_harmony[i] += self.beta * (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n\n            # Ensure new harmony is within bounds\n            new_harmony = np.clip(new_harmony, lb, ub)\n\n            # Evaluate the new harmony\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            # Update harmony memory if the new solution is better\n            worst_idx = np.argmax(func_values)\n            if new_value < func_values[worst_idx]:\n                self.harmony_memory[worst_idx] = new_harmony\n                func_values[worst_idx] = new_value\n                self.phi = min(1.0, self.phi + 0.01)  # Increase phi\n\n            self.gamma *= (1 - 0.001 * diversity)  # Adaptive decay strategy for gamma\n\n        # Return the best found solution and its value\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Enhanced Adaptive Swarm Harmony Optimization by introducing a variable dynamic pitch adjustment rate based on the evaluation progress and an adaptive gamma decaying based on the harmony memory diversity principle to improve exploration-exploitation balance.", "configspace": "", "generation": 14, "fitness": 0.8709990508408403, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.871 with standard deviation 0.013. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "f5698e46-afc9-48a0-868d-720a25779eef", "metadata": {"aucs": [0.8607268027259285, 0.8626729959589966, 0.889597353837596], "final_y": [0.13406753366737134, 0.12402425129842298, 0.11599154490888608]}, "mutation_prompt": null}
{"id": "a3a505a3-1f4b-4422-9c67-dbfd179f3151", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim\n        self.harmony_memory_size = max(5, dim)\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.phi = 0.5\n        self.beta = 1.0\n        self.gamma = 0.5\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        eval_count = self.harmony_memory_size\n\n        while eval_count < self.budget:\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.phi:\n                    idx = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = self.harmony_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n                if np.random.rand() < self.gamma:\n                    self.beta = 0.5 + np.exp(-4 * eval_count / self.budget)  # Non-linear adaptive pitch adjustment\n                    new_harmony[i] += self.beta * (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n\n            new_harmony = np.clip(new_harmony, lb, ub)\n\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(func_values)\n            if new_value < func_values[worst_idx]:\n                self.harmony_memory[worst_idx] = new_harmony\n                func_values[worst_idx] = new_value\n                self.phi = min(1.0, self.phi + (0.02 * (1 - eval_count / self.budget)))  # Improved dynamic phi\n\n            self.gamma *= 0.98  # Slightly faster decay strategy for gamma\n            self.population_size = min(self.population_size + 1, self.budget - eval_count)\n\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Refinement of AdaptiveSwarmHarmonyOptimization by introducing a non-linear adaptive beta and improved dynamic harmony consideration rate to enhance convergence and solution quality. ", "configspace": "", "generation": 15, "fitness": 0.878681243984468, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.879 with standard deviation 0.021. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "722723cf-e45b-4373-a7ff-d469777bf630", "metadata": {"aucs": [0.9080132817144543, 0.8602366672628519, 0.8677937829760981], "final_y": [0.12006855021836593, 0.13090132940574006, 0.13056289324447456]}, "mutation_prompt": null}
{"id": "1611476d-d3ab-4b25-9b8f-13f99bac0a95", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim  # Adaptive based on dimension\n        self.harmony_memory_size = max(5, dim)  # Size of harmony memory\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.phi = 0.5  # Harmony memory consideration rate\n        self.beta = 1.0  # Parameter to control randomization\n        self.gamma = 0.5  # Parameter to control local search\n\n    def __call__(self, func):\n        # Initialize harmony memory with random solutions\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        eval_count = self.harmony_memory_size\n\n        while eval_count < self.budget:\n            # Generate a new harmony vector\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.phi:\n                    idx = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = self.harmony_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n                # Adjust new harmony using pitch adjustment\n                if np.random.rand() < self.gamma:\n                    self.beta = 0.5 + 0.5 * (self.budget - eval_count) / self.budget  # Adaptive pitch adjustment\n                    new_harmony[i] += self.beta * (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n                    new_harmony[i] = np.clip(new_harmony[i], lb[i], ub[i])  # Ensure within bounds\n\n            # Evaluate the new harmony\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            # Update harmony memory if the new solution is better\n            worst_idx = np.argmax(func_values)\n            if new_value < func_values[worst_idx]:\n                self.harmony_memory[worst_idx] = new_harmony\n                func_values[worst_idx] = new_value\n                self.phi = 0.8 * self.phi + 0.2 * (eval_count / self.budget)  # Dynamic phi\n\n            self.gamma *= 0.99  # Decay strategy for gamma\n            self.population_size = min(self.population_size + 1, self.budget - eval_count)  # Dynamic adjustment\n\n        # Return the best found solution and its value\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Improved exploration-exploitation balance by introducing a dynamic harmony memory consideration rate and adaptive boundary restriction for pitch adjustment.", "configspace": "", "generation": 15, "fitness": 0.8493923335293766, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.849 with standard deviation 0.039. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "722723cf-e45b-4373-a7ff-d469777bf630", "metadata": {"aucs": [0.796748730085753, 0.8615904776858375, 0.8898377928165395], "final_y": [0.1238840981038305, 0.12819894584117608, 0.12241888540417079]}, "mutation_prompt": null}
{"id": "aeb18ec7-1ce5-4653-8761-3eed979697f0", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim  # Adaptive based on dimension\n        self.harmony_memory_size = max(5, dim)  # Size of harmony memory\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.phi = 0.5  # Harmony memory consideration rate\n        self.beta = 1.0  # Parameter to control randomization\n        self.gamma = 0.5  # Parameter to control local search\n\n    def __call__(self, func):\n        # Initialize harmony memory with random solutions\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        eval_count = self.harmony_memory_size\n\n        while eval_count < self.budget:\n            # Generate a new harmony vector\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.phi:\n                    idx = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = self.harmony_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n                # Adjust new harmony using pitch adjustment\n                if np.random.rand() < self.gamma:\n                    self.beta = np.random.uniform(0.3, 1.7)  # Adaptive pitch adjustment\n                    new_harmony[i] += self.beta * (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n\n            # Ensure new harmony is within bounds\n            new_harmony = np.clip(new_harmony, lb, ub)\n\n            # Evaluate the new harmony\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            # Update harmony memory if the new solution is better\n            worst_idx = np.argmax(func_values)\n            if new_value < func_values[worst_idx]:\n                self.harmony_memory[worst_idx] = new_harmony\n                func_values[worst_idx] = new_value\n                self.phi = min(1.0, self.phi + 0.02)  # Increase phi more\n\n            self.gamma *= 0.99  # Decay strategy for gamma\n\n        # Return the best found solution and its value\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Enhanced Adaptive Swarm Harmony Optimization by refining pitch adjustment with a dynamic beta range and introducing adaptive harmony memory consideration rate.", "configspace": "", "generation": 15, "fitness": 0.8742821707521117, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.874 with standard deviation 0.012. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "f5698e46-afc9-48a0-868d-720a25779eef", "metadata": {"aucs": [0.8866191620135644, 0.8778422864560649, 0.8583850637867059], "final_y": [0.12361673128447082, 0.1258175145132262, 0.13252324176998542]}, "mutation_prompt": null}
{"id": "7fd70e0f-c11d-4489-b680-1e6c0b3d5caa", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim  # Adaptive based on dimension\n        self.harmony_memory_size = max(5, dim)  # Size of harmony memory\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.phi = 0.5  # Harmony memory consideration rate\n        self.beta = 1.0  # Parameter to control randomization\n        self.gamma = 0.5  # Parameter to control local search\n\n    def __call__(self, func):\n        # Initialize harmony memory with random solutions\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        eval_count = self.harmony_memory_size\n\n        while eval_count < self.budget:\n            # Generate a new harmony vector\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.phi:\n                    idx = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = self.harmony_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n                # Adjust new harmony using pitch adjustment\n                if np.random.rand() < self.gamma:\n                    self.beta = 0.5 + 1.0 * (self.budget - eval_count) / self.budget  # Adaptive pitch adjustment\n                    new_harmony[i] += np.random.uniform(-self.beta, self.beta) * (ub[i] - lb[i])  # Changed line\n\n            # Ensure new harmony is within bounds\n            new_harmony = np.clip(new_harmony, lb, ub)\n\n            # Slight perturbation based on eval_count for improved exploration\n            new_harmony += np.random.uniform(-0.01, 0.01, size=self.dim) * (self.budget - eval_count) / self.budget\n\n            # Evaluate the new harmony\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            # Update harmony memory if the new solution is better\n            worst_idx = np.argmax(func_values)\n            if new_value < func_values[worst_idx]:\n                self.harmony_memory[worst_idx] = new_harmony\n                func_values[worst_idx] = new_value\n                self.phi = min(1.0, self.phi + 0.01)  # Increase phi\n\n            self.gamma *= 0.99  # Decay strategy for gamma\n            self.population_size = min(self.population_size + 1, self.budget - eval_count)  # Dynamic adjustment\n\n        # Return the best found solution and its value\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Improved convergence and exploration by adding perturbation based on evaluation progress for better diversity.", "configspace": "", "generation": 15, "fitness": 0.856671877355223, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.857 with standard deviation 0.012. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "8f452827-23db-403f-9250-ec9a8f5b359f", "metadata": {"aucs": [0.8710238220221023, 0.8425547726333725, 0.8564370374101941], "final_y": [0.12603007112663445, 0.13852256883497271, 0.13390985287429502]}, "mutation_prompt": null}
{"id": "1943d02d-43ae-4e5d-ac09-13659641c785", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim  # Adaptive based on dimension\n        self.harmony_memory_size = max(5, dim)  # Size of harmony memory\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.phi = 0.5  # Harmony memory consideration rate\n        self.beta = 1.0  # Parameter to control randomization\n        self.gamma = 0.5  # Parameter to control local search\n\n    def __call__(self, func):\n        # Initialize harmony memory with random solutions\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        eval_count = self.harmony_memory_size\n\n        while eval_count < self.budget:\n            # Generate a new harmony vector\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.phi:\n                    idx = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = self.harmony_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n                # Adjust new harmony using pitch adjustment\n                if np.random.rand() < self.gamma:\n                    self.beta = 0.5 + 1.0 * (self.budget - eval_count) / self.budget  # Adaptive pitch adjustment\n                    new_harmony[i] += np.random.uniform(-self.beta, self.beta) * (ub[i] - lb[i])  # Changed line\n\n            # Ensure new harmony is within bounds\n            new_harmony = np.clip(new_harmony, lb, ub)\n\n            # Evaluate the new harmony\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            # Update harmony memory if the new solution is better\n            worst_idx = np.argmax(func_values)\n            if new_value < func_values[worst_idx]:\n                self.harmony_memory[worst_idx] = new_harmony\n                func_values[worst_idx] = new_value\n                self.phi = min(1.0, self.phi + 0.01)  # Increase phi\n\n            self.gamma *= 1 - (eval_count / self.budget) * 0.01  # Flexible decay strategy for gamma\n            self.population_size = min(self.population_size + 1, self.budget - eval_count)  # Dynamic adjustment\n\n        # Return the best found solution and its value\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Enhanced convergence by introducing a flexible gamma decay strategy based on evaluation progress.", "configspace": "", "generation": 15, "fitness": 0.8620287831054894, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.862 with standard deviation 0.004. And the mean value of best solutions found was 0.130 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "8f452827-23db-403f-9250-ec9a8f5b359f", "metadata": {"aucs": [0.861038286748744, 0.8671522288148295, 0.8578958337528946], "final_y": [0.12626668265366792, 0.12983814014087192, 0.13287065397545883]}, "mutation_prompt": null}
{"id": "d0f5f0f9-454c-4b27-af96-428422e3274f", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim\n        self.harmony_memory_size = max(5, dim)\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.secondary_memory_size = max(3, dim // 2)\n        self.secondary_memory = np.random.rand(self.secondary_memory_size, dim)\n        self.phi = 0.5\n        self.beta = 1.0\n        self.gamma = 0.5\n        self.dynamic_adaptation_rate = 0.007  # Slightly increased adaptation rate\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        self.secondary_memory = lb + (ub - lb) * np.random.rand(self.secondary_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        secondary_values = np.array([func(sm) for sm in self.secondary_memory])\n        eval_count = self.harmony_memory_size + self.secondary_memory_size\n\n        while eval_count < self.budget:\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.phi:\n                    if np.random.rand() < 0.5:\n                        idx = np.random.randint(self.harmony_memory_size)\n                        new_harmony[i] = self.harmony_memory[idx, i]\n                    else:\n                        idx = np.random.randint(self.secondary_memory_size)\n                        new_harmony[i] = self.secondary_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n                if np.random.rand() < self.gamma:\n                    self.beta = np.random.uniform(0.5, 1.5)\n                    new_harmony[i] += self.beta * (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n\n            new_harmony = np.clip(new_harmony, lb, ub)\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            if new_value < max(func_values.max(), secondary_values.max()):\n                if new_value < func_values.max():\n                    worst_idx = np.argmax(func_values)\n                    self.harmony_memory[worst_idx] = new_harmony\n                    func_values[worst_idx] = new_value\n                else:\n                    worst_idx = np.argmax(secondary_values)\n                    self.secondary_memory[worst_idx] = new_harmony\n                    secondary_values[worst_idx] = new_value\n\n                self.phi = min(1.0, self.phi + self.dynamic_adaptation_rate)\n                self.harmony_memory_size = min(self.population_size, int(self.harmony_memory_size * 1.05))  # Adaptive memory size\n\n            self.gamma = max(0.1, self.gamma * 0.97)  # Self-tuning gamma\n\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Introduced minor adjustments to the dynamic adaptation rate to further enhance convergence.", "configspace": "", "generation": 16, "fitness": 0.8730223176033117, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.873 with standard deviation 0.012. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "78eaa883-60a3-4fca-9804-7a326fda381e", "metadata": {"aucs": [0.8626442099877848, 0.8666430661744396, 0.8897796766477106], "final_y": [0.12180080762135004, 0.12232401117968161, 0.12063328757678438]}, "mutation_prompt": null}
{"id": "e0f22fc9-ed71-4352-ac4a-a8b168dcf8c2", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim\n        self.harmony_memory_size = max(5, dim)\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.phi = 0.5\n        self.beta = 1.0\n        self.gamma = 0.5\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        eval_count = self.harmony_memory_size\n\n        while eval_count < self.budget:\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.phi:\n                    idx = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = self.harmony_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n                if np.random.rand() < self.gamma:\n                    self.beta = 0.5 + np.exp(-4 * eval_count / self.budget)  # Non-linear adaptive pitch adjustment\n                    new_harmony[i] += self.beta * (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n\n            new_harmony = np.clip(new_harmony, lb, ub)\n\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(func_values)\n            if new_value < func_values[worst_idx]:\n                self.harmony_memory[worst_idx] = new_harmony\n                func_values[worst_idx] = new_value\n                self.phi = min(1.0, self.phi + (0.02 * (1 - eval_count / self.budget)))  # Improved dynamic phi\n\n            self.gamma *= np.exp(-0.02)  # Introduced exponential decay for gamma\n            self.population_size = min(self.population_size + 1, self.budget - eval_count)\n\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Enhanced AdaptiveSwarmHarmonyOptimization by introducing exponential decay for `gamma` to accelerate convergence.", "configspace": "", "generation": 16, "fitness": 0.8459056518733826, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.846 with standard deviation 0.018. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "a3a505a3-1f4b-4422-9c67-dbfd179f3151", "metadata": {"aucs": [0.8240268881097148, 0.8449512846516237, 0.8687387828588091], "final_y": [0.14676773468513937, 0.13049658826175858, 0.12272395102976474]}, "mutation_prompt": null}
{"id": "c28dc10e-2280-4058-92a4-1cc8d0b62f8c", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim  # Adaptive based on dimension\n        self.harmony_memory_size = max(5, dim)  # Size of harmony memory\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.phi = 0.5  # Harmony memory consideration rate\n        self.beta = 1.0  # Parameter to control randomization\n        self.gamma = 0.5  # Parameter to control local search\n\n    def __call__(self, func):\n        # Initialize harmony memory with random solutions\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        eval_count = self.harmony_memory_size\n\n        while eval_count < self.budget:\n            # Generate a new harmony vector\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.phi:\n                    idx = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = self.harmony_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n                # Adjust new harmony using pitch adjustment\n                if np.random.rand() < self.gamma:\n                    distance_to_best = np.linalg.norm(new_harmony - self.harmony_memory[np.argmin(func_values)])  # New distance-based beta\n                    self.beta = np.clip(distance_to_best / (ub[i] - lb[i]), 0.5, 1.5)\n                    new_harmony[i] += self.beta * (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n\n            # Ensure new harmony is within bounds\n            new_harmony = np.clip(new_harmony, lb, ub)\n\n            # Evaluate the new harmony\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            # Update harmony memory if the new solution is better\n            worst_idx = np.argmax(func_values)\n            if new_value < func_values[worst_idx]:\n                self.harmony_memory[worst_idx] = new_harmony\n                func_values[worst_idx] = new_value\n                self.phi = min(1.0, self.phi + 0.01)  # Increase phi\n\n            self.gamma *= 0.99  # Decay strategy for gamma\n\n        # Return the best found solution and its value\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Enhanced solution quality by refining the beta adjustment to be more adaptive based on distance to the best solution.", "configspace": "", "generation": 16, "fitness": 0.8521911937772727, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.852 with standard deviation 0.021. And the mean value of best solutions found was 0.130 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "f5698e46-afc9-48a0-868d-720a25779eef", "metadata": {"aucs": [0.8310274705638585, 0.8454509972513902, 0.8800951135165694], "final_y": [0.1414062752850347, 0.1294032662360891, 0.11805786205025348]}, "mutation_prompt": null}
{"id": "a1368a62-272d-4e0b-9b4b-9611db309bee", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim\n        self.harmony_memory_size = max(5, dim)\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.phi = 0.5\n        self.beta = 1.0\n        self.gamma = 0.5\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        eval_count = self.harmony_memory_size\n\n        while eval_count < self.budget:\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.phi:\n                    idx = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = self.harmony_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n                if np.random.rand() < self.gamma:\n                    # Update beta based on the difference between best and worst harmony values\n                    beta_factor = (np.max(func_values) - np.min(func_values)) / (np.max(func_values) + 1e-9)\n                    self.beta = 0.5 + 0.5 * np.exp(-4 * eval_count / self.budget) * (1 - beta_factor)\n                    new_harmony[i] += self.beta * (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n\n            new_harmony = np.clip(new_harmony, lb, ub)\n\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(func_values)\n            if new_value < func_values[worst_idx]:\n                self.harmony_memory[worst_idx] = new_harmony\n                func_values[worst_idx] = new_value\n                self.phi = min(1.0, self.phi + (0.02 * (1 - eval_count / self.budget)))  # Improved dynamic phi\n\n            self.gamma *= 0.98  # Slightly faster decay strategy for gamma\n            self.population_size = min(self.population_size + 1, self.budget - eval_count)\n\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Improved convergence speed by incorporating a dynamic beta update based on the difference between the best and worst harmony values in the memory.", "configspace": "", "generation": 16, "fitness": 0.8605244901210815, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.861 with standard deviation 0.025. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "a3a505a3-1f4b-4422-9c67-dbfd179f3151", "metadata": {"aucs": [0.8383971787938507, 0.8475961447260791, 0.8955801468433146], "final_y": [0.13916716523727113, 0.12447938423054827, 0.11530162974406388]}, "mutation_prompt": null}
{"id": "eda27496-a116-421a-b9a0-9ddc0d2baf20", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim\n        self.harmony_memory_size = max(5, dim)\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.phi = 0.5\n        self.beta = 1.0\n        self.gamma = 0.5\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        eval_count = self.harmony_memory_size\n\n        while eval_count < self.budget:\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.phi:\n                    idx = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = self.harmony_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n                if np.random.rand() < self.gamma:\n                    self.beta = 0.5 + np.exp(-4 * eval_count / self.budget)  # Non-linear adaptive pitch adjustment\n                    new_harmony[i] += self.beta * (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n\n            new_harmony = np.clip(new_harmony, lb, ub)\n\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(func_values)\n            if new_value < func_values[worst_idx]:\n                self.harmony_memory[worst_idx] = new_harmony\n                func_values[worst_idx] = new_value\n                self.phi = min(1.0, self.phi + (0.02 * (1 - eval_count / self.budget)))  # Improved dynamic phi\n\n            self.gamma *= 0.99  # Slightly slower decay strategy for gamma\n            self.population_size = min(self.population_size + 1, self.budget - eval_count)\n\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Enhanced Adaptive Swarm Harmony Optimization by adjusting the decay strategy of `gamma` for improved exploration-exploitation balance.", "configspace": "", "generation": 16, "fitness": 0.8914306869457816, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.891 with standard deviation 0.007. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "a3a505a3-1f4b-4422-9c67-dbfd179f3151", "metadata": {"aucs": [0.886794628792371, 0.8860357532155214, 0.9014616788294525], "final_y": [0.11947817310202191, 0.11464710228293529, 0.11606291966896987]}, "mutation_prompt": null}
{"id": "c32f37fd-ec36-40a7-b5fe-5d308bc98948", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim  # Adaptive based on dimension\n        self.harmony_memory_size = max(5, dim)  # Size of harmony memory\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.phi = 0.5  # Harmony memory consideration rate\n        self.beta = 1.0  # Parameter to control randomization\n        self.gamma = 0.5  # Parameter to control local search\n\n    def __call__(self, func):\n        # Initialize harmony memory with random solutions\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        eval_count = self.harmony_memory_size\n\n        while eval_count < self.budget:\n            # Generate a new harmony vector\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.phi:\n                    idx = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = self.harmony_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n                # Adjust new harmony using pitch adjustment\n                if np.random.rand() < self.gamma:\n                    self.beta = np.random.uniform(0.5, 1.5)  # Adaptive pitch adjustment\n                    new_harmony[i] += self.beta * (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n\n            # Ensure new harmony is within bounds\n            new_harmony = np.clip(new_harmony, lb, ub)\n\n            # Evaluate the new harmony\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            # Update harmony memory if the new solution is better\n            worst_idx = np.argmax(func_values)\n            if new_value < func_values[worst_idx]:\n                self.harmony_memory[worst_idx] = new_harmony\n                func_values[worst_idx] = new_value\n                self.phi = min(1.0, self.phi + 0.01)  # Increase phi\n\n            self.gamma *= 0.99  # Decay strategy for gamma\n            self.beta *= 0.99  # Adaptive beta decay\n\n        # Return the best found solution and its value\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Improve convergence by adapting both gamma and beta using evaluation progress to balance exploration and exploitation.", "configspace": "", "generation": 17, "fitness": 0.8941297735577579, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.894 with standard deviation 0.009. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "f5698e46-afc9-48a0-868d-720a25779eef", "metadata": {"aucs": [0.8849954224361275, 0.90615189221952, 0.8912420060176266], "final_y": [0.1236962955609765, 0.11396541184310027, 0.1155673956062424]}, "mutation_prompt": null}
{"id": "8f865818-d6ec-4562-8207-94ab3de2746f", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim\n        self.harmony_memory_size = max(5, dim)\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.secondary_memory_size = max(3, dim // 2)\n        self.secondary_memory = np.random.rand(self.secondary_memory_size, dim)\n        self.phi = 0.5\n        self.beta = 1.0\n        self.gamma = 0.5\n        self.dynamic_adaptation_rate = 0.005\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        self.secondary_memory = lb + (ub - lb) * np.random.rand(self.secondary_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        secondary_values = np.array([func(sm) for sm in self.secondary_memory])\n        eval_count = self.harmony_memory_size + self.secondary_memory_size\n\n        while eval_count < self.budget:\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.phi:\n                    if np.random.rand() < 0.5:\n                        idx = np.random.randint(self.harmony_memory_size)\n                        new_harmony[i] = self.harmony_memory[idx, i]\n                    else:\n                        idx = np.random.randint(self.secondary_memory_size)\n                        new_harmony[i] = self.secondary_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n                if np.random.rand() < self.gamma:\n                    self.beta = np.random.uniform(0.5, 1.5)\n                    # Change made here: adaptive beta scaling\n                    new_harmony[i] += self.beta * (ub[i] - lb[i]) * (np.random.rand() - 0.5) * (1 - eval_count / self.budget)\n\n            new_harmony = np.clip(new_harmony, lb, ub)\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            if new_value < max(func_values.max(), secondary_values.max()):\n                if new_value < func_values.max():\n                    worst_idx = np.argmax(func_values)\n                    self.harmony_memory[worst_idx] = new_harmony\n                    func_values[worst_idx] = new_value\n                else:\n                    worst_idx = np.argmax(secondary_values)\n                    self.secondary_memory[worst_idx] = new_harmony\n                    secondary_values[worst_idx] = new_value\n\n                self.phi = min(1.0, self.phi + self.dynamic_adaptation_rate)\n                self.harmony_memory_size = min(self.population_size, int(self.harmony_memory_size * 1.05))  # Adaptive memory size\n\n            self.gamma = max(0.1, self.gamma * 0.97)  # Self-tuning gamma\n\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Enhanced Adaptive Swarm Harmony Optimization by introducing an adaptive beta scaling strategy for improved exploration.", "configspace": "", "generation": 17, "fitness": 0.8934358009579011, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.893 with standard deviation 0.005. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "78eaa883-60a3-4fca-9804-7a326fda381e", "metadata": {"aucs": [0.8861993319865829, 0.89891860677843, 0.8951894641086906], "final_y": [0.11657783059124827, 0.11284372758190697, 0.11635585378291824]}, "mutation_prompt": null}
{"id": "092eadfa-87e6-4127-841e-711047461116", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim  # Adaptive based on dimension\n        self.harmony_memory_size = max(5, dim)  # Size of harmony memory\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.phi = 0.5  # Harmony memory consideration rate\n        self.beta = 1.0  # Parameter to control randomization\n        self.gamma = 0.5  # Parameter to control local search\n\n    def __call__(self, func):\n        # Initialize harmony memory with random solutions\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        eval_count = self.harmony_memory_size\n\n        while eval_count < self.budget:\n            # Generate a new harmony vector\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.phi:\n                    idx = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = self.harmony_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n                # Adjust new harmony using pitch adjustment\n                if np.random.rand() < self.gamma:\n                    self.beta = np.random.uniform(0.3, 1.2)  # Adjusted pitch adjustment limit\n                    new_harmony[i] += self.beta * (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n\n            # Ensure new harmony is within bounds\n            new_harmony = np.clip(new_harmony, lb, ub)\n\n            # Evaluate the new harmony\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            # Update harmony memory if the new solution is better\n            worst_idx = np.argmax(func_values)\n            if new_value < func_values[worst_idx]:\n                self.harmony_memory[worst_idx] = new_harmony\n                func_values[worst_idx] = new_value\n                self.phi *= 0.99  # Decay strategy for phi\n\n            self.gamma *= 0.99  # Decay strategy for gamma\n\n        # Return the best found solution and its value\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Improved Adaptive Swarm Harmony Optimization by introducing a decay strategy for harmony memory consideration rate and dynamic pitch adjustment limits for enhanced exploration and convergence.", "configspace": "", "generation": 17, "fitness": 0.8539598982292391, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.854 with standard deviation 0.024. And the mean value of best solutions found was 0.129 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "f5698e46-afc9-48a0-868d-720a25779eef", "metadata": {"aucs": [0.8305620680913051, 0.8439533357533908, 0.8873642908430214], "final_y": [0.13755055924088866, 0.1316185414548663, 0.11641113210786402]}, "mutation_prompt": null}
{"id": "816d19f3-c46b-4352-a3a9-397b34d6d029", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim  # Adaptive based on dimension\n        self.harmony_memory_size = max(5, dim)  # Size of harmony memory\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.phi = 0.5  # Harmony memory consideration rate\n        self.beta = 1.0  # Parameter to control randomization\n        self.gamma = 0.5  # Parameter to control local search\n\n    def __call__(self, func):\n        # Initialize harmony memory with random solutions\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        eval_count = self.harmony_memory_size\n\n        while eval_count < self.budget:\n            # Generate a new harmony vector\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.phi:\n                    idx = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = self.harmony_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n                # Adjust new harmony using pitch adjustment\n                if np.random.rand() < self.gamma:\n                    self.beta = np.random.uniform(0.5, 1.5)  # Adaptive pitch adjustment\n                    new_harmony[i] += self.beta * (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n\n            # Ensure new harmony is within bounds\n            new_harmony = np.clip(new_harmony, lb, ub)\n\n            # Evaluate the new harmony\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            # Update harmony memory if the new solution is better\n            worst_idx = np.argmax(func_values)\n            if new_value < func_values[worst_idx]:\n                self.harmony_memory[worst_idx] = new_harmony\n                func_values[worst_idx] = new_value\n                self.phi = min(1.0, self.phi + 0.01)  # Increase phi\n\n            self.gamma *= 0.99 ** (eval_count / self.budget)  # Nonlinear decay strategy for gamma\n\n        # Return the best found solution and its value\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Refined Adaptive Swarm Harmony Optimization by implementing a nonlinear decay strategy for gamma to balance exploration and exploitation dynamically.", "configspace": "", "generation": 17, "fitness": 0.8817026583983761, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.882 with standard deviation 0.005. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "f5698e46-afc9-48a0-868d-720a25779eef", "metadata": {"aucs": [0.8796757240118314, 0.8768417740002752, 0.8885904771830221], "final_y": [0.11960244037379131, 0.11526998619687534, 0.11433687110695157]}, "mutation_prompt": null}
{"id": "2d899f5d-40b9-4568-9157-5a5a03ecf33a", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim\n        self.harmony_memory_size = max(5, dim)\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.phi = 0.5\n        self.beta = 1.0\n        self.gamma = 0.5\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        eval_count = self.harmony_memory_size\n\n        while eval_count < self.budget:\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.phi:\n                    idx = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = self.harmony_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n                if np.random.rand() < self.gamma:\n                    self.beta = 0.5 + np.sin(2 * np.pi * eval_count / self.budget)  # Sinusoidal adaptive pitch adjustment\n                    new_harmony[i] += self.beta * (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n\n            new_harmony = np.clip(new_harmony, lb, ub)\n\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(func_values)\n            if new_value < func_values[worst_idx]:\n                self.harmony_memory[worst_idx] = new_harmony\n                func_values[worst_idx] = new_value\n                self.phi = min(1.0, self.phi + (0.02 * (1 - eval_count / self.budget)))  # Improved dynamic phi\n\n            self.gamma *= 0.98  # Slightly faster decay strategy for gamma\n            self.population_size = min(self.population_size + 1, self.budget - eval_count)\n\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Modified the pitch adjustment strategy by introducing a sinusoidal decay for beta to improve solution diversity.", "configspace": "", "generation": 17, "fitness": 0.8856736293458739, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.886 with standard deviation 0.004. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "a3a505a3-1f4b-4422-9c67-dbfd179f3151", "metadata": {"aucs": [0.8846768524900954, 0.8905364930840636, 0.8818075424634629], "final_y": [0.12523149657707355, 0.11215876849541839, 0.1193600233463783]}, "mutation_prompt": null}
{"id": "78b374c3-be51-4d30-a48d-21d563c5defe", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim\n        self.harmony_memory_size = max(5, dim)\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.phi = 0.5\n        self.beta = 1.0\n        self.gamma = 0.5\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        eval_count = self.harmony_memory_size\n\n        while eval_count < self.budget:\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.phi:\n                    idx = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = self.harmony_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n                if np.random.rand() < self.gamma:\n                    self.beta = 0.5 + np.exp(-4 * eval_count / self.budget)  # Non-linear adaptive pitch adjustment\n                    new_harmony[i] += self.beta * (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n\n            new_harmony = np.clip(new_harmony, lb, ub)\n\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(func_values)\n            if new_value < func_values[worst_idx]:\n                self.harmony_memory[worst_idx] = new_harmony\n                func_values[worst_idx] = new_value\n                self.phi = min(1.0, self.phi + (0.02 * (1 - eval_count / self.budget)))  # Improved dynamic phi\n\n            self.gamma *= 0.98  # Enhanced non-linear decay strategy for gamma\n            self.population_size = min(self.population_size + 1, self.budget - eval_count)\n\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Refined Adaptive Swarm Harmony Optimization with an enhanced non-linear gamma decay strategy for improved exploration-exploitation dynamics.", "configspace": "", "generation": 18, "fitness": 0.8612981745200564, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.861 with standard deviation 0.003. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "eda27496-a116-421a-b9a0-9ddc0d2baf20", "metadata": {"aucs": [0.8601890893294942, 0.8578269771458852, 0.8658784570847899], "final_y": [0.13253667287543525, 0.13468687414621738, 0.133258183086422]}, "mutation_prompt": null}
{"id": "0fc7cf94-6297-41aa-8d8c-e1677c677ad2", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim\n        self.harmony_memory_size = max(5, dim)\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.phi = 0.5\n        self.beta = 1.0\n        self.gamma = 0.5\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        eval_count = self.harmony_memory_size\n\n        while eval_count < self.budget:\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.phi:\n                    idx = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = self.harmony_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n                if np.random.rand() < self.gamma:\n                    self.beta = 0.5 + np.sin(2 * np.pi * eval_count / self.budget) * np.exp(-0.01 * eval_count)  # Altered beta calculation\n                    new_harmony[i] += self.beta * (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n\n            new_harmony = np.clip(new_harmony, lb, ub)\n\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(func_values)\n            if new_value < func_values[worst_idx]:\n                self.harmony_memory[worst_idx] = new_harmony\n                func_values[worst_idx] = new_value\n                self.phi = min(1.0, self.phi + (0.02 * (1 - eval_count / self.budget)))  # Improved dynamic phi\n\n            self.gamma *= 0.98  # Slightly faster decay strategy for gamma\n            self.population_size = min(self.population_size + 1, self.budget - eval_count)\n\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Improved solution diversity by adjusting the beta calculation to incorporate an exponential decay factor.", "configspace": "", "generation": 18, "fitness": 0.8636221369427565, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.864 with standard deviation 0.029. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "2d899f5d-40b9-4568-9157-5a5a03ecf33a", "metadata": {"aucs": [0.8968514803149275, 0.826927250469305, 0.8670876800440369], "final_y": [0.12186864377724849, 0.1437950882277863, 0.13322243918720078]}, "mutation_prompt": null}
{"id": "7885c3a3-aecc-4e5f-8fdb-53ce776d84eb", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim\n        self.harmony_memory_size = max(5, dim)\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.phi = 0.5\n        self.beta = 1.0\n        self.gamma = 0.5\n        self.feedback_threshold = 0.1  # New parameter for feedback adjustment\n        self.adaptive_gamma = True  # New parameter to enable dual decay strategy\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        eval_count = self.harmony_memory_size\n\n        while eval_count < self.budget:\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.phi:\n                    idx = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = self.harmony_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n                if np.random.rand() < self.gamma:\n                    self.beta = np.random.uniform(0.5, 1.5)\n                    new_harmony[i] += self.beta * (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n\n            new_harmony = np.clip(new_harmony, lb, ub)\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            if new_value < func_values.max():\n                worst_idx = np.argmax(func_values)\n                self.harmony_memory[worst_idx] = new_harmony\n                func_values[worst_idx] = new_value\n                self.phi = min(1.0, self.phi + 0.01)\n\n            if self.adaptive_gamma:\n                if new_value <= func_values.mean() - self.feedback_threshold:\n                    self.gamma *= 0.95\n                    self.beta *= 0.95\n                else:\n                    self.gamma *= 1.05\n                    self.beta *= 1.05\n\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Introduced a dual decay strategy for gamma and adaptive beta using a feedback-based mechanism to enhance exploration and exploitation balance for improved convergence.", "configspace": "", "generation": 18, "fitness": 0.8566261118794972, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.857 with standard deviation 0.059. And the mean value of best solutions found was 0.134 (0. is the best) with standard deviation 0.018.", "error": "", "parent_id": "f5698e46-afc9-48a0-868d-720a25779eef", "metadata": {"aucs": [0.7729488239827946, 0.9001121282123848, 0.8968173834433121], "final_y": [0.1593696234205163, 0.12190920490535839, 0.1217361345841762]}, "mutation_prompt": null}
{"id": "57587df2-e9f2-40d5-80ae-eabafdf8149b", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim  # Adaptive based on dimension\n        self.harmony_memory_size = max(5, dim)  # Size of harmony memory\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.phi = 0.5  # Harmony memory consideration rate\n        self.beta = 1.0  # Parameter to control randomization\n        self.gamma = 0.5  # Parameter to control local search\n\n    def __call__(self, func):\n        # Initialize harmony memory with random solutions\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        eval_count = self.harmony_memory_size\n\n        while eval_count < self.budget:\n            # Generate a new harmony vector\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.phi:\n                    idx = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = self.harmony_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n                # Adjust new harmony using pitch adjustment\n                if np.random.rand() < self.gamma:\n                    self.beta = np.random.uniform(0.5, 1.5)  # Adaptive pitch adjustment\n                    new_harmony[i] += self.beta * (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n\n            # Ensure new harmony is within bounds\n            new_harmony = np.clip(new_harmony, lb, ub)\n\n            # Evaluate the new harmony\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            # Update harmony memory if the new solution is better\n            worst_idx = np.argmax(func_values)\n            if new_value < func_values[worst_idx]:\n                self.harmony_memory[worst_idx] = new_harmony\n                func_values[worst_idx] = new_value\n                self.phi = min(1.0, self.phi + 0.01)  # Increase phi\n\n            progress = eval_count / self.budget\n            self.gamma *= (1 - 0.5 * progress)  # Dynamic decay strategy for gamma\n            self.beta *= (1 - 0.5 * progress)  # Dynamic decay strategy for beta\n\n        # Return the best found solution and its value\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Improved convergence by adjusting the decay strategy of gamma and beta dynamically based on the iteration progress.", "configspace": "", "generation": 18, "fitness": 0.8605559736683245, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.861 with standard deviation 0.013. And the mean value of best solutions found was 0.134 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "c32f37fd-ec36-40a7-b5fe-5d308bc98948", "metadata": {"aucs": [0.8599156254548869, 0.84467225196383, 0.8770800435862566], "final_y": [0.13365494991491023, 0.13889038831198286, 0.12883302307709854]}, "mutation_prompt": null}
{"id": "104e3974-aa61-43e0-8c22-61d0ed582605", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim\n        self.harmony_memory_size = max(5, dim)\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.phi = 0.5\n        self.beta = 1.0\n        self.gamma = 0.5\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        eval_count = self.harmony_memory_size\n\n        while eval_count < self.budget:\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.phi:\n                    idx = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = self.harmony_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n                if np.random.rand() < self.gamma:\n                    self.beta = 0.5 + np.exp(-4 * eval_count / self.budget)  # Non-linear adaptive pitch adjustment\n                    new_harmony[i] += self.beta * (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n\n            new_harmony = np.clip(new_harmony, lb, ub)\n\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(func_values)\n            if new_value < func_values[worst_idx]:\n                self.harmony_memory[worst_idx] = new_harmony\n                func_values[worst_idx] = new_value\n                self.phi = min(1.0, self.phi + (0.02 * (1 - eval_count / self.budget)))  # Improved dynamic phi\n\n            self.gamma *= (0.99 + 0.01 * (eval_count / self.budget))  # Dynamic scaling for gamma\n            self.population_size = min(self.population_size + 1, self.budget - eval_count)\n\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Refine the Adaptive Swarm Harmony Optimization by introducing a dynamic scaling factor for gamma to better adapt exploration and exploitation phases.", "configspace": "", "generation": 18, "fitness": 0.866830892629781, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.867 with standard deviation 0.020. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "eda27496-a116-421a-b9a0-9ddc0d2baf20", "metadata": {"aucs": [0.895216009156404, 0.8517491754182172, 0.8535274933147214], "final_y": [0.12010896769735879, 0.1369833408020248, 0.13603282669758054]}, "mutation_prompt": null}
{"id": "b051decc-93f8-4096-b460-18518e20e01c", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim\n        self.harmony_memory_size = max(5, dim)\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.phi = 0.5\n        self.beta = 1.0\n        self.gamma = 0.5\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        eval_count = self.harmony_memory_size\n\n        while eval_count < self.budget:\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.phi:\n                    idx = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = self.harmony_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n                if np.random.rand() < self.gamma:\n                    self.beta = 0.5 + (eval_count / self.budget)  # Dynamic beta adaptation\n                    new_harmony[i] += self.beta * (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n\n            new_harmony = np.clip(new_harmony, lb, ub)\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(func_values)\n            if new_value < func_values[worst_idx]:\n                self.harmony_memory[worst_idx] = new_harmony\n                func_values[worst_idx] = new_value\n                self.phi = min(1.0, self.phi + 0.02)  # Increased phi increment\n\n            self.gamma *= 0.98  # Enhanced decay strategy for gamma\n            self.beta *= 0.97  # Adjusted beta decay\n\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Improve convergence and diversity by introducing a dynamic pitch adjustment strategy and adaptive memory consideration rate.", "configspace": "", "generation": 19, "fitness": 0.8693896690174583, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.869 with standard deviation 0.032. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "c32f37fd-ec36-40a7-b5fe-5d308bc98948", "metadata": {"aucs": [0.8945061628718566, 0.8236285158689954, 0.8900343283115228], "final_y": [0.12289185653791312, 0.14651795907745613, 0.12242812140275272]}, "mutation_prompt": null}
{"id": "3c2f6c6e-2278-4230-afa3-413d6055f104", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim\n        self.harmony_memory_size = max(5, dim)\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.phi = 0.5\n        self.beta = 1.0\n        self.gamma = 0.5\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        eval_count = self.harmony_memory_size\n\n        while eval_count < self.budget:\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.phi:\n                    idx = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = self.harmony_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n                if np.random.rand() < self.gamma:\n                    self.beta = 0.5 + np.exp(-4 * eval_count / self.budget)\n                    new_harmony[i] += self.beta * (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n\n            new_harmony = np.clip(new_harmony, lb, ub)\n\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(func_values)\n            if new_value < func_values[worst_idx]:\n                self.harmony_memory[worst_idx] = new_harmony\n                func_values[worst_idx] = new_value\n                self.phi = min(1.0, self.phi + (0.02 * (1 - eval_count / self.budget)))\n\n            improvement_rate = (np.min(func_values) - new_value) / (np.max(func_values) - np.min(func_values) + 1e-10)\n            self.gamma *= 0.99 + 0.01 * improvement_rate  # Adaptive decay strategy for gamma\n            self.population_size = min(self.population_size + 1, self.budget - eval_count)\n\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Enhanced Adaptive Swarm Harmony Optimization with adaptive gamma decay based on current improvement rate.", "configspace": "", "generation": 19, "fitness": 0.8766634992148917, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.877 with standard deviation 0.017. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "eda27496-a116-421a-b9a0-9ddc0d2baf20", "metadata": {"aucs": [0.8542331563294236, 0.8820339926389951, 0.8937233486762564], "final_y": [0.1359605828585927, 0.127015731620838, 0.12149958397253058]}, "mutation_prompt": null}
{"id": "37b40bec-a089-4c37-bda3-e973fd1355e0", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim  # Adaptive based on dimension\n        self.harmony_memory_size = max(5, dim)  # Size of harmony memory\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.phi = 0.5  # Harmony memory consideration rate\n        self.beta = 1.0  # Parameter to control randomization\n        self.gamma = 0.5  # Parameter to control local search\n\n    def __call__(self, func):\n        # Initialize harmony memory with random solutions\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        eval_count = self.harmony_memory_size\n        \n        while eval_count < self.budget:\n            new_harmony = np.zeros(self.dim)\n            learning_rate = 0.1 + 0.9 * eval_count / self.budget  # Dynamic learning rate\n            for i in range(self.dim):\n                if np.random.rand() < self.phi:\n                    idx = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = self.harmony_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n                if np.random.rand() < self.gamma:\n                    adaptive_beta = 0.5 + learning_rate  # Dynamic pitch adjustment\n                    new_harmony[i] += adaptive_beta * (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n\n            new_harmony = np.clip(new_harmony, lb, ub)\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(func_values)\n            if new_value < func_values[worst_idx]:\n                self.harmony_memory[worst_idx] = (1 - learning_rate) * self.harmony_memory[worst_idx] + learning_rate * new_harmony\n                func_values[worst_idx] = new_value\n                self.phi = min(1.0, self.phi + 0.01)\n\n            self.gamma *= 0.98  # Adjusted decay strategy for gamma\n            self.beta *= 0.97  # Adjusted adaptive beta decay\n\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Optimize convergence by introducing a dynamic pitch adjustment strategy, adapting beta and gamma with evaluation progress, and employing a learning-based memory update.", "configspace": "", "generation": 19, "fitness": 0.8678402887802831, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.868 with standard deviation 0.007. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "c32f37fd-ec36-40a7-b5fe-5d308bc98948", "metadata": {"aucs": [0.8692815610625692, 0.875794864304433, 0.8584444409738472], "final_y": [0.12243592690390392, 0.12575328170239786, 0.13341181257103363]}, "mutation_prompt": null}
{"id": "c28ace80-8ea1-4d97-883d-a7a76d8dd58a", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim  # Adaptive based on dimension\n        self.harmony_memory_size = max(5, dim)  # Size of harmony memory\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.phi = 0.5  # Harmony memory consideration rate\n        self.beta = 1.0  # Parameter to control randomization\n        self.gamma = 0.5  # Parameter to control local search\n\n    def __call__(self, func):\n        # Initialize harmony memory with random solutions\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        eval_count = self.harmony_memory_size\n\n        while eval_count < self.budget:\n            # Generate a new harmony vector\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.phi:\n                    idx = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = self.harmony_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n                # Adjust new harmony using pitch adjustment\n                if np.random.rand() < self.gamma:\n                    self.beta = np.random.uniform(0.3, 1.7)  # Adaptive pitch adjustment\n                    new_harmony[i] += self.beta * (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n\n            # Ensure new harmony is within bounds\n            new_harmony = np.clip(new_harmony, lb, ub)\n\n            # Evaluate the new harmony\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            # Update harmony memory if the new solution is better\n            worst_idx = np.argmax(func_values)\n            if new_value < func_values[worst_idx]:\n                self.harmony_memory[worst_idx] = new_harmony\n                func_values[worst_idx] = new_value\n                self.phi = min(1.0, self.phi + 0.01)  # Increase phi\n\n            self.gamma *= 0.99  # Decay strategy for gamma\n            self.beta *= 0.99  # Adaptive beta decay\n\n        # Return the best found solution and its value\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Enhanced exploration by increasing variance in pitch adjustment through a wider beta range.", "configspace": "", "generation": 19, "fitness": 0.8894142930438922, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.889 with standard deviation 0.011. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "c32f37fd-ec36-40a7-b5fe-5d308bc98948", "metadata": {"aucs": [0.9050500155568881, 0.8790457915352686, 0.8841470720395198], "final_y": [0.11568228966635474, 0.12213486445178035, 0.12366588301152048]}, "mutation_prompt": null}
{"id": "0ba263cc-2c06-446d-8a44-aa4d73ff8adc", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonyOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * dim  # Adaptive based on dimension\n        self.harmony_memory_size = max(5, dim)  # Size of harmony memory\n        self.harmony_memory = np.random.rand(self.harmony_memory_size, dim)\n        self.phi = 0.5  # Harmony memory consideration rate\n        self.beta = 1.0  # Parameter to control randomization\n        self.gamma = 0.5  # Parameter to control local search\n\n    def __call__(self, func):\n        # Initialize harmony memory with random solutions\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        self.harmony_memory = lb + (ub - lb) * np.random.rand(self.harmony_memory_size, self.dim)\n        func_values = np.array([func(hm) for hm in self.harmony_memory])\n        eval_count = self.harmony_memory_size\n\n        while eval_count < self.budget:\n            # Generate a new harmony vector\n            new_harmony = np.zeros(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.phi:\n                    idx = np.random.randint(self.harmony_memory_size)\n                    new_harmony[i] = self.harmony_memory[idx, i]\n                else:\n                    new_harmony[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n                # Adjust new harmony using pitch adjustment\n                if np.random.rand() < self.gamma:\n                    self.beta = np.random.uniform(0.5, 1.5)  # Adaptive pitch adjustment\n                    new_harmony[i] += self.beta * (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n\n            # Ensure new harmony is within bounds\n            new_harmony = np.clip(new_harmony, lb, ub)\n\n            # Evaluate the new harmony\n            new_value = func(new_harmony)\n            eval_count += 1\n\n            # Update harmony memory if the new solution is better\n            worst_idx = np.argmax(func_values)\n            if new_value < func_values[worst_idx]:\n                self.harmony_memory[worst_idx] = new_harmony\n                func_values[worst_idx] = new_value\n                self.phi = min(1.0, self.phi + np.random.uniform(0.01, 0.05))  # Stochastically increase phi\n\n            self.gamma *= 0.99  # Decay strategy for gamma\n\n        # Return the best found solution and its value\n        best_idx = np.argmin(func_values)\n        return self.harmony_memory[best_idx], func_values[best_idx]", "name": "AdaptiveSwarmHarmonyOptimization", "description": "Introduced a stochastic update of the harmony memory consideration rate 'phi' to improve exploration capabilities.", "configspace": "", "generation": 19, "fitness": 0.8818533154151843, "feedback": "The algorithm AdaptiveSwarmHarmonyOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.882 with standard deviation 0.014. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "f5698e46-afc9-48a0-868d-720a25779eef", "metadata": {"aucs": [0.8914845254947217, 0.8619762700843243, 0.8920991506665069], "final_y": [0.1176341521457257, 0.1318375359528814, 0.1229584636221217]}, "mutation_prompt": null}
