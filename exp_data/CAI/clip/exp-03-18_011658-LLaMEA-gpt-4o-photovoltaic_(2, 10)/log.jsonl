{"id": "0cdb3c2f-96b0-402e-9119-fc07a28f54d6", "solution": "import numpy as np\n\nclass Particle:\n    def __init__(self, dim, bounds):\n        self.position = np.random.uniform(bounds.lb, bounds.ub, dim)\n        self.velocity = np.random.uniform(-1, 1, dim)\n        self.best_position = np.copy(self.position)\n        self.best_value = float('inf')\n\nclass ParticleSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = []\n        self.bounds = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive (particle) weight\n        self.c2 = 1.5  # social (swarm) weight\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        num_particles = min(40, self.budget // 5)  # adaptively choosing swarm size\n        self.particles = [Particle(self.dim, self.bounds) for _ in range(num_particles)]\n        \n        for _ in range(self.budget):\n            for particle in self.particles:\n                fitness = func(particle.position)\n                if fitness < particle.best_value:\n                    particle.best_value = fitness\n                    particle.best_position = np.copy(particle.position)\n\n                if fitness < self.global_best_value:\n                    self.global_best_value = fitness\n                    self.global_best_position = np.copy(particle.position)\n\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                particle.velocity = (self.w * particle.velocity +\n                                     self.c1 * r1 * (particle.best_position - particle.position) +\n                                     self.c2 * r2 * (self.global_best_position - particle.position))\n                # Perform differential mutation\n                a, b, c = np.random.choice(self.particles, 3, replace=False)\n                F = np.random.uniform(0.5, 0.9)\n                mutant = a.position + F * (b.position - c.position)\n                mutant = np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n                trial = np.copy(particle.position)\n                for j in range(self.dim):\n                    if np.random.rand() < 0.5:\n                        trial[j] = mutant[j]\n\n                trial_fitness = func(trial)\n                if trial_fitness < fitness:\n                    particle.position = trial\n                else:\n                    particle.position += particle.velocity\n\n        return self.global_best_position, self.global_best_value", "name": "Particle", "description": "The algorithm combines particle swarm dynamics with adaptive differential mutation to enhance exploration and exploitation capabilities in high-dimensional black box optimization tasks.", "configspace": "", "generation": 0, "fitness": -Infinity, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/scratch/hyin/LLaMEA/llamea/llamea.py\", line 194, in initialize_single\n    new_individual = self.evaluate_fitness(new_individual)\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/scratch/hyin/LLaMEA/llamea/llamea.py\", line 288, in evaluate_fitness\n    updated_individual = self.f(individual, self.logger)\n                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/scratch/hyin/LLaMEA/benchmarks/tuto_global_optimization_photonics/exp_photonic.py\", line 148, in evaluatePhotonic\n    algorithm = globals()[algorithm_name](budget=budget, dim=dim)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nTypeError: Particle.__init__() got an unexpected keyword argument 'budget'\n.", "error": "TypeError(\"Particle.__init__() got an unexpected keyword argument 'budget'\")Traceback (most recent call last):\n  File \"/scratch/hyin/LLaMEA/llamea/llamea.py\", line 194, in initialize_single\n    new_individual = self.evaluate_fitness(new_individual)\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/scratch/hyin/LLaMEA/llamea/llamea.py\", line 288, in evaluate_fitness\n    updated_individual = self.f(individual, self.logger)\n                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/scratch/hyin/LLaMEA/benchmarks/tuto_global_optimization_photonics/exp_photonic.py\", line 148, in evaluatePhotonic\n    algorithm = globals()[algorithm_name](budget=budget, dim=dim)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nTypeError: Particle.__init__() got an unexpected keyword argument 'budget'\n", "parent_id": null, "metadata": {}, "mutation_prompt": null}
{"id": "5e0c5662-6e8d-4ef4-b52e-c3a78c165ac3", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.5   # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            # Evaluate and update personal bests\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            # DE Mutation and Crossover\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "A hybrid metaheuristic algorithm combining particle swarm optimization with adaptive differential evolution for efficient exploration and exploitation in high-dimensional search spaces.", "configspace": "", "generation": 0, "fitness": 0.8600835910864726, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.860 with standard deviation 0.037. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": null, "metadata": {"aucs": [0.8104655120499382, 0.872155493351243, 0.8976297678582367], "final_y": [0.14479057941038298, 0.12001420732134793, 0.1150248257827764]}, "mutation_prompt": null}
{"id": "14debac8-89c3-4f31-b17b-7c936680a51f", "solution": "import numpy as np\n\nclass Particle:\n    def __init__(self, dim, bounds):\n        self.position = np.random.uniform(bounds.lb, bounds.ub, dim)\n        self.velocity = np.random.uniform(-1, 1, dim)\n        self.best_position = np.copy(self.position)\n        self.best_value = float('inf')\n\nclass ParticleSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = []\n        self.bounds = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive (particle) weight\n        self.c2 = 1.5  # social (swarm) weight\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        num_particles = min(40, self.budget // 5)  # adaptively choosing swarm size\n        self.particles = [Particle(self.dim, self.bounds) for _ in range(num_particles)]\n        \n        for iteration in range(self.budget):\n            for particle in self.particles:\n                fitness = func(particle.position)\n                if fitness < particle.best_value:\n                    particle.best_value = fitness\n                    particle.best_position = np.copy(particle.position)\n\n                if fitness < self.global_best_value:\n                    self.global_best_value = fitness\n                    self.global_best_position = np.copy(particle.position)\n\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                self.w = 0.9 - (0.5 * (iteration / self.budget))  # adaptive inertia weight adjustment\n                particle.velocity = (self.w * particle.velocity +\n                                     self.c1 * r1 * (particle.best_position - particle.position) +\n                                     self.c2 * r2 * (self.global_best_position - particle.position))\n                # Perform differential mutation\n                a, b, c = np.random.choice(self.particles, 3, replace=False)\n                F = np.random.uniform(0.5, 0.9)\n                mutant = a.position + F * (b.position - c.position)\n                mutant = np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n                trial = np.copy(particle.position)\n                for j in range(self.dim):\n                    if np.random.rand() < 0.5:\n                        trial[j] = mutant[j]\n\n                trial_fitness = func(trial)\n                if trial_fitness < fitness:\n                    particle.position = trial\n                else:\n                    particle.position += particle.velocity\n\n        return self.global_best_position, self.global_best_value", "name": "Particle", "description": "The algorithm incorporates adaptive inertia weight adjustment to enhance convergence speed and solution accuracy in high-dimensional optimization tasks.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "An exception occurred: TypeError(\"Particle.__init__() got an unexpected keyword argument 'budget'\").", "error": "TypeError(\"Particle.__init__() got an unexpected keyword argument 'budget'\")", "parent_id": "0cdb3c2f-96b0-402e-9119-fc07a28f54d6", "metadata": {}, "mutation_prompt": null}
{"id": "369d5868-7a35-42f8-af30-5b2739ea0c8e", "solution": "import numpy as np\n\nclass Particle:\n    def __init__(self, dim, bounds):\n        self.position = np.random.uniform(bounds.lb, bounds.ub, dim)\n        self.velocity = np.random.uniform(-1, 1, dim)\n        self.best_position = np.copy(self.position)\n        self.best_value = float('inf')\n\nclass ParticleSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = []\n        self.bounds = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive (particle) weight\n        self.c2 = 1.5  # social (swarm) weight\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        num_particles = min(40, self.budget // 5)  # adaptively choosing swarm size\n        self.particles = [Particle(self.dim, self.bounds) for _ in range(num_particles)]\n        \n        for t in range(self.budget):\n            self.w = 0.9 - t * ((0.9 - 0.4) / self.budget)  # dynamically adjust inertia weight\n            for particle in self.particles:\n                fitness = func(particle.position)\n                if fitness < particle.best_value:\n                    particle.best_value = fitness\n                    particle.best_position = np.copy(particle.position)\n\n                if fitness < self.global_best_value:\n                    self.global_best_value = fitness\n                    self.global_best_position = np.copy(particle.position)\n\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                particle.velocity = (self.w * particle.velocity +\n                                     self.c1 * r1 * (particle.best_position - particle.position) +\n                                     self.c2 * r2 * (self.global_best_position - particle.position))\n                # Perform differential mutation\n                a, b, c = np.random.choice(self.particles, 3, replace=False)\n                F = np.random.uniform(0.5, 0.9)\n                mutant = a.position + F * (b.position - c.position)\n                mutant = np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n                trial = np.copy(particle.position)\n                for j in range(self.dim):\n                    if np.random.rand() < 0.5:\n                        trial[j] = mutant[j]\n\n                trial_fitness = func(trial)\n                if trial_fitness < fitness:\n                    particle.position = trial\n                else:\n                    particle.position += particle.velocity\n\n        return self.global_best_position, self.global_best_value", "name": "Particle", "description": "Incorporate a dynamic adjustment of inertia weight based on iteration progress to balance exploration and exploitation in high-dimensional optimization.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "An exception occurred: TypeError(\"Particle.__init__() got an unexpected keyword argument 'budget'\").", "error": "TypeError(\"Particle.__init__() got an unexpected keyword argument 'budget'\")", "parent_id": "0cdb3c2f-96b0-402e-9119-fc07a28f54d6", "metadata": {}, "mutation_prompt": null}
{"id": "9e91ba91-7ded-4bfe-9c99-b96fa99082f7", "solution": "import numpy as np\n\nclass Particle:\n    def __init__(self, dim, bounds):\n        self.position = np.random.uniform(bounds.lb, bounds.ub, dim)\n        self.velocity = np.random.uniform(-1, 1, dim)\n        self.best_position = np.copy(self.position)\n        self.best_value = float('inf')\n\nclass ParticleSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = []\n        self.bounds = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.w = 0.8  # inertia weight, slightly increased for better exploration\n        self.c1 = 1.5  # cognitive (particle) weight\n        self.c2 = 1.5  # social (swarm) weight\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        num_particles = min(40, self.budget // 5)  # adaptively choosing swarm size\n        self.particles = [Particle(self.dim, self.bounds) for _ in range(num_particles)]\n        \n        for _ in range(self.budget):\n            for particle in self.particles:\n                fitness = func(particle.position)\n                if fitness < particle.best_value:\n                    particle.best_value = fitness\n                    particle.best_position = np.copy(particle.position)\n\n                if fitness < self.global_best_value:\n                    self.global_best_value = fitness\n                    self.global_best_position = np.copy(particle.position)\n\n                # Update velocity with adaptive scaling\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                scale = np.random.uniform(0.5, 0.9) if fitness > self.global_best_value else 1.1\n                particle.velocity = (self.w * scale * particle.velocity +\n                                     self.c1 * r1 * (particle.best_position - particle.position) +\n                                     self.c2 * r2 * (self.global_best_position - particle.position))\n                # Perform differential mutation\n                a, b, c = np.random.choice(self.particles, 3, replace=False)\n                F = np.random.uniform(0.5, 0.9)\n                mutant = a.position + F * (b.position - c.position)\n                mutant = np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n                trial = np.copy(particle.position)\n                for j in range(self.dim):\n                    if np.random.rand() < 0.5:\n                        trial[j] = mutant[j]\n\n                trial_fitness = func(trial)\n                if trial_fitness < fitness:\n                    particle.position = trial\n                else:\n                    particle.position += particle.velocity\n\n        return self.global_best_position, self.global_best_value", "name": "Particle", "description": "The algorithm incorporates fuzzy adaptive velocity scaling in particle swarm dynamics to enhance convergence and robustness in high-dimensional optimization scenarios.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "An exception occurred: TypeError(\"Particle.__init__() got an unexpected keyword argument 'budget'\").", "error": "TypeError(\"Particle.__init__() got an unexpected keyword argument 'budget'\")", "parent_id": "0cdb3c2f-96b0-402e-9119-fc07a28f54d6", "metadata": {}, "mutation_prompt": null}
{"id": "8e19bdd7-feeb-419f-ae31-2a3ded7d2c02", "solution": "import numpy as np\n\nclass Particle:\n    def __init__(self, dim, bounds):\n        self.position = np.random.uniform(bounds.lb, bounds.ub, dim)\n        self.velocity = np.random.uniform(-1, 1, dim)\n        self.best_position = np.copy(self.position)\n        self.best_value = float('inf')\n\nclass ParticleSwarmDifferential:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particles = []\n        self.bounds = None\n        self.global_best_position = None\n        self.global_best_value = float('inf')\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive (particle) weight\n        self.c2 = 1.5  # social (swarm) weight\n        self.F_min = 0.5\n        self.F_max = 0.9\n\n    def __call__(self, func):\n        self.bounds = func.bounds\n        num_particles = min(40, self.budget // 5)  # adaptively choosing swarm size\n        self.particles = [Particle(self.dim, self.bounds) for _ in range(num_particles)]\n        \n        for _ in range(self.budget):\n            for particle in self.particles:\n                fitness = func(particle.position)\n                if fitness < particle.best_value:\n                    particle.best_value = fitness\n                    particle.best_position = np.copy(particle.position)\n\n                if fitness < self.global_best_value:\n                    self.global_best_value = fitness\n                    self.global_best_position = np.copy(particle.position)\n\n                # Update velocity\n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                self.w = 0.4 + 0.1 * np.random.rand()  # Adaptive inertia weight\n                particle.velocity = (self.w * particle.velocity +\n                                     self.c1 * r1 * (particle.best_position - particle.position) +\n                                     self.c2 * r2 * (self.global_best_position - particle.position))\n                # Perform differential mutation\n                a, b, c = np.random.choice(self.particles, 3, replace=False)\n                F = np.random.uniform(self.F_min, self.F_max)\n                mutant = a.position + F * (b.position - c.position)\n                mutant = np.clip(mutant, self.bounds.lb, self.bounds.ub)\n\n                trial = np.copy(particle.position)\n                for j in range(self.dim):\n                    if np.random.rand() < 0.5:\n                        trial[j] = mutant[j]\n\n                trial_fitness = func(trial)\n                if trial_fitness < fitness:\n                    particle.position = trial\n                else:\n                    particle.position += particle.velocity\n\n        return self.global_best_position, self.global_best_value", "name": "Particle", "description": "The algorithm uses adaptive learning rates for velocity and mutation adjustments to enhance convergence speed and accuracy. ", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "An exception occurred: TypeError(\"Particle.__init__() got an unexpected keyword argument 'budget'\").", "error": "TypeError(\"Particle.__init__() got an unexpected keyword argument 'budget'\")", "parent_id": "0cdb3c2f-96b0-402e-9119-fc07a28f54d6", "metadata": {}, "mutation_prompt": null}
{"id": "07bf653e-501a-4dc1-9a7f-3566ebed56d7", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.9   # starting inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            self.w = 0.9 - (0.5 * (eval_count / self.budget))  # Dynamic inertia weight\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            # Evaluate and update personal bests\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            # DE Mutation and Crossover\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "The algorithm incorporates a dynamic inertia weight strategy to enhance convergence properties and balance exploration and exploitation in high-dimensional optimization tasks.", "configspace": "", "generation": 1, "fitness": 0.8163852829013604, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.816 with standard deviation 0.014. And the mean value of best solutions found was 0.135 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "5e0c5662-6e8d-4ef4-b52e-c3a78c165ac3", "metadata": {"aucs": [0.8360064968257417, 0.8049959509440243, 0.8081534009343149], "final_y": [0.13642273413098127, 0.1447646401203978, 0.12412237586681407]}, "mutation_prompt": null}
{"id": "ab654e1b-c052-43d6-b154-670227adcb4a", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.9   # inertia weight adjusted to enhance exploration\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            # Evaluate and update personal bests\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            # DE Mutation and Crossover\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Enhanced global best selection with adaptive inertia weight adjustment for improved convergence in HybridPSO_DE.", "configspace": "", "generation": 1, "fitness": 0.8114858997397065, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.811 with standard deviation 0.011. And the mean value of best solutions found was 0.136 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "5e0c5662-6e8d-4ef4-b52e-c3a78c165ac3", "metadata": {"aucs": [0.799142404184966, 0.8264292728816957, 0.8088860221524578], "final_y": [0.13844147352447111, 0.12492803948715747, 0.14515898423050277]}, "mutation_prompt": null}
{"id": "dc83c8c7-ab2f-4cea-9349-97514a8cd19a", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w_max = 0.9  # max inertia weight\n        self.w_min = 0.4  # min inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n        self.dynamic_adjust = 0.05  # dynamic adjustment factor\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Adaptive inertia weight\n            self.w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)\n\n            # PSO Update with adaptive inertia\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            # Evaluate and update personal bests\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            # DE Mutation and Crossover with dynamic parameter tuning\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    self.diff_weight += self.dynamic_adjust * (1 - trial_score / scores[i])\n\n        return global_best", "name": "HybridPSO_DE", "description": "A novel integration of Particle Swarm Optimization and Differential Evolution with adaptive inertia and dynamic parameter tuning based on convergence trends to enhance search efficiency and solution quality.", "configspace": "", "generation": 1, "fitness": 0.8380738079951063, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.838 with standard deviation 0.022. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "5e0c5662-6e8d-4ef4-b52e-c3a78c165ac3", "metadata": {"aucs": [0.8160435179022374, 0.8309312425485159, 0.8672466635345655], "final_y": [0.13487995084958737, 0.12647364609466838, 0.12345400334446632]}, "mutation_prompt": null}
{"id": "e6de6acc-9407-4450-b05f-aa06d331fc04", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.7   # improved inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            # Evaluate and update personal bests\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            # DE Mutation and Crossover\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "A hybrid algorithm combining particle swarm optimization with adaptive differential evolution and improved inertia weight schedule for efficient exploration and exploitation in high-dimensional search spaces.", "configspace": "", "generation": 1, "fitness": 0.8409726942266191, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.841 with standard deviation 0.033. And the mean value of best solutions found was 0.129 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "5e0c5662-6e8d-4ef4-b52e-c3a78c165ac3", "metadata": {"aucs": [0.8684492506982369, 0.8598224038538278, 0.7946464281277925], "final_y": [0.12163452791435458, 0.12771851350187358, 0.13863195115693228]}, "mutation_prompt": null}
{"id": "fbe208ab-dbd2-4b76-81c9-9f43cd78f941", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.9   # increased inertia weight for better exploration\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        inertia_decay = 0.99  # add inertia decay for dynamic adjustment\n\n        while eval_count < self.budget:\n            # PSO Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            # Evaluate and update personal bests\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            # DE Mutation and Crossover\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n            self.w *= inertia_decay  # dynamically adjust inertia weight\n\n        return global_best", "name": "HybridPSO_DE", "description": "Enhanced hybrid metaheuristic algorithm integrating particle swarm optimization with differential evolution and adaptive inertia weight for improved convergence in high-dimensional search spaces.", "configspace": "", "generation": 1, "fitness": 0.8296058510138508, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.830 with standard deviation 0.025. And the mean value of best solutions found was 0.136 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "5e0c5662-6e8d-4ef4-b52e-c3a78c165ac3", "metadata": {"aucs": [0.860077963573989, 0.8308163265871358, 0.7979232628804271], "final_y": [0.12673466896384233, 0.13512075992015105, 0.1468968959753565]}, "mutation_prompt": null}
{"id": "efa9af05-3d57-4e90-acaf-08b11db002dd", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.5   # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = 0.4 + 0.1 * (1 - eval_count / self.budget)  # Dynamic inertia weight\n            velocities = w_dynamic * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            # Evaluate and update personal bests\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            # DE Mutation and Crossover\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Improved global exploration by adjusting the inertia weight dynamically based on the evaluation count.", "configspace": "", "generation": 1, "fitness": 0.855656079897364, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.856 with standard deviation 0.012. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "5e0c5662-6e8d-4ef4-b52e-c3a78c165ac3", "metadata": {"aucs": [0.8440233862056479, 0.8501803095141112, 0.872764543972333], "final_y": [0.13183808702259847, 0.12526592617895194, 0.12084800321445366]}, "mutation_prompt": null}
{"id": "dd984256-e2bc-4799-96f6-ee55d6d32bbd", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.5   # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = 0.4 + 0.1 * (1 - eval_count / self.budget)  # Dynamic inertia weight\n            c1_dynamic = self.c1 + 0.5 * (eval_count / self.budget)  # Dynamic cognitive component\n            c2_dynamic = self.c2 - 0.5 * (eval_count / self.budget)  # Dynamic social component\n            velocities = w_dynamic * velocities + c1_dynamic * r1 * (personal_best - pop) + c2_dynamic * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            # Evaluate and update personal bests\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            # DE Mutation and Crossover\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Enhanced exploration by adjusting cognitive and social components based on evaluation progress.", "configspace": "", "generation": 2, "fitness": 0.8664678777043128, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.866 with standard deviation 0.019. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "efa9af05-3d57-4e90-acaf-08b11db002dd", "metadata": {"aucs": [0.8401237197650269, 0.878406988150968, 0.8808729251969434], "final_y": [0.13080917785898727, 0.11908494658784774, 0.1183384082125859]}, "mutation_prompt": null}
{"id": "433b97f7-006b-4dc6-9d40-17869436f243", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.5   # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = 0.4 + 0.1 * (1 - eval_count / self.budget)  # Dynamic inertia weight\n            velocities = w_dynamic * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            # Evaluate and update personal bests\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            # DE Mutation and Crossover\n            pop_std = pop.std(axis=0)\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + (0.5 + 0.3 * (1 - pop_std.mean())) * (x2 - x3)  # Adaptive diff_weight based on diversity\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Introduce adaptive differential weight in DE based on diversity to enhance exploration and exploitation balance.", "configspace": "", "generation": 2, "fitness": 0.8656042728056543, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.866 with standard deviation 0.033. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "efa9af05-3d57-4e90-acaf-08b11db002dd", "metadata": {"aucs": [0.818811735261797, 0.8917227727795805, 0.8862783103755855], "final_y": [0.14499877588298893, 0.11729015645946161, 0.1138797930688693]}, "mutation_prompt": null}
{"id": "41d2e0c4-290c-4e21-b6bb-6d83857d476c", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.5   # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = 0.4 + 0.1 * (1 - eval_count / self.budget)  # Dynamic inertia weight\n            velocities = w_dynamic * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            # Evaluate and update personal bests\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            # DE Mutation and Crossover\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                self.diff_weight = 0.5 + 0.3 * (1 - eval_count / self.budget)  # Adaptive differential weight\n                mutant = x1 + self.diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Introducing adaptive differential weight in DE to enhance exploration during early evaluations.", "configspace": "", "generation": 2, "fitness": 0.8528492948049436, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.853 with standard deviation 0.014. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "efa9af05-3d57-4e90-acaf-08b11db002dd", "metadata": {"aucs": [0.8372368521677405, 0.8718375570765953, 0.8494734751704953], "final_y": [0.1339152688369587, 0.1236621580318561, 0.12706175323552782]}, "mutation_prompt": null}
{"id": "a6bb0ff2-e8eb-41fa-baa9-fcddfdb00400", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.7   # improved inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.3 * (1 - eval_count / self.budget)  # Adaptive inertia weight\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            # Evaluate and update personal bests\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            # DE Mutation and Crossover\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.diff_weight * (x2 - x3)\n                self.cr = 0.5 + 0.4 * (eval_count / self.budget)  # Adaptive crossover rate\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Enhanced hybrid algorithm with adaptive inertia and crossover rate based on evaluation count for improved convergence in dynamic landscapes.", "configspace": "", "generation": 2, "fitness": 0.8522593440622662, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.852 with standard deviation 0.022. And the mean value of best solutions found was 0.129 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "e6de6acc-9407-4450-b05f-aa06d331fc04", "metadata": {"aucs": [0.8220362003921734, 0.8731147427358862, 0.8616270890587387], "final_y": [0.13933921972277707, 0.11987197283304452, 0.12884408399611658]}, "mutation_prompt": null}
{"id": "960912a0-8359-46e8-9c46-6de0bc81f93a", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.7   # improved inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            # Evaluate and update personal bests\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            # DE Mutation and Crossover\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.diff_weight * (x2 - x3)\n                self.cr = 0.9 * (1 - eval_count / self.budget) + 0.1  # dynamic adjustment\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Introduced dynamic adjustment of the crossover probability (cr) based on evaluation count to balance exploration and exploitation.", "configspace": "", "generation": 2, "fitness": 0.8314280194602093, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.831 with standard deviation 0.009. And the mean value of best solutions found was 0.137 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "e6de6acc-9407-4450-b05f-aa06d331fc04", "metadata": {"aucs": [0.8300588527654489, 0.8436789188654801, 0.8205462867496987], "final_y": [0.13878671148653188, 0.13592951548421583, 0.13544683816036474]}, "mutation_prompt": null}
{"id": "6730b5dd-ce80-4f3c-9b7c-d59fb0d106a3", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.7   # improved inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            # Evaluate and update personal bests\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = (scores < personal_best_scores) & (np.random.rand(self.population_size) < (eval_count / self.budget))\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            # DE Mutation and Crossover\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Enhanced exploration by adjusting personal best update strategy using probability factor based on evaluation count.", "configspace": "", "generation": 2, "fitness": 0.8585058251905145, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.859 with standard deviation 0.042. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "e6de6acc-9407-4450-b05f-aa06d331fc04", "metadata": {"aucs": [0.7998091568411053, 0.8883091923913246, 0.8873991263391139], "final_y": [0.1368226278242789, 0.11631951580761235, 0.11354142613356133]}, "mutation_prompt": null}
{"id": "43d32f51-8c36-4304-9cf5-520607c8d659", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.5   # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = 0.4 + 0.1 * (1 - eval_count / self.budget)  # Dynamic inertia weight\n            velocities = w_dynamic * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            # Evaluate and update personal bests\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            # DE Mutation and Crossover\n            adaptive_diff_weight = self.diff_weight * (1 - eval_count / self.budget)  # Adaptive diff_weight\n            adaptive_cr = self.cr * (eval_count / self.budget)                        # Adaptive cr\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + adaptive_diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Enhancing hybrid PSO-DE with adaptive differential weight and crossover probability based on evaluation progress.", "configspace": "", "generation": 2, "fitness": 0.8875537420673035, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.888 with standard deviation 0.018. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "efa9af05-3d57-4e90-acaf-08b11db002dd", "metadata": {"aucs": [0.8729770293734103, 0.8773328357014449, 0.9123513611270554], "final_y": [0.12487020667767446, 0.12147345872549664, 0.11344810497107372]}, "mutation_prompt": null}
{"id": "1e112dc0-7532-4e11-9261-a409c3507630", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.5   # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = 0.4 + 0.1 * (1 - eval_count / self.budget)  # Dynamic inertia weight\n            velocities = w_dynamic * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            # Evaluate and update personal bests\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            # DE Mutation and Crossover\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.diff_weight * (x2 - x3)\n                cr_dynamic = self.cr - 0.3 * (eval_count / self.budget)  # Dynamic crossover rate\n                trial = np.where(np.random.rand(self.dim) < cr_dynamic, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Introduced a dynamic crossover rate in DE based on evaluation count to enhance balance between exploration and exploitation.", "configspace": "", "generation": 2, "fitness": 0.8699441601211281, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.870 with standard deviation 0.021. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "efa9af05-3d57-4e90-acaf-08b11db002dd", "metadata": {"aucs": [0.8416743166705967, 0.8757062466752815, 0.8924519170175059], "final_y": [0.13492574601460883, 0.11766784826859267, 0.11441201988547522]}, "mutation_prompt": null}
{"id": "e3c2c570-ae02-4ebf-bb26-ad47c331da9e", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1_initial, self.c1_final = 2.5, 1.5  # dynamic cognitive component\n        self.c2_initial, self.c2_final = 1.5, 2.5  # dynamic social component\n        self.w = 0.7   # improved inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Time-varying coefficients\n            t = eval_count / self.budget\n            c1 = self.c1_initial - t * (self.c1_initial - self.c1_final)\n            c2 = self.c2_initial + t * (self.c2_final - self.c2_initial)\n\n            # PSO Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            velocities = self.w * velocities + c1 * r1 * (personal_best - pop) + c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            # Evaluate and update personal bests\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            # DE Mutation and Crossover\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Incorporate time-varying acceleration coefficients to enhance convergence speed and solution precision.", "configspace": "", "generation": 2, "fitness": 0.8679438529680797, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.868 with standard deviation 0.033. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "e6de6acc-9407-4450-b05f-aa06d331fc04", "metadata": {"aucs": [0.823744080096589, 0.9013544182841666, 0.8787330605234837], "final_y": [0.14587386085818332, 0.11625793581062838, 0.11955314963022246]}, "mutation_prompt": null}
{"id": "89b692e8-1eff-4340-bcc9-deab38706c49", "solution": "import numpy as np\n\nclass HybridPSO_DE_Chaotic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 2.0  # increased cognitive component\n        self.c2 = 2.0  # increased social component\n        self.w = 0.3   # reduced initial inertia weight\n        self.diff_weight = 0.9  # adjusted differential weight for DE\n        self.cr = 0.85  # adjusted crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = 0.5 / (1 + eval_count / self.budget)  # More adaptive inertia weight\n            velocities = w_dynamic * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            # Evaluate and update personal bests\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            # DE Mutation and Crossover with chaotic local search\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best", "name": "HybridPSO_DE_Chaotic", "description": "Hybrid optimization strategy with adaptive inertia and chaotic local searches for enhanced exploration-exploitation balance.", "configspace": "", "generation": 2, "fitness": 0.8473871278654839, "feedback": "The algorithm HybridPSO_DE_Chaotic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.847 with standard deviation 0.006. And the mean value of best solutions found was 0.130 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "efa9af05-3d57-4e90-acaf-08b11db002dd", "metadata": {"aucs": [0.8390323390994459, 0.8512340097309153, 0.8518950347660904], "final_y": [0.1300945375318846, 0.13364124641129282, 0.1268288411208749]}, "mutation_prompt": null}
{"id": "794e5bee-ed56-4488-8262-165c4015e70b", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.5   # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = 0.3 + 0.5 * (1 - eval_count / self.budget)  # Dynamic inertia weight (modified range)\n            velocities = w_dynamic * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            # Evaluate and update personal bests\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            # DE Mutation and Crossover\n            adaptive_diff_weight = self.diff_weight * (1 - eval_count / self.budget)  # Adaptive diff_weight\n            adaptive_cr = self.cr * (eval_count / self.budget)                        # Adaptive cr\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + adaptive_diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "HybridPSO_DE with adaptive inertia weight range to improve exploration and exploitation balance.", "configspace": "", "generation": 3, "fitness": 0.8668413641553713, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.867 with standard deviation 0.022. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "43d32f51-8c36-4304-9cf5-520607c8d659", "metadata": {"aucs": [0.8364088485865795, 0.8805709676990667, 0.8835442761804675], "final_y": [0.13579477051189737, 0.11965251164233381, 0.11990569158222741]}, "mutation_prompt": null}
{"id": "43ce19e9-8e7d-476d-9fc6-299cb24cdc07", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.5   # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = 0.4 + 0.1 * (1 - eval_count / self.budget)  # Dynamic inertia weight\n            c1_dynamic = self.c1 - 0.5 * (eval_count / self.budget)  # Dynamic cognitive component\n            velocities = w_dynamic * velocities + c1_dynamic * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            # Evaluate and update personal bests\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            # DE Mutation and Crossover\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.diff_weight * (x2 - x3)\n                cr_dynamic = self.cr - 0.3 * (eval_count / self.budget)  # Dynamic crossover rate\n                trial = np.where(np.random.rand(self.dim) < cr_dynamic, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Improved balance between exploration and exploitation by adjusting the cognitive and social components dynamically based on evaluation progress.", "configspace": "", "generation": 3, "fitness": 0.8776315236191584, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.878 with standard deviation 0.014. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "1e112dc0-7532-4e11-9261-a409c3507630", "metadata": {"aucs": [0.858434367234605, 0.8917398501074016, 0.8827203535154687], "final_y": [0.12975540219576853, 0.11663625502884367, 0.12032817196775669]}, "mutation_prompt": null}
{"id": "52e94d4d-be4e-4a90-a017-cb2fea617349", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.5   # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = 0.4 + 0.3 * (1 - eval_count / self.budget)  # Enhanced dynamic inertia weight\n            velocities = w_dynamic * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            # Evaluate and update personal bests\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            # DE Mutation and Crossover\n            adaptive_diff_weight = self.diff_weight * (0.5 + 0.5 * (1 - eval_count / self.budget))  # Enhanced adaptive diff_weight\n            adaptive_cr = self.cr * (0.5 + 0.5 * (eval_count / self.budget))                        # Enhanced adaptive cr\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + adaptive_diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Introduced adaptive mutation scaling in DE and dynamic parameter control in PSO for improved exploration-exploitation balance.", "configspace": "", "generation": 3, "fitness": 0.8616138518618777, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.862 with standard deviation 0.005. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "43d32f51-8c36-4304-9cf5-520607c8d659", "metadata": {"aucs": [0.8624284025396415, 0.8677937136331169, 0.8546194394128745], "final_y": [0.12600848245492924, 0.11997279294852081, 0.12300023841513008]}, "mutation_prompt": null}
{"id": "7690a999-b9b8-4a6f-94d6-8f493424c4b9", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.5   # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = 0.9 - 0.5 * (eval_count / self.budget)  # Dynamic inertia weight, linearly decreasing\n            velocities = w_dynamic * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            # Evaluate and update personal bests\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            # DE Mutation and Crossover\n            adaptive_diff_weight = 0.9 * self.diff_weight * (1 - eval_count / self.budget)  # More aggressive adaptive diff_weight\n            adaptive_cr = self.cr * (eval_count / self.budget)                        # Adaptive cr\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + adaptive_diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Enhance adaptive mechanisms by using a linearly decreasing inertia weight and a more aggressive adaptive differential weight to balance exploration and exploitation.", "configspace": "", "generation": 3, "fitness": 0.8436129919553466, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.844 with standard deviation 0.020. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "43d32f51-8c36-4304-9cf5-520607c8d659", "metadata": {"aucs": [0.8166298504584666, 0.8645767178946615, 0.8496324075129114], "final_y": [0.13790596373555952, 0.11781980172653794, 0.1265647923622223]}, "mutation_prompt": null}
{"id": "fb24eeec-2d5f-4ab4-95b8-f61fc32565ba", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.5   # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = 0.4 + 0.1 * (1 - eval_count / self.budget)  # Dynamic inertia weight\n            c1_dynamic = self.c1 * (1 - eval_count / self.budget) + 0.5  # Dynamic cognitive component\n            velocities = w_dynamic * velocities + c1_dynamic * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            # Evaluate and update personal bests\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            # DE Mutation and Crossover\n            adaptive_diff_weight = self.diff_weight * (1 - eval_count / self.budget)  # Adaptive diff_weight\n            adaptive_cr = self.cr * (eval_count / self.budget)                        # Adaptive cr\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + adaptive_diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Improved hybrid PSO-DE by introducing dynamic scaling of cognitive component to enhance exploration in early stages and exploitation in later stages.", "configspace": "", "generation": 3, "fitness": 0.8712100220907445, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.871 with standard deviation 0.023. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "43d32f51-8c36-4304-9cf5-520607c8d659", "metadata": {"aucs": [0.8397905354450946, 0.8794924146003321, 0.8943471162268066], "final_y": [0.13755539019717078, 0.1188294375797706, 0.11596738429709563]}, "mutation_prompt": null}
{"id": "44e96f18-6e11-4816-9b64-de32c088be3f", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.5   # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = 0.4 + 0.1 * (1 - eval_count / self.budget)  # Dynamic inertia weight\n            velocities = w_dynamic * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            # Evaluate and update personal bests\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            # DE Mutation and Crossover\n            adaptive_diff_weight = self.diff_weight * (1 - eval_count / self.budget)  # Adaptive diff_weight\n            adaptive_cr = self.cr * (eval_count / self.budget)                        # Adaptive cr\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + adaptive_diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n            # Random reset for stagnating particles\n            if eval_count % (self.population_size * 10) == 0:  # Reset every 10 iterations as an example\n                stagnation_mask = scores >= personal_best_scores\n                pop[stagnation_mask] = np.random.uniform(lb, ub, (np.sum(stagnation_mask), self.dim))\n\n        return global_best", "name": "HybridPSO_DE", "description": "Improved convergence by adding a random reset mechanism for stagnating particles in HybridPSO_DE.", "configspace": "", "generation": 3, "fitness": 0.8544297884682535, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.854 with standard deviation 0.033. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "43d32f51-8c36-4304-9cf5-520607c8d659", "metadata": {"aucs": [0.8202848828391691, 0.8993202595667825, 0.8436842229988089], "final_y": [0.14372256563735475, 0.11642308318673755, 0.12115850672030781]}, "mutation_prompt": null}
{"id": "ffc57a0e-09fa-4270-b035-8c3d7b5cd831", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(5, int(budget / (dim * 10)))\n        self.population_size = self.initial_population_size\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.5   # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n        prev_global_best_score = global_best_score\n\n        while eval_count < self.budget:\n            # PSO Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = 0.4 + 0.1 * (1 - eval_count / self.budget)  # Dynamic inertia weight\n            velocities = w_dynamic * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            # Evaluate and update personal bests\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            # DE Mutation and Crossover\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.diff_weight * (x2 - x3)\n                cr_dynamic = self.cr - 0.3 * (eval_count / self.budget)  # Dynamic crossover rate\n                trial = np.where(np.random.rand(self.dim) < cr_dynamic, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n            # Adaptive population resizing based on convergence\n            if eval_count % (self.budget // 5) == 0:\n                improvement = prev_global_best_score - global_best_score\n                if improvement < 1e-6:  # Adaptive condition\n                    self.population_size = max(5, self.population_size // 2)\n                    pop = pop[:self.population_size]\n                    velocities = velocities[:self.population_size]\n                    personal_best = personal_best[:self.population_size]\n                    personal_best_scores = personal_best_scores[:self.population_size]\n                prev_global_best_score = global_best_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Integrating adaptive population resizing based on convergence rate to balance exploration and exploitation.", "configspace": "", "generation": 3, "fitness": 0.8766713438610286, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.877 with standard deviation 0.008. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "1e112dc0-7532-4e11-9261-a409c3507630", "metadata": {"aucs": [0.8708208613574953, 0.871449760684009, 0.8877434095415817], "final_y": [0.12708686364419075, 0.118091992253188, 0.11729672851882933]}, "mutation_prompt": null}
{"id": "87d9d45d-42b7-4f79-a4d2-5c99940a162c", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.5   # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = 0.4 + 0.1 * (1 - eval_count / self.budget)  # Dynamic inertia weight\n            c2_dynamic = self.c2 * (1 + 0.5 * (eval_count / self.budget))  # Dynamic social component\n            velocities = w_dynamic * velocities + self.c1 * r1 * (personal_best - pop) + c2_dynamic * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            # Evaluate and update personal bests\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            # DE Mutation and Crossover\n            adaptive_diff_weight = self.diff_weight * (1 - eval_count / self.budget)  # Adaptive diff_weight\n            adaptive_cr = self.cr * (eval_count / self.budget)                        # Adaptive cr\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + adaptive_diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Introduce dynamic social component weight in PSO to enhance adaptability based on evaluation progress.", "configspace": "", "generation": 3, "fitness": 0.8667749811733035, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.867 with standard deviation 0.038. And the mean value of best solutions found was 0.129 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "43d32f51-8c36-4304-9cf5-520607c8d659", "metadata": {"aucs": [0.8300164462571071, 0.8516484559706147, 0.9186600412921888], "final_y": [0.14089202330627015, 0.13460866914366043, 0.11291090358402878]}, "mutation_prompt": null}
{"id": "10e10188-99b5-4984-974c-34e6ef744ea4", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.5   # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = 0.4 + 0.1 * (1 - (eval_count / self.budget)**2)  # Non-linear inertia weight\n            velocities = w_dynamic * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            # Evaluate and update personal bests\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            # DE Mutation and Crossover\n            adaptive_diff_weight = self.diff_weight * (1 - (eval_count / self.budget)**2)  # Non-linear adaptive diff_weight\n            adaptive_cr = self.cr * (eval_count / self.budget)  # Adaptive cr\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + adaptive_diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Introduced a non-linear decay in inertia weight and differential weight adaptation to enhance exploration-exploitation balance.", "configspace": "", "generation": 3, "fitness": 0.8850059182323307, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.885 with standard deviation 0.011. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "43d32f51-8c36-4304-9cf5-520607c8d659", "metadata": {"aucs": [0.8712207926300315, 0.8855035455145963, 0.8982934165523644], "final_y": [0.12803700787556116, 0.11643033421197468, 0.1102400539796341]}, "mutation_prompt": null}
{"id": "f6cb5255-0333-44cf-8ebb-5e2937c1e662", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.5   # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = 0.4 + 0.1 * (1 - eval_count / self.budget)  # Dynamic inertia weight\n            velocities = w_dynamic * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            # Evaluate and update personal bests\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            # DE Mutation and Crossover\n            adaptive_diff_weight = self.diff_weight * (1 - eval_count / self.budget)  # Adaptive diff_weight\n            adaptive_cr = self.cr * (eval_count / self.budget)                        # Adaptive cr\n            switch_strategy = eval_count < self.budget * 0.5  # Switch strategy halfway\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + adaptive_diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Enhanced hybrid PSO-DE with dynamic strategy switch to balance exploration and exploitation.  ", "configspace": "", "generation": 3, "fitness": 0.881946234210241, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.882 with standard deviation 0.036. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "43d32f51-8c36-4304-9cf5-520607c8d659", "metadata": {"aucs": [0.833437336793754, 0.8919111748727467, 0.9204901909642222], "final_y": [0.1425988943436839, 0.11628015248697998, 0.11448824616272535]}, "mutation_prompt": null}
{"id": "5f8c425c-6cd2-4108-ae4a-e5e636e95d63", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.5   # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        learning_rate = 0.1\n        \n        while eval_count < self.budget:\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = 0.4 + 0.1 * (1 - eval_count / self.budget)\n            velocities = w_dynamic * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + learning_rate * velocities, lb, ub)  # Adaptive learning rate\n            \n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            diversity = np.mean(np.std(pop, axis=0))\n            if diversity < 1e-5:\n                pop += np.random.uniform(-0.01, 0.01, pop.shape)  # Diversity promotion\n\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            adaptive_diff_weight = self.diff_weight * (1 - eval_count / self.budget)\n            adaptive_cr = self.cr * (eval_count / self.budget)\n            switch_strategy = eval_count < self.budget * 0.5\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + adaptive_diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Improved HybridPSO_DE by integrating adaptive learning rates and diversity promotion to enhance convergence and solution quality.", "configspace": "", "generation": 4, "fitness": 0.8394658883081089, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.839 with standard deviation 0.015. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "f6cb5255-0333-44cf-8ebb-5e2937c1e662", "metadata": {"aucs": [0.8487877156440379, 0.8510415951893575, 0.8185683540909313], "final_y": [0.13146971914028027, 0.12629031504479427, 0.13542182442591744]}, "mutation_prompt": null}
{"id": "920af8b8-a72b-42f7-9d86-631bde3d61e0", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.5   # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = 0.4 + 0.3 * (1 - eval_count / self.budget)  # Adaptive inertia weight\n            velocities = w_dynamic * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            # Evaluate and update personal bests\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            # DE Mutation and Crossover\n            performance_factor = (global_best_score - personal_best_scores.mean()) / global_best_score\n            adaptive_diff_weight = self.diff_weight * performance_factor  # Adaptive diff_weight\n            adaptive_cr = self.cr * (1 - performance_factor)             # Adaptive cr\n            switch_strategy = eval_count < self.budget * 0.5  # Switch strategy halfway\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + adaptive_diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Introduced adaptive inertia weight and crossover probability based on performance feedback to enhance convergence in dynamic environments.", "configspace": "", "generation": 4, "fitness": 0.8438570889298235, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.844 with standard deviation 0.016. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "f6cb5255-0333-44cf-8ebb-5e2937c1e662", "metadata": {"aucs": [0.8222442551243743, 0.8614794777337186, 0.8478475339313775], "final_y": [0.13833647460156395, 0.1177393915401348, 0.12363744768267149]}, "mutation_prompt": null}
{"id": "a093a68c-d7dd-4ec4-84d1-e742137363dc", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.5   # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = 0.4 + 0.1 * (1 - (eval_count / self.budget)**2)  # Non-linear inertia weight\n            velocities = w_dynamic * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            diversity = np.std(pop, axis=0).mean()\n            adaptive_diff_weight = self.diff_weight * (1 - (eval_count / self.budget)**2 + diversity * 0.5)\n            adaptive_cr = self.cr * (eval_count / self.budget)  # Adaptive cr\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + adaptive_diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Enhanced convergence by incorporating an adaptive mechanism for mutation rate based on diversity measures.", "configspace": "", "generation": 4, "fitness": 0.8654416354765697, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.865 with standard deviation 0.006. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "10e10188-99b5-4984-974c-34e6ef744ea4", "metadata": {"aucs": [0.8733041685762549, 0.8641163368496145, 0.8589044010038398], "final_y": [0.12685539477682095, 0.11719913339255672, 0.12309126966645423]}, "mutation_prompt": null}
{"id": "0d5dfefe-2770-4055-8953-9287a963ea1b", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.5   # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n        self.memory_size = 5\n        self.memory = []\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = 0.4 + 0.1 * (1 - eval_count / self.budget)  # Dynamic inertia weight\n            velocities = w_dynamic * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            # Evaluate and update personal bests\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            # Update global best with memory\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n                self.memory.append(global_best)\n                if len(self.memory) > self.memory_size:\n                    self.memory.pop(0)\n                global_best = min(self.memory, key=lambda x: func(x))\n\n            # DE Mutation and Crossover\n            adaptive_diff_weight = self.diff_weight * (1 - eval_count / self.budget)  # Adaptive diff_weight\n            adaptive_cr = self.cr * (eval_count / self.budget)                        # Adaptive cr\n            switch_strategy = eval_count < self.budget * 0.5  # Switch strategy halfway\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + adaptive_diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Refine global best update using a memory buffer to store and utilize historical best solutions for enhanced convergence.", "configspace": "", "generation": 4, "fitness": 0.8496807254109365, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.850 with standard deviation 0.013. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "f6cb5255-0333-44cf-8ebb-5e2937c1e662", "metadata": {"aucs": [0.8386157749603286, 0.8686758062673782, 0.8417505950051027], "final_y": [0.14113268791122768, 0.12291257321329774, 0.12946710099379033]}, "mutation_prompt": null}
{"id": "c67e6dd8-8995-4a0c-8675-ca7b8f6a858d", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  # initial cognitive component\n        self.c2 = 1.5  # initial social component\n        self.w = 0.5   # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = 0.4 + 0.1 * (1 - eval_count / self.budget)  # Dynamic inertia weight\n            c1_dynamic = 1.5 - 0.5 * (eval_count / self.budget)  # Adaptive cognitive component\n            c2_dynamic = 1.5 + 0.5 * (eval_count / self.budget)  # Adaptive social component\n            velocities = w_dynamic * velocities + c1_dynamic * r1 * (personal_best - pop) + c2_dynamic * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            # Evaluate and update personal bests\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            # DE Mutation and Crossover\n            adaptive_diff_weight = self.diff_weight * (1 - eval_count / self.budget)  # Adaptive diff_weight\n            adaptive_cr = self.cr * (eval_count / self.budget)                        # Adaptive cr\n            switch_strategy = eval_count < self.budget * 0.5  # Switch strategy halfway\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + adaptive_diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Incorporate adaptive learning rates for cognitive and social components to dynamically adjust exploration versus exploitation during optimization.", "configspace": "", "generation": 4, "fitness": 0.8517476171803287, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.852 with standard deviation 0.016. And the mean value of best solutions found was 0.130 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "f6cb5255-0333-44cf-8ebb-5e2937c1e662", "metadata": {"aucs": [0.8690323891909146, 0.8300380269283218, 0.8561724354217497], "final_y": [0.12361701330377162, 0.1378800783958113, 0.12884061500609167]}, "mutation_prompt": null}
{"id": "29e724f9-769d-4451-8778-300f74f91b8a", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1_initial = 1.5  # initial cognitive component\n        self.c2_initial = 1.5  # initial social component\n        self.w = 0.5   # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = 0.4 + 0.1 * (1 - eval_count / self.budget)  # Dynamic inertia weight\n            c1 = self.c1_initial * (1 - eval_count / self.budget)  # Adaptive cognitive component\n            c2 = self.c2_initial * (eval_count / self.budget)  # Adaptive social component\n            velocities = w_dynamic * velocities + c1 * r1 * (personal_best - pop) + c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            # Evaluate and update personal bests\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            # DE Mutation and Crossover\n            adaptive_diff_weight = self.diff_weight * (1 - eval_count / self.budget)  # Adaptive diff_weight\n            adaptive_cr = self.cr * (eval_count / self.budget)                        # Adaptive cr\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + adaptive_diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Enhanced hybrid PSO-DE with dynamic diversity preservation and adaptive learning factors to improve solution quality and convergence rate.", "configspace": "", "generation": 4, "fitness": 0.8407615333267054, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.841 with standard deviation 0.033. And the mean value of best solutions found was 0.130 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "f6cb5255-0333-44cf-8ebb-5e2937c1e662", "metadata": {"aucs": [0.7962713124860552, 0.8489842998071866, 0.8770289876868742], "final_y": [0.14336767064184996, 0.1247270365751113, 0.12249887558247863]}, "mutation_prompt": null}
{"id": "9d72dcaa-bdcc-439b-96a4-caa9f4d87d5a", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.5   # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = 0.4 + 0.1 * (1 - eval_count / self.budget)  # Dynamic inertia weight\n            velocities = w_dynamic * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            # Evaluate and update personal bests\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            # DE Mutation and Crossover\n            adaptive_diff_weight = self.diff_weight * (1 - eval_count / self.budget)  # Adaptive diff_weight\n            adaptive_cr = self.cr * (eval_count / self.budget)                        # Adaptive cr\n            switch_strategy = eval_count < self.budget * 0.5  # Switch strategy halfway\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + adaptive_diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:  # Convergence-based global best update\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Introduced a self-tuning mechanism for DE parameters and a convergence-based global best update to enhance solution quality.", "configspace": "", "generation": 4, "fitness": 0.865360778969686, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.865 with standard deviation 0.025. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "f6cb5255-0333-44cf-8ebb-5e2937c1e662", "metadata": {"aucs": [0.9002376960036542, 0.8409375977501887, 0.854907043155215], "final_y": [0.11174709478547873, 0.13064924481334028, 0.12406954337234422]}, "mutation_prompt": null}
{"id": "0094a5c2-1008-47f6-88e1-222f69490c88", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1_initial = 2.0  # initial cognitive component\n        self.c2_initial = 2.0  # initial social component\n        self.c1_final = 0.5  # final cognitive component\n        self.c2_final = 0.5  # final social component\n        self.w = 0.5   # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = 0.4 + 0.1 * (1 - eval_count / self.budget)  # Dynamic inertia weight\n            c1_dynamic = self.c1_final + (self.c1_initial - self.c1_final) * (1 - eval_count / self.budget)\n            c2_dynamic = self.c2_final + (self.c2_initial - self.c2_final) * (1 - eval_count / self.budget)\n            velocities = w_dynamic * velocities + c1_dynamic * r1 * (personal_best - pop) + c2_dynamic * r2 * (global_best - pop)\n            velocities = np.clip(velocities, -abs(ub-lb), abs(ub-lb))  # Velocity clamping\n            pop = np.clip(pop + velocities, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            adaptive_diff_weight = self.diff_weight * (1 - eval_count / self.budget)\n            adaptive_cr = self.cr * (eval_count / self.budget)\n            switch_strategy = eval_count < self.budget * 0.5\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + adaptive_diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Introduced adaptive learning rates for cognitive and social components alongside velocity clamping to refine exploration-exploitation balance in PSO-DE.", "configspace": "", "generation": 4, "fitness": 0.8521615510787273, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.852 with standard deviation 0.013. And the mean value of best solutions found was 0.130 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "f6cb5255-0333-44cf-8ebb-5e2937c1e662", "metadata": {"aucs": [0.8610678409731759, 0.86114648363141, 0.834270328631596], "final_y": [0.13046777230151407, 0.12291714918873076, 0.13525754467305373]}, "mutation_prompt": null}
{"id": "09045684-6624-4055-b834-3b8c3b23bfea", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.5   # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = 0.4 + 0.1 * (1 - eval_count / self.budget)  # Dynamic inertia weight\n            c1_dynamic = self.c1 * (1 - eval_count / self.budget)  # Adaptive cognitive component\n            c2_dynamic = self.c2 * (eval_count / self.budget)      # Adaptive social component\n            velocities = w_dynamic * velocities + c1_dynamic * r1 * (personal_best - pop) + c2_dynamic * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            # Evaluate and update personal bests\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            # DE Mutation and Crossover\n            adaptive_diff_weight = self.diff_weight * (1 - eval_count / self.budget)  # Adaptive diff_weight\n            adaptive_cr = self.cr * (eval_count / self.budget)                        # Adaptive cr\n            switch_strategy = eval_count < self.budget * 0.5  # Switch strategy halfway\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + adaptive_diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Introduced adaptive cognitive and social components for PSO to enhance balance between exploration and exploitation.", "configspace": "", "generation": 4, "fitness": 0.8350197192682557, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.835 with standard deviation 0.034. And the mean value of best solutions found was 0.132 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "f6cb5255-0333-44cf-8ebb-5e2937c1e662", "metadata": {"aucs": [0.8025683325143985, 0.8811721394747585, 0.8213186858156103], "final_y": [0.1401394140438873, 0.12486316946794973, 0.129981642155372]}, "mutation_prompt": null}
{"id": "3e7b05f4-65fe-4c31-87d8-583f80ed6b70", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.5   # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = self._chaotic_initialization(lb, ub)  # Chaotic initialization\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = 0.4 + 0.1 * (1 - eval_count / self.budget)\n            velocities = w_dynamic * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            adaptive_diff_weight = self.diff_weight * (1 - eval_count / self.budget)\n            adaptive_cr = self.cr * (eval_count / self.budget)\n            switch_strategy = eval_count < self.budget * 0.5\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + adaptive_diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best\n\n    def _chaotic_initialization(self, lb, ub):  # New chaotic initialization method\n        # Using logistic map for chaotic sequence\n        chaotic_sequence = np.zeros((self.population_size, self.dim))\n        x = 0.7  # Initial chaotic value\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                x = 3.99 * x * (1 - x)\n                chaotic_sequence[i, j] = lb[j] + (ub[j] - lb[j]) * x\n        return chaotic_sequence", "name": "HybridPSO_DE", "description": "Enhanced adaptive strategy with chaotic initialization for improved diversity and convergence.", "configspace": "", "generation": 4, "fitness": 0.8622247256727884, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.862 with standard deviation 0.017. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "f6cb5255-0333-44cf-8ebb-5e2937c1e662", "metadata": {"aucs": [0.857322105157241, 0.8853470783568838, 0.8440049935042405], "final_y": [0.1342151571754353, 0.1167885132307308, 0.1190067043257429]}, "mutation_prompt": null}
{"id": "3806317d-e611-48c4-a4d8-03e428e3c848", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.5   # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = 0.4 + 0.1 * (1 - (eval_count / self.budget)**2)  # Non-linear inertia weight\n            velocities = w_dynamic * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            diversity = np.std(pop, axis=0).mean()\n            adaptive_diff_weight = self.diff_weight * (1 - (eval_count / self.budget)**2 + diversity * 0.5)\n            adaptive_cr = self.cr * (eval_count / self.budget)  # Adaptive cr\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + adaptive_diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n            # Dynamic resizing of population based on current diversity\n            if eval_count % (self.budget // 5) == 0:  # every 20% of the budget\n                self.population_size = max(5, int(self.population_size * (1 + diversity * 0.1)))\n                pop = np.resize(pop, (self.population_size, self.dim))\n                velocities = np.resize(velocities, (self.population_size, self.dim))\n                scores = np.resize(scores, self.population_size)\n                personal_best = np.resize(personal_best, (self.population_size, self.dim))\n                personal_best_scores = np.resize(personal_best_scores, self.population_size)\n\n        return global_best", "name": "HybridPSO_DE", "description": "Enhanced exploration by incorporating a dynamic population resizing mechanism based on evaluation progress and diversity measures.", "configspace": "", "generation": 5, "fitness": 0.8610205905241681, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.861 with standard deviation 0.017. And the mean value of best solutions found was 0.130 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "a093a68c-d7dd-4ec4-84d1-e742137363dc", "metadata": {"aucs": [0.8372473113923014, 0.8715141457987499, 0.8743003143814533], "final_y": [0.1375205296443469, 0.12774580579804673, 0.12461385260222257]}, "mutation_prompt": null}
{"id": "136c80e2-72c1-4e36-ac98-95c23083aa69", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.5   # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = 0.4 + 0.2 * np.sin(np.pi * (eval_count / self.budget))  # Non-linear adaptive inertia weight\n            velocities = w_dynamic * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            diversity = np.std(pop, axis=0).mean()\n            adaptive_diff_weight = self.diff_weight * (1 - (eval_count / self.budget)**2 + diversity * 0.5)\n            adaptive_cr = self.cr * (eval_count / self.budget)  # Adaptive cr\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + adaptive_diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Introduced non-linear adaptive inertia weight for improved convergence speed.", "configspace": "", "generation": 5, "fitness": 0.8479395467856925, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.848 with standard deviation 0.027. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "a093a68c-d7dd-4ec4-84d1-e742137363dc", "metadata": {"aucs": [0.8107375831153987, 0.8618264271867693, 0.8712546300549093], "final_y": [0.15181991413136586, 0.1277650381961405, 0.11920027003975886]}, "mutation_prompt": null}
{"id": "060c72c3-8bd3-4285-9dd7-19849cf040c1", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.5   # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = 0.4 + 0.1 * (1 - eval_count / self.budget)  # Dynamic inertia weight\n            velocities = w_dynamic * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            # Evaluate and update personal bests\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            # DE Mutation and Crossover\n            adaptive_diff_weight = self.diff_weight * (1 - eval_count / self.budget)  # Adaptive diff_weight\n            adaptive_cr = self.cr * (eval_count / self.budget)  # Adaptive cr\n            diversity = np.mean(np.std(pop, axis=0))\n            adaptive_cr = self.cr * (diversity / np.ptp(func.bounds.ub - func.bounds.lb))  # Change: dynamically adjust cr based on diversity\n            switch_strategy = eval_count < self.budget * 0.5  # Switch strategy halfway\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + adaptive_diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:  # Convergence-based global best update\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Enhanced diversity maintenance by dynamically adjusting crossover probability in DE based on population diversity.", "configspace": "", "generation": 5, "fitness": 0.8473647045478088, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.847 with standard deviation 0.026. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "9d72dcaa-bdcc-439b-96a4-caa9f4d87d5a", "metadata": {"aucs": [0.845643224057767, 0.8796168457180412, 0.8168340438676179], "final_y": [0.13180950137766645, 0.11779801210188767, 0.14481744713219458]}, "mutation_prompt": null}
{"id": "e7a62ae4-1e8d-4910-ae0d-2727b37a5cf1", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.5   # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = 0.4 + 0.1 * (1 - (eval_count / self.budget)**2)  # Non-linear inertia weight\n            velocities = w_dynamic * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            diversity = np.std(pop, axis=0).mean()\n            adaptive_diff_weight = self.diff_weight * (1 - (eval_count / self.budget) + diversity * 0.5)  # Improved adaptive mechanism\n            adaptive_cr = self.cr * (1 - (eval_count / self.budget))  # Improved adaptive mechanism\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + adaptive_diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Improved adaptive tuning of differential weight and crossover rate parameters for better exploration-exploitation balance.", "configspace": "", "generation": 5, "fitness": 0.8914315953310318, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.891 with standard deviation 0.009. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "a093a68c-d7dd-4ec4-84d1-e742137363dc", "metadata": {"aucs": [0.8887049119152515, 0.9034026788253364, 0.8821871952525074], "final_y": [0.1157252351020377, 0.11622535943358003, 0.11877799562610891]}, "mutation_prompt": null}
{"id": "353bb76b-4ec2-4aaa-a6c4-4d6753379389", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.5   # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = 0.4 + 0.1 * (1 - eval_count / self.budget)  # Dynamic inertia weight\n            velocities = w_dynamic * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            # Evaluate and update personal bests\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            # DE Mutation and Crossover\n            adaptive_diff_weight = self.diff_weight * (1 - eval_count / self.budget)  # Adaptive diff_weight\n            adaptive_cr = self.cr * (1 - np.var(scores) / np.mean(scores))            # Dynamic adaptive cr based on diversity\n            switch_strategy = eval_count < self.budget * 0.5  # Switch strategy halfway\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + adaptive_diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:  # Convergence-based global best update\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Introduced a dynamic crossover probability strategy based on population diversity to enhance exploration and exploitation balance.", "configspace": "", "generation": 5, "fitness": 0.8660523455098529, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.866 with standard deviation 0.031. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "9d72dcaa-bdcc-439b-96a4-caa9f4d87d5a", "metadata": {"aucs": [0.8219290291748147, 0.8875855254488246, 0.8886424819059191], "final_y": [0.14077504382951933, 0.12234458885333155, 0.12227534453776256]}, "mutation_prompt": null}
{"id": "fdc53214-6a47-4a64-8b69-673be9142c46", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(5, int(budget / (dim * 10)))\n        self.final_population_size = max(3, self.initial_population_size // 2)\n        self.population_size = self.initial_population_size\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.5   # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n        self.adaptive_c1 = lambda eval_count: 2.5 - 2 * (eval_count / self.budget)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = 0.4 + 0.1 * (1 - eval_count / self.budget)  # Dynamic inertia weight\n            velocities = w_dynamic * velocities + self.adaptive_c1(eval_count) * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            # Evaluate and update personal bests\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            # DE Mutation and Crossover\n            adaptive_diff_weight = self.diff_weight * (1 - eval_count / self.budget)  # Adaptive diff_weight\n            adaptive_cr = self.cr * (eval_count / self.budget)                        # Adaptive cr\n            switch_strategy = eval_count < self.budget * 0.5  # Switch strategy halfway\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + adaptive_diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:  # Convergence-based global best update\n                        global_best = trial\n                        global_best_score = trial_score\n\n            # Adjust population size\n            self.population_size = int(self.initial_population_size - (eval_count / self.budget) * (self.initial_population_size - self.final_population_size))\n            pop = pop[:self.population_size]\n            velocities = velocities[:self.population_size]\n            personal_best = personal_best[:self.population_size]\n            personal_best_scores = personal_best_scores[:self.population_size]\n\n        return global_best", "name": "HybridPSO_DE", "description": "Introduced a dynamic population size and adaptive personal learning rate to enhance exploration and exploitation balance.", "configspace": "", "generation": 5, "fitness": 0.8711574860102221, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.871 with standard deviation 0.019. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "9d72dcaa-bdcc-439b-96a4-caa9f4d87d5a", "metadata": {"aucs": [0.8485942375435993, 0.8950938354633224, 0.8697843850237449], "final_y": [0.13425592056773017, 0.12135513402335996, 0.11817636900488226]}, "mutation_prompt": null}
{"id": "7d2bc16c-a36d-4cef-a381-f74df3fd3dbc", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.5   # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = 0.4 + 0.1 * (1 - eval_count / self.budget)  # Dynamic inertia weight\n            self.c1, self.c2 = 1.5 + 0.5 * (eval_count / self.budget), 1.5 - 0.5 * (eval_count / self.budget)  # Dynamic cognitive and social components\n            velocities = w_dynamic * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            # Evaluate and update personal bests\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            # DE Mutation and Crossover\n            adaptive_diff_weight = self.diff_weight * (1 - eval_count / self.budget)  # Adaptive diff_weight\n            adaptive_cr = self.cr * (eval_count / self.budget)                        # Adaptive cr\n            switch_strategy = eval_count < self.budget * 0.5  # Switch strategy halfway\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + adaptive_diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:  # Convergence-based global best update\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Introduced a dynamic mechanism for cognitive and social components based on convergence to enhance diversification and intensification balance.", "configspace": "", "generation": 5, "fitness": 0.8782932458201554, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.878 with standard deviation 0.007. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "9d72dcaa-bdcc-439b-96a4-caa9f4d87d5a", "metadata": {"aucs": [0.8756748945238717, 0.8884055133409224, 0.8707993295956719], "final_y": [0.12385497422898717, 0.11792052601293579, 0.1150038573042963]}, "mutation_prompt": null}
{"id": "2e055278-aba1-46e5-8b81-3d9a25aa01a3", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.5   # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = 0.4 + 0.1 * (1 - (eval_count / self.budget)**2)  # Non-linear inertia weight\n            velocities = w_dynamic * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            diversity = np.std(pop, axis=0).mean()\n            adaptive_diff_weight = self.diff_weight * (1 - (eval_count / self.budget)**3 + diversity * 0.5)  # Change 1\n            adaptive_cr = self.cr * ((diversity + 0.1) / (1.1 + diversity))  # Change 2\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + adaptive_diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Improved adaptive mutation and crossover strategies in HybridPSO_DE based on population diversity and convergence rate.", "configspace": "", "generation": 5, "fitness": 0.8569179900988209, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.857 with standard deviation 0.040. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "a093a68c-d7dd-4ec4-84d1-e742137363dc", "metadata": {"aucs": [0.8019358337052553, 0.8755047520624145, 0.8933133845287927], "final_y": [0.14675507322317616, 0.1208718894294264, 0.11527612343415017]}, "mutation_prompt": null}
{"id": "8a8d4de6-3a16-4d38-a2ef-9865e0d31f69", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.5   # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = 0.4 + 0.1 * (1 - (eval_count / self.budget)**2)  # Non-linear inertia weight\n            velocities = w_dynamic * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            update_frequency = 1 - (eval_count / self.budget)**2  # Non-linear decay for personal best update\n            if np.random.rand() < update_frequency:\n                better_mask = scores < personal_best_scores\n                personal_best[better_mask] = pop[better_mask]\n                personal_best_scores[better_mask] = scores[better_mask]\n\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            diversity = np.std(pop, axis=0).mean()\n            adaptive_diff_weight = self.diff_weight * (1 - (eval_count / self.budget)**2 + diversity * 0.5)\n            adaptive_cr = self.cr * (eval_count / self.budget)  # Adaptive cr\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + adaptive_diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Incorporate a nonlinear decay in personal best update frequency to enhance exploration in early iterations.", "configspace": "", "generation": 5, "fitness": 0.8721120243419973, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.872 with standard deviation 0.026. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "a093a68c-d7dd-4ec4-84d1-e742137363dc", "metadata": {"aucs": [0.83554982216818, 0.8888485787079896, 0.8919376721498226], "final_y": [0.13724286824385679, 0.12152438855856462, 0.11300419708299847]}, "mutation_prompt": null}
{"id": "d506037e-b797-4744-a421-f7f67da639e8", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.5   # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = 0.4 + 0.1 * (1 - eval_count / self.budget)  # Dynamic inertia weight\n            velocities = w_dynamic * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop) * (eval_count / self.budget)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            # Evaluate and update personal bests\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            # DE Mutation and Crossover\n            adaptive_diff_weight = self.diff_weight * (1 - eval_count / self.budget)  # Adaptive diff_weight\n            adaptive_cr = self.cr * (eval_count / self.budget)                        # Adaptive cr\n            switch_strategy = eval_count < self.budget * 0.5  # Switch strategy halfway\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + adaptive_diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr * 1.1, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:  # Convergence-based global best update\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Enhanced convergence by incorporating an adaptive convergence acceleration factor in PSO velocity update and adaptive crossover weight in DE.", "configspace": "", "generation": 5, "fitness": 0.8569405752017331, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.857 with standard deviation 0.033. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "9d72dcaa-bdcc-439b-96a4-caa9f4d87d5a", "metadata": {"aucs": [0.8122317249153717, 0.8677907052073544, 0.8907992954824732], "final_y": [0.12881349248188456, 0.12952720427958353, 0.1136725976103019]}, "mutation_prompt": null}
{"id": "c71155d3-a578-4e58-8ad0-107cc75abe38", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.5   # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n        self.population_size = self.initial_population_size\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = 0.4 + 0.1 * (1 - eval_count / self.budget)  # Dynamic inertia weight\n            self.c1, self.c2 = 1.5 + 0.5 * np.sin(eval_count/self.budget * np.pi), 1.5 - 0.5 * np.sin(eval_count/self.budget * np.pi)  # Updated cognitive and social components\n            velocities = w_dynamic * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            adaptive_diff_weight = self.diff_weight * (1 - eval_count / self.budget)  # Adaptive diff_weight\n            adaptive_cr = self.cr * (eval_count / self.budget)                        # Adaptive cr\n            switch_strategy = eval_count < self.budget * 0.5  # Switch strategy halfway\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + adaptive_diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:  # Convergence-based global best update\n                        global_best = trial\n                        global_best_score = trial_score\n\n            if eval_count < self.budget // 2:\n                self.population_size = max(5, int(self.population_size * 0.9))  # Decrease population size\n\n        return global_best", "name": "HybridPSO_DE", "description": "Introduced an adaptive population size and hybrid velocity update to enhance convergence speed and solution diversity.", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (9,10) (10,10) ').", "error": "ValueError('operands could not be broadcast together with shapes (9,10) (10,10) ')", "parent_id": "7d2bc16c-a36d-4cef-a381-f74df3fd3dbc", "metadata": {}, "mutation_prompt": null}
{"id": "4afd82e1-e5b1-4f86-95c9-368b48aaff1a", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.5   # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = 0.4 + 0.1 * (1 - eval_count / self.budget)  # Dynamic inertia weight\n            self.c1, self.c2 = 1.5 + 0.5 * (eval_count / self.budget), 1.5 - 0.5 * (eval_count / self.budget)  # Dynamic cognitive and social components\n            velocities = w_dynamic * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            # Evaluate and update personal bests\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            # DE Mutation and Crossover\n            adaptive_diff_weight = self.diff_weight * (1 - eval_count / (2 * self.budget))  # Convergence-aware adaptive diff_weight\n            adaptive_cr = self.cr * (eval_count / self.budget)                        # Adaptive cr\n            switch_strategy = eval_count < self.budget * 0.5  # Switch strategy halfway\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + adaptive_diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:  # Convergence-based global best update\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Introduced a convergence-aware scaling factor for the differential weight in DE to enhance adaptability and convergence speed.  ", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (9,10) (10,10) ').", "error": "ValueError('operands could not be broadcast together with shapes (9,10) (10,10) ')", "parent_id": "7d2bc16c-a36d-4cef-a381-f74df3fd3dbc", "metadata": {}, "mutation_prompt": null}
{"id": "9e4f2893-c884-4358-a1cd-e2857c0675d8", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.5   # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = 0.4 + 0.1 * (1 - (eval_count / self.budget)**2)  # Non-linear inertia weight\n            c1_dynamic = self.c1 * (1 - (eval_count / self.budget)**2)  # Quadratic decay for cognitive component\n            velocities = w_dynamic * velocities + c1_dynamic * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            diversity = np.std(pop, axis=0).mean()\n            adaptive_diff_weight = self.diff_weight * (1 - (eval_count / self.budget) + diversity * 0.5)  # Improved adaptive mechanism\n            adaptive_cr = self.cr * (1 - (eval_count / self.budget))  # Improved adaptive mechanism\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + adaptive_diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Introduced a quadratic decay for the cognitive component to enhance convergence speed and solution quality.", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (9,10) (10,10) ').", "error": "ValueError('operands could not be broadcast together with shapes (9,10) (10,10) ')", "parent_id": "e7a62ae4-1e8d-4910-ae0d-2727b37a5cf1", "metadata": {}, "mutation_prompt": null}
{"id": "1fcb0448-21be-4659-8855-8d63e231c150", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.5   # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = 0.4 + 0.1 * (1 - eval_count / self.budget)  # Dynamic inertia weight\n            self.c1, self.c2 = 1.5 + 0.5 * (eval_count / self.budget), 1.5 - 0.5 * (eval_count / self.budget)  # Dynamic cognitive and social components\n            velocities = w_dynamic * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            # Evaluate and update personal bests\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                if np.random.rand() < 0.5:  # Stochastic global best update\n                    global_best_score = personal_best_scores[min_idx]\n                    global_best = personal_best[min_idx]\n\n            # DE Mutation and Crossover\n            adaptive_diff_weight = self.diff_weight * (1 - eval_count / self.budget)  # Adaptive diff_weight\n            adaptive_cr = self.cr * (eval_count / self.budget)                        # Adaptive cr\n            switch_strategy = eval_count < self.budget * 0.5  # Switch strategy halfway\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + adaptive_diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:  # Convergence-based global best update\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Enhanced global-best update strategy using stochastic selection to improve exploration-exploitation balance.", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (9,10) (10,10) ').", "error": "ValueError('operands could not be broadcast together with shapes (9,10) (10,10) ')", "parent_id": "7d2bc16c-a36d-4cef-a381-f74df3fd3dbc", "metadata": {}, "mutation_prompt": null}
{"id": "6342ed36-2a00-45c7-8f94-f41a7c3374f5", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.5   # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = 0.4 + 0.1 * (1 - (eval_count / self.budget)**2)  # Non-linear inertia weight\n            velocities = w_dynamic * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            if eval_count % (self.population_size * 2) == 0:  # Random reinitialization mechanism\n                pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            \n            diversity = np.std(pop, axis=0).mean()\n            adaptive_diff_weight = self.diff_weight * (1 - (eval_count / self.budget) + diversity * 0.5)  # Improved adaptive mechanism\n            adaptive_cr = self.cr * (1 - (eval_count / self.budget))  # Improved adaptive mechanism\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + adaptive_diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Introduced a random reinitialization mechanism to improve exploration during stagnation.", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (9,10) (10,10) ').", "error": "ValueError('operands could not be broadcast together with shapes (9,10) (10,10) ')", "parent_id": "e7a62ae4-1e8d-4910-ae0d-2727b37a5cf1", "metadata": {}, "mutation_prompt": null}
{"id": "3526b8c6-74ef-441b-b1f2-0bfba7817da1", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.5   # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = 0.4 + 0.1 * (1 - eval_count / self.budget)  # Dynamic inertia weight\n            self.c1, self.c2 = 1.5 + 0.5 * (eval_count / self.budget), 1.5 - 0.5 * (eval_count / self.budget)  # Dynamic cognitive and social components\n            velocities = w_dynamic * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            # Evaluate and update personal bests\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            # DE Mutation and Crossover\n            adaptive_diff_weight = self.diff_weight * (1 - eval_count / self.budget)  # Adaptive diff_weight\n            adaptive_cr = self.cr * (eval_count / self.budget)                        # Adaptive cr\n            switch_strategy = eval_count < self.budget * 0.5  # Switch strategy halfway\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                step = np.random.standard_cauchy(size=self.dim)  # Lévy flight step\n                mutant = x1 + adaptive_diff_weight * (x2 - x3) + step  # Incorporate Lévy flight\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:  # Convergence-based global best update\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Enhanced local search using Lévy flights for diversified exploration to avoid trapping in local optima.", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (9,10) (10,10) ').", "error": "ValueError('operands could not be broadcast together with shapes (9,10) (10,10) ')", "parent_id": "7d2bc16c-a36d-4cef-a381-f74df3fd3dbc", "metadata": {}, "mutation_prompt": null}
{"id": "736e7621-720c-4fe0-87bf-24627382cf87", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.5   # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = 0.4 + 0.1 * (1 - (eval_count / self.budget)**2)  # Non-linear inertia weight\n            velocities = w_dynamic * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            diversity = np.std(pop, axis=0).mean()\n            adaptive_diff_weight = self.diff_weight * (1 - (eval_count / self.budget) + diversity * 0.5)  # Improved adaptive mechanism\n            adaptive_cr = self.cr * (1 - (eval_count / self.budget) * diversity)  # Adjusted dynamic crossover\n\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + adaptive_diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Introduced dynamic crossover focusing on diversity and convergence to enhance solution quality in hybrid PSO-DE.", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (9,10) (10,10) ').", "error": "ValueError('operands could not be broadcast together with shapes (9,10) (10,10) ')", "parent_id": "e7a62ae4-1e8d-4910-ae0d-2727b37a5cf1", "metadata": {}, "mutation_prompt": null}
{"id": "6278461b-6775-4ec3-bbbd-cbb8efec913b", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.5   # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = 0.4 + 0.1 * (1 - (eval_count / self.budget)**2)  # Non-linear inertia weight\n            exploration_weight = 0.3 * (1 - eval_count / self.budget)  # Time-varying exploration component\n            velocities = w_dynamic * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop) + exploration_weight * np.random.randn(self.population_size, self.dim)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            diversity = np.std(pop, axis=0).mean()\n            adaptive_diff_weight = self.diff_weight * (1 - (eval_count / self.budget) + diversity * 0.5)  # Improved adaptive mechanism\n            adaptive_cr = self.cr * (1 - (eval_count / self.budget))  # Improved adaptive mechanism\n            \n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + adaptive_diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Enhanced velocity update by incorporating a time-varying random exploration component to improve global exploration capabilities.", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (9,10) (10,10) ').", "error": "ValueError('operands could not be broadcast together with shapes (9,10) (10,10) ')", "parent_id": "e7a62ae4-1e8d-4910-ae0d-2727b37a5cf1", "metadata": {}, "mutation_prompt": null}
{"id": "107546b1-7fc6-4af2-9c29-c7878096c018", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.5   # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = 0.4 + 0.3 * (1 - eval_count / self.budget)  # Dynamic inertia weight with adjusted scaling\n            self.c1, self.c2 = 1.5 + 0.5 * (eval_count / self.budget), 1.5 - 0.5 * (eval_count / self.budget)  # Dynamic cognitive and social components\n            velocities = w_dynamic * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            # Evaluate and update personal bests\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            # DE Mutation and Crossover\n            adaptive_diff_weight = self.diff_weight * (1 - eval_count / self.budget)  # Adaptive diff_weight\n            adaptive_cr = self.cr * (eval_count / self.budget)                        # Adaptive cr\n            switch_strategy = eval_count < self.budget * 0.5  # Switch strategy halfway\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + adaptive_diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:  # Convergence-based global best update\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Introduced adaptive scaling of the inertia weight based on the convergence rate to refine the exploration-exploitation dynamic.", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (9,10) (10,10) ').", "error": "ValueError('operands could not be broadcast together with shapes (9,10) (10,10) ')", "parent_id": "7d2bc16c-a36d-4cef-a381-f74df3fd3dbc", "metadata": {}, "mutation_prompt": null}
{"id": "7de2274b-3c22-4625-b2be-7f9ec5a5963a", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.5   # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n        self.elite_fraction = 0.1  # fraction of elite solutions to retain\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = 0.3 + 0.2 * np.cos(np.pi * eval_count / self.budget)  # Modified dynamic inertia weight\n            self.c1, self.c2 = 1.5 + 0.5 * (eval_count / self.budget), 1.5 - 0.5 * (eval_count / self.budget)\n            velocities = w_dynamic * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            # Evaluate and update personal bests\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            # DE Mutation and Crossover\n            adaptive_diff_weight = self.diff_weight * (1 - eval_count / self.budget)\n            adaptive_cr = self.cr * (eval_count / self.budget)\n            switch_strategy = eval_count < self.budget * 0.5\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + adaptive_diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n            \n            # Elitism: Retain top solutions\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_count]\n            for i in elite_indices:\n                pop[i] = personal_best[i]\n\n        return global_best", "name": "HybridPSO_DE", "description": "Introduced an adaptive mechanism to fine-tune inertia weight, while introducing elitism to retain top solutions across iterations.", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (9,10) (10,10) ').", "error": "ValueError('operands could not be broadcast together with shapes (9,10) (10,10) ')", "parent_id": "7d2bc16c-a36d-4cef-a381-f74df3fd3dbc", "metadata": {}, "mutation_prompt": null}
{"id": "a4199473-bf70-4c26-b7fe-d87d22e9387a", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.5   # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n        self.population_size = self.initial_population_size\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = 0.4 + 0.1 * (1 - eval_count / self.budget)  # Dynamic inertia weight\n            self.c1, self.c2 = 1.5 + 0.5 * np.sin(eval_count/self.budget * np.pi), 1.5 - 0.5 * np.sin(eval_count/self.budget * np.pi)  # Updated cognitive and social components\n            velocities = w_dynamic * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            adaptive_diff_weight = self.diff_weight * (1 - eval_count / self.budget)  # Adaptive diff_weight\n            adaptive_cr = self.cr * (eval_count / self.budget)                        # Adaptive cr            \n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + adaptive_diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:  # Convergence-based global best update\n                        global_best = trial\n                        global_best_score = trial_score\n\n            if eval_count < self.budget // 2:\n                self.population_size = max(5, int(self.population_size * 0.95))  # Adjusted population size reduction\n\n        return global_best", "name": "HybridPSO_DE", "description": "Enhanced adaptive population control and velocity update mechanism to improve convergence speed without exceeding strict line change constraints.", "configspace": "", "generation": 7, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (9,10) (10,10) ').", "error": "ValueError('operands could not be broadcast together with shapes (9,10) (10,10) ')", "parent_id": "c71155d3-a578-4e58-8ad0-107cc75abe38", "metadata": {}, "mutation_prompt": null}
{"id": "9018f19f-8fa3-42f2-bb97-a02bd600872c", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.5   # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n        self.population_size = self.initial_population_size\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = 0.4 + 0.1 * (1 - eval_count / self.budget)  # Dynamic inertia weight\n            self.c1, self.c2 = 1.5 + 0.5 * np.sin(eval_count/self.budget * np.pi), 1.5 - 0.5 * np.sin(eval_count/self.budget * np.pi)  # Updated cognitive and social components\n            velocities = w_dynamic * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            adaptive_diff_weight = self.diff_weight * (0.5 + 0.5 * (1 - eval_count / self.budget))  # Improved adaptive diff_weight\n            adaptive_cr = self.cr * (eval_count / self.budget)                        # Adaptive cr\n            switch_strategy = eval_count < self.budget * 0.5  # Switch strategy halfway\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + adaptive_diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:  # Convergence-based global best update\n                        global_best = trial\n                        global_best_score = trial_score\n\n            if eval_count < self.budget // 2:\n                self.population_size = max(5, int(self.population_size * 0.9))  # Decrease population size\n\n        return global_best", "name": "HybridPSO_DE", "description": "Improved adaptive strategy for differential evolution parameters to enhance convergence robustness.", "configspace": "", "generation": 7, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (9,10) (10,10) ').", "error": "ValueError('operands could not be broadcast together with shapes (9,10) (10,10) ')", "parent_id": "c71155d3-a578-4e58-8ad0-107cc75abe38", "metadata": {}, "mutation_prompt": null}
{"id": "662e1fcc-57c4-4daf-84ae-82141b64184e", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.5   # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n        self.population_size = self.initial_population_size\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = 0.4 + 0.1 * (1 - eval_count / self.budget)  # Dynamic inertia weight\n            self.c1, self.c2 = 1.5 + 0.5 * np.sin(eval_count/self.budget * np.pi), 1.5 - 0.5 * np.sin(eval_count/self.budget * np.pi)  # Updated cognitive and social components\n            velocities = w_dynamic * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            adaptive_diff_weight = self.diff_weight * (1 - eval_count / (self.budget + 1e-9))  # Corrected adaptive diff_weight\n            adaptive_cr = self.cr * (eval_count / (self.budget + 1e-9))                        # Corrected adaptive cr \n            switch_strategy = eval_count < self.budget * 0.5  # Switch strategy halfway\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + adaptive_diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:  # Convergence-based global best update\n                        global_best = trial\n                        global_best_score = trial_score\n\n            if eval_count < self.budget // 2:\n                self.population_size = max(5, int(self.population_size * 0.9))  # Decrease population size\n\n        return global_best", "name": "HybridPSO_DE", "description": "Enhanced convergence by correcting array broadcasting and fine-tuning adaptive parameters.", "configspace": "", "generation": 7, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (9,10) (10,10) ').", "error": "ValueError('operands could not be broadcast together with shapes (9,10) (10,10) ')", "parent_id": "c71155d3-a578-4e58-8ad0-107cc75abe38", "metadata": {}, "mutation_prompt": null}
{"id": "471f5df1-9778-4c11-903f-cf59efdf015e", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.5   # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n        self.population_size = self.initial_population_size\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = 0.4 + 0.1 * (1 - eval_count / self.budget)  # Dynamic inertia weight\n            self.c1, self.c2 = 1.5 + 0.5 * np.sin(eval_count/self.budget * np.pi), 1.5 - 0.5 * np.sin(eval_count/self.budget * np.pi)  # Updated cognitive and social components\n            velocities = w_dynamic * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score - np.std(personal_best_scores) * 0.01:  # Consider diversity\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            adaptive_diff_weight = self.diff_weight * (1 - eval_count / self.budget)  # Adaptive diff_weight\n            adaptive_cr = self.cr * (eval_count / self.budget)                        # Adaptive cr\n            switch_strategy = eval_count < self.budget * 0.5  # Switch strategy halfway\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + adaptive_diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:  # Convergence-based global best update\n                        global_best = trial\n                        global_best_score = trial_score\n\n            if eval_count < self.budget // 2:\n                self.population_size = max(5, int(self.population_size * 0.9))  # Decrease population size\n\n        return global_best", "name": "HybridPSO_DE", "description": "Enhanced global best update by considering personal best diversity to mitigate premature convergence.", "configspace": "", "generation": 7, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (9,10) (10,10) ').", "error": "ValueError('operands could not be broadcast together with shapes (9,10) (10,10) ')", "parent_id": "c71155d3-a578-4e58-8ad0-107cc75abe38", "metadata": {}, "mutation_prompt": null}
{"id": "f63c3a95-57e7-47a1-a2b8-8a37f2769202", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.5   # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n        self.population_size = self.initial_population_size\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-0.5 * (ub-lb), 0.5 * (ub-lb), (self.population_size, self.dim))  # Changed line\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = 0.4 + 0.1 * (1 - eval_count / self.budget)\n            self.c1, self.c2 = 1.5 + 0.5 * np.sin(eval_count/self.budget * np.pi), 1.5 - 0.5 * np.sin(eval_count/self.budget * np.pi)\n            velocities = w_dynamic * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            adaptive_diff_weight = self.diff_weight * (1 - eval_count / self.budget)\n            adaptive_cr = self.cr * (eval_count / self.budget)\n            switch_strategy = eval_count < self.budget * 0.5\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + adaptive_diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n            if eval_count < self.budget // 2:\n                self.population_size = max(5, int(self.population_size * 0.9))\n\n        return global_best", "name": "HybridPSO_DE", "description": "Introduced dimension-dependent velocity initialization and enhanced diversity preservation in trials to improve solution exploration and convergence stability.", "configspace": "", "generation": 7, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (9,10) (10,10) ').", "error": "ValueError('operands could not be broadcast together with shapes (9,10) (10,10) ')", "parent_id": "c71155d3-a578-4e58-8ad0-107cc75abe38", "metadata": {}, "mutation_prompt": null}
{"id": "bcbcdb64-7e33-41d3-961b-f2eea9307e75", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.5   # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = 0.4 + 0.1 * (1 - eval_count / self.budget)  # Dynamic inertia weight\n            self.c1, self.c2 = 1.5 + 0.5 * (eval_count / self.budget), 1.5 - 0.5 * (eval_count / self.budget)  # Dynamic cognitive and social components\n            velocities = w_dynamic * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            # Evaluate and update personal bests\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            # DE Mutation and Crossover\n            adaptive_diff_weight = self.diff_weight * (1 - eval_count / (2 * self.budget))  # Convergence-aware adaptive diff_weight\n            adaptive_cr = self.cr * (1 - eval_count / (2 * self.budget))                    # Adaptive cr correction\n            switch_strategy = eval_count < self.budget * 0.5  # Switch strategy halfway\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + adaptive_diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:  # Convergence-based global best update\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Enhanced the dynamic adaptive parameters to improve convergence and solution quality in hybrid PSO-DE optimization.", "configspace": "", "generation": 7, "fitness": 0.8870797890616711, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.887 with standard deviation 0.006. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "4afd82e1-e5b1-4f86-95c9-368b48aaff1a", "metadata": {"aucs": [0.8795756702127585, 0.8882382355871334, 0.8934254613851214], "final_y": [0.12030639984948122, 0.11631870659276311, 0.12189657900691775]}, "mutation_prompt": null}
{"id": "0abd85ea-1170-4329-aaf2-8a05635cced6", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.5   # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = 0.4 + 0.1 * (1 - eval_count / self.budget)  # Dynamic inertia weight\n            self.c1, self.c2 = 1.5 + 0.5 * (eval_count / self.budget), 1.5 - 0.5 * (eval_count / self.budget)  # Dynamic cognitive and social components\n            velocities = w_dynamic * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            # Evaluate and update personal bests\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            # DE Mutation and Crossover\n            adaptive_diff_weight = self.diff_weight * (1 - eval_count / (2 * self.budget))  # Convergence-aware adaptive diff_weight\n            adaptive_cr = self.cr * (eval_count / self.budget)                        # Adaptive cr\n            switch_strategy = eval_count < self.budget * 0.5  # Switch strategy halfway\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = np.clip(x1 + adaptive_diff_weight * (x2 - x3), lb, ub)  # Ensure valid dimensions\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:  # Convergence-based global best update\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Enhanced adaptive DE strategy by ensuring valid dimension operations to resolve broadcasting errors.", "configspace": "", "generation": 7, "fitness": 0.8678553283432757, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.868 with standard deviation 0.040. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.018.", "error": "", "parent_id": "4afd82e1-e5b1-4f86-95c9-368b48aaff1a", "metadata": {"aucs": [0.8159720283791083, 0.8751958898227018, 0.9123980668280172], "final_y": [0.15045360758761628, 0.11660554160028458, 0.11002597257161884]}, "mutation_prompt": null}
{"id": "38a31f66-d259-4b31-82ac-ca06dcf8d7a8", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10))) # Unchanged\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.5   # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = 0.4 + 0.1 * (1 - eval_count / self.budget)  # Dynamic inertia weight\n            self.c1, self.c2 = 1.5 + 0.5 * (eval_count / self.budget), 1.5 - 0.5 * (eval_count / self.budget)  # Dynamic cognitive and social components\n            velocities = w_dynamic * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            # Evaluate and update personal bests\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            \n            # Enhanced dynamic population adjustment\n            if eval_count < self.budget * 0.3:\n                personal_best_scores += np.random.normal(0, 0.1, personal_best_scores.shape)\n\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            # DE Mutation and Crossover\n            adaptive_diff_weight = self.diff_weight * (1 - eval_count / (2 * self.budget))  # Convergence-aware adaptive diff_weight\n            adaptive_cr = self.cr * (eval_count / self.budget)                        # Adaptive cr\n            switch_strategy = eval_count < self.budget * 0.5  # Switch strategy halfway\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                # Convergence-based mutation with small random perturbations\n                mutant = x1 + adaptive_diff_weight * (x2 - x3) + np.random.normal(0, 0.01, self.dim)\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:  # Convergence-based global best update\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Enhanced PSO-DE with dynamic population adjustment and convergence-based mutation for adaptive search efficacy.", "configspace": "", "generation": 7, "fitness": 0.853632561321212, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.854 with standard deviation 0.057. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "4afd82e1-e5b1-4f86-95c9-368b48aaff1a", "metadata": {"aucs": [0.773320794463082, 0.8872748753379498, 0.9003020141626044], "final_y": [0.13946343857602517, 0.11792219320512276, 0.11216384913127553]}, "mutation_prompt": null}
{"id": "5e935e69-a841-427a-8d5c-640f4ad7790a", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.5   # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))  # Ensure population shape matches dimension\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = 0.4 + 0.1 * (1 - eval_count / self.budget)  # Dynamic inertia weight\n            self.c1, self.c2 = 1.5 + 0.5 * (eval_count / self.budget), 1.5 - 0.5 * (eval_count / self.budget)  # Dynamic cognitive and social components\n            velocities = w_dynamic * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            # Evaluate and update personal bests\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            # DE Mutation and Crossover\n            adaptive_diff_weight = self.diff_weight * (1 - eval_count / (2 * self.budget))  # Convergence-aware adaptive diff_weight\n            adaptive_cr = self.cr * (eval_count / self.budget)                        # Adaptive cr\n            switch_strategy = eval_count < self.budget * 0.5  # Switch strategy halfway\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + adaptive_diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:  # Convergence-based global best update\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Adjusted initialization of population and velocities to ensure dimension consistency and avoid broadcasting errors.", "configspace": "", "generation": 7, "fitness": 0.8700209469299436, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.870 with standard deviation 0.044. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.017.", "error": "", "parent_id": "4afd82e1-e5b1-4f86-95c9-368b48aaff1a", "metadata": {"aucs": [0.808139771211754, 0.8925293939233797, 0.909393675654697], "final_y": [0.15160610274356012, 0.11626142918912696, 0.11500119088910177]}, "mutation_prompt": null}
{"id": "3e375de6-12b1-4be5-8b7c-ee6f0545b4ca", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10))) + 1  # Adjusted population size to avoid dimension mismatch\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.5   # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = 0.4 + 0.1 * (1 - eval_count / self.budget)  # Dynamic inertia weight\n            self.c1, self.c2 = 1.5 + 0.5 * (eval_count / self.budget), 1.5 - 0.5 * (eval_count / self.budget)  # Dynamic cognitive and social components\n            velocities = w_dynamic * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            # Evaluate and update personal bests\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            # DE Mutation and Crossover\n            adaptive_diff_weight = self.diff_weight * (1 - eval_count / (2 * self.budget))  # Convergence-aware adaptive diff_weight\n            adaptive_cr = self.cr * (eval_count / self.budget)                        # Adaptive cr\n            switch_strategy = eval_count < self.budget * 0.5  # Switch strategy halfway\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + adaptive_diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:  # Convergence-based global best update\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Introduced a fix for dimension mismatch in DE mutation by adjusting the population size calculation.", "configspace": "", "generation": 7, "fitness": 0.8760203044220151, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.876 with standard deviation 0.033. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "4afd82e1-e5b1-4f86-95c9-368b48aaff1a", "metadata": {"aucs": [0.831129558464167, 0.9082953720388766, 0.8886359827630015], "final_y": [0.13746714540264782, 0.1118759904880271, 0.11739240627889846]}, "mutation_prompt": null}
{"id": "9fcc56a0-05b7-4eda-8a25-b47efa1f9603", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.w = 0.5   \n        self.diff_weight = 0.8  \n        self.cr = 0.9   \n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n        num_swarms = 2  # Divide population into swarms\n        while eval_count < self.budget:\n            for swarm in range(num_swarms):  # Iterate through each swarm\n                swarm_slice = slice(swarm, self.population_size, num_swarms)\n                r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n                w_dynamic = 0.4 + 0.1 * (1 - eval_count / self.budget)\n                self.c1, self.c2 = 1.5 + 0.5 * (eval_count / self.budget), 1.5 - 0.5 * (eval_count / self.budget)\n                velocities[swarm_slice] = w_dynamic * velocities[swarm_slice] + self.c1 * r1[swarm_slice] * (personal_best[swarm_slice] - pop[swarm_slice]) + self.c2 * r2[swarm_slice] * (global_best - pop[swarm_slice])\n                pop[swarm_slice] = np.clip(pop[swarm_slice] + velocities[swarm_slice], lb, ub)\n\n                scores = np.array([func(ind) for ind in pop[swarm_slice]])\n                eval_count += self.population_size // num_swarms\n                better_mask = scores < personal_best_scores[swarm_slice]\n                personal_best[swarm_slice][better_mask] = pop[swarm_slice][better_mask]\n                personal_best_scores[swarm_slice][better_mask] = scores[better_mask]\n\n                min_idx = np.argmin(personal_best_scores)\n                if personal_best_scores[min_idx] < global_best_score:\n                    global_best_score = personal_best_scores[min_idx]\n                    global_best = personal_best[min_idx]\n\n            adaptive_diff_weight = self.diff_weight * (1 - eval_count / (2 * self.budget))\n            adaptive_cr = self.cr * (1 - eval_count / (2 * self.budget))\n            switch_strategy = eval_count < self.budget * 0.5\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + adaptive_diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Incorporate a multi-swarm approach with local search to enhance exploration and exploitation in hybrid PSO-DE optimization.", "configspace": "", "generation": 8, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 5 is out of bounds for axis 0 with size 5').", "error": "IndexError('index 5 is out of bounds for axis 0 with size 5')", "parent_id": "bcbcdb64-7e33-41d3-961b-f2eea9307e75", "metadata": {}, "mutation_prompt": null}
{"id": "422af8b8-66a9-453d-b226-e452466ff2bf", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.4   # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = 0.3 + 0.1 * (1 - eval_count / self.budget)  # Dynamic inertia weight\n            self.c1, self.c2 = 1.5 + 0.5 * (eval_count / self.budget), 1.5 - 0.5 * (eval_count / self.budget)  # Dynamic cognitive and social components\n            velocities = w_dynamic * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            # Evaluate and update personal bests\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            # DE Mutation and Crossover\n            adaptive_diff_weight = self.diff_weight * (1 - eval_count / (self.budget))  # Convergence-aware adaptive diff_weight\n            adaptive_cr = self.cr * (1 - eval_count / (2 * self.budget))                    # Adaptive cr correction\n            switch_strategy = eval_count < self.budget * 0.5  # Switch strategy halfway\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + adaptive_diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:  # Convergence-based global best update\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Improved hybrid PSO-DE by dynamically adapting the mutation factor and reducing inertia weight range to enhance exploration and exploitation balance.", "configspace": "", "generation": 8, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 5 is out of bounds for axis 0 with size 5').", "error": "IndexError('index 5 is out of bounds for axis 0 with size 5')", "parent_id": "bcbcdb64-7e33-41d3-961b-f2eea9307e75", "metadata": {}, "mutation_prompt": null}
{"id": "9dd26016-c6d2-43b8-b060-0e0092db0ab9", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.5   # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n\n        while eval_count < self.budget:\n            # Dynamic population size\n            self.population_size = max(5, int(self.initial_population_size * (1 - eval_count / self.budget)))\n            pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n            velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n            personal_best = pop.copy()\n            personal_best_scores = np.array([func(ind) for ind in personal_best])\n            global_best = personal_best[np.argmin(personal_best_scores)]\n            global_best_score = personal_best_scores.min()\n            eval_count += self.population_size\n\n            # PSO Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = 0.4 + 0.1 * (1 - eval_count / self.budget)  # Dynamic inertia weight\n            self.c1, self.c2 = 1.5 + 0.5 * (eval_count / self.budget), 1.5 - 0.5 * (eval_count / self.budget)  # Dynamic cognitive and social components\n            velocities = w_dynamic * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            # Evaluate and update personal bests\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            # DE Mutation and Crossover\n            adaptive_diff_weight = self.diff_weight * (1 - eval_count / (2 * self.budget))  # Convergence-aware adaptive diff_weight\n            adaptive_cr = self.cr * (1 - eval_count / (2 * self.budget))                    # Adaptive cr correction\n            switch_strategy = eval_count < self.budget * 0.5  # Switch strategy halfway\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + adaptive_diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:  # Convergence-based global best update\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Introduced a dynamic population size strategy that reduces linearly as the budget is consumed for improved convergence.", "configspace": "", "generation": 8, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 5 is out of bounds for axis 0 with size 5').", "error": "IndexError('index 5 is out of bounds for axis 0 with size 5')", "parent_id": "bcbcdb64-7e33-41d3-961b-f2eea9307e75", "metadata": {}, "mutation_prompt": null}
{"id": "9fb60ec7-b6b1-4f1d-9a1b-6462ae055741", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.5   # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = 0.4 + 0.2 * (1 - eval_count / self.budget)  # Dynamic inertia weight\n            self.c1, self.c2 = 1.5 + 0.3 * (eval_count / self.budget), 1.5 - 0.3 * (eval_count / self.budget)  # Dynamic cognitive and social components\n            velocities = w_dynamic * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            # Evaluate and update personal bests\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            # DE Mutation and Crossover\n            adaptive_diff_weight = self.diff_weight * (1 - eval_count / (1.5 * self.budget))  # Convergence-aware adaptive diff_weight\n            adaptive_cr = self.cr * (1 - eval_count / (1.5 * self.budget))                    # Adaptive cr correction\n            switch_strategy = eval_count < self.budget * 0.5  # Switch strategy halfway\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + adaptive_diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:  # Convergence-based global best update\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Slightly modified the dynamic adaptation strategy for PSO and DE parameters to improve exploration and exploitation balance.", "configspace": "", "generation": 8, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 5 is out of bounds for axis 0 with size 5').", "error": "IndexError('index 5 is out of bounds for axis 0 with size 5')", "parent_id": "bcbcdb64-7e33-41d3-961b-f2eea9307e75", "metadata": {}, "mutation_prompt": null}
{"id": "c0567da2-0359-41b7-9ac6-2efcbc6e6dd1", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.5   # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n        self.archive_size = 5  # archive for non-dominated solutions\n        self.archive = []\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = 0.5 + 0.3 * np.sin(np.pi * eval_count / self.budget)  # Dynamic inertia weight with sinusoidal adjustment\n            self.c1, self.c2 = 1.2 + 0.3 * np.cos(np.pi * eval_count / self.budget), 1.8 - 0.3 * np.cos(np.pi * eval_count / self.budget)  # Oscillating cognitive and social components\n            velocities = w_dynamic * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            # Evaluate and update personal bests\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            # DE Mutation and Crossover\n            adaptive_diff_weight = self.diff_weight * np.sin(np.pi * eval_count / (2 * self.budget))  # Sinusoidal adaptive diff_weight\n            adaptive_cr = self.cr * np.cos(np.pi * eval_count / (2 * self.budget))                    # Cosine adaptive cr correction\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + adaptive_diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:  # Convergence-based global best update\n                        global_best = trial\n                        global_best_score = trial_score\n\n                # Archive non-dominated solutions\n                self.archive.append(trial)\n                if len(self.archive) > self.archive_size:\n                    self.archive = sorted(self.archive, key=func)[:self.archive_size]\n\n        return global_best", "name": "HybridPSO_DE", "description": "Introduced multi-objective particle adaptation and enhanced crossover for improved exploration-exploitation balance in hybrid PSO-DE.", "configspace": "", "generation": 8, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 5 is out of bounds for axis 0 with size 5').", "error": "IndexError('index 5 is out of bounds for axis 0 with size 5')", "parent_id": "bcbcdb64-7e33-41d3-961b-f2eea9307e75", "metadata": {}, "mutation_prompt": null}
{"id": "877631ec-e131-46a6-8690-c6a9756c1ef0", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10))) + 1\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.5\n        self.diff_weight = 0.8\n        self.cr = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            elite = np.argpartition(personal_best_scores, 2)[:2]  # Select top elites\n            elite_pop = personal_best[elite]\n            w_dynamic = 0.5 + 0.2 * np.sin(eval_count / self.budget * np.pi)  # Adaptive inertia weight\n            self.c1, self.c2 = 1.5 + 0.5 * np.cos(eval_count / self.budget * np.pi), 1.5 - 0.5 * np.sin(eval_count / self.budget * np.pi)\n            velocities = w_dynamic * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            adaptive_diff_weight = self.diff_weight * (1 - eval_count / (1.5 * self.budget))\n            adaptive_cr = self.cr * (1 - np.cos(eval_count / self.budget * np.pi))\n            switch_strategy = eval_count < self.budget * 0.5\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + adaptive_diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i] or (i in elite and trial_score < personal_best_scores[i]):\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Enhanced HybridPSO_DE by integrating an adaptive learning mechanism for evolving cognitive and social factors and incorporating elite migration between PSO and DE strategies.", "configspace": "", "generation": 8, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 5 is out of bounds for axis 0 with size 5').", "error": "IndexError('index 5 is out of bounds for axis 0 with size 5')", "parent_id": "3e375de6-12b1-4be5-8b7c-ee6f0545b4ca", "metadata": {}, "mutation_prompt": null}
{"id": "e34f87f4-a7c7-46cf-834a-ea7afe986790", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10))) + 1  # Adjusted population size to avoid dimension mismatch\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.5   # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = 0.4 + 0.1 * (1 - eval_count / self.budget)  # Dynamic inertia weight\n            self.c1, self.c2 = 1.5 + 0.5 * (eval_count / self.budget), 1.5 - 0.5 * (eval_count / self.budget)  # Dynamic cognitive and social components\n            velocities = w_dynamic * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            # Evaluate and update personal bests\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            # DE Mutation and Crossover\n            adaptive_diff_weight = self.diff_weight * (1 - eval_count / (2 * self.budget)) * (0.5 + 0.5 * np.random.rand())  # Convergence-aware adaptive diff_weight with random scaling\n            adaptive_cr = self.cr * (eval_count / self.budget)                        # Adaptive cr\n            switch_strategy = eval_count < self.budget * 0.5  # Switch strategy halfway\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + adaptive_diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:  # Convergence-based global best update\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Introduced an adaptive mutation scaling factor in DE to enhance exploration.", "configspace": "", "generation": 8, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 5 is out of bounds for axis 0 with size 5').", "error": "IndexError('index 5 is out of bounds for axis 0 with size 5')", "parent_id": "3e375de6-12b1-4be5-8b7c-ee6f0545b4ca", "metadata": {}, "mutation_prompt": null}
{"id": "2dc657d7-211b-4b80-af3f-6102ecc56d7f", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10))) + 1  # Adjusted population size to avoid dimension mismatch\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.5   # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = 0.4 + 0.1 * (1 - eval_count / self.budget)  # Dynamic inertia weight\n            velocities = w_dynamic * velocities + (self.c1 + np.random.rand()) * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)  # Convergence-driven adaptive velocity control\n            pop = np.clip(pop + velocities, lb, ub)\n\n            # Evaluate and update personal bests\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            # DE Mutation and Crossover\n            adaptive_diff_weight = self.diff_weight * (1 - eval_count / (2 * self.budget))  # Convergence-aware adaptive diff_weight\n            adaptive_cr = self.cr * (eval_count / self.budget)                        # Adaptive cr\n            switch_strategy = eval_count < self.budget * 0.5  # Switch strategy halfway\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + adaptive_diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:  # Convergence-based global best update\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Introduced a convergence-driven adaptive velocity control in PSO for enhanced exploration and exploitation balance.", "configspace": "", "generation": 8, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 5 is out of bounds for axis 0 with size 5').", "error": "IndexError('index 5 is out of bounds for axis 0 with size 5')", "parent_id": "3e375de6-12b1-4be5-8b7c-ee6f0545b4ca", "metadata": {}, "mutation_prompt": null}
{"id": "c00b2327-45f9-4a25-900f-d11f4d4ea825", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10))) + 1  # Adjusted population size to avoid dimension mismatch\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.5   # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = 0.4 + 0.1 * (1 - eval_count / self.budget)  # Dynamic inertia weight\n            self.c1, self.c2 = 1.5 + 0.5 * (eval_count / self.budget), 1.5 - 0.5 * (eval_count / self.budget)  # Dynamic cognitive and social components\n            velocities = w_dynamic * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            # Evaluate and update personal bests\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            # DE Mutation and Crossover\n            self.diff_weight = 0.5 + 0.3 * np.random.rand()  # Self-adaptive differential weight tuning\n            adaptive_cr = self.cr * (eval_count / self.budget)                        # Adaptive cr\n            switch_strategy = eval_count < self.budget * 0.5  # Switch strategy halfway\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:  # Convergence-based global best update\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Enhanced mutation strategy by introducing a self-adaptive differential weight tuning mechanism to improve exploration and exploitation balance.", "configspace": "", "generation": 8, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 5 is out of bounds for axis 0 with size 5').", "error": "IndexError('index 5 is out of bounds for axis 0 with size 5')", "parent_id": "3e375de6-12b1-4be5-8b7c-ee6f0545b4ca", "metadata": {}, "mutation_prompt": null}
{"id": "dbfa45d8-d4dd-4b6e-bf4a-d9aa5c3c371f", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10))) + 1  # Adjusted population size to avoid dimension mismatch\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.5   # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = 0.4 + 0.1 * (1 - eval_count / self.budget)  # Dynamic inertia weight\n            self.c1, self.c2 = 1.5 + 0.5 * (eval_count / self.budget), 1.5 - 0.5 * (eval_count / self.budget)  # Dynamic cognitive and social components\n            velocities = w_dynamic * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            # Evaluate and update personal bests\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            # DE Mutation and Crossover\n            adaptive_diff_weight = self.diff_weight * (1 - eval_count / (2 * self.budget))  # Convergence-aware adaptive diff_weight\n            adaptive_cr = self.cr * (1 - eval_count / (2 * self.budget))                   # Enhanced adaptive cr\n            switch_strategy = eval_count < self.budget * 0.5  # Switch strategy halfway\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + adaptive_diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:  # Convergence-based global best update\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Enhanced adaptive crossover rate to improve exploration-exploitation balance.", "configspace": "", "generation": 8, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 5 is out of bounds for axis 0 with size 5').", "error": "IndexError('index 5 is out of bounds for axis 0 with size 5')", "parent_id": "3e375de6-12b1-4be5-8b7c-ee6f0545b4ca", "metadata": {}, "mutation_prompt": null}
{"id": "b101d6e1-3d33-46d8-9724-0003f87bad71", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.w = 0.5   \n        self.diff_weight = 0.8  \n        self.cr = 0.9   \n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n        num_swarms = min(3, self.population_size)  # Adjust number of swarms based on population size\n        while eval_count < self.budget:\n            for swarm in range(num_swarms):  # Iterate through each swarm\n                swarm_slice = slice(swarm, self.population_size, num_swarms)\n                r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n                w_dynamic = 0.4 + 0.1 * (1 - eval_count / self.budget)\n                self.c1, self.c2 = 1.5 + 0.5 * (eval_count / self.budget), 1.5 - 0.5 * (eval_count / self.budget)\n                velocities[swarm_slice] = w_dynamic * velocities[swarm_slice] + self.c1 * r1[swarm_slice] * (personal_best[swarm_slice] - pop[swarm_slice]) + self.c2 * r2[swarm_slice] * (global_best - pop[swarm_slice])\n                pop[swarm_slice] = np.clip(pop[swarm_slice] + velocities[swarm_slice], lb, ub)\n\n                scores = np.array([func(ind) for ind in pop[swarm_slice]])\n                eval_count += self.population_size // num_swarms\n                better_mask = scores < personal_best_scores[swarm_slice]\n                personal_best[swarm_slice][better_mask] = pop[swarm_slice][better_mask]\n                personal_best_scores[swarm_slice][better_mask] = scores[better_mask]\n\n                min_idx = np.argmin(personal_best_scores)\n                if personal_best_scores[min_idx] < global_best_score:\n                    global_best_score = personal_best_scores[min_idx]\n                    global_best = personal_best[min_idx]\n\n            adaptive_diff_weight = self.diff_weight * (1 - eval_count / (2 * self.budget))\n            adaptive_cr = self.cr * (1 - eval_count / (2 * self.budget))\n            switch_strategy = eval_count < self.budget * 0.5\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + adaptive_diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Refine the multi-swarm hybrid PSO-DE by adjusting swarm dynamics and mutation strategy for improved robustness.", "configspace": "", "generation": 9, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 3 is out of bounds for axis 0 with size 3').", "error": "IndexError('index 3 is out of bounds for axis 0 with size 3')", "parent_id": "9fcc56a0-05b7-4eda-8a25-b47efa1f9603", "metadata": {}, "mutation_prompt": null}
{"id": "65eab19a-80e3-4636-b891-03d62ae4ca11", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.w = 0.5   \n        self.diff_weight = 0.8  \n        self.cr = 0.9   \n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n        num_swarms = min(3, max(1, self.population_size // 3))  # Dynamic swarm size\n        while eval_count < self.budget:\n            for swarm in range(num_swarms):  # Iterate through each swarm\n                swarm_slice = slice(swarm, self.population_size, num_swarms)\n                r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n                w_dynamic = 0.4 + 0.1 * (1 - eval_count / self.budget)\n                self.c1, self.c2 = 1.5 + 0.5 * (eval_count / self.budget), 1.5 - 0.5 * (eval_count / self.budget)\n                velocities[swarm_slice] = w_dynamic * velocities[swarm_slice] + self.c1 * r1[swarm_slice] * (personal_best[swarm_slice] - pop[swarm_slice]) + self.c2 * r2[swarm_slice] * (global_best - pop[swarm_slice])\n                pop[swarm_slice] = np.clip(pop[swarm_slice] + velocities[swarm_slice], lb, ub)\n\n                scores = np.array([func(ind) for ind in pop[swarm_slice]])\n                eval_count += self.population_size // num_swarms\n                better_mask = scores < personal_best_scores[swarm_slice]\n                personal_best[swarm_slice][better_mask] = pop[swarm_slice][better_mask]\n                personal_best_scores[swarm_slice][better_mask] = scores[better_mask]\n\n                min_idx = np.argmin(personal_best_scores)\n                if personal_best_scores[min_idx] < global_best_score:\n                    global_best_score = personal_best_scores[min_idx]\n                    global_best = personal_best[min_idx]\n\n            adaptive_diff_weight = self.diff_weight * (1 - eval_count / (2 * self.budget))\n            adaptive_cr = self.cr * (1 - np.abs(global_best_score - personal_best_scores.mean()) / ub.sum())  # Adaptive CR\n            switch_strategy = eval_count < self.budget * 0.5\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + adaptive_diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Enhance hybrid PSO-DE by introducing dynamic swarm sizes and adaptive crossover rates based on convergence rate to improve exploration and exploitation balance.", "configspace": "", "generation": 9, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 3 is out of bounds for axis 0 with size 3').", "error": "IndexError('index 3 is out of bounds for axis 0 with size 3')", "parent_id": "9fcc56a0-05b7-4eda-8a25-b47efa1f9603", "metadata": {}, "mutation_prompt": null}
{"id": "0a7fff49-6bd9-459b-8380-ea986b061691", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.w = 0.5   \n        self.diff_weight = 0.8  \n        self.cr = 0.9   \n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n        num_swarms = 2  # Divide population into swarms\n        while eval_count < self.budget:\n            for swarm in range(num_swarms):  # Iterate through each swarm\n                swarm_slice = slice(swarm, min(self.population_size, self.population_size), num_swarms)  # <--- Modified line\n                r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n                w_dynamic = 0.4 + 0.1 * (1 - eval_count / self.budget)\n                self.c1, self.c2 = 1.5 + 0.5 * (eval_count / self.budget), 1.5 - 0.5 * (eval_count / self.budget)\n                velocities[swarm_slice] = w_dynamic * velocities[swarm_slice] + self.c1 * r1[swarm_slice] * (personal_best[swarm_slice] - pop[swarm_slice]) + self.c2 * r2[swarm_slice] * (global_best - pop[swarm_slice])\n                pop[swarm_slice] = np.clip(pop[swarm_slice] + velocities[swarm_slice], lb, ub)\n\n                scores = np.array([func(ind) for ind in pop[swarm_slice]])\n                eval_count += self.population_size // num_swarms\n                better_mask = scores < personal_best_scores[swarm_slice]\n                personal_best[swarm_slice][better_mask] = pop[swarm_slice][better_mask]\n                personal_best_scores[swarm_slice][better_mask] = scores[better_mask]\n\n                min_idx = np.argmin(personal_best_scores)\n                if personal_best_scores[min_idx] < global_best_score:\n                    global_best_score = personal_best_scores[min_idx]\n                    global_best = personal_best[min_idx]\n\n            adaptive_diff_weight = self.diff_weight * (1 - eval_count / (2 * self.budget))\n            adaptive_cr = self.cr * (1 - eval_count / (2 * self.budget))\n            switch_strategy = eval_count < self.budget * 0.5\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + adaptive_diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Improve boundary handling by limiting swarm index to population size to prevent index out-of-bounds errors.", "configspace": "", "generation": 9, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 5 is out of bounds for axis 0 with size 5').", "error": "IndexError('index 5 is out of bounds for axis 0 with size 5')", "parent_id": "9fcc56a0-05b7-4eda-8a25-b47efa1f9603", "metadata": {}, "mutation_prompt": null}
{"id": "15238518-0702-4eca-8dd9-7b187bf01f50", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.w = 0.5   \n        self.diff_weight = 0.8  \n        self.cr = 0.9   \n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n        num_swarms = 2  # Divide population into swarms\n        while eval_count < self.budget:\n            for swarm in range(num_swarms):  # Iterate through each swarm\n                swarm_slice = slice(swarm, self.population_size, num_swarms)\n                r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n                w_dynamic = 0.4 + 0.1 * (1 - eval_count / self.budget)\n                self.c1, self.c2 = 1.5 + 0.5 * (eval_count / self.budget), 1.5 - 0.5 * (eval_count / self.budget)\n                velocities[swarm_slice] = w_dynamic * velocities[swarm_slice] + self.c1 * r1[swarm_slice] * (personal_best[swarm_slice] - pop[swarm_slice]) + self.c2 * r2[swarm_slice] * (global_best - pop[swarm_slice])\n                pop[swarm_slice] = np.clip(pop[swarm_slice] + velocities[swarm_slice], lb, ub)\n\n                scores = np.array([func(ind) for ind in pop[swarm_slice]])\n                eval_count += self.population_size // num_swarms\n                better_mask = scores < personal_best_scores[swarm_slice]\n                personal_best[swarm_slice][better_mask] = pop[swarm_slice][better_mask]\n                personal_best_scores[swarm_slice][better_mask] = scores[better_mask]\n\n                min_idx = np.argmin(personal_best_scores)\n                if personal_best_scores[min_idx] < global_best_score:\n                    global_best_score = personal_best_scores[min_idx]\n                    global_best = personal_best[min_idx]\n\n            adaptive_diff_weight = self.diff_weight * (1 - eval_count / (2 * self.budget))\n            adaptive_cr = self.cr * (1 - eval_count / (2 * self.budget))\n            switch_strategy = eval_count < self.budget * 0.5\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + adaptive_diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Enhance hybrid PSO-DE with a multi-swarm approach and adaptive weight strategy for balanced exploration and exploitation.", "configspace": "", "generation": 9, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 5 is out of bounds for axis 0 with size 5').", "error": "IndexError('index 5 is out of bounds for axis 0 with size 5')", "parent_id": "9fcc56a0-05b7-4eda-8a25-b47efa1f9603", "metadata": {}, "mutation_prompt": null}
{"id": "0de0121a-274b-4591-8b2b-b9b1309066e3", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.w = 0.5   \n        self.diff_weight = 0.8  \n        self.cr = 0.9   \n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n        num_swarms = max(2, self.population_size // 5)  # Adjust swarm count dynamically\n        while eval_count < self.budget:\n            for swarm in range(num_swarms):  # Iterate through each swarm\n                swarm_slice = slice(swarm, self.population_size, num_swarms)\n                r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n                w_dynamic = 0.4 + 0.1 * (1 - eval_count / self.budget)\n                self.c1, self.c2 = 1.5 + 0.5 * (eval_count / self.budget), 1.5 - 0.5 * (eval_count / self.budget)\n                velocities[swarm_slice] = w_dynamic * velocities[swarm_slice] + self.c1 * r1[swarm_slice] * (personal_best[swarm_slice] - pop[swarm_slice]) + self.c2 * r2[swarm_slice] * (global_best - pop[swarm_slice])\n                pop[swarm_slice] = np.clip(pop[swarm_slice] + velocities[swarm_slice], lb, ub)\n\n                scores = np.array([func(ind) for ind in pop[swarm_slice]])\n                eval_count += self.population_size // num_swarms\n                better_mask = scores < personal_best_scores[swarm_slice]\n                personal_best[swarm_slice][better_mask] = pop[swarm_slice][better_mask]\n                personal_best_scores[swarm_slice][better_mask] = scores[better_mask]\n\n                min_idx = np.argmin(personal_best_scores)\n                if personal_best_scores[min_idx] < global_best_score:\n                    global_best_score = personal_best_scores[min_idx]\n                    global_best = personal_best[min_idx]\n\n            adaptive_diff_weight = self.diff_weight * (1 - eval_count / (2 * self.budget))\n            adaptive_cr = self.cr * (1 - eval_count / (2 * self.budget))\n            switch_strategy = eval_count < self.budget * 0.5\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + adaptive_diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Enhance swarm allocation and differential mutation strategy for better convergence in hybrid PSO-DE optimization.", "configspace": "", "generation": 9, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 5 is out of bounds for axis 0 with size 5').", "error": "IndexError('index 5 is out of bounds for axis 0 with size 5')", "parent_id": "9fcc56a0-05b7-4eda-8a25-b47efa1f9603", "metadata": {}, "mutation_prompt": null}
{"id": "02d50c31-d7f1-4a64-9e87-863a65b31420", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.4   # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = 0.3 + 0.2 * (1 - eval_count / self.budget)  # Changed dynamic inertia weight\n            self.c1, self.c2 = 1.5 + 0.3 * (eval_count / self.budget), 1.5 - 0.3 * (eval_count / self.budget)  # Adjusted dynamic components\n            velocities = w_dynamic * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            # Evaluate and update personal bests\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            # DE Mutation and Crossover\n            adaptive_diff_weight = self.diff_weight * (1 - eval_count / (self.budget))  # Convergence-aware adaptive diff_weight\n            adaptive_cr = self.cr * (1 - eval_count / (2 * self.budget))                    # Adaptive cr correction\n            switch_strategy = eval_count < self.budget * 0.5  # Switch strategy halfway\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + adaptive_diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:  # Convergence-based global best update\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Enhanced hybrid PSO-DE by refining population initialization and dynamic parameter adjustment to prevent premature convergence.", "configspace": "", "generation": 9, "fitness": 0.8513389318384926, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.851 with standard deviation 0.024. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "422af8b8-66a9-453d-b226-e452466ff2bf", "metadata": {"aucs": [0.8312417466010166, 0.83831284831076, 0.8844622006037013], "final_y": [0.13520080951355362, 0.13028579347175817, 0.11806461473096086]}, "mutation_prompt": null}
{"id": "bde6d469-a30a-43ef-812e-25644e4f50ac", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.4   # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = 0.5 + 0.1 * (1 - eval_count / self.budget)  # Adjusted dynamic inertia weight\n            self.c1, self.c2 = 1.7 + 0.5 * (eval_count / self.budget), 1.3 - 0.5 * (eval_count / self.budget)  # Refined cognitive and social components\n            velocities = w_dynamic * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            # Evaluate and update personal bests\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            # DE Mutation and Crossover\n            adaptive_diff_weight = self.diff_weight * (1 - eval_count / self.budget)  # Convergence-aware adaptive diff_weight\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + adaptive_diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, pop[i])  # Removed adaptive_cr for simplicity\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:  # Convergence-based global best update\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Enhance the hybrid PSO-DE by refining DE's mutation strategy and adaptive parameters to better balance exploration and exploitation.", "configspace": "", "generation": 9, "fitness": 0.8365829916021957, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.837 with standard deviation 0.016. And the mean value of best solutions found was 0.136 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "422af8b8-66a9-453d-b226-e452466ff2bf", "metadata": {"aucs": [0.850739805786822, 0.8447641489262707, 0.8142450200934945], "final_y": [0.12230989413457571, 0.13860690460318947, 0.14851436040507138]}, "mutation_prompt": null}
{"id": "9c629139-31d0-47f8-8edc-bcd18a366b40", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 20)))  # Adjusted the population size calculation\n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.w = 0.5   \n        self.diff_weight = 0.8  \n        self.cr = 0.9   \n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n        num_swarms = 2  # Divide population into swarms\n        while eval_count < self.budget:\n            for swarm in range(num_swarms):  # Iterate through each swarm\n                swarm_slice = slice(swarm, self.population_size, num_swarms)\n                r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n                w_dynamic = 0.4 + 0.1 * (1 - eval_count / self.budget)\n                self.c1, self.c2 = 1.5 + 0.5 * (eval_count / self.budget), 1.5 - 0.5 * (eval_count / self.budget)\n                velocities[swarm_slice] = w_dynamic * velocities[swarm_slice] + self.c1 * r1[swarm_slice] * (personal_best[swarm_slice] - pop[swarm_slice]) + self.c2 * r2[swarm_slice] * (global_best - pop[swarm_slice])\n                pop[swarm_slice] = np.clip(pop[swarm_slice] + velocities[swarm_slice], lb, ub)\n\n                scores = np.array([func(ind) for ind in pop[swarm_slice]])\n                eval_count += self.population_size // num_swarms\n                better_mask = scores < personal_best_scores[swarm_slice]\n                personal_best[swarm_slice][better_mask] = pop[swarm_slice][better_mask]\n                personal_best_scores[swarm_slice][better_mask] = scores[better_mask]\n\n                min_idx = np.argmin(personal_best_scores)\n                if personal_best_scores[min_idx] < global_best_score:\n                    global_best_score = personal_best_scores[min_idx]\n                    global_best = personal_best[min_idx]\n\n            adaptive_diff_weight = self.diff_weight * (1 - eval_count / (2 * self.budget))\n            adaptive_cr = self.cr * (1 - eval_count / (2 * self.budget))\n            switch_strategy = eval_count < self.budget * 0.5\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + adaptive_diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i % len(scores)]:  # Fixed index error by using modulo\n                    pop[i] = trial\n                    scores[i % len(scores)] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Enhance multi-swarm Hybrid PSO-DE by fixing index error and adjusting population size calculation.", "configspace": "", "generation": 9, "fitness": 0.8811916445722177, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.881 with standard deviation 0.012. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "9fcc56a0-05b7-4eda-8a25-b47efa1f9603", "metadata": {"aucs": [0.8640480722355177, 0.8895843063118047, 0.8899425551693304], "final_y": [0.1320034337428605, 0.11951149405373351, 0.11651043299121078]}, "mutation_prompt": null}
{"id": "d8d44ce9-643d-450c-8632-5d37e13bf5a4", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.4   # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = 0.3 + 0.1 * (1 - eval_count / self.budget)  # Dynamic inertia weight\n            self.c1, self.c2 = 1.5 + 0.5 * (eval_count / self.budget), 1.5 - 0.5 * (eval_count / self.budget) \n            velocities = w_dynamic * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            # Evaluate and update personal bests\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            # DE Mutation and Crossover\n            adaptive_diff_weight = self.diff_weight * (1 - eval_count / (self.budget))\n            adaptive_cr = self.cr * (1 - eval_count / (2 * self.budget))\n            switch_strategy = eval_count < self.budget * 0.5 \n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + adaptive_diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n            \n            # Stochastic Reinitialization\n            if eval_count > self.budget * 0.75 and np.std(personal_best_scores) < 1e-5:\n                pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                scores = np.array([func(ind) for ind in pop])\n                eval_count += self.population_size\n\n            # Elite Selection\n            elite_indices = np.argsort(personal_best_scores)[:max(2, self.population_size // 4)]\n            elite_pop = personal_best[elite_indices]\n            pop[:elite_pop.shape[0]] = elite_pop\n\n        return global_best", "name": "HybridPSO_DE", "description": "A refined hybrid PSO-DE algorithm that enhances diversity and convergence by incorporating stochastic reinitialization and elite selection, which prevent premature convergence and maintain exploration. ", "configspace": "", "generation": 9, "fitness": 0.8714601285563663, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.871 with standard deviation 0.015. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "422af8b8-66a9-453d-b226-e452466ff2bf", "metadata": {"aucs": [0.8781807191053199, 0.8851232451272315, 0.8510764214365476], "final_y": [0.12274405633507457, 0.118392589754026, 0.13229940373498938]}, "mutation_prompt": null}
{"id": "62f47366-ff28-4e17-b5dd-2eaae9172bc2", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.4   # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = 0.3 + 0.1 * (1 - eval_count / self.budget)  # Dynamic inertia weight\n            self.c1, self.c2 = 1.5 + 0.5 * (eval_count / self.budget), 1.5 - 0.5 * (eval_count / self.budget)  # Dynamic cognitive and social components\n            velocities = w_dynamic * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            # Evaluate and update personal bests\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            # DE Mutation and Crossover\n            adaptive_diff_weight = self.diff_weight * (1 - eval_count / (self.budget))  # Convergence-aware adaptive diff_weight\n            adaptive_cr = self.cr * (1 - eval_count / (2 * self.budget))                    # Adaptive cr correction\n            switch_strategy = eval_count < self.budget * 0.5  # Switch strategy halfway\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + adaptive_diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:  # Convergence-based global best update\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Refine the index selection for DE mutation to prevent out-of-bounds array access.", "configspace": "", "generation": 9, "fitness": 0.8744290042270438, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.874 with standard deviation 0.013. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "422af8b8-66a9-453d-b226-e452466ff2bf", "metadata": {"aucs": [0.8632310578650817, 0.8919456964211614, 0.8681102583948884], "final_y": [0.11709026693059499, 0.11934776341581776, 0.1285096281874496]}, "mutation_prompt": null}
{"id": "c7c2780b-0bc4-43d5-93f8-3744879f396b", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.4   # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = 0.3 + 0.2 * (1 - eval_count / self.budget)  # Enhanced dynamic inertia weight\n            self.c1, self.c2 = 1.5 + 0.5 * (eval_count / self.budget), 1.5 - 0.5 * (eval_count / self.budget)  # Dynamic cognitive and social components\n            velocities = w_dynamic * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            # Evaluate and update personal bests\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            # DE Mutation and Crossover\n            adaptive_diff_weight = self.diff_weight * (1 - (eval_count / self.budget)**2)  # Improved DE diversity\n            adaptive_cr = self.cr * (1 - eval_count / (2 * self.budget))                    # Adaptive cr correction\n            switch_strategy = eval_count < self.budget * 0.5  # Switch strategy halfway\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + adaptive_diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:  # Convergence-based global best update\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Refine Hybrid PSO-DE by enhancing inertia weight strategy and improving differential evolution diversity.", "configspace": "", "generation": 10, "fitness": 0.9062739615215007, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.906 with standard deviation 0.011. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "62f47366-ff28-4e17-b5dd-2eaae9172bc2", "metadata": {"aucs": [0.9063597906359673, 0.8921625926993563, 0.9202995012291786], "final_y": [0.11270658618814067, 0.11691835855865707, 0.11499257147239683]}, "mutation_prompt": null}
{"id": "87ec3455-da74-43d5-93b2-84c102f59749", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.4   # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        diversity_threshold = 0.05  # Adding a diversity threshold to maintain swarm variety\n        while eval_count < self.budget:\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = 0.3 + 0.1 * (1 - eval_count / self.budget)  # Dynamic inertia weight\n            self.c1, self.c2 = 1.5 + 0.5 * (eval_count / self.budget), 1.5 - 0.5 * (eval_count / self.budget)  # Dynamic cognitive and social components\n            velocities = w_dynamic * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            # Evaluate and update personal bests\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            # DE Mutation and Crossover\n            adaptive_diff_weight = self.diff_weight * (1 - eval_count / (self.budget))  # Convergence-aware adaptive diff_weight\n            adaptive_cr = self.cr * (1 - eval_count / (2 * self.budget))                    # Adaptive cr correction\n            switch_strategy = eval_count < self.budget * 0.5  # Switch strategy halfway\n\n            # Swarm diversity control\n            diversity = np.std(pop, axis=0).mean()\n            if diversity < diversity_threshold:\n                self.diff_weight *= 1.2  # Boost mutation when diversity is low\n                self.c1, self.c2 = self.c2, self.c1  # Swap cognitive and social influence\n                \n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + adaptive_diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:  # Convergence-based global best update\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Enhanced dynamic PSO-DE by introducing swarm diversity control and adaptive mutation strategies.", "configspace": "", "generation": 10, "fitness": 0.8876102635368553, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.888 with standard deviation 0.024. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "62f47366-ff28-4e17-b5dd-2eaae9172bc2", "metadata": {"aucs": [0.8554868564185069, 0.8951149290194866, 0.9122290051725723], "final_y": [0.12760889299338352, 0.11693173342267082, 0.118132153714812]}, "mutation_prompt": null}
{"id": "417f54dd-40b9-4c76-8062-29e11db9be9c", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.4   # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = self.w * (1 + 0.1 * np.sin(2 * np.pi * eval_count / self.budget))  # Sinusoidal adaptive inertia\n            self.c1, self.c2 = 1.5 + 0.5 * (eval_count / self.budget), 1.5 - 0.5 * (eval_count / self.budget)\n            velocities = w_dynamic * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            # Evaluate and update personal bests\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            # DE Mutation and Crossover\n            adaptive_diff_weight = self.diff_weight * (1 - eval_count / (self.budget))  \n            adaptive_cr = self.cr * (1 - eval_count / (2 * self.budget))\n            switch_strategy = eval_count < self.budget * 0.5\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + adaptive_diff_weight * (x2 - x3) + 0.1 * (personal_best[i] - x1)  # Memory-based mutation\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Improve convergence and diversity by introducing adaptive inertia and memory-based mutation in PSO-DE.", "configspace": "", "generation": 10, "fitness": 0.8829909123563824, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.883 with standard deviation 0.028. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "62f47366-ff28-4e17-b5dd-2eaae9172bc2", "metadata": {"aucs": [0.8449878781608323, 0.8937738217570061, 0.9102110371513087], "final_y": [0.13301285319032263, 0.11979173629664475, 0.11173259891831788]}, "mutation_prompt": null}
{"id": "27b124ce-1776-47bb-aa7c-a3fd60991128", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.4   # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = 0.3 + 0.1 * (1 - eval_count / self.budget)  # Dynamic inertia weight\n            self.c1, self.c2 = 1.5 + 0.5 * (eval_count / self.budget), 1.5 - 0.5 * (eval_count / self.budget)  # Dynamic cognitive and social components\n            velocities = w_dynamic * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            # Evaluate and update personal bests\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            # DE Mutation and Crossover\n            adaptive_diff_weight = self.diff_weight * (0.5 + 0.5 * (1 - eval_count / self.budget))  # Adjusted convergence-aware adaptive diff_weight\n            adaptive_cr = self.cr * (1 - eval_count / (1.5 * self.budget))  # Adjusted adaptive cr correction\n            switch_strategy = eval_count < self.budget * 0.5  # Switch strategy halfway\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + adaptive_diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:  # Convergence-based global best update\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Improve convergence by modifying dynamic strategy for DE component and enhancing exploration.", "configspace": "", "generation": 10, "fitness": 0.8647651601435907, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.865 with standard deviation 0.013. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "62f47366-ff28-4e17-b5dd-2eaae9172bc2", "metadata": {"aucs": [0.8574575673782251, 0.8534238579821313, 0.8834140550704161], "final_y": [0.13121813814180938, 0.12737587124323901, 0.12021642421973877]}, "mutation_prompt": null}
{"id": "206cb3bb-9b95-4d5c-b970-a49f37611c4f", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 20)))  # Adjusted the population size calculation\n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.w = 0.5   \n        self.diff_weight = 0.8  \n        self.cr = 0.9   \n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n        num_swarms = 2  # Divide population into swarms\n        while eval_count < self.budget:\n            for swarm in range(num_swarms):  # Iterate through each swarm\n                swarm_slice = slice(swarm, self.population_size, num_swarms)\n                r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n                w_dynamic = 0.4 + 0.1 * (1 - eval_count / self.budget)\n                self.c1, self.c2 = 1.4 + 0.6 * (eval_count / self.budget), 1.4 - 0.6 * (eval_count / self.budget)  # Changed coefficients\n                velocities[swarm_slice] = w_dynamic * velocities[swarm_slice] + self.c1 * r1[swarm_slice] * (personal_best[swarm_slice] - pop[swarm_slice]) + self.c2 * r2[swarm_slice] * (global_best - pop[swarm_slice])\n                pop[swarm_slice] = np.clip(pop[swarm_slice] + velocities[swarm_slice], lb, ub)\n\n                scores = np.array([func(ind) for ind in pop[swarm_slice]])\n                eval_count += self.population_size // num_swarms\n                better_mask = scores < personal_best_scores[swarm_slice]\n                personal_best[swarm_slice][better_mask] = pop[swarm_slice][better_mask]\n                personal_best_scores[swarm_slice][better_mask] = scores[better_mask]\n\n                min_idx = np.argmin(personal_best_scores)\n                if personal_best_scores[min_idx] < global_best_score:\n                    global_best_score = personal_best_scores[min_idx]\n                    global_best = personal_best[min_idx]\n\n            adaptive_diff_weight = self.diff_weight * (1 - eval_count / (2 * self.budget))\n            adaptive_cr = self.cr * (1 - eval_count / (2 * self.budget))\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + adaptive_diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i % len(scores)]:  # Fixed index error by using modulo\n                    pop[i] = trial\n                    scores[i % len(scores)] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Introduce adaptive swarm dynamics and mutation crossover rates to enhance exploration and exploitation balance.", "configspace": "", "generation": 10, "fitness": 0.8899232146630465, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.890 with standard deviation 0.013. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "9c629139-31d0-47f8-8edc-bcd18a366b40", "metadata": {"aucs": [0.9073693066854822, 0.8787011247769766, 0.8836992125266807], "final_y": [0.11644471964713743, 0.12150991817921608, 0.11450650874230561]}, "mutation_prompt": null}
{"id": "967fcbf2-5ac0-4c0d-bede-c763b0ca13a9", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 25)))  # Adjusted the population size calculation\n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.w = 0.5   \n        self.diff_weight = 0.8  \n        self.cr = 0.9   \n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n        num_swarms = 2  # Divide population into swarms\n        while eval_count < self.budget:\n            for swarm in range(num_swarms):  # Iterate through each swarm\n                swarm_slice = slice(swarm, self.population_size, num_swarms)\n                r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n                w_dynamic = 0.4 + 0.3 * (1 - eval_count / self.budget)  # Increased dynamic range for adaptive inertia\n                self.c1, self.c2 = 1.5 + 0.5 * (eval_count / self.budget), 1.5 - 0.5 * (eval_count / self.budget)\n                velocities[swarm_slice] = w_dynamic * velocities[swarm_slice] + self.c1 * r1[swarm_slice] * (personal_best[swarm_slice] - pop[swarm_slice]) + self.c2 * r2[swarm_slice] * (global_best - pop[swarm_slice])\n                pop[swarm_slice] = np.clip(pop[swarm_slice] + velocities[swarm_slice], lb, ub)\n\n                scores = np.array([func(ind) for ind in pop[swarm_slice]])\n                eval_count += self.population_size // num_swarms\n                better_mask = scores < personal_best_scores[swarm_slice]\n                personal_best[swarm_slice][better_mask] = pop[swarm_slice][better_mask]\n                personal_best_scores[swarm_slice][better_mask] = scores[better_mask]\n\n                min_idx = np.argmin(personal_best_scores)\n                if personal_best_scores[min_idx] < global_best_score:\n                    global_best_score = personal_best_scores[min_idx]\n                    global_best = personal_best[min_idx]\n\n            adaptive_diff_weight = self.diff_weight * (1 - eval_count / (2 * self.budget))\n            adaptive_cr = self.cr * (1 - eval_count / (2 * self.budget))\n            switch_strategy = eval_count < self.budget * 0.5\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + adaptive_diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i % len(scores)]:  # Fixed index error by using modulo\n                    pop[i] = trial\n                    scores[i % len(scores)] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Introduced adaptive inertia weight and population size to enhance convergence and exploration-exploitation balance.", "configspace": "", "generation": 10, "fitness": 0.8736058545236284, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.874 with standard deviation 0.022. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "9c629139-31d0-47f8-8edc-bcd18a366b40", "metadata": {"aucs": [0.8628326134200527, 0.9036863653436877, 0.8542985848071448], "final_y": [0.12629718711380244, 0.11684203268391913, 0.13109470980716964]}, "mutation_prompt": null}
{"id": "5e8fb94a-7f0c-4f5e-a21a-e27348cd39c8", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.4   # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = 0.4 + 0.2 * ((self.budget - eval_count) / self.budget)  # More adaptive inertia weight calculation\n            self.c1, self.c2 = 1.5 + 0.5 * (eval_count / self.budget), 1.5 - 0.5 * (eval_count / self.budget)  # Dynamic cognitive and social components\n            velocities = w_dynamic * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            # Evaluate and update personal bests\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            # DE Mutation and Crossover\n            adaptive_diff_weight = self.diff_weight * (1 - eval_count / (self.budget))  # Convergence-aware adaptive diff_weight\n            adaptive_cr = self.cr * (1 - eval_count / (2 * self.budget))                    # Adaptive cr correction\n            switch_strategy = eval_count < self.budget * 0.5  # Switch strategy halfway\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + adaptive_diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:  # Convergence-based global best update\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Introduce a more adaptive inertia weight calculation to enhance exploration-exploitation balance.", "configspace": "", "generation": 10, "fitness": 0.8750838683202485, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.875 with standard deviation 0.018. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "62f47366-ff28-4e17-b5dd-2eaae9172bc2", "metadata": {"aucs": [0.8730738702814455, 0.8980203424909287, 0.8541573921883715], "final_y": [0.11546864559601233, 0.11766269336922575, 0.13086849754455487]}, "mutation_prompt": null}
{"id": "380fb080-48c6-4f1d-a233-473413d4402b", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.4   # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = 0.3 + 0.1 * (1 - eval_count / self.budget)  # Dynamic inertia weight\n            self.c1, self.c2 = 1.5 + 0.5 * (eval_count / self.budget), 1.5 - 0.5 * (eval_count / self.budget)  # Dynamic cognitive and social components\n            velocities = w_dynamic * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + velocities, lb, ub)\n\n            # Evaluate and update personal bests\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            # DE Mutation and Crossover\n            diversity = np.std(pop, axis=0).mean() / (ub - lb).mean()  # Measure diversity\n            adaptive_diff_weight = self.diff_weight * (1 - diversity)  # Adjust diff_weight based on diversity\n            adaptive_cr = self.cr * (1 - eval_count / self.budget)  # Dynamic crossover rate\n            switch_strategy = eval_count < self.budget * 0.5  # Switch strategy halfway\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + adaptive_diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i]:\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:  # Convergence-based global best update\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Integrate a dynamic crossover probability and improve the DE strategy by adapting the mutation factor based on diversity. ", "configspace": "", "generation": 10, "fitness": 0.8695748004150731, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.870 with standard deviation 0.032. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "62f47366-ff28-4e17-b5dd-2eaae9172bc2", "metadata": {"aucs": [0.8412878420481583, 0.8529348671426831, 0.9145016920543778], "final_y": [0.13389715593481977, 0.12654194100714755, 0.11471636821512121]}, "mutation_prompt": null}
{"id": "d351587a-a077-437a-99fc-9f49dd50884c", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 20)))  # Adjusted the population size calculation\n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.w = 0.5   \n        self.diff_weight = 0.8  \n        self.cr = 0.9   \n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n        num_swarms = 2  # Divide population into swarms\n        while eval_count < self.budget:\n            for swarm in range(num_swarms):  # Iterate through each swarm\n                swarm_slice = slice(swarm, self.population_size, num_swarms)\n                r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n                w_dynamic = 0.3 + 0.2 * (1 - eval_count / self.budget)  # Adjusted the dynamic inertia weight\n                self.c1, self.c2 = 1.5 + 0.5 * (eval_count / self.budget), 1.5 - 0.5 * (eval_count / self.budget)\n                velocities[swarm_slice] = w_dynamic * velocities[swarm_slice] + self.c1 * r1[swarm_slice] * (personal_best[swarm_slice] - pop[swarm_slice]) + self.c2 * r2[swarm_slice] * (global_best - pop[swarm_slice])\n                pop[swarm_slice] = np.clip(pop[swarm_slice] + velocities[swarm_slice], lb, ub)\n\n                scores = np.array([func(ind) for ind in pop[swarm_slice]])\n                eval_count += self.population_size // num_swarms\n                better_mask = scores < personal_best_scores[swarm_slice]\n                personal_best[swarm_slice][better_mask] = pop[swarm_slice][better_mask]\n                personal_best_scores[swarm_slice][better_mask] = scores[better_mask]\n\n                min_idx = np.argmin(personal_best_scores)\n                if personal_best_scores[min_idx] < global_best_score:\n                    global_best_score = personal_best_scores[min_idx]\n                    global_best = personal_best[min_idx]\n\n            adaptive_diff_weight = self.diff_weight * (1 - eval_count / (2 * self.budget))\n            adaptive_cr = max(0.5, self.cr * (2 - eval_count / self.budget))  # Adjusted the adaptive crossover rate\n            switch_strategy = eval_count < self.budget * 0.5\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + adaptive_diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i % len(scores)]:  # Fixed index error by using modulo\n                    pop[i] = trial\n                    scores[i % len(scores)] = trial_score\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Enhance the adaptive inertia and crossover rates for better exploration and exploitation balance.", "configspace": "", "generation": 10, "fitness": 0.8852595205479847, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.885 with standard deviation 0.030. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "9c629139-31d0-47f8-8edc-bcd18a366b40", "metadata": {"aucs": [0.8429414459982767, 0.9046425372750132, 0.9081945783706642], "final_y": [0.13368220390943297, 0.12036805334744038, 0.11668512771349027]}, "mutation_prompt": null}
{"id": "849c00a4-206d-41c8-913a-5580cee7a92a", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(budget / (dim * 10)))\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n        self.w = 0.4   # inertia weight\n        self.diff_weight = 0.8  # differential weight for DE\n        self.cr = 0.9   # crossover probability for DE\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub-lb), abs(ub-lb), (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = personal_best_scores.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # PSO Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = 0.3 + 0.1 * (1 - eval_count / self.budget)  # Dynamic inertia weight\n            self.c1, self.c2 = 1.5 + 0.5 * (eval_count / self.budget), 1.5 - 0.5 * (eval_count / self.budget)  # Dynamic cognitive and social components\n            velocities = w_dynamic * velocities + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            velocities = np.clip(velocities, -0.1 * (ub - lb), 0.1 * (ub - lb))  # Adaptive velocity clamping\n            pop = np.clip(pop + velocities, lb, ub)\n\n            # Evaluate and update personal bests\n            scores = np.array([func(ind) for ind in pop])\n            eval_count += self.population_size\n            better_mask = scores < personal_best_scores\n            personal_best[better_mask] = pop[better_mask]\n            personal_best_scores[better_mask] = scores[better_mask]\n\n            # Update global best\n            min_idx = np.argmin(personal_best_scores)\n            if personal_best_scores[min_idx] < global_best_score:\n                global_best_score = personal_best_scores[min_idx]\n                global_best = personal_best[min_idx]\n\n            # DE Mutation and Crossover\n            adaptive_diff_weight = self.diff_weight * (1 - eval_count / (self.budget))  # Convergence-aware adaptive diff_weight\n            adaptive_cr = self.cr * (1 - eval_count / (2 * self.budget))                    # Adaptive cr correction\n            switch_strategy = eval_count < self.budget * 0.5  # Switch strategy halfway\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + adaptive_diff_weight * (x2 - x3)\n                trial = np.where(np.random.rand(self.dim) < adaptive_cr, mutant, pop[i])\n                trial = np.clip(trial, lb, ub)\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < scores[i] or np.random.rand() < 0.1:  # Acceptance criteria with randomness for exploration\n                    pop[i] = trial\n                    scores[i] = trial_score\n                    if trial_score < global_best_score:  # Convergence-based global best update\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best", "name": "HybridPSO_DE", "description": "Refine Hybrid PSO-DE with adaptive velocity clamping and trial solution acceptance criteria.", "configspace": "", "generation": 10, "fitness": 0.8803996834677146, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.880 with standard deviation 0.006. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "62f47366-ff28-4e17-b5dd-2eaae9172bc2", "metadata": {"aucs": [0.8863760702998751, 0.8824173462465745, 0.872405633856694], "final_y": [0.11037413747732117, 0.11690374594362662, 0.11856273011591256]}, "mutation_prompt": null}
