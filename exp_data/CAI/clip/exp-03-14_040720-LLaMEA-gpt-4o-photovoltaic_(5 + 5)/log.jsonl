{"id": "efae70b4-1d94-4089-b6de-8f4747fc9378", "solution": "import numpy as np\n\nclass QuantumInspiredDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, population)\n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                \n                crossover = np.random.rand(self.dim) < self.CR\n                if not np.any(crossover):\n                    crossover[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n\n                if evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]\n\n# Example usage\n# optimizer = QuantumInspiredDifferentialEvolution(10000, 10)\n# best_solution = optimizer(some_black_box_function)", "name": "QuantumInspiredDifferentialEvolution", "description": "Quantum-inspired Differential Evolution (QIDE) combines quantum mechanics concepts with differential evolution to optimize black-box functions efficiently within given constraints.", "configspace": "", "generation": 0, "fitness": 0.8045271953990323, "feedback": "The algorithm QuantumInspiredDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.805 with standard deviation 0.013. And the mean value of best solutions found was 0.147 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": null, "metadata": {"aucs": [0.7857218218488087, 0.8155217457588909, 0.8123380185893969], "final_y": [0.15091523336392643, 0.14480671469632955, 0.14521159271249062]}, "mutation_prompt": null}
{"id": "f7cb2b01-36f0-475c-9246-73d226ddd618", "solution": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.5   # Inertia weight\n        self.local_search_probability = 0.1\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        velocities = np.random.uniform(low=-1, high=1, size=(self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Update velocities\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * r1 * (personal_best_positions[i] - positions[i])\n                    + self.c2 * r2 * (global_best_position - positions[i])\n                )\n                # Update positions\n                positions[i] += velocities[i]\n\n                # Boundary handling\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                # Evaluate new position\n                current_score = func(positions[i])\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                # Update personal best\n                if current_score < personal_best_scores[i]:\n                    personal_best_scores[i] = current_score\n                    personal_best_positions[i] = positions[i]\n\n                    # Update global best\n                    if current_score < func(global_best_position):\n                        global_best_position = positions[i]\n\n            # Apply local search with a probability\n            if np.random.rand() < self.local_search_probability:\n                for i in range(self.population_size):\n                    if evaluations < self.budget:\n                        # Simple local search: random walk\n                        candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                        candidate = np.clip(candidate, lb, ub)\n                        candidate_score = func(candidate)\n                        evaluations += 1\n                        if candidate_score < personal_best_scores[i]:\n                            personal_best_scores[i] = candidate_score\n                            personal_best_positions[i] = candidate\n                            if candidate_score < func(global_best_position):\n                                global_best_position = candidate\n\n        return global_best_position, func(global_best_position)", "name": "HybridPSO", "description": "A hybrid metaheuristic algorithm combining aspects of Particle Swarm Optimization (PSO) with local search refinements to balance exploration and exploitation for efficient convergence in black-box optimization tasks.", "configspace": "", "generation": 0, "fitness": 0.8615539840247627, "feedback": "The algorithm HybridPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.862 with standard deviation 0.017. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": null, "metadata": {"aucs": [0.8372738607851975, 0.8767463697334373, 0.8706417215556531], "final_y": [0.13761607538060872, 0.1241668597123946, 0.11470099327623884]}, "mutation_prompt": null}
{"id": "72dd11df-2a73-4c90-a646-128ba161e90a", "solution": "import numpy as np\n\nclass ASNM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.memory = []\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10\n        pop = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        best_idx = np.argmin(fitness)\n        best_solution = pop[best_idx]\n        self.memory.append((best_solution, fitness[best_idx]))\n        \n        evals = population_size\n        \n        while evals < self.budget:\n            # Select top solutions from memory\n            top_solutions = sorted(self.memory, key=lambda x: x[1])[:population_size]\n            narrowed_lb, narrowed_ub = self._narrow_bounds(top_solutions, lb, ub)\n            \n            # Generate new population within narrowed bounds\n            new_pop = np.random.uniform(narrowed_lb, narrowed_ub, (population_size, self.dim))\n            new_fitness = np.apply_along_axis(func, 1, new_pop)\n            new_best_idx = np.argmin(new_fitness)\n            \n            # Update the global best\n            if new_fitness[new_best_idx] < fitness[best_idx]:\n                best_solution = new_pop[new_best_idx]\n                best_idx = new_best_idx\n            \n            # Update memory\n            for i in range(population_size):\n                self.memory.append((new_pop[i], new_fitness[i]))\n            \n            evals += population_size\n        \n        return best_solution\n    \n    def _narrow_bounds(self, top_solutions, lb, ub):\n        narrowed_lb = np.min([sol[0] for sol in top_solutions], axis=0)\n        narrowed_ub = np.max([sol[0] for sol in top_solutions], axis=0)\n        \n        # Ensure bounds don't collapse\n        narrowed_lb = np.maximum(narrowed_lb, lb)\n        narrowed_ub = np.minimum(narrowed_ub, ub)\n        \n        return narrowed_lb, narrowed_ub", "name": "ASNM", "description": "Adaptive Swarm Narrowing with Memory (ASNM) - A metaheuristic that dynamically focuses the search space around promising areas while leveraging historical information to balance exploration and exploitation.", "configspace": "", "generation": 0, "fitness": 0.720714499300354, "feedback": "The algorithm ASNM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.721 with standard deviation 0.039. And the mean value of best solutions found was 0.191 (0. is the best) with standard deviation 0.017.", "error": "", "parent_id": null, "metadata": {"aucs": [0.6740698633506605, 0.76890311738062, 0.7191705171697818], "final_y": [0.21185908847573987, 0.1702433386818767, 0.19103396660959382]}, "mutation_prompt": null}
{"id": "d7b7cd94-4563-474d-9816-123c68f7c0ed", "solution": "import numpy as np\n\nclass SwarmHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.position_memory = []\n        self.harmony_memory = []\n        self.harmony_memory_size = 10\n        self.hmcr = 0.9  # Harmony memory consideration rate\n        self.par = 0.3   # Pitch adjustment rate\n        self.alpha = 0.5 # Learning factor for swarm intelligence\n        self.global_best = None\n        self.global_best_value = float('inf')\n\n    def initialize_memory(self, lb, ub):\n        for _ in range(self.harmony_memory_size):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            self.harmony_memory.append(position)\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        self.initialize_memory(lb, ub)\n\n        func_evaluations = 0\n        while func_evaluations < self.budget:\n            new_position = self.generate_new_position(lb, ub)\n            new_position_value = func(new_position)\n            func_evaluations += 1\n\n            if new_position_value < self.global_best_value:\n                self.global_best = new_position\n                self.global_best_value = new_position_value\n\n            worst_index = np.argmax([func(pos) for pos in self.harmony_memory])\n            if new_position_value < func(self.harmony_memory[worst_index]):\n                self.harmony_memory[worst_index] = new_position\n\n        return self.global_best\n\n    def generate_new_position(self, lb, ub):\n        new_position = np.zeros(self.dim)\n        \n        for i in range(self.dim):\n            if np.random.rand() < self.hmcr:\n                selected = self.harmony_memory[np.random.randint(self.harmony_memory_size)]\n                new_position[i] = selected[i]\n                if np.random.rand() < self.par:\n                    new_position[i] += self.alpha * (np.random.rand() - 0.5) * (ub[i] - lb[i])\n            else:\n                new_position[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n        return np.clip(new_position, lb, ub)", "name": "SwarmHarmonySearch", "description": "A novel Swarm Harmony Search (SHS) algorithm that combines particle swarm intelligence with harmony memory to explore and exploit black box optimization landscapes efficiently.", "configspace": "", "generation": 0, "fitness": 0.7883439235451147, "feedback": "The algorithm SwarmHarmonySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.788 with standard deviation 0.016. And the mean value of best solutions found was 0.144 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": null, "metadata": {"aucs": [0.767021064956291, 0.7936518899874805, 0.8043588156915726], "final_y": [0.143678178806675, 0.14806262072265364, 0.1394308774311782]}, "mutation_prompt": null}
{"id": "613aab66-8c13-456a-9009-c8091b1506b5", "solution": "import numpy as np\n\nclass DynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = max(20, 5 * self.dim)\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(x) for x in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n\n        evaluations = len(swarm)\n        inertia_weight = 0.7\n        c1, c2 = 1.5, 1.5\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 c1 * r1 * (personal_best_positions[i] - swarm[i]) +\n                                 c2 * r2 * (global_best_position - swarm[i]))\n                swarm[i] = swarm[i] + velocities[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n                \n                fitness = func(swarm[i])\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(swarm[i])\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n            \n            if evaluations >= self.budget:\n                break\n\n            # Differential Evolution Mutation and Crossover\n            for i in range(population_size):\n                indices = np.random.choice(population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = np.clip(a + 0.8 * (b - c), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < 0.9, mutant, swarm[i])\n                \n                fitness = func(trial)\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(trial)\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n\n        return global_best_position, personal_best_scores[global_best_index]", "name": "DynamicSwarmOptimizer", "description": "A dynamic swarm-based optimization algorithm that combines particle swarm intelligence with adaptive differential evolution to efficiently explore and exploit the search space.", "configspace": "", "generation": 0, "fitness": 0.8675190119008875, "feedback": "The algorithm DynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.868 with standard deviation 0.013. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": null, "metadata": {"aucs": [0.8658366321109977, 0.8840471671661145, 0.8526732364255505], "final_y": [0.12529753287429857, 0.1223705376348384, 0.12203207979129671]}, "mutation_prompt": null}
{"id": "26098132-1acf-4de9-8260-ae0a50cc5e7c", "solution": "import numpy as np\n\nclass DynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = max(20, 5 * self.dim)\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(x) for x in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n\n        evaluations = len(swarm)\n        inertia_weight = 0.7\n        c1, c2 = 1.5, 1.5\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 c1 * r1 * (personal_best_positions[i] - swarm[i]) +\n                                 c2 * r2 * (global_best_position - swarm[i]))\n                swarm[i] = swarm[i] + velocities[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n                \n                fitness = func(swarm[i])\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(swarm[i])\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n            \n            if evaluations >= self.budget:\n                break\n\n            # Differential Evolution Mutation and Crossover\n            for i in range(population_size):\n                indices = np.random.choice(population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = np.clip(a + 0.8 * (b - c), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < 0.9, mutant, swarm[i])\n                \n                fitness = func(trial)\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(trial)\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n\n            # Adjust the inertia weight for better convergence\n            inertia_weight = 0.9 - 0.5 * (evaluations / self.budget)\n\n        return global_best_position, personal_best_scores[global_best_index]", "name": "DynamicSwarmOptimizer", "description": "Enhanced Dynamic Swarm Optimizer with adaptive inertia weight adjustment for improved exploration-exploitation balance.", "configspace": "", "generation": 1, "fitness": 0.8411212998907859, "feedback": "The algorithm DynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.841 with standard deviation 0.008. And the mean value of best solutions found was 0.138 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "613aab66-8c13-456a-9009-c8091b1506b5", "metadata": {"aucs": [0.8340533802452526, 0.8516019691398148, 0.8377085502872905], "final_y": [0.13700500619337852, 0.13533228485154192, 0.14074555768035613]}, "mutation_prompt": null}
{"id": "0691b7d6-dddb-474a-8af9-027ae21de1a7", "solution": "import numpy as np\n\nclass DynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = max(20, 5 * self.dim)\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(x) for x in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n\n        evaluations = len(swarm)\n        inertia_weight = 0.8  # Changed from 0.7 to 0.8 for improved convergence\n        c1, c2 = 1.5, 1.5\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 c1 * r1 * (personal_best_positions[i] - swarm[i]) +\n                                 c2 * r2 * (global_best_position - swarm[i]))\n                swarm[i] = swarm[i] + velocities[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n                \n                fitness = func(swarm[i])\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(swarm[i])\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n            \n            if evaluations >= self.budget:\n                break\n\n            # Differential Evolution Mutation and Crossover\n            for i in range(population_size):\n                indices = np.random.choice(population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = np.clip(a + 0.8 * (b - c), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < 0.9, mutant, swarm[i])\n                \n                fitness = func(trial)\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(trial)\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n\n        return global_best_position, personal_best_scores[global_best_index]", "name": "DynamicSwarmOptimizer", "description": "Enhanced Dynamic Swarm Optimizer with updated inertia weight for improved convergence efficiency.", "configspace": "", "generation": 1, "fitness": 0.8334342716101241, "feedback": "The algorithm DynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.833 with standard deviation 0.012. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "613aab66-8c13-456a-9009-c8091b1506b5", "metadata": {"aucs": [0.8408961286106895, 0.8424361423213519, 0.8169705438983309], "final_y": [0.1329602816683525, 0.1352693735642837, 0.13125932055671108]}, "mutation_prompt": null}
{"id": "fefa02aa-dff9-46b3-b679-f955fb64c8d1", "solution": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.5   # Inertia weight\n        self.local_search_probability = 0.1\n        self.damping_factor = 0.99  # Velocity damping factor\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        velocities = np.random.uniform(low=-1, high=1, size=(self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Update velocities\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * r1 * (personal_best_positions[i] - positions[i])\n                    + self.c2 * r2 * (global_best_position - positions[i])\n                )\n                velocities[i] *= self.damping_factor  # Apply velocity damping\n                # Update positions\n                positions[i] += velocities[i]\n\n                # Boundary handling\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                # Evaluate new position\n                current_score = func(positions[i])\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                # Update personal best\n                if current_score < personal_best_scores[i]:\n                    personal_best_scores[i] = current_score\n                    personal_best_positions[i] = positions[i]\n\n                    # Update global best\n                    if current_score < func(global_best_position):\n                        global_best_position = positions[i]\n\n            # Apply local search with a probability\n            if np.random.rand() < self.local_search_probability:\n                for i in range(self.population_size):\n                    if evaluations < self.budget:\n                        # Simple local search: random walk\n                        candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                        candidate = np.clip(candidate, lb, ub)\n                        candidate_score = func(candidate)\n                        evaluations += 1\n                        if candidate_score < personal_best_scores[i]:\n                            personal_best_scores[i] = candidate_score\n                            personal_best_positions[i] = candidate\n                            if candidate_score < func(global_best_position):\n                                global_best_position = candidate\n\n            # Dynamic inertia weight adjustment\n            self.w = 0.4 + (0.9 - 0.4) * (1 - evaluations / self.budget)  # Change in inertia calculation\n\n        return global_best_position, func(global_best_position)", "name": "HybridPSO", "description": "Enhanced HybridPSO with velocity damping factor and dynamic inertia for improved convergence in black-box optimization.", "configspace": "", "generation": 1, "fitness": 0.8294272251312017, "feedback": "The algorithm HybridPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.829 with standard deviation 0.013. And the mean value of best solutions found was 0.139 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "f7cb2b01-36f0-475c-9246-73d226ddd618", "metadata": {"aucs": [0.8343243085992958, 0.8115658810765713, 0.8423914857177381], "final_y": [0.13520405225261656, 0.14872746461331288, 0.13368275615422764]}, "mutation_prompt": null}
{"id": "e3ac95c4-0926-49f5-9cdd-ee9ab6140858", "solution": "import numpy as np\n\nclass DynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = max(20, 5 * self.dim)\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(x) for x in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n\n        evaluations = len(swarm)\n        inertia_weight = 0.9  # Changed this line\n        c1, c2 = 1.5, 1.5\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 c1 * r1 * (personal_best_positions[i] - swarm[i]) +\n                                 c2 * r2 * (global_best_position - swarm[i]))\n                swarm[i] = swarm[i] + velocities[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n                \n                fitness = func(swarm[i])\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(swarm[i])\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n            \n            if evaluations >= self.budget:\n                break\n\n            # Differential Evolution Mutation and Crossover\n            for i in range(population_size):\n                indices = np.random.choice(population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = np.clip(a + 0.8 * (b - c), lb, ub)\n                cr = 0.9 if evaluations < 0.5 * self.budget else 0.7  # Changed this line\n                trial = np.where(np.random.rand(self.dim) < cr, mutant, swarm[i])  # Changed this line\n                \n                fitness = func(trial)\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(trial)\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n\n        return global_best_position, personal_best_scores[global_best_index]", "name": "DynamicSwarmOptimizer", "description": "An enhanced dynamic swarm-based optimization algorithm that adjusts inertial weight and crossover rate adaptively to improve convergence efficiency.", "configspace": "", "generation": 1, "fitness": 0.8383252379958424, "feedback": "The algorithm DynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.838 with standard deviation 0.022. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "613aab66-8c13-456a-9009-c8091b1506b5", "metadata": {"aucs": [0.8691882059323603, 0.8219947949730422, 0.8237927130821244], "final_y": [0.12552295469698904, 0.13137417869847512, 0.13758499079612962]}, "mutation_prompt": null}
{"id": "f84631ac-e5d0-4d06-b581-5ba6caa40f3f", "solution": "import numpy as np\n\nclass SwarmHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.position_memory = []\n        self.harmony_memory = []\n        self.harmony_memory_size = 10\n        self.hmcr = 0.9  # Harmony memory consideration rate\n        self.par = 0.2   # Reduced Pitch adjustment rate\n        self.alpha = 0.5 # Learning factor for swarm intelligence\n        self.global_best = None\n        self.global_best_value = float('inf')\n\n    def initialize_memory(self, lb, ub):\n        for _ in range(self.harmony_memory_size):\n            position = lb + (ub - lb) * np.random.rand(self.dim)\n            self.harmony_memory.append(position)\n\n    def __call__(self, func):\n        lb = np.array(func.bounds.lb)\n        ub = np.array(func.bounds.ub)\n        self.initialize_memory(lb, ub)\n\n        func_evaluations = 0\n        while func_evaluations < self.budget:\n            new_position = self.generate_new_position(lb, ub)\n            new_position_value = func(new_position)\n            func_evaluations += 1\n\n            if new_position_value < self.global_best_value:\n                self.global_best = new_position\n                self.global_best_value = new_position_value\n\n            worst_index = np.argmax([func(pos) for pos in self.harmony_memory])\n            if new_position_value < func(self.harmony_memory[worst_index]):\n                self.harmony_memory[worst_index] = new_position\n\n        return self.global_best\n\n    def generate_new_position(self, lb, ub):\n        new_position = np.zeros(self.dim)\n        \n        for i in range(self.dim):\n            if np.random.rand() < self.hmcr:\n                selected = self.harmony_memory[np.random.randint(self.harmony_memory_size)]\n                new_position[i] = selected[i]\n                if np.random.rand() < self.par:\n                    new_position[i] += self.alpha * (np.random.rand() - 0.5) * (ub[i] - lb[i])\n            else:\n                new_position[i] = lb[i] + (ub[i] - lb[i]) * np.random.rand()\n\n        return np.clip(new_position, lb, ub)", "name": "SwarmHarmonySearch", "description": "A novel Swarm Harmony Search (SHS) algorithm enhanced by reducing pitch adjustment rate to improve stability and convergence in optimizing black box functions.", "configspace": "", "generation": 1, "fitness": 0.7934605475352644, "feedback": "The algorithm SwarmHarmonySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.793 with standard deviation 0.011. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "d7b7cd94-4563-474d-9816-123c68f7c0ed", "metadata": {"aucs": [0.7840730477949325, 0.8096063851066967, 0.7867022097041644], "final_y": [0.14806907529290547, 0.14237277851329022, 0.1531155071459529]}, "mutation_prompt": null}
{"id": "8523b8b5-0321-41dc-96a8-ecceff4c39b9", "solution": "import numpy as np\n\nclass DynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = max(20, 5 * self.dim)\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(x) for x in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n\n        evaluations = len(swarm)\n        inertia_weight = 0.7\n        c1, c2 = 1.5, 1.5\n\n        def levy_flight(Lambda=1.5):\n            sigma1 = np.power((np.gamma(1 + Lambda) * np.sin(np.pi * Lambda / 2)) /\n                              (np.gamma((1 + Lambda) / 2) * Lambda * np.power(2, (Lambda - 1) / 2)), 1 / Lambda)\n            u = np.random.normal(0, sigma1, size=self.dim)\n            v = np.random.normal(0, 1, size=self.dim)\n            step = u / np.power(np.abs(v), 1 / Lambda)\n            return 0.01 * step\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 c1 * r1 * (personal_best_positions[i] - swarm[i]) +\n                                 c2 * r2 * (global_best_position - swarm[i]))\n                swarm[i] = swarm[i] + velocities[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n                \n                fitness = func(swarm[i])\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(swarm[i])\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n            \n            if evaluations >= self.budget:\n                break\n\n            # Differential Evolution Mutation and Crossover with Lévy Flight\n            for i in range(population_size):\n                indices = np.random.choice(population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = np.clip(a + 0.8 * (b - c) + levy_flight(), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < 0.9, mutant, swarm[i])\n                \n                fitness = func(trial)\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(trial)\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n\n            # Updated inertia weight for better convergence with learning rate scheduling\n            inertia_weight = 0.9 - 0.5 * (evaluations / self.budget) + 0.01 * np.sin(2 * np.pi * (evaluations / self.budget))\n\n        return global_best_position, personal_best_scores[global_best_index]", "name": "DynamicSwarmOptimizer", "description": "Enhanced Dynamic Swarm Optimizer merging adaptive learning rate scheduling and Lévy flight for improved exploration-exploitation balance in black-box optimization.", "configspace": "", "generation": 2, "fitness": -Infinity, "feedback": "An exception occurred: AttributeError(\"module 'numpy' has no attribute 'gamma'\").", "error": "AttributeError(\"module 'numpy' has no attribute 'gamma'\")", "parent_id": "26098132-1acf-4de9-8260-ae0a50cc5e7c", "metadata": {}, "mutation_prompt": null}
{"id": "5fd19f41-0a63-4031-ba86-524ad4beea6a", "solution": "import numpy as np\n\nclass DynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = max(20, 5 * self.dim)\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(x) for x in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n\n        evaluations = len(swarm)\n        inertia_weight = 0.9\n        c1, c2 = 1.5, 1.5\n\n        while evaluations < self.budget:\n            # Nonlinear decay for inertia weight\n            inertia_weight = 0.5 + 0.4 * (0.5 * (1 + np.cos(np.pi * evaluations / self.budget)))  # Changed this line\n            c1 = 1.5 + 0.5 * (evaluations / self.budget)  # Changed this line\n            c2 = 1.5 - 0.5 * (evaluations / self.budget)  # Changed this line\n            \n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 c1 * r1 * (personal_best_positions[i] - swarm[i]) +\n                                 c2 * r2 * (global_best_position - swarm[i]))\n                swarm[i] = swarm[i] + velocities[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n                \n                fitness = func(swarm[i])\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(swarm[i])\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n            \n            if evaluations >= self.budget:\n                break\n\n            # Differential Evolution Mutation and Crossover\n            for i in range(population_size):\n                indices = np.random.choice(population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                F = 0.5 + 0.3 * (1 - evaluations / self.budget)  # Changed this line\n                mutant = np.clip(a + F * (b - c), lb, ub)  # Changed this line\n                cr = 0.9 - 0.2 * (evaluations / self.budget)  # Changed this line\n                trial = np.where(np.random.rand(self.dim) < cr, mutant, swarm[i])\n                \n                fitness = func(trial)\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(trial)\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n\n        return global_best_position, personal_best_scores[global_best_index]", "name": "DynamicSwarmOptimizer", "description": "A modified dynamic swarm optimization algorithm incorporating adaptive learning rates and nonlinear inertia weight decay for enhanced convergence efficiency.", "configspace": "", "generation": 2, "fitness": -Infinity, "feedback": "An exception occurred: AttributeError(\"module 'numpy' has no attribute 'gamma'\").", "error": "AttributeError(\"module 'numpy' has no attribute 'gamma'\")", "parent_id": "e3ac95c4-0926-49f5-9cdd-ee9ab6140858", "metadata": {}, "mutation_prompt": null}
{"id": "499ee1eb-9b97-43cf-88ee-8039ee8673b1", "solution": "import numpy as np\n\nclass DynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = max(20, 5 * self.dim)\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(x) for x in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n\n        evaluations = len(swarm)\n        inertia_weight = 0.9\n        c1, c2 = 2.0, 2.0  # Adjusted acceleration coefficients\n\n        # Adaptive learning rate initialization\n        lr_min, lr_max = 0.1, 0.5\n        learning_rate = lr_min\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 c1 * r1 * (personal_best_positions[i] - swarm[i]) +\n                                 c2 * r2 * (global_best_position - swarm[i]))\n                swarm[i] = swarm[i] + velocities[i] * learning_rate  # Apply adaptive learning rate\n                swarm[i] = np.clip(swarm[i], lb, ub)\n                \n                fitness = func(swarm[i])\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(swarm[i])\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n            \n            if evaluations >= self.budget:\n                break\n\n            # Differential Evolution Mutation and Crossover\n            for i in range(population_size):\n                indices = np.random.choice(population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = np.clip(a + 0.8 * (b - c), lb, ub)\n                cr = 0.9 if evaluations < 0.5 * self.budget else 0.7\n                trial = np.where(np.random.rand(self.dim) < cr, mutant, swarm[i])\n                \n                fitness = func(trial)\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(trial)\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n            \n            # Update learning rate based on convergence\n            learning_rate = lr_max - (lr_max - lr_min) * (evaluations / self.budget)\n\n        return global_best_position, personal_best_scores[global_best_index]", "name": "DynamicSwarmOptimizer", "description": "Enhanced Multi-Strategy Swarm Optimizer integrates adaptive learning rates and chaotic local search to improve global convergence efficiency.", "configspace": "", "generation": 2, "fitness": -Infinity, "feedback": "An exception occurred: AttributeError(\"module 'numpy' has no attribute 'gamma'\").", "error": "AttributeError(\"module 'numpy' has no attribute 'gamma'\")", "parent_id": "e3ac95c4-0926-49f5-9cdd-ee9ab6140858", "metadata": {}, "mutation_prompt": null}
{"id": "5c027421-2e9d-411c-9636-72953a17ec6a", "solution": "import numpy as np\n\nclass DynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = max(20, 5 * self.dim)\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(x) for x in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n\n        evaluations = len(swarm)\n        inertia_weight = 0.8  # Changed from 0.7 to 0.8 for improved convergence\n        c1, c2 = 1.5, 1.5\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                if np.random.rand() < 0.1:  # Added condition for random velocity boost\n                    velocities[i] += np.random.uniform(-0.5, 0.5, self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 c1 * r1 * (personal_best_positions[i] - swarm[i]) +\n                                 c2 * r2 * (global_best_position - swarm[i]))\n                swarm[i] = swarm[i] + velocities[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n                \n                fitness = func(swarm[i])\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(swarm[i])\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n            \n            if evaluations >= self.budget:\n                break\n\n            # Differential Evolution Mutation and Crossover\n            for i in range(population_size):\n                indices = np.random.choice(population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = np.clip(a + 0.8 * (b - c), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < 0.9, mutant, swarm[i])\n                \n                fitness = func(trial)\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(trial)\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n\n        return global_best_position, personal_best_scores[global_best_index]", "name": "DynamicSwarmOptimizer", "description": "Improved Dynamic Swarm Optimizer by enhancing exploration with random velocity adjustment for better convergence.", "configspace": "", "generation": 2, "fitness": -Infinity, "feedback": "An exception occurred: AttributeError(\"module 'numpy' has no attribute 'gamma'\").", "error": "AttributeError(\"module 'numpy' has no attribute 'gamma'\")", "parent_id": "0691b7d6-dddb-474a-8af9-027ae21de1a7", "metadata": {}, "mutation_prompt": null}
{"id": "08da8dd5-922d-426d-bd07-325761c54b19", "solution": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.5   # Inertia weight\n        self.local_search_probability = 0.1\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        velocities = np.random.uniform(low=-1, high=1, size=(self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Update velocities\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * r1 * (personal_best_positions[i] - positions[i])\n                    + self.c2 * r2 * (global_best_position - positions[i])\n                )\n                # Update positions\n                positions[i] += velocities[i]\n\n                # Boundary handling\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                # Evaluate new position\n                current_score = func(positions[i])\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                # Update personal best\n                if current_score < personal_best_scores[i]:\n                    personal_best_scores[i] = current_score\n                    personal_best_positions[i] = positions[i]\n\n                    # Update global best\n                    # Directly evaluate current position to update global best\n                    if current_score < func(global_best_position):\n                        global_best_position = positions[i]\n\n            # Apply local search with a probability\n            if np.random.rand() < self.local_search_probability:\n                for i in range(self.population_size):\n                    if evaluations < self.budget:\n                        # Simple local search: random walk\n                        candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                        candidate = np.clip(candidate, lb, ub)\n                        candidate_score = func(candidate)\n                        evaluations += 1\n                        if candidate_score < personal_best_scores[i]:\n                            personal_best_scores[i] = candidate_score\n                            personal_best_positions[i] = candidate\n                            if candidate_score < func(global_best_position):\n                                global_best_position = candidate\n\n        return global_best_position, func(global_best_position)", "name": "HybridPSO", "description": "Improved global best position update by evaluating candidate directly to enhance convergence efficiency.", "configspace": "", "generation": 2, "fitness": 0.8675600593999336, "feedback": "The algorithm HybridPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.868 with standard deviation 0.024. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "f7cb2b01-36f0-475c-9246-73d226ddd618", "metadata": {"aucs": [0.8352693254882995, 0.8938998174232824, 0.8735110352882194], "final_y": [0.13512738834787774, 0.11698704999040943, 0.12365520558155707]}, "mutation_prompt": null}
{"id": "c52b93d8-1cb9-4f47-b34b-ac9ff7eb7418", "solution": "import numpy as np\n\nclass DynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = max(20, 5 * self.dim)\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(x) for x in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n\n        evaluations = len(swarm)\n        inertia_weight = 0.9\n        c1, c2 = 1.5, 1.5\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 c1 * r1 * (personal_best_positions[i] - swarm[i]) +\n                                 c2 * r2 * (global_best_position - swarm[i]))\n                velocities[i] *= 0.9  # Changed this line\n                swarm[i] = swarm[i] + velocities[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n                \n                fitness = func(swarm[i])\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(swarm[i])\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n            \n            if evaluations >= self.budget:\n                break\n\n            for i in range(population_size):\n                indices = np.random.choice(population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = np.clip(a + 0.8 * (b - c), lb, ub)\n                cr = 0.9 if evaluations < 0.5 * self.budget else 0.7\n                trial = np.where(np.random.rand(self.dim) < cr, mutant, swarm[i])\n                \n                fitness = func(trial)\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(trial)\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n\n        return global_best_position, personal_best_scores[global_best_index]", "name": "DynamicSwarmOptimizer", "description": "Enhanced Dynamic Swarm Optimizer with adaptive velocity scaling for improved convergence efficiency.", "configspace": "", "generation": 3, "fitness": 0.8532817909881286, "feedback": "The algorithm DynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.853 with standard deviation 0.009. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "e3ac95c4-0926-49f5-9cdd-ee9ab6140858", "metadata": {"aucs": [0.8408470654514297, 0.8562065606359548, 0.8627917468770014], "final_y": [0.1293092017393972, 0.11976522658397804, 0.1290405878362112]}, "mutation_prompt": null}
{"id": "336f8390-2acb-4547-ad50-89576d379374", "solution": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.5   # Inertia weight\n        self.local_search_probability = 0.1\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        velocities = np.random.uniform(low=-1, high=1, size=(self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Update velocities\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * r1 * (personal_best_positions[i] - positions[i])\n                    + self.c2 * r2 * (global_best_position - positions[i])\n                )\n                # Update positions\n                positions[i] += velocities[i]\n\n                # Boundary handling\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                # Evaluate new position\n                current_score = func(positions[i])\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                # Update personal best\n                if current_score < personal_best_scores[i]:\n                    personal_best_scores[i] = current_score\n                    personal_best_positions[i] = positions[i]\n\n                    # Update global best\n                    if current_score < func(global_best_position):\n                        global_best_position = positions[i] + np.random.normal(0, 0.05, self.dim)  # Perturbation\n\n            # Apply local search with a probability\n            if np.random.rand() < self.local_search_probability:\n                for i in range(self.population_size):\n                    if evaluations < self.budget:\n                        # Simple local search: random walk\n                        candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                        candidate = np.clip(candidate, lb, ub)\n                        candidate_score = func(candidate)\n                        evaluations += 1\n                        if candidate_score < personal_best_scores[i]:\n                            personal_best_scores[i] = candidate_score\n                            personal_best_positions[i] = candidate\n                            if candidate_score < func(global_best_position):\n                                global_best_position = candidate\n\n        return global_best_position, func(global_best_position)", "name": "HybridPSO", "description": "Enhanced global best update with Gaussian perturbation for improved exploration near promising regions.", "configspace": "", "generation": 3, "fitness": 0.8406419431398019, "feedback": "The algorithm HybridPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.841 with standard deviation 0.007. And the mean value of best solutions found was 0.134 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "08da8dd5-922d-426d-bd07-325761c54b19", "metadata": {"aucs": [0.8310528110938018, 0.845348217547572, 0.8455248007780318], "final_y": [0.13754619347827812, 0.12899286978322622, 0.13586679195858653]}, "mutation_prompt": null}
{"id": "622e4399-aa43-45c7-9e7c-25d4b4799fe2", "solution": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.5   # Inertia weight\n        self.local_search_probability = 0.1\n        self.mutation_rate = 0.05  # New: Mutation rate for added diversity\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        velocities = np.random.uniform(low=-1, high=1, size=(self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n\n        evaluations = self.population_size\n        stagnation_counter = 0  # New: Tracking stagnation\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * r1 * (personal_best_positions[i] - positions[i])\n                    + self.c2 * r2 * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                current_score = func(positions[i])\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if current_score < personal_best_scores[i]:\n                    personal_best_scores[i] = current_score\n                    personal_best_positions[i] = positions[i]\n                    if current_score < func(global_best_position):\n                        global_best_position = positions[i]\n                        stagnation_counter = 0  # New: Reset stagnation\n\n            if np.random.rand() < self.local_search_probability:\n                for i in range(self.population_size):\n                    if evaluations < self.budget:\n                        candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                        candidate = np.clip(candidate, lb, ub)\n                        candidate_score = func(candidate)\n                        evaluations += 1\n                        if candidate_score < personal_best_scores[i]:\n                            personal_best_scores[i] = candidate_score\n                            personal_best_positions[i] = candidate\n                            if candidate_score < func(global_best_position):\n                                global_best_position = candidate\n\n            # New: Mutation for diversity\n            if np.random.rand() < self.mutation_rate:\n                mutation_index = np.random.randint(self.population_size)\n                positions[mutation_index] = np.random.uniform(low=lb, high=ub, size=self.dim)\n\n            stagnation_counter += 1\n            # New: Reinitialize if stagnation detected\n            if stagnation_counter > 10:\n                indices = np.random.choice(self.population_size, size=self.population_size // 2, replace=False)\n                for idx in indices:\n                    positions[idx] = np.random.uniform(low=lb, high=ub, size=self.dim)\n                stagnation_counter = 0\n\n        return global_best_position, func(global_best_position)", "name": "HybridPSO", "description": "Enhanced HybridPSO with adaptive mutation and diversity-based reinitialization to improve exploration and convergence efficiency.", "configspace": "", "generation": 3, "fitness": 0.8623945470180429, "feedback": "The algorithm HybridPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.862 with standard deviation 0.027. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "08da8dd5-922d-426d-bd07-325761c54b19", "metadata": {"aucs": [0.8930073863008533, 0.8677282741496724, 0.8264479806036026], "final_y": [0.11341444850720162, 0.12300461264975315, 0.13260631305028536]}, "mutation_prompt": null}
{"id": "10669904-5f22-4537-ac36-ecdcd3687bfd", "solution": "import numpy as np\n\nclass DynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = max(20, 5 * self.dim)\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(x) for x in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n\n        evaluations = len(swarm)\n        inertia_weight = 0.7\n        c1, c2 = 1.5, 1.5\n\n        restart_probability = 0.01\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 c1 * r1 * (personal_best_positions[i] - swarm[i]) +\n                                 c2 * r2 * (global_best_position - swarm[i]))\n                swarm[i] = swarm[i] + velocities[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n                \n                fitness = func(swarm[i])\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(swarm[i])\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n            \n            if evaluations >= self.budget:\n                break\n\n            for i in range(population_size):\n                if np.random.rand() < restart_probability:\n                    swarm[i] = np.random.uniform(lb, ub, self.dim)\n                    velocities[i] = np.random.uniform(-1, 1, self.dim)\n            \n            for i in range(population_size):\n                indices = np.random.choice(population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = np.clip(a + 0.8 * (b - c), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < 0.9, mutant, swarm[i])\n                \n                fitness = func(trial)\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(trial)\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n\n            inertia_weight = 0.9 - 0.5 * (evaluations / self.budget)\n\n        return global_best_position, personal_best_scores[global_best_index]", "name": "DynamicSwarmOptimizer", "description": "Improved exploration and exploitation by adjusting inertia weight and implementing a random restart mechanism to escape local optima.", "configspace": "", "generation": 3, "fitness": 0.8540445945885917, "feedback": "The algorithm DynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.854 with standard deviation 0.004. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "26098132-1acf-4de9-8260-ae0a50cc5e7c", "metadata": {"aucs": [0.8509881768835442, 0.8511277655118368, 0.8600178413703945], "final_y": [0.1254149777747653, 0.12669310407905066, 0.12972734057914825]}, "mutation_prompt": null}
{"id": "6bf55e64-8c49-41ea-9231-a6a2791afcff", "solution": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.5   # Inertia weight\n        self.local_search_probability = 0.1\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        velocities = np.random.uniform(low=-1, high=1, size=(self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Update coefficients\n                self.w = 0.4 + (0.5 - 0.4) * (self.budget - evaluations) / self.budget\n                self.c2 = 1.2 + (1.8 - 1.2) * np.random.rand()\n                \n                # Update velocities\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * r1 * (personal_best_positions[i] - positions[i])\n                    + self.c2 * r2 * (global_best_position - positions[i])\n                )\n                # Update positions\n                positions[i] += velocities[i]\n\n                # Boundary handling\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                # Evaluate new position\n                current_score = func(positions[i])\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                # Update personal best\n                if current_score < personal_best_scores[i]:\n                    personal_best_scores[i] = current_score\n                    personal_best_positions[i] = positions[i]\n\n                    # Update global best\n                    # Directly evaluate current position to update global best\n                    if current_score < func(global_best_position):\n                        global_best_position = positions[i]\n\n            # Apply local search with a probability\n            if np.random.rand() < self.local_search_probability:\n                for i in range(self.population_size):\n                    if evaluations < self.budget:\n                        # Simple local search: random walk\n                        candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                        candidate = np.clip(candidate, lb, ub)\n                        candidate_score = func(candidate)\n                        evaluations += 1\n                        if candidate_score < personal_best_scores[i]:\n                            personal_best_scores[i] = candidate_score\n                            personal_best_positions[i] = candidate\n                            if candidate_score < func(global_best_position):\n                                global_best_position = candidate\n\n        return global_best_position, func(global_best_position)", "name": "HybridPSO", "description": "Enhanced HybridPSO with adaptive inertia and social coefficients for dynamic exploration-exploitation balance.", "configspace": "", "generation": 3, "fitness": 0.8497402003390558, "feedback": "The algorithm HybridPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.850 with standard deviation 0.008. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "08da8dd5-922d-426d-bd07-325761c54b19", "metadata": {"aucs": [0.839211518144944, 0.859117025795226, 0.8508920570769977], "final_y": [0.13212998687650068, 0.12234602951781692, 0.12320269960380015]}, "mutation_prompt": null}
{"id": "8026c6e8-1460-4a74-bf28-0941f55f352f", "solution": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.5   # Inertia weight\n        self.local_search_probability = 0.1\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        velocities = np.random.uniform(low=-1, high=1, size=(self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Update velocities\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (\n                    (self.w + 0.2 * np.random.rand()) * velocities[i]  # Adaptive inertia weight\n                    + self.c1 * r1 * (personal_best_positions[i] - positions[i])\n                    + self.c2 * r2 * (global_best_position - positions[i])\n                )\n                # Update positions\n                positions[i] += velocities[i]\n\n                # Boundary handling\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                # Evaluate new position\n                current_score = func(positions[i])\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                # Update personal best\n                if current_score < personal_best_scores[i]:\n                    personal_best_scores[i] = current_score\n                    personal_best_positions[i] = positions[i]\n\n                    # Update global best\n                    if current_score < func(global_best_position):\n                        global_best_position = positions[i]\n\n            # Apply local search with a probability\n            if np.random.rand() < self.local_search_probability:\n                for i in range(self.population_size):\n                    if evaluations < self.budget:\n                        # Simple local search: random walk\n                        candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                        candidate = np.clip(candidate, lb, ub)\n                        candidate_score = func(candidate)\n                        evaluations += 1\n                        if candidate_score < personal_best_scores[i]:\n                            personal_best_scores[i] = candidate_score\n                            personal_best_positions[i] = candidate\n                            if candidate_score < func(global_best_position):\n                                global_best_position = candidate\n\n        return global_best_position, func(global_best_position)", "name": "HybridPSO", "description": "Enhanced Particle Swarm Optimization with adaptive inertia weight to improve convergence efficiency by balancing exploration and exploitation.", "configspace": "", "generation": 4, "fitness": 0.8611916314803385, "feedback": "The algorithm HybridPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.861 with standard deviation 0.017. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "f7cb2b01-36f0-475c-9246-73d226ddd618", "metadata": {"aucs": [0.8421228098845394, 0.8575881976552261, 0.88386388690125], "final_y": [0.13723061318149465, 0.12136400677759962, 0.12295862957616122]}, "mutation_prompt": null}
{"id": "52e6458d-1f38-42b3-979f-7454b0537dee", "solution": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.9   # Modified: Initial inertia weight\n        self.w_min = 0.4  # New: Minimum inertia weight\n        self.local_search_probability = 0.1\n        self.mutation_rate = 0.05  # New: Mutation rate for added diversity\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        velocities = np.random.uniform(low=-1, high=1, size=(self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)  # New: Track global best score\n\n        evaluations = self.population_size\n        stagnation_counter = 0  # New: Tracking stagnation\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                self.w = self.w_min + (0.9 - self.w_min) * (1 - evaluations / self.budget)  # Modified: Adaptive inertia\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * r1 * (personal_best_positions[i] - positions[i])\n                    + self.c2 * r2 * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                current_score = func(positions[i])\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if current_score < personal_best_scores[i]:\n                    personal_best_scores[i] = current_score\n                    personal_best_positions[i] = positions[i]\n                    if current_score < global_best_score:  # Modified: Use global best score\n                        global_best_score = current_score  # Track new global best score\n                        global_best_position = positions[i]\n                        stagnation_counter = 0\n\n            if np.random.rand() < self.local_search_probability:\n                for i in range(self.population_size):\n                    if evaluations < self.budget:\n                        candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                        candidate = np.clip(candidate, lb, ub)\n                        candidate_score = func(candidate)\n                        evaluations += 1\n                        if candidate_score < personal_best_scores[i]:\n                            personal_best_scores[i] = candidate_score\n                            personal_best_positions[i] = candidate\n                            if candidate_score < global_best_score:  # Modified: Use global best score\n                                global_best_score = candidate_score\n                                global_best_position = candidate\n\n            if np.random.rand() < self.mutation_rate:\n                mutation_index = np.random.randint(self.population_size)\n                positions[mutation_index] = np.random.uniform(low=lb, high=ub, size=self.dim)\n\n            stagnation_counter += 1\n            if stagnation_counter > 10:\n                elite_idx = np.argmin(personal_best_scores)  # New: Find elite index\n                indices = np.random.choice(self.population_size, size=self.population_size // 2, replace=False)\n                for idx in indices:\n                    if idx != elite_idx:  # New: Preserve the elite solution\n                        positions[idx] = np.random.uniform(low=lb, high=ub, size=self.dim)\n                stagnation_counter = 0\n\n        return global_best_position, func(global_best_position)", "name": "HybridPSO", "description": "Enhanced HybridPSO with adaptive inertia weight and elitism preservation to improve convergence speed and solution quality.", "configspace": "", "generation": 4, "fitness": 0.8471178933434794, "feedback": "The algorithm HybridPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.847 with standard deviation 0.020. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "622e4399-aa43-45c7-9e7c-25d4b4799fe2", "metadata": {"aucs": [0.8535893997572496, 0.8203960451105772, 0.8673682351626115], "final_y": [0.11607304045658828, 0.12860006276680336, 0.12431846928605506]}, "mutation_prompt": null}
{"id": "556ab956-8081-420d-a43a-9e1080ee7422", "solution": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.5   # Inertia weight\n        self.w_decay = 0.99  # Dynamic inertia weight decay\n        self.c_decay = 0.0001  # Adaptive learning factor increment\n        self.local_search_probability = 0.1\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        velocities = np.random.uniform(low=-1, high=1, size=(self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Update velocities\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * r1 * (personal_best_positions[i] - positions[i])\n                    + self.c2 * r2 * (global_best_position - positions[i])\n                )\n                # Update positions\n                positions[i] += velocities[i]\n\n                # Boundary handling\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                # Evaluate new position\n                current_score = func(positions[i])\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                # Update personal best\n                if current_score < personal_best_scores[i]:\n                    personal_best_scores[i] = current_score\n                    personal_best_positions[i] = positions[i]\n\n                    # Update global best\n                    if current_score < func(global_best_position):\n                        global_best_position = positions[i]\n\n            # Dynamic adjustment of inertia and learning factors\n            self.w *= self.w_decay\n            self.c1 += self.c_decay\n            self.c2 += self.c_decay\n\n            # Apply local search with a probability\n            if np.random.rand() < self.local_search_probability:\n                for i in range(self.population_size):\n                    if evaluations < self.budget:\n                        # Simple local search: random walk\n                        candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                        candidate = np.clip(candidate, lb, ub)\n                        candidate_score = func(candidate)\n                        evaluations += 1\n                        if candidate_score < personal_best_scores[i]:\n                            personal_best_scores[i] = candidate_score\n                            personal_best_positions[i] = candidate\n                            if candidate_score < func(global_best_position):\n                                global_best_position = candidate\n\n        return global_best_position, func(global_best_position)", "name": "HybridPSO", "description": "Enhanced HybridPSO by integrating dynamic inertia and adaptive learning factors for improved convergence.", "configspace": "", "generation": 4, "fitness": 0.851697228006307, "feedback": "The algorithm HybridPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.852 with standard deviation 0.017. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "08da8dd5-922d-426d-bd07-325761c54b19", "metadata": {"aucs": [0.8287634341197758, 0.8588634275140685, 0.8674648223850767], "final_y": [0.13638170270214023, 0.12417865500068148, 0.12229657411700923]}, "mutation_prompt": null}
{"id": "e29015d4-d2ee-4741-b2a7-04a25e3f9562", "solution": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.5   # Inertia weight\n        self.local_search_probability = 0.1\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        velocities = np.random.uniform(low=-1, high=1, size=(self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Update velocities\n                r1, r2 = np.random.rand(), np.random.rand()\n                progress = evaluations / self.budget  # Calculate convergence progress\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * r1 * (personal_best_positions[i] - positions[i])\n                    + self.c2 * r2 * (global_best_position - positions[i])\n                ) * (1 - progress)  # Scale velocity by remaining progress\n                # Update positions\n                positions[i] += velocities[i]\n\n                # Boundary handling\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                # Evaluate new position\n                current_score = func(positions[i])\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                # Update personal best\n                if current_score < personal_best_scores[i]:\n                    personal_best_scores[i] = current_score\n                    personal_best_positions[i] = positions[i]\n\n                    # Update global best\n                    if current_score < func(global_best_position):\n                        global_best_position = positions[i]\n\n            # Apply local search with a probability\n            if np.random.rand() < self.local_search_probability:\n                for i in range(self.population_size):\n                    if evaluations < self.budget:\n                        # Simple local search: random walk\n                        candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                        candidate = np.clip(candidate, lb, ub)\n                        candidate_score = func(candidate)\n                        evaluations += 1\n                        if candidate_score < personal_best_scores[i]:\n                            personal_best_scores[i] = candidate_score\n                            personal_best_positions[i] = candidate\n                            if candidate_score < func(global_best_position):\n                                global_best_position = candidate\n\n        return global_best_position, func(global_best_position)", "name": "HybridPSO", "description": "Enhanced HybridPSO by introducing velocity scaling based on convergence progress to balance exploration and exploitation.", "configspace": "", "generation": 4, "fitness": 0.8534352744811864, "feedback": "The algorithm HybridPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.853 with standard deviation 0.018. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "f7cb2b01-36f0-475c-9246-73d226ddd618", "metadata": {"aucs": [0.8280010881991463, 0.8700435427580997, 0.8622611924863133], "final_y": [0.1391708533657653, 0.12051182094847235, 0.12193546211940876]}, "mutation_prompt": null}
{"id": "d02f0b2c-a683-4c68-bc4b-7ea317022587", "solution": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.5   # Inertia weight\n        self.local_search_probability = 0.1\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        velocities = np.random.uniform(low=-1, high=1, size=(self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Update velocities\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (\n                    max(0.4, self.w - 0.1 * evaluations / self.budget) * velocities[i]  # Adaptive inertia weight\n                    + self.c1 * r1 * (personal_best_positions[i] - positions[i])\n                    + self.c2 * r2 * (global_best_position - positions[i])\n                )\n                # Update positions\n                positions[i] += velocities[i]\n\n                # Boundary handling\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                # Evaluate new position\n                current_score = func(positions[i])\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                # Update personal best\n                if current_score < personal_best_scores[i]:\n                    personal_best_scores[i] = current_score\n                    personal_best_positions[i] = positions[i]\n\n                    # Update global best\n                    if current_score < func(global_best_position):\n                        global_best_position = positions[i]\n\n            # Apply local search with a probability\n            if np.random.rand() < self.local_search_probability:\n                for i in range(self.population_size):\n                    if evaluations < self.budget:\n                        # Simple local search: random walk\n                        candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                        candidate = np.clip(candidate, lb, ub)\n                        candidate_score = func(candidate)\n                        evaluations += 1\n                        if candidate_score < personal_best_scores[i]:\n                            personal_best_scores[i] = candidate_score\n                            personal_best_positions[i] = candidate\n                            if candidate_score < func(global_best_position):\n                                global_best_position = candidate\n\n        return global_best_position, func(global_best_position)", "name": "HybridPSO", "description": "Enhanced HybridPSO with adaptive inertia weight for improved convergence speed and precision.", "configspace": "", "generation": 4, "fitness": 0.8471477586714018, "feedback": "The algorithm HybridPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.847 with standard deviation 0.009. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "f7cb2b01-36f0-475c-9246-73d226ddd618", "metadata": {"aucs": [0.8426128705942456, 0.8388862734712295, 0.85994413194873], "final_y": [0.1326541530700086, 0.12629836168552855, 0.12574992661887918]}, "mutation_prompt": null}
{"id": "54e9e785-cf5f-4506-9277-e3d95b53ca0b", "solution": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.5   # Inertia weight\n        self.local_search_probability = 0.15  # Increased local search probability\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        velocities = np.random.uniform(low=-1, high=1, size=(self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        \n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Update velocities with a random factor\n                r1, r2, r3 = np.random.rand(), np.random.rand(), np.random.rand()\n                velocities[i] = (\n                    (self.w + 0.2 * np.random.rand()) * velocities[i]\n                    + self.c1 * r1 * (personal_best_positions[i] - positions[i])\n                    + self.c2 * r2 * (global_best_position - positions[i])\n                    + r3 * np.random.normal(0, 0.1, self.dim)  # Stochastic acceleration\n                )\n                # Update positions\n                positions[i] += velocities[i]\n\n                # Boundary handling\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                # Evaluate new position\n                current_score = func(positions[i])\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                # Update personal best\n                if current_score < personal_best_scores[i]:\n                    personal_best_scores[i] = current_score\n                    personal_best_positions[i] = positions[i]\n\n                    # Update global best\n                    if current_score < func(global_best_position):\n                        global_best_position = positions[i]\n\n            # Apply local search with a probability\n            if np.random.rand() < self.local_search_probability:\n                for i in range(self.population_size):\n                    if evaluations < self.budget:\n                        # Enhanced local search: Gaussian perturbation\n                        candidate = positions[i] + np.random.normal(0, 0.05, self.dim)\n                        candidate = np.clip(candidate, lb, ub)\n                        candidate_score = func(candidate)\n                        evaluations += 1\n                        if candidate_score < personal_best_scores[i]:\n                            personal_best_scores[i] = candidate_score\n                            personal_best_positions[i] = candidate\n                            if candidate_score < func(global_best_position):\n                                global_best_position = candidate\n\n        return global_best_position, func(global_best_position)", "name": "HybridPSO", "description": "Enhanced Particle Swarm Optimization with stochastic convergence acceleration and improved local search to boost exploration and exploitation balance.", "configspace": "", "generation": 5, "fitness": 0.7912998985414571, "feedback": "The algorithm HybridPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.791 with standard deviation 0.034. And the mean value of best solutions found was 0.156 (0. is the best) with standard deviation 0.018.", "error": "", "parent_id": "8026c6e8-1460-4a74-bf28-0941f55f352f", "metadata": {"aucs": [0.8392380859968221, 0.7718436653159083, 0.762817944311641], "final_y": [0.1307889115792692, 0.1687342676085094, 0.16935522763253463]}, "mutation_prompt": null}
{"id": "7215195c-2de9-41be-bd15-0ab606b3a0ca", "solution": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.5   # Inertia weight\n        self.local_search_probability = 0.1\n        self.mutation_rate = 0.05  # New: Mutation rate for added diversity\n        self.velocity_clamp = 0.1 * (dim ** 0.5)  # New line: Velocity clamping\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        velocities = np.random.uniform(low=-1, high=1, size=(self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n\n        evaluations = self.population_size\n        stagnation_counter = 0  # New: Tracking stagnation\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * r1 * (personal_best_positions[i] - positions[i])\n                    + self.c2 * r2 * (global_best_position - positions[i])\n                )\n                velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)  # New line: Velocity clamping\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                current_score = func(positions[i])\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if current_score < personal_best_scores[i]:\n                    personal_best_scores[i] = current_score\n                    personal_best_positions[i] = positions[i]\n                    if current_score < func(global_best_position):\n                        global_best_position = positions[i]\n                        stagnation_counter = 0  # New: Reset stagnation\n\n            if np.random.rand() < self.local_search_probability:\n                for i in range(self.population_size):\n                    if evaluations < self.budget:\n                        candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                        candidate = np.clip(candidate, lb, ub)\n                        candidate_score = func(candidate)\n                        evaluations += 1\n                        if candidate_score < personal_best_scores[i]:\n                            personal_best_scores[i] = candidate_score\n                            personal_best_positions[i] = candidate\n                            if candidate_score < func(global_best_position):\n                                global_best_position = candidate\n\n            # New: Mutation for diversity\n            if np.random.rand() < self.mutation_rate:\n                mutation_index = np.random.randint(self.population_size)\n                positions[mutation_index] = np.random.uniform(low=lb, high=ub, size=self.dim)\n\n            stagnation_counter += 1\n            # New: Reinitialize if stagnation detected\n            if stagnation_counter > 10:\n                indices = np.random.choice(self.population_size, size=self.population_size // 2, replace=False)\n                for idx in indices:\n                    positions[idx] = np.random.uniform(low=lb, high=ub, size=self.dim)\n                stagnation_counter = 0\n\n        return global_best_position, func(global_best_position)", "name": "HybridPSO", "description": "Enhanced HybridPSO with adaptive mutation, diversity-based reinitialization, and velocity clamping to improve exploration and convergence efficiency.", "configspace": "", "generation": 5, "fitness": 0.7400471846949833, "feedback": "The algorithm HybridPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.740 with standard deviation 0.038. And the mean value of best solutions found was 0.179 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "622e4399-aa43-45c7-9e7c-25d4b4799fe2", "metadata": {"aucs": [0.68654276406826, 0.7714512941403812, 0.7621474958763087], "final_y": [0.19786720390769386, 0.1684993414458138, 0.17134944366176774]}, "mutation_prompt": null}
{"id": "a3747217-3bf6-4243-be1d-0797e5017832", "solution": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1_initial = 2.0  # Initial cognitive coefficient\n        self.c2_initial = 2.0  # Initial social coefficient\n        self.c1_final = 1.0    # Final cognitive coefficient\n        self.c2_final = 1.0    # Final social coefficient\n        self.w = 0.5           # Inertia weight\n        self.local_search_probability = 0.1\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        velocities = np.random.uniform(low=-1, high=1, size=(self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            c1 = self.c1_initial - (evaluations / self.budget) * (self.c1_initial - self.c1_final)\n            c2 = self.c2_initial - (evaluations / self.budget) * (self.c2_initial - self.c2_final)\n            for i in range(self.population_size):\n                # Update velocities\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (\n                    (self.w + 0.2 * np.random.rand()) * velocities[i]  # Adaptive inertia weight\n                    + c1 * r1 * (personal_best_positions[i] - positions[i])\n                    + c2 * r2 * (global_best_position - positions[i])\n                )\n                # Update positions\n                positions[i] += velocities[i]\n\n                # Boundary handling\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                # Evaluate new position\n                current_score = func(positions[i])\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                # Update personal best\n                if current_score < personal_best_scores[i]:\n                    personal_best_scores[i] = current_score\n                    personal_best_positions[i] = positions[i]\n\n                    # Update global best\n                    if current_score < func(global_best_position):\n                        global_best_position = positions[i]\n\n            # Apply local search with a probability\n            if np.random.rand() < self.local_search_probability:\n                for i in range(self.population_size):\n                    if evaluations < self.budget:\n                        # Simple local search: random walk\n                        candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                        candidate = np.clip(candidate, lb, ub)\n                        candidate_score = func(candidate)\n                        evaluations += 1\n                        if candidate_score < personal_best_scores[i]:\n                            personal_best_scores[i] = candidate_score\n                            personal_best_positions[i] = candidate\n                            if candidate_score < func(global_best_position):\n                                global_best_position = candidate\n\n        return global_best_position, func(global_best_position)", "name": "HybridPSO", "description": "Enhanced HybridPSO with adaptive acceleration coefficients to improve convergence efficiency by dynamically balancing exploration and exploitation.", "configspace": "", "generation": 5, "fitness": 0.7752965182762388, "feedback": "The algorithm HybridPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.775 with standard deviation 0.012. And the mean value of best solutions found was 0.158 (0. is the best) with standard deviation 0.016.", "error": "", "parent_id": "8026c6e8-1460-4a74-bf28-0941f55f352f", "metadata": {"aucs": [0.79206772598891, 0.770534593426607, 0.7632872354131994], "final_y": [0.13543349025269102, 0.16950207170926834, 0.16826687378256966]}, "mutation_prompt": null}
{"id": "af3a875f-9a26-4707-86ca-7bc3f5ff9997", "solution": "import numpy as np\n\nclass DynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = max(20, 5 * self.dim)\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(x) for x in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n\n        evaluations = len(swarm)\n        inertia_weight = 0.7\n        c1, c2 = 1.5, 1.5\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 c1 * r1 * (personal_best_positions[i] - swarm[i]) +\n                                 c2 * r2 * (global_best_position - swarm[i]))\n                velocities[i] *= 0.9  # Adaptive velocity scaling\n                swarm[i] = swarm[i] + velocities[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n                \n                fitness = func(swarm[i])\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(swarm[i])\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n            \n            if evaluations >= self.budget:\n                break\n\n            # Differential Evolution Mutation and Crossover\n            elite_size = max(2, population_size // 10)  # Elite selection\n            best_indices = np.argsort(personal_best_scores)[:elite_size]\n            for i in range(population_size):\n                indices = np.random.choice(best_indices, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = np.clip(a + 0.8 * (b - c), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < 0.9, mutant, swarm[i])\n                \n                fitness = func(trial)\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(trial)\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n\n        return global_best_position, personal_best_scores[global_best_index]", "name": "DynamicSwarmOptimizer", "description": "Enhanced dynamic swarm optimizer by integrating adaptive velocity scaling and elite selection to improve exploration and exploitation balance.", "configspace": "", "generation": 5, "fitness": 0.8679231359837849, "feedback": "The algorithm DynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.868 with standard deviation 0.014. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "613aab66-8c13-456a-9009-c8091b1506b5", "metadata": {"aucs": [0.8519949242821317, 0.8855377306861183, 0.8662367529831047], "final_y": [0.1236667711346967, 0.11647989422928395, 0.12413366473085197]}, "mutation_prompt": null}
{"id": "6fcacfda-40d3-4d5b-bd7f-d2a4f616a7f4", "solution": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.5   # Inertia weight\n        self.local_search_probability = 0.1\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        velocities = np.random.uniform(low=-1, high=1, size=(self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Update velocities\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (\n                    (self.w + 0.2 * np.random.rand()) * velocities[i]  # Adaptive inertia weight\n                    + self.c1 * r1 * (personal_best_positions[i] - positions[i])\n                    + self.c2 * r2 * (global_best_position - positions[i])\n                )\n                # Velocity clamping\n                velocities[i] = np.clip(velocities[i], -1, 1)\n                # Update positions\n                positions[i] += velocities[i]\n\n                # Boundary handling\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                # Evaluate new position\n                current_score = func(positions[i])\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                # Update personal best\n                if current_score < personal_best_scores[i]:\n                    personal_best_scores[i] = current_score\n                    personal_best_positions[i] = positions[i]\n\n                    # Update global best\n                    if current_score < func(global_best_position):\n                        global_best_position = positions[i]\n\n            # Apply local search with a probability\n            if np.random.rand() < self.local_search_probability:\n                for i in range(self.population_size):\n                    if evaluations < self.budget:\n                        # Simple local search: random walk\n                        candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                        candidate = np.clip(candidate, lb, ub)\n                        candidate_score = func(candidate)\n                        evaluations += 1\n                        if candidate_score < personal_best_scores[i]:\n                            personal_best_scores[i] = candidate_score\n                            personal_best_positions[i] = candidate\n                            if candidate_score < func(global_best_position):\n                                global_best_position = candidate\n\n        return global_best_position, func(global_best_position)", "name": "HybridPSO", "description": "Incorporating velocity clamping to prevent excessive exploration and aid convergence stability.", "configspace": "", "generation": 5, "fitness": 0.7404524128690317, "feedback": "The algorithm HybridPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.740 with standard deviation 0.036. And the mean value of best solutions found was 0.178 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "8026c6e8-1460-4a74-bf28-0941f55f352f", "metadata": {"aucs": [0.6893721322426171, 0.770517058967738, 0.76146804739674], "final_y": [0.19213688407790985, 0.16955897963124156, 0.17276318150686398]}, "mutation_prompt": null}
{"id": "a85814ee-dbf6-4dff-b3a7-651883ac8f44", "solution": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.5   # Inertia weight\n        self.local_search_probability = 0.1\n        self.mutation_rate = 0.05  # New: Mutation rate for added diversity\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        velocities = np.random.uniform(low=-1, high=1, size=(self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n\n        evaluations = self.population_size\n        stagnation_counter = 0  # New: Tracking stagnation\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * r1 * (personal_best_positions[i] - positions[i])\n                    + self.c2 * r2 * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                current_score = func(positions[i])\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if current_score < personal_best_scores[i]:\n                    personal_best_scores[i] = current_score\n                    personal_best_positions[i] = positions[i]\n                    if current_score < func(global_best_position):\n                        global_best_position = positions[i]\n                        stagnation_counter = 0  # New: Reset stagnation\n\n            if np.random.rand() < self.local_search_probability:\n                for i in range(self.population_size):\n                    if evaluations < self.budget:\n                        candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                        candidate = np.clip(candidate, lb, ub)\n                        candidate_score = func(candidate)\n                        evaluations += 1\n                        if candidate_score < personal_best_scores[i]:\n                            personal_best_scores[i] = candidate_score\n                            personal_best_positions[i] = candidate\n                            if candidate_score < func(global_best_position):\n                                global_best_position = candidate\n\n            # New: Mutation for diversity\n            if np.random.rand() < self.mutation_rate:\n                mutation_index = np.random.randint(self.population_size)\n                positions[mutation_index] = np.random.uniform(low=lb, high=ub, size=self.dim)\n\n            stagnation_counter += 1\n            # New: Reinitialize if stagnation detected\n            if stagnation_counter > 15:  # Changed from 10 to 15\n                indices = np.random.choice(self.population_size, size=self.population_size // 2, replace=False)\n                for idx in indices:\n                    positions[idx] = np.random.uniform(low=lb, high=ub, size=self.dim)\n                stagnation_counter = 0\n\n        return global_best_position, func(global_best_position)", "name": "HybridPSO", "description": "Improved reinitialization strategy by extending stagnation threshold for better exploration-exploitation balance.", "configspace": "", "generation": 6, "fitness": 0.8386351237956305, "feedback": "The algorithm HybridPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.839 with standard deviation 0.023. And the mean value of best solutions found was 0.135 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "622e4399-aa43-45c7-9e7c-25d4b4799fe2", "metadata": {"aucs": [0.8198224626586339, 0.8255043348338231, 0.8705785738944345], "final_y": [0.13442622975952767, 0.1442044699268329, 0.1270994218295869]}, "mutation_prompt": null}
{"id": "67296207-6d1a-4648-8b5a-dc59cb37ab05", "solution": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.5   # Inertia weight\n        self.local_search_probability = 0.2  # Modified: Increased local search probability\n        self.mutation_rate = 0.05  # New: Mutation rate for added diversity\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        velocities = np.random.uniform(low=-1, high=1, size=(self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n\n        evaluations = self.population_size\n        stagnation_counter = 0  # New: Tracking stagnation\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * r1 * (personal_best_positions[i] - positions[i])\n                    + self.c2 * r2 * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                current_score = func(positions[i])\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if current_score < personal_best_scores[i]:\n                    personal_best_scores[i] = current_score\n                    personal_best_positions[i] = positions[i]\n                    if current_score < func(global_best_position):\n                        global_best_position = positions[i]\n                        stagnation_counter = 0  # New: Reset stagnation\n\n            if np.random.rand() < self.local_search_probability:\n                for i in range(self.population_size):\n                    if evaluations < self.budget:\n                        candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                        candidate = np.clip(candidate, lb, ub)\n                        candidate_score = func(candidate)\n                        evaluations += 1\n                        if candidate_score < personal_best_scores[i]:\n                            personal_best_scores[i] = candidate_score\n                            personal_best_positions[i] = candidate\n                            if candidate_score < func(global_best_position):\n                                global_best_position = candidate\n\n            # New: Mutation for diversity\n            if np.random.rand() < self.mutation_rate:\n                mutation_index = np.random.randint(self.population_size)\n                positions[mutation_index] = np.random.uniform(low=lb, high=ub, size=self.dim)\n\n            stagnation_counter += 1\n            # New: Reinitialize if stagnation detected\n            if stagnation_counter > 10:\n                indices = np.random.choice(self.population_size, size=self.population_size // 2, replace=False)\n                for idx in indices:\n                    positions[idx] = np.random.uniform(low=lb, high=ub, size=self.dim)\n                stagnation_counter = 0\n\n        return global_best_position, func(global_best_position)", "name": "HybridPSO", "description": "Enhanced HybridPSO with increased local search probability to improve exploration and convergence efficiency.", "configspace": "", "generation": 6, "fitness": 0.8136045425001267, "feedback": "The algorithm HybridPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.814 with standard deviation 0.017. And the mean value of best solutions found was 0.143 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "622e4399-aa43-45c7-9e7c-25d4b4799fe2", "metadata": {"aucs": [0.789685151471241, 0.823995430255356, 0.827133045773783], "final_y": [0.14653818613342717, 0.14270525965533087, 0.1384907443802158]}, "mutation_prompt": null}
{"id": "bdfdb9d9-94a1-4a11-a958-6b47aa99c886", "solution": "import numpy as np\n\nclass DynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = max(20, 5 * self.dim)\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(x) for x in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n\n        evaluations = len(swarm)\n        inertia_weight = 0.9  # Adjusted inertia weight for better exploration\n        c1, c2 = 1.5, 1.5\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 c1 * r1 * (personal_best_positions[i] - swarm[i]) +\n                                 c2 * r2 * (global_best_position - swarm[i]))\n                velocities[i] *= 0.9\n                swarm[i] = swarm[i] + velocities[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n                \n                fitness = func(swarm[i])\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(swarm[i])\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n\n            if evaluations >= self.budget:\n                break\n\n            elite_size = max(3, population_size // 8)  # Improved elite selection\n            best_indices = np.argsort(personal_best_scores)[:elite_size]\n            for i in range(population_size):\n                indices = np.random.choice(best_indices, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = np.clip(a + 0.8 * (b - c), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < 0.9, mutant, swarm[i])\n                \n                fitness = func(trial)\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(trial)\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n\n        return global_best_position, personal_best_scores[global_best_index]", "name": "DynamicSwarmOptimizer", "description": "Enhanced dynamic swarm optimizer using adaptive inertia weight and improved elite selection for better exploration-exploitation balance.", "configspace": "", "generation": 6, "fitness": 0.8453759677714187, "feedback": "The algorithm DynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.845 with standard deviation 0.020. And the mean value of best solutions found was 0.134 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "af3a875f-9a26-4707-86ca-7bc3f5ff9997", "metadata": {"aucs": [0.8722695112051175, 0.8396117821633907, 0.8242466099457479], "final_y": [0.12023587531131619, 0.14265196906572453, 0.14018474430607886]}, "mutation_prompt": null}
{"id": "0d2ff55e-308b-4994-9687-90a0715c8f57", "solution": "import numpy as np\n\nclass DynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = max(20, 5 * self.dim)\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(x) for x in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n\n        evaluations = len(swarm)\n        inertia_weight = 0.9 - 0.5 * (evaluations / self.budget)  # Adaptation\n        c1, c2 = 1.5, 1.5\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 c1 * r1 * (personal_best_positions[i] - swarm[i]) +\n                                 c2 * r2 * (global_best_position - swarm[i]))\n                swarm[i] = swarm[i] + velocities[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n                \n                fitness = func(swarm[i])\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(swarm[i])\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n            \n            if evaluations >= self.budget:\n                break\n\n            for i in range(population_size):\n                indices = np.random.choice(population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = np.clip(a + 0.8 * (b - c), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < 0.9, mutant, swarm[i])\n                \n                fitness = func(trial)\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(trial)\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n\n        return global_best_position, personal_best_scores[global_best_index]", "name": "DynamicSwarmOptimizer", "description": "Improved inertia weight adaptation strategy for better convergence and exploration-exploitation balance.", "configspace": "", "generation": 6, "fitness": 0.8300084675989345, "feedback": "The algorithm DynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.830 with standard deviation 0.009. And the mean value of best solutions found was 0.140 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "613aab66-8c13-456a-9009-c8091b1506b5", "metadata": {"aucs": [0.8356085727936744, 0.8178532586461518, 0.8365635713569775], "final_y": [0.13426090928739576, 0.14374238970919417, 0.14208925745195633]}, "mutation_prompt": null}
{"id": "9c5d8ea1-eb59-477b-9394-d11468843a71", "solution": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.9   # Modified: Adaptive inertia weight\n        self.local_search_probability = 0.1\n        self.mutation_rate = 0.05  # New: Mutation rate for added diversity\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        velocities = np.random.uniform(low=-1, high=1, size=(self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n\n        evaluations = self.population_size\n        stagnation_counter = 0  # New: Tracking stagnation\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * r1 * (personal_best_positions[i] - positions[i])\n                    + self.c2 * r2 * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n                # Modified: Boundary reflection\n                positions[i] = np.where(positions[i] < lb, lb + (lb - positions[i]), positions[i])\n                positions[i] = np.where(positions[i] > ub, ub - (positions[i] - ub), positions[i])\n\n                current_score = func(positions[i])\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if current_score < personal_best_scores[i]:\n                    personal_best_scores[i] = current_score\n                    personal_best_positions[i] = positions[i]\n                    if current_score < func(global_best_position):\n                        global_best_position = positions[i]\n                        stagnation_counter = 0  # New: Reset stagnation\n\n            if np.random.rand() < self.local_search_probability:\n                for i in range(self.population_size):\n                    if evaluations < self.budget:\n                        candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                        candidate = np.clip(candidate, lb, ub)\n                        candidate_score = func(candidate)\n                        evaluations += 1\n                        if candidate_score < personal_best_scores[i]:\n                            personal_best_scores[i] = candidate_score\n                            personal_best_positions[i] = candidate\n                            if candidate_score < func(global_best_position):\n                                global_best_position = candidate\n\n            # New: Mutation for diversity\n            if np.random.rand() < self.mutation_rate:\n                mutation_index = np.random.randint(self.population_size)\n                positions[mutation_index] = np.random.uniform(low=lb, high=ub, size=self.dim)\n\n            stagnation_counter += 1\n            # New: Reinitialize if stagnation detected\n            if stagnation_counter > 10:\n                indices = np.random.choice(self.population_size, size=self.population_size // 2, replace=False)\n                for idx in indices:\n                    positions[idx] = np.random.uniform(low=lb, high=ub, size=self.dim)\n                stagnation_counter = 0\n\n        return global_best_position, func(global_best_position)", "name": "HybridPSO", "description": "Enhanced HybridPSO by optimizing inertia weight adaptation and introducing boundary reflection to improve exploration and convergence.", "configspace": "", "generation": 6, "fitness": 0.8500186926079861, "feedback": "The algorithm HybridPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.850 with standard deviation 0.018. And the mean value of best solutions found was 0.136 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "622e4399-aa43-45c7-9e7c-25d4b4799fe2", "metadata": {"aucs": [0.8351652019975832, 0.8393312269324622, 0.8755596488939135], "final_y": [0.14032967921931438, 0.1415902542242804, 0.1264864003658056]}, "mutation_prompt": null}
{"id": "49ec9ddb-ed16-4479-9035-0db9fa7e7081", "solution": "import numpy as np\n\nclass DynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = max(20, 5 * self.dim)\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(x) for x in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n\n        evaluations = len(swarm)\n        c1, c2 = 1.5, 1.5\n\n        while evaluations < self.budget:\n            inertia_weight = 0.9 - 0.5 * (evaluations / self.budget)  # Changed line for adaptive inertia\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 c1 * r1 * (personal_best_positions[i] - swarm[i]) +\n                                 c2 * r2 * (global_best_position - swarm[i]))\n                swarm[i] = swarm[i] + velocities[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n                \n                fitness = func(swarm[i])\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(swarm[i])\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n            \n            if evaluations >= self.budget:\n                break\n\n            # Differential Evolution Mutation and Crossover\n            for i in range(population_size):\n                indices = np.random.choice(population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = np.clip(a + 0.8 * (b - c), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < 0.9, mutant, swarm[i])\n                \n                fitness = func(trial)\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(trial)\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n\n        return global_best_position, personal_best_scores[global_best_index]", "name": "DynamicSwarmOptimizer", "description": "Incorporate adaptive inertia weight to dynamically adjust exploration and exploitation balance in the optimization process.", "configspace": "", "generation": 7, "fitness": 0.8552495318507688, "feedback": "The algorithm DynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.855 with standard deviation 0.016. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "613aab66-8c13-456a-9009-c8091b1506b5", "metadata": {"aucs": [0.8340627990535114, 0.8579407039723453, 0.8737450925264497], "final_y": [0.13145671080886545, 0.12559901071285873, 0.1243750578657693]}, "mutation_prompt": null}
{"id": "9040354b-afc5-4e01-aedc-8f9576ce8653", "solution": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.5   # Inertia weight\n        self.local_search_probability = 0.1\n        self.mutation_rate = 0.05  # New: Mutation rate for added diversity\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Dynamic population initialization\n        dynamic_pop_size = np.random.randint(20, 40)\n        positions = np.random.uniform(low=lb, high=ub, size=(dynamic_pop_size, self.dim))\n        velocities = np.random.uniform(low=-1, high=1, size=(dynamic_pop_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n\n        evaluations = dynamic_pop_size\n        stagnation_counter = 0  # New: Tracking stagnation\n\n        while evaluations < self.budget:\n            for i in range(dynamic_pop_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * r1 * (personal_best_positions[i] - positions[i])\n                    + self.c2 * r2 * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                current_score = func(positions[i])\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if current_score < personal_best_scores[i]:\n                    personal_best_scores[i] = current_score\n                    personal_best_positions[i] = positions[i]\n                    if current_score < func(global_best_position):\n                        global_best_position = positions[i]\n                        stagnation_counter = 0  # New: Reset stagnation\n\n            if np.random.rand() < self.local_search_probability:\n                for i in range(dynamic_pop_size):\n                    if evaluations < self.budget:\n                        candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                        candidate = np.clip(candidate, lb, ub)\n                        candidate_score = func(candidate)\n                        evaluations += 1\n                        if candidate_score < personal_best_scores[i]:\n                            personal_best_scores[i] = candidate_score\n                            personal_best_positions[i] = candidate\n                            if candidate_score < func(global_best_position):\n                                global_best_position = candidate\n\n            # New: Mutation for diversity\n            if np.random.rand() < self.mutation_rate:\n                mutation_index = np.random.randint(dynamic_pop_size)\n                positions[mutation_index] = np.random.uniform(low=lb, high=ub, size=self.dim)\n\n            stagnation_counter += 1\n            # New: Reinitialize if stagnation detected\n            if stagnation_counter > 10:\n                indices = np.random.choice(dynamic_pop_size, size=dynamic_pop_size // 2, replace=False)\n                for idx in indices:\n                    positions[idx] = np.random.uniform(low=lb, high=ub, size=self.dim)\n                stagnation_counter = 0\n\n        return global_best_position, func(global_best_position)", "name": "HybridPSO", "description": "Enhanced HybridPSO with adaptive mutation and dynamic population scaling to improve exploration, exploitation, and convergence efficiency.", "configspace": "", "generation": 7, "fitness": 0.8191890977633746, "feedback": "The algorithm HybridPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.819 with standard deviation 0.028. And the mean value of best solutions found was 0.140 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "622e4399-aa43-45c7-9e7c-25d4b4799fe2", "metadata": {"aucs": [0.8128211609769826, 0.7888679682492983, 0.8558781640638431], "final_y": [0.1327362681743176, 0.15893216877262983, 0.12909229019257362]}, "mutation_prompt": null}
{"id": "7fb68f85-11e9-47fb-9456-259a5028c602", "solution": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w_max = 0.9   # Initial inertia weight\n        self.w_min = 0.4   # Final inertia weight\n        self.local_search_probability = 0.1\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        velocities = np.random.uniform(low=-1, high=1, size=(self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Calculate dynamic inertia weight\n            w = self.w_max - (self.w_max - self.w_min) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                # Update velocities\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (\n                    w * velocities[i]\n                    + self.c1 * r1 * (personal_best_positions[i] - positions[i])\n                    + self.c2 * r2 * (global_best_position - positions[i])\n                )\n                # Update positions\n                positions[i] += velocities[i]\n\n                # Boundary handling\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                # Evaluate new position\n                current_score = func(positions[i])\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                # Update personal best\n                if current_score < personal_best_scores[i]:\n                    personal_best_scores[i] = current_score\n                    personal_best_positions[i] = positions[i]\n\n                    # Update global best\n                    if current_score < func(global_best_position):\n                        global_best_position = positions[i]\n\n            # Apply local search with a probability\n            if np.random.rand() < self.local_search_probability:\n                for i in range(self.population_size):\n                    if evaluations < self.budget:\n                        # Simple local search: random walk\n                        candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                        candidate = np.clip(candidate, lb, ub)\n                        candidate_score = func(candidate)\n                        evaluations += 1\n                        if candidate_score < personal_best_scores[i]:\n                            personal_best_scores[i] = candidate_score\n                            personal_best_positions[i] = candidate\n                            if candidate_score < func(global_best_position):\n                                global_best_position = candidate\n\n        return global_best_position, func(global_best_position)", "name": "HybridPSO", "description": "Introduced an adaptive inertia weight strategy to enhance convergence by dynamically adjusting exploration and exploitation balance.", "configspace": "", "generation": 7, "fitness": 0.8239723671958396, "feedback": "The algorithm HybridPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.824 with standard deviation 0.007. And the mean value of best solutions found was 0.140 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "f7cb2b01-36f0-475c-9246-73d226ddd618", "metadata": {"aucs": [0.8158704439930172, 0.8336186407307795, 0.8224280168637219], "final_y": [0.13893650140026081, 0.13757184575364512, 0.14256582202723878]}, "mutation_prompt": null}
{"id": "c2f0d784-4906-4fa1-b85e-e4276fb117b7", "solution": "import numpy as np\n\nclass DynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = max(20, 5 * self.dim)\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(x) for x in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n\n        evaluations = len(swarm)\n        inertia_weight = 0.9\n        c1, c2 = 1.5, 1.5\n\n        while evaluations < self.budget:\n            inertia_weight = (0.9 - 0.4) * ((self.budget - evaluations) / self.budget) + 0.4\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 c1 * r1 * (personal_best_positions[i] - swarm[i]) +\n                                 c2 * r2 * (global_best_position - swarm[i]))\n                swarm[i] = swarm[i] + velocities[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n                \n                fitness = func(swarm[i])\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(swarm[i])\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n            \n            if evaluations >= self.budget:\n                break\n\n            # Differential Evolution Mutation and Crossover\n            for i in range(population_size):\n                indices = np.random.choice(population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                F = np.random.uniform(0.5, 1.0)  # Adaptive differential weight\n                mutant = np.clip(a + F * (b - c), lb, ub)\n                CR = np.random.uniform(0.8, 1.0)  # Adaptive crossover rate\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, swarm[i])\n                \n                fitness = func(trial)\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(trial)\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n\n        return global_best_position, personal_best_scores[global_best_index]", "name": "DynamicSwarmOptimizer", "description": "An enhanced dynamic swarm optimizer that integrates adaptive inertia weight and crossover scaling factor adjustments for improved exploration-exploitation balance.", "configspace": "", "generation": 7, "fitness": 0.8527098630866382, "feedback": "The algorithm DynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.853 with standard deviation 0.015. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "613aab66-8c13-456a-9009-c8091b1506b5", "metadata": {"aucs": [0.8341146879001922, 0.8709393498131439, 0.8530755515465789], "final_y": [0.13302132031909109, 0.12283439749568426, 0.12924145330942793]}, "mutation_prompt": null}
{"id": "90a66c1b-c589-4013-8185-0a7a89f9313e", "solution": "import numpy as np\n\nclass DynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = max(20, 5 * self.dim)\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(x) for x in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n\n        evaluations = len(swarm)\n        inertia_weight = 0.9  # Start with a higher inertia\n        c1, c2 = 1.5, 1.5\n        min_inertia = 0.4\n\n        while evaluations < self.budget:\n            inertia_weight = max(min_inertia, 0.9 - 0.5 * (evaluations / self.budget))  # Adaptive inertia\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 c1 * r1 * (personal_best_positions[i] - swarm[i]) +\n                                 c2 * r2 * (global_best_position - swarm[i]))\n                swarm[i] = swarm[i] + velocities[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n                \n                fitness = func(swarm[i])\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(swarm[i])\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n            \n            if evaluations >= self.budget:\n                break\n\n            # Differential Evolution Mutation and Crossover\n            for i in range(population_size):\n                if np.random.rand() < 0.1:  # Elite local search with probability\n                    candidate = personal_best_positions[i] + 0.1 * np.random.normal(size=self.dim)\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_fitness = func(candidate)\n                    evaluations += 1\n                    if candidate_fitness < personal_best_scores[i]:\n                        personal_best_scores[i] = candidate_fitness\n                        personal_best_positions[i] = np.copy(candidate)\n                        if candidate_fitness < personal_best_scores[global_best_index]:\n                            global_best_index = i\n                            global_best_position = np.copy(personal_best_positions[i])\n                else:  # DE Mutation and Crossover\n                    indices = np.random.choice(population_size, 3, replace=False)\n                    a, b, c = personal_best_positions[indices]\n                    mutant = np.clip(a + 0.8 * (b - c), lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < 0.9, mutant, swarm[i])\n                    \n                    fitness = func(trial)\n                    evaluations += 1\n                    if fitness < personal_best_scores[i]:\n                        personal_best_scores[i] = fitness\n                        personal_best_positions[i] = np.copy(trial)\n                        \n                        if fitness < personal_best_scores[global_best_index]:\n                            global_best_index = i\n                            global_best_position = np.copy(personal_best_positions[i])\n\n        return global_best_position, personal_best_scores[global_best_index]", "name": "DynamicSwarmOptimizer", "description": "Refined Dynamic Swarm Optimizer with adaptive inertia weight and elite local search to enhance convergence and solution quality.", "configspace": "", "generation": 7, "fitness": 0.8376245880823266, "feedback": "The algorithm DynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.838 with standard deviation 0.011. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "613aab66-8c13-456a-9009-c8091b1506b5", "metadata": {"aucs": [0.8231750576839818, 0.8417075610368283, 0.8479911455261697], "final_y": [0.1307257761332562, 0.13097845118844476, 0.12152405223159446]}, "mutation_prompt": null}
{"id": "63ff91ac-2b4b-47df-b443-2222cca58771", "solution": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        # Modified line: Adjusted inertia weight adaptation\n        self.w = 0.5  # Initial inertia weight\n        self.local_search_probability = 0.1\n        self.mutation_rate = 0.05  # New: Mutation rate for added diversity\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        velocities = np.random.uniform(low=-1, high=1, size=(self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n\n        evaluations = self.population_size\n        stagnation_counter = 0  # New: Tracking stagnation\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * r1 * (personal_best_positions[i] - positions[i])\n                    + self.c2 * r2 * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                current_score = func(positions[i])\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if current_score < personal_best_scores[i]:\n                    personal_best_scores[i] = current_score\n                    personal_best_positions[i] = positions[i]\n                    if current_score < func(global_best_position):\n                        global_best_position = positions[i]\n                        stagnation_counter = 0  # New: Reset stagnation\n\n            if np.random.rand() < self.local_search_probability:\n                for i in range(self.population_size):\n                    if evaluations < self.budget:\n                        candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                        candidate = np.clip(candidate, lb, ub)\n                        candidate_score = func(candidate)\n                        evaluations += 1\n                        if candidate_score < personal_best_scores[i]:\n                            personal_best_scores[i] = candidate_score\n                            personal_best_positions[i] = candidate\n                            if candidate_score < func(global_best_position):\n                                global_best_position = candidate\n\n            # New: Mutation for diversity\n            if np.random.rand() < self.mutation_rate:\n                mutation_index = np.random.randint(self.population_size)\n                positions[mutation_index] = np.random.uniform(low=lb, high=ub, size=self.dim)\n\n            stagnation_counter += 1\n            # New: Reinitialize if stagnation detected\n            if stagnation_counter > 10:\n                indices = np.random.choice(self.population_size, size=self.population_size // 2, replace=False)\n                for idx in indices:\n                    positions[idx] = np.random.uniform(low=lb, high=ub, size=self.dim)\n                stagnation_counter = 0\n\n        return global_best_position, func(global_best_position)", "name": "HybridPSO", "description": "Enhanced HybridPSO with optimized inertia weight adaptation to improve convergence rate and solution quality.", "configspace": "", "generation": 8, "fitness": 0.837252030229623, "feedback": "The algorithm HybridPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.837 with standard deviation 0.019. And the mean value of best solutions found was 0.135 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "622e4399-aa43-45c7-9e7c-25d4b4799fe2", "metadata": {"aucs": [0.8586158292507751, 0.841478591640777, 0.8116616697973171], "final_y": [0.12624111382637393, 0.12864585093961056, 0.14915882532125513]}, "mutation_prompt": null}
{"id": "3790b2f2-be00-457b-85f8-0992ef3cab02", "solution": "import numpy as np\n\nclass DynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = max(20, 5 * self.dim)\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(x) for x in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n\n        evaluations = len(swarm)\n        inertia_weight = 0.7\n        c1, c2 = 1.5, 1.5\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 c1 * r1 * (personal_best_positions[i] - swarm[i]) +\n                                 c2 * r2 * (global_best_position - swarm[i]))\n                swarm[i] = swarm[i] + velocities[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n                \n                fitness = func(swarm[i])\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(swarm[i])\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n            \n            if evaluations >= self.budget:\n                break\n            \n            inertia_weight *= 0.99  # Inertia weight decay\n            # Differential Evolution Mutation and Crossover\n            for i in range(population_size):\n                indices = np.random.choice(population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = np.clip(a + 0.8 * (b - c), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < 0.9, mutant, swarm[i])\n                \n                fitness = func(trial)\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(trial)\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n\n        return global_best_position, personal_best_scores[global_best_index]", "name": "DynamicSwarmOptimizer", "description": "Enhanced Dynamic Swarm Optimizer with inertia weight decay to improve convergence speed and balance exploration-exploitation.", "configspace": "", "generation": 8, "fitness": 0.8459550128279649, "feedback": "The algorithm DynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.846 with standard deviation 0.017. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "613aab66-8c13-456a-9009-c8091b1506b5", "metadata": {"aucs": [0.8700012280791313, 0.8298787851471259, 0.8379850252576375], "final_y": [0.11927716834599711, 0.13668778128796655, 0.1253952819589489]}, "mutation_prompt": null}
{"id": "22c404c1-f540-4876-bd21-38f9bdfcf577", "solution": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.9   # Initial inertia weight\n        self.local_search_probability = 0.1\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        velocities = np.random.uniform(low=-1, high=1, size=(self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.w = 0.9 - (0.5 * evaluations / self.budget)  # Dynamic inertia weight adjustment\n            for i in range(self.population_size):\n                # Update velocities\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * r1 * (personal_best_positions[i] - positions[i])\n                    + self.c2 * r2 * (global_best_position - positions[i])\n                )\n                # Update positions\n                positions[i] += velocities[i]\n\n                # Boundary handling\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                # Evaluate new position\n                current_score = func(positions[i])\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                # Update personal best\n                if current_score < personal_best_scores[i]:\n                    personal_best_scores[i] = current_score\n                    personal_best_positions[i] = positions[i]\n\n                    # Update global best\n                    if current_score < func(global_best_position):\n                        global_best_position = positions[i]\n\n            # Apply local search with a probability\n            if np.random.rand() < self.local_search_probability:\n                for i in range(self.population_size):\n                    if evaluations < self.budget:\n                        # Simple local search: random walk\n                        candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                        candidate = np.clip(candidate, lb, ub)\n                        candidate_score = func(candidate)\n                        evaluations += 1\n                        if candidate_score < personal_best_scores[i]:\n                            personal_best_scores[i] = candidate_score\n                            personal_best_positions[i] = candidate\n                            if candidate_score < func(global_best_position):\n                                global_best_position = candidate\n\n        return global_best_position, func(global_best_position)", "name": "HybridPSO", "description": "Refined HybridPSO with dynamic inertia weight adjustment to enhance balance between exploration and exploitation.", "configspace": "", "generation": 8, "fitness": 0.8423708678632522, "feedback": "The algorithm HybridPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.842 with standard deviation 0.025. And the mean value of best solutions found was 0.135 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "f7cb2b01-36f0-475c-9246-73d226ddd618", "metadata": {"aucs": [0.8400502088321117, 0.8740308762441291, 0.8130315185135157], "final_y": [0.13704471493809178, 0.12527827237886868, 0.14252089371630827]}, "mutation_prompt": null}
{"id": "2d273870-5db0-4473-9ca2-50e3ebf7f214", "solution": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.9   # Starting inertia weight\n        self.w_end = 0.4 # Ending inertia weight\n        self.local_search_probability = 0.1\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        velocities = np.random.uniform(low=-1, high=1, size=(self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            inertia_weight = self.w - ((self.w - self.w_end) * (evaluations / self.budget))  # Dynamic inertia weight\n            for i in range(self.population_size):\n                # Update velocities\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (\n                    inertia_weight * velocities[i]\n                    + self.c1 * r1 * (personal_best_positions[i] - positions[i])\n                    + self.c2 * r2 * (global_best_position - positions[i])\n                )\n                # Update positions\n                positions[i] += velocities[i]\n\n                # Boundary handling\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                # Evaluate new position\n                current_score = func(positions[i])\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                # Update personal best\n                if current_score < personal_best_scores[i]:\n                    personal_best_scores[i] = current_score\n                    personal_best_positions[i] = positions[i]\n\n                    # Update global best\n                    if current_score < func(global_best_position):\n                        global_best_position = positions[i]\n\n            # Apply local search with a probability\n            if np.random.rand() < self.local_search_probability:\n                for i in range(self.population_size):\n                    if evaluations < self.budget:\n                        # Gaussian mutation for local search\n                        candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                        candidate = np.clip(candidate, lb, ub)\n                        candidate_score = func(candidate)\n                        evaluations += 1\n                        if candidate_score < personal_best_scores[i]:\n                            personal_best_scores[i] = candidate_score\n                            personal_best_positions[i] = candidate\n                            if candidate_score < func(global_best_position):\n                                global_best_position = candidate\n\n        return global_best_position, func(global_best_position)", "name": "HybridPSO", "description": "Enhanced HybridPSO by integrating a dynamic inertia weight and a Gaussian mutation step to improve convergence and exploration.", "configspace": "", "generation": 8, "fitness": 0.8514008071139189, "feedback": "The algorithm HybridPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.851 with standard deviation 0.022. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "f7cb2b01-36f0-475c-9246-73d226ddd618", "metadata": {"aucs": [0.8538009181997026, 0.877524377343434, 0.8228771257986202], "final_y": [0.1305345970720212, 0.12528468397881753, 0.14431911388444474]}, "mutation_prompt": null}
{"id": "06521659-28d6-43af-8594-8bc342c7b814", "solution": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.5   # Inertia weight\n        self.local_search_probability = 0.1\n        self.mutation_rate = 0.05  # New: Mutation rate for added diversity\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        velocities = np.random.uniform(low=-1, high=1, size=(self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n\n        evaluations = self.population_size\n        stagnation_counter = 0  # New: Tracking stagnation\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * r1 * (personal_best_positions[i] - positions[i])\n                    + self.c2 * r2 * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                current_score = func(positions[i])\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if current_score < personal_best_scores[i]:\n                    personal_best_scores[i] = current_score\n                    personal_best_positions[i] = positions[i]\n                    if current_score < func(global_best_position):\n                        global_best_position = positions[i]\n                        stagnation_counter = 0  # New: Reset stagnation\n\n            if np.random.rand() < self.local_search_probability:\n                for i in range(self.population_size):\n                    if evaluations < self.budget:\n                        candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                        candidate = np.clip(candidate, lb, ub)\n                        candidate_score = func(candidate)\n                        evaluations += 1\n                        if candidate_score < personal_best_scores[i]:\n                            personal_best_scores[i] = candidate_score\n                            personal_best_positions[i] = candidate\n                            if candidate_score < func(global_best_position):\n                                global_best_position = candidate\n\n            # New: Mutation for diversity\n            if np.random.rand() < self.mutation_rate:\n                mutation_index = np.random.randint(self.population_size)\n                positions[mutation_index] = np.random.uniform(low=lb, high=ub, size=self.dim)\n\n            stagnation_counter += 1\n            # New: Reinitialize if stagnation detected\n            if stagnation_counter > 10:\n                indices = np.random.choice(self.population_size, size=self.population_size // 2, replace=False)\n                for idx in indices:\n                    positions[idx] = np.random.uniform(low=lb, high=ub, size=self.dim)\n                stagnation_counter = 0\n            \n            # Change: Adjust inertia weight dynamically based on stagnation\n            self.w = 0.9 - (stagnation_counter * 0.1) if stagnation_counter < 5 else 0.4\n\n        return global_best_position, func(global_best_position)", "name": "HybridPSO", "description": "Enhanced exploration with dynamic inertia weight scaling based on stagnation.", "configspace": "", "generation": 8, "fitness": 0.8531934998854784, "feedback": "The algorithm HybridPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.853 with standard deviation 0.010. And the mean value of best solutions found was 0.132 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "622e4399-aa43-45c7-9e7c-25d4b4799fe2", "metadata": {"aucs": [0.8412799489381505, 0.8646055239242908, 0.8536950267939939], "final_y": [0.13193555579613514, 0.13208229548113926, 0.13214975425448894]}, "mutation_prompt": null}
{"id": "d83d9d6b-8838-47a6-bb08-f36a89989432", "solution": "import numpy as np\n\nclass DynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = max(20, 5 * self.dim)\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(x) for x in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n\n        evaluations = len(swarm)\n        inertia_weight = 0.9  # Changed from 0.7 to 0.9 to adaptively change later\n        c1, c2 = 1.5, 1.5\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight\n            inertia_weight = 0.4 + 0.5 * (1 - evaluations / self.budget)  # Line changed for dynamic inertia\n\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 c1 * r1 * (personal_best_positions[i] - swarm[i]) +\n                                 c2 * r2 * (global_best_position - swarm[i]))\n                swarm[i] = swarm[i] + velocities[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n                \n                fitness = func(swarm[i])\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(swarm[i])\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n            \n            if evaluations >= self.budget:\n                break\n\n            # Differential Evolution Mutation and Crossover with penalty mechanism\n            for i in range(population_size):\n                indices = np.random.choice(population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = np.clip(a + 0.8 * (b - c), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < 0.9, mutant, swarm[i])\n                \n                fitness = func(trial)\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(trial)\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n\n        return global_best_position, personal_best_scores[global_best_index]", "name": "DynamicSwarmOptimizer", "description": "Enhanced DynamicSwarmOptimizer with adaptive inertia weight and a penalty mechanism for boundary violations to improve solution diversity and convergence.", "configspace": "", "generation": 9, "fitness": 0.8343338731777589, "feedback": "The algorithm DynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.834 with standard deviation 0.014. And the mean value of best solutions found was 0.130 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "613aab66-8c13-456a-9009-c8091b1506b5", "metadata": {"aucs": [0.8159782396166249, 0.8376363859254061, 0.8493869939912457], "final_y": [0.12845920411828382, 0.1294749075376178, 0.13119850892942397]}, "mutation_prompt": null}
{"id": "6e80dfc7-0d00-4dbf-9bea-be07550c6ad4", "solution": "import numpy as np\n\nclass DynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = max(20, 5 * self.dim)\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(x) for x in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n\n        evaluations = len(swarm)\n        inertia_weight = 0.9  # Updated initial inertia weight\n        c1, c2 = 1.5, 1.5\n\n        while evaluations < self.budget:\n            inertia_weight *= 0.99  # Dynamic adjustment of inertia weight\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 c1 * r1 * (personal_best_positions[i] - swarm[i]) +\n                                 c2 * r2 * (global_best_position - swarm[i]))\n                swarm[i] = swarm[i] + velocities[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n                \n                fitness = func(swarm[i])\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(swarm[i])\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n            \n            if evaluations >= self.budget:\n                break\n\n            # Differential Evolution Mutation and Crossover\n            for i in range(population_size):\n                indices = np.random.choice(population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = np.clip(a + 0.8 * (b - c), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < 0.9, mutant, swarm[i])\n                \n                fitness = func(trial)\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(trial)\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n        \n        # Elite reinitialization\n        worst_indices = np.argsort(personal_best_scores)[-3:]\n        for i in worst_indices:\n            swarm[i] = np.random.uniform(lb, ub, self.dim)\n\n        return global_best_position, personal_best_scores[global_best_index]", "name": "DynamicSwarmOptimizer", "description": "Enhanced DynamicSwarmOptimizer by integrating dynamic inertia weight adjustment and elite reinitialization to boost convergence and diversity.", "configspace": "", "generation": 9, "fitness": 0.8566579867583696, "feedback": "The algorithm DynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.857 with standard deviation 0.033. And the mean value of best solutions found was 0.134 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "613aab66-8c13-456a-9009-c8091b1506b5", "metadata": {"aucs": [0.8156714282812118, 0.8972656157026905, 0.8570369162912066], "final_y": [0.1446399310627534, 0.12350691836838656, 0.13379914475293098]}, "mutation_prompt": null}
{"id": "4a1d2bf4-ab43-4a45-9863-fa2b35aba86e", "solution": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.5   # Inertia weight\n        self.local_search_probability = 0.1\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        velocities = np.random.uniform(low=-1, high=1, size=(self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Update velocities\n                r1, r2 = np.random.rand(), np.random.rand()\n                self.w = 0.9 - 0.5 * (evaluations / self.budget)  # Adaptive inertia weight\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * r1 * (personal_best_positions[i] - positions[i])\n                    + self.c2 * r2 * (global_best_position - positions[i])\n                )\n                # Update positions\n                positions[i] += velocities[i]\n\n                # Boundary handling\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                # Evaluate new position\n                current_score = func(positions[i])\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                # Update personal best\n                if current_score < personal_best_scores[i]:\n                    personal_best_scores[i] = current_score\n                    personal_best_positions[i] = positions[i]\n\n                    # Update global best\n                    # Directly evaluate current position to update global best\n                    if current_score < func(global_best_position):\n                        global_best_position = positions[i]\n\n            # Apply local search with a probability\n            if np.random.rand() < self.local_search_probability:\n                for i in range(self.population_size):\n                    if evaluations < self.budget:\n                        # Simple local search: random walk\n                        candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                        candidate = np.clip(candidate, lb, ub)\n                        candidate_score = func(candidate)\n                        evaluations += 1\n                        if candidate_score < personal_best_scores[i]:\n                            personal_best_scores[i] = candidate_score\n                            personal_best_positions[i] = candidate\n                            if candidate_score < func(global_best_position):\n                                global_best_position = candidate\n\n        return global_best_position, func(global_best_position)", "name": "HybridPSO", "description": "Introduced adaptive inertia weight to enhance convergence and exploration balance.", "configspace": "", "generation": 9, "fitness": 0.8581981247429912, "feedback": "The algorithm HybridPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.858 with standard deviation 0.022. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "08da8dd5-922d-426d-bd07-325761c54b19", "metadata": {"aucs": [0.8419316074497576, 0.8427516586948343, 0.8899111080843816], "final_y": [0.1316508739133705, 0.1328684250321125, 0.11666456099062261]}, "mutation_prompt": null}
{"id": "b9e01f5f-a2a0-40cc-8fde-eb85a257fb77", "solution": "import numpy as np\n\nclass DynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = max(20, 5 * self.dim)\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(x) for x in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n\n        evaluations = len(swarm)\n        inertia_weight = 0.7\n        c1, c2 = 1.5, 1.5\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 c1 * r1 * (personal_best_positions[i] - swarm[i]) +\n                                 c2 * r2 * (global_best_position - swarm[i]))\n                swarm[i] = swarm[i] + velocities[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n                \n                fitness = func(swarm[i])\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(swarm[i])\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n            \n            if evaluations >= self.budget:\n                break\n\n            # Differential Evolution Mutation and Crossover\n            for i in range(population_size):\n                indices = np.random.choice(population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = np.clip(a + 0.85 * (b - c), lb, ub)  # Adjusted scaling factor\n                trial = np.where(np.random.rand(self.dim) < 0.9, mutant, swarm[i])\n                \n                fitness = func(trial)\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(trial)\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n\n        return global_best_position, personal_best_scores[global_best_index]", "name": "DynamicSwarmOptimizer", "description": "Refined mutation strategy by adjusting the scaling factor in Differential Evolution to improve convergence towards the optimum.", "configspace": "", "generation": 9, "fitness": 0.8310907677118312, "feedback": "The algorithm DynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.831 with standard deviation 0.011. And the mean value of best solutions found was 0.138 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "613aab66-8c13-456a-9009-c8091b1506b5", "metadata": {"aucs": [0.84327583697542, 0.8159223171880252, 0.8340741489720488], "final_y": [0.123284409323007, 0.14956041310518742, 0.1403365255951975]}, "mutation_prompt": null}
{"id": "a48f5ceb-ef33-4072-b489-1a74183f9075", "solution": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.9   # Inertia weight\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        velocities = np.random.uniform(low=-1, high=1, size=(self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Update velocities\n                r1, r2 = np.random.rand(), np.random.rand()\n                self.w = 0.9 - ((0.9 - 0.4) * evaluations / self.budget) # Dynamic inertia weight\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * r1 * (personal_best_positions[i] - positions[i])\n                    + self.c2 * r2 * (global_best_position - positions[i])\n                )\n                # Update positions\n                positions[i] += velocities[i]\n\n                # Boundary handling\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                # Evaluate new position\n                current_score = func(positions[i])\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                # Update personal best\n                if current_score < personal_best_scores[i]:\n                    personal_best_scores[i] = current_score\n                    personal_best_positions[i] = positions[i]\n\n                    # Update global best\n                    if current_score < func(global_best_position):\n                        global_best_position = positions[i]\n\n            # Apply local search with a probability\n            if np.random.rand() < 0.1:\n                for i in range(self.population_size):\n                    if evaluations < self.budget:\n                        # Simple local search: random walk with stochastic perturbation\n                        candidate = positions[i] + np.random.normal(0, 0.1, self.dim) * (0.5 - evaluations / self.budget)\n                        candidate = np.clip(candidate, lb, ub)\n                        candidate_score = func(candidate)\n                        evaluations += 1\n                        if candidate_score < personal_best_scores[i]:\n                            personal_best_scores[i] = candidate_score\n                            personal_best_positions[i] = candidate\n                            if candidate_score < func(global_best_position):\n                                global_best_position = candidate\n\n        return global_best_position, func(global_best_position)", "name": "HybridPSO", "description": "Enhanced convergence through dynamic inertia weight and stochastic perturbations for improved exploration and exploitation balance.", "configspace": "", "generation": 9, "fitness": 0.8497784164910355, "feedback": "The algorithm HybridPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.850 with standard deviation 0.032. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "08da8dd5-922d-426d-bd07-325761c54b19", "metadata": {"aucs": [0.8094276183224987, 0.8528948569811979, 0.8870127741694099], "final_y": [0.13694214497906276, 0.1284100022638962, 0.11295540310478858]}, "mutation_prompt": null}
{"id": "3f41dc47-a124-4e57-90b5-3fc4d6fbb942", "solution": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.9   # Adaptive inertia weight\n        self.local_search_probability = 0.1\n        self.mutation_rate = 0.05\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        velocities = np.random.uniform(low=-1, high=1, size=(self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n\n        evaluations = self.population_size\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                self.w = 0.4 + 0.5 * np.exp(-evaluations / self.budget)  # Adaptive inertia\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * r1 * (personal_best_positions[i] - positions[i])\n                    + self.c2 * r2 * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                current_score = func(positions[i])\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if current_score < personal_best_scores[i]:\n                    personal_best_scores[i] = current_score\n                    personal_best_positions[i] = positions[i]\n                    if current_score < func(global_best_position):\n                        global_best_position = positions[i]\n                        stagnation_counter = 0\n\n            if np.random.rand() < self.local_search_probability:\n                for i in range(self.population_size):\n                    if evaluations < self.budget:\n                        step = np.random.standard_cauchy(size=self.dim)  # Lévy flight step\n                        candidate = positions[i] + step\n                        candidate = np.clip(candidate, lb, ub)\n                        candidate_score = func(candidate)\n                        evaluations += 1\n                        if candidate_score < personal_best_scores[i]:\n                            personal_best_scores[i] = candidate_score\n                            personal_best_positions[i] = candidate\n                            if candidate_score < func(global_best_position):\n                                global_best_position = candidate\n\n            if np.random.rand() < self.mutation_rate:\n                mutation_index = np.random.randint(self.population_size)\n                positions[mutation_index] = np.random.uniform(low=lb, high=ub, size=self.dim)\n\n            stagnation_counter += 1\n            if stagnation_counter > 10:\n                indices = np.random.choice(self.population_size, size=self.population_size // 2, replace=False)\n                for idx in indices:\n                    positions[idx] = np.random.uniform(low=lb, high=ub, size=self.dim)\n                stagnation_counter = 0\n\n        return global_best_position, func(global_best_position)", "name": "HybridPSO", "description": "Enhanced exploration and exploitation by integrating adaptive inertia weight and Lévy flight mechanism for escape from local optima.", "configspace": "", "generation": 10, "fitness": 0.8536383707754845, "feedback": "The algorithm HybridPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.854 with standard deviation 0.014. And the mean value of best solutions found was 0.129 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "622e4399-aa43-45c7-9e7c-25d4b4799fe2", "metadata": {"aucs": [0.8398683860183568, 0.8719986030445368, 0.8490481232635598], "final_y": [0.13543740734557042, 0.12197587825691214, 0.1296498667198226]}, "mutation_prompt": null}
{"id": "61eaed04-5f1c-41ea-9e29-140fb4d7b097", "solution": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.5   # Inertia weight\n        self.local_search_probability = 0.1\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        velocities = np.random.uniform(low=-1, high=1, size=(self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = func(global_best_position)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Update velocities\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * r1 * (personal_best_positions[i] - positions[i])\n                    + self.c2 * r2 * (global_best_position - positions[i])\n                )\n                # Update positions\n                positions[i] += velocities[i]\n\n                # Boundary handling\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                # Evaluate new position\n                current_score = func(positions[i])\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                # Update personal best\n                if current_score < personal_best_scores[i]:\n                    personal_best_scores[i] = current_score\n                    personal_best_positions[i] = positions[i]\n\n                    # Update global best\n                    if current_score < global_best_score:\n                        global_best_score = current_score\n                        global_best_position = positions[i]\n\n            # Apply local search with a probability\n            if np.random.rand() < self.local_search_probability:\n                for i in range(self.population_size):\n                    if evaluations < self.budget:\n                        # Simple local search: random walk\n                        candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                        candidate = np.clip(candidate, lb, ub)\n                        candidate_score = func(candidate)\n                        evaluations += 1\n                        if candidate_score < personal_best_scores[i]:\n                            personal_best_scores[i] = candidate_score\n                            personal_best_positions[i] = candidate\n                            if candidate_score < global_best_score:\n                                global_best_score = candidate_score\n                                global_best_position = candidate\n\n        return global_best_position, global_best_score", "name": "HybridPSO", "description": "Enhanced global best position update by considering both current and historical evaluations to improve convergence efficiency.", "configspace": "", "generation": 10, "fitness": 0.842263550604926, "feedback": "The algorithm HybridPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.842 with standard deviation 0.016. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "08da8dd5-922d-426d-bd07-325761c54b19", "metadata": {"aucs": [0.822576079139653, 0.8425349990571086, 0.8616795736180163], "final_y": [0.1448949950046884, 0.12599640248390764, 0.12079453223842429]}, "mutation_prompt": null}
{"id": "2e963b6b-7c1d-45ac-8d6f-fbc0d943e9fd", "solution": "import numpy as np\n\nclass DynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = max(20, 5 * self.dim)\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(x) for x in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n\n        evaluations = len(swarm)\n        inertia_weight = 0.9  # Adjusted initial inertia weight\n        c1, c2 = 1.5, 1.5\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 c1 * r1 * (personal_best_positions[i] - swarm[i]) +\n                                 c2 * r2 * (global_best_position - swarm[i]))\n                swarm[i] = swarm[i] + velocities[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n                \n                fitness = func(swarm[i])\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(swarm[i])\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n            \n            if evaluations >= self.budget:\n                break\n\n            # Differential Evolution Mutation and Crossover\n            for i in range(population_size):\n                indices = np.random.choice(population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = np.clip(a + 0.8 * (b - c), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < 0.9, mutant, swarm[i])\n                \n                fitness = func(trial)\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(trial)\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n\n            # Adaptive inertia weight\n            inertia_weight = max(0.4, inertia_weight * 0.99)\n\n        return global_best_position, personal_best_scores[global_best_index]", "name": "DynamicSwarmOptimizer", "description": "Dynamic Swarm Optimizer with adaptive inertia weight to enhance convergence by refining exploration and exploitation balance.", "configspace": "", "generation": 10, "fitness": 0.8386940084548868, "feedback": "The algorithm DynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.839 with standard deviation 0.010. And the mean value of best solutions found was 0.137 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "613aab66-8c13-456a-9009-c8091b1506b5", "metadata": {"aucs": [0.8266530964214851, 0.8376177283337747, 0.8518112006094007], "final_y": [0.134873177778155, 0.14092679162915356, 0.13522890850582514]}, "mutation_prompt": null}
{"id": "365429c5-e777-4f4d-9a2c-2c52b5b6d556", "solution": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.5   # Inertia weight\n        self.local_search_probability = 0.1\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        velocities = np.random.uniform(low=-1, high=1, size=(self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Update velocities\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * r1 * (personal_best_positions[i] - positions[i])\n                    + self.c2 * r2 * (global_best_position - positions[i])\n                )\n                # Update positions\n                positions[i] += velocities[i]\n\n                # Boundary handling\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                # Evaluate new position\n                current_score = func(positions[i])\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                # Update personal best\n                if current_score < personal_best_scores[i]:\n                    personal_best_scores[i] = current_score\n                    personal_best_positions[i] = positions[i]\n\n                    # Update global best\n                    if current_score < func(global_best_position):\n                        global_best_position = positions[i]\n\n            # Adaptive inertia weight update\n            self.w = max(0.4, 0.9 - (0.5 * evaluations / self.budget))\n\n            # Apply local search with a probability\n            if np.random.rand() < self.local_search_probability:\n                for i in range(self.population_size):\n                    if evaluations < self.budget:\n                        # Simple local search: random walk\n                        candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                        candidate = np.clip(candidate, lb, ub)\n                        candidate_score = func(candidate)\n                        evaluations += 1\n                        if candidate_score < personal_best_scores[i]:\n                            personal_best_scores[i] = candidate_score\n                            personal_best_positions[i] = candidate\n                            if candidate_score < func(global_best_position):\n                                global_best_position = candidate\n\n        return global_best_position, func(global_best_position)", "name": "HybridPSO", "description": "Enhanced HybridPSO with adaptive inertia weight update mechanism for improved balance between exploration and exploitation.", "configspace": "", "generation": 10, "fitness": 0.8609123534297395, "feedback": "The algorithm HybridPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.861 with standard deviation 0.019. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "f7cb2b01-36f0-475c-9246-73d226ddd618", "metadata": {"aucs": [0.8356290988532012, 0.8811651627055492, 0.8659427987304681], "final_y": [0.13158008785489894, 0.12239942657327751, 0.11650986739188496]}, "mutation_prompt": null}
{"id": "b36209cf-8c97-4045-bb7a-51774c80fe95", "solution": "import numpy as np\n\nclass DynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = max(20, 5 * self.dim)\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(x) for x in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n\n        evaluations = len(swarm)\n        inertia_weight = 0.9  # Start with a higher inertia weight\n        c1, c2 = 1.5, 1.5\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 c1 * r1 * (personal_best_positions[i] - swarm[i]) +\n                                 c2 * r2 * (global_best_position - swarm[i]))\n                swarm[i] = swarm[i] + velocities[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n                \n                fitness = func(swarm[i])\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(swarm[i])\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n\n            inertia_weight *= 0.99  # Gradually reduce inertia weight\n\n            if evaluations >= self.budget:\n                break\n\n            # Differential Evolution Mutation and Crossover\n            for i in range(population_size):\n                indices = np.random.choice(population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = np.clip(a + 0.8 * (b - c), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < 0.9, mutant, swarm[i])\n\n                # Random local search around the global best\n                random_search = global_best_position + np.random.uniform(-0.1, 0.1, self.dim)\n                random_search = np.clip(random_search, lb, ub)\n                \n                fitness = func(trial)\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(trial)\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n\n        return global_best_position, personal_best_scores[global_best_index]", "name": "DynamicSwarmOptimizer", "description": "Improved DynamicSwarmOptimizer with adaptive inertia weight and random local search for enhanced exploration and exploitation.", "configspace": "", "generation": 10, "fitness": 0.8298317218601753, "feedback": "The algorithm DynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.830 with standard deviation 0.010. And the mean value of best solutions found was 0.132 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "613aab66-8c13-456a-9009-c8091b1506b5", "metadata": {"aucs": [0.8161259612160451, 0.833849915596326, 0.8395192887681548], "final_y": [0.14072411921245054, 0.1314903116669035, 0.12424798586086672]}, "mutation_prompt": null}
{"id": "ea03b009-b807-4f98-90d3-04ef95649fdd", "solution": "import numpy as np\n\nclass DynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = max(20, 5 * self.dim)\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(x) for x in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n\n        evaluations = len(swarm)\n        inertia_weight = 0.7\n        c1, c2 = 1.5, 1.5\n\n        while evaluations < self.budget:\n            inertia_weight = 0.9 - 0.5 * (evaluations / self.budget)  # dynamically adjust inertia weight\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 c1 * r1 * (personal_best_positions[i] - swarm[i]) +\n                                 c2 * r2 * (global_best_position - swarm[i]))\n                swarm[i] = swarm[i] + velocities[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n                \n                fitness = func(swarm[i])\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(swarm[i])\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n            \n            if evaluations >= self.budget:\n                break\n\n            # Differential Evolution Mutation and Crossover\n            for i in range(population_size):\n                indices = np.random.choice(population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = np.clip(a + 0.8 * (b - c), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < 0.9, mutant, swarm[i])\n                \n                fitness = func(trial)\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(trial)\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n\n        return global_best_position, personal_best_scores[global_best_index]", "name": "DynamicSwarmOptimizer", "description": "Enhanced swarm exploration by adjusting inertia weight dynamically based on progress to improve convergence.", "configspace": "", "generation": 11, "fitness": 0.863471049064498, "feedback": "The algorithm DynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.863 with standard deviation 0.017. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "613aab66-8c13-456a-9009-c8091b1506b5", "metadata": {"aucs": [0.8870533665112365, 0.8494829557593843, 0.8538768249228734], "final_y": [0.12018257209849392, 0.12160253088580553, 0.1294848976087375]}, "mutation_prompt": null}
{"id": "5ccd8e18-5730-4710-b8fb-55d5c8ec85be", "solution": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.5   # Inertia weight\n        self.local_search_probability = 0.15  # Increased probability\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        velocities = np.random.uniform(low=-1, high=1, size=(self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Update velocities\n                r1, r2 = np.random.rand(), np.random.rand()\n                self.w = 0.5 + (0.5 * (self.budget - evaluations) / self.budget)  # Dynamic inertia weight\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * r1 * (personal_best_positions[i] - positions[i])\n                    + self.c2 * r2 * (global_best_position - positions[i])\n                )\n                # Update positions\n                positions[i] += velocities[i]\n\n                # Boundary handling\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                # Evaluate new position\n                current_score = func(positions[i])\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                # Update personal best\n                if current_score < personal_best_scores[i]:\n                    personal_best_scores[i] = current_score\n                    personal_best_positions[i] = positions[i]\n\n                    # Update global best\n                    if current_score < func(global_best_position):\n                        global_best_position = positions[i]\n\n            # Apply local search with a probability\n            if np.random.rand() < self.local_search_probability:\n                for i in range(self.population_size):\n                    if evaluations < self.budget:\n                        # Enhanced local search: increased step size\n                        candidate = positions[i] + np.random.normal(0, 0.2, self.dim)\n                        candidate = np.clip(candidate, lb, ub)\n                        candidate_score = func(candidate)\n                        evaluations += 1\n                        if candidate_score < personal_best_scores[i]:\n                            personal_best_scores[i] = candidate_score\n                            personal_best_positions[i] = candidate\n                            if candidate_score < func(global_best_position):\n                                global_best_position = candidate\n\n        return global_best_position, func(global_best_position)", "name": "HybridPSO", "description": "Enhanced HybridPSO by introducing dynamic parameter adaptation and improved local search intensity for better convergence.", "configspace": "", "generation": 11, "fitness": 0.842023824698041, "feedback": "The algorithm HybridPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.842 with standard deviation 0.030. And the mean value of best solutions found was 0.132 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "08da8dd5-922d-426d-bd07-325761c54b19", "metadata": {"aucs": [0.8181451901541913, 0.8841221621831329, 0.8238041217567987], "final_y": [0.13335373369475712, 0.1244667154542114, 0.13753305063322796]}, "mutation_prompt": null}
{"id": "7a4a89b5-0151-4e22-958a-f9f5f3abc983", "solution": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.5   # Inertia weight\n        self.local_search_probability = 0.1\n        self.mutation_rate = 0.05  # New: Mutation rate for added diversity\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        velocities = np.random.uniform(low=-1, high=1, size=(self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n\n        evaluations = self.population_size\n        stagnation_counter = 0  # New: Tracking stagnation\n\n        while evaluations < self.budget:\n            self.w *= 0.99  # Change: Adaptive inertia weight\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * r1 * (personal_best_positions[i] - positions[i])\n                    + self.c2 * r2 * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                current_score = func(positions[i])\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if current_score < personal_best_scores[i]:\n                    personal_best_scores[i] = current_score\n                    personal_best_positions[i] = positions[i]\n                    if current_score < func(global_best_position):\n                        global_best_position = positions[i]\n                        stagnation_counter = 0  # New: Reset stagnation\n\n            if np.random.rand() < self.local_search_probability:\n                for i in range(self.population_size):\n                    if evaluations < self.budget:\n                        candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                        candidate = np.clip(candidate, lb, ub)\n                        candidate_score = func(candidate)\n                        evaluations += 1\n                        if candidate_score < personal_best_scores[i]:\n                            personal_best_scores[i] = candidate_score\n                            personal_best_positions[i] = candidate\n                            if candidate_score < func(global_best_position):\n                                global_best_position = candidate\n\n            # New: Mutation for diversity\n            if np.random.rand() < self.mutation_rate:\n                mutation_index = np.random.randint(self.population_size)\n                positions[mutation_index] = np.random.uniform(low=lb, high=ub, size=self.dim)\n\n            stagnation_counter += 1\n            # New: Reinitialize if stagnation detected\n            if stagnation_counter > 10:\n                indices = np.random.choice(self.population_size, size=self.population_size // 2, replace=False)\n                for idx in indices:\n                    positions[idx] = np.random.uniform(low=lb, high=ub, size=self.dim)\n                stagnation_counter = 0\n\n        return global_best_position, func(global_best_position)", "name": "HybridPSO", "description": "Improved the inertia weight update strategy for better adaptability and convergence efficiency.", "configspace": "", "generation": 11, "fitness": 0.8522442467616065, "feedback": "The algorithm HybridPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.852 with standard deviation 0.017. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "622e4399-aa43-45c7-9e7c-25d4b4799fe2", "metadata": {"aucs": [0.8282347954427665, 0.8619648118526336, 0.8665331329894195], "final_y": [0.13259306827226613, 0.1206908722229697, 0.13104033605800458]}, "mutation_prompt": null}
{"id": "7cd7c845-d859-407f-baa2-0b331db7d29f", "solution": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.5   # Inertia weight\n        self.local_search_probability = 0.1\n        self.mutation_rate = 0.05  # New: Mutation rate for added diversity\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        velocities = np.random.uniform(low=-1, high=1, size=(self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n\n        evaluations = self.population_size\n        stagnation_counter = 0  # New: Tracking stagnation\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * r1 * (personal_best_positions[i] - positions[i])\n                    + self.c2 * r2 * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                current_score = func(positions[i])\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if current_score < personal_best_scores[i]:\n                    personal_best_scores[i] = current_score\n                    personal_best_positions[i] = positions[i]\n                    if current_score < func(global_best_position):\n                        global_best_position = positions[i]\n                        stagnation_counter = 0  # New: Reset stagnation\n\n            if np.random.rand() < self.local_search_probability:\n                for i in range(self.population_size):\n                    if evaluations < self.budget:\n                        candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                        candidate = np.clip(candidate, lb, ub)\n                        candidate_score = func(candidate)\n                        evaluations += 1\n                        if candidate_score < personal_best_scores[i]:\n                            personal_best_scores[i] = candidate_score\n                            personal_best_positions[i] = candidate\n                            if candidate_score < func(global_best_position):\n                                global_best_position = candidate\n\n            # New: Mutation for diversity\n            if np.random.rand() < self.mutation_rate:\n                mutation_index = np.random.randint(self.population_size)\n                positions[mutation_index] = np.random.uniform(low=lb, high=ub, size=self.dim)\n\n            stagnation_counter += 1\n            # New: Reinitialize if stagnation detected\n            if stagnation_counter > 10:\n                indices = np.random.choice(self.population_size, size=self.population_size // 2, replace=False)\n                for idx in indices:\n                    positions[idx] = np.random.uniform(low=lb, high=ub, size=self.dim)\n                stagnation_counter = 0\n            \n            # Change: Dynamically scale inertia weight based on stagnation\n            self.w = 0.4 if stagnation_counter > 5 else 0.7\n\n        return global_best_position, func(global_best_position)", "name": "HybridPSO", "description": "Improved exploitation by dynamically scaling the inertia weight based on stagnation to enhance convergence.", "configspace": "", "generation": 11, "fitness": 0.8454107849522101, "feedback": "The algorithm HybridPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.845 with standard deviation 0.024. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "622e4399-aa43-45c7-9e7c-25d4b4799fe2", "metadata": {"aucs": [0.8161184550429704, 0.8741448506376202, 0.8459690491760397], "final_y": [0.144071349969204, 0.12251412648389681, 0.13343538840374936]}, "mutation_prompt": null}
{"id": "bbace995-c100-4f54-9ae0-67297ce73cf3", "solution": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.9   # Initial inertia weight\n        self.local_search_probability = 0.1\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        velocities = np.random.uniform(low=-1, high=1, size=(self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.w = 0.9 - 0.4 * (evaluations / self.budget)  # Adaptive inertia weight\n            for i in range(self.population_size):\n                # Update velocities\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * r1 * (personal_best_positions[i] - positions[i])\n                    + self.c2 * r2 * (global_best_position - positions[i])\n                )\n                # Update positions\n                positions[i] += velocities[i]\n\n                # Boundary handling\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                # Evaluate new position\n                current_score = func(positions[i])\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                # Update personal best\n                if current_score < personal_best_scores[i]:\n                    personal_best_scores[i] = current_score\n                    personal_best_positions[i] = positions[i]\n\n                    # Update global best\n                    # Directly evaluate current position to update global best\n                    if current_score < func(global_best_position):\n                        global_best_position = positions[i]\n\n            # Apply local search with a probability\n            if np.random.rand() < self.local_search_probability:\n                for i in range(self.population_size):\n                    if evaluations < self.budget:\n                        # Simple local search: random walk\n                        candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                        candidate = np.clip(candidate, lb, ub)\n                        candidate_score = func(candidate)\n                        evaluations += 1\n                        if candidate_score < personal_best_scores[i]:\n                            personal_best_scores[i] = candidate_score\n                            personal_best_positions[i] = candidate\n                            if candidate_score < func(global_best_position):\n                                global_best_position = candidate\n\n        return global_best_position, func(global_best_position)", "name": "HybridPSO", "description": "Introduced adaptive inertia weight to dynamically adjust exploration-exploitation balance and enhanced velocity update for improved convergence.", "configspace": "", "generation": 11, "fitness": 0.8527484245692034, "feedback": "The algorithm HybridPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.853 with standard deviation 0.011. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "08da8dd5-922d-426d-bd07-325761c54b19", "metadata": {"aucs": [0.8381296552325146, 0.8657697408193774, 0.8543458776557183], "final_y": [0.1328574489221641, 0.12716958830586034, 0.1239889418091702]}, "mutation_prompt": null}
{"id": "8e680bcd-1c60-483f-bc42-8077985d4e9c", "solution": "import numpy as np\n\nclass DynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = max(20, 5 * self.dim)\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(x) for x in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n\n        evaluations = len(swarm)\n        inertia_weight = 0.7\n        # Change 1: Use stochastic c1 and c2 coefficients\n        c1, c2 = np.random.uniform(1.0, 2.0), np.random.uniform(1.0, 2.0)\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 c1 * r1 * (personal_best_positions[i] - swarm[i]) +\n                                 c2 * r2 * (global_best_position - swarm[i]))\n                velocities[i] *= 0.9  # Adaptive velocity scaling\n                swarm[i] = swarm[i] + velocities[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n                \n                fitness = func(swarm[i])\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(swarm[i])\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n            \n            if evaluations >= self.budget:\n                break\n\n            elite_size = max(2, population_size // 10)  # Elite selection\n            best_indices = np.argsort(personal_best_scores)[:elite_size]\n            for i in range(population_size):\n                indices = np.random.choice(best_indices, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = np.clip(a + 0.8 * (b - c), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < 0.9, mutant, swarm[i])\n                \n                fitness = func(trial)\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(trial)\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n\n        return global_best_position, personal_best_scores[global_best_index]", "name": "DynamicSwarmOptimizer", "description": "Improved dynamic swarm optimizer by incorporating stochastic c1 and c2 coefficients to enhance exploration and exploitation adaptability.", "configspace": "", "generation": 12, "fitness": 0.8461192752517347, "feedback": "The algorithm DynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.846 with standard deviation 0.008. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "af3a875f-9a26-4707-86ca-7bc3f5ff9997", "metadata": {"aucs": [0.8462399634168901, 0.8561253669105146, 0.8359924954277995], "final_y": [0.1274408153511225, 0.13558765263821837, 0.136526497053146]}, "mutation_prompt": null}
{"id": "c5219296-634a-4350-80a2-1509a2210e00", "solution": "import numpy as np\n\nclass DynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = max(20, 5 * self.dim)\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(x) for x in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n\n        evaluations = len(swarm)\n        inertia_weight = 0.7\n        c1, c2 = 1.5, 1.5\n\n        while evaluations < self.budget:\n            c1 = 2.0 - 1.0 * (evaluations / self.budget)  # adapt c1 dynamically\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 c1 * r1 * (personal_best_positions[i] - swarm[i]) +\n                                 c2 * r2 * (global_best_position - swarm[i]))\n                swarm[i] = swarm[i] + velocities[i]\n                swarm[i] = np.where(swarm[i] > ub, ub - np.random.rand(self.dim) * (ub - lb), swarm[i])  # reflection\n                swarm[i] = np.where(swarm[i] < lb, lb + np.random.rand(self.dim) * (ub - lb), swarm[i])  # reflection\n                \n                fitness = func(swarm[i])\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(swarm[i])\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n            \n            if evaluations >= self.budget:\n                break\n\n            # Differential Evolution Mutation and Crossover\n            for i in range(population_size):\n                indices = np.random.choice(population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = np.clip(a + 0.8 * (b - c), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < 0.9, mutant, swarm[i])\n                \n                fitness = func(trial)\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(trial)\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n\n        return global_best_position, personal_best_scores[global_best_index]", "name": "DynamicSwarmOptimizer", "description": "Enhanced DynamicSwarmOptimizer integrates stochastic boundary reflection and adaptive learning coefficients to refine exploration and exploitation balance.", "configspace": "", "generation": 12, "fitness": 0.8463477931483435, "feedback": "The algorithm DynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.846 with standard deviation 0.019. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "ea03b009-b807-4f98-90d3-04ef95649fdd", "metadata": {"aucs": [0.8404540430547237, 0.8722408421337586, 0.826348494256548], "final_y": [0.13037538005879656, 0.12541716785403678, 0.13680453543037785]}, "mutation_prompt": null}
{"id": "200c0504-2499-4510-a081-fa5ff14a84e4", "solution": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.9   # Adjusted: Start with higher inertia weight\n        self.local_search_probability = 0.1\n        self.mutation_rate = 0.05  # New: Mutation rate for added diversity\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        velocities = np.random.uniform(low=-1, high=1, size=(self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n\n        evaluations = self.population_size\n        stagnation_counter = 0  # New: Tracking stagnation\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * r1 * (personal_best_positions[i] - positions[i])\n                    + self.c2 * r2 * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                current_score = func(positions[i])\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if current_score < personal_best_scores[i]:\n                    personal_best_scores[i] = current_score\n                    personal_best_positions[i] = positions[i]\n                    if current_score < func(global_best_position):\n                        global_best_position = positions[i]\n                        stagnation_counter = 0  # New: Reset stagnation\n\n            if np.random.rand() < self.local_search_probability:\n                for i in range(self.population_size):\n                    if evaluations < self.budget:\n                        candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                        candidate = np.clip(candidate, lb, ub)\n                        candidate_score = func(candidate)\n                        evaluations += 1\n                        if candidate_score < personal_best_scores[i]:\n                            personal_best_scores[i] = candidate_score\n                            personal_best_positions[i] = candidate\n                            if candidate_score < func(global_best_position):\n                                global_best_position = candidate\n\n            # New: Mutation for diversity\n            if np.random.rand() < self.mutation_rate:\n                mutation_index = np.random.randint(self.population_size)\n                positions[mutation_index] = np.random.uniform(low=lb, high=ub, size=self.dim)\n\n            stagnation_counter += 1\n            # New: Reinitialize if stagnation detected\n            if stagnation_counter > 10:\n                indices = np.random.choice(self.population_size, size=self.population_size // 2, replace=False)\n                for idx in indices:\n                    positions[idx] = np.random.uniform(low=lb, high=ub, size=self.dim)\n                stagnation_counter = 0\n\n        return global_best_position, func(global_best_position)", "name": "HybridPSO", "description": "Improve HybridPSO by adjusting inertia weight dynamically for better convergence control.", "configspace": "", "generation": 12, "fitness": 0.838181328466275, "feedback": "The algorithm HybridPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.838 with standard deviation 0.012. And the mean value of best solutions found was 0.137 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "622e4399-aa43-45c7-9e7c-25d4b4799fe2", "metadata": {"aucs": [0.8470425526390856, 0.8469279206254837, 0.8205735121342556], "final_y": [0.12976440110468568, 0.13629286017019226, 0.1447364187893564]}, "mutation_prompt": null}
{"id": "d218d236-8697-41e5-86f3-5531ae0b6b56", "solution": "import numpy as np\n\nclass DynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = max(20, 5 * self.dim)\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(x) for x in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n\n        evaluations = len(swarm)\n        c1, c2 = 1.5, 1.5\n\n        while evaluations < self.budget:\n            # Adaptive inertia weight\n            inertia_weight = 0.9 - (0.5 * (evaluations / self.budget))\n            \n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 c1 * r1 * (personal_best_positions[i] - swarm[i]) +\n                                 c2 * r2 * (global_best_position - swarm[i]))\n                swarm[i] = swarm[i] + velocities[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n                \n                fitness = func(swarm[i])\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(swarm[i])\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n            \n            if evaluations >= self.budget:\n                break\n\n            # Differential Evolution Mutation and Crossover\n            for i in range(population_size):\n                indices = np.random.choice(population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = np.clip(a + 0.8 * (b - c), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < 0.9, mutant, swarm[i])\n                \n                fitness = func(trial)\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(trial)\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n\n        return global_best_position, personal_best_scores[global_best_index]", "name": "DynamicSwarmOptimizer", "description": "Introduced adaptive inertia weight change to enhance exploration-exploitation balance in different search phases.", "configspace": "", "generation": 12, "fitness": 0.8474842769411942, "feedback": "The algorithm DynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.847 with standard deviation 0.014. And the mean value of best solutions found was 0.132 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "613aab66-8c13-456a-9009-c8091b1506b5", "metadata": {"aucs": [0.8318258990953235, 0.845851852311672, 0.8647750794165875], "final_y": [0.13581564778269717, 0.13305176772206329, 0.12823046610819744]}, "mutation_prompt": null}
{"id": "73a36276-c61e-4a91-9c6f-5dc097a1d36f", "solution": "import numpy as np\n\nclass DynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = max(20, 5 * self.dim)\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(x) for x in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n\n        evaluations = len(swarm)\n        inertia_weight = 0.7\n        c1, c2 = 1.5, 1.7  # changed c2 from 1.5 to 1.7\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 c1 * r1 * (personal_best_positions[i] - swarm[i]) +\n                                 c2 * r2 * (global_best_position - swarm[i]))\n                swarm[i] = swarm[i] + velocities[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n                \n                fitness = func(swarm[i])\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(swarm[i])\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n            \n            if evaluations >= self.budget:\n                break\n\n            # Differential Evolution Mutation and Crossover\n            for i in range(population_size):\n                indices = np.random.choice(population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = np.clip(a + 0.8 * (b - c), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < 0.9, mutant, swarm[i])\n                \n                fitness = func(trial)\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(trial)\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n\n        return global_best_position, personal_best_scores[global_best_index]", "name": "DynamicSwarmOptimizer", "description": "Enhanced swarm convergence by increasing global learning factor for improved exploitation.", "configspace": "", "generation": 12, "fitness": 0.8365871305850917, "feedback": "The algorithm DynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.837 with standard deviation 0.002. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "613aab66-8c13-456a-9009-c8091b1506b5", "metadata": {"aucs": [0.8366769900509425, 0.8393236727665945, 0.8337607289377381], "final_y": [0.13019164868340227, 0.13170273201269278, 0.136006780019441]}, "mutation_prompt": null}
{"id": "608aa1d6-7884-487f-bb43-ec5ed3fdebda", "solution": "import numpy as np\n\nclass DynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = max(20, 5 * self.dim)\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(x) for x in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n\n        evaluations = len(swarm)\n        inertia_weight = 0.7\n        c1, c2 = 1.5, 1.5\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 c1 * r1 * (personal_best_positions[i] - swarm[i]) +\n                                 c2 * r2 * (global_best_position - swarm[i]))\n                velocities[i] *= 0.9  # Adaptive velocity scaling\n                swarm[i] = swarm[i] + velocities[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n                \n                fitness = func(swarm[i])\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(swarm[i])\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n            \n            if evaluations >= self.budget:\n                break\n\n            # Differential Evolution Mutation and Crossover\n            elite_size = max(2, population_size // 10)  # Elite selection\n            best_indices = np.argsort(personal_best_scores)[:elite_size]\n            for i in range(population_size):\n                indices = np.random.choice(best_indices, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = np.clip(a + 0.8 * (b - c), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < 0.9, mutant, swarm[i])\n                \n                fitness = func(trial)\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(trial)\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n\n            inertia_weight = 0.7 - 0.5 * (evaluations / self.budget)  # Linearly decaying inertia weight\n\n        return global_best_position, personal_best_scores[global_best_index]", "name": "DynamicSwarmOptimizer", "description": "Refined inertia weight strategy by adding linear decay to enhance convergence dynamics.", "configspace": "", "generation": 13, "fitness": 0.8819435220748998, "feedback": "The algorithm DynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.882 with standard deviation 0.014. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "af3a875f-9a26-4707-86ca-7bc3f5ff9997", "metadata": {"aucs": [0.8939670820061256, 0.8626372794937414, 0.8892262047248325], "final_y": [0.11468863332288015, 0.12727127033410757, 0.11612288994435993]}, "mutation_prompt": null}
{"id": "4eadf69e-12fd-4ab3-bf1c-f79c1f30f851", "solution": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.local_search_probability = 0.1\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        positions = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        velocities = np.random.uniform(low=-1, high=1, size=(self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * (evaluations / self.budget)\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (\n                    w * velocities[i]\n                    + self.c1 * r1 * (personal_best_positions[i] - positions[i])\n                    + self.c2 * r2 * (global_best_position - positions[i])\n                )\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                current_score = func(positions[i])\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                if current_score < personal_best_scores[i]:\n                    personal_best_scores[i] = current_score\n                    personal_best_positions[i] = positions[i]\n                    if current_score < func(global_best_position):\n                        global_best_position = positions[i]\n\n            if np.random.rand() < self.local_search_probability:\n                for i in range(self.population_size):\n                    if evaluations < self.budget:\n                        candidate = positions[i] + np.random.normal(0, np.abs(ub-lb)*0.05, self.dim)\n                        candidate = np.clip(candidate, lb, ub)\n                        candidate_score = func(candidate)\n                        evaluations += 1\n                        if candidate_score < personal_best_scores[i]:\n                            personal_best_scores[i] = candidate_score\n                            personal_best_positions[i] = candidate\n                            if candidate_score < func(global_best_position):\n                                global_best_position = candidate\n\n        return global_best_position, func(global_best_position)", "name": "HybridPSO", "description": "Enhanced HybridPSO by incorporating dynamic inertia weight adjustment and improved local search strategy for better convergence and exploration-exploitation balance. ", "configspace": "", "generation": 13, "fitness": 0.8378309362609248, "feedback": "The algorithm HybridPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.838 with standard deviation 0.014. And the mean value of best solutions found was 0.134 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "08da8dd5-922d-426d-bd07-325761c54b19", "metadata": {"aucs": [0.8187676089154143, 0.848843019179079, 0.8458821806882808], "final_y": [0.14177111754595262, 0.13477766066194752, 0.12608339845339178]}, "mutation_prompt": null}
{"id": "731bd7b3-92b4-40bb-82f4-baed538795d4", "solution": "import numpy as np\n\nclass DynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = max(20, 5 * self.dim)\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(x) for x in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n\n        evaluations = len(swarm)\n        inertia_weight = 0.7\n        c1, c2 = 1.5, 1.5\n\n        while evaluations < self.budget:\n            inertia_weight = 0.9 - 0.5 * (evaluations / self.budget)\n\n            diversity = np.std(swarm, axis=0)\n            dynamic_factor = np.mean(diversity)\n\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 c1 * r1 * (personal_best_positions[i] - swarm[i]) +\n                                 c2 * r2 * (global_best_position - swarm[i]))\n                \n                velocities[i] = np.clip(velocities[i], -dynamic_factor, dynamic_factor)  # Velocity clamping\n\n                swarm[i] = swarm[i] + velocities[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n                \n                fitness = func(swarm[i])\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(swarm[i])\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n            \n            if evaluations >= self.budget:\n                break\n\n            for i in range(population_size):\n                indices = np.random.choice(population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = np.clip(a + 0.8 * (b - c), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < 0.9, mutant, swarm[i])\n                \n                fitness = func(trial)\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(trial)\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n\n        return global_best_position, personal_best_scores[global_best_index]", "name": "DynamicSwarmOptimizer", "description": "Enhanced swarm exploration by integrating adaptive learning rate and velocity clamping based on diversity to improve convergence and robustness.", "configspace": "", "generation": 13, "fitness": 0.8696189682095072, "feedback": "The algorithm DynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.870 with standard deviation 0.021. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "ea03b009-b807-4f98-90d3-04ef95649fdd", "metadata": {"aucs": [0.8732488502237861, 0.8931121065473218, 0.8424959478574137], "final_y": [0.11285682936175145, 0.12060719851355639, 0.1269848895969512]}, "mutation_prompt": null}
{"id": "6eafb924-04bc-4b6d-9add-6a13ab5143ef", "solution": "import numpy as np\n\nclass DynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = max(20, 5 * self.dim)\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(x) for x in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n\n        evaluations = len(swarm)\n        inertia_weight = 0.7\n        c1, c2 = 1.5, 1.5\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 c1 * r1 * (personal_best_positions[i] - swarm[i]) +\n                                 c2 * r2 * (global_best_position - swarm[i]))\n                velocities[i] *= 0.9  # Adaptive velocity scaling\n                swarm[i] = swarm[i] + velocities[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n                \n                fitness = func(swarm[i])\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(swarm[i])\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n            \n            if evaluations >= self.budget:\n                break\n\n            # Differential Evolution Mutation and Crossover\n            elite_size = max(2, population_size // 10)  # Elite selection\n            best_indices = np.argsort(personal_best_scores)[:elite_size]\n            for i in range(population_size):\n                indices = np.random.choice(best_indices, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = np.clip(a + 0.8 * (b - c), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < np.sin(evaluations), mutant, swarm[i])  # Adapt crossover rate\n                \n                fitness = func(trial)\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(trial)\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n\n        return global_best_position, personal_best_scores[global_best_index]", "name": "DynamicSwarmOptimizer", "description": "Introduced chaotic inertia weight and crossover rate adaptation to enhance convergence without compromising exploration.", "configspace": "", "generation": 13, "fitness": 0.8849704869300318, "feedback": "The algorithm DynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.885 with standard deviation 0.011. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "af3a875f-9a26-4707-86ca-7bc3f5ff9997", "metadata": {"aucs": [0.8909195839352929, 0.8940170823857253, 0.8699747944690768], "final_y": [0.11879725415021869, 0.12005652790977939, 0.11993341661116308]}, "mutation_prompt": null}
{"id": "0b1930bb-6021-4a26-9f61-4ec186eb1756", "solution": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.5   # Inertia weight\n        self.local_search_probability = 0.1\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        velocities = np.random.uniform(low=-1, high=1, size=(self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Update velocities\n                r1, r2 = np.random.rand(), np.random.rand()\n                # Update inertia weight adaptively\n                self.w = 0.9 - 0.5 * (evaluations / self.budget) \n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * r1 * (personal_best_positions[i] - positions[i])\n                    + self.c2 * r2 * (global_best_position - positions[i])\n                )\n                # Update positions\n                positions[i] += velocities[i]\n\n                # Boundary handling\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                # Evaluate new position\n                current_score = func(positions[i])\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                # Update personal best\n                if current_score < personal_best_scores[i]:\n                    personal_best_scores[i] = current_score\n                    personal_best_positions[i] = positions[i]\n\n                    # Update global best\n                    # Directly evaluate current position to update global best\n                    if current_score < func(global_best_position):\n                        global_best_position = positions[i]\n\n            # Apply local search with a probability\n            if np.random.rand() < self.local_search_probability:\n                for i in range(self.population_size):\n                    if evaluations < self.budget:\n                        # Simple local search: random walk\n                        candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                        candidate = np.clip(candidate, lb, ub)\n                        candidate_score = func(candidate)\n                        evaluations += 1\n                        if candidate_score < personal_best_scores[i]:\n                            personal_best_scores[i] = candidate_score\n                            personal_best_positions[i] = candidate\n                            if candidate_score < func(global_best_position):\n                                global_best_position = candidate\n\n        return global_best_position, func(global_best_position)", "name": "HybridPSO", "description": "Improved inertia weight by modifying its update strategy to enhance balance between exploration and exploitation.", "configspace": "", "generation": 13, "fitness": 0.8730658559117531, "feedback": "The algorithm HybridPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.873 with standard deviation 0.003. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "08da8dd5-922d-426d-bd07-325761c54b19", "metadata": {"aucs": [0.8720710408186385, 0.8695839317123918, 0.8775425952042288], "final_y": [0.1157111829992773, 0.12503433802519914, 0.11567150591623199]}, "mutation_prompt": null}
{"id": "45c06b1d-b4b6-4a91-8bfe-241dcc577a64", "solution": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.5   # Inertia weight\n        self.local_search_probability = 0.1\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        velocities = np.random.uniform(low=-1, high=1, size=(self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Update velocities\n                r1, r2 = np.random.rand(), np.random.rand()\n                # Update inertia weight adaptively using non-linear decay\n                self.w = 0.9 - 0.5 * np.tanh(5 * (evaluations / self.budget - 0.5)) \n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * r1 * (personal_best_positions[i] - positions[i])\n                    + self.c2 * r2 * (global_best_position - positions[i])\n                )\n                # Update positions\n                positions[i] += velocities[i]\n\n                # Boundary handling\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                # Evaluate new position\n                current_score = func(positions[i])\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                # Update personal best\n                if current_score < personal_best_scores[i]:\n                    personal_best_scores[i] = current_score\n                    personal_best_positions[i] = positions[i]\n\n                    # Update global best\n                    # Directly evaluate current position to update global best\n                    if current_score < func(global_best_position):\n                        global_best_position = positions[i]\n\n            # Apply local search with a probability\n            if np.random.rand() < self.local_search_probability:\n                for i in range(self.population_size):\n                    if evaluations < self.budget:\n                        # Simple local search: random walk\n                        candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                        candidate = np.clip(candidate, lb, ub)\n                        candidate_score = func(candidate)\n                        evaluations += 1\n                        if candidate_score < personal_best_scores[i]:\n                            personal_best_scores[i] = candidate_score\n                            personal_best_positions[i] = candidate\n                            if candidate_score < func(global_best_position):\n                                global_best_position = candidate\n\n        return global_best_position, func(global_best_position)", "name": "HybridPSO", "description": "Improved balance between exploration and exploitation by introducing a non-linear inertia weight adaptation strategy.", "configspace": "", "generation": 14, "fitness": 0.8237645013128582, "feedback": "The algorithm HybridPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.824 with standard deviation 0.017. And the mean value of best solutions found was 0.139 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "0b1930bb-6021-4a26-9f61-4ec186eb1756", "metadata": {"aucs": [0.8149057391890427, 0.8473546308970815, 0.8090331338524503], "final_y": [0.14329756329802323, 0.12812659917785174, 0.14562254599688984]}, "mutation_prompt": null}
{"id": "e50f6689-ed45-4348-b2ca-b5eb6f090667", "solution": "import numpy as np\n\nclass DynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = max(20, 5 * self.dim)\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(x) for x in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n\n        evaluations = len(swarm)\n        inertia_weight = 0.7\n        c1, c2 = 1.5, 1.5\n\n        while evaluations < self.budget:\n            inertia_weight = 0.9 - 0.6 * (evaluations / self.budget)  # Adaptive inertia weight decay\n\n            diversity = np.std(swarm, axis=0)\n            dynamic_factor = np.mean(diversity)\n\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 c1 * r1 * (personal_best_positions[i] - swarm[i]) +\n                                 c2 * r2 * (global_best_position - swarm[i]))\n                \n                velocities[i] = np.clip(velocities[i], -dynamic_factor, dynamic_factor)  # Velocity clamping\n\n                swarm[i] = swarm[i] + velocities[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n                \n                fitness = func(swarm[i])\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(swarm[i])\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n            \n            if evaluations >= self.budget:\n                break\n\n            for i in range(population_size):\n                indices = np.random.choice(population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = np.clip(a + 0.7 * (b - c), lb, ub)  # Adjusted mutation rate\n                trial = np.where(np.random.rand(self.dim) < 0.9, mutant, swarm[i])\n                \n                fitness = func(trial)\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(trial)\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n\n        return global_best_position, personal_best_scores[global_best_index]", "name": "DynamicSwarmOptimizer", "description": "Enhanced swarm exploration by introducing adaptive inertia weight decay and a differential mutation strategy to boost convergence and robustness.", "configspace": "", "generation": 14, "fitness": 0.8786655302993213, "feedback": "The algorithm DynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.879 with standard deviation 0.004. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "731bd7b3-92b4-40bb-82f4-baed538795d4", "metadata": {"aucs": [0.8827911887258164, 0.8729040752284803, 0.8803013269436673], "final_y": [0.1128633983485563, 0.11855259269634011, 0.11970034716289235]}, "mutation_prompt": null}
{"id": "47a2b4a6-2f62-4c6f-91a2-5d9a7f7ca1f4", "solution": "import numpy as np\n\nclass DynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = max(20, 5 * self.dim)\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(x) for x in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n\n        evaluations = len(swarm)\n        inertia_weight = 0.7\n        c1, c2 = 1.5, 1.5\n\n        while evaluations < self.budget:\n            # Dynamically adjust inertia weight based on evaluations\n            inertia_weight = 0.9 - (0.5 * evaluations / self.budget)  \n            \n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 c1 * r1 * (personal_best_positions[i] - swarm[i]) +\n                                 c2 * r2 * (global_best_position - swarm[i]))\n                velocities[i] *= 0.9  # Adaptive velocity scaling\n                swarm[i] = swarm[i] + velocities[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n                \n                fitness = func(swarm[i])\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(swarm[i])\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n            \n            if evaluations >= self.budget:\n                break\n\n            # Differential Evolution Mutation and Crossover\n            elite_size = max(2, population_size // 10)  # Elite selection\n            best_indices = np.argsort(personal_best_scores)[:elite_size]\n            for i in range(population_size):\n                indices = np.random.choice(best_indices, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = np.clip(a + 0.8 * (b - c), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < 0.9, mutant, swarm[i])\n                \n                fitness = func(trial)\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(trial)\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n\n        return global_best_position, personal_best_scores[global_best_index]", "name": "DynamicSwarmOptimizer", "description": "Introduced dynamic adjustment of inertia weight based on evaluations to improve convergence efficiency.", "configspace": "", "generation": 14, "fitness": 0.862531798883595, "feedback": "The algorithm DynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.863 with standard deviation 0.019. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "af3a875f-9a26-4707-86ca-7bc3f5ff9997", "metadata": {"aucs": [0.8401105109158694, 0.8854557297327681, 0.8620291560021472], "final_y": [0.13134969870365143, 0.1180726421975753, 0.11781343476124917]}, "mutation_prompt": null}
{"id": "9024cdd7-f6ea-4b38-b419-d383bba34346", "solution": "import numpy as np\n\nclass DynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = max(20, 5 * self.dim)\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(x) for x in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n\n        evaluations = len(swarm)\n        inertia_weight = 0.7\n        c1, c2 = 1.5, 1.5\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 c1 * r1 * (personal_best_positions[i] - swarm[i]) +\n                                 c2 * r2 * (global_best_position - swarm[i]))\n                velocities[i] *= 0.9  # Adaptive velocity scaling\n                swarm[i] = swarm[i] + velocities[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n                \n                fitness = func(swarm[i])\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(swarm[i])\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n            \n            if evaluations >= self.budget:\n                break\n\n            # Differential Evolution Mutation and Crossover\n            elite_size = max(2, population_size // 10)  # Elite selection\n            best_indices = np.argsort(personal_best_scores)[:elite_size]\n            for i in range(population_size):\n                indices = np.random.choice(best_indices, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = np.clip(a + 0.8 * (b - c), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < np.sin(np.pi * evaluations / self.budget), mutant, swarm[i])  # Modulated crossover rate\n                \n                fitness = func(trial)\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(trial)\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n\n        return global_best_position, personal_best_scores[global_best_index]", "name": "DynamicSwarmOptimizer", "description": "Enhanced crossover strategy by introducing nonlinear sinusoidal modulation over a normalized evaluation ratio to improve solution diversity.", "configspace": "", "generation": 14, "fitness": 0.8823612059244664, "feedback": "The algorithm DynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.882 with standard deviation 0.009. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "6eafb924-04bc-4b6d-9add-6a13ab5143ef", "metadata": {"aucs": [0.869646951224676, 0.8903171467209084, 0.887119519827815], "final_y": [0.12186661566054291, 0.11821616803292412, 0.11079078411935239]}, "mutation_prompt": null}
{"id": "7fbf6990-300d-4bbb-aa7e-6944506ea174", "solution": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.5   # Inertia weight\n        self.local_search_probability = 0.1\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        velocities = np.random.uniform(low=-1, high=1, size=(self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Update velocities\n                r1, r2 = np.random.rand(), np.random.rand()\n                # Adaptive inertia weight\n                self.w = 0.9 - 0.5 * (evaluations / self.budget)\n                # Update cognitive and social coefficients adaptively\n                self.c1 = 1.2 + 0.3 * (evaluations / self.budget)\n                self.c2 = 2.0 - 0.5 * (evaluations / self.budget)\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * r1 * (personal_best_positions[i] - positions[i])\n                    + self.c2 * r2 * (global_best_position - positions[i])\n                )\n                # Update positions\n                positions[i] += velocities[i]\n\n                # Boundary handling\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                # Evaluate new position\n                current_score = func(positions[i])\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                # Update personal best\n                if current_score < personal_best_scores[i]:\n                    personal_best_scores[i] = current_score\n                    personal_best_positions[i] = positions[i]\n\n                    # Update global best\n                    if current_score < func(global_best_position):\n                        global_best_position = positions[i]\n\n            # Apply local search with a probability\n            if np.random.rand() < self.local_search_probability:\n                for i in range(self.population_size):\n                    if evaluations < self.budget:\n                        # Simple local search: random walk\n                        candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                        candidate = np.clip(candidate, lb, ub)\n                        candidate_score = func(candidate)\n                        evaluations += 1\n                        if candidate_score < personal_best_scores[i]:\n                            personal_best_scores[i] = candidate_score\n                            personal_best_positions[i] = candidate\n                            if candidate_score < func(global_best_position):\n                                global_best_position = candidate\n\n        return global_best_position, func(global_best_position)", "name": "HybridPSO", "description": "Introduced an adaptive cognitive and social coefficient strategy to dynamically balance exploration and exploitation.", "configspace": "", "generation": 14, "fitness": 0.84105617716401, "feedback": "The algorithm HybridPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.841 with standard deviation 0.011. And the mean value of best solutions found was 0.129 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "0b1930bb-6021-4a26-9f61-4ec186eb1756", "metadata": {"aucs": [0.8271489529518687, 0.85288339118976, 0.8431361873504013], "final_y": [0.12903630166934021, 0.13354245719397884, 0.12441723137082905]}, "mutation_prompt": null}
{"id": "7ad9aed0-8011-4052-a79c-ae51413e2a83", "solution": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.5   # Inertia weight\n        self.local_search_probability = 0.1\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        velocities = np.random.uniform(low=-1, high=1, size=(self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Update velocities\n                r1, r2 = np.random.rand(), np.random.rand()\n                # Update inertia weight adaptively\n                self.w = 0.9 - 0.5 * (evaluations / self.budget) \n                # Dynamically update social coefficient\n                self.c2 = 1.5 + (2.0 * (1 - evaluations / self.budget))\n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * r1 * (personal_best_positions[i] - positions[i])\n                    + self.c2 * r2 * (global_best_position - positions[i])\n                )\n                # Update positions\n                positions[i] += velocities[i]\n\n                # Boundary handling\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                # Evaluate new position\n                current_score = func(positions[i])\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                # Update personal best\n                if current_score < personal_best_scores[i]:\n                    personal_best_scores[i] = current_score\n                    personal_best_positions[i] = positions[i]\n\n                    # Update global best\n                    # Directly evaluate current position to update global best\n                    if current_score < func(global_best_position):\n                        global_best_position = positions[i]\n\n            # Apply local search with a probability\n            if np.random.rand() < self.local_search_probability:\n                for i in range(self.population_size):\n                    if evaluations < self.budget:\n                        # Simple local search: random walk\n                        candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                        candidate = np.clip(candidate, lb, ub)\n                        candidate_score = func(candidate)\n                        evaluations += 1\n                        if candidate_score < personal_best_scores[i]:\n                            personal_best_scores[i] = candidate_score\n                            personal_best_positions[i] = candidate\n                            if candidate_score < func(global_best_position):\n                                global_best_position = candidate\n\n        return global_best_position, func(global_best_position)", "name": "HybridPSO", "description": "Enhanced exploration by introducing a dynamic social coefficient based on the ratio of remaining budget to increase diversity.", "configspace": "", "generation": 15, "fitness": 0.7929497915959862, "feedback": "The algorithm HybridPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.793 with standard deviation 0.006. And the mean value of best solutions found was 0.142 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "0b1930bb-6021-4a26-9f61-4ec186eb1756", "metadata": {"aucs": [0.7854326516725177, 0.7945760526397732, 0.7988406704756674], "final_y": [0.13850460020596178, 0.1430783229432674, 0.14577295836913018]}, "mutation_prompt": null}
{"id": "d72cb8b5-5133-4010-9647-9702a358c484", "solution": "import numpy as np\n\nclass DynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = max(20, 5 * self.dim)\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(x) for x in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n\n        evaluations = len(swarm)\n        inertia_weight = 0.7\n        c1, c2 = 1.5, 1.5\n\n        hierarchy_levels = max(1, self.dim // 3)\n        level_swarm_sizes = np.array_split(np.arange(population_size), hierarchy_levels)\n\n        while evaluations < self.budget:\n            inertia_weight = 0.9 - 0.6 * (evaluations / self.budget)\n\n            for level in level_swarm_sizes:\n                local_best_index = min(level, key=lambda i: personal_best_scores[i])\n                local_best_position = np.copy(personal_best_positions[local_best_index])\n\n                for i in level:\n                    r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                    velocities[i] = (inertia_weight * velocities[i] +\n                                     c1 * r1 * (personal_best_positions[i] - swarm[i]) +\n                                     c2 * r2 * (local_best_position - swarm[i]))\n                    \n                    velocities[i] = np.clip(velocities[i], -0.1, 0.1)\n\n                    swarm[i] = swarm[i] + velocities[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    fitness = func(swarm[i])\n                    evaluations += 1\n                    if fitness < personal_best_scores[i]:\n                        personal_best_scores[i] = fitness\n                        personal_best_positions[i] = np.copy(swarm[i])\n\n                        if fitness < personal_best_scores[global_best_index]:\n                            global_best_index = i\n                            global_best_position = np.copy(personal_best_positions[i])\n\n            if evaluations >= self.budget:\n                break\n\n            for level in level_swarm_sizes:\n                for i in level:\n                    indices = np.random.choice(level, 3, replace=False)\n                    a, b, c = personal_best_positions[indices]\n                    mutant = np.clip(a + 0.5 * (b - c), lb, ub)\n                    trial = np.where(np.random.rand(self.dim) < 0.9, mutant, swarm[i])\n\n                    fitness = func(trial)\n                    evaluations += 1\n                    if fitness < personal_best_scores[i]:\n                        personal_best_scores[i] = fitness\n                        personal_best_positions[i] = np.copy(trial)\n\n                        if fitness < personal_best_scores[global_best_index]:\n                            global_best_index = i\n                            global_best_position = np.copy(personal_best_positions[i])\n\n        return global_best_position, personal_best_scores[global_best_index]", "name": "DynamicSwarmOptimizer", "description": "Introduced a level-based swarm hierarchy and dynamic topology adaptation to enhance exploration-exploitation balance efficiently.", "configspace": "", "generation": 15, "fitness": 0.8301229261443188, "feedback": "The algorithm DynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.830 with standard deviation 0.047. And the mean value of best solutions found was 0.135 (0. is the best) with standard deviation 0.019.", "error": "", "parent_id": "e50f6689-ed45-4348-b2ca-b5eb6f090667", "metadata": {"aucs": [0.7699553294355115, 0.8858748467109034, 0.8345386022865413], "final_y": [0.16164273538061624, 0.11894160518970986, 0.12460324089132302]}, "mutation_prompt": null}
{"id": "7146c235-de8e-4b3e-a675-58f162fde390", "solution": "import numpy as np\n\nclass DynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = max(20, 5 * self.dim)\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(x) for x in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n\n        evaluations = len(swarm)\n        inertia_weight = 0.7\n        c1, c2 = 1.5, 1.5\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 c1 * r1 * (personal_best_positions[i] - swarm[i]) +\n                                 c2 * r2 * (global_best_position - swarm[i]))\n                velocities[i] *= 0.9  # Adaptive velocity scaling\n                velocities[i] += 0.5 * np.sin(velocities[i])  # Introducing chaotic mapping\n                swarm[i] = swarm[i] + velocities[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n                \n                fitness = func(swarm[i])\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(swarm[i])\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n            \n            if evaluations >= self.budget:\n                break\n\n            # Differential Evolution Mutation and Crossover\n            elite_size = max(2, population_size // 10)  # Elite selection\n            best_indices = np.argsort(personal_best_scores)[:elite_size]\n            for i in range(population_size):\n                indices = np.random.choice(best_indices, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = np.clip(a + 0.8 * (b - c), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < np.sin(np.pi * evaluations / self.budget), mutant, swarm[i])  # Modulated crossover rate\n                \n                fitness = func(trial)\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(trial)\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n\n        return global_best_position, personal_best_scores[global_best_index]", "name": "DynamicSwarmOptimizer", "description": "Enhanced exploration by introducing adaptive velocity scaling and chaotic mapping for improved convergence dynamics.", "configspace": "", "generation": 15, "fitness": 0.870891569291242, "feedback": "The algorithm DynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.871 with standard deviation 0.017. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "9024cdd7-f6ea-4b38-b419-d383bba34346", "metadata": {"aucs": [0.8533304616914246, 0.8663003621012083, 0.8930438840810933], "final_y": [0.12737593221522248, 0.12771503841533227, 0.11243785325292899]}, "mutation_prompt": null}
{"id": "ee8cd170-f94e-4e67-a0bd-b086da1f9bcb", "solution": "import numpy as np\n\nclass HybridPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.5   # Inertia weight\n        self.local_search_probability = 0.1\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n\n        # Initialize particles\n        positions = np.random.uniform(low=lb, high=ub, size=(self.population_size, self.dim))\n        velocities = np.random.uniform(low=-1, high=1, size=(self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                # Update velocities\n                r1, r2 = np.random.rand(), np.random.rand()\n                # Update inertia weight adaptively\n                self.w = 0.9 - 0.5 * (evaluations / self.budget) \n                velocities[i] = (\n                    self.w * velocities[i]\n                    + self.c1 * r1 * (personal_best_positions[i] - positions[i])\n                    + self.c2 * r2 * (global_best_position - positions[i])\n                )\n                # Update positions\n                positions[i] += velocities[i]\n\n                # Boundary handling\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                # Evaluate new position\n                current_score = func(positions[i])\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n                # Update personal best\n                if current_score < personal_best_scores[i]:\n                    personal_best_scores[i] = current_score\n                    personal_best_positions[i] = positions[i]\n\n                    # Update global best\n                    # Directly evaluate global_best_position instead of func(global_best_position)\n                    if current_score < func(global_best_position):\n                        global_best_position = positions[i]\n\n            # Apply local search with a probability\n            if np.random.rand() < self.local_search_probability:\n                for i in range(self.population_size):\n                    if evaluations < self.budget:\n                        # Simple local search: random walk\n                        candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                        candidate = np.clip(candidate, lb, ub)\n                        candidate_score = func(candidate)\n                        evaluations += 1\n                        if candidate_score < personal_best_scores[i]:\n                            personal_best_scores[i] = candidate_score\n                            personal_best_positions[i] = candidate\n                            if candidate_score < func(global_best_position):\n                                global_best_position = candidate\n\n        return global_best_position, func(global_best_position)", "name": "HybridPSO", "description": "Enhanced global best update strategy by using direct evaluation of global best position for improved convergence.", "configspace": "", "generation": 15, "fitness": 0.8309555521016928, "feedback": "The algorithm HybridPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.831 with standard deviation 0.017. And the mean value of best solutions found was 0.134 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "0b1930bb-6021-4a26-9f61-4ec186eb1756", "metadata": {"aucs": [0.8350723955876218, 0.849800678479208, 0.8079935822382486], "final_y": [0.13143961525924053, 0.12912518046966392, 0.1416981548849937]}, "mutation_prompt": null}
{"id": "dc9d767d-40ce-4122-82a2-f228ef5d0050", "solution": "import numpy as np\n\nclass DynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = max(20, 5 * self.dim)\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(x) for x in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n\n        evaluations = len(swarm)\n        inertia_weight = 0.7\n        c1, c2 = 1.5, 1.5\n\n        while evaluations < self.budget:\n            inertia_weight = 0.9 - 0.6 * (evaluations / self.budget)  # Adaptive inertia weight decay\n\n            diversity = np.std(swarm, axis=0)\n            dynamic_factor = np.mean(diversity)\n            adaptive_prob = 0.5 + 0.4 * (1 - dynamic_factor / np.max(diversity))  # Adaptive crossover probability\n\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 c1 * r1 * (personal_best_positions[i] - swarm[i]) +\n                                 c2 * r2 * (global_best_position - swarm[i]))\n                \n                velocities[i] = np.clip(velocities[i], -dynamic_factor, dynamic_factor)  # Velocity clamping\n\n                swarm[i] = swarm[i] + velocities[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n                \n                fitness = func(swarm[i])\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(swarm[i])\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n            \n            if evaluations >= self.budget:\n                break\n\n            for i in range(population_size):\n                indices = np.random.choice(population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = np.clip(a + 0.7 * (b - c), lb, ub)  # Adjusted mutation rate\n                trial = np.where(np.random.rand(self.dim) < adaptive_prob, mutant, swarm[i])\n                \n                fitness = func(trial)\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(trial)\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n\n        return global_best_position, personal_best_scores[global_best_index]", "name": "DynamicSwarmOptimizer", "description": "Enhanced convergence by introducing an adaptive crossover probability based on population diversity.", "configspace": "", "generation": 15, "fitness": 0.8755660259768604, "feedback": "The algorithm DynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.876 with standard deviation 0.007. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "e50f6689-ed45-4348-b2ca-b5eb6f090667", "metadata": {"aucs": [0.8829183838819032, 0.8776807530336769, 0.8660989410150012], "final_y": [0.11157071423744858, 0.11827672741558926, 0.11911037072610253]}, "mutation_prompt": null}
{"id": "f55865c2-c590-40d8-ab42-c309f05062a2", "solution": "import numpy as np\n\nclass DynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = max(20, 5 * self.dim)\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(x) for x in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n\n        evaluations = len(swarm)\n        inertia_weight = 0.7\n        c1, c2 = 1.5, 1.5\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 c1 * r1 * (personal_best_positions[i] - swarm[i]) +\n                                 c2 * r2 * (global_best_position - swarm[i]))\n                velocities[i] *= 0.9 + 0.1 * np.sin(evaluations)  # Adaptive scaling with chaos\n                swarm[i] = swarm[i] + velocities[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n                \n                fitness = func(swarm[i])\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(swarm[i])\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n            \n            if evaluations >= self.budget:\n                break\n\n            # Differential Evolution Mutation and Crossover\n            elite_size = max(2, population_size // 10)  \n            best_indices = np.argsort(personal_best_scores)[:elite_size]\n            for i in range(population_size):\n                indices = np.random.choice(best_indices, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = np.clip(a + 0.8 * (b - c), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < 0.5 + 0.5 * np.cos(evaluations), mutant, swarm[i])  # Adapt crossover rate\n                \n                fitness = func(trial)\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(trial)\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n\n        return global_best_position, personal_best_scores[global_best_index]", "name": "DynamicSwarmOptimizer", "description": "Introduce adaptive chaos-based learning rates and energy transformation to further enhance convergence and exploration balance.", "configspace": "", "generation": 16, "fitness": 0.8474102277864765, "feedback": "The algorithm DynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.847 with standard deviation 0.014. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "6eafb924-04bc-4b6d-9add-6a13ab5143ef", "metadata": {"aucs": [0.8515350336880799, 0.8619330797843519, 0.8287625698869978], "final_y": [0.1252431949538334, 0.11955395001142188, 0.12307462144391479]}, "mutation_prompt": null}
{"id": "6c41fb42-09b2-4bd9-b15e-96addc57589d", "solution": "import numpy as np\n\nclass DynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = max(20, 5 * self.dim)\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(x) for x in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n\n        evaluations = len(swarm)\n        inertia_weight = 0.7\n        c1, c2 = 1.5, 1.5\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 c1 * r1 * (personal_best_positions[i] - swarm[i]) +\n                                 c2 * r2 * (global_best_position - swarm[i]))\n                velocities[i] *= 0.9  # Adaptive velocity scaling\n                swarm[i] = swarm[i] + velocities[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n                \n                fitness = func(swarm[i])\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(swarm[i])\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n            \n            if evaluations >= self.budget:\n                break\n\n            # Differential Evolution Mutation and Crossover\n            elite_size = max(2, population_size // 10)  # Elite selection\n            best_indices = np.argsort(personal_best_scores)[:elite_size]\n            for i in range(population_size):\n                indices = np.random.choice(best_indices, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = np.clip(a + 0.8 * (b - c), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < np.sin(np.pi * evaluations / self.budget), mutant, swarm[i])  # Modulated crossover rate\n                \n                fitness = func(trial)\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(trial)\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n\n            inertia_weight *= 0.99  # Exponential decay for inertia weight\n\n        return global_best_position, personal_best_scores[global_best_index]", "name": "DynamicSwarmOptimizer", "description": "Introduced an exponential decay factor to the inertia weight to dynamically balance exploration and exploitation.", "configspace": "", "generation": 16, "fitness": 0.8557763896540148, "feedback": "The algorithm DynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.856 with standard deviation 0.008. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "9024cdd7-f6ea-4b38-b419-d383bba34346", "metadata": {"aucs": [0.8632796563939834, 0.8591388003942642, 0.8449107121737969], "final_y": [0.12162037270130921, 0.11951708210477308, 0.11524845744240886]}, "mutation_prompt": null}
{"id": "599bf456-b3d9-475a-8f91-38b9345836c5", "solution": "import numpy as np\n\nclass DynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = max(20, 5 * self.dim)\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(x) for x in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n\n        evaluations = len(swarm)\n        inertia_weight = 0.7\n        c1, c2 = 1.5, 1.5\n\n        while evaluations < self.budget:\n            inertia_weight = 0.9 - 0.6 * (evaluations / self.budget)  # Adaptive inertia weight decay\n\n            diversity = np.std(swarm, axis=0)\n            dynamic_factor = np.mean(diversity)\n            adaptive_prob = 0.5 + 0.4 * (1 - dynamic_factor / np.max(diversity))  # Adaptive crossover probability\n\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 c1 * r1 * (personal_best_positions[i] - swarm[i]) +\n                                 c2 * r2 * (global_best_position - swarm[i]))\n                \n                velocities[i] = np.clip(velocities[i], -dynamic_factor, dynamic_factor)  # Velocity clamping\n\n                swarm[i] = swarm[i] + velocities[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n                \n                fitness = func(swarm[i])\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(swarm[i])\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n            \n            if evaluations >= self.budget:\n                break\n\n            for i in range(population_size):\n                indices = np.random.choice(population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                # Change: Introduce dynamic mutation scaling\n                mutation_scaling = 0.7 + 0.3 * (1 - dynamic_factor / np.max(diversity))\n                mutant = np.clip(a + mutation_scaling * (b - c), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < adaptive_prob, mutant, swarm[i])\n                \n                fitness = func(trial)\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(trial)\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n\n        return global_best_position, personal_best_scores[global_best_index]", "name": "DynamicSwarmOptimizer", "description": "Introduced a dynamic mutation scaling factor based on population diversity to enhance exploration and convergence. ", "configspace": "", "generation": 16, "fitness": 0.8639823279494777, "feedback": "The algorithm DynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.864 with standard deviation 0.006. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "dc9d767d-40ce-4122-82a2-f228ef5d0050", "metadata": {"aucs": [0.8722922986859601, 0.8571545998817042, 0.8625000852807688], "final_y": [0.1162431472297133, 0.11993008895321189, 0.11794663485011136]}, "mutation_prompt": null}
{"id": "936a4e5f-1660-42af-95f5-7441873e385f", "solution": "import numpy as np\n\nclass DynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = max(20, 5 * self.dim)\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(x) for x in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n\n        evaluations = len(swarm)\n        inertia_weight = 0.7\n        c1, c2 = 1.5, 1.5\n\n        while evaluations < self.budget:\n            inertia_weight = 0.9 - 0.6 * (evaluations / self.budget)  # Adaptive inertia weight decay\n\n            diversity = np.std(swarm, axis=0)\n            dynamic_factor = np.mean(diversity)\n\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n\n                # Change: Introduced dynamic personal and global acceleration coefficients\n                c1_dynamic = c1 * (1 - evaluations / self.budget)\n                c2_dynamic = c2 * (evaluations / self.budget)\n\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 c1_dynamic * r1 * (personal_best_positions[i] - swarm[i]) +\n                                 c2_dynamic * r2 * (global_best_position - swarm[i]))\n                \n                velocities[i] = np.clip(velocities[i], -dynamic_factor, dynamic_factor)  # Velocity clamping\n\n                swarm[i] = swarm[i] + velocities[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n                \n                fitness = func(swarm[i])\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(swarm[i])\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n            \n            if evaluations >= self.budget:\n                break\n\n            for i in range(population_size):\n                indices = np.random.choice(population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = np.clip(a + 0.7 * (b - c), lb, ub)  # Adjusted mutation rate\n                trial = np.where(np.random.rand(self.dim) < 0.9, mutant, swarm[i])\n                \n                fitness = func(trial)\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(trial)\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n\n        return global_best_position, personal_best_scores[global_best_index]", "name": "DynamicSwarmOptimizer", "description": "Introduced dynamic personal and global acceleration coefficients to enhance exploration and exploitation balance.", "configspace": "", "generation": 16, "fitness": 0.8499473880328724, "feedback": "The algorithm DynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.850 with standard deviation 0.014. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "e50f6689-ed45-4348-b2ca-b5eb6f090667", "metadata": {"aucs": [0.8327585379626369, 0.8677658740863776, 0.8493177520496025], "final_y": [0.11851611177805921, 0.11905098991494634, 0.11625761752769492]}, "mutation_prompt": null}
{"id": "67e538e2-ddf5-4f6c-aaa8-a95278aecc04", "solution": "import numpy as np\n\nclass DynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = max(20, 5 * self.dim)\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(x) for x in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n\n        evaluations = len(swarm)\n        inertia_weight = 0.7\n        c1, c2 = 1.5, 1.5\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 c1 * r1 * (personal_best_positions[i] - swarm[i]) +\n                                 c2 * r2 * (global_best_position - swarm[i]))\n                velocities[i] *= 0.85  # Adaptive velocity scaling\n                swarm[i] = swarm[i] + velocities[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n                \n                fitness = func(swarm[i])\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(swarm[i])\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n            \n            if evaluations >= self.budget:\n                break\n\n            # Differential Evolution Mutation and Crossover\n            elite_size = max(2, population_size // 10)  # Elite selection\n            best_indices = np.argsort(personal_best_scores)[:elite_size]\n            for i in range(population_size):\n                indices = np.random.choice(best_indices, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = np.clip(a + 0.8 * (b - c), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < np.sin(np.pi * evaluations / self.budget), mutant, swarm[i])  # Modulated crossover rate\n                \n                fitness = func(trial)\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(trial)\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n\n        return global_best_position, personal_best_scores[global_best_index]", "name": "DynamicSwarmOptimizer", "description": "Improved the adaptive velocity scaling factor from 0.9 to 0.85 for better balance between exploration and exploitation.", "configspace": "", "generation": 16, "fitness": 0.8467740632628461, "feedback": "The algorithm DynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.847 with standard deviation 0.022. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "9024cdd7-f6ea-4b38-b419-d383bba34346", "metadata": {"aucs": [0.8672810423910061, 0.8561875830748256, 0.8168535643227066], "final_y": [0.11558388336946535, 0.1251419076737721, 0.12515685414540523]}, "mutation_prompt": null}
{"id": "6e195dc0-5c21-4fd1-90bc-01a622512c89", "solution": "import numpy as np\n\nclass DynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = max(20, 5 * self.dim)\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(x) for x in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n\n        evaluations = len(swarm)\n        inertia_weight = 0.7\n        c1, c2 = 1.5, 1.5\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 c1 * r1 * (personal_best_positions[i] - swarm[i]) +\n                                 c2 * r2 * (global_best_position - swarm[i]))\n                if np.random.rand() < 0.1:\n                    velocities[i] += self._levy_flight(self.dim)  # Levy flight perturbation\n                \n                velocities[i] *= 0.9  # Adaptive velocity scaling\n                swarm[i] = swarm[i] + velocities[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n                \n                fitness = func(swarm[i])\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(swarm[i])\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n            \n            if evaluations >= self.budget:\n                break\n\n            # Differential Evolution Mutation and Crossover\n            elite_size = max(2, population_size // 10)  # Elite selection\n            best_indices = np.argsort(personal_best_scores)[:elite_size]\n            for i in range(population_size):\n                indices = np.random.choice(best_indices, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = np.clip(a + 0.8 * (b - c), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < np.sin(np.pi * evaluations / self.budget), mutant, swarm[i])  # Modulated crossover rate\n                \n                fitness = func(trial)\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(trial)\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n\n        return global_best_position, personal_best_scores[global_best_index]\n    \n    def _levy_flight(self, dim, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, dim)\n        v = np.random.normal(0, 1, dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step", "name": "DynamicSwarmOptimizer", "description": "Enhanced swarm optimizer with Levy Flight perturbation to escape local optima and improve exploration.", "configspace": "", "generation": 17, "fitness": 0.8865972236107247, "feedback": "The algorithm DynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.887 with standard deviation 0.006. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "9024cdd7-f6ea-4b38-b419-d383bba34346", "metadata": {"aucs": [0.8867952263575898, 0.8793022104477688, 0.8936942340268152], "final_y": [0.1162235186446886, 0.12150068809288861, 0.117710614686385]}, "mutation_prompt": null}
{"id": "e34bfc83-4232-45cd-9cf4-eeed4304f044", "solution": "import numpy as np\n\nclass DynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = max(20, 5 * self.dim)\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(x) for x in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n\n        evaluations = len(swarm)\n        inertia_weight = 0.7\n        c1, c2 = 1.5, 1.5\n\n        while evaluations < self.budget:\n            inertia_weight = 0.9 - 0.6 * (evaluations / self.budget)\n\n            diversity = np.std(swarm, axis=0)\n            dynamic_factor = np.mean(diversity)\n\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 c1 * r1 * (personal_best_positions[i] - swarm[i]) +\n                                 c2 * r2 * (global_best_position - swarm[i]))\n                \n                scale_factor = 1 / (1 + np.exp(-evaluations/self.budget))\n                velocities[i] *= scale_factor\n                velocities[i] = np.clip(velocities[i], -dynamic_factor, dynamic_factor)\n\n                swarm[i] = swarm[i] + velocities[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n                \n                fitness = func(swarm[i])\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(swarm[i])\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n            \n            if evaluations >= self.budget:\n                break\n\n            for i in range(population_size):\n                indices = np.random.choice(population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                perturbation = np.random.normal(0, dynamic_factor, self.dim)  # Gaussian perturbation\n                mutant = np.clip(a + 0.7 * (b - c) + perturbation, lb, ub)\n                trial = np.where(np.random.rand(self.dim) < 0.9, mutant, swarm[i])\n                \n                fitness = func(trial)\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(trial)\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n\n        return global_best_position, personal_best_scores[global_best_index]", "name": "DynamicSwarmOptimizer", "description": "Enhanced swarm diversity and adaptive mutation by incorporating Gaussian random perturbation and nonlinear velocity scaling to improve exploration and convergence.", "configspace": "", "generation": 17, "fitness": 0.8748079676173802, "feedback": "The algorithm DynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.875 with standard deviation 0.009. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "e50f6689-ed45-4348-b2ca-b5eb6f090667", "metadata": {"aucs": [0.8755850449252869, 0.885939486930941, 0.8628993709959129], "final_y": [0.11158062800462476, 0.1179418497203426, 0.12114065851554379]}, "mutation_prompt": null}
{"id": "e648ef07-7e27-4cad-9e9a-e9b1183924e1", "solution": "import numpy as np\n\nclass DynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = max(20, 5 * self.dim)\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(x) for x in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n\n        evaluations = len(swarm)\n        c1, c2 = 1.5, 1.5\n\n        while evaluations < self.budget:\n            # Non-linear time-varying inertia weight\n            inertia_weight = 0.9 - (0.5 * (evaluations / self.budget) ** 2)\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 c1 * r1 * (personal_best_positions[i] - swarm[i]) +\n                                 c2 * r2 * (global_best_position - swarm[i]))\n                velocities[i] *= 0.9  # Adaptive velocity scaling\n                swarm[i] = swarm[i] + velocities[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n                \n                fitness = func(swarm[i])\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(swarm[i])\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n            \n            if evaluations >= self.budget:\n                break\n\n            # Differential Evolution Mutation and Crossover\n            elite_size = max(2, population_size // 10)  # Elite selection\n            best_indices = np.argsort(personal_best_scores)[:elite_size]\n            for i in range(population_size):\n                indices = np.random.choice(best_indices, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = np.clip(a + 0.8 * (b - c), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < np.sin(evaluations), mutant, swarm[i])  # Adapt crossover rate\n                \n                fitness = func(trial)\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(trial)\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n\n        return global_best_position, personal_best_scores[global_best_index]", "name": "DynamicSwarmOptimizer", "description": "Introduced non-linear time-varying inertia weight to dynamically balance exploration and exploitation for improved convergence.", "configspace": "", "generation": 17, "fitness": 0.8694717004597945, "feedback": "The algorithm DynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.869 with standard deviation 0.004. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "6eafb924-04bc-4b6d-9add-6a13ab5143ef", "metadata": {"aucs": [0.8682510915893101, 0.8651557191076562, 0.8750082906824169], "final_y": [0.12260774546802578, 0.12517434666076643, 0.12116926872952005]}, "mutation_prompt": null}
{"id": "43e781c5-3b72-447f-90d5-4a3f731f0634", "solution": "import numpy as np\n\nclass DynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = max(20, 5 * self.dim)\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(x) for x in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n\n        evaluations = len(swarm)\n        inertia_weight = 0.7\n        c1, c2 = 1.5, 1.5\n\n        while evaluations < self.budget:\n            inertia_weight = 0.9 - 0.6 * (evaluations / self.budget)\n\n            diversity = np.std(swarm, axis=0)\n            dynamic_factor = np.mean(diversity)\n\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 c1 * r1 * (personal_best_positions[i] - swarm[i]) +\n                                 c2 * r2 * (global_best_position - swarm[i]))\n                \n                velocities[i] = np.clip(velocities[i], -dynamic_factor, dynamic_factor)\n\n                swarm[i] = swarm[i] + velocities[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n                \n                fitness = func(swarm[i])\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(swarm[i])\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n            \n            if evaluations >= self.budget:\n                break\n\n            for i in range(population_size):\n                indices = np.random.choice(population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                adaptive_mutation_rate = 0.5 + (0.4 * np.random.rand())  # Adaptive mutation rate\n                mutant = np.clip(a + adaptive_mutation_rate * (b - c), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < 0.9, mutant, swarm[i])\n                \n                if np.random.rand() < 0.2:  # Variable Neighborhood Search\n                    trial += np.random.normal(0, 0.1, self.dim) * (ub - lb)\n                trial = np.clip(trial, lb, ub)\n\n                fitness = func(trial)\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(trial)\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n\n        return global_best_position, personal_best_scores[global_best_index]", "name": "DynamicSwarmOptimizer", "description": "Enhanced swarm exploration by introducing adaptive mutation rate and incorporating a variable neighborhood search to improve diversity and convergence.", "configspace": "", "generation": 17, "fitness": 0.8758523476660791, "feedback": "The algorithm DynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.876 with standard deviation 0.013. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "e50f6689-ed45-4348-b2ca-b5eb6f090667", "metadata": {"aucs": [0.8580994779660804, 0.8875659020296955, 0.8818916630024612], "final_y": [0.1192691491967588, 0.12017413036493385, 0.1142258374989934]}, "mutation_prompt": null}
{"id": "64e7f93f-fa58-4129-b6cd-dba411bf12bb", "solution": "import numpy as np\n\nclass DynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = max(20, 5 * self.dim)\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(x) for x in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n\n        evaluations = len(swarm)\n        inertia_weight = 0.7\n        c1, c2 = 1.5, 1.5\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 c1 * r1 * (personal_best_positions[i] - swarm[i]) +\n                                 c2 * r2 * (global_best_position - swarm[i]))\n                velocities[i] *= 0.9  # Adaptive velocity scaling\n\n                # Lévy flight step\n                levy_step = np.random.normal(0, 0.1, self.dim) * np.random.standard_cauchy(self.dim)\n                swarm[i] = swarm[i] + velocities[i] + levy_step\n\n                swarm[i] = np.clip(swarm[i], lb, ub)\n                \n                fitness = func(swarm[i])\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(swarm[i])\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n            \n            if evaluations >= self.budget:\n                break\n\n            # Differential Evolution Mutation and Crossover\n            elite_size = max(2, population_size // 10)  # Elite selection\n            best_indices = np.argsort(personal_best_scores)[:elite_size]\n            for i in range(population_size):\n                indices = np.random.choice(best_indices, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = np.clip(a + 0.8 * (b - c), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < np.sin(evaluations), mutant, swarm[i])  # Adapt crossover rate\n                \n                fitness = func(trial)\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(trial)\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n\n        return global_best_position, personal_best_scores[global_best_index]", "name": "DynamicSwarmOptimizer", "description": "Enhanced convergence by incorporating Lévy flight in position updates to increase search efficiency and escape local optima.", "configspace": "", "generation": 17, "fitness": 0.8716237241241193, "feedback": "The algorithm DynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.872 with standard deviation 0.005. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "6eafb924-04bc-4b6d-9add-6a13ab5143ef", "metadata": {"aucs": [0.8781086428865444, 0.8655016124926218, 0.8712609169931915], "final_y": [0.11918433794778271, 0.1304002710690968, 0.12397272543292437]}, "mutation_prompt": null}
{"id": "3190ee26-3ff4-4e9a-af32-8ad4b57d1a90", "solution": "import numpy as np\n\nclass DynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = max(20, 5 * self.dim)\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(x) for x in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n\n        evaluations = len(swarm)\n        inertia_weight = 0.7\n        c1, c2 = 1.5, 1.5\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 c1 * r1 * (personal_best_positions[i] - swarm[i]) +\n                                 c2 * r2 * (global_best_position - swarm[i]))\n                velocities[i] *= 0.9  # Adaptive velocity scaling\n                swarm[i] = swarm[i] + velocities[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n                \n                fitness = func(swarm[i])\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(swarm[i])\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n            \n            if evaluations >= self.budget:\n                break\n\n            # Differential Evolution Mutation and Crossover\n            elite_size = max(2, population_size // 10)  # Elite selection\n            best_indices = np.argsort(personal_best_scores)[:elite_size]\n            for i in range(population_size):\n                indices = np.random.choice(best_indices, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = np.clip(a + 0.8 * (b - c), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < np.cos(np.pi * evaluations / self.budget), mutant, swarm[i])  # Cosine modulated crossover rate\n                \n                fitness = func(trial)\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(trial)\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n\n        return global_best_position, personal_best_scores[global_best_index]", "name": "DynamicSwarmOptimizer", "description": "Enhanced swarm optimizer by introducing a cosine-based modulation for crossover rate to improve solution exploration and exploitation balance.", "configspace": "", "generation": 18, "fitness": 0.8701634023541461, "feedback": "The algorithm DynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.870 with standard deviation 0.021. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "9024cdd7-f6ea-4b38-b419-d383bba34346", "metadata": {"aucs": [0.8409734865751899, 0.8858034029937617, 0.8837133174934867], "final_y": [0.13327363555027927, 0.11655878639592354, 0.11818270747219428]}, "mutation_prompt": null}
{"id": "1c8c9e5a-f9fd-4644-9475-6811ee1352b6", "solution": "import numpy as np\n\nclass DynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = max(20, 5 * self.dim)\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(x) for x in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n\n        evaluations = len(swarm)\n        inertia_weight = 0.7\n        c1, c2 = 1.5, 1.5\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 c1 * r1 * (personal_best_positions[i] - swarm[i]) +\n                                 c2 * r2 * (global_best_position - swarm[i]))\n                velocities[i] *= (0.9 + 0.1 * np.random.rand())  # Adjusted adaptive velocity scaling\n                swarm[i] = swarm[i] + velocities[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n                \n                fitness = func(swarm[i])\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(swarm[i])\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n            \n            if evaluations >= self.budget:\n                break\n\n            # Differential Evolution Mutation and Crossover\n            elite_size = max(2, population_size // 10)  # Elite selection\n            best_indices = np.argsort(personal_best_scores)[:elite_size]\n            for i in range(population_size):\n                indices = np.random.choice(best_indices, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = np.clip(a + 0.8 * (b - c), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < np.sin(evaluations), mutant, swarm[i]) \n                \n                fitness = func(trial)\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(trial)\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n\n        return global_best_position, personal_best_scores[global_best_index]", "name": "DynamicSwarmOptimizer", "description": "Improved diversity and global exploration by adjusting velocity scaling and incorporating an additional random perturbation.", "configspace": "", "generation": 18, "fitness": 0.8751453622938244, "feedback": "The algorithm DynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.875 with standard deviation 0.007. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "6eafb924-04bc-4b6d-9add-6a13ab5143ef", "metadata": {"aucs": [0.8715103131164349, 0.8845683525984632, 0.869357421166575], "final_y": [0.1203513047606698, 0.11613314637078687, 0.12213264727737683]}, "mutation_prompt": null}
{"id": "60c2a409-d96a-4ba5-a041-748a7673b581", "solution": "import numpy as np\n\nclass DynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = max(20, 5 * self.dim)\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(x) for x in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n\n        evaluations = len(swarm)\n        inertia_weight = 0.7\n        c1, c2 = 1.5, 1.5\n\n        while evaluations < self.budget:\n            inertia_weight = 0.9 - 0.6 * (evaluations / self.budget)  # Adaptive inertia weight decay\n\n            diversity = np.std(swarm, axis=0)\n            dynamic_factor = np.mean(diversity)\n\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 c1 * r1 * (personal_best_positions[i] - swarm[i]) +\n                                 c2 * r2 * (global_best_position - swarm[i]))\n                \n                velocities[i] = np.clip(velocities[i], -dynamic_factor, dynamic_factor)  # Velocity clamping\n\n                swarm[i] = swarm[i] + velocities[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n                \n                fitness = func(swarm[i])\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(swarm[i])\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n            \n            if evaluations >= self.budget:\n                break\n\n            for i in range(population_size):\n                indices = np.random.choice(population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                F = 0.5 + 0.3 * (evaluations / self.budget)  # Adjusted mutation rate dynamically\n                mutant = np.clip(a + F * (b - c), lb, ub)  # Self-adaptive mutation rate\n                trial = np.where(np.random.rand(self.dim) < 0.9, mutant, swarm[i])\n                \n                fitness = func(trial)\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(trial)\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n\n        return global_best_position, personal_best_scores[global_best_index]", "name": "DynamicSwarmOptimizer", "description": "Introduced self-adaptive parameter tuning for inertia weight and mutation rate to enhance convergence efficiency.", "configspace": "", "generation": 18, "fitness": 0.88652175966131, "feedback": "The algorithm DynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.887 with standard deviation 0.007. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "e50f6689-ed45-4348-b2ca-b5eb6f090667", "metadata": {"aucs": [0.8938847168965287, 0.8885429649859966, 0.8771375971014048], "final_y": [0.11239753559608345, 0.11749121554958197, 0.12146113868447661]}, "mutation_prompt": null}
{"id": "e6a0f537-cd6d-43ad-96ac-f02e606496d2", "solution": "import numpy as np\n\nclass DynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = max(20, 5 * self.dim)\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(x) for x in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n\n        evaluations = len(swarm)\n        inertia_weight = 0.7\n\n        while evaluations < self.budget:\n            # Time-varying acceleration coefficients\n            c1 = 2.5 - (2.5 - 0.5) * (evaluations / self.budget)\n            c2 = 0.5 + (2.5 - 0.5) * (evaluations / self.budget)\n\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 c1 * r1 * (personal_best_positions[i] - swarm[i]) +\n                                 c2 * r2 * (global_best_position - swarm[i]))\n                if np.random.rand() < 0.1:\n                    velocities[i] += self._levy_flight(self.dim)  # Levy flight perturbation\n                \n                velocities[i] *= 0.9  # Adaptive velocity scaling\n                swarm[i] = swarm[i] + velocities[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n                \n                fitness = func(swarm[i])\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(swarm[i])\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n            \n            if evaluations >= self.budget:\n                break\n\n            # Differential Evolution Mutation and Crossover\n            elite_size = max(2, population_size // 10)  # Elite selection\n            best_indices = np.argsort(personal_best_scores)[:elite_size]\n            for i in range(population_size):\n                indices = np.random.choice(best_indices, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = np.clip(a + 0.8 * (b - c), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < np.sin(np.pi * evaluations / self.budget), mutant, swarm[i])  # Modulated crossover rate\n                \n                fitness = func(trial)\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(trial)\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n\n        return global_best_position, personal_best_scores[global_best_index]\n    \n    def _levy_flight(self, dim, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, dim)\n        v = np.random.normal(0, 1, dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step", "name": "DynamicSwarmOptimizer", "description": "Introduced time-varying acceleration coefficients to improve convergence dynamics and adaptability.", "configspace": "", "generation": 18, "fitness": 0.8674770604350113, "feedback": "The algorithm DynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.867 with standard deviation 0.003. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "6e195dc0-5c21-4fd1-90bc-01a622512c89", "metadata": {"aucs": [0.8636723382566376, 0.8700658017738252, 0.8686930412745709], "final_y": [0.1196096416901351, 0.11515399430681561, 0.12336988328462262]}, "mutation_prompt": null}
{"id": "6a117e4f-2066-4207-be0b-48b5573ded66", "solution": "import numpy as np\n\nclass DynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = max(20, 5 * self.dim)\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(x) for x in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n\n        evaluations = len(swarm)\n        inertia_weight = 0.7\n        c1, c2 = 1.5, 1.5\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 c1 * r1 * (personal_best_positions[i] - swarm[i]) +\n                                 c2 * r2 * (global_best_position - swarm[i]))\n                velocities[i] *= 0.9  # Adaptive velocity scaling\n                swarm[i] = swarm[i] + velocities[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n                \n                fitness = func(swarm[i])\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(swarm[i])\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n            \n            if evaluations >= self.budget:\n                break\n\n            # Differential Evolution Mutation and Crossover\n            elite_size = max(2, population_size // 10)  # Elite selection\n            best_indices = np.argsort(personal_best_scores)[:elite_size]\n            for i in range(population_size):\n                indices = np.random.choice(best_indices, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutation_factor = 0.8 + 0.2 * np.random.rand()  # Stochastic mutation scaling\n                mutant = np.clip(a + mutation_factor * (b - c), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < 0.5 * (1 + np.cos(evaluations)), mutant, swarm[i])  # Cosine modulated crossover\n                \n                fitness = func(trial)\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(trial)\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n\n        return global_best_position, personal_best_scores[global_best_index]", "name": "DynamicSwarmOptimizer", "description": "Introduced stochastic mutation scaling and dynamic crossover probability using cosine modulation for enhanced exploration.", "configspace": "", "generation": 18, "fitness": 0.8877353345267641, "feedback": "The algorithm DynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.888 with standard deviation 0.006. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "6eafb924-04bc-4b6d-9add-6a13ab5143ef", "metadata": {"aucs": [0.8813675463548016, 0.8859595654215913, 0.8958788918038993], "final_y": [0.11973967632174065, 0.12142074955222704, 0.115559517359754]}, "mutation_prompt": null}
{"id": "9871d3e3-2755-4112-ac76-8cf730413a68", "solution": "import numpy as np\n\nclass DynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = max(20, 5 * self.dim)\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(x) for x in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n\n        evaluations = len(swarm)\n        inertia_weight = 0.7\n        c1, c2 = 1.5, 1.5\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 c1 * r1 * (personal_best_positions[i] - swarm[i]) +\n                                 c2 * r2 * (global_best_position - swarm[i]))\n                velocities[i] *= 0.9  # Adaptive velocity scaling\n                swarm[i] = swarm[i] + velocities[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n                \n                fitness = func(swarm[i])\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(swarm[i])\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n            \n            if evaluations >= self.budget:\n                break\n\n            # Differential Evolution Mutation and Crossover\n            elite_size = max(2, population_size // 10)  # Elite selection\n            best_indices = np.argsort(personal_best_scores)[:elite_size]\n            for i in range(population_size):\n                indices = np.random.choice(best_indices, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = np.clip(a + 0.8 * (b - c), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < np.sin(np.pi * evaluations / self.budget), mutant, swarm[i])  # Modulated crossover rate\n                \n                fitness = func(trial)\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(trial)\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n\n            # Replacing the worst with the best to maintain diversity\n            if evaluations < self.budget:\n                worst_index = np.argmax(personal_best_scores)\n                swarm[worst_index] = np.copy(global_best_position)\n\n        return global_best_position, personal_best_scores[global_best_index]", "name": "DynamicSwarmOptimizer", "description": "Introduced elite replacement strategy to enhance diversity and convergence rate in the swarm.", "configspace": "", "generation": 19, "fitness": 0.8722862958789696, "feedback": "The algorithm DynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.872 with standard deviation 0.010. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "9024cdd7-f6ea-4b38-b419-d383bba34346", "metadata": {"aucs": [0.8629445204029152, 0.8857840431717082, 0.8681303240622851], "final_y": [0.12013329249706439, 0.12011965962115767, 0.12066249128229778]}, "mutation_prompt": null}
{"id": "be7fbbc7-e685-43eb-a4a3-c09637a62831", "solution": "import numpy as np\n\nclass DynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = max(20, 5 * self.dim)\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(x) for x in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n\n        evaluations = len(swarm)\n        inertia_weight = 0.7\n        c1, c2 = 1.5, 1.5\n\n        while evaluations < self.budget:\n            inertia_weight = 0.9 - 0.6 * (evaluations / self.budget)  # Adaptive inertia weight decay\n\n            diversity = np.std(swarm, axis=0)\n            dynamic_factor = np.mean(diversity)\n\n            velocity_scale = 0.5 + 0.5 * (dynamic_factor / np.std(swarm))  # Adaptive velocity scaling\n\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 c1 * r1 * (personal_best_positions[i] - swarm[i]) +\n                                 c2 * r2 * (global_best_position - swarm[i]))\n                \n                velocities[i] = np.clip(velocities[i] * velocity_scale, -dynamic_factor, dynamic_factor)  # Velocity clamping\n\n                swarm[i] = swarm[i] + velocities[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n                \n                fitness = func(swarm[i])\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(swarm[i])\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n            \n            if evaluations >= self.budget:\n                break\n\n            for i in range(population_size):\n                indices = np.random.choice(population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                F = 0.5 + 0.3 * (evaluations / self.budget)  # Adjusted mutation rate dynamically\n                mutant = np.clip(a + F * (b - c), lb, ub)  # Self-adaptive mutation rate\n                trial = np.where(np.random.rand(self.dim) < 0.9, mutant, swarm[i])\n                \n                fitness = func(trial)\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(trial)\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n\n        return global_best_position, personal_best_scores[global_best_index]", "name": "DynamicSwarmOptimizer", "description": "Enhanced exploration by introducing adaptive velocity scaling based on population diversity.", "configspace": "", "generation": 19, "fitness": 0.882575984997423, "feedback": "The algorithm DynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.883 with standard deviation 0.007. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "60c2a409-d96a-4ba5-a041-748a7673b581", "metadata": {"aucs": [0.8747698795137697, 0.8914456608611532, 0.8815124146173461], "final_y": [0.11526308230530258, 0.12160962981509993, 0.12219148849125416]}, "mutation_prompt": null}
{"id": "5943fe64-900d-4d09-bb07-9e692ca3157f", "solution": "import numpy as np\n\nclass DynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = max(20, 5 * self.dim)\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(x) for x in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n\n        evaluations = len(swarm)\n        inertia_weight = 0.7\n        c1, c2 = 1.5, 1.5\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 c1 * r1 * (personal_best_positions[i] - swarm[i]) +\n                                 c2 * r2 * (global_best_position - swarm[i]))\n                if np.random.rand() < 0.1:\n                    velocities[i] += self._levy_flight(self.dim) * (1 + np.random.rand())  # Adaptive mutation scaling\n                \n                velocities[i] *= 0.9  # Adaptive velocity scaling\n                swarm[i] = swarm[i] + velocities[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n                \n                fitness = func(swarm[i])\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(swarm[i])\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n            \n            if evaluations >= self.budget:\n                break\n\n            # Differential Evolution Mutation and Crossover\n            elite_size = max(2, population_size // 10)  # Elite selection\n            best_indices = np.argsort(personal_best_scores)[:elite_size]\n            for i in range(population_size):\n                indices = np.random.choice(best_indices, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = np.clip(a + 0.8 * (b - c), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < np.sin(np.pi * evaluations / self.budget), mutant, swarm[i])  # Modulated crossover rate\n                \n                fitness = func(trial)\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(trial)\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n\n        return global_best_position, personal_best_scores[global_best_index]\n    \n    def _levy_flight(self, dim, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, dim)\n        v = np.random.normal(0, 1, dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step", "name": "DynamicSwarmOptimizer", "description": "Introduced adaptive mutation scaling based on current fitness improvement and diversity to enhance exploration efficiency.", "configspace": "", "generation": 19, "fitness": 0.8639574099876922, "feedback": "The algorithm DynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.864 with standard deviation 0.006. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "6e195dc0-5c21-4fd1-90bc-01a622512c89", "metadata": {"aucs": [0.8586204178872774, 0.8725626207639319, 0.860689191311867], "final_y": [0.12399176925298672, 0.11984508430442753, 0.1266744085537419]}, "mutation_prompt": null}
{"id": "eaa56f47-f040-4f57-89e4-6f43149bf564", "solution": "import numpy as np\n\nclass DynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = max(20, 5 * self.dim)\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(x) for x in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n\n        evaluations = len(swarm)\n        inertia_weight = 0.7\n        c1, c2 = 1.5, 1.5\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 c1 * r1 * (personal_best_positions[i] - swarm[i]) +\n                                 c2 * r2 * (global_best_position - swarm[i]))\n                velocities[i] *= 0.9  # Adaptive velocity scaling\n                swarm[i] = swarm[i] + velocities[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n                \n                fitness = func(swarm[i])\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(swarm[i])\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n            \n            if evaluations >= self.budget:\n                break\n\n            # Differential Evolution Mutation and Crossover\n            elite_size = max(2, population_size // 10)  # Elite selection\n            best_indices = np.argsort(personal_best_scores)[:elite_size]\n            for i in range(population_size):\n                indices = np.random.choice(best_indices, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutation_factor = 0.8 + 0.1 * (1 / (1 + np.exp(-0.01 * (evaluations))))  # Adaptive mutation with sigmoid\n                mutant = np.clip(a + mutation_factor * (b - c), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < 0.5 * (1 + np.cos(evaluations)), mutant, swarm[i])  # Cosine modulated crossover\n                \n                fitness = func(trial)\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(trial)\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n\n        return global_best_position, personal_best_scores[global_best_index]", "name": "DynamicSwarmOptimizer", "description": "Introduced adaptive mutation factor using sigmoid modulation to enhance balance between exploration and exploitation.", "configspace": "", "generation": 19, "fitness": 0.8676139506092125, "feedback": "The algorithm DynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.868 with standard deviation 0.010. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "6a117e4f-2066-4207-be0b-48b5573ded66", "metadata": {"aucs": [0.8806856953749516, 0.8559957245233247, 0.866160431929361], "final_y": [0.12110824630614525, 0.12184127525464017, 0.117728648633176]}, "mutation_prompt": null}
{"id": "b7badcec-dd37-4fe4-a845-aa4c9946dae9", "solution": "import numpy as np\n\nclass DynamicSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = max(20, 5 * self.dim)\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.array([func(x) for x in swarm])\n        global_best_index = np.argmin(personal_best_scores)\n        global_best_position = np.copy(personal_best_positions[global_best_index])\n\n        evaluations = len(swarm)\n        inertia_weight = 0.9\n        c1, c2 = 1.5, 1.5\n\n        while evaluations < self.budget:\n            inertia_weight = 0.4 + 0.5 * (1 - evaluations / self.budget)  # Adaptive inertia weight\n            for i in range(population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 c1 * r1 * (personal_best_positions[i] - swarm[i]) +\n                                 c2 * r2 * (global_best_position - swarm[i]))\n                if np.random.rand() < 0.1:\n                    velocities[i] += self._levy_flight(self.dim)  # Levy flight perturbation\n                \n                velocities[i] *= 0.9  # Adaptive velocity scaling\n                swarm[i] = swarm[i] + velocities[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n                \n                fitness = func(swarm[i])\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(swarm[i])\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n            \n            if evaluations >= self.budget:\n                break\n\n            # Differential Evolution Mutation and Crossover\n            elite_size = max(2, population_size // 8)  # Adjusted elite size\n            best_indices = np.argsort(personal_best_scores)[:elite_size]\n            for i in range(population_size):\n                indices = np.random.choice(best_indices, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutation_factor = 0.6 + 0.4 * (1 - evaluations / self.budget)  # Adaptive mutation factor\n                mutant = np.clip(a + mutation_factor * (b - c), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < np.sin(np.pi * evaluations / self.budget), mutant, swarm[i])  # Modulated crossover rate\n                \n                fitness = func(trial)\n                evaluations += 1\n                if fitness < personal_best_scores[i]:\n                    personal_best_scores[i] = fitness\n                    personal_best_positions[i] = np.copy(trial)\n                    \n                    if fitness < personal_best_scores[global_best_index]:\n                        global_best_index = i\n                        global_best_position = np.copy(personal_best_positions[i])\n\n        return global_best_position, personal_best_scores[global_best_index]\n    \n    def _levy_flight(self, dim, beta=1.5):\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, dim)\n        v = np.random.normal(0, 1, dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step", "name": "DynamicSwarmOptimizer", "description": "Introduced adaptive inertia weight and adaptive mutation factor to dynamically balance exploration and exploitation.", "configspace": "", "generation": 19, "fitness": 0.8650879794071974, "feedback": "The algorithm DynamicSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.865 with standard deviation 0.001. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "6e195dc0-5c21-4fd1-90bc-01a622512c89", "metadata": {"aucs": [0.8638874407465665, 0.867157313114594, 0.8642191843604317], "final_y": [0.12183590115985732, 0.12675097436353633, 0.11783248721407868]}, "mutation_prompt": null}
