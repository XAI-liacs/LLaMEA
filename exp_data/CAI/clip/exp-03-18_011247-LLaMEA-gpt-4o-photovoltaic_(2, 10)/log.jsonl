{"id": "e9a64d65-3b46-42ff-a566-eb038f7f0f98", "solution": "import numpy as np\n\nclass HybridAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.population = np.random.rand(self.population_size, dim)\n        self.performance_memory = []\n        self.current_evaluations = 0\n\n    def adaptive_mutation_factor(self):\n        if len(self.performance_memory) < 2:\n            return self.mutation_factor\n        return 0.5 + 0.1 * np.sign(self.performance_memory[-1] - self.performance_memory[-2])\n\n    def select_parents(self, idx):\n        indices = list(range(self.population_size))\n        indices.remove(idx)\n        return np.random.choice(indices, 3, replace=False)\n\n    def mutate_and_crossover(self, target_idx, func):\n        a, b, c = self.select_parents(target_idx)\n        mutant_vector = self.population[a] + self.adaptive_mutation_factor() * (self.population[b] - self.population[c])\n        mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n        trial_vector = np.copy(self.population[target_idx])\n        crossover_points = np.random.rand(self.dim) < self.crossover_rate\n        trial_vector[crossover_points] = mutant_vector[crossover_points]\n        return trial_vector\n\n    def optimize(self, func):\n        fitness = np.array([func(ind) for ind in self.population])\n        self.current_evaluations += self.population_size\n        for _ in range(self.budget - self.current_evaluations):\n            for i in range(self.population_size):\n                trial_vector = self.mutate_and_crossover(i, func)\n                trial_fitness = func(trial_vector)\n                self.current_evaluations += 1\n                if trial_fitness < fitness[i]:\n                    self.population[i] = trial_vector\n                    fitness[i] = trial_fitness\n            self.performance_memory.append(np.min(fitness))\n        return self.population[np.argmin(fitness)]\n\n    def __call__(self, func):\n        return self.optimize(func)\n\n# Example usage:\n# optimizer = HybridAdaptiveDifferentialEvolution(budget=1000, dim=10)\n# best_solution = optimizer(some_black_box_function)", "name": "HybridAdaptiveDifferentialEvolution", "description": "A novel hybrid algorithm combining adaptive differential evolution with a learning-based strategy to efficiently explore and exploit the search space within limited function evaluations.", "configspace": "", "generation": 0, "fitness": 0.660056797745749, "feedback": "The algorithm HybridAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.660 with standard deviation 0.000. And the mean value of best solutions found was 0.219 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": null, "metadata": {"aucs": [0.660056797745749, 0.660056797745749, 0.660056797745749], "final_y": [0.21891901516198964, 0.21891901516198964, 0.21891901516198964]}, "mutation_prompt": null}
{"id": "bc6d9795-97d7-4a14-86a9-e9757aadc8c5", "solution": "import numpy as np\n\nclass HybridPSO_SA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 10\n        self.w = 0.5  # Inertia weight\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.T_init = 1.0  # Initial temperature for SA\n        self.T_min = 1e-3  # Minimum temperature for SA\n        self.alpha = 0.9  # Cooling rate for SA\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        X = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        V = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        P_best = X.copy()\n        P_best_values = np.array([func(x) for x in P_best])\n        G_best = P_best[np.argmin(P_best_values)]\n        G_best_value = min(P_best_values)\n        \n        eval_count = self.num_particles\n        T = self.T_init\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization (PSO) step\n            r1, r2 = np.random.rand(self.num_particles, self.dim), np.random.rand(self.num_particles, self.dim)\n            V = self.w * V + self.c1 * r1 * (P_best - X) + self.c2 * r2 * (G_best - X)\n            X = np.clip(X + V, lb, ub)\n\n            # Evaluate new positions\n            current_values = np.array([func(x) for x in X])\n            eval_count += self.num_particles\n\n            # Update personal and global bests\n            for i in range(self.num_particles):\n                if current_values[i] < P_best_values[i]:\n                    P_best[i] = X[i]\n                    P_best_values[i] = current_values[i]\n                    if P_best_values[i] < G_best_value:\n                        G_best = P_best[i]\n                        G_best_value = P_best_values[i]\n\n            # Simulated Annealing (SA) step\n            for i in range(self.num_particles):\n                new_pos = X[i] + np.random.normal(0, 1, self.dim) * (ub - lb) / 10\n                new_pos = np.clip(new_pos, lb, ub)\n                new_value = func(new_pos)\n                eval_count += 1\n                if new_value < current_values[i] or np.random.rand() < np.exp((current_values[i] - new_value) / T):\n                    X[i] = new_pos\n                    current_values[i] = new_value\n                    if new_value < P_best_values[i]:\n                        P_best[i] = new_pos\n                        P_best_values[i] = new_value\n                        if new_value < G_best_value:\n                            G_best = new_pos\n                            G_best_value = new_value\n\n            # Cooling schedule for SA\n            T = max(self.T_min, T * self.alpha)\n\n        return G_best", "name": "HybridPSO_SA", "description": "A hybrid metaheuristic algorithm combining particle swarm optimization (PSO) and simulated annealing (SA) for dynamic exploration and exploitation in high-dimensional spaces.", "configspace": "", "generation": 0, "fitness": 0.8818696688040536, "feedback": "The algorithm HybridPSO_SA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.882 with standard deviation 0.010. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": null, "metadata": {"aucs": [0.869268182557325, 0.8840015829849048, 0.8923392408699309], "final_y": [0.11549323219502639, 0.11416673593111526, 0.11621739898412964]}, "mutation_prompt": null}
