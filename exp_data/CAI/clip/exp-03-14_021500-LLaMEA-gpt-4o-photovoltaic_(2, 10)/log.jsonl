{"id": "c1b4d63b-f6a9-4cfc-9205-5cbfd70db9d9", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.scale_factor = 0.5\n        self.crossover_rate = 0.9\n        self.population = None\n        self.bounds = None\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def mutate(self, idx, lb, ub):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.scale_factor * (b - c), lb, ub)\n        return mutant\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        target_fitness = func(target)\n        trial_fitness = func(trial)\n        return trial if trial_fitness < target_fitness else target, min(target_fitness, trial_fitness)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        best_solution = None\n        best_fitness = float('inf')\n\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, lb, ub)\n                trial = self.crossover(target, mutant)\n                selected, fitness = self.select(target, trial, func)\n                self.population[i] = selected\n\n                if fitness < best_fitness:\n                    best_solution, best_fitness = selected, fitness\n\n                evaluations += 1\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Adaptive Differential Evolution with Dynamic Parameter Adjustments for Efficient Black-Box Optimization.", "configspace": "", "generation": 0, "fitness": 0.7952430326673503, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.795 with standard deviation 0.017. And the mean value of best solutions found was 0.154 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": null, "metadata": {"aucs": [0.8042667760164925, 0.8094517756029176, 0.7720105463826409], "final_y": [0.15658611197316297, 0.1492823872578558, 0.1571203516958286]}, "mutation_prompt": null}
{"id": "52acbc76-2d68-42cc-a546-ce8344afd100", "solution": "import numpy as np\n\nclass PSO_DE_Hybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particle_count = 10\n        self.particles = np.random.rand(self.particle_count, self.dim)\n        self.velocities = np.random.rand(self.particle_count, self.dim)\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.particle_count, np.inf)\n        self.global_best = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n\n        # Initialize particles\n        for i in range(self.particle_count):\n            self.particles[i] = lb + (ub - lb) * self.particles[i]\n\n        while eval_count < self.budget:\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current particle\n                score = func(self.particles[i])\n                eval_count += 1\n\n                # Update personal and global bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions (PSO)\n            inertia_weight = 0.5\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = 2.0 * r1 * (self.personal_best[i] - self.particles[i])\n                social = 2.0 * r2 * (self.global_best - self.particles[i])\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive + social\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            # Differential Evolution (Mutation and Crossover)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.particle_count) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + 0.8 * (b - c), lb, ub)\n                crossover_rate = 0.9\n                trial = np.where(np.random.rand(self.dim) < crossover_rate, mutant, self.particles[i])\n                \n                score = func(trial)\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = trial\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best = trial\n\n        return self.global_best, self.global_best_score", "name": "PSO_DE_Hybrid", "description": "The algorithm is a hybrid Particle Swarm Optimization (PSO) and Differential Evolution (DE) approach that adapts over iterations to balance exploration and exploitation effectively.", "configspace": "", "generation": 0, "fitness": 0.86752094915205, "feedback": "The algorithm PSO_DE_Hybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.868 with standard deviation 0.022. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": null, "metadata": {"aucs": [0.8391880326436946, 0.8711432256930914, 0.8922315891193641], "final_y": [0.13383335086836123, 0.12073449410679404, 0.11634608839208604]}, "mutation_prompt": null}
{"id": "464216a3-ed6f-483f-828e-adf778ec352b", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.scale_factor = 0.5\n        self.crossover_rate = 0.9\n        self.population = None\n        self.bounds = None\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def mutate(self, idx, lb, ub):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        self.scale_factor = np.random.uniform(0.4, 0.9)  # Change 1: dynamic scale factor\n        mutant = np.clip(a + self.scale_factor * (b - c), lb, ub)\n        return mutant\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        target_fitness = func(target)\n        trial_fitness = func(trial)\n        return trial if trial_fitness < target_fitness else target, min(target_fitness, trial_fitness)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        best_solution = None\n        best_fitness = float('inf')\n\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, lb, ub)\n                trial = self.crossover(target, mutant)\n                selected, fitness = self.select(target, trial, func)\n                self.population[i] = selected\n\n                if fitness < best_fitness:\n                    best_solution, best_fitness = selected, fitness\n\n                evaluations += 1\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Adaptive Differential Evolution with Dynamic Scale Factor Adjustment for Improved Exploration-Exploitation Balance.", "configspace": "", "generation": 1, "fitness": 0.788790814832903, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.789 with standard deviation 0.015. And the mean value of best solutions found was 0.157 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "c1b4d63b-f6a9-4cfc-9205-5cbfd70db9d9", "metadata": {"aucs": [0.8044773052214749, 0.793493532134913, 0.7684016071423211], "final_y": [0.1504895785377356, 0.1601017669387199, 0.15919789782071814]}, "mutation_prompt": null}
{"id": "099c09f5-1f42-40d4-85e5-db50cfe235be", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.scale_factor = 0.5\n        self.crossover_rate = 0.9\n        self.population = None\n        self.bounds = None\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def mutate(self, idx, lb, ub):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.scale_factor * (b - c), lb, ub)\n        return mutant\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        target_fitness = func(target)\n        trial_fitness = func(trial)\n        return trial if trial_fitness < target_fitness else target, min(target_fitness, trial_fitness)\n\n    def adapt_parameters(self, iteration):\n        self.scale_factor = 0.5 + 0.3 * np.cos(2 * np.pi * iteration / self.budget)\n        self.crossover_rate = 0.9 - 0.4 * iteration / self.budget\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        best_solution = None\n        best_fitness = float('inf')\n\n        evaluations = 0\n        iteration = 0\n        while evaluations < self.budget:\n            self.adapt_parameters(iteration)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, lb, ub)\n                trial = self.crossover(target, mutant)\n                selected, fitness = self.select(target, trial, func)\n                self.population[i] = selected\n\n                if fitness < best_fitness:\n                    best_solution, best_fitness = selected, fitness\n\n                evaluations += 1\n            iteration += 1\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Enhanced Adaptive Differential Evolution with Dynamic Parameter Adaptation and Diversity Preservation for Efficient Black-Box Optimization.", "configspace": "", "generation": 1, "fitness": 0.779839640209131, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.780 with standard deviation 0.015. And the mean value of best solutions found was 0.160 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "c1b4d63b-f6a9-4cfc-9205-5cbfd70db9d9", "metadata": {"aucs": [0.7609124128519377, 0.7985175732958014, 0.7800889344796536], "final_y": [0.16171132286236023, 0.15337620207796387, 0.16384669565921717]}, "mutation_prompt": null}
{"id": "f9400def-b594-4292-a52b-6b49243dbcc4", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.scale_factor = 0.5\n        self.crossover_rate = 0.9\n        self.population = None\n        self.bounds = None\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def mutate(self, idx, lb, ub):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        # Dynamic scaling factor adjustment\n        F = np.random.uniform(0.4, 0.9) \n        mutant = np.clip(a + F * (b - c), lb, ub)\n        return mutant\n\n    def crossover(self, target, mutant):\n        # Self-adaptive crossover rate\n        CR = np.random.rand() if np.random.rand() < 0.1 else self.crossover_rate\n        cross_points = np.random.rand(self.dim) < CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        target_fitness = func(target)\n        trial_fitness = func(trial)\n        return trial if trial_fitness < target_fitness else target, min(target_fitness, trial_fitness)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        best_solution = None\n        best_fitness = float('inf')\n\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, lb, ub)\n                trial = self.crossover(target, mutant)\n                selected, fitness = self.select(target, trial, func)\n                self.population[i] = selected\n\n                if fitness < best_fitness:\n                    best_solution, best_fitness = selected, fitness\n\n                evaluations += 1\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Enhanced adaptive differential evolution using dynamic scaling and self-adaptive crossover rates for improved optimization performance.", "configspace": "", "generation": 1, "fitness": 0.8079609641516271, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.808 with standard deviation 0.003. And the mean value of best solutions found was 0.149 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "c1b4d63b-f6a9-4cfc-9205-5cbfd70db9d9", "metadata": {"aucs": [0.810793677489805, 0.8031400834324324, 0.8099491315326437], "final_y": [0.13620355566766051, 0.15630709185348168, 0.15400130216530816]}, "mutation_prompt": null}
{"id": "a3289f41-3680-4f50-898f-6985d29990eb", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.scale_factor = 0.5\n        self.crossover_rate = 0.95  # Changed to enhance crossover effectiveness\n        self.population = None\n        self.bounds = None\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def mutate(self, idx, lb, ub):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.scale_factor * (b - c), lb, ub)\n        return mutant\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        target_fitness = func(target)\n        trial_fitness = func(trial)\n        return trial if trial_fitness < target_fitness else target, min(target_fitness, trial_fitness)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        best_solution = None\n        best_fitness = float('inf')\n\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, lb, ub)\n                trial = self.crossover(target, mutant)\n                selected, fitness = self.select(target, trial, func)\n                self.population[i] = selected\n\n                if fitness < best_fitness:\n                    best_solution, best_fitness = selected, fitness\n\n                evaluations += 1\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Adaptive Differential Evolution with Enhanced Crossover Strategy for Efficient Black-Box Optimization.", "configspace": "", "generation": 1, "fitness": 0.7948817375394427, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.795 with standard deviation 0.001. And the mean value of best solutions found was 0.151 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "c1b4d63b-f6a9-4cfc-9205-5cbfd70db9d9", "metadata": {"aucs": [0.79603275282777, 0.7936652562275105, 0.794947203563048], "final_y": [0.1358972330810415, 0.16000002157593862, 0.15762083481813038]}, "mutation_prompt": null}
{"id": "75319515-1855-46e4-b710-6478de0db8e2", "solution": "import numpy as np\n\nclass PSO_DE_Hybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particle_count = 10\n        self.particles = np.random.rand(self.particle_count, self.dim)\n        self.velocities = np.random.rand(self.particle_count, self.dim)\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.particle_count, np.inf)\n        self.global_best = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n\n        # Initialize particles\n        for i in range(self.particle_count):\n            self.particles[i] = lb + (ub - lb) * self.particles[i]\n\n        while eval_count < self.budget:\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current particle\n                score = func(self.particles[i])\n                eval_count += 1\n\n                # Update personal and global bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions (PSO)\n            inertia_weight = 0.9 - 0.5 * (eval_count / self.budget)  # Adaptive inertia weight\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = 2.0 * r1 * (self.personal_best[i] - self.particles[i])\n                social = 2.0 * r2 * (self.global_best - self.particles[i])\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive + social\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            # Differential Evolution (Mutation and Crossover)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.particle_count) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + 0.8 * (b - c), lb, ub)\n                crossover_rate = 0.9\n                trial = np.where(np.random.rand(self.dim) < crossover_rate, mutant, self.particles[i])\n                \n                score = func(trial)\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = trial\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best = trial\n\n        return self.global_best, self.global_best_score", "name": "PSO_DE_Hybrid", "description": "Improved hybrid PSO-DE algorithm with adaptive inertia weight for enhanced exploration-exploitation balance.", "configspace": "", "generation": 1, "fitness": 0.8343397391176719, "feedback": "The algorithm PSO_DE_Hybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.834 with standard deviation 0.026. And the mean value of best solutions found was 0.134 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "52acbc76-2d68-42cc-a546-ce8344afd100", "metadata": {"aucs": [0.7981151203464272, 0.8480689923731416, 0.8568351046334468], "final_y": [0.15001628576775172, 0.13148563532505508, 0.12179459631308076]}, "mutation_prompt": null}
{"id": "b2b2fddb-278b-44c4-ae0b-80dbacf31858", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.scale_factor = 0.5\n        self.crossover_rate = 0.9\n        self.population = None\n        self.bounds = None\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def mutate(self, idx, lb, ub):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        self.scale_factor = 0.5 + (0.5 * np.random.rand())  # Dynamic adjustment of scale factor\n        mutant = np.clip(a + self.scale_factor * (b - c), lb, ub)\n        return mutant\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        target_fitness = func(target)\n        trial_fitness = func(trial)\n        return trial if trial_fitness < target_fitness else target, min(target_fitness, trial_fitness)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        best_solution = None\n        best_fitness = float('inf')\n\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, lb, ub)\n                trial = self.crossover(target, mutant)\n                selected, fitness = self.select(target, trial, func)\n                self.population[i] = selected\n\n                if fitness < best_fitness:\n                    best_solution, best_fitness = selected, fitness\n\n                evaluations += 1\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Introduced a dynamic adjustment to the scale factor to enhance exploration and exploitation balance in the Adaptive Differential Evolution algorithm.", "configspace": "", "generation": 1, "fitness": 0.7765053868631381, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.777 with standard deviation 0.013. And the mean value of best solutions found was 0.161 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "c1b4d63b-f6a9-4cfc-9205-5cbfd70db9d9", "metadata": {"aucs": [0.7737673179029603, 0.793493532134913, 0.7622553105515408], "final_y": [0.15227677647138993, 0.1601017669387199, 0.17049031428678552]}, "mutation_prompt": null}
{"id": "d82f2da1-7f51-422c-8bd8-9f9b9c081404", "solution": "import numpy as np\n\nclass PSO_DE_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particle_count = 12  # Increased particle count for better exploration\n        self.particles = np.random.rand(self.particle_count, self.dim)\n        self.velocities = np.random.rand(self.particle_count, self.dim)\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.particle_count, np.inf)\n        self.global_best = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n\n        # Initialize particles\n        for i in range(self.particle_count):\n            self.particles[i] = lb + (ub - lb) * self.particles[i]\n        \n        inertia_weight = 0.9  # Start with a higher inertia weight\n\n        while eval_count < self.budget:\n            # Decrease inertia weight over time\n            inertia_weight *= 0.99\n\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current particle\n                score = func(self.particles[i])\n                eval_count += 1\n\n                # Update personal and global bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions (PSO)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = 2.0 * r1 * (self.personal_best[i] - self.particles[i])\n                social = 2.0 * r2 * (self.global_best - self.particles[i])\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive + social\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            # Differential Evolution (Mutation and Crossover)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.particle_count) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + 0.8 * (b - c), lb, ub)\n                crossover_rate = 0.8  # Slightly reduced to increase diversity\n                trial = np.where(np.random.rand(self.dim) < crossover_rate, mutant, self.particles[i])\n                \n                score = func(trial)\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = trial\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best = trial\n\n        return self.global_best, self.global_best_score", "name": "PSO_DE_Enhanced", "description": "Enhanced Hybrid PSO and DE with Adaptive Inertia and Randomized Global Perturbations for Improved Exploration and Exploitation Balance.", "configspace": "", "generation": 1, "fitness": 0.8390607351925151, "feedback": "The algorithm PSO_DE_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.839 with standard deviation 0.022. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "52acbc76-2d68-42cc-a546-ce8344afd100", "metadata": {"aucs": [0.8158971018440766, 0.8335293977319304, 0.8677557060015384], "final_y": [0.13557012407509372, 0.13121929079957706, 0.12683910356652583]}, "mutation_prompt": null}
{"id": "f0e97db0-de36-48f7-b4cd-fde62f463fbf", "solution": "import numpy as np\n\nclass PSO_DE_Hybrid_Improved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particle_count = 10\n        self.particles = np.random.rand(self.particle_count, self.dim)\n        self.velocities = np.random.rand(self.particle_count, self.dim)\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.particle_count, np.inf)\n        self.global_best = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n        \n        # Adaptive parameters\n        inertia_weight = 0.9\n        cognitive_coeff = 2.0\n        social_coeff = 2.0\n        F = 0.5\n        CR = 0.9\n\n        # Initialize particles\n        for i in range(self.particle_count):\n            self.particles[i] = lb + (ub - lb) * self.particles[i]\n\n        while eval_count < self.budget:\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.particles[i])\n                eval_count += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions (PSO)\n            inertia_weight = 0.5 + 0.4 * (1 - eval_count / self.budget)  # Adaptive inertia weight\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = cognitive_coeff * r1 * (self.personal_best[i] - self.particles[i])\n                social = social_coeff * r2 * (self.global_best - self.particles[i])\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive + social\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            # Differential Evolution (Mutation and Crossover)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.particle_count) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F * (b - c), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, self.particles[i])\n                \n                score = func(trial)\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = trial\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best = trial\n\n        return self.global_best, self.global_best_score", "name": "PSO_DE_Hybrid_Improved", "description": "Introduce adaptive learning rates and dynamic parameter tuning to enhance the exploration-exploitation balance in the PSO-DE hybrid algorithm.", "configspace": "", "generation": 1, "fitness": 0.8478993302061175, "feedback": "The algorithm PSO_DE_Hybrid_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.848 with standard deviation 0.032. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "52acbc76-2d68-42cc-a546-ce8344afd100", "metadata": {"aucs": [0.8028397018563187, 0.8644656391883805, 0.8763926495736535], "final_y": [0.139063852741931, 0.12744984795741887, 0.12788116845962627]}, "mutation_prompt": null}
{"id": "df676bc4-ac7e-4844-a7f3-a8d496621ee0", "solution": "import numpy as np\n\nclass PSO_DE_Hybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particle_count = 10\n        self.particles = np.random.rand(self.particle_count, self.dim)\n        self.velocities = np.random.rand(self.particle_count, self.dim)\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.particle_count, np.inf)\n        self.global_best = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n\n        # Initialize particles\n        for i in range(self.particle_count):\n            self.particles[i] = lb + (ub - lb) * self.particles[i]\n\n        while eval_count < self.budget:\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current particle\n                score = func(self.particles[i])\n                eval_count += 1\n\n                # Update personal and global bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions (PSO)\n            inertia_weight = 0.9 - (0.5 * eval_count / self.budget)  # Dynamic inertia\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = 2.0 * r1 * (self.personal_best[i] - self.particles[i])\n                social = 2.0 * r2 * (self.global_best - self.particles[i])\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive + social\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            # Differential Evolution (Mutation and Crossover)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.particle_count) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + 0.8 * (b - c), lb, ub)\n                crossover_rate = 0.9\n                trial = np.where(np.random.rand(self.dim) < crossover_rate, mutant, self.particles[i])\n                \n                score = func(trial)\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = trial\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best = trial\n\n        return self.global_best, self.global_best_score", "name": "PSO_DE_Hybrid", "description": "Enhanced PSO_DE_Hybrid using dynamic inertia weight adjustment to improve convergence speed and solution quality.", "configspace": "", "generation": 1, "fitness": 0.8636319404047145, "feedback": "The algorithm PSO_DE_Hybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.864 with standard deviation 0.022. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "52acbc76-2d68-42cc-a546-ce8344afd100", "metadata": {"aucs": [0.8324427463240307, 0.8798717433611217, 0.8785813315289912], "final_y": [0.13503218947372853, 0.12123813317103727, 0.11627163433700793]}, "mutation_prompt": null}
{"id": "faf45152-d5de-4322-bf4e-a757f4f999af", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.scale_factor = 0.5\n        self.crossover_rate = 0.9\n        self.population = None\n        self.bounds = None\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def mutate(self, idx, lb, ub):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.scale_factor * (b - c), lb, ub)\n        return mutant\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def select(self, target, trial, func):\n        target_fitness = func(target)\n        trial_fitness = func(trial)\n        return trial if trial_fitness < target_fitness else target, min(target_fitness, trial_fitness)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population(lb, ub)\n        best_solution = None\n        best_fitness = float('inf')\n\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                target = self.population[i]\n                mutant = self.mutate(i, lb, ub)\n                \n                # Modify crossover rate dynamically based on evaluations\n                self.crossover_rate = 0.9 - (0.5 * (evaluations / self.budget))\n                \n                trial = self.crossover(target, mutant)\n                selected, fitness = self.select(target, trial, func)\n                self.population[i] = selected\n\n                if fitness < best_fitness:\n                    best_solution, best_fitness = selected, fitness\n\n                evaluations += 1\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Enhanced Adaptive Differential Evolution with Adaptive Crossover Rate for Improved Exploration and Exploitation Balance.", "configspace": "", "generation": 1, "fitness": 0.7875271430332486, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.788 with standard deviation 0.011. And the mean value of best solutions found was 0.157 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "c1b4d63b-f6a9-4cfc-9205-5cbfd70db9d9", "metadata": {"aucs": [0.7716396264080441, 0.793493532134913, 0.7974482705567886], "final_y": [0.16155772744620278, 0.1601017669387199, 0.15040114616651235]}, "mutation_prompt": null}
{"id": "b92f754b-f168-4414-afc4-78d5923a9336", "solution": "import numpy as np\n\nclass PSO_DE_Hybrid_Improved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particle_count = int(max(10, 0.1 * self.budget))  # Dynamic particle count\n        self.particles = np.random.rand(self.particle_count, self.dim)\n        self.velocities = np.random.rand(self.particle_count, self.dim)\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.particle_count, np.inf)\n        self.global_best = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n        \n        # Adaptive parameters\n        inertia_weight = 0.9\n        cognitive_coeff = 2.0\n        social_coeff = 2.0\n        F = 0.5\n        CR = 0.9\n\n        # Initialize particles\n        for i in range(self.particle_count):\n            self.particles[i] = lb + (ub - lb) * self.particles[i]\n\n        while eval_count < self.budget:\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.particles[i])\n                eval_count += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions (PSO)\n            inertia_weight = 0.5 + 0.4 * (1 - eval_count / self.budget)  # Adaptive inertia weight\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = cognitive_coeff * r1 * (self.personal_best[i] - self.particles[i])\n                social = social_coeff * r2 * (self.global_best - self.particles[i])\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive + social\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            # Differential Evolution (Mutation and Crossover)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.particle_count) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F * (b - c) * np.random.rand(), lb, ub)  # Enhanced mutation strategy\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, self.particles[i])\n                \n                score = func(trial)\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = trial\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best = trial\n\n        return self.global_best, self.global_best_score", "name": "PSO_DE_Hybrid_Improved", "description": "Introduce a dynamic particle count adjustment strategy and enhanced mutation strategy to improve convergence and solution quality.", "configspace": "", "generation": 2, "fitness": 0.8381432238461063, "feedback": "The algorithm PSO_DE_Hybrid_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.838 with standard deviation 0.036. And the mean value of best solutions found was 0.130 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "f0e97db0-de36-48f7-b4cd-fde62f463fbf", "metadata": {"aucs": [0.7908851426363368, 0.8459697435462091, 0.877574785355773], "final_y": [0.1416694585014513, 0.1327903895866992, 0.1154550926588036]}, "mutation_prompt": null}
{"id": "4aef2bfc-0a5b-42fd-9da3-6c9946025195", "solution": "import numpy as np\n\nclass PSO_DE_Hybrid_Improved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particle_count = 10\n        self.particles = np.random.rand(self.particle_count, self.dim)\n        self.velocities = np.random.rand(self.particle_count, self.dim)\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.particle_count, np.inf)\n        self.global_best = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n        \n        # Adaptive parameters\n        inertia_weight = 0.9\n        cognitive_coeff = 2.0\n        social_coeff = 2.0\n        F_base = 0.5\n        CR = 0.9\n\n        # Initialize particles\n        for i in range(self.particle_count):\n            self.particles[i] = lb + (ub - lb) * self.particles[i]\n\n        while eval_count < self.budget:\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.particles[i])\n                eval_count += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions (PSO)\n            inertia_weight = 0.5 + 0.4 * (1 - eval_count / self.budget)  # Adaptive inertia weight\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = cognitive_coeff * r1 * (self.personal_best[i] - self.particles[i])\n                social = social_coeff * r2 * (self.global_best - self.particles[i])\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive + social\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            # Differential Evolution (Mutation and Crossover)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.particle_count) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                F = F_base + 0.2 * (1 - self.personal_best_scores[i] / self.global_best_score) # Enhanced mutation\n                mutant = np.clip(a + F * (b - c), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, self.particles[i])\n                \n                score = func(trial)\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = trial\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best = trial\n\n            # Dynamic swarm resizing\n            if eval_count % 50 == 0 and self.particle_count < 20: \n                self.particle_count += 1\n                new_particle = lb + (ub - lb) * np.random.rand(self.dim)\n                self.particles = np.vstack((self.particles, new_particle))\n                self.velocities = np.vstack((self.velocities, np.random.rand(self.dim)))\n                self.personal_best = np.vstack((self.personal_best, new_particle))\n                self.personal_best_scores = np.append(self.personal_best_scores, np.inf)\n\n        return self.global_best, self.global_best_score", "name": "PSO_DE_Hybrid_Improved", "description": "Implement a dynamic swarm resizing strategy and enhanced DE mutation based on individual performance to improve exploration and convergence.", "configspace": "", "generation": 2, "fitness": 0.8605591088406263, "feedback": "The algorithm PSO_DE_Hybrid_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.861 with standard deviation 0.016. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "f0e97db0-de36-48f7-b4cd-fde62f463fbf", "metadata": {"aucs": [0.8455682620880393, 0.8525810110553881, 0.8835280533784517], "final_y": [0.1309791925534145, 0.13528804896535784, 0.11810288641186917]}, "mutation_prompt": null}
{"id": "f1a7c37f-19e7-4f0c-bf61-4f2e82724dff", "solution": "import numpy as np\n\nclass PSO_DE_Hybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particle_count = 10\n        self.particles = np.random.rand(self.particle_count, self.dim)\n        self.velocities = np.random.rand(self.particle_count, self.dim)\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.particle_count, np.inf)\n        self.global_best = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n\n        # Initialize particles\n        for i in range(self.particle_count):\n            self.particles[i] = lb + (ub - lb) * self.particles[i]\n\n        while eval_count < self.budget:\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current particle\n                score = func(self.particles[i])\n                eval_count += 1\n\n                # Update personal and global bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions (PSO)\n            inertia_weight = 0.9 - (0.5 * eval_count / self.budget)  # Dynamic inertia\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = 2.0 * r1 * (self.personal_best[i] - self.particles[i])\n                social = 2.0 * r2 * (self.global_best - self.particles[i])\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive + social\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            # Differential Evolution (Mutation and Crossover)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.particle_count) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + 0.8 * (b - c), lb, ub)\n                crossover_rate = 0.5 + 0.4 * (1 - eval_count / self.budget)  # Adaptive crossover rate\n                trial = np.where(np.random.rand(self.dim) < crossover_rate, mutant, self.particles[i])\n                \n                score = func(trial)\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = trial\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best = trial\n\n        return self.global_best, self.global_best_score", "name": "PSO_DE_Hybrid", "description": "Introduce an adaptive crossover rate in the DE step to balance exploration and exploitation dynamically.", "configspace": "", "generation": 2, "fitness": 0.8614970568583346, "feedback": "The algorithm PSO_DE_Hybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.861 with standard deviation 0.017. And the mean value of best solutions found was 0.130 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "df676bc4-ac7e-4844-a7f3-a8d496621ee0", "metadata": {"aucs": [0.8377512235119016, 0.8751746705414876, 0.8715652765216148], "final_y": [0.13987029495662984, 0.12164348765310085, 0.12781632206338545]}, "mutation_prompt": null}
{"id": "c480fe28-d698-4cc9-8895-f68bd336aec8", "solution": "import numpy as np\n\nclass PSO_DE_Hybrid_Improved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particle_count = 10\n        self.particles = np.random.rand(self.particle_count, self.dim)\n        self.velocities = np.random.rand(self.particle_count, self.dim)\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.particle_count, np.inf)\n        self.global_best = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n        \n        # Adaptive parameters\n        inertia_weight = 0.9\n        cognitive_coeff = 2.0\n        social_coeff = 2.0\n        F = 0.5\n        CR = 0.9\n\n        # Initialize particles\n        for i in range(self.particle_count):\n            self.particles[i] = lb + (ub - lb) * self.particles[i]\n\n        while eval_count < self.budget:\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.particles[i])\n                eval_count += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions (PSO)\n            inertia_weight = 0.5 + 0.4 * (1 - eval_count / self.budget)  # Adaptive inertia weight\n            cognitive_coeff = 0.5 + 1.5 * (eval_count / self.budget)  # Dynamic cognitive coefficient\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = cognitive_coeff * r1 * (self.personal_best[i] - self.particles[i])\n                social = social_coeff * r2 * (self.global_best - self.particles[i])\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive + social\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            # Differential Evolution (Mutation and Crossover)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.particle_count) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F * (b - c), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, self.particles[i])\n                \n                score = func(trial)\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = trial\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best = trial\n\n        return self.global_best, self.global_best_score", "name": "PSO_DE_Hybrid_Improved", "description": "Introduce a dynamic cognitive coefficient to enhance convergence by adapting exploration capabilities over iterations.", "configspace": "", "generation": 2, "fitness": 0.8466261025067846, "feedback": "The algorithm PSO_DE_Hybrid_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.847 with standard deviation 0.007. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "f0e97db0-de36-48f7-b4cd-fde62f463fbf", "metadata": {"aucs": [0.8560428135586948, 0.8451357696090813, 0.8386997243525779], "final_y": [0.13471052489469215, 0.12796123766330936, 0.11518594377762503]}, "mutation_prompt": null}
{"id": "950b3139-9b41-458b-bc1a-151b38e38101", "solution": "import numpy as np\n\nclass PSO_DE_Hybrid_Improved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particle_count = 10\n        self.particles = np.random.rand(self.particle_count, self.dim)\n        self.velocities = np.random.rand(self.particle_count, self.dim)\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.particle_count, np.inf)\n        self.global_best = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n        \n        # Adaptive parameters\n        inertia_weight = 0.9\n        cognitive_coeff_init = 2.5\n        social_coeff_init = 1.5\n        F = 0.5\n        CR = 0.9\n\n        for i in range(self.particle_count):\n            self.particles[i] = lb + (ub - lb) * self.particles[i]\n\n        while eval_count < self.budget:\n            cognitive_coeff = cognitive_coeff_init * (1 - eval_count / self.budget)\n            social_coeff = social_coeff_init * (eval_count / self.budget)\n\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.particles[i])\n                eval_count += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            inertia_weight = 0.5 + 0.4 * (1 - eval_count / self.budget)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = cognitive_coeff * r1 * (self.personal_best[i] - self.particles[i])\n                social = social_coeff * r2 * (self.global_best - self.particles[i])\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive + social\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.particle_count) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = F + 0.5 * (1 - eval_count / self.budget)  # Adaptive scaling factor\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, self.particles[i])\n                \n                score = func(trial)\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = trial\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best = trial\n\n        return self.global_best, self.global_best_score", "name": "PSO_DE_Hybrid_Improved", "description": "Introduce dynamic cognitive and social coefficients with adaptive mutation strategy to enhance exploration-exploitation in PSO-DE hybrid.", "configspace": "", "generation": 2, "fitness": 0.8363376334967016, "feedback": "The algorithm PSO_DE_Hybrid_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.836 with standard deviation 0.014. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "f0e97db0-de36-48f7-b4cd-fde62f463fbf", "metadata": {"aucs": [0.8332192773456666, 0.821341913871166, 0.8544517092732724], "final_y": [0.11731372729546008, 0.1381188365038647, 0.1288907061204525]}, "mutation_prompt": null}
{"id": "e3794ddf-3a26-423a-b3e6-79bf0153f5e3", "solution": "import numpy as np\n\nclass PSO_DE_Hybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particle_count = 10\n        self.particles = np.random.rand(self.particle_count, self.dim)\n        self.velocities = np.random.rand(self.particle_count, self.dim)\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.particle_count, np.inf)\n        self.global_best = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n\n        # Initialize particles\n        for i in range(self.particle_count):\n            self.particles[i] = lb + (ub - lb) * self.particles[i]\n\n        while eval_count < self.budget:\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current particle\n                score = func(self.particles[i])\n                eval_count += 1\n\n                # Update personal and global bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions (PSO)\n            inertia_weight = 0.9 - (0.5 * eval_count / self.budget)  # Dynamic inertia\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = 2.0 * r1 * (self.personal_best[i] - self.particles[i])\n                social = 2.0 * r2 * (self.global_best - self.particles[i])\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive + social\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            # Differential Evolution (Mutation and Crossover)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.particle_count) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                F = 0.6 + 0.4 * (eval_count / self.budget)  # Adaptive mutation factor\n                mutant = np.clip(a + F * (b - c), lb, ub)\n                crossover_rate = 0.9\n                trial = np.where(np.random.rand(self.dim) < crossover_rate, mutant, self.particles[i])\n                \n                score = func(trial)\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = trial\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best = trial\n\n        return self.global_best, self.global_best_score", "name": "PSO_DE_Hybrid", "description": "Integrate adaptive mutation factor in DE to enhance exploration-exploitation balance and solution quality.", "configspace": "", "generation": 2, "fitness": 0.8500736033734403, "feedback": "The algorithm PSO_DE_Hybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.850 with standard deviation 0.021. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "df676bc4-ac7e-4844-a7f3-a8d496621ee0", "metadata": {"aucs": [0.8655639207577192, 0.8639097850623785, 0.8207471043002235], "final_y": [0.12701767354288274, 0.1279067748896916, 0.13878561701194403]}, "mutation_prompt": null}
{"id": "4708c91b-d07b-4114-b571-767d8bdc1bcc", "solution": "import numpy as np\n\nclass PSO_DE_Hybrid_Improved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particle_count = 10\n        self.particles = np.random.rand(self.particle_count, self.dim)\n        self.velocities = np.random.rand(self.particle_count, self.dim)\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.particle_count, np.inf)\n        self.global_best = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n        \n        # Adaptive parameters\n        inertia_weight = 0.9\n        cognitive_coeff = 2.0\n        social_coeff = 2.0\n        F = 0.5\n        CR = 0.9\n\n        # Initialize particles\n        for i in range(self.particle_count):\n            self.particles[i] = lb + (ub - lb) * self.particles[i]\n\n        while eval_count < self.budget:\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.particles[i])\n                eval_count += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions (PSO)\n            inertia_weight = 0.5 + 0.4 * (1 - eval_count / self.budget)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = cognitive_coeff * r1 * (self.personal_best[i] - self.particles[i])\n                social = social_coeff * r2 * (self.global_best - self.particles[i])\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive + social\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n                \n            # Enhanced Differential Evolution with Local Search\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.particle_count) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = 0.4 + 0.1 * (1 - eval_count / self.budget)\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, self.particles[i])\n                \n                score = func(trial)\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = trial\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best = trial\n\n        return self.global_best, self.global_best_score", "name": "PSO_DE_Hybrid_Improved", "description": "Enhance PSO_DE_Hybrid_Improved by incorporating a local search mechanism and adaptive mutation strategies to boost exploration and exploitation balance.", "configspace": "", "generation": 2, "fitness": 0.8417524225415134, "feedback": "The algorithm PSO_DE_Hybrid_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.842 with standard deviation 0.016. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "f0e97db0-de36-48f7-b4cd-fde62f463fbf", "metadata": {"aucs": [0.8631003187931721, 0.8267186706025622, 0.835438278228806], "final_y": [0.1252061589005774, 0.13743668328030678, 0.13575428391045596]}, "mutation_prompt": null}
{"id": "189e5462-6688-45ac-bd4b-858a548c015e", "solution": "import numpy as np\n\nclass PSO_DE_Hybrid_Improved_V2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particle_count = 10\n        self.particles = np.random.rand(self.particle_count, self.dim)\n        self.velocities = np.random.rand(self.particle_count, self.dim)\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.particle_count, np.inf)\n        self.global_best = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n        \n        # Adaptive parameters\n        inertia_weight = 0.9\n        cognitive_coeff = 2.0\n        social_coeff = 2.0\n        F = 0.5\n        CR = 0.9\n\n        # Initialize particles\n        for i in range(self.particle_count):\n            self.particles[i] = lb + (ub - lb) * self.particles[i]\n\n        while eval_count < self.budget:\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.particles[i])\n                eval_count += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions (PSO)\n            inertia_weight = 0.5 + 0.4 * (1 - eval_count / self.budget)  # Adaptive inertia weight\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = cognitive_coeff * r1 * (self.personal_best[i] - self.particles[i])\n                social = social_coeff * r2 * (self.global_best - self.particles[i])\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive + social\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            # Differential Evolution (Adaptive Mutation and Crossover)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.particle_count) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                diversity = np.std(self.particles, axis=0)\n                adaptive_F = F + 0.1 * np.mean(diversity)  # Adaptive mutation factor\n                mutant = np.clip(a + adaptive_F * (b - c), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, self.particles[i])\n                \n                score = func(trial)\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = trial\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best = trial\n\n        return self.global_best, self.global_best_score", "name": "PSO_DE_Hybrid_Improved_V2", "description": "Introduce diversity preservation through adaptive mutation and crowding distance-based selection to enhance exploration in the PSO-DE hybrid algorithm.", "configspace": "", "generation": 2, "fitness": 0.8308492365917491, "feedback": "The algorithm PSO_DE_Hybrid_Improved_V2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.831 with standard deviation 0.008. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "f0e97db0-de36-48f7-b4cd-fde62f463fbf", "metadata": {"aucs": [0.8251094986900701, 0.8427124762628494, 0.824725734822328], "final_y": [0.13256728036812893, 0.12342819676907957, 0.1363884350396407]}, "mutation_prompt": null}
{"id": "16867217-22c3-42dd-a5b3-3b3c8b39624e", "solution": "import numpy as np\n\nclass PSO_DE_Hybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particle_count = 10\n        self.particles = np.random.rand(self.particle_count, self.dim)\n        self.velocities = np.random.rand(self.particle_count, self.dim)\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.particle_count, np.inf)\n        self.global_best = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n\n        # Initialize particles\n        for i in range(self.particle_count):\n            self.particles[i] = lb + (ub - lb) * self.particles[i]\n\n        while eval_count < self.budget:\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current particle\n                score = func(self.particles[i])\n                eval_count += 1\n\n                # Update personal and global bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions (PSO)\n            inertia_weight = 0.9 - (0.5 * eval_count / self.budget)  # Dynamic inertia\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = 2.0 * r1 * (self.personal_best[i] - self.particles[i])\n                social = 2.0 * r2 * (self.global_best - self.particles[i])\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive + social\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            # Differential Evolution (Mutation and Crossover)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.particle_count) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                # Dynamically adjust scaling factor in mutation\n                scaling_factor = 0.5 + (0.5 * eval_count / self.budget)\n                mutant = np.clip(a + scaling_factor * (b - c), lb, ub)\n                crossover_rate = 0.9\n                trial = np.where(np.random.rand(self.dim) < crossover_rate, mutant, self.particles[i])\n                \n                score = func(trial)\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = trial\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best = trial\n\n        return self.global_best, self.global_best_score", "name": "PSO_DE_Hybrid", "description": "Enhance mutation strategy by dynamically adjusting scaling factor in DE mutation based on evaluation progress.", "configspace": "", "generation": 2, "fitness": 0.8391016324668742, "feedback": "The algorithm PSO_DE_Hybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.839 with standard deviation 0.010. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "df676bc4-ac7e-4844-a7f3-a8d496621ee0", "metadata": {"aucs": [0.8251744092742499, 0.8470012279105773, 0.8451292602157953], "final_y": [0.13543864688090612, 0.12111443235530095, 0.12651626784798942]}, "mutation_prompt": null}
{"id": "7d9f461c-18f1-442c-8d27-44b6a230bb62", "solution": "import numpy as np\n\nclass PSO_DE_Hybrid_Improved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particle_count = 10\n        self.particles = np.random.rand(self.particle_count, self.dim)\n        self.velocities = np.random.rand(self.particle_count, self.dim)\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.particle_count, np.inf)\n        self.global_best = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n        \n        # Adaptive parameters\n        inertia_weight = 0.9\n        cognitive_coeff = 2.0\n        social_coeff = 2.0\n        F = 0.5\n        CR = 0.9\n\n        # Initialize particles\n        for i in range(self.particle_count):\n            self.particles[i] = lb + (ub - lb) * self.particles[i]\n\n        while eval_count < self.budget:\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.particles[i])\n                eval_count += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions (PSO)\n            inertia_weight = 0.5 + 0.4 * (1 - eval_count / self.budget)  # Adaptive inertia weight\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = cognitive_coeff * r1 * (self.personal_best[i] - self.particles[i])\n                social = social_coeff * r2 * (self.global_best - self.particles[i])\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive + social\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            # Differential Evolution (Mutation and Crossover)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                F = 0.5 + 0.3 * (1 - eval_count / self.budget)  # Adaptive F parameter\n                idxs = [idx for idx in range(self.particle_count) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + F * (b - c), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, self.particles[i])\n                \n                score = func(trial)\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = trial\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best = trial\n\n        return self.global_best, self.global_best_score", "name": "PSO_DE_Hybrid_Improved", "description": "Introduce a secondary adaptive parameter strategy for DE differential weight F to dynamically evolve based on the optimization progress.", "configspace": "", "generation": 2, "fitness": 0.8508855050501459, "feedback": "The algorithm PSO_DE_Hybrid_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.851 with standard deviation 0.021. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "f0e97db0-de36-48f7-b4cd-fde62f463fbf", "metadata": {"aucs": [0.8342869925228027, 0.8378652151625401, 0.8805043074650948], "final_y": [0.1284441932694238, 0.1302301039314655, 0.120468807099125]}, "mutation_prompt": null}
{"id": "1d338cae-806f-4867-896a-ce236309b1e0", "solution": "import numpy as np\n\nclass PSO_DE_Hybrid_Improved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particle_count = 10\n        self.particles = np.random.rand(self.particle_count, self.dim)\n        self.velocities = np.random.rand(self.particle_count, self.dim)\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.particle_count, np.inf)\n        self.global_best = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n        \n        # Adaptive parameters\n        inertia_weight = 0.9\n        cognitive_coeff = 2.0\n        social_coeff = 2.0\n        F_base = 0.5\n        CR = 0.9\n\n        # Initialize particles\n        for i in range(self.particle_count):\n            self.particles[i] = lb + (ub - lb) * self.particles[i]\n\n        adaptivity_factor = 1.0  # New adaptive factor for parameter tuning\n\n        while eval_count < self.budget:\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.particles[i])\n                eval_count += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions (PSO)\n            inertia_weight = 0.5 + 0.4 * (1 - eval_count / self.budget) * adaptivity_factor  # Adaptive inertia weight\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = cognitive_coeff * r1 * (self.personal_best[i] - self.particles[i])\n                social = social_coeff * r2 * (self.global_best - self.particles[i])\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive + social\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            # Differential Evolution (Mutation and Crossover)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.particle_count) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                F = F_base + 0.2 * (1 - self.personal_best_scores[i] / self.global_best_score) * adaptivity_factor  # Enhanced mutation\n                mutant = np.clip(a + F * (b - c), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, self.particles[i])\n                \n                score = func(trial)\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = trial\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best = trial\n\n            # Dynamic swarm resizing\n            if eval_count % 50 == 0 and self.particle_count < 20: \n                self.particle_count += 1\n                new_particle = lb + (ub - lb) * np.random.rand(self.dim)\n                self.particles = np.vstack((self.particles, new_particle))\n                self.velocities = np.vstack((self.velocities, np.random.rand(self.dim)))\n                self.personal_best = np.vstack((self.personal_best, new_particle))\n                self.personal_best_scores = np.append(self.personal_best_scores, np.inf)\n\n            # Adjust adaptivity factor\n            if eval_count % 50 == 0:\n                convergence_speed = np.std(self.personal_best_scores)\n                adaptivity_factor = 1.0 + np.tanh(convergence_speed - 0.5)\n\n        return self.global_best, self.global_best_score", "name": "PSO_DE_Hybrid_Improved", "description": "Introduce a self-adaptive learning mechanism that dynamically adjusts parameters and mutation strategies based on convergence speed to enhance exploration and exploitation balance.", "configspace": "", "generation": 3, "fitness": 0.8214510822875122, "feedback": "The algorithm PSO_DE_Hybrid_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.821 with standard deviation 0.050. And the mean value of best solutions found was 0.144 (0. is the best) with standard deviation 0.022.", "error": "", "parent_id": "4aef2bfc-0a5b-42fd-9da3-6c9946025195", "metadata": {"aucs": [0.7522961941825973, 0.8450911845702181, 0.8669658681097212], "final_y": [0.17541931269839883, 0.1316211172423185, 0.12555479324363283]}, "mutation_prompt": null}
{"id": "deb3f281-b39e-4273-b032-45bcd900708f", "solution": "import numpy as np\n\nclass PSO_DE_Hybrid_Improved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particle_count = 10\n        self.particles = np.random.rand(self.particle_count, self.dim)\n        self.velocities = np.random.rand(self.particle_count, self.dim)\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.particle_count, np.inf)\n        self.global_best = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n        \n        # Adaptive parameters\n        inertia_weight = 0.9\n        cognitive_coeff = 2.0\n        social_coeff = 2.0\n        F_base = 0.5\n        CR = 0.9\n\n        # Initialize particles\n        for i in range(self.particle_count):\n            self.particles[i] = lb + (ub - lb) * self.particles[i]\n\n        while eval_count < self.budget:\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.particles[i])\n                eval_count += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions (PSO)\n            inertia_weight = 0.5 + 0.4 * (1 - eval_count / self.budget)  # Adaptive inertia weight\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = cognitive_coeff * r1 * (self.personal_best[i] - self.particles[i])\n                social = social_coeff * r2 * (self.global_best - self.particles[i])\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive + social\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            # Differential Evolution (Mutation and Crossover)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.particle_count) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                F = F_base + 0.2 * (1 - self.personal_best_scores[i] / self.global_best_score) # Enhanced mutation\n                mutant = np.clip(a + F * (b - c), lb, ub)\n                CR_dynamic = CR * (1 - self.personal_best_scores[i] / self.global_best_score) # Dynamic CR\n                trial = np.where(np.random.rand(self.dim) < CR_dynamic, mutant, self.particles[i])\n                \n                score = func(trial)\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = trial\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best = trial\n\n            # Dynamic swarm resizing\n            if eval_count % 50 == 0 and self.particle_count < 20: \n                self.particle_count += 1\n                new_particle = lb + (ub - lb) * np.random.rand(self.dim)\n                self.particles = np.vstack((self.particles, new_particle))\n                self.velocities = np.vstack((self.velocities, np.random.rand(self.dim)))\n                self.personal_best = np.vstack((self.personal_best, new_particle))\n                self.personal_best_scores = np.append(self.personal_best_scores, np.inf)\n\n        return self.global_best, self.global_best_score", "name": "PSO_DE_Hybrid_Improved", "description": "Adjust the differential evolution's crossover rate (CR) dynamically based on the relative performance of particles to better balance exploration and exploitation.", "configspace": "", "generation": 3, "fitness": 0.8505444837914866, "feedback": "The algorithm PSO_DE_Hybrid_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.851 with standard deviation 0.009. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "4aef2bfc-0a5b-42fd-9da3-6c9946025195", "metadata": {"aucs": [0.8411918344615237, 0.8476950020897847, 0.8627466148231516], "final_y": [0.13562799864298303, 0.13064647727535816, 0.1322972079802962]}, "mutation_prompt": null}
{"id": "6439431a-c98e-4577-985f-5f11d0b28563", "solution": "import numpy as np\n\nclass PSO_DE_Hybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particle_count = 10\n        self.particles = np.random.rand(self.particle_count, self.dim)\n        self.velocities = np.random.rand(self.particle_count, self.dim)\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.particle_count, np.inf)\n        self.global_best = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n\n        # Initialize particles\n        for i in range(self.particle_count):\n            self.particles[i] = lb + (ub - lb) * self.particles[i]\n\n        while eval_count < self.budget:\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current particle\n                score = func(self.particles[i])\n                eval_count += 1\n\n                # Update personal and global bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions (PSO)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = 2.0 * r1 * (self.personal_best[i] - self.particles[i])\n                social = 2.0 * r2 * (self.global_best - self.particles[i])\n                inertia_weight = 0.9 - 0.5 * (self.personal_best_scores[i] / self.global_best_score)  # Dynamic based on performance\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive + social\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            # Differential Evolution (Mutation and Crossover)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.particle_count) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + 0.8 * (b - c), lb, ub)\n                crossover_rate = 0.5 + 0.4 * (1 - eval_count / self.budget)  # Adaptive crossover rate\n                trial = np.where(np.random.rand(self.dim) < crossover_rate, mutant, self.particles[i])\n                \n                score = func(trial)\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = trial\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best = trial\n\n        return self.global_best, self.global_best_score", "name": "PSO_DE_Hybrid", "description": "Introduce a dynamic inertia weight that adapts based on particle performance rather than a fixed reduction schedule.", "configspace": "", "generation": 3, "fitness": 0.8561355087570202, "feedback": "The algorithm PSO_DE_Hybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.856 with standard deviation 0.015. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "f1a7c37f-19e7-4f0c-bf61-4f2e82724dff", "metadata": {"aucs": [0.8522359029220844, 0.8405939129577558, 0.8755767103912201], "final_y": [0.1344818206181566, 0.13184066897622582, 0.12557617835088097]}, "mutation_prompt": null}
{"id": "1c33a1a4-ff05-4b03-8856-a0c6662d14d9", "solution": "import numpy as np\n\nclass PSO_DE_Hybrid_Improved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particle_count = 10\n        self.particles = np.random.rand(self.particle_count, self.dim)\n        self.velocities = np.random.rand(self.particle_count, self.dim)\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.particle_count, np.inf)\n        self.global_best = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n        \n        # Adaptive parameters\n        inertia_weight = 0.9\n        cognitive_coeff = 2.0\n        social_coeff = 2.0\n        F_base = 0.5\n        CR = 0.9\n\n        # Initialize particles\n        for i in range(self.particle_count):\n            self.particles[i] = lb + (ub - lb) * self.particles[i]\n\n        while eval_count < self.budget:\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.particles[i])\n                eval_count += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions (PSO)\n            inertia_weight = 0.5 + 0.4 * (1 - eval_count / self.budget)  # Adaptive inertia weight\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = cognitive_coeff * r1 * (self.personal_best[i] - self.particles[i])\n                social = social_coeff * r2 * (self.global_best - self.particles[i])\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive + social\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            # Differential Evolution (Mutation and Crossover)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.particle_count) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                F = F_base + 0.2 * (1 - self.personal_best_scores[i] / self.global_best_score) # Enhanced mutation\n                mutant = np.clip(a + F * (b - c), lb, ub)\n                CR = 0.9 - 0.5 * (eval_count / self.budget)  # Dynamic crossover rate\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, self.particles[i])\n                \n                score = func(trial)\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = trial\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best = trial\n\n            # Dynamic swarm resizing\n            if eval_count % 50 == 0 and self.particle_count < 20: \n                self.particle_count += 1\n                new_particle = lb + (ub - lb) * np.random.rand(self.dim)\n                self.particles = np.vstack((self.particles, new_particle))\n                self.velocities = np.vstack((self.velocities, np.random.rand(self.dim)))\n                self.personal_best = np.vstack((self.personal_best, new_particle))\n                self.personal_best_scores = np.append(self.personal_best_scores, np.inf)\n\n        return self.global_best, self.global_best_score", "name": "PSO_DE_Hybrid_Improved", "description": "Introduce a dynamic crossover rate (CR) based on iteration count to enhance exploration and convergence balance in DE step.", "configspace": "", "generation": 3, "fitness": 0.841480199706376, "feedback": "The algorithm PSO_DE_Hybrid_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.841 with standard deviation 0.017. And the mean value of best solutions found was 0.135 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "4aef2bfc-0a5b-42fd-9da3-6c9946025195", "metadata": {"aucs": [0.8174593074437109, 0.8534126006446872, 0.8535686910307296], "final_y": [0.14516418478345416, 0.12656897264733147, 0.1343770843805946]}, "mutation_prompt": null}
{"id": "beef09c8-b3f4-48c0-b67a-d54bdec90f7c", "solution": "import numpy as np\n\nclass PSO_DE_Hybrid_Improved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particle_count = 10\n        self.particles = np.random.rand(self.particle_count, self.dim)\n        self.velocities = np.random.rand(self.particle_count, self.dim)\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.particle_count, np.inf)\n        self.global_best = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n        \n        # Adaptive parameters\n        inertia_weight = 0.9\n        cognitive_coeff = 2.0\n        social_coeff = 2.0\n        F_base = 0.5\n        CR = 0.9\n\n        # Initialize particles\n        for i in range(self.particle_count):\n            self.particles[i] = lb + (ub - lb) * self.particles[i]\n\n        while eval_count < self.budget:\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.particles[i])\n                eval_count += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions (PSO)\n            inertia_weight = 0.5 + 0.4 * (1 - eval_count / self.budget)  # Adaptive inertia weight\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = cognitive_coeff * r1 * (self.personal_best[i] - self.particles[i])\n                social = social_coeff * r2 * (self.global_best - self.particles[i])\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive + social\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            # Differential Evolution (Mutation and Crossover)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.particle_count) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                F_adaptive = F_base + 0.1 * (self.global_best_score / (self.personal_best_scores[i] + 1e-9))  # Self-adaptive mutation\n                mutant = np.clip(a + F_adaptive * (b - c), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, self.particles[i])\n                \n                score = func(trial)\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = trial\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best = trial\n\n            # Dynamic swarm resizing\n            if eval_count % 50 == 0 and self.particle_count < 20: \n                self.particle_count += 1\n                new_particle = lb + (ub - lb) * np.random.rand(self.dim)\n                self.particles = np.vstack((self.particles, new_particle))\n                self.velocities = np.vstack((self.velocities, np.random.rand(self.dim)))\n                self.personal_best = np.vstack((self.personal_best, new_particle))\n                self.personal_best_scores = np.append(self.personal_best_scores, np.inf)\n\n        return self.global_best, self.global_best_score", "name": "PSO_DE_Hybrid_Improved", "description": "Introduce a self-adaptive learning rate for DE mutation and dynamic adjustment of particle influence based on improvement rate.", "configspace": "", "generation": 3, "fitness": 0.8406847088434476, "feedback": "The algorithm PSO_DE_Hybrid_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.841 with standard deviation 0.008. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "4aef2bfc-0a5b-42fd-9da3-6c9946025195", "metadata": {"aucs": [0.8294495009110532, 0.8477218824809444, 0.8448827431383453], "final_y": [0.13396143243571912, 0.12316559705173535, 0.12830499699986042]}, "mutation_prompt": null}
{"id": "b877a6cb-99a8-4b95-b869-948af9cc9413", "solution": "import numpy as np\n\nclass PSO_DE_Hybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particle_count = 10\n        self.particles = np.random.rand(self.particle_count, self.dim)\n        self.velocities = np.random.rand(self.particle_count, self.dim)\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.particle_count, np.inf)\n        self.global_best = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n\n        # Initialize particles\n        for i in range(self.particle_count):\n            self.particles[i] = lb + (ub - lb) * self.particles[i]\n\n        while eval_count < self.budget:\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current particle\n                score = func(self.particles[i])\n                eval_count += 1\n\n                # Update personal and global bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions (PSO)\n            inertia_weight = 0.9 - (0.5 * eval_count / self.budget)  # Dynamic inertia\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = 2.0 * r1 * (self.personal_best[i] - self.particles[i])\n                social = 2.0 * r2 * (self.global_best - self.particles[i])\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive + social\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            # Differential Evolution (Mutation and Crossover)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.particle_count) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                F = 0.8 + 0.2 * (eval_count / self.budget)  # Dynamic scaling factor\n                mutant = np.clip(a + F * (b - c), lb, ub)\n                crossover_rate = 0.5 + 0.4 * (1 - eval_count / self.budget)  # Adaptive crossover rate\n                trial = np.where(np.random.rand(self.dim) < crossover_rate, mutant, self.particles[i])\n                \n                score = func(trial)\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = trial\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best = trial\n\n        return self.global_best, self.global_best_score", "name": "PSO_DE_Hybrid", "description": "Introduce a dynamic scaling factor in the DE mutation to enhance exploration during early iterations and exploitation during later stages.", "configspace": "", "generation": 3, "fitness": 0.853538604516765, "feedback": "The algorithm PSO_DE_Hybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.854 with standard deviation 0.020. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "f1a7c37f-19e7-4f0c-bf61-4f2e82724dff", "metadata": {"aucs": [0.8258495391052215, 0.8644619003926834, 0.8703043740523897], "final_y": [0.13718284141515524, 0.1215380395104001, 0.12657079933913462]}, "mutation_prompt": null}
{"id": "a3855f0f-5b2f-4455-a602-776e783d6295", "solution": "import numpy as np\n\nclass PSO_DE_Hybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particle_count = 10\n        self.particles = np.random.rand(self.particle_count, self.dim)\n        self.velocities = np.random.rand(self.particle_count, self.dim)\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.particle_count, np.inf)\n        self.global_best = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n\n        # Initialize particles\n        for i in range(self.particle_count):\n            self.particles[i] = lb + (ub - lb) * self.particles[i]\n\n        while eval_count < self.budget:\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current particle\n                score = func(self.particles[i])\n                eval_count += 1\n\n                # Update personal and global bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions (PSO)\n            inertia_weight = 0.9 - (0.5 * eval_count / self.budget)  # Dynamic inertia\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = 2.0 * r1 * (self.personal_best[i] - self.particles[i])\n                social = 2.0 * r2 * (self.global_best - self.particles[i])\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive + social\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            # Differential Evolution (Mutation and Crossover)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.particle_count) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + 0.8 * (b - c), lb, ub)\n                crossover_rate = 0.5 + 0.4 * (1 - eval_count / self.budget)  # Adaptive crossover rate\n                trial = np.where(np.random.rand(self.dim) < crossover_rate, mutant, self.particles[i])\n                \n                score = func(trial)\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = trial\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best = trial\n        \n        if eval_count >= self.budget // 2: \n            self.particle_count = 15  # Increase particle count to enhance exploration\n\n        return self.global_best, self.global_best_score", "name": "PSO_DE_Hybrid", "description": "Introduce a dynamic particle count adjustment mechanism at half of the budget to enhance exploration and convergence.", "configspace": "", "generation": 3, "fitness": 0.8531367370378421, "feedback": "The algorithm PSO_DE_Hybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.853 with standard deviation 0.006. And the mean value of best solutions found was 0.129 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "f1a7c37f-19e7-4f0c-bf61-4f2e82724dff", "metadata": {"aucs": [0.8558699423938675, 0.8587662184943892, 0.8447740502252699], "final_y": [0.13422050034613275, 0.12075614579217608, 0.13306282312007978]}, "mutation_prompt": null}
{"id": "f404c512-8fca-47ce-9a57-abb9068dd61e", "solution": "import numpy as np\n\nclass PSO_DE_Hybrid_Improved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particle_count = 10\n        self.particles = np.random.rand(self.particle_count, self.dim)\n        self.velocities = np.random.rand(self.particle_count, self.dim)\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.particle_count, np.inf)\n        self.global_best = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n        \n        # Adaptive parameters\n        inertia_weight = 0.9\n        cognitive_coeff = 2.0\n        social_coeff = 2.0\n        F_base = 0.5\n        CR = 0.9\n\n        # Initialize particles\n        for i in range(self.particle_count):\n            self.particles[i] = lb + (ub - lb) * self.particles[i]\n\n        while eval_count < self.budget:\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.particles[i])\n                eval_count += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions (PSO)\n            inertia_weight = 0.6 + 0.3 * (1 - eval_count / self.budget)  # Slightly refined adaptive inertia weight\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = cognitive_coeff * r1 * (self.personal_best[i] - self.particles[i])\n                social = social_coeff * r2 * (self.global_best - self.particles[i])\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive + social\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            # Differential Evolution (Mutation and Crossover)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.particle_count) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                F = F_base + 0.3 * (1 - self.personal_best_scores[i] / self.global_best_score) # Slightly refined mutation\n                mutant = np.clip(a + F * (b - c), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, self.particles[i])\n                \n                score = func(trial)\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = trial\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best = trial\n\n            # Dynamic swarm resizing\n            if eval_count % 50 == 0 and self.particle_count < 20: \n                self.particle_count += 1\n                new_particle = lb + (ub - lb) * np.random.rand(self.dim)\n                self.particles = np.vstack((self.particles, new_particle))\n                self.velocities = np.vstack((self.velocities, np.random.rand(self.dim)))\n                self.personal_best = np.vstack((self.personal_best, new_particle))\n                self.personal_best_scores = np.append(self.personal_best_scores, np.inf)\n\n        return self.global_best, self.global_best_score", "name": "PSO_DE_Hybrid_Improved", "description": "Refine mutation factor scaling and introduce small-scale adaptive inertia weight adjustments to further balance the exploration and exploitation phases.", "configspace": "", "generation": 3, "fitness": 0.8495913224318303, "feedback": "The algorithm PSO_DE_Hybrid_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.850 with standard deviation 0.028. And the mean value of best solutions found was 0.134 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "4aef2bfc-0a5b-42fd-9da3-6c9946025195", "metadata": {"aucs": [0.888597502354088, 0.8366094501958645, 0.8235670147455385], "final_y": [0.12526560394218766, 0.13148578847770476, 0.14562574749448376]}, "mutation_prompt": null}
{"id": "9972bed5-7d58-4ac6-a631-3a3feff676a1", "solution": "import numpy as np\n\nclass PSO_DE_Hybrid_Improved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particle_count = 10\n        self.particles = np.random.rand(self.particle_count, self.dim)\n        self.velocities = np.random.rand(self.particle_count, self.dim)\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.particle_count, np.inf)\n        self.global_best = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n        \n        # Adaptive parameters\n        inertia_weight = 0.9\n        cognitive_coeff = 2.0\n        social_coeff = 2.0\n        F_base = 0.5\n        CR = 0.9\n\n        # Initialize particles\n        for i in range(self.particle_count):\n            self.particles[i] = lb + (ub - lb) * self.particles[i]\n\n        while eval_count < self.budget:\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.particles[i])\n                eval_count += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions (PSO)\n            inertia_weight = 0.5 + 0.4 * (1 - eval_count / self.budget)  # Adaptive inertia weight\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                # Self-adaptive strategy for cognitive and social coefficients\n                cognitive_coeff = 2.0 - 1.5 * (self.personal_best_scores[i] / self.global_best_score)\n                social_coeff = 1.5 + 1.5 * (self.personal_best_scores[i] / self.global_best_score)\n                cognitive = cognitive_coeff * r1 * (self.personal_best[i] - self.particles[i])\n                social = social_coeff * r2 * (self.global_best - self.particles[i])\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive + social\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            # Differential Evolution (Mutation and Crossover)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.particle_count) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                F = F_base + 0.2 * (1 - self.personal_best_scores[i] / self.global_best_score) # Enhanced mutation\n                mutant = np.clip(a + F * (b - c), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < CR, mutant, self.particles[i])\n                \n                score = func(trial)\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = trial\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best = trial\n\n            # Dynamic swarm resizing\n            if eval_count % 50 == 0 and self.particle_count < 20: \n                self.particle_count += 1\n                new_particle = lb + (ub - lb) * np.random.rand(self.dim)\n                self.particles = np.vstack((self.particles, new_particle))\n                self.velocities = np.vstack((self.velocities, np.random.rand(self.dim)))\n                self.personal_best = np.vstack((self.personal_best, new_particle))\n                self.personal_best_scores = np.append(self.personal_best_scores, np.inf)\n\n        return self.global_best, self.global_best_score", "name": "PSO_DE_Hybrid_Improved", "description": "Introduce a self-adaptive strategy for adjusting the cognitive and social coefficients to enhance convergence and exploration balance.", "configspace": "", "generation": 3, "fitness": 0.8389668611989721, "feedback": "The algorithm PSO_DE_Hybrid_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.839 with standard deviation 0.033. And the mean value of best solutions found was 0.136 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "4aef2bfc-0a5b-42fd-9da3-6c9946025195", "metadata": {"aucs": [0.791863694906394, 0.8638988411671473, 0.8611380475233751], "final_y": [0.15408196984984934, 0.1271279828920967, 0.12782367944887718]}, "mutation_prompt": null}
{"id": "6a4afe0d-77d9-4999-b588-bc3daef161da", "solution": "import numpy as np\n\nclass PSO_DE_Hybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particle_count = 10\n        self.particles = np.random.rand(self.particle_count, self.dim)\n        self.velocities = np.random.rand(self.particle_count, self.dim)\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.particle_count, np.inf)\n        self.global_best = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n\n        # Initialize particles\n        for i in range(self.particle_count):\n            self.particles[i] = lb + (ub - lb) * self.particles[i]\n\n        while eval_count < self.budget:\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current particle\n                score = func(self.particles[i])\n                eval_count += 1\n\n                # Update personal and global bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions (PSO)\n            inertia_weight = 0.9 - (0.5 * eval_count / self.budget)  # Dynamic inertia\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = 2.0 * r1 * (self.personal_best[i] - self.particles[i])\n                social = 2.0 * r2 * (self.global_best - self.particles[i])\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive + social\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            # Differential Evolution (Mutation and Crossover)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.particle_count) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + 0.8 * (b - c), lb, ub)\n                diversity = np.std(self.particles)  # Calculate diversity\n                crossover_rate = 0.5 + 0.4 * diversity  # Adaptive crossover rate\n                trial = np.where(np.random.rand(self.dim) < crossover_rate, mutant, self.particles[i])\n                \n                score = func(trial)\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = trial\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best = trial\n\n        return self.global_best, self.global_best_score", "name": "PSO_DE_Hybrid", "description": "Enhance the DE crossover by implementing a dynamic crossover rate based on the diversity of particle positions.", "configspace": "", "generation": 3, "fitness": 0.8508777240080835, "feedback": "The algorithm PSO_DE_Hybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.851 with standard deviation 0.019. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "f1a7c37f-19e7-4f0c-bf61-4f2e82724dff", "metadata": {"aucs": [0.8300428699720953, 0.8761145674491856, 0.8464757346029695], "final_y": [0.13806308803859846, 0.12134688034680796, 0.1249334580743856]}, "mutation_prompt": null}
{"id": "7770e16c-9aaf-4e56-9ed7-b66bfaf1dd14", "solution": "import numpy as np\n\nclass PSO_DE_Hybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particle_count = 10\n        self.particles = np.random.rand(self.particle_count, self.dim)\n        self.velocities = np.random.rand(self.particle_count, self.dim)\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.particle_count, np.inf)\n        self.global_best = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n\n        # Initialize particles\n        for i in range(self.particle_count):\n            self.particles[i] = lb + (ub - lb) * self.particles[i]\n\n        while eval_count < self.budget:\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current particle\n                score = func(self.particles[i])\n                eval_count += 1\n\n                # Update personal and global bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions (PSO)\n            inertia_weight = 0.9 - (0.5 * eval_count / self.budget)  # Dynamic inertia\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = 2.0 * r1 * (self.personal_best[i] - self.particles[i])\n                social = 2.0 * r2 * (self.global_best - self.particles[i])\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive + social\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            # Differential Evolution (Levy-inspired Mutation and Crossover)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.particle_count) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                # Levy flight step size\n                levy_exponent = 1.5\n                levy_step = np.random.standard_cauchy(self.dim) ** (1/levy_exponent)\n                F = 0.8 * (1 + levy_step)  # Levy-inspired dynamic scaling\n                mutant = np.clip(a + F * (b - c), lb, ub)\n                crossover_rate = 0.5 + 0.4 * (1 - eval_count / self.budget)\n                trial = np.where(np.random.rand(self.dim) < crossover_rate, mutant, self.particles[i])\n                \n                score = func(trial)\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = trial\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best = trial\n\n        return self.global_best, self.global_best_score", "name": "PSO_DE_Hybrid", "description": "Introduce Levy flight-inspired mutation in DE to balance exploration and exploitation dynamically.", "configspace": "", "generation": 4, "fitness": 0.8693537843483831, "feedback": "The algorithm PSO_DE_Hybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.869 with standard deviation 0.007. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "b877a6cb-99a8-4b95-b869-948af9cc9413", "metadata": {"aucs": [0.8777720949671368, 0.861716551998098, 0.8685727060799143], "final_y": [0.1237315143369615, 0.13025667366085036, 0.11920438393506472]}, "mutation_prompt": null}
{"id": "882b0afc-bf72-4f69-8ae2-0061e5c2e819", "solution": "import numpy as np\n\nclass PSO_DE_Hybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particle_count = 10\n        self.particles = np.random.rand(self.particle_count, self.dim)\n        self.velocities = np.random.rand(self.particle_count, self.dim)\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.particle_count, np.inf)\n        self.global_best = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n\n        # Initialize particles\n        for i in range(self.particle_count):\n            self.particles[i] = lb + (ub - lb) * self.particles[i]\n\n        while eval_count < self.budget:\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current particle\n                score = func(self.particles[i])\n                eval_count += 1\n\n                # Update personal and global bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions (PSO)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = 2.0 * (1 - self.personal_best_scores[i] / self.global_best_score) * r1 * (self.personal_best[i] - self.particles[i]) # Dynamic cognitive factor\n                social = 2.0 * r2 * (self.global_best - self.particles[i])\n                inertia_weight = 0.9 - 0.5 * (self.personal_best_scores[i] / self.global_best_score)  # Dynamic based on performance\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive + social\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            # Differential Evolution (Mutation and Crossover)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.particle_count) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + 0.8 * (b - c), lb, ub)\n                crossover_rate = 0.5 + 0.4 * (1 - eval_count / self.budget)  # Adaptive crossover rate\n                trial = np.where(np.random.rand(self.dim) < crossover_rate, mutant, self.particles[i])\n                \n                score = func(trial)\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = trial\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best = trial\n\n        return self.global_best, self.global_best_score", "name": "PSO_DE_Hybrid", "description": "Introduce a dynamic cognitive factor based on particle's relative performance to enhance local search efficiency.", "configspace": "", "generation": 4, "fitness": 0.8609107212674526, "feedback": "The algorithm PSO_DE_Hybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.861 with standard deviation 0.016. And the mean value of best solutions found was 0.129 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "6439431a-c98e-4577-985f-5f11d0b28563", "metadata": {"aucs": [0.8377300554322353, 0.87374706033645, 0.8712550480336727], "final_y": [0.14186008777613623, 0.12122584623882138, 0.12332803543647697]}, "mutation_prompt": null}
{"id": "cee01cb8-ea4c-48c9-bfce-291c58c8242d", "solution": "import numpy as np\n\nclass PSO_DE_Hybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particle_count = 10\n        self.particles = np.random.rand(self.particle_count, self.dim)\n        self.velocities = np.random.rand(self.particle_count, self.dim)\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.particle_count, np.inf)\n        self.global_best = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n\n        # Initialize particles\n        for i in range(self.particle_count):\n            self.particles[i] = lb + (ub - lb) * self.particles[i]\n\n        while eval_count < self.budget:\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current particle\n                score = func(self.particles[i])\n                eval_count += 1\n\n                # Update personal and global bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions (PSO)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = 2.0 * r1 * (self.personal_best[i] - self.particles[i])\n                social = 2.0 * r2 * (self.global_best - self.particles[i])\n                inertia_weight = 0.9 - 0.5 * (self.personal_best_scores[i] / np.min(self.personal_best_scores))  # Dynamic based on neighborhood performance\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive + social\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            # Differential Evolution (Mutation and Crossover)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.particle_count) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + 0.8 * (b - c), lb, ub)\n                crossover_rate = 0.5 + 0.4 * (1 - eval_count / self.budget)  # Adaptive crossover rate\n                trial = np.where(np.random.rand(self.dim) < crossover_rate, mutant, self.particles[i])\n                \n                score = func(trial)\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = trial\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best = trial\n\n        return self.global_best, self.global_best_score", "name": "PSO_DE_Hybrid", "description": "Introduce a dynamically adaptive velocity update mechanism based on both personal and neighborhood performance to enhance swarm convergence.", "configspace": "", "generation": 4, "fitness": 0.8419407834255145, "feedback": "The algorithm PSO_DE_Hybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.842 with standard deviation 0.022. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "6439431a-c98e-4577-985f-5f11d0b28563", "metadata": {"aucs": [0.8208792423051317, 0.8326101090773923, 0.8723329988940197], "final_y": [0.14587695270680434, 0.1278771266141686, 0.11992142647661808]}, "mutation_prompt": null}
{"id": "9633faf7-f4f4-4d88-8724-9fc88ac2d629", "solution": "import numpy as np\n\nclass PSO_DE_Hybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particle_count = 10\n        self.particles = np.random.rand(self.particle_count, self.dim)\n        self.velocities = np.random.rand(self.particle_count, self.dim)\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.particle_count, np.inf)\n        self.global_best = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n\n        # Initialize particles\n        for i in range(self.particle_count):\n            self.particles[i] = lb + (ub - lb) * self.particles[i]\n\n        while eval_count < self.budget:\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current particle\n                score = func(self.particles[i])\n                eval_count += 1\n\n                # Update personal and global bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions (PSO)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = (0.5 + 1.5 * eval_count / self.budget) * r1 * (self.personal_best[i] - self.particles[i])  # Adaptive learning rates\n                social = (0.5 + 1.5 * eval_count / self.budget) * r2 * (self.global_best - self.particles[i])  # Adaptive learning rates\n                inertia_weight = 0.9 - 0.5 * (self.personal_best_scores[i] / self.global_best_score)  # Dynamic based on performance\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive + social\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            # Differential Evolution (Mutation and Crossover)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.particle_count) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + 0.8 * (b - c), lb, ub)\n                crossover_rate = 0.5 + 0.4 * (1 - eval_count / self.budget)  # Adaptive crossover rate\n                trial = np.where(np.random.rand(self.dim) < crossover_rate, mutant, self.particles[i])\n                \n                score = func(trial)\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = trial\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best = trial\n\n        return self.global_best, self.global_best_score", "name": "PSO_DE_Hybrid", "description": "Introduce adaptive dynamic learning rates in PSO to further balance exploration and exploitation phases.", "configspace": "", "generation": 4, "fitness": 0.8791273429987682, "feedback": "The algorithm PSO_DE_Hybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.879 with standard deviation 0.006. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "6439431a-c98e-4577-985f-5f11d0b28563", "metadata": {"aucs": [0.8851280051519348, 0.8704397447370701, 0.8818142791072998], "final_y": [0.11503085844855687, 0.12740320945024375, 0.11722635241334445]}, "mutation_prompt": null}
{"id": "64e2f682-91bb-4282-9a29-eb7f8cba18e2", "solution": "import numpy as np\n\nclass PSO_DE_Hybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particle_count = 10\n        self.particles = np.random.rand(self.particle_count, self.dim)\n        self.velocities = np.random.rand(self.particle_count, self.dim)\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.particle_count, np.inf)\n        self.global_best = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n\n        # Initialize particles\n        for i in range(self.particle_count):\n            self.particles[i] = lb + (ub - lb) * self.particles[i]\n\n        while eval_count < self.budget:\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current particle\n                score = func(self.particles[i])\n                eval_count += 1\n\n                # Update personal and global bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions (PSO)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = 2.0 * r1 * (self.personal_best[i] - self.particles[i])\n                social = 2.0 * r2 * (self.global_best - self.particles[i])\n                phase_factor = 0.5 + 0.5 * (1 - eval_count / self.budget)  # New phase factor\n                inertia_weight = (0.9 - 0.5 * (self.personal_best_scores[i] / self.global_best_score)) * phase_factor  # Adjusted inertia\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive + social\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            # Differential Evolution (Mutation and Crossover)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.particle_count) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + 0.8 * (b - c), lb, ub)\n                crossover_rate = 0.5 + 0.4 * (1 - eval_count / self.budget)  # Adaptive crossover rate\n                trial = np.where(np.random.rand(self.dim) < crossover_rate, mutant, self.particles[i])\n                \n                score = func(trial)\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = trial\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best = trial\n\n        return self.global_best, self.global_best_score", "name": "PSO_DE_Hybrid", "description": "Introduce a multi-phase inertia weight strategy that adapts based on both particle performance and dynamic state of exploration versus exploitation.", "configspace": "", "generation": 4, "fitness": 0.87018046091922, "feedback": "The algorithm PSO_DE_Hybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.870 with standard deviation 0.019. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "6439431a-c98e-4577-985f-5f11d0b28563", "metadata": {"aucs": [0.8942192230281604, 0.8479534346315469, 0.8683687250979524], "final_y": [0.11810056130849655, 0.13069045233322418, 0.11550973063960801]}, "mutation_prompt": null}
{"id": "aa6915f5-78c9-4756-8077-85a945493c40", "solution": "import numpy as np\n\nclass PSO_DE_Hybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particle_count = 10\n        self.particles = np.random.rand(self.particle_count, self.dim)\n        self.velocities = np.random.rand(self.particle_count, self.dim)\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.particle_count, np.inf)\n        self.global_best = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n\n        # Initialize particles\n        for i in range(self.particle_count):\n            self.particles[i] = lb + (ub - lb) * self.particles[i]\n\n        while eval_count < self.budget:\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current particle\n                score = func(self.particles[i])\n                eval_count += 1\n\n                # Update personal and global bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions (PSO)\n            inertia_weight = 0.9 - (0.6 * eval_count / self.budget)  # Dynamic inertia\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = 2.0 * r1 * (self.personal_best[i] - self.particles[i])\n                social = 2.0 * r2 * (self.global_best - self.particles[i])\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive + social\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            # Differential Evolution (Mutation and Crossover)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.particle_count) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                F = 0.8 + 0.2 * (eval_count / self.budget)  # Dynamic scaling factor\n                mutant = np.clip(a + F * (b - c), lb, ub)\n                crossover_rate = 0.5 + 0.4 * (1 - eval_count / self.budget)  # Adaptive crossover rate\n                trial = np.where(np.random.rand(self.dim) < crossover_rate, mutant, self.particles[i])\n                \n                score = func(trial)\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = trial\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best = trial\n\n        return self.global_best, self.global_best_score", "name": "PSO_DE_Hybrid", "description": "Adjust the inertia weight formula to improve convergence rate by fine-tuning exploration-exploitation balance.", "configspace": "", "generation": 4, "fitness": 0.8631427383046263, "feedback": "The algorithm PSO_DE_Hybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.863 with standard deviation 0.022. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "b877a6cb-99a8-4b95-b869-948af9cc9413", "metadata": {"aucs": [0.8516366469224944, 0.8435942580127599, 0.8941973099786247], "final_y": [0.1309377032307546, 0.1223359025089159, 0.11388555981184767]}, "mutation_prompt": null}
{"id": "9065851b-3497-477a-a3c8-13c033b72442", "solution": "import numpy as np\n\nclass PSO_DE_Hybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particle_count = 10\n        self.particles = np.random.rand(self.particle_count, self.dim)\n        self.velocities = np.random.rand(self.particle_count, self.dim)\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.particle_count, np.inf)\n        self.global_best = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n\n        # Initialize particles\n        for i in range(self.particle_count):\n            self.particles[i] = lb + (ub - lb) * self.particles[i]\n\n        while eval_count < self.budget:\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current particle\n                score = func(self.particles[i])\n                eval_count += 1\n\n                # Update personal and global bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions (PSO)\n            inertia_weight = 0.9 - (0.5 * eval_count / self.budget)  # Dynamic inertia\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = 2.0 * r1 * (self.personal_best[i] - self.particles[i])\n                social = 2.0 * r2 * (self.global_best - self.particles[i])\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive + social\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            # Differential Evolution (Mutation and Crossover)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.particle_count) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                F = 0.8 + 0.2 * (eval_count / self.budget)  # Dynamic scaling factor\n                mutant = np.clip(a + F * (b - c), lb, ub)\n                crossover_rate = 0.1 + 0.9 * (eval_count / self.budget)  # Rapidly increasing crossover rate\n                trial = np.where(np.random.rand(self.dim) < crossover_rate, mutant, self.particles[i])\n                \n                score = func(trial)\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = trial\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best = trial\n\n        return self.global_best, self.global_best_score", "name": "PSO_DE_Hybrid", "description": "Introduce a dynamic crossover rate that increases rapidly during early iterations and gradually stabilizes to enhance the balance between exploration and exploitation.", "configspace": "", "generation": 4, "fitness": 0.8406253672949782, "feedback": "The algorithm PSO_DE_Hybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.841 with standard deviation 0.053. And the mean value of best solutions found was 0.135 (0. is the best) with standard deviation 0.023.", "error": "", "parent_id": "b877a6cb-99a8-4b95-b869-948af9cc9413", "metadata": {"aucs": [0.7668445815552081, 0.8648241596636426, 0.890207360666084], "final_y": [0.16750627007157093, 0.12121058789040762, 0.11632197865535066]}, "mutation_prompt": null}
{"id": "793629b7-2e90-42e4-8207-2a5c4a301460", "solution": "import numpy as np\n\nclass PSO_DE_Hybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particle_count = 10\n        self.particles = np.random.rand(self.particle_count, self.dim)\n        self.velocities = np.random.rand(self.particle_count, self.dim)\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.particle_count, np.inf)\n        self.global_best = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n\n        # Initialize particles\n        for i in range(self.particle_count):\n            self.particles[i] = lb + (ub - lb) * self.particles[i]\n\n        while eval_count < self.budget:\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current particle\n                score = func(self.particles[i])\n                eval_count += 1\n\n                # Update personal and global bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions (PSO)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = 2.0 * r1 * (self.personal_best[i] - self.particles[i])\n                social = 2.0 * r2 * (self.global_best - self.particles[i])\n                inertia_weight = 0.8 - 0.3 * (self.personal_best_scores[i] / self.global_best_score)  # Adjusted range\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive + social\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            # Differential Evolution (Mutation and Crossover)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.particle_count) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                scale_factor = 0.7 + 0.3 * (1 - eval_count / self.budget)  # Dynamic scaling factor\n                mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n                crossover_rate = 0.5 + 0.4 * (1 - eval_count / self.budget)  # Adaptive crossover rate\n                trial = np.where(np.random.rand(self.dim) < crossover_rate, mutant, self.particles[i])\n                \n                score = func(trial)\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = trial\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best = trial\n\n        return self.global_best, self.global_best_score", "name": "PSO_DE_Hybrid", "description": "Enhance global exploration by adjusting inertia weight range and employing a dynamic scaling factor in DE mutation.", "configspace": "", "generation": 4, "fitness": 0.8599488082174848, "feedback": "The algorithm PSO_DE_Hybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.860 with standard deviation 0.021. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "6439431a-c98e-4577-985f-5f11d0b28563", "metadata": {"aucs": [0.8829277955062229, 0.8317060637332535, 0.8652125654129781], "final_y": [0.12124896881105329, 0.12510099875725433, 0.1214001163554902]}, "mutation_prompt": null}
{"id": "24c6900b-9143-4e65-a69b-1fb31bb01401", "solution": "import numpy as np\n\nclass PSO_DE_Hybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particle_count = 10\n        self.particles = np.random.rand(self.particle_count, self.dim)\n        self.velocities = np.random.rand(self.particle_count, self.dim)\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.particle_count, np.inf)\n        self.global_best = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n\n        # Initialize particles\n        for i in range(self.particle_count):\n            self.particles[i] = lb + (ub - lb) * self.particles[i]\n\n        while eval_count < self.budget:\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current particle\n                score = func(self.particles[i])\n                eval_count += 1\n\n                # Update personal and global bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions (PSO)\n            inertia_weight = 0.9 - (0.5 * eval_count / self.budget)  # Dynamic inertia\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = 2.0 * r1 * (self.personal_best[i] - self.particles[i])\n                social = 2.0 * r2 * (self.global_best - self.particles[i])\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive + social\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            # Differential Evolution (Mutation and Crossover)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.particle_count) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                F = 0.8 + 0.2 * (eval_count / self.budget)  # Dynamic scaling factor\n                mutant = np.clip(a + F * (b - c), lb, ub)\n                crossover_rate = 0.5 + 0.4 * (1 - eval_count / self.budget)  # Adaptive crossover rate\n                trial = np.where(np.random.rand(self.dim) < crossover_rate, mutant, self.particles[i])\n                \n                score = func(trial)\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = trial\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best = trial\n                \n                # Local search refinement\n                if eval_count < self.budget:\n                    refined_trial = np.clip(trial + 0.05 * np.random.randn(self.dim), lb, ub)\n                    refined_score = func(refined_trial)\n                    eval_count += 1\n                    if refined_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = refined_score\n                        self.personal_best[i] = refined_trial\n                        if refined_score < self.global_best_score:\n                            self.global_best_score = refined_score\n                            self.global_best = refined_trial\n\n        return self.global_best, self.global_best_score", "name": "PSO_DE_Hybrid", "description": "Incorporate a local search mechanism after DE trial generation to refine promising solutions further.", "configspace": "", "generation": 4, "fitness": 0.8423707744796017, "feedback": "The algorithm PSO_DE_Hybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.842 with standard deviation 0.023. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "b877a6cb-99a8-4b95-b869-948af9cc9413", "metadata": {"aucs": [0.8108057176365064, 0.8631856070420489, 0.8531209987602499], "final_y": [0.1410862657935681, 0.12165359598243186, 0.12968662306157686]}, "mutation_prompt": null}
{"id": "a05c74ef-e6b5-4156-8940-4b36b4a60992", "solution": "import numpy as np\n\nclass PSO_DE_Hybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particle_count = 10\n        self.particles = np.random.rand(self.particle_count, self.dim)\n        self.velocities = np.random.rand(self.particle_count, self.dim)\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.particle_count, np.inf)\n        self.global_best = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n\n        # Initialize particles\n        for i in range(self.particle_count):\n            self.particles[i] = lb + (ub - lb) * self.particles[i]\n\n        while eval_count < self.budget:\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current particle\n                score = func(self.particles[i])\n                eval_count += 1\n\n                # Update personal and global bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions (PSO)\n            diversity = np.std(self.particles)\n            learning_factor = 1.5 + 0.5 * diversity  # Dynamic learning factor based on diversity\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = learning_factor * r1 * (self.personal_best[i] - self.particles[i])  # Modified\n                social = learning_factor * r2 * (self.global_best - self.particles[i])  # Modified\n                inertia_weight = 0.9 - 0.5 * (self.personal_best_scores[i] / self.global_best_score)  # Dynamic based on performance\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive + social\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            # Differential Evolution (Mutation and Crossover)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.particle_count) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + 0.8 * (b - c), lb, ub)\n                crossover_rate = 0.5 + 0.4 * (1 - eval_count / self.budget)  # Adaptive crossover rate\n                trial = np.where(np.random.rand(self.dim) < crossover_rate, mutant, self.particles[i])\n                \n                score = func(trial)\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = trial\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best = trial\n\n        return self.global_best, self.global_best_score", "name": "PSO_DE_Hybrid", "description": "Introduce a dynamic learning factor based on particle diversity to balance exploration and exploitation in the PSO component.", "configspace": "", "generation": 4, "fitness": 0.8338550613993685, "feedback": "The algorithm PSO_DE_Hybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.834 with standard deviation 0.048. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.018.", "error": "", "parent_id": "6439431a-c98e-4577-985f-5f11d0b28563", "metadata": {"aucs": [0.7667355568640052, 0.8713939109151447, 0.8634357164189557], "final_y": [0.1588958280835595, 0.12026259393738159, 0.12092839073641282]}, "mutation_prompt": null}
{"id": "06c8b39e-76ff-43c5-9f04-2d523fc77ce7", "solution": "import numpy as np\n\nclass PSO_DE_Hybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particle_count = 10\n        self.particles = np.random.rand(self.particle_count, self.dim)\n        self.velocities = np.random.rand(self.particle_count, self.dim)\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.particle_count, np.inf)\n        self.global_best = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n\n        # Initialize particles\n        for i in range(self.particle_count):\n            self.particles[i] = lb + (ub - lb) * self.particles[i]\n\n        while eval_count < self.budget:\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current particle\n                score = func(self.particles[i])\n                eval_count += 1\n\n                # Update personal and global bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions (PSO)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                decay_factor = 0.95  # Changed line with decay factor\n                cognitive = decay_factor * (0.5 + 1.5 * eval_count / self.budget) * r1 * (self.personal_best[i] - self.particles[i])  # Adaptive learning rates\n                social = decay_factor * (0.5 + 1.5 * eval_count / self.budget) * r2 * (self.global_best - self.particles[i])  # Adaptive learning rates\n                inertia_weight = 0.9 - 0.5 * (self.personal_best_scores[i] / self.global_best_score)  # Dynamic based on performance\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive + social\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            # Differential Evolution (Mutation and Crossover)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.particle_count) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + 0.8 * (b - c), lb, ub)\n                crossover_rate = 0.5 + 0.4 * (1 - eval_count / self.budget)  # Adaptive crossover rate\n                trial = np.where(np.random.rand(self.dim) < crossover_rate, mutant, self.particles[i])\n                \n                score = func(trial)\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = trial\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best = trial\n\n        return self.global_best, self.global_best_score", "name": "PSO_DE_Hybrid", "description": "Introduce a decay factor to the adaptive learning rate to enhance convergence speed in PSO-DE Hybrid.", "configspace": "", "generation": 5, "fitness": 0.9084933340092037, "feedback": "The algorithm PSO_DE_Hybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.908 with standard deviation 0.003. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "9633faf7-f4f4-4d88-8724-9fc88ac2d629", "metadata": {"aucs": [0.9097218436261045, 0.9044272081439992, 0.9113309502575073], "final_y": [0.11317377999398537, 0.11623077581753505, 0.11172067197002356]}, "mutation_prompt": null}
{"id": "076d4cec-482f-4bb9-8e11-167383e6b167", "solution": "import numpy as np\n\nclass PSO_DE_Hybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particle_count = 10\n        self.particles = np.random.rand(self.particle_count, self.dim)\n        self.velocities = np.random.rand(self.particle_count, self.dim)\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.particle_count, np.inf)\n        self.global_best = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n\n        # Initialize particles\n        for i in range(self.particle_count):\n            self.particles[i] = lb + (ub - lb) * self.particles[i]\n\n        while eval_count < self.budget:\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current particle\n                score = func(self.particles[i])\n                eval_count += 1\n\n                # Update personal and global bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions (PSO)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = 2.0 * r1 * (self.personal_best[i] - self.particles[i])\n                social = 2.0 * r2 * (self.global_best - self.particles[i])\n                phase_factor = 0.5 + 0.5 * (1 - eval_count / self.budget)  # New phase factor\n                inertia_weight = (0.9 - 0.5 * (self.personal_best_scores[i] / self.global_best_score)) * phase_factor  # Adjusted inertia\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive + social\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            # Differential Evolution (Mutation and Crossover)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.particle_count) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                adaptive_factor = 0.5 + 0.3 * (1 - eval_count / self.budget)  # Adaptive scaling factor\n                mutant = np.clip(a + adaptive_factor * (b - c), lb, ub)  # Updated scaling factor line\n                crossover_rate = 0.5 + 0.4 * (1 - eval_count / self.budget)  # Adaptive crossover rate\n                trial = np.where(np.random.rand(self.dim) < crossover_rate, mutant, self.particles[i])\n                \n                score = func(trial)\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = trial\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best = trial\n\n        return self.global_best, self.global_best_score", "name": "PSO_DE_Hybrid", "description": "Introduce an adaptive scaling factor in the DE mutation to enhance convergence.", "configspace": "", "generation": 5, "fitness": 0.9092680742158326, "feedback": "The algorithm PSO_DE_Hybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.909 with standard deviation 0.014. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "64e2f682-91bb-4282-9a29-eb7f8cba18e2", "metadata": {"aucs": [0.8962655617653866, 0.902891074982906, 0.9286475858992052], "final_y": [0.12026174534621425, 0.11628872570866311, 0.1112650850898027]}, "mutation_prompt": null}
{"id": "fd4b192d-05dd-474d-ab33-488006cce3b6", "solution": "import numpy as np\n\nclass PSO_DE_Hybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particle_count = min(20, 5 + dim)  # Dynamic particle count\n        self.particles = np.random.rand(self.particle_count, self.dim)\n        self.velocities = np.random.rand(self.particle_count, self.dim)\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.particle_count, np.inf)\n        self.global_best = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n\n        # Initialize particles\n        for i in range(self.particle_count):\n            self.particles[i] = lb + (ub - lb) * self.particles[i]\n\n        while eval_count < self.budget:\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current particle\n                score = func(self.particles[i])\n                eval_count += 1\n\n                # Update personal and global bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions (PSO)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = 2.0 * r1 * (self.personal_best[i] - self.particles[i])\n                social = 2.0 * r2 * (self.global_best - self.particles[i])\n                phase_factor = 0.5 + 0.5 * (1 - eval_count / self.budget)  # New phase factor\n                inertia_weight = (0.9 - 0.5 * (self.personal_best_scores[i] / self.global_best_score)) * phase_factor  # Adjusted inertia\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive + social\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            # Differential Evolution (Mutation and Crossover)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.particle_count) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                F = 0.7 + 0.3 * (eval_count / self.budget)  # Adaptive mutation factor\n                mutant = np.clip(a + F * (b - c), lb, ub)\n                crossover_rate = 0.5 + 0.4 * (1 - eval_count / self.budget)  # Adaptive crossover rate\n                trial = np.where(np.random.rand(self.dim) < crossover_rate, mutant, self.particles[i])\n                \n                score = func(trial)\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = trial\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best = trial\n\n        return self.global_best, self.global_best_score", "name": "PSO_DE_Hybrid", "description": "Enhance the PSO-DE Hybrid by introducing an adaptive mutation strategy and a dynamic particle count adjustment mechanism for improved convergence.", "configspace": "", "generation": 5, "fitness": 0.9117478078437206, "feedback": "The algorithm PSO_DE_Hybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.912 with standard deviation 0.009. And the mean value of best solutions found was 0.111 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "64e2f682-91bb-4282-9a29-eb7f8cba18e2", "metadata": {"aucs": [0.9044456576887515, 0.9057369283530422, 0.9250608374893683], "final_y": [0.11059669604171751, 0.1117644188686644, 0.11019517002525481]}, "mutation_prompt": null}
{"id": "7cd7a2c4-2623-4142-bcdd-70e07c35bf95", "solution": "import numpy as np\n\nclass PSO_DE_Hybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particle_count = 10\n        self.particles = np.random.rand(self.particle_count, self.dim)\n        self.velocities = np.random.rand(self.particle_count, self.dim)\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.particle_count, np.inf)\n        self.global_best = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n\n        # Initialize particles\n        for i in range(self.particle_count):\n            self.particles[i] = lb + (ub - lb) * self.particles[i]\n\n        while eval_count < self.budget:\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current particle\n                score = func(self.particles[i])\n                eval_count += 1\n\n                # Update personal and global bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions (PSO)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = (0.5 + 1.5 * eval_count / self.budget) * r1 * (self.personal_best[i] - self.particles[i])  # Adaptive learning rates\n                social = (0.5 + 1.5 * eval_count / self.budget) * r2 * (self.global_best - self.particles[i])  # Adaptive learning rates\n                inertia_weight = 0.9 - 0.5 * ((self.personal_best_scores[i] / self.global_best_score)**2)  # Non-linear dynamic based on performance\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive + social\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            # Differential Evolution (Mutation and Crossover)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.particle_count) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + 0.8 * (b - c), lb, ub)\n                crossover_rate = 0.5 + 0.4 * (1 - eval_count / self.budget)  # Adaptive crossover rate\n                trial = np.where(np.random.rand(self.dim) < crossover_rate, mutant, self.particles[i])\n                \n                score = func(trial)\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = trial\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best = trial\n\n        return self.global_best, self.global_best_score", "name": "PSO_DE_Hybrid", "description": "Introduce a non-linear adaptive inertia weight strategy in PSO to further balance exploration and exploitation phases.", "configspace": "", "generation": 5, "fitness": 0.8961982520461916, "feedback": "The algorithm PSO_DE_Hybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.896 with standard deviation 0.022. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "9633faf7-f4f4-4d88-8724-9fc88ac2d629", "metadata": {"aucs": [0.8806395377733702, 0.8800674849286542, 0.9278877334365507], "final_y": [0.12530359988804862, 0.1266798447510249, 0.11001818148578091]}, "mutation_prompt": null}
{"id": "93519c7b-fbba-4bb8-934b-436bbd830a1f", "solution": "import numpy as np\n\nclass PSO_DE_Hybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particle_count = 10\n        self.particles = np.random.rand(self.particle_count, self.dim)\n        self.velocities = np.random.rand(self.particle_count, self.dim)\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.particle_count, np.inf)\n        self.global_best = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n\n        # Initialize particles\n        for i in range(self.particle_count):\n            self.particles[i] = lb + (ub - lb) * self.particles[i]\n\n        while eval_count < self.budget:\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current particle\n                score = func(self.particles[i])\n                eval_count += 1\n\n                # Update personal and global bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions (PSO)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = 2.0 * r1 * (self.personal_best[i] - self.particles[i])\n                social = 2.0 * r2 * (self.global_best - self.particles[i])\n                phase_factor = 0.5 + 0.5 * np.cos(np.pi * eval_count / self.budget)  # Nonlinear phase factor\n                inertia_weight = (0.9 - 0.5 * (self.personal_best_scores[i] / self.global_best_score)) * phase_factor  # Adjusted inertia\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive + social\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            # Differential Evolution (Mutation and Crossover)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.particle_count) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + 0.8 * (b - c), lb, ub)\n                crossover_rate = 0.5 + 0.4 * (1 - eval_count / self.budget)  # Adaptive crossover rate\n                trial = np.where(np.random.rand(self.dim) < crossover_rate, mutant, self.particles[i])\n                \n                score = func(trial)\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = trial\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best = trial\n\n        return self.global_best, self.global_best_score", "name": "PSO_DE_Hybrid", "description": "Enhance adaptive learning by introducing a nonlinear dynamic inertia weight strategy based on iteration progress for improved convergence.", "configspace": "", "generation": 5, "fitness": 0.8860160352231811, "feedback": "The algorithm PSO_DE_Hybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.886 with standard deviation 0.045. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.016.", "error": "", "parent_id": "64e2f682-91bb-4282-9a29-eb7f8cba18e2", "metadata": {"aucs": [0.8232551062873041, 0.9293766905843284, 0.9054163087979108], "final_y": [0.14610634449951387, 0.11172261174183828, 0.11353312412428751]}, "mutation_prompt": null}
{"id": "022dc06f-798d-48ed-aaa6-528b4825062d", "solution": "import numpy as np\n\nclass PSO_DE_Hybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particle_count = 10\n        self.particles = np.random.rand(self.particle_count, self.dim)\n        self.velocities = np.random.rand(self.particle_count, self.dim)\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.particle_count, np.inf)\n        self.global_best = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n\n        # Initialize particles\n        for i in range(self.particle_count):\n            self.particles[i] = lb + (ub - lb) * self.particles[i]\n\n        while eval_count < self.budget:\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current particle\n                score = func(self.particles[i])\n                eval_count += 1\n\n                # Update personal and global bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions (PSO)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                # Dynamic scaling factor for cognitive component\n                cognitive_scale = 1 + 0.5 * (self.global_best_score / self.personal_best_scores[i]) \n                cognitive = cognitive_scale * r1 * (self.personal_best[i] - self.particles[i])\n                social = 2.0 * r2 * (self.global_best - self.particles[i])\n                phase_factor = 0.5 + 0.5 * (1 - eval_count / self.budget)  # New phase factor\n                inertia_weight = (0.9 - 0.5 * (self.personal_best_scores[i] / self.global_best_score)) * phase_factor  # Adjusted inertia\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive + social\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            # Differential Evolution (Mutation and Crossover)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.particle_count) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + 0.8 * (b - c), lb, ub)\n                crossover_rate = 0.5 + 0.4 * (1 - eval_count / self.budget)  # Adaptive crossover rate\n                trial = np.where(np.random.rand(self.dim) < crossover_rate, mutant, self.particles[i])\n                \n                score = func(trial)\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = trial\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best = trial\n\n        return self.global_best, self.global_best_score", "name": "PSO_DE_Hybrid", "description": "Introduce a dynamic scaling factor to the cognitive component of PSO based on particle fitness relative to global best.  ", "configspace": "", "generation": 5, "fitness": 0.8945457424654498, "feedback": "The algorithm PSO_DE_Hybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.895 with standard deviation 0.016. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "64e2f682-91bb-4282-9a29-eb7f8cba18e2", "metadata": {"aucs": [0.8724166766594208, 0.899428107829032, 0.9117924429078966], "final_y": [0.12428615480788685, 0.11537879077812285, 0.11157950377197257]}, "mutation_prompt": null}
{"id": "1e077f7d-2641-4ebd-b8ef-9137d7223d42", "solution": "import numpy as np\n\nclass PSO_DE_Hybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particle_count = 10\n        self.particles = np.random.rand(self.particle_count, self.dim)\n        self.velocities = np.random.rand(self.particle_count, self.dim)\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.particle_count, np.inf)\n        self.global_best = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n\n        # Initialize particles\n        for i in range(self.particle_count):\n            self.particles[i] = lb + (ub - lb) * self.particles[i]\n\n        while eval_count < self.budget:\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current particle\n                score = func(self.particles[i])\n                eval_count += 1\n\n                # Update personal and global bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions (PSO)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = 2.0 * r1 * (self.personal_best[i] - self.particles[i])\n                social = 2.0 * r2 * (self.global_best - self.particles[i])\n                phase_factor = 0.5 + 0.5 * (1 - eval_count / self.budget)  # New phase factor\n                inertia_weight = (0.9 - 0.5 * ((self.personal_best_scores[i] / self.global_best_score) ** 0.5)) * phase_factor  # Adjusted inertia\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive + social\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            # Differential Evolution (Mutation and Crossover)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.particle_count) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + 0.8 * (b - c), lb, ub)\n                crossover_rate = 0.5 + 0.4 * (1 - eval_count / self.budget)  # Adaptive crossover rate\n                trial = np.where(np.random.rand(self.dim) < crossover_rate, mutant, self.particles[i])\n                \n                score = func(trial)\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = trial\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best = trial\n\n        return self.global_best, self.global_best_score", "name": "PSO_DE_Hybrid", "description": "Introduce adaptive inertia weight considering both personal and global best improvements to enhance convergence.", "configspace": "", "generation": 5, "fitness": 0.8970228677782236, "feedback": "The algorithm PSO_DE_Hybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.897 with standard deviation 0.033. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "64e2f682-91bb-4282-9a29-eb7f8cba18e2", "metadata": {"aucs": [0.8503470126230304, 0.9136842775759586, 0.9270373131356819], "final_y": [0.13747998433598418, 0.11240222838957603, 0.1100765318659227]}, "mutation_prompt": null}
{"id": "1e392880-6fb4-4f92-9a03-8a9e965150cb", "solution": "import numpy as np\n\nclass PSO_DE_Hybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particle_count = 10\n        self.particles = np.random.rand(self.particle_count, self.dim)\n        self.velocities = np.random.rand(self.particle_count, self.dim)\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.particle_count, np.inf)\n        self.global_best = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n\n        # Initialize particles\n        for i in range(self.particle_count):\n            self.particles[i] = lb + (ub - lb) * self.particles[i]\n\n        while eval_count < self.budget:\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current particle\n                score = func(self.particles[i])\n                eval_count += 1\n\n                # Update personal and global bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions (PSO)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = 2.0 * r1 * (self.personal_best[i] - self.particles[i])\n                social = 2.0 * r2 * (self.global_best - self.particles[i])\n                phase_factor = 0.5 + 0.5 * (1 - eval_count / self.budget)  # New phase factor\n                inertia_weight = (0.9 - 0.5 * (self.personal_best_scores[i] / self.global_best_score)) * phase_factor  # Adjusted inertia\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive + social\n                # Updated velocity clamping mechanism\n                max_velocity = 0.1 * (ub - lb) \n                self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            # Differential Evolution (Mutation and Crossover)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.particle_count) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + 0.8 * (b - c), lb, ub)\n                crossover_rate = 0.5 + 0.4 * (1 - eval_count / self.budget)  # Adaptive crossover rate\n                trial = np.where(np.random.rand(self.dim) < crossover_rate, mutant, self.particles[i])\n                \n                score = func(trial)\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = trial\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best = trial\n\n        return self.global_best, self.global_best_score", "name": "PSO_DE_Hybrid", "description": "Enhance the existing multi-phase inertia weight strategy by incorporating an adaptive velocity clamping mechanism to better control the exploration and exploitation trade-off.", "configspace": "", "generation": 5, "fitness": 0.9176698210800264, "feedback": "The algorithm PSO_DE_Hybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.918 with standard deviation 0.005. And the mean value of best solutions found was 0.112 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "64e2f682-91bb-4282-9a29-eb7f8cba18e2", "metadata": {"aucs": [0.9158851668993668, 0.9120522346562834, 0.9250720616844289], "final_y": [0.11093620556354222, 0.11630080921684949, 0.11008113677043707]}, "mutation_prompt": null}
{"id": "93ee4008-2853-4a86-ad30-068b4d6c2b80", "solution": "import numpy as np\n\nclass PSO_DE_Hybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particle_count = 10\n        self.particles = np.random.rand(self.particle_count, self.dim)\n        self.velocities = np.random.rand(self.particle_count, self.dim)\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.particle_count, np.inf)\n        self.global_best = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n\n        # Initialize particles\n        for i in range(self.particle_count):\n            self.particles[i] = lb + (ub - lb) * self.particles[i]\n\n        while eval_count < self.budget:\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current particle\n                score = func(self.particles[i])\n                eval_count += 1\n\n                # Update personal and global bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions (PSO)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = (1.5 + 0.5 * (1 - eval_count / self.budget)) * r1 * (self.personal_best[i] - self.particles[i])  # Adaptive cognitive\n                social = (1.5 + 0.5 * (1 - eval_count / self.budget)) * r2 * (self.global_best - self.particles[i])  # Adaptive social\n                phase_factor = 0.5 + 0.5 * (1 - eval_count / self.budget)  # New phase factor\n                inertia_weight = (0.9 - 0.5 * (self.personal_best_scores[i] / self.global_best_score)) * phase_factor  # Adjusted inertia\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive + social\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            # Differential Evolution (Mutation and Crossover)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.particle_count) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + 0.8 * (b - c), lb, ub)\n                crossover_rate = 0.5 + 0.4 * (1 - eval_count / self.budget)  # Adaptive crossover rate\n                trial = np.where(np.random.rand(self.dim) < crossover_rate, mutant, self.particles[i])\n                \n                score = func(trial)\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = trial\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best = trial\n\n        return self.global_best, self.global_best_score", "name": "PSO_DE_Hybrid", "description": "Enhance the PSO-DE Hybrid by introducing adaptive cognitive and social components to further refine exploration and exploitation balance.", "configspace": "", "generation": 5, "fitness": 0.8889841459837285, "feedback": "The algorithm PSO_DE_Hybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.889 with standard deviation 0.041. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "64e2f682-91bb-4282-9a29-eb7f8cba18e2", "metadata": {"aucs": [0.831231153675017, 0.9116286336391389, 0.9240926506370302], "final_y": [0.14135930322835966, 0.11622576370242499, 0.10994124310619724]}, "mutation_prompt": null}
{"id": "68bddc87-cd40-46ae-bd71-17ee2f33476d", "solution": "import numpy as np\n\nclass PSO_DE_Hybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particle_count = 10\n        self.particles = np.random.rand(self.particle_count, self.dim)\n        self.velocities = np.random.rand(self.particle_count, self.dim)\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.particle_count, np.inf)\n        self.global_best = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n\n        # Initialize particles\n        for i in range(self.particle_count):\n            self.particles[i] = lb + (ub - lb) * self.particles[i]\n\n        while eval_count < self.budget:\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current particle\n                score = func(self.particles[i])\n                eval_count += 1\n\n                # Update personal and global bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions (PSO)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = (0.5 + 1.5 * eval_count / self.budget) * r1 * (self.personal_best[i] - self.particles[i])  # Adaptive learning rates\n                social = (0.5 + 1.5 * eval_count / self.budget) * r2 * (self.global_best - self.particles[i])  # Adaptive learning rates\n                inertia_weight = 0.9 - 0.5 * (self.personal_best_scores[i] / self.global_best_score)  # Dynamic based on performance\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive + social\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            # Differential Evolution (Mutation and Crossover)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.particle_count) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                mutant_factor = 0.8 * (1 - self.personal_best_scores[i] / self.global_best_score)  # Adaptive mutation factor\n                mutant = np.clip(a + mutant_factor * (b - c), lb, ub)\n                crossover_rate = 0.5 + 0.4 * (1 - eval_count / self.budget)  # Adaptive crossover rate\n                trial = np.where(np.random.rand(self.dim) < crossover_rate, mutant, self.particles[i])\n                \n                score = func(trial)\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = trial\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best = trial\n\n        return self.global_best, self.global_best_score", "name": "PSO_DE_Hybrid", "description": "Introduce an adaptive mutation factor in DE based on current particle performance to balance exploration and exploitation phases.", "configspace": "", "generation": 5, "fitness": 0.890566547422546, "feedback": "The algorithm PSO_DE_Hybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.891 with standard deviation 0.023. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "9633faf7-f4f4-4d88-8724-9fc88ac2d629", "metadata": {"aucs": [0.8594520205342708, 0.8964813747304727, 0.9157662470028944], "final_y": [0.12576169957197803, 0.11631601316002627, 0.11228937113480975]}, "mutation_prompt": null}
{"id": "258af06e-43b9-4baf-a82d-48f5827c3257", "solution": "import numpy as np\n\nclass PSO_DE_Hybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particle_count = min(20, 5 + dim)  # Dynamic particle count\n        self.particles = np.random.rand(self.particle_count, self.dim)\n        self.velocities = np.random.rand(self.particle_count, self.dim)\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.particle_count, np.inf)\n        self.global_best = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n\n        # Initialize particles\n        for i in range(self.particle_count):\n            self.particles[i] = lb + (ub - lb) * self.particles[i]\n\n        while eval_count < self.budget:\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current particle\n                score = func(self.particles[i])\n                eval_count += 1\n\n                # Update personal and global bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions (PSO)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = 2.0 * r1 * (self.personal_best[i] - self.particles[i])\n                social = 2.0 * r2 * (self.global_best - self.particles[i])\n                phase_factor = 0.5 + 0.5 * (1 - eval_count / self.budget)  # New phase factor\n                inertia_weight = (0.9 - 0.5 * (self.personal_best_scores[i] / self.global_best_score)) * phase_factor  # Adjusted inertia\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive + social\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = lb + (ub - lb) * ((self.particles[i] - lb) % (ub - lb)) / (ub - lb)  # Adaptive boundary handling\n\n            # Differential Evolution (Mutation and Crossover)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.particle_count) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                F = 0.7 + 0.3 * (eval_count / self.budget)  # Adaptive mutation factor\n                mutant = np.clip(a + F * (b - c), lb, ub)\n                crossover_rate = 0.5 + 0.4 * (1 - eval_count / self.budget)  # Adaptive crossover rate\n                trial = np.where(np.random.rand(self.dim) < crossover_rate, mutant, self.particles[i])\n                \n                score = func(trial)\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = trial\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best = trial\n\n        return self.global_best, self.global_best_score", "name": "PSO_DE_Hybrid", "description": "Refine the PSO-DE Hybrid by introducing an adaptive boundary handling mechanism to improve solution quality at search space edges.", "configspace": "", "generation": 6, "fitness": 0.9056853331645752, "feedback": "The algorithm PSO_DE_Hybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.906 with standard deviation 0.012. And the mean value of best solutions found was 0.111 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "fd4b192d-05dd-474d-ab33-488006cce3b6", "metadata": {"aucs": [0.8902499262484136, 0.9076977824482845, 0.9191082907970278], "final_y": [0.11219114441212907, 0.11167014091038452, 0.1103688349769012]}, "mutation_prompt": null}
{"id": "786b2cea-9f5d-462b-a41f-2211f19c44b2", "solution": "import numpy as np\n\nclass PSO_DE_Hybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particle_count = 10\n        self.particles = np.random.rand(self.particle_count, self.dim)\n        self.velocities = np.random.rand(self.particle_count, self.dim)\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.particle_count, np.inf)\n        self.global_best = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n\n        # Initialize particles\n        for i in range(self.particle_count):\n            self.particles[i] = lb + (ub - lb) * self.particles[i]\n\n        while eval_count < self.budget:\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current particle\n                score = func(self.particles[i])\n                eval_count += 1\n\n                # Update personal and global bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions (PSO)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = 2.0 * r1 * (self.personal_best[i] - self.particles[i])\n                social = 2.0 * r2 * (self.global_best - self.particles[i])\n                phase_factor = 0.5 + 0.5 * (1 - eval_count / self.budget)  # New phase factor\n                inertia_weight = (0.9 - 0.5 * (self.personal_best_scores[i] / self.global_best_score)) * phase_factor  # Adjusted inertia\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive + social\n                # Updated velocity clamping mechanism\n                max_velocity = 0.1 * (ub - lb) \n                self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            # Differential Evolution (Mutation and Crossover)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.particle_count) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                # Adaptive mutation factor for enhanced exploration\n                mutation_factor = 0.8 + 0.2 * (eval_count / self.budget)\n                mutant = np.clip(a + mutation_factor * (b - c), lb, ub)\n                crossover_rate = 0.5 + 0.4 * (1 - eval_count / self.budget)  # Adaptive crossover rate\n                trial = np.where(np.random.rand(self.dim) < crossover_rate, mutant, self.particles[i])\n                \n                score = func(trial)\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = trial\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best = trial\n\n        return self.global_best, self.global_best_score", "name": "PSO_DE_Hybrid", "description": "Introduce an adaptive mutation factor in the DE phase to enhance exploration adaptively over time.", "configspace": "", "generation": 6, "fitness": 0.8961575020264768, "feedback": "The algorithm PSO_DE_Hybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.896 with standard deviation 0.028. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "1e392880-6fb4-4f92-9a03-8a9e965150cb", "metadata": {"aucs": [0.8595911095938867, 0.9027909741715636, 0.9260904223139802], "final_y": [0.1318668971165854, 0.1162234913850928, 0.11154918839842554]}, "mutation_prompt": null}
{"id": "742f49c2-4326-4d75-bcdb-4ceb962ef3d0", "solution": "import numpy as np\n\nclass PSO_DE_Hybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particle_count = min(20, 5 + dim)  # Dynamic particle count\n        self.particles = np.random.rand(self.particle_count, self.dim)\n        self.velocities = np.random.rand(self.particle_count, self.dim)\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.particle_count, np.inf)\n        self.global_best = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n\n        # Initialize particles\n        for i in range(self.particle_count):\n            self.particles[i] = lb + (ub - lb) * self.particles[i]\n\n        while eval_count < self.budget:\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current particle\n                score = func(self.particles[i])\n                eval_count += 1\n\n                # Update personal and global bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions (PSO)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                C1 = 1.5 + 0.5 * (eval_count / self.budget)  # Adaptive cognitive factor\n                C2 = 1.5 + 0.5 * (1 - eval_count / self.budget)  # Adaptive social factor\n                cognitive = C1 * r1 * (self.personal_best[i] - self.particles[i])\n                social = C2 * r2 * (self.global_best - self.particles[i])\n                phase_factor = 0.5 + 0.5 * (1 - eval_count / self.budget)  # New phase factor\n                inertia_weight = (0.9 - 0.5 * (self.personal_best_scores[i] / self.global_best_score)) * phase_factor  # Adjusted inertia\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive + social\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            # Differential Evolution (Mutation and Crossover)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.particle_count) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                F = 0.7 + 0.3 * (eval_count / self.budget)  # Adaptive mutation factor\n                mutant = np.clip(a + F * (b - c), lb, ub)\n                crossover_rate = 0.5 + 0.4 * (1 - eval_count / self.budget)  # Adaptive crossover rate\n                trial = np.where(np.random.rand(self.dim) < crossover_rate, mutant, self.particles[i])\n                \n                score = func(trial)\n                eval_count += 1\n                # Use competitive selection for replacement\n                if score < self.personal_best_scores[i] or np.random.rand() < 0.1:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = trial\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best = trial\n\n        return self.global_best, self.global_best_score", "name": "PSO_DE_Hybrid", "description": "Introduce adaptive learning factors in PSO and utilize a competitive selection mechanism in DE to enhance convergence efficiency. ", "configspace": "", "generation": 6, "fitness": 0.907376675730788, "feedback": "The algorithm PSO_DE_Hybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.907 with standard deviation 0.007. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "fd4b192d-05dd-474d-ab33-488006cce3b6", "metadata": {"aucs": [0.902831623986348, 0.901566770081411, 0.9177316331246053], "final_y": [0.11275759173483568, 0.11529811010027935, 0.11022358067344906]}, "mutation_prompt": null}
{"id": "fea00127-b2be-482d-8239-4ea7685af952", "solution": "import numpy as np\n\nclass PSO_DE_Hybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particle_count = 10\n        self.particles = np.random.rand(self.particle_count, self.dim)\n        self.velocities = np.random.rand(self.particle_count, self.dim)\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.particle_count, np.inf)\n        self.global_best = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n\n        # Initialize particles\n        for i in range(self.particle_count):\n            self.particles[i] = lb + (ub - lb) * self.particles[i]\n\n        while eval_count < self.budget:\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current particle\n                score = func(self.particles[i])\n                eval_count += 1\n\n                # Update personal and global bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions (PSO)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = 2.0 * r1 * (self.personal_best[i] - self.particles[i])\n                social = 2.0 * r2 * (self.global_best - self.particles[i])\n                phase_factor = 0.5 + 0.5 * (1 - eval_count / self.budget)  # New phase factor\n                inertia_weight = (0.9 - 0.5 * (self.personal_best_scores[i] / self.global_best_score)) * phase_factor  # Adjusted inertia\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive + social\n                # Updated velocity clamping mechanism\n                max_velocity = 0.1 * (ub - lb) \n                self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            # Differential Evolution (Mutation and Crossover)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.particle_count) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + 0.8 * (b - c), lb, ub)\n                crossover_rate = 0.5 + 0.4 * (1 - eval_count / self.budget)  # Adaptive crossover rate\n                trial = np.where(np.random.rand(self.dim) < crossover_rate, mutant, self.particles[i])\n                \n                score = func(trial)\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = trial\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best = trial\n\n            # Stochastic ranking\n            rank_prob = 0.45\n            if np.random.rand() < rank_prob and eval_count < self.budget:\n                self.particles = self.particles[np.argsort(self.personal_best_scores)]\n\n        return self.global_best, self.global_best_score", "name": "PSO_DE_Hybrid", "description": "Improve PSO-DE Hybrid by incorporating stochastic ranking within selection to balance exploration and exploitation more effectively.", "configspace": "", "generation": 6, "fitness": 0.8986969552802289, "feedback": "The algorithm PSO_DE_Hybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.899 with standard deviation 0.009. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "1e392880-6fb4-4f92-9a03-8a9e965150cb", "metadata": {"aucs": [0.8874731069283235, 0.8979930545668322, 0.9106247043455308], "final_y": [0.11725510563745867, 0.11654400958575661, 0.1123608290975312]}, "mutation_prompt": null}
{"id": "30540104-c0a7-49c2-8092-c3e7742b1f04", "solution": "import numpy as np\n\nclass PSO_DE_Hybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particle_count = 10\n        self.particles = np.random.rand(self.particle_count, self.dim)\n        self.velocities = np.random.rand(self.particle_count, self.dim)\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.particle_count, np.inf)\n        self.global_best = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n\n        # Initialize particles\n        for i in range(self.particle_count):\n            self.particles[i] = lb + (ub - lb) * self.particles[i]\n\n        while eval_count < self.budget:\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current particle\n                score = func(self.particles[i])\n                eval_count += 1\n\n                # Update personal and global bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions (PSO)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = 2.0 * r1 * (self.personal_best[i] - self.particles[i])\n                social = 2.0 * r2 * (self.global_best - self.particles[i])\n                phase_factor = 0.5 + 0.5 * (1 - eval_count / self.budget)  # New phase factor\n                inertia_weight = (0.9 - 0.5 * (self.personal_best_scores[i] / self.global_best_score)) * phase_factor  # Adjusted inertia\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive + social\n                # Updated velocity clamping mechanism\n                max_velocity = 0.1 * (ub - lb) \n                self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            # Differential Evolution (Mutation and Crossover)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.particle_count) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + 0.8 * (b - c), lb, ub)\n                crossover_rate = 0.5 + 0.4 * (1 - eval_count / self.budget)  # Adaptive crossover rate\n                trial = np.where(np.random.rand(self.dim) < crossover_rate, mutant, self.particles[i])\n                \n                score = func(trial)\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = trial\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best = trial\n\n            # Dynamically adjust particle count\n            if eval_count % (self.budget // 10) == 0 and eval_count > 0:\n                self.particle_count = max(5, int(0.9 * self.particle_count))\n\n        return self.global_best, self.global_best_score", "name": "PSO_DE_Hybrid", "description": "Introduce a dynamic particle count adjustment mechanism by modifying particle count based on performance improvement, enhancing exploration and convergence.  ", "configspace": "", "generation": 6, "fitness": 0.8988014441711213, "feedback": "The algorithm PSO_DE_Hybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.899 with standard deviation 0.015. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "1e392880-6fb4-4f92-9a03-8a9e965150cb", "metadata": {"aucs": [0.8778743438077811, 0.9094125040330692, 0.9091174846725133], "final_y": [0.11986329308686772, 0.11624333032653877, 0.11237625590918687]}, "mutation_prompt": null}
{"id": "45129461-bb34-406f-b572-526c2c477a85", "solution": "import numpy as np\n\nclass PSO_DE_Hybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particle_count = min(20, 5 + dim)  # Dynamic particle count\n        self.particles = np.random.rand(self.particle_count, self.dim)\n        self.velocities = np.random.rand(self.particle_count, self.dim)\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.particle_count, np.inf)\n        self.global_best = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n\n        # Initialize particles\n        for i in range(self.particle_count):\n            self.particles[i] = lb + (ub - lb) * self.particles[i]\n\n        while eval_count < self.budget:\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current particle\n                score = func(self.particles[i])\n                eval_count += 1\n\n                # Update personal and global bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions (PSO)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = 2.0 * r1 * (self.personal_best[i] - self.particles[i])\n                social = 2.0 * r2 * (self.global_best - self.particles[i])\n                phase_factor = 0.5 + 0.5 * (1 - eval_count / self.budget)  # New phase factor\n                inertia_weight = 0.9 - 0.4 * (eval_count / self.budget)  # Dynamic inertia weight adjustment\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive + social\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            # Differential Evolution (Mutation and Crossover)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.particle_count) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                F = 0.7 + 0.3 * (eval_count / self.budget)  # Adaptive mutation factor\n                mutant = np.clip(a + F * (b - c), lb, ub)\n                crossover_rate = 0.5 + 0.4 * (1 - eval_count / self.budget)  # Adaptive crossover rate\n                trial = np.where(np.random.rand(self.dim) < crossover_rate, mutant, self.particles[i])\n                \n                score = func(trial)\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = trial\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best = trial\n\n        return self.global_best, self.global_best_score", "name": "PSO_DE_Hybrid", "description": "Introduce a dynamic inertia weight adjustment to balance exploration and exploitation more effectively by modifying the inertia weight calculation.", "configspace": "", "generation": 6, "fitness": 0.8934043049544039, "feedback": "The algorithm PSO_DE_Hybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.893 with standard deviation 0.040. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "fd4b192d-05dd-474d-ab33-488006cce3b6", "metadata": {"aucs": [0.8376393022710417, 0.9173799617620719, 0.9251936508300986], "final_y": [0.1299939169379981, 0.11242358126583474, 0.1100854569816222]}, "mutation_prompt": null}
{"id": "c22221e4-5bc8-440d-8111-6fce49e07ae7", "solution": "import numpy as np\n\nclass PSO_DE_Hybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particle_count = min(20, 5 + dim)  # Dynamic particle count\n        self.particles = np.random.rand(self.particle_count, self.dim)\n        self.velocities = np.random.rand(self.particle_count, self.dim)\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.particle_count, np.inf)\n        self.global_best = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n\n        # Initialize particles\n        for i in range(self.particle_count):\n            self.particles[i] = lb + (ub - lb) * self.particles[i]\n\n        while eval_count < self.budget:\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current particle\n                score = func(self.particles[i])\n                eval_count += 1\n\n                # Update personal and global bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions (PSO)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = 2.0 * r1 * (self.personal_best[i] - self.particles[i])\n                social = 2.0 * r2 * (self.global_best - self.particles[i])\n                phase_factor = 0.5 + 0.5 * (1 - eval_count / self.budget)  # New phase factor\n                inertia_weight = (0.9 - 0.5 * (self.personal_best_scores[i] / self.global_best_score)) * phase_factor  # Adjusted inertia\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive + social\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            # Differential Evolution (Mutation and Crossover)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.particle_count) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                F = 0.7 + 0.3 * (eval_count / self.budget)  # Adaptive mutation factor\n                mutant = np.clip(a + F * (b - c), lb, ub)\n                crossover_rate = 0.5 + 0.4 * (1 - eval_count / self.budget)  # Adaptive crossover rate\n                trial = np.where(np.random.rand(self.dim) < crossover_rate, mutant, self.particles[i])\n                \n                score = func(trial)\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = trial\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best = trial\n\n            # Dynamically adjust particle count based on convergence\n            if eval_count % (self.budget // 10) == 0 and eval_count < self.budget * 0.8:\n                self.particle_count = max(10, self.particle_count - 1)  # Reduce particle count to focus on exploitation\n\n        return self.global_best, self.global_best_score", "name": "PSO_DE_Hybrid", "description": "Improve the PSO-DE Hybrid by dynamically adjusting the particle count based on convergence speed for enhanced adaptability and convergence.", "configspace": "", "generation": 6, "fitness": 0.893260439330431, "feedback": "The algorithm PSO_DE_Hybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.893 with standard deviation 0.022. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "fd4b192d-05dd-474d-ab33-488006cce3b6", "metadata": {"aucs": [0.8637476691817544, 0.9011682470486755, 0.9148654017608633], "final_y": [0.13036902890073065, 0.11623485321904803, 0.11210758453945768]}, "mutation_prompt": null}
{"id": "9e0ed135-91b4-4b74-a3eb-f8eb92a4ea55", "solution": "import numpy as np\n\nclass PSO_DE_Hybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particle_count = 10\n        self.particles = np.random.rand(self.particle_count, self.dim)\n        self.velocities = np.random.rand(self.particle_count, self.dim)\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.particle_count, np.inf)\n        self.global_best = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n\n        # Initialize particles\n        for i in range(self.particle_count):\n            self.particles[i] = lb + (ub - lb) * self.particles[i]\n\n        while eval_count < self.budget:\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current particle\n                score = func(self.particles[i])\n                eval_count += 1\n\n                # Update personal and global bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions (PSO)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = 2.0 * r1 * (self.personal_best[i] - self.particles[i])\n                social = 2.0 * r2 * (self.global_best - self.particles[i])\n                phase_factor = 0.5 + 0.5 * (1 - eval_count / self.budget)  # New phase factor\n                inertia_weight = (0.99 - 0.5 * (self.personal_best_scores[i] / self.global_best_score)) * phase_factor  # Adjusted inertia\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive + social\n                # Updated velocity clamping mechanism\n                max_velocity = 0.1 * (ub - lb) \n                self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            # Differential Evolution (Mutation and Crossover)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.particle_count) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + 0.85 * (b - c), lb, ub)\n                crossover_rate = 0.5 + 0.4 * (1 - eval_count / self.budget)  # Adaptive crossover rate\n                trial = np.where(np.random.rand(self.dim) < crossover_rate, mutant, self.particles[i])\n                \n                score = func(trial)\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = trial\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best = trial\n\n        return self.global_best, self.global_best_score", "name": "PSO_DE_Hybrid", "description": "Enhance the adaptive mutation strategy and inertia weight adjustment for improved exploration and convergence.", "configspace": "", "generation": 6, "fitness": 0.9085670247708615, "feedback": "The algorithm PSO_DE_Hybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.909 with standard deviation 0.009. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "1e392880-6fb4-4f92-9a03-8a9e965150cb", "metadata": {"aucs": [0.9029730739663389, 0.9017231795534113, 0.9210048207928345], "final_y": [0.11583740397689224, 0.11626850678961131, 0.11248250663873327]}, "mutation_prompt": null}
{"id": "4cd31bab-aa8d-4c0c-8e30-fb3cf2725148", "solution": "import numpy as np\n\nclass PSO_DE_Hybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particle_count = min(20, 5 + dim)  # Dynamic particle count\n        self.particles = np.random.rand(self.particle_count, self.dim)\n        self.velocities = np.random.rand(self.particle_count, self.dim)\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.particle_count, np.inf)\n        self.global_best = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n\n        # Initialize particles\n        for i in range(self.particle_count):\n            self.particles[i] = lb + (ub - lb) * self.particles[i]\n\n        while eval_count < self.budget:\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current particle\n                score = func(self.particles[i])\n                eval_count += 1\n\n                # Update personal and global bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions (PSO)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = 2.0 * r1 * (self.personal_best[i] - self.particles[i])\n                social = 2.0 * r2 * (self.global_best - self.particles[i])\n                phase_factor = 0.5 + 0.5 * (1 - eval_count / self.budget)  # New phase factor\n                inertia_weight = (0.9 - 0.5 * (self.personal_best_scores[i] / self.global_best_score)) * phase_factor  # Adjusted inertia\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive + social\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            # Differential Evolution (Mutation and Crossover)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.particle_count) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                F = 0.7 + 0.3 * np.sin(eval_count * np.pi / self.budget)  # Sinusoidal adaptive mutation factor\n                mutant = np.clip(a + F * (b - c), lb, ub)\n                crossover_rate = 0.5 + 0.4 * (1 - eval_count / self.budget)  # Adaptive crossover rate\n                trial = np.where(np.random.rand(self.dim) < crossover_rate, mutant, self.particles[i])\n                \n                score = func(trial)\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = trial\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best = trial\n\n        return self.global_best, self.global_best_score", "name": "PSO_DE_Hybrid", "description": "Enhance the PSO-DE Hybrid by modifying the adaptive mutation factor to incorporate a sinusoidal variation for better exploration.", "configspace": "", "generation": 6, "fitness": 0.8996330146489256, "feedback": "The algorithm PSO_DE_Hybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.900 with standard deviation 0.020. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "fd4b192d-05dd-474d-ab33-488006cce3b6", "metadata": {"aucs": [0.8748825381295445, 0.899185757282758, 0.9248307485344746], "final_y": [0.12168552943343702, 0.11622940951838445, 0.10974683880414571]}, "mutation_prompt": null}
{"id": "901d782f-9a2f-4589-b899-b9f4bc83339c", "solution": "import numpy as np\n\nclass PSO_DE_Hybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particle_count = 10\n        self.particles = np.random.rand(self.particle_count, self.dim)\n        self.velocities = np.random.rand(self.particle_count, self.dim)\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.particle_count, np.inf)\n        self.global_best = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n\n        # Initialize particles\n        for i in range(self.particle_count):\n            self.particles[i] = lb + (ub - lb) * self.particles[i]\n\n        while eval_count < self.budget:\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current particle\n                score = func(self.particles[i])\n                eval_count += 1\n\n                # Update personal and global bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions (PSO)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = 2.0 * r1 * (self.personal_best[i] - self.particles[i])\n                social = 2.0 * r2 * (self.global_best - self.particles[i])\n                phase_factor = 0.5 + 0.5 * (1 - eval_count / self.budget)  # New phase factor\n                inertia_weight = (0.9 - 0.5 * (self.personal_best_scores[i] / self.global_best_score)) * phase_factor  # Adjusted inertia\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive + social\n                # Updated velocity clamping mechanism\n                max_velocity = 0.1 * (ub - lb) \n                self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            # Differential Evolution (Mutation and Crossover)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.particle_count) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + 0.8 * (b - c), lb, ub)\n                crossover_rate = 0.3 + 0.5 * (1 - eval_count / self.budget)  # More dynamic adaptive crossover rate\n                trial = np.where(np.random.rand(self.dim) < crossover_rate, mutant, self.particles[i])\n                \n                score = func(trial)\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = trial\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best = trial\n\n        return self.global_best, self.global_best_score", "name": "PSO_DE_Hybrid", "description": "Enhance the algorithm by refining the adaptive crossover rate to a more dynamic range, improving exploitation capabilities.", "configspace": "", "generation": 6, "fitness": 0.9031385054913761, "feedback": "The algorithm PSO_DE_Hybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.903 with standard deviation 0.010. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "1e392880-6fb4-4f92-9a03-8a9e965150cb", "metadata": {"aucs": [0.8924400050331618, 0.90099331901156, 0.9159821924294066], "final_y": [0.11675529483600722, 0.11644687373156604, 0.11253141701637248]}, "mutation_prompt": null}
{"id": "d8769b1c-eb89-41d4-9d5f-883adc3f3e26", "solution": "import numpy as np\n\nclass PSO_DE_Hybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particle_count = 10\n        self.particles = np.random.rand(self.particle_count, self.dim)\n        self.velocities = np.random.rand(self.particle_count, self.dim)\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.particle_count, np.inf)\n        self.global_best = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n\n        # Initialize particles\n        for i in range(self.particle_count):\n            self.particles[i] = lb + (ub - lb) * self.particles[i]\n\n        while eval_count < self.budget:\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current particle\n                score = func(self.particles[i])\n                eval_count += 1\n\n                # Update personal and global bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions (PSO)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = 2.0 * r1 * (self.personal_best[i] - self.particles[i])\n                social = 2.0 * r2 * (self.global_best - self.particles[i])\n                phase_factor = 0.5 + 0.5 * (1 - eval_count / self.budget)  # New phase factor\n                inertia_weight = (0.99 - 0.5 * (self.personal_best_scores[i] / self.global_best_score)) * phase_factor  # Adjusted inertia\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive + social\n                # Updated velocity clamping mechanism\n                max_velocity = 0.1 * (ub - lb) \n                self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            # Differential Evolution (Mutation and Crossover)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.particle_count) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + np.random.uniform(0.6, 0.9) * (b - c), lb, ub)  # Adaptive dynamic coefficient\n                tournament = np.random.choice(idxs, 2, p=[0.5, 0.5])  # Tournament selection\n                if self.personal_best_scores[tournament[0]] < self.personal_best_scores[tournament[1]]:\n                    trial = self.personal_best[tournament[0]]\n                else:\n                    trial = self.personal_best[tournament[1]]\n                crossover_rate = 0.5 + 0.4 * (1 - eval_count / self.budget)  # Adaptive crossover rate\n                trial = np.where(np.random.rand(self.dim) < crossover_rate, mutant, self.particles[i])\n                \n                score = func(trial)\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = trial\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best = trial\n\n        return self.global_best, self.global_best_score", "name": "PSO_DE_Hybrid", "description": "Introduce adaptive dynamic coefficient and tournament selection to enhance diversity and exploitation in PSO-DE Hybrid.", "configspace": "", "generation": 7, "fitness": -Infinity, "feedback": "An exception occurred: ValueError(\"'a' and 'p' must have same size\").", "error": "ValueError(\"'a' and 'p' must have same size\")", "parent_id": "9e0ed135-91b4-4b74-a3eb-f8eb92a4ea55", "metadata": {}, "mutation_prompt": null}
{"id": "e3ada2fc-cdcb-4924-bee8-c403bd9d9385", "solution": "import numpy as np\n\nclass PSO_DE_Hybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particle_count = 10\n        self.particles = np.random.rand(self.particle_count, self.dim)\n        self.velocities = np.random.rand(self.particle_count, self.dim)\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.particle_count, np.inf)\n        self.global_best = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n\n        # Initialize particles\n        for i in range(self.particle_count):\n            self.particles[i] = lb + (ub - lb) * self.particles[i]\n\n        while eval_count < self.budget:\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current particle\n                score = func(self.particles[i])\n                eval_count += 1\n\n                # Update personal and global bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions (PSO)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = 2.0 * r1 * (self.personal_best[i] - self.particles[i])\n                social = 2.0 * r2 * (self.global_best - self.particles[i])\n                phase_factor = 0.5 + 0.5 * (1 - eval_count / self.budget)  # New phase factor\n                inertia_weight = (0.99 - 0.5 * (self.personal_best_scores[i] / self.global_best_score)) * phase_factor  # Adjusted inertia\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive + social\n                # Updated velocity clamping mechanism\n                max_velocity = 0.1 * (ub - lb) \n                self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            # Differential Evolution (Mutation and Crossover)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.particle_count) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + 0.85 * (b - c), lb, ub)\n                crossover_rate = 0.5 + 0.4 * (1 - eval_count / self.budget)  # Adaptive crossover rate\n                trial = np.where(np.random.rand(self.dim) < crossover_rate, mutant, self.particles[i])\n                \n                score = func(trial)\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = trial\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best = trial\n\n            # Dynamically adjust particle count\n            self.particle_count = max(5, self.particle_count + int(np.random.choice([-1, 1])))\n\n        return self.global_best, self.global_best_score", "name": "PSO_DE_Hybrid", "description": "Introduce dynamic particle count adjustment to enhance flexibility and efficiency in exploration and convergence.", "configspace": "", "generation": 7, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 10 is out of bounds for axis 0 with size 10').", "error": "IndexError('index 10 is out of bounds for axis 0 with size 10')", "parent_id": "9e0ed135-91b4-4b74-a3eb-f8eb92a4ea55", "metadata": {}, "mutation_prompt": null}
{"id": "37c241fb-caef-4753-b3ce-b454420315b2", "solution": "import numpy as np\n\nclass PSO_DE_Hybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particle_count = min(20, 5 + dim)  # Dynamic particle count\n        self.particles = np.random.rand(self.particle_count, self.dim)\n        self.velocities = np.random.rand(self.particle_count, self.dim)\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.particle_count, np.inf)\n        self.global_best = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n\n        # Initialize particles\n        for i in range(self.particle_count):\n            self.particles[i] = lb + (ub - lb) * self.particles[i]\n\n        while eval_count < self.budget:\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current particle\n                score = func(self.particles[i])\n                eval_count += 1\n\n                # Update personal and global bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions (PSO)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                C1 = 1.5 + 0.5 * (eval_count / self.budget)  # Adaptive cognitive factor\n                C2 = 1.5 + 0.5 * (1 - eval_count / self.budget)  # Adaptive social factor\n                cognitive = C1 * r1 * (self.personal_best[i] - self.particles[i])\n                social = C2 * r2 * (self.global_best - self.particles[i])\n                phase_factor = 0.5 + 0.5 * (1 - eval_count / self.budget)  # New phase factor\n                inertia_weight = (0.9 - 0.5 * (self.personal_best_scores[i] / self.global_best_score)) * (0.95 ** (eval_count / self.budget))  # Adjusted inertia with damping\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive + social\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            # Differential Evolution (Mutation and Crossover)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.particle_count) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                F = 0.7 + 0.3 * (eval_count / self.budget)  # Adaptive mutation factor\n                mutant = np.clip(a + F * (b - c), lb, ub)\n                crossover_rate = 0.5 + 0.4 * (1 - eval_count / self.budget)  # Adaptive crossover rate\n                trial = np.where(np.random.rand(self.dim) < crossover_rate, mutant, self.particles[i])\n                \n                score = func(trial)\n                eval_count += 1\n                # Use competitive selection for replacement\n                if score < self.personal_best_scores[i] or np.random.rand() < 0.1:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = trial\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best = trial\n\n        return self.global_best, self.global_best_score", "name": "PSO_DE_Hybrid", "description": "Introduce an adaptive inertia damping mechanism to balance exploration and exploitation over time.", "configspace": "", "generation": 7, "fitness": 0.8877948744757941, "feedback": "The algorithm PSO_DE_Hybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.888 with standard deviation 0.027. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "742f49c2-4326-4d75-bcdb-4ceb962ef3d0", "metadata": {"aucs": [0.8499232363286958, 0.9001001981864843, 0.9133611889122023], "final_y": [0.13279980322336737, 0.11627043936275694, 0.11253727611092723]}, "mutation_prompt": null}
{"id": "5a46038b-881e-4139-b3f0-53c5b9d0a12d", "solution": "import numpy as np\n\nclass PSO_DE_Hybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particle_count = 10\n        self.particles = np.random.rand(self.particle_count, self.dim)\n        self.velocities = np.random.rand(self.particle_count, self.dim)\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.particle_count, np.inf)\n        self.global_best = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n\n        # Initialize particles\n        for i in range(self.particle_count):\n            self.particles[i] = lb + (ub - lb) * self.particles[i]\n\n        while eval_count < self.budget:\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current particle\n                score = func(self.particles[i])\n                eval_count += 1\n\n                # Update personal and global bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions (PSO)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = 2.0 * r1 * (self.personal_best[i] - self.particles[i])\n                social = 2.0 * r2 * (self.global_best - self.particles[i]) * (1 - eval_count / self.budget)  # Dynamic social factor\n                phase_factor = 0.5 + 0.5 * (1 - eval_count / self.budget)  # New phase factor\n                inertia_weight = (0.99 - 0.5 * (self.personal_best_scores[i] / self.global_best_score)) * phase_factor  # Adjusted inertia\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive + social\n                # Updated velocity clamping mechanism\n                max_velocity = 0.1 * (ub - lb) \n                self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            # Differential Evolution (Mutation and Crossover)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.particle_count) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + 0.85 * (b - c), lb, ub)\n                crossover_rate = 0.5 + 0.4 * (1 - eval_count / self.budget)  # Adaptive crossover rate\n                trial = np.where(np.random.rand(self.dim) < crossover_rate, mutant, self.particles[i])\n                \n                score = func(trial)\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = trial\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best = trial\n\n        return self.global_best, self.global_best_score", "name": "PSO_DE_Hybrid", "description": "Update the velocity calculation in PSO with a dynamic social factor based on convergence progress.", "configspace": "", "generation": 7, "fitness": 0.8949046731977561, "feedback": "The algorithm PSO_DE_Hybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.895 with standard deviation 0.015. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "9e0ed135-91b4-4b74-a3eb-f8eb92a4ea55", "metadata": {"aucs": [0.8738172678066812, 0.9012949450415039, 0.9096018067450833], "final_y": [0.12142981710410594, 0.11622771920977704, 0.1121808613355082]}, "mutation_prompt": null}
{"id": "c981e2d6-676b-43e7-98ca-ad6c3cacfeaa", "solution": "import numpy as np\n\nclass PSO_DE_Hybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particle_count = 10\n        self.particles = np.random.rand(self.particle_count, self.dim)\n        self.velocities = np.random.rand(self.particle_count, self.dim)\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.particle_count, np.inf)\n        self.global_best = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n\n        # Initialize particles\n        for i in range(self.particle_count):\n            self.particles[i] = lb + (ub - lb) * self.particles[i]\n\n        while eval_count < self.budget:\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current particle\n                score = func(self.particles[i])\n                eval_count += 1\n\n                # Update personal and global bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions (PSO)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = 2.0 * r1 * (self.personal_best[i] - self.particles[i])\n                social = 2.0 * r2 * (self.global_best - self.particles[i])\n                phase_factor = 0.5 + 0.5 * (1 - eval_count / self.budget)  # New phase factor\n                inertia_weight = (0.5 + 0.4 * np.sin(np.pi * eval_count / self.budget))  # Adjusted inertia\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive + social\n                # Updated velocity clamping mechanism\n                max_velocity = 0.1 * (ub - lb) + 0.05 * (ub - lb) * np.cos(np.pi * eval_count / self.budget)\n                self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            # Differential Evolution (Mutation and Crossover)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.particle_count) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + 0.85 * (b - c), lb, ub)\n                crossover_rate = 0.5 + 0.4 * (1 - eval_count / self.budget)  # Adaptive crossover rate\n                trial = np.where(np.random.rand(self.dim) < crossover_rate, mutant, self.particles[i])\n                \n                score = func(trial)\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = trial\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best = trial\n\n        return self.global_best, self.global_best_score", "name": "PSO_DE_Hybrid", "description": "Introduce a more dynamic inertia weight adjustment and adaptive velocity clamping to enhance the convergence speed and exploration capability.", "configspace": "", "generation": 7, "fitness": 0.910778449414167, "feedback": "The algorithm PSO_DE_Hybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.911 with standard deviation 0.006. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "9e0ed135-91b4-4b74-a3eb-f8eb92a4ea55", "metadata": {"aucs": [0.9022697845763545, 0.9132529243975517, 0.9168126392685948], "final_y": [0.11652412785229938, 0.11178797702916976, 0.11154277712625549]}, "mutation_prompt": null}
{"id": "b76b214f-ae9d-4af0-8b76-893fb95803fa", "solution": "import numpy as np\n\nclass PSO_DE_Hybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particle_count = min(20, 5 + dim)  # Dynamic particle count\n        self.particles = np.random.rand(self.particle_count, self.dim)\n        self.velocities = np.random.rand(self.particle_count, self.dim)\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.particle_count, np.inf)\n        self.global_best = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n\n        # Initialize particles\n        for i in range(self.particle_count):\n            self.particles[i] = lb + (ub - lb) * self.particles[i]\n\n        while eval_count < self.budget:\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current particle\n                score = func(self.particles[i])\n                eval_count += 1\n\n                # Update personal and global bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions (PSO)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                C1 = 1.5 + 0.5 * (eval_count / self.budget)\n                C2 = 1.5 + 0.5 * (1 - eval_count / self.budget)\n                cognitive = C1 * r1 * (self.personal_best[i] - self.particles[i])\n                social = C2 * r2 * (self.global_best - self.particles[i])\n                phase_factor = 0.5 + 0.5 * (1 - eval_count / self.budget)\n                inertia_weight = 0.9 - 0.4 * (eval_count / self.budget)  # Adaptive inertia reduction\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive + social\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            # Differential Evolution (Mutation and Crossover)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.particle_count) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                F = 0.7 + 0.3 * (eval_count / self.budget)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n                crossover_rate = 0.3 + 0.7 * (eval_count / self.budget)  # Dynamic crossover strategy\n                trial = np.where(np.random.rand(self.dim) < crossover_rate, mutant, self.particles[i])\n                \n                score = func(trial)\n                eval_count += 1\n                # Use competitive selection for replacement\n                if score < self.personal_best_scores[i] or np.random.rand() < 0.1:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = trial\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best = trial\n\n        return self.global_best, self.global_best_score", "name": "PSO_DE_Hybrid", "description": "Enhance the hybrid PSO-DE strategy by introducing adaptive inertia reduction and a dynamic crossover strategy to improve convergence and solution diversity.", "configspace": "", "generation": 7, "fitness": 0.8760662155087222, "feedback": "The algorithm PSO_DE_Hybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.876 with standard deviation 0.026. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "742f49c2-4326-4d75-bcdb-4ceb962ef3d0", "metadata": {"aucs": [0.8476247440432783, 0.9103012387696277, 0.8702726637132608], "final_y": [0.13767227144026128, 0.11623877482958123, 0.11970404828275216]}, "mutation_prompt": null}
{"id": "fa9dae2e-eab1-420e-9b5e-00141e804a74", "solution": "import numpy as np\n\nclass PSO_DE_Hybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particle_count = 10\n        self.particles = np.random.rand(self.particle_count, self.dim)\n        self.velocities = np.random.rand(self.particle_count, self.dim)\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.particle_count, np.inf)\n        self.global_best = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n\n        # Initialize particles\n        for i in range(self.particle_count):\n            self.particles[i] = lb + (ub - lb) * self.particles[i]\n\n        while eval_count < self.budget:\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current particle\n                score = func(self.particles[i])\n                eval_count += 1\n\n                # Update personal and global bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions (PSO)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                # Adaptive learning factors\n                cognitive = (1.5 + 0.5 * (eval_count / self.budget)) * r1 * (self.personal_best[i] - self.particles[i])\n                social = (1.5 + 0.5 * (eval_count / self.budget)) * r2 * (self.global_best - self.particles[i])\n                phase_factor = 0.5 + 0.5 * (1 - eval_count / self.budget)  # New phase factor\n                inertia_weight = (0.99 - 0.5 * (self.personal_best_scores[i] / self.global_best_score)) * phase_factor  # Adjusted inertia\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive + social\n                # Updated velocity clamping mechanism\n                max_velocity = 0.1 * (ub - lb) \n                self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            # Differential Evolution (Mutation and Crossover)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.particle_count) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                # Diversified mutation strategy\n                mutant = np.clip(a + np.random.uniform(0.7, 0.9) * (b - c), lb, ub)\n                crossover_rate = 0.5 + 0.4 * (1 - eval_count / self.budget)  # Adaptive crossover rate\n                trial = np.where(np.random.rand(self.dim) < crossover_rate, mutant, self.particles[i])\n                \n                score = func(trial)\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = trial\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best = trial\n\n        return self.global_best, self.global_best_score", "name": "PSO_DE_Hybrid", "description": "Enhance PSO component with adaptive learning rates and diversify DE mutation strategy for improved convergence and solution quality.", "configspace": "", "generation": 7, "fitness": 0.8980472916903707, "feedback": "The algorithm PSO_DE_Hybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.898 with standard deviation 0.015. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "9e0ed135-91b4-4b74-a3eb-f8eb92a4ea55", "metadata": {"aucs": [0.8780020359217151, 0.9006951495374256, 0.9154446896119715], "final_y": [0.12344217186568274, 0.11621820332075827, 0.11210796812550694]}, "mutation_prompt": null}
{"id": "6f3fa924-6e16-4a15-ae3b-acbbca6873e1", "solution": "import numpy as np\n\nclass PSO_DE_Hybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particle_count = min(20, 5 + dim)  # Dynamic particle count\n        self.particles = np.random.rand(self.particle_count, self.dim)\n        self.velocities = np.random.rand(self.particle_count, self.dim)\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.particle_count, np.inf)\n        self.global_best = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n\n        # Initialize particles\n        for i in range(self.particle_count):\n            self.particles[i] = lb + (ub - lb) * self.particles[i]\n\n        while eval_count < self.budget:\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current particle\n                score = func(self.particles[i])\n                eval_count += 1\n\n                # Update personal and global bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions (PSO)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                C1 = 1.5 + 0.5 * (eval_count / self.budget)  # Adaptive cognitive factor\n                C2 = 1.5 + 0.5 * (1 - eval_count / self.budget)  # Adaptive social factor\n                cognitive = C1 * r1 * (self.personal_best[i] - self.particles[i])\n                social = C2 * r2 * (self.global_best - self.particles[i])\n                phase_factor = 0.5 + 0.5 * (1 - eval_count / self.budget)  # New phase factor\n                inertia_weight = (0.9 - 0.5 * (self.personal_best_scores[i] / self.global_best_score)) * phase_factor  # Adjusted inertia\n                noise = np.random.normal(0, 0.1, self.dim)  # Added stochastic noise\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive + social + noise\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            # Differential Evolution (Mutation and Crossover)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.particle_count) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                F = 0.7 + 0.3 * (eval_count / self.budget)  # Adaptive mutation factor\n                mutant = np.clip(a + F * (b - c), lb, ub)\n                noise = np.random.normal(0, 0.1, self.dim)  # Added stochastic noise\n                crossover_rate = 0.5 + 0.4 * (1 - eval_count / self.budget)  # Adaptive crossover rate\n                trial = np.where(np.random.rand(self.dim) < crossover_rate, mutant + noise, self.particles[i])\n                \n                score = func(trial)\n                eval_count += 1\n                # Use competitive selection for replacement\n                if score < self.personal_best_scores[i] or np.random.rand() < 0.1:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = trial\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best = trial\n\n        return self.global_best, self.global_best_score", "name": "PSO_DE_Hybrid", "description": "Incorporate stochastic perturbations in velocities and trial vectors to enhance diversity and escape local optima.", "configspace": "", "generation": 7, "fitness": 0.8674018285744248, "feedback": "The algorithm PSO_DE_Hybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.867 with standard deviation 0.024. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "742f49c2-4326-4d75-bcdb-4ceb962ef3d0", "metadata": {"aucs": [0.8433051704948005, 0.900966300695893, 0.8579340145325813], "final_y": [0.13392679433810717, 0.11635423098376196, 0.12414254874186992]}, "mutation_prompt": null}
{"id": "a100de28-9150-4daf-a25e-30a14206d7ec", "solution": "import numpy as np\n\nclass PSO_DE_Hybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particle_count = max(10, int(dim * 1.5))  # Dynamic particle count\n        self.particles = np.random.rand(self.particle_count, self.dim)\n        self.velocities = np.random.rand(self.particle_count, self.dim)\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.particle_count, np.inf)\n        self.global_best = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n\n        # Initialize particles\n        for i in range(self.particle_count):\n            self.particles[i] = lb + (ub - lb) * self.particles[i]\n\n        while eval_count < self.budget:\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current particle\n                score = func(self.particles[i])\n                eval_count += 1\n\n                # Update personal and global bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions (PSO)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = 2.0 * r1 * (self.personal_best[i] - self.particles[i])\n                social = 2.0 * r2 * (self.global_best - self.particles[i])\n                phase_factor = 0.5 + 0.5 * (1 - eval_count / self.budget)  # New phase factor\n                inertia_weight = 0.9 + 0.09 * np.sin(eval_count / self.budget * np.pi)  # Adaptive inertia weight\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive + social\n                # Updated velocity clamping mechanism\n                max_velocity = 0.1 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            # Differential Evolution (Mutation and Crossover)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.particle_count) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + 0.85 * (b - c), lb, ub)\n                crossover_rate = 0.5 + 0.4 * (1 - eval_count / self.budget)  # Adaptive crossover rate\n                trial = np.where(np.random.rand(self.dim) < crossover_rate, mutant, self.particles[i])\n                \n                score = func(trial)\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = trial\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best = trial\n\n        return self.global_best, self.global_best_score", "name": "PSO_DE_Hybrid", "description": "Introduce dynamic particle count and an adaptive inertia weight schedule to enhance exploration and convergence balance.", "configspace": "", "generation": 7, "fitness": 0.9010125925610106, "feedback": "The algorithm PSO_DE_Hybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.901 with standard deviation 0.012. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "9e0ed135-91b4-4b74-a3eb-f8eb92a4ea55", "metadata": {"aucs": [0.8906026240064904, 0.8944965874777953, 0.9179385661987465], "final_y": [0.1151178176222104, 0.11654863447037977, 0.11041333595262037]}, "mutation_prompt": null}
{"id": "3647216f-e178-4064-a770-74aa1b83d6db", "solution": "import numpy as np\n\nclass PSO_DE_Hybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particle_count = min(20, 5 + dim)  # Dynamic particle count\n        self.particles = np.random.rand(self.particle_count, self.dim)\n        self.velocities = np.random.rand(self.particle_count, self.dim)\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.particle_count, np.inf)\n        self.global_best = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n\n        # Initialize particles\n        for i in range(self.particle_count):\n            self.particles[i] = lb + (ub - lb) * self.particles[i]\n\n        while eval_count < self.budget:\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current particle\n                score = func(self.particles[i])\n                eval_count += 1\n\n                # Update personal and global bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions (PSO)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                C1 = 1.5 + 0.5 * (eval_count / self.budget)  # Adaptive cognitive factor\n                C2 = 1.5 + 0.5 * (1 - eval_count / self.budget)  # Adaptive social factor\n                cognitive = C1 * r1 * (self.personal_best[i] - self.particles[i])\n                social = C2 * r2 * (self.global_best - self.particles[i])\n                neighborhood_influence = 0.1 * np.mean(self.particles, axis=0)  # Dynamic neighborhood influence\n                phase_factor = 0.5 + 0.5 * (1 - eval_count / self.budget)  # New phase factor\n                inertia_weight = (0.9 - 0.5 * (self.personal_best_scores[i] / self.global_best_score)) * phase_factor\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive + social + neighborhood_influence\n                vel_clamp = 0.1 * (ub - lb)  # Adaptive velocity clamping\n                self.velocities[i] = np.clip(self.velocities[i], -vel_clamp, vel_clamp)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            # Differential Evolution (Mutation and Crossover)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.particle_count) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                F = 0.7 + 0.3 * (eval_count / self.budget)  # Adaptive mutation factor\n                mutant = np.clip(a + F * (b - c), lb, ub)\n                crossover_rate = 0.5 + 0.4 * (1 - eval_count / self.budget)  # Adaptive crossover rate\n                trial = np.where(np.random.rand(self.dim) < crossover_rate, mutant, self.particles[i])\n                \n                score = func(trial)\n                eval_count += 1\n                # Use competitive selection for replacement\n                if score < self.personal_best_scores[i] or np.random.rand() < 0.1:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = trial\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best = trial\n\n        return self.global_best, self.global_best_score", "name": "PSO_DE_Hybrid", "description": "Integrate dynamic neighborhood influence and adaptive velocity clamping for improved convergence and solution quality.", "configspace": "", "generation": 7, "fitness": 0.8709221379493061, "feedback": "The algorithm PSO_DE_Hybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.871 with standard deviation 0.056. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.019.", "error": "", "parent_id": "742f49c2-4326-4d75-bcdb-4ceb962ef3d0", "metadata": {"aucs": [0.7915844787597841, 0.9071689115178626, 0.9140130235702718], "final_y": [0.15323588784129738, 0.11621801564714129, 0.11048263327231211]}, "mutation_prompt": null}
{"id": "098a3a3e-86de-4e74-b7f0-23dcdb430c19", "solution": "import numpy as np\n\nclass PSO_DE_Hybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particle_count = 10\n        self.particles = np.random.rand(self.particle_count, self.dim)\n        self.velocities = np.random.rand(self.particle_count, self.dim)\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.particle_count, np.inf)\n        self.global_best = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n\n        # Initialize particles\n        for i in range(self.particle_count):\n            self.particles[i] = lb + (ub - lb) * self.particles[i]\n\n        while eval_count < self.budget:\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current particle\n                score = func(self.particles[i])\n                eval_count += 1\n\n                # Update personal and global bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions (PSO)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = 2.0 * r1 * (self.personal_best[i] - self.particles[i])\n                social = 2.0 * r2 * (self.global_best - self.particles[i])\n                phase_factor = 0.5 + 0.5 * (1 - eval_count / self.budget)  # New phase factor\n                inertia_weight = (0.5 + 0.4 * np.sin(np.pi * eval_count / self.budget))  # Adjusted inertia\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive + social\n                # Updated velocity clamping mechanism\n                max_velocity = 0.1 * (ub - lb) + 0.05 * (ub - lb) * np.cos(np.pi * eval_count / self.budget)\n                self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            # Differential Evolution (Mutation and Crossover)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.particle_count) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                diff_weight = 0.85 - 0.3 * (eval_count / self.budget)  # Adaptive differential weight\n                mutant = np.clip(a + diff_weight * (b - c), lb, ub)\n                crossover_rate = 0.5 + 0.4 * (1 - eval_count / self.budget)  # Adaptive crossover rate\n                trial = np.where(np.random.rand(self.dim) < crossover_rate, mutant, self.particles[i])\n                \n                score = func(trial)\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = trial\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best = trial\n\n        return self.global_best, self.global_best_score", "name": "PSO_DE_Hybrid", "description": "Introduce adaptive differential weight scaling for enhanced exploration and exploitation balance.", "configspace": "", "generation": 8, "fitness": 0.8711663917439855, "feedback": "The algorithm PSO_DE_Hybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.871 with standard deviation 0.010. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "c981e2d6-676b-43e7-98ca-ad6c3cacfeaa", "metadata": {"aucs": [0.856824985912557, 0.8765761476528682, 0.8800980416665314], "final_y": [0.13113909353196807, 0.12299064338282495, 0.12069437389582727]}, "mutation_prompt": null}
{"id": "bee748d0-2920-4e53-9083-b10ffa533583", "solution": "import numpy as np\n\nclass PSO_DE_Hybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particle_count = max(10, int(dim * 1.5))  # Dynamic particle count\n        self.particles = np.random.rand(self.particle_count, self.dim)\n        self.velocities = np.random.rand(self.particle_count, self.dim)\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.particle_count, np.inf)\n        self.global_best = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n\n        for i in range(self.particle_count):\n            self.particles[i] = lb + (ub - lb) * self.particles[i]\n\n        while eval_count < self.budget:\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                score = func(self.particles[i])\n                eval_count += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions (PSO)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = (1.5 + 1.0 * (eval_count / self.budget)) * r1 * (self.personal_best[i] - self.particles[i])  # Adaptive learning factor\n                social = (2.5 - 1.0 * (eval_count / self.budget)) * r2 * (self.global_best - self.particles[i])\n                inertia_weight = 0.9 + 0.09 * np.sin(eval_count / self.budget * np.pi)\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive + social\n                max_velocity = 0.1 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            # Differential Evolution (Mutation and Crossover)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.particle_count) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + 0.85 * (b - c) + 0.1 * (self.global_best - a), lb, ub)  # Diversified mutation strategy\n                crossover_rate = 0.5 + 0.4 * (1 - eval_count / self.budget)\n                trial = np.where(np.random.rand(self.dim) < crossover_rate, mutant, self.particles[i])\n                \n                score = func(trial)\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = trial\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best = trial\n\n        return self.global_best, self.global_best_score", "name": "PSO_DE_Hybrid", "description": "Enhance exploration and exploitation balance by introducing adaptive learning factor modulation and a diversified mutation strategy.", "configspace": "", "generation": 8, "fitness": 0.8907476857447006, "feedback": "The algorithm PSO_DE_Hybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.891 with standard deviation 0.012. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "a100de28-9150-4daf-a25e-30a14206d7ec", "metadata": {"aucs": [0.8850566549144594, 0.8803845433448698, 0.9068018589747727], "final_y": [0.11999680021747094, 0.11349340892152593, 0.11493884824965883]}, "mutation_prompt": null}
{"id": "754995bc-d0ee-4101-a87e-a662e8cb352f", "solution": "import numpy as np\n\nclass PSO_DE_Hybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particle_count = max(10, int(dim * 1.5))  # Dynamic particle count\n        self.particles = np.random.rand(self.particle_count, self.dim)\n        self.velocities = np.random.rand(self.particle_count, self.dim)\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.particle_count, np.inf)\n        self.global_best = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n\n        # Initialize particles\n        for i in range(self.particle_count):\n            self.particles[i] = lb + (ub - lb) * self.particles[i]\n\n        while eval_count < self.budget:\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current particle\n                score = func(self.particles[i])\n                eval_count += 1\n\n                # Update personal and global bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions (PSO)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = (1.5 + 0.5 * (1 - eval_count / self.budget)) * r1 * (self.personal_best[i] - self.particles[i])  # Adaptive cognitive factor\n                social = (1.5 + 0.5 * (1 - eval_count / self.budget)) * r2 * (self.global_best - self.particles[i])  # Adaptive social factor\n                phase_factor = 0.5 + 0.5 * (1 - eval_count / self.budget)  # New phase factor\n                inertia_weight = 0.9 + 0.09 * np.sin(eval_count / self.budget * np.pi)  # Adaptive inertia weight\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive + social\n                # Updated velocity clamping mechanism\n                max_velocity = 0.1 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            # Differential Evolution (Mutation and Crossover)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.particle_count) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + 0.9 * (b - c), lb, ub)  # Enhanced mutation factor\n                crossover_rate = 0.5 + 0.4 * (1 - eval_count / self.budget)  # Adaptive crossover rate\n                trial = np.where(np.random.rand(self.dim) < crossover_rate, mutant, self.particles[i])\n                \n                score = func(trial)\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = trial\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best = trial\n\n        return self.global_best, self.global_best_score", "name": "PSO_DE_Hybrid", "description": "Introduce adaptive learning factors and enhance differential mutation for improved exploration and convergence.", "configspace": "", "generation": 8, "fitness": 0.8824361696423462, "feedback": "The algorithm PSO_DE_Hybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.882 with standard deviation 0.007. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "a100de28-9150-4daf-a25e-30a14206d7ec", "metadata": {"aucs": [0.8751689298751566, 0.8914828528069332, 0.8806567262449488], "final_y": [0.12211723782497919, 0.11858571149608688, 0.11554257014963276]}, "mutation_prompt": null}
{"id": "a4372647-4f43-4e7d-ade0-c8a576fc6762", "solution": "import numpy as np\n\nclass PSO_DE_Hybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particle_count = 10\n        self.particles = np.random.rand(self.particle_count, self.dim)\n        self.velocities = np.random.rand(self.particle_count, self.dim)\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.particle_count, np.inf)\n        self.global_best = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n\n        # Chaotic initialization of particles\n        for i in range(self.particle_count):\n            self.particles[i] = lb + (ub - lb) * np.sin(np.pi * np.random.rand(self.dim))\n\n        while eval_count < self.budget:\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current particle\n                score = func(self.particles[i])\n                eval_count += 1\n\n                # Update personal and global bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions (PSO)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = 2.0 * r1 * (self.personal_best[i] - self.particles[i])\n                social = 2.0 * r2 * (self.global_best - self.particles[i])\n                phase_factor = 0.5 + 0.5 * (1 - eval_count / self.budget)\n                inertia_weight = (0.4 + 0.6 * np.exp(-5 * eval_count / self.budget))  # Nonlinear inertia\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive + social\n                max_velocity = 0.1 * (ub - lb) + 0.05 * (ub - lb) * np.cos(np.pi * eval_count / self.budget)\n                self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            # Differential Evolution (Mutation and Crossover)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.particle_count) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + 0.85 * (b - c), lb, ub)\n                crossover_rate = 0.5 + 0.4 * (1 - eval_count / self.budget)\n                trial = np.where(np.random.rand(self.dim) < crossover_rate, mutant, self.particles[i])\n                \n                score = func(trial)\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = trial\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best = trial\n\n        return self.global_best, self.global_best_score", "name": "PSO_DE_Hybrid", "description": "Introduce chaotic initialization and a nonlinear inertia weight schedule to enhance exploration and convergence.", "configspace": "", "generation": 8, "fitness": 0.8817786349775742, "feedback": "The algorithm PSO_DE_Hybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.882 with standard deviation 0.027. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "c981e2d6-676b-43e7-98ca-ad6c3cacfeaa", "metadata": {"aucs": [0.8499778443710525, 0.8801122653295823, 0.9152457952320878], "final_y": [0.13595861655369879, 0.11893324526991034, 0.11271917988117064]}, "mutation_prompt": null}
{"id": "25d7bc60-2dd9-43b9-8134-58960ff26d04", "solution": "import numpy as np\n\nclass PSO_DE_Hybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particle_count = 10\n        self.particles = np.random.rand(self.particle_count, self.dim)\n        self.velocities = np.random.rand(self.particle_count, self.dim)\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.particle_count, np.inf)\n        self.global_best = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n\n        # Initialize particles\n        for i in range(self.particle_count):\n            self.particles[i] = lb + (ub - lb) * self.particles[i]\n\n        while eval_count < self.budget:\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current particle\n                score = func(self.particles[i])\n                eval_count += 1\n\n                # Update personal and global bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions (PSO)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = 2.0 * r1 * (self.personal_best[i] - self.particles[i])\n                social = 2.0 * r2 * (self.global_best - self.particles[i])\n                phase_factor = 0.5 + 0.5 * (1 - eval_count / self.budget)  # New phase factor\n                inertia_weight = (0.5 + 0.4 * np.sin(np.pi * eval_count / self.budget))  # Adjusted inertia\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive + social\n                # Updated velocity clamping mechanism\n                max_velocity = 0.1 * (ub - lb) + 0.05 * (ub - lb) * np.cos(np.pi * eval_count / self.budget)\n                self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            # Differential Evolution (Mutation and Crossover)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.particle_count) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                mutation_factor = 0.85 + 0.15 * np.sin(2 * np.pi * eval_count / self.budget)  # Adaptive mutation factor\n                mutant = np.clip(a + mutation_factor * (b - c), lb, ub)\n                crossover_rate = 0.5 + 0.4 * (1 - eval_count / self.budget)  # Adaptive crossover rate\n                trial = np.where(np.random.rand(self.dim) < crossover_rate, mutant, self.particles[i])\n                \n                score = func(trial)\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = trial\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best = trial\n\n        return self.global_best, self.global_best_score", "name": "PSO_DE_Hybrid", "description": "Integrate adaptive mutation scaling in Differential Evolution to enhance solution diversity and robustness.", "configspace": "", "generation": 8, "fitness": 0.8973482415276764, "feedback": "The algorithm PSO_DE_Hybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.897 with standard deviation 0.009. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "c981e2d6-676b-43e7-98ca-ad6c3cacfeaa", "metadata": {"aucs": [0.9046888440885723, 0.8849117002735267, 0.9024441802209301], "final_y": [0.1118445099948504, 0.12125892921630788, 0.11295588697227066]}, "mutation_prompt": null}
{"id": "f43453c7-a185-4381-a5b4-37ce5ac0ede6", "solution": "import numpy as np\n\nclass PSO_DE_Hybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particle_count = 10\n        self.particles = np.random.rand(self.particle_count, self.dim)\n        self.velocities = np.random.rand(self.particle_count, self.dim)\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.particle_count, np.inf)\n        self.global_best = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n\n        for i in range(self.particle_count):\n            self.particles[i] = lb + (ub - lb) * self.particles[i]\n\n        while eval_count < self.budget:\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.particles[i])\n                eval_count += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = 2.0 * r1 * (self.personal_best[i] - self.particles[i])\n                social = 2.0 * r2 * (self.global_best - self.particles[i])\n                inertia_weight = 0.5 * np.exp(-3 * eval_count / self.budget) + 0.4  # Non-linear dynamic inertia\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive + social\n                max_velocity = 0.1 * (ub - lb) + 0.05 * (ub - lb) * np.cos(np.pi * eval_count / self.budget)\n                self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.particle_count) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                mutation_scaling = 0.85 + 0.15 * np.sin(np.pi * eval_count / self.budget)  # Adaptive mutation scaling\n                mutant = np.clip(a + mutation_scaling * (b - c), lb, ub)\n                crossover_rate = 0.5 + 0.4 * (1 - eval_count / self.budget)\n                trial = np.where(np.random.rand(self.dim) < crossover_rate, mutant, self.particles[i])\n                \n                score = func(trial)\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = trial\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best = trial\n\n        return self.global_best, self.global_best_score", "name": "PSO_DE_Hybrid", "description": "Introduce non-linear dynamic inertia weight and adaptive mutation scaling to enhance exploration and exploitation balance.", "configspace": "", "generation": 8, "fitness": 0.8943333726226242, "feedback": "The algorithm PSO_DE_Hybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.894 with standard deviation 0.006. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "c981e2d6-676b-43e7-98ca-ad6c3cacfeaa", "metadata": {"aucs": [0.8879955980275918, 0.8930935751294038, 0.9019109447108771], "final_y": [0.1205480687305005, 0.11897311432603963, 0.11567138275433009]}, "mutation_prompt": null}
{"id": "1ff532fd-6b1e-4ef3-bea9-0de0e40c5264", "solution": "import numpy as np\n\nclass PSO_DE_Hybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particle_count = max(10, int(dim * 1.5))  # Dynamic particle count\n        self.particles = np.random.rand(self.particle_count, self.dim)\n        self.velocities = np.random.rand(self.particle_count, self.dim)\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.particle_count, np.inf)\n        self.global_best = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n\n        # Initialize particles\n        for i in range(self.particle_count):\n            self.particles[i] = lb + (ub - lb) * self.particles[i]\n\n        while eval_count < self.budget:\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current particle\n                score = func(self.particles[i])\n                eval_count += 1\n\n                # Update personal and global bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions (PSO)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = 2.0 * r1 * (self.personal_best[i] - self.particles[i])\n                social = 2.0 * r2 * (self.global_best - self.particles[i])\n                phase_factor = 0.5 + 0.5 * (1 - eval_count / self.budget)  # New phase factor\n                inertia_weight = 0.9 + 0.09 * np.sin(eval_count / self.budget * np.pi)  # Adaptive inertia weight\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive + social\n                # Updated velocity clamping mechanism\n                max_velocity = 0.1 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            # Differential Evolution (Mutation and Crossover)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.particle_count) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + 0.85 * (b - c), lb, ub)\n                crossover_rate = 0.5 + 0.4 * (1 - eval_count / self.budget)  # Adaptive crossover rate\n                trial = np.where(np.random.rand(self.dim) < crossover_rate, mutant, self.particles[i])\n                \n                score = func(trial)\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = trial\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best = trial\n\n        return self.global_best, self.global_best_score", "name": "PSO_DE_Hybrid", "description": "Introduce an adaptive learning rate to balance exploitation and exploration for improved global convergence.", "configspace": "", "generation": 8, "fitness": 0.8701847713070135, "feedback": "The algorithm PSO_DE_Hybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.870 with standard deviation 0.009. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "a100de28-9150-4daf-a25e-30a14206d7ec", "metadata": {"aucs": [0.8727372190080007, 0.879179353655065, 0.858637741257975], "final_y": [0.11477282197906036, 0.11793286651420443, 0.12871752579636653]}, "mutation_prompt": null}
{"id": "93828280-2a14-4b13-8cfb-6adc0e4451e8", "solution": "import numpy as np\n\nclass PSO_DE_Hybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particle_count = max(10, int(dim * 1.5))  # Dynamic particle count\n        self.particles = np.random.rand(self.particle_count, self.dim)\n        self.velocities = np.random.rand(self.particle_count, self.dim)\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.particle_count, np.inf)\n        self.global_best = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n\n        # Initialize particles\n        for i in range(self.particle_count):\n            self.particles[i] = lb + (ub - lb) * self.particles[i]\n\n        while eval_count < self.budget:\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current particle\n                score = func(self.particles[i])\n                eval_count += 1\n\n                # Update personal and global bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions (PSO)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = 2.0 * r1 * (self.personal_best[i] - self.particles[i])\n                social = 2.0 * r2 * (self.global_best - self.particles[i])\n                phase_factor = 0.5 + 0.5 * (1 - eval_count / self.budget)  # New phase factor\n                inertia_weight = 0.9 + 0.09 * np.sin(eval_count / self.budget * np.pi)  # Adaptive inertia weight\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive + social\n                # Updated velocity clamping mechanism\n                max_velocity = 0.1 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            # Differential Evolution (Mutation and Crossover)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.particle_count) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                scaling_factor = 0.8 + 0.2 * np.cos(eval_count / self.budget * np.pi)  # Adaptive scaling factor\n                mutant = np.clip(a + scaling_factor * (b - c), lb, ub)\n                crossover_rate = 0.5 + 0.4 * (1 - eval_count / self.budget)  # Adaptive crossover rate\n                trial = np.where(np.random.rand(self.dim) < crossover_rate, mutant, self.particles[i])\n                \n                score = func(trial)\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = trial\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best = trial\n\n        return self.global_best, self.global_best_score", "name": "PSO_DE_Hybrid", "description": "Introduce an adaptive scaling factor for Differential Evolution to improve exploration-exploitation balance.", "configspace": "", "generation": 8, "fitness": 0.8799443861734998, "feedback": "The algorithm PSO_DE_Hybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.880 with standard deviation 0.016. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "a100de28-9150-4daf-a25e-30a14206d7ec", "metadata": {"aucs": [0.8627318397718424, 0.8753854483879779, 0.9017158703606789], "final_y": [0.12087529948489228, 0.1239617164444693, 0.11254542231742226]}, "mutation_prompt": null}
{"id": "52a3fe96-0631-4ea7-be5f-0c4de5ad0181", "solution": "import numpy as np\n\nclass PSO_DE_Hybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particle_count = 10\n        self.particles = np.random.rand(self.particle_count, self.dim)\n        self.velocities = np.random.rand(self.particle_count, self.dim)\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.particle_count, np.inf)\n        self.global_best = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n\n        # Initialize particles\n        for i in range(self.particle_count):\n            self.particles[i] = lb + (ub - lb) * self.particles[i]\n\n        while eval_count < self.budget:\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                \n                # Evaluate current particle\n                score = func(self.particles[i])\n                eval_count += 1\n\n                # Update personal and global bests\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            # Update velocities and positions (PSO)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = (1.5 + 0.5 * np.sin(eval_count / self.budget * np.pi)) * r1 * (self.personal_best[i] - self.particles[i])  # Adaptive cognitive component\n                social = (1.5 + 0.5 * np.cos(eval_count / self.budget * np.pi)) * r2 * (self.global_best - self.particles[i])  # Adaptive social component\n                phase_factor = 0.5 + 0.5 * (1 - eval_count / self.budget)  # New phase factor\n                inertia_weight = (0.5 + 0.4 * np.sin(np.pi * eval_count / self.budget))  # Adjusted inertia\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive + social\n                max_velocity = 0.1 * (ub - lb) + 0.05 * (ub - lb) * np.cos(np.pi * eval_count / self.budget)\n                self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n\n            # Differential Evolution (Mutation and Crossover)\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.particle_count) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + 0.85 * (b - c), lb, ub)\n                crossover_rate = 0.5 + 0.4 * (1 - eval_count / self.budget)  # Adaptive crossover rate\n                trial = np.where(np.random.rand(self.dim) < crossover_rate, mutant, self.particles[i])\n                \n                score = func(trial)\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = trial\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best = trial\n\n        return self.global_best, self.global_best_score", "name": "PSO_DE_Hybrid", "description": "Introduce adaptive learning factors and enhanced boundary handling to improve convergence and solution quality.", "configspace": "", "generation": 8, "fitness": 0.8861143130365591, "feedback": "The algorithm PSO_DE_Hybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.886 with standard deviation 0.004. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "c981e2d6-676b-43e7-98ca-ad6c3cacfeaa", "metadata": {"aucs": [0.8824154090985111, 0.8835144610152, 0.892413068995966], "final_y": [0.12145582771113039, 0.11400047288602033, 0.1166743588483683]}, "mutation_prompt": null}
{"id": "2f267e5f-f2d5-4caa-a625-e92fa00bf076", "solution": "import numpy as np\n\nclass PSO_DE_Hybrid:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.particle_count = max(10, int(dim * 1.5))\n        self.particles = np.random.rand(self.particle_count, self.dim)\n        self.velocities = np.random.rand(self.particle_count, self.dim)\n        self.personal_best = self.particles.copy()\n        self.personal_best_scores = np.full(self.particle_count, np.inf)\n        self.global_best = None\n        self.global_best_score = np.inf\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        eval_count = 0\n        \n        for i in range(self.particle_count):\n            self.particles[i] = lb + (ub - lb) * self.particles[i]\n\n        chaotic_map = np.random.rand()\n        \n        while eval_count < self.budget:\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                \n                score = func(self.particles[i])\n                eval_count += 1\n\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best = self.particles[i].copy()\n\n            chaotic_map = 4 * chaotic_map * (1 - chaotic_map)  # Logistic map update\n\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive = 2.0 * r1 * (self.personal_best[i] - self.particles[i])\n                social = 2.0 * r2 * (self.global_best - self.particles[i])\n                inertia_weight = 0.9 + 0.09 * np.sin(eval_count / self.budget * np.pi) * chaotic_map\n                self.velocities[i] = inertia_weight * self.velocities[i] + cognitive + social\n                max_velocity = 0.1 * (ub - lb)\n                self.velocities[i] = np.clip(self.velocities[i], -max_velocity, max_velocity)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], lb, ub)\n                chaotic_map = 4 * chaotic_map * (1 - chaotic_map)  # Update once more\n\n            for i in range(self.particle_count):\n                if eval_count >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.particle_count) if idx != i]\n                a, b, c = self.particles[np.random.choice(idxs, 3, replace=False)]\n                factor = 0.5 + chaotic_map / 2  # Dynamic mutation factor\n                mutant = np.clip(a + factor * (b - c), lb, ub)\n                crossover_rate = 0.4 + 0.6 * chaotic_map\n                trial = np.where(np.random.rand(self.dim) < crossover_rate, mutant, self.particles[i])\n                \n                score = func(trial)\n                eval_count += 1\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best[i] = trial\n                    if score < self.global_best_score:\n                        self.global_best_score = score\n                        self.global_best = trial\n\n        return self.global_best, self.global_best_score", "name": "PSO_DE_Hybrid", "description": "Introduce chaotic maps for dynamic parameter tuning and improve mutation strategy to enhance exploration and exploitation balance.", "configspace": "", "generation": 8, "fitness": 0.8888132666640995, "feedback": "The algorithm PSO_DE_Hybrid got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.889 with standard deviation 0.008. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "a100de28-9150-4daf-a25e-30a14206d7ec", "metadata": {"aucs": [0.8978663653911075, 0.8907458380985509, 0.87782759650264], "final_y": [0.11494407217933278, 0.11933993650322461, 0.120806069289211]}, "mutation_prompt": null}
