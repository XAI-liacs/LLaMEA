{"id": "47353224-2fde-47c3-9d22-bb5e6ed2a8f5", "solution": "import numpy as np\n\nclass HybridDifferentialEvolutionLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # Crossover probability\n        self.local_search_rate = 0.1  # Probability of applying local search\n        self.population = None\n        self.best_individual = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_population(bounds)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                # Differential Evolution mutation and crossover\n                mutant = self.de_mutation(i, bounds)\n                trial = self.de_crossover(self.population[i], mutant)\n                \n                # Local search\n                if np.random.rand() < self.local_search_rate:\n                    trial = self.local_search(trial, bounds, func)\n                \n                # Selection\n                trial_score = self.evaluate(func, trial)\n                if trial_score < self.evaluate(func, self.population[i]):\n                    self.population[i] = trial\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_individual = trial\n        \n        return self.best_individual\n\n    def initialize_population(self, bounds):\n        self.population = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        for individual in self.population:\n            score = self.evaluate(func, individual)\n            if score < self.best_score:\n                self.best_score = score\n                self.best_individual = individual\n\n    def de_mutation(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), bounds[:, 0], bounds[:, 1])\n        return mutant\n\n    def de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, individual, bounds, func):\n        perturbation = np.random.normal(0, 0.1, self.dim)\n        perturbed_individual = np.clip(individual + perturbation, bounds[:, 0], bounds[:, 1])\n        perturbed_score = self.evaluate(func, perturbed_individual)\n        if perturbed_score < self.evaluate(func, individual):\n            return perturbed_individual\n        return individual\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridDifferentialEvolutionLocalSearch", "description": "A hybrid algorithm combining Differential Evolution and Adaptive Local Search for efficient exploration and exploitation in high-dimensional spaces.", "configspace": "", "generation": 0, "fitness": -Infinity, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 187, in initialize_single\n    new_individual = self.evaluate_fitness(new_individual)\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 264, in evaluate_fitness\n    updated_individual = self.f(individual, self.logger)\n  File \"benchmarks/tuto_global_optimization_photonics/exp_photonic.py\", line 129, in evaluatePhotonic\n    algorithm(problem)\n  File \"<string>\", line 18, in __call__\n  File \"<string>\", line 46, in initialize_population\nNameError: name 'func' is not defined\n.", "error": "NameError(\"name 'func' is not defined\")Traceback (most recent call last):\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 187, in initialize_single\n    new_individual = self.evaluate_fitness(new_individual)\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 264, in evaluate_fitness\n    updated_individual = self.f(individual, self.logger)\n  File \"benchmarks/tuto_global_optimization_photonics/exp_photonic.py\", line 129, in evaluatePhotonic\n    algorithm(problem)\n  File \"<string>\", line 18, in __call__\n  File \"<string>\", line 46, in initialize_population\nNameError: name 'func' is not defined\n", "parent_id": null, "metadata": {}, "mutation_prompt": null}
{"id": "57a70eb9-8791-408e-8e09-4d1cd4de0e94", "solution": "import numpy as np\n\nclass HybridDifferentialEvolutionLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # DE scaling factor\n        self.CR = 0.9  # Crossover probability\n        self.local_search_rate = 0.1  # Probability of applying local search\n        self.population = None\n        self.best_individual = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_population(bounds, func)  # Pass func to initialize_population\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                # Differential Evolution mutation and crossover\n                mutant = self.de_mutation(i, bounds)\n                trial = self.de_crossover(self.population[i], mutant)\n                \n                # Local search\n                if np.random.rand() < self.local_search_rate:\n                    trial = self.local_search(trial, bounds, func)\n                \n                # Selection\n                trial_score = self.evaluate(func, trial)\n                if trial_score < self.evaluate(func, self.population[i]):\n                    self.population[i] = trial\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_individual = trial\n        \n        return self.best_individual\n\n    def initialize_population(self, bounds, func):  # Add func as parameter\n        self.population = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        for individual in self.population:\n            score = self.evaluate(func, individual)\n            if score < self.best_score:\n                self.best_score = score\n                self.best_individual = individual\n\n    def de_mutation(self, target_idx, bounds):\n        indices = list(range(self.population_size))\n        indices.remove(target_idx)\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), bounds[:, 0], bounds[:, 1])\n        return mutant\n\n    def de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, individual, bounds, func):\n        perturbation = np.random.normal(0, 0.05, self.dim)  # Reduced perturbation scale\n        perturbed_individual = np.clip(individual + perturbation, bounds[:, 0], bounds[:, 1])\n        perturbed_score = self.evaluate(func, perturbed_individual)\n        if perturbed_score < self.evaluate(func, individual):\n            return perturbed_individual\n        return individual\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridDifferentialEvolutionLocalSearch", "description": "Improved hybrid algorithm by refining the initialization and local search strategy for better exploration and solution quality.", "configspace": "", "generation": 1, "fitness": 0.10037023434192271, "feedback": "The algorithm HybridDifferentialEvolutionLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.100 with standard deviation 0.001. And the mean value of best solutions found was 0.146 (0. is the best).", "error": "", "parent_id": "47353224-2fde-47c3-9d22-bb5e6ed2a8f5", "metadata": {"aucs": [0.09967418793540916, 0.1011649578550875, 0.10027155723527148], "final_y": [0.14144881409452936, 0.1517795681855787, 0.1451598139343242]}, "mutation_prompt": null}
{"id": "5d720674-83a9-47b9-8498-067fe7d9e1e0", "solution": "import numpy as np\n\nclass AdaptiveHybridDifferentialEvolutionLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.init_population_size = 10 * dim\n        self.F = 0.8  # Initial DE scaling factor\n        self.CR = 0.9  # Crossover probability\n        self.local_search_rate = 0.1  # Probability of applying local search\n        self.population = None\n        self.best_individual = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1  # Rate to adapt mutation factor\n        self.dynamic_population = True\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_population(bounds, func)\n        \n        while self.evaluations < self.budget:\n            if self.dynamic_population and self.evaluations % (self.budget // 10) == 0:\n                self.reduce_population()\n\n            for i in range(len(self.population)):\n                if self.evaluations >= self.budget:\n                    break\n                \n                # Differential Evolution mutation and crossover\n                mutant = self.de_mutation(i, bounds)\n                trial = self.de_crossover(self.population[i], mutant)\n                \n                # Local search\n                if np.random.rand() < self.local_search_rate:\n                    trial = self.local_search(trial, bounds, func)\n                \n                # Selection\n                trial_score = self.evaluate(func, trial)\n                if trial_score < self.evaluate(func, self.population[i]):\n                    self.population[i] = trial\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_individual = trial\n                        self.F = min(1.0, self.F + self.adaptation_rate)  # Increase mutation factor adaptively\n                else:\n                    self.F = max(0.4, self.F - self.adaptation_rate)  # Decrease mutation factor\n\n        return self.best_individual\n\n    def initialize_population(self, bounds, func):\n        self.population = np.random.rand(self.init_population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        for individual in self.population:\n            score = self.evaluate(func, individual)\n            if score < self.best_score:\n                self.best_score = score\n                self.best_individual = individual\n\n    def reduce_population(self):\n        if len(self.population) > 4 * self.dim:\n            self.population = self.population[:len(self.population)//2]\n\n    def de_mutation(self, target_idx, bounds):\n        indices = list(range(len(self.population)))\n        indices.remove(target_idx)\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), bounds[:, 0], bounds[:, 1])\n        return mutant\n\n    def de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, individual, bounds, func):\n        perturbation = np.random.normal(0, 0.02, self.dim)\n        perturbed_individual = np.clip(individual + perturbation, bounds[:, 0], bounds[:, 1])\n        perturbed_score = self.evaluate(func, perturbed_individual)\n        if perturbed_score < self.evaluate(func, individual):\n            return perturbed_individual\n        return individual\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "AdaptiveHybridDifferentialEvolutionLocalSearch", "description": "Enhance the existing algorithm by introducing an adaptive mutation strategy and dynamic population sizing for improved convergence performance.", "configspace": "", "generation": 2, "fitness": 0.10354999879787037, "feedback": "The algorithm AdaptiveHybridDifferentialEvolutionLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.104 with standard deviation 0.000. And the mean value of best solutions found was 0.134 (0. is the best).", "error": "", "parent_id": "57a70eb9-8791-408e-8e09-4d1cd4de0e94", "metadata": {"aucs": [0.10307298024633016, 0.10394858202524071, 0.10362843412204026], "final_y": [0.13213189965799943, 0.13510399640702486, 0.13329418304668583]}, "mutation_prompt": null}
{"id": "401a6882-7bfd-4d08-800e-79893f9ca5cd", "solution": "import numpy as np\n\nclass AdaptiveHybridDifferentialEvolutionLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.init_population_size = 10 * dim\n        self.F = 0.8  # Initial DE scaling factor\n        self.CR = 0.9  # Crossover probability\n        self.local_search_rate = 0.1  # Probability of applying local search\n        self.population = None\n        self.best_individual = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1  # Rate to adapt mutation factor\n        self.dynamic_population = True\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_population(bounds, func)\n        \n        while self.evaluations < self.budget:\n            if self.dynamic_population and self.evaluations % (self.budget // 10) == 0:\n                self.reduce_population()\n\n            for i in range(len(self.population)):\n                if self.evaluations >= self.budget:\n                    break\n                \n                # Differential Evolution mutation and crossover\n                mutant = self.de_mutation(i, bounds)\n                trial = self.de_crossover(self.population[i], mutant)\n                \n                # Local search\n                if np.random.rand() < self.local_search_rate:\n                    trial = self.local_search(trial, bounds, func)\n                \n                # Selection\n                trial_score = self.evaluate(func, trial)\n                if trial_score < self.evaluate(func, self.population[i]):\n                    self.population[i] = trial\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_individual = trial\n                        self.F = min(1.0, self.F + self.adaptation_rate)  # Increase mutation factor adaptively\n                        self.CR = min(1.0, self.CR + 0.02)  # Adapt crossover probability\n                else:\n                    self.F = max(0.4, self.F - self.adaptation_rate)  # Decrease mutation factor\n                    self.CR = max(0.5, self.CR - 0.02)  # Adapt crossover probability\n\n        return self.best_individual\n\n    def initialize_population(self, bounds, func):\n        self.population = np.random.rand(self.init_population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        for individual in self.population:\n            score = self.evaluate(func, individual)\n            if score < self.best_score:\n                self.best_score = score\n                self.best_individual = individual\n\n    def reduce_population(self):\n        if len(self.population) > 4 * self.dim:\n            self.population = self.population[:len(self.population)//2]\n\n    def de_mutation(self, target_idx, bounds):\n        indices = list(range(len(self.population)))\n        indices.remove(target_idx)\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), bounds[:, 0], bounds[:, 1])\n        return mutant\n\n    def de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, individual, bounds, func):\n        perturbation = np.random.normal(0, 0.02, self.dim)\n        perturbed_individual = np.clip(individual + perturbation, bounds[:, 0], bounds[:, 1])\n        perturbed_score = self.evaluate(func, perturbed_individual)\n        if perturbed_score < self.evaluate(func, individual):\n            return perturbed_individual\n        return individual\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "AdaptiveHybridDifferentialEvolutionLocalSearch", "description": "Introduce adaptive crossover probability and enhanced local search strategy for improved convergence.", "configspace": "", "generation": 3, "fitness": 0.10393251784193631, "feedback": "The algorithm AdaptiveHybridDifferentialEvolutionLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.104 with standard deviation 0.001. And the mean value of best solutions found was 0.138 (0. is the best).", "error": "", "parent_id": "5d720674-83a9-47b9-8498-067fe7d9e1e0", "metadata": {"aucs": [0.10495733257376783, 0.10240559750810563, 0.1044346234439355], "final_y": [0.1391678640824595, 0.1432183774250424, 0.13167191309014725]}, "mutation_prompt": null}
{"id": "a3b22f2e-2d0c-44a3-af37-0661af24f724", "solution": "import numpy as np\n\nclass AdaptiveHybridDifferentialEvolutionLocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.init_population_size = 10 * dim\n        self.F = 0.8  # Initial DE scaling factor\n        self.CR = 0.9  # Crossover probability\n        self.local_search_rate = 0.1  # Probability of applying local search\n        self.population = None\n        self.best_individual = None\n        self.best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1  # Rate to adapt mutation factor\n        self.dynamic_population = True\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_population(bounds, func)\n        \n        while self.evaluations < self.budget:\n            if self.dynamic_population and self.evaluations % (self.budget // 10) == 0:\n                self.reduce_population()\n\n            for i in range(len(self.population)):\n                if self.evaluations >= self.budget:\n                    break\n                \n                # Differential Evolution mutation and crossover\n                mutant = self.de_mutation(i, bounds)\n                trial = self.de_crossover(self.population[i], mutant)\n                \n                # Local search\n                if np.random.rand() < self.local_search_rate:\n                    trial = self.local_search(trial, bounds, func)\n                \n                # Selection\n                trial_score = self.evaluate(func, trial)\n                if trial_score < self.evaluate(func, self.population[i]):\n                    self.population[i] = trial\n                    if trial_score < self.best_score:\n                        self.best_score = trial_score\n                        self.best_individual = trial\n                        self.F = min(1.2, self.F + self.adaptation_rate * 0.5)  # Increase mutation factor adaptively\n                        self.CR = min(1.0, self.CR + 0.02)  # Adapt crossover probability\n                else:\n                    self.F = max(0.3, self.F - self.adaptation_rate * 0.7)  # Decrease mutation factor\n                    self.CR = max(0.5, self.CR - 0.02)  # Adapt crossover probability\n\n        return self.best_individual\n\n    def initialize_population(self, bounds, func):\n        self.population = np.random.rand(self.init_population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        for individual in self.population:\n            score = self.evaluate(func, individual)\n            if score < self.best_score:\n                self.best_score = score\n                self.best_individual = individual\n\n    def reduce_population(self):\n        if len(self.population) > 4 * self.dim:\n            self.population = self.population[:len(self.population)//2]\n\n    def de_mutation(self, target_idx, bounds):\n        indices = list(range(len(self.population)))\n        indices.remove(target_idx)\n        a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), bounds[:, 0], bounds[:, 1])\n        return mutant\n\n    def de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_search(self, individual, bounds, func):\n        perturbation = np.random.normal(0, 0.02, self.dim)\n        perturbed_individual = np.clip(individual + perturbation, bounds[:, 0], bounds[:, 1])\n        perturbed_score = self.evaluate(func, perturbed_individual)\n        if perturbed_score < self.evaluate(func, individual):\n            return perturbed_individual\n        return individual\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "AdaptiveHybridDifferentialEvolutionLocalSearch", "description": "Introduce dynamic adaptation of scaling factor `F` based on performance to further enhance convergence.", "configspace": "", "generation": 4, "fitness": 0.10399898516364259, "feedback": "The algorithm AdaptiveHybridDifferentialEvolutionLocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.104 with standard deviation 0.000. And the mean value of best solutions found was 0.134 (0. is the best).", "error": "", "parent_id": "401a6882-7bfd-4d08-800e-79893f9ca5cd", "metadata": {"aucs": [0.10391840880950753, 0.10350896780789975, 0.10456957887352047], "final_y": [0.13337971898525247, 0.13763935896537527, 0.1297848433668949]}, "mutation_prompt": null}
{"id": "9feafe06-c62a-4e3e-b6ce-412bf06e52dd", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] + \n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i], bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                self.w = max(0.4, self.w - self.adaptation_rate * 0.01)\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Introduce a swarm-based hybrid strategy combining Particle Swarm Optimization (PSO) with adaptive opposition-based learning to maintain diversity and enhance convergence speed.", "configspace": "", "generation": 5, "fitness": 0.11183469063682679, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.112 with standard deviation 0.002. And the mean value of best solutions found was 0.118 (0. is the best).", "error": "", "parent_id": "a3b22f2e-2d0c-44a3-af37-0661af24f724", "metadata": {"aucs": [0.11018805988965719, 0.11521634591659391, 0.11009966610422928], "final_y": [0.12287774412282626, 0.11167885604659844, 0.1194847104039144]}, "mutation_prompt": null}
{"id": "c3d9e90b-3eed-40c3-85cd-6315474b8c0b", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.9   # Adjusted inertia weight to start with higher exploration\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.c1 = 0.5 + np.random.rand()  # Add variability to c1\n                self.c2 = 1.5 + np.random.rand()  # Add variability to c2\n                self.velocities[i] = (self.w * self.velocities[i] + \n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i], bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                self.w = max(0.4, self.w - self.adaptation_rate * 0.01)\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Enhance the swarm-based hybrid PSO by introducing a dynamic inertia weight adjustment and improving cognitive coefficient diversity for better exploration.", "configspace": "", "generation": 6, "fitness": 0.10672398349110172, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.107 with standard deviation 0.003. And the mean value of best solutions found was 0.130 (0. is the best).", "error": "", "parent_id": "9feafe06-c62a-4e3e-b6ce-412bf06e52dd", "metadata": {"aucs": [0.10293608615468564, 0.108988090822282, 0.10824777349633752], "final_y": [0.14550563822849838, 0.12040297529682598, 0.12398944150259061]}, "mutation_prompt": null}
{"id": "f2abbbaf-18e6-4c86-a330-01c413b09855", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1_initial = 1.5  # Initial Cognitive coefficient\n        self.c2_initial = 1.5  # Initial Social coefficient\n        self.c1 = self.c1_initial\n        self.c2 = self.c2_initial\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n        self.feedback_threshold = 10  # Performance feedback threshold\n        self.improvement_count = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] + \n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i], bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                    self.improvement_count += 1\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                self.w = max(0.4, self.w - self.adaptation_rate * 0.01)\n            \n            # Adjust coefficients based on performance feedback\n            if self.improvement_count >= self.feedback_threshold:\n                self.c1 = min(self.c1 + 0.1, 2.0)\n                self.c2 = max(self.c2 - 0.1, 1.0)\n                self.improvement_count = 0\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Enhance convergence by dynamically adjusting cognitive and social coefficients based on performance feedback.", "configspace": "", "generation": 7, "fitness": 0.11168408350039132, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.112 with standard deviation 0.002. And the mean value of best solutions found was 0.115 (0. is the best).", "error": "", "parent_id": "9feafe06-c62a-4e3e-b6ce-412bf06e52dd", "metadata": {"aucs": [0.11013428126076297, 0.11506243213936851, 0.10985553710104246], "final_y": [0.11432687108484596, 0.11055268335135893, 0.12013070060784514]}, "mutation_prompt": null}
{"id": "0b9c6178-ca55-4214-b055-5d9600b85e2d", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.c1 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                self.c2 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                self.velocities[i] = (self.w * self.velocities[i] + \n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i], bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                self.w = max(0.4, self.w - self.adaptation_rate * 0.01)\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Enhance convergence by adjusting cognitive and social coefficients dynamically based on particle performance.", "configspace": "", "generation": 8, "fitness": 0.11217754007937981, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.112 with standard deviation 0.002. And the mean value of best solutions found was 0.118 (0. is the best).", "error": "", "parent_id": "9feafe06-c62a-4e3e-b6ce-412bf06e52dd", "metadata": {"aucs": [0.1107225994964115, 0.11444083763508506, 0.1113691831066429], "final_y": [0.11782024043029593, 0.11867443895466268, 0.11799351332682029]}, "mutation_prompt": null}
{"id": "8734d4fc-68de-4806-89ba-5737198254c7", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.c1 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                self.c2 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                self.velocities[i] = (self.w * self.velocities[i] + \n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i], bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                self.w = max(0.4, self.w - self.adaptation_rate * 0.01)\n\n            # Dynamic population size adjustment\n            if self.evaluations % (self.budget // 10) == 0:  \n                self.population_size = max(5, int(self.population_size * 0.9))\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Introduce a dynamic adaptation of the population size to enhance search diversity and exploitation.", "configspace": "", "generation": 9, "fitness": 0.11112567471721828, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.111 with standard deviation 0.003. And the mean value of best solutions found was 0.120 (0. is the best).", "error": "", "parent_id": "0b9c6178-ca55-4214-b055-5d9600b85e2d", "metadata": {"aucs": [0.10775439787731345, 0.11445141480187049, 0.11117121147247089], "final_y": [0.12472960199405703, 0.11861444027387391, 0.11788020696009038]}, "mutation_prompt": null}
{"id": "0c86ef01-6d16-4d83-b66c-9e0be4771865", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.9   # Initial inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.c1 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                self.c2 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                self.velocities[i] = (self.w * self.velocities[i] + \n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i], bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                self.w = 0.4 + (0.5 * np.cos(np.pi * self.evaluations / self.budget))\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        # Using a logistic map for initial positions\n        logistic_map = lambda x: 4 * x * (1 - x)\n        x = np.random.rand(self.population_size, self.dim)\n        self.particles = logistic_map(x) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Incorporate a nonlinear inertia weight adaptation and chaotic map initialization to enhance exploration and convergence.", "configspace": "", "generation": 10, "fitness": 0.10606749317058244, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.106 with standard deviation 0.001. And the mean value of best solutions found was 0.124 (0. is the best).", "error": "", "parent_id": "0b9c6178-ca55-4214-b055-5d9600b85e2d", "metadata": {"aucs": [0.1067740947616792, 0.1070954295648503, 0.10433295518521779], "final_y": [0.12340398908805539, 0.11910796747401431, 0.13063042222992116]}, "mutation_prompt": null}
{"id": "da90a165-5201-4928-b245-64dade30326a", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.c1 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                self.c2 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                self.velocities[i] = (self.w * self.velocities[i] + \n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                perturbation = np.random.randn(self.dim) * 0.01 * (bounds[:, 1] - bounds[:, 0]) # Stochastic perturbation\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                self.w = max(0.4, self.w - self.adaptation_rate * 0.01)\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Integrate stochastic perturbation to enhance exploration capability and prevent premature convergence.", "configspace": "", "generation": 11, "fitness": 0.11280739276548186, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.113 with standard deviation 0.001. And the mean value of best solutions found was 0.116 (0. is the best).", "error": "", "parent_id": "0b9c6178-ca55-4214-b055-5d9600b85e2d", "metadata": {"aucs": [0.11156958991655008, 0.11274871801442621, 0.11410387036546932], "final_y": [0.11816492241729848, 0.11841934387166964, 0.11053384610178796]}, "mutation_prompt": null}
{"id": "20c5ca3c-d115-45ed-b198-85a66cc54f71", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.c1 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                self.c2 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                self.velocities[i] = (self.w * self.velocities[i] + \n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                perturbation = np.random.randn(self.dim) * 0.01 * (bounds[:, 1] - bounds[:, 0]) # Stochastic perturbation\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n                # Hybrid crossover for global best update\n                if np.random.rand() < 0.1:\n                    crossover_point = np.random.randint(0, self.dim)\n                    self.global_best_position[:crossover_point] = self.particles[i][:crossover_point]\n\n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                self.w = max(0.4, self.w - self.adaptation_rate * 0.01)\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Enhanced global best position update using a hybrid crossover operator to maintain diversity.", "configspace": "", "generation": 12, "fitness": 0.10628631431914404, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.106 with standard deviation 0.001. And the mean value of best solutions found was 0.135 (0. is the best).", "error": "", "parent_id": "da90a165-5201-4928-b245-64dade30326a", "metadata": {"aucs": [0.10478124467504568, 0.10640923205721431, 0.10766846622517212], "final_y": [0.13858118133431674, 0.13382597770600824, 0.13328406334902754]}, "mutation_prompt": null}
{"id": "306f0e82-3d48-464d-b41e-72e7d8c2aa1b", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.c1 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                self.c2 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                self.velocities[i] = (self.w * self.velocities[i] + \n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                perturbation = np.random.randn(self.dim) * 0.01 * (bounds[:, 1] - bounds[:, 0]) # Stochastic perturbation\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                self.w = max(0.4, self.w - self.adaptation_rate * 0.01)\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Integrate stochastic perturbation to enhance exploration capability and prevent premature convergence.", "configspace": "", "generation": 12, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('list index out of range').", "error": "IndexError('list index out of range')", "parent_id": "da90a165-5201-4928-b245-64dade30326a", "metadata": {"aucs": [0.11156958991655008, 0.11274871801442621, 0.11410387036546932], "final_y": [0.11816492241729848, 0.11841934387166964, 0.11053384610178796]}, "mutation_prompt": null}
{"id": "5a00e4d0-32e4-4f85-9e91-f29862a5d962", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.c1 = 1.2 + (0.5 * np.random.rand())  # Slightly increased adjustment range\n                self.c2 = 1.2 + (0.5 * np.random.rand())  # Slightly increased adjustment range\n                self.velocities[i] = (self.w * self.velocities[i] + \n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                perturbation = np.random.randn(self.dim) * 0.02 * (bounds[:, 1] - bounds[:, 0]) # Slightly increased perturbation\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < self.personal_best_scores[i]:\n                    self.particles[i] = opposite_particle\n                    self.personal_best_scores[i] = opposite_score\n                    self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                self.w = max(0.4, self.w - self.adaptation_rate * 0.01)\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Enhance PSO by strategically replacing particles with oppositional learning and dynamic coefficient adjustment to balance exploration and exploitation.", "configspace": "", "generation": 14, "fitness": 0.11179222264646231, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.112 with standard deviation 0.001. And the mean value of best solutions found was 0.117 (0. is the best).", "error": "", "parent_id": "da90a165-5201-4928-b245-64dade30326a", "metadata": {"aucs": [0.11100414498238054, 0.11240777419991355, 0.11196474875709284], "final_y": [0.11876664964375694, 0.11981387183869696, 0.11273641745698249]}, "mutation_prompt": null}
{"id": "d6b535dc-2039-4b28-a5c3-58b432e2ad5a", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n        self.successful_updates = 0  # Track successful updates\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.c1 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                self.c2 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                self.velocities[i] = (self.w * self.velocities[i] + \n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                perturbation = np.random.randn(self.dim) * 0.01 * (bounds[:, 1] - bounds[:, 0]) # Stochastic perturbation\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                    self.successful_updates += 1  # Track success\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                self.w = max(0.4, self.w - (0.01 if self.successful_updates / self.evaluations > 0.1 else 0.005))  # Adjust based on success rate\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Introduce adaptive inertia weight adjustment based on success rate to enhance convergence.", "configspace": "", "generation": 15, "fitness": 0.1119221953895501, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.112 with standard deviation 0.000. And the mean value of best solutions found was 0.117 (0. is the best).", "error": "", "parent_id": "da90a165-5201-4928-b245-64dade30326a", "metadata": {"aucs": [0.11156125483297186, 0.11207940039045661, 0.11212593094522183], "final_y": [0.11810137308663682, 0.11837542779733456, 0.11479376892262139]}, "mutation_prompt": null}
{"id": "86c17ce0-1e76-44fe-abd0-c66aa0d32b07", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.c1 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                self.c2 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                scaling_factor = np.random.uniform(0.5, 1.5, size=self.dim)  # Random scaling\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor + \n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                perturbation = np.random.randn(self.dim) * 0.01 * (bounds[:, 1] - bounds[:, 0]) # Stochastic perturbation\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                self.w = max(0.4, self.w - self.adaptation_rate * 0.01)\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Introduce random scaling in velocities for enhanced diversity and improved exploratory behavior.", "configspace": "", "generation": 16, "fitness": 0.11288843693253521, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.113 with standard deviation 0.001. And the mean value of best solutions found was 0.115 (0. is the best).", "error": "", "parent_id": "da90a165-5201-4928-b245-64dade30326a", "metadata": {"aucs": [0.11385149040549714, 0.11260145402660982, 0.1122123663654987], "final_y": [0.11028547878165518, 0.11858873734264341, 0.11547960586311756]}, "mutation_prompt": null}
{"id": "9d2220f8-b9b7-493b-8637-21c0c3d69d44", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.c1 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                self.c2 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                scaling_factor = np.random.uniform(0.5, 1.5, size=self.dim)  # Random scaling\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor + \n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                perturbation = np.random.randn(self.dim) * 0.01 * np.exp(-self.evaluations/self.budget) * (bounds[:, 1] - bounds[:, 0]) # Exponential decay\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                self.w = max(0.4, self.w - self.adaptation_rate * 0.01)\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Introduce exponential decay in perturbation to enhance local search precision over iterations.", "configspace": "", "generation": 17, "fitness": 0.11293178636700278, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.113 with standard deviation 0.000. And the mean value of best solutions found was 0.114 (0. is the best).", "error": "", "parent_id": "86c17ce0-1e76-44fe-abd0-c66aa0d32b07", "metadata": {"aucs": [0.11337551697378523, 0.11255727990178022, 0.11286256222544289], "final_y": [0.10996165098822419, 0.11849512374436799, 0.11413816041231739]}, "mutation_prompt": null}
{"id": "6dbe92b7-4cd8-4392-94fa-1270796b7c7a", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.c1 = 1.2 + (0.3 * np.random.rand())\n                self.c2 = 1.2 + (0.3 * np.random.rand())\n                scaling_factor = np.random.uniform(0.5, 1.5, size=self.dim)  # Random scaling\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor + \n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                levy_perturbation = np.random.standard_cauchy(self.dim) * 0.01 * np.exp(-self.evaluations/self.budget) * (bounds[:, 1] - bounds[:, 0]) # Lvy flight perturbation\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + levy_perturbation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                self.w = max(0.4, self.w - self.adaptation_rate * 0.01)\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Enhance exploration by introducing Lvy flight perturbations for improved global search capability.", "configspace": "", "generation": 18, "fitness": 0.11279449860227346, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.113 with standard deviation 0.001. And the mean value of best solutions found was 0.116 (0. is the best).", "error": "", "parent_id": "9d2220f8-b9b7-493b-8637-21c0c3d69d44", "metadata": {"aucs": [0.11105611029793105, 0.11383553746713959, 0.11349184804174972], "final_y": [0.11310509977182692, 0.11884497547060635, 0.11477322536154944]}, "mutation_prompt": null}
{"id": "b33d4f2a-0b71-4ebc-969b-00180e7d53e9", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.c1 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                self.c2 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                scaling_factor = np.random.uniform(0.5, 1.5, size=self.dim)  # Random scaling\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor + \n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                perturbation = np.random.randn(self.dim) * 0.01 * np.exp(-self.evaluations/self.budget) * (bounds[:, 1] - bounds[:, 0]) # Exponential decay\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                diversity = np.mean(np.std(self.particles, axis=0))\n                self.w = max(0.4, 0.9 - (0.9 - 0.4) * (self.evaluations/self.budget) * (1 + 0.5 * diversity))\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Introduce dynamic inertia weight influenced by both the iteration progress and diversity of the swarm to enhance exploration and exploitation balance.", "configspace": "", "generation": 19, "fitness": 0.11320653523660766, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.113 with standard deviation 0.001. And the mean value of best solutions found was 0.115 (0. is the best).", "error": "", "parent_id": "9d2220f8-b9b7-493b-8637-21c0c3d69d44", "metadata": {"aucs": [0.11226079713997039, 0.11332469464504846, 0.11403411392480411], "final_y": [0.11391204572228575, 0.11949655738460652, 0.11154445444864092]}, "mutation_prompt": null}
{"id": "d487365f-391d-4db2-9a48-5ca5a5ee9e0b", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.c1 = 1.2 + (0.5 * np.random.rand())  # Dynamic adjustment, increased range\n                self.c2 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                scaling_factor = np.random.uniform(0.5, 1.5, size=self.dim)  # Random scaling\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor + \n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                perturbation = np.random.randn(self.dim) * 0.01 * np.exp(-self.evaluations/self.budget) * (bounds[:, 1] - bounds[:, 0]) # Exponential decay\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                diversity = np.mean(np.std(self.particles, axis=0))\n                self.w = max(0.4, 0.9 - (0.9 - 0.4) * (self.evaluations/self.budget) * (1 + 0.5 * diversity))\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Introduce an adaptive learning strategy by varying the cognitive coefficient dynamically for enhanced convergence.", "configspace": "", "generation": 20, "fitness": 0.11154414306767906, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.112 with standard deviation 0.001. And the mean value of best solutions found was 0.120 (0. is the best).", "error": "", "parent_id": "b33d4f2a-0b71-4ebc-969b-00180e7d53e9", "metadata": {"aucs": [0.11165296465958585, 0.11315603380630335, 0.10982343073714795], "final_y": [0.1156399422482477, 0.12041523577956903, 0.12514102943691674]}, "mutation_prompt": null}
{"id": "f09dd451-5261-4b34-8503-b98ebb33db3b", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.c1 = 1.2 + (0.3 * np.random.rand())  \n                self.c2 = 1.2 + (0.3 * np.random.rand())  \n                scaling_factor = np.random.uniform(0.5, 1.5, size=self.dim)  \n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor + \n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                perturbation = np.random.randn(self.dim) * 0.01 * np.exp(-self.evaluations/self.budget) * (bounds[:, 1] - bounds[:, 0]) \n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation, bounds[:, 0], bounds[:, 1])\n                \n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                diversity = np.mean(np.std(self.particles, axis=0))\n                self.w = max(0.4, 0.9 - (0.9 - 0.4) * (self.evaluations/self.budget)**2 * (1 + 0.5 * diversity))\n\n            if self.evaluations/self.budget > 0.5 and np.mean(self.personal_best_scores) > 0.2 * self.global_best_score:\n                self.population_size = max(5 * self.dim, int(self.population_size * 0.9))\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Enhance the particle swarming strategy by implementing a nonlinear inertia weight decay and dynamic population adjustment based on performance.", "configspace": "", "generation": 21, "fitness": 0.11055296832382151, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.111 with standard deviation 0.003. And the mean value of best solutions found was 0.121 (0. is the best).", "error": "", "parent_id": "b33d4f2a-0b71-4ebc-969b-00180e7d53e9", "metadata": {"aucs": [0.10570393726239657, 0.11276078287978586, 0.11319418482928212], "final_y": [0.1342467597085405, 0.11820042658023766, 0.11046574488373051]}, "mutation_prompt": null}
{"id": "38fd8ad4-194d-4b3e-b365-99b93261fef3", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.c1 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                self.c2 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                scaling_factor = np.random.uniform(0.5, 1.5, size=self.dim)  # Random scaling\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor + \n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                perturbation_factor = np.exp(-self.evaluations/self.budget) * (bounds[:, 1] - bounds[:, 0])\n                levy_flight = np.random.standard_cauchy(self.dim) * perturbation_factor  # Levy flight\n                perturbation = np.random.randn(self.dim) * 0.01 * perturbation_factor\n                perturbation = np.where(np.random.rand(self.dim) < 0.1, levy_flight, perturbation)  # Adaptive scaling\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                diversity = np.mean(np.std(self.particles, axis=0))\n                self.w = max(0.4, 0.9 - (0.9 - 0.4) * (self.evaluations/self.budget) * (1 + 0.5 * diversity))\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Introduce Levy flights and adaptive perturbation scaling to enhance exploration and convergence speed.", "configspace": "", "generation": 22, "fitness": 0.1091922048000545, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.109 with standard deviation 0.000. And the mean value of best solutions found was 0.127 (0. is the best).", "error": "", "parent_id": "b33d4f2a-0b71-4ebc-969b-00180e7d53e9", "metadata": {"aucs": [0.10970609896266736, 0.10930340085281309, 0.10856711458468304], "final_y": [0.12369185389144732, 0.12755191478141126, 0.12979359081071662]}, "mutation_prompt": null}
{"id": "744aa00a-04ab-4f83-a2cc-fd63b197a1bc", "solution": "import numpy as np\n\nclass BiLevelAdaptiveGA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_rate = 0.1\n        self.elitism_rate = 0.1\n        self.evaluations = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = self.initialize_population(bounds)\n        scores = np.array([self.evaluate(func, ind) for ind in population])\n        \n        while self.evaluations < self.budget:\n            # Selection\n            selected_indices = self.roulette_wheel_selection(scores)\n            offspring = population[selected_indices]\n            \n            # Crossover\n            offspring = self.crossover(offspring, bounds)\n            \n            # Mutation\n            offspring = self.mutate(offspring, scores[selected_indices], bounds)\n            \n            # Evaluate offspring\n            offspring_scores = np.array([self.evaluate(func, ind) for ind in offspring])\n            \n            # Elitism\n            top_indices = np.argsort(scores)[:int(self.population_size * self.elitism_rate)]\n            combined_population = np.concatenate((population[top_indices], offspring))\n            combined_scores = np.concatenate((scores[top_indices], offspring_scores))\n            \n            # Survival selection\n            best_indices = np.argsort(combined_scores)[:self.population_size]\n            population = combined_population[best_indices]\n            scores = combined_scores[best_indices]\n        \n        best_index = np.argmin(scores)\n        return population[best_index]\n\n    def initialize_population(self, bounds):\n        return np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)\n\n    def roulette_wheel_selection(self, scores):\n        fitness = 1 / (1 + scores)\n        probabilities = fitness / np.sum(fitness)\n        return np.random.choice(self.population_size, self.population_size, p=probabilities)\n\n    def crossover(self, population, bounds):\n        offspring = population.copy()\n        np.random.shuffle(offspring)\n        for i in range(0, self.population_size - 1, 2):\n            if np.random.rand() < 0.9:  # Crossover probability\n                alpha = np.random.rand(self.dim)\n                offspring[i] = alpha * population[i] + (1 - alpha) * population[i + 1]\n                offspring[i + 1] = alpha * population[i + 1] + (1 - alpha) * population[i]\n        return np.clip(offspring, bounds[:, 0], bounds[:, 1])\n\n    def mutate(self, population, fitness_ranks, bounds):\n        mutation_strength = self.mutation_rate * (1.0 + 0.5 * (fitness_ranks / np.max(fitness_ranks)))\n        for i in range(self.population_size):\n            if np.random.rand() < mutation_strength[i]:\n                disturbance = np.random.randn(self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n                population[i] = np.clip(population[i] + disturbance, bounds[:, 0], bounds[:, 1])\n        return population", "name": "BiLevelAdaptiveGA", "description": "Introduce a bi-level adaptive mutation strategy based on fitness ranking and diversity to enhance exploration and exploitation balance.", "configspace": "", "generation": 23, "fitness": 0.1097787730835289, "feedback": "The algorithm BiLevelAdaptiveGA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.110 with standard deviation 0.001. And the mean value of best solutions found was 0.121 (0. is the best).", "error": "", "parent_id": "b33d4f2a-0b71-4ebc-969b-00180e7d53e9", "metadata": {"aucs": [0.1094995176377368, 0.11074452842129923, 0.10909227319155068], "final_y": [0.12112120558225892, 0.12057610059671053, 0.12208203938572515]}, "mutation_prompt": null}
{"id": "9d78213b-ec74-4115-afec-7bce6ea7cec7", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                # Update velocity with Lvy flight\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.c1 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                self.c2 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                levy = np.random.standard_normal(self.dim) * 0.01\n                self.velocities[i] = (self.w * self.velocities[i] + \n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]) + levy)\n\n                # Update particle position with Gaussian mutation\n                perturbation = np.random.randn(self.dim) * 0.01 * np.exp(-self.evaluations/self.budget) * (bounds[:, 1] - bounds[:, 0])\n                gaussian_mutation = np.random.normal(0, 0.1, self.dim)\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation + gaussian_mutation, bounds[:, 0], bounds[:, 1])\n\n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                diversity = np.mean(np.std(self.particles, axis=0))\n                self.w = max(0.4, 0.9 - (0.9 - 0.4) * (self.evaluations/self.budget) * (1 + 0.5 * diversity))\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Enhance exploration by incorporating Lvy flight into the velocity update and diversify search with Gaussian mutations on positions.", "configspace": "", "generation": 24, "fitness": 0.1110833119058892, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.111 with standard deviation 0.003. And the mean value of best solutions found was 0.122 (0. is the best).", "error": "", "parent_id": "b33d4f2a-0b71-4ebc-969b-00180e7d53e9", "metadata": {"aucs": [0.11472136966350621, 0.11088831987336567, 0.1076402461807957], "final_y": [0.10977688655095963, 0.12488732217065868, 0.13134998138850262]}, "mutation_prompt": null}
{"id": "529f40b5-628c-4fd8-9525-dce9ac8f2337", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.c1 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                self.c2 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                scaling_factor = np.random.uniform(0.5, 1.5, size=self.dim)  # Random scaling\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor + \n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n                \n                # Reinitialize velocity\n                if np.random.rand() < 0.05:\n                    self.velocities[i] = np.random.randn(self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n\n                # Update particle position\n                perturbation = np.random.randn(self.dim) * 0.01 * np.exp(-self.evaluations/self.budget) * (bounds[:, 1] - bounds[:, 0]) # Exponential decay\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i] * np.random.rand(self.dim)\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                diversity = np.mean(np.std(self.particles, axis=0))\n                self.w = max(0.4, 0.9 - (0.9 - 0.4) * (self.evaluations/self.budget) * (1 + 0.5 * diversity))\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Introduce random velocity reinitialization and enhance oppositional learning to improve exploration and convergence.", "configspace": "", "generation": 25, "fitness": 0.11191129822078605, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.112 with standard deviation 0.002. And the mean value of best solutions found was 0.119 (0. is the best).", "error": "", "parent_id": "b33d4f2a-0b71-4ebc-969b-00180e7d53e9", "metadata": {"aucs": [0.10840175674583563, 0.11399172574274186, 0.11334041217378066], "final_y": [0.1280372587867894, 0.11622347969789493, 0.11267367824894214]}, "mutation_prompt": null}
{"id": "ed44c64f-6a46-4b1b-8c17-42d32b35e557", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.c1 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                self.c2 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                scaling_factor = np.random.uniform(0.5, 1.5, size=self.dim)  # Random scaling\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor + \n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                perturbation = np.random.randn(self.dim) * 0.01 * np.exp(-self.evaluations/self.budget) * (bounds[:, 1] - bounds[:, 0]) # Exponential decay\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                diversity = np.mean(np.std(self.particles, axis=0))\n                self.w = max(0.4, 0.9 - (0.9 - 0.4) * np.tanh(0.5 * (self.evaluations/self.budget)) * (1 + 0.5 * diversity))\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Introduce a non-linear dynamic inertia weight influenced by both the iteration progress and diversity of the swarm for enhanced adaptability.", "configspace": "", "generation": 26, "fitness": 0.11293565096180642, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.113 with standard deviation 0.001. And the mean value of best solutions found was 0.116 (0. is the best).", "error": "", "parent_id": "b33d4f2a-0b71-4ebc-969b-00180e7d53e9", "metadata": {"aucs": [0.11329033268965094, 0.11336332993082099, 0.11215329026494736], "final_y": [0.1164056444140189, 0.11836809848841345, 0.11445438098611149]}, "mutation_prompt": null}
{"id": "f1269715-a6bd-4040-9e01-ed954a6c898d", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.c1 = 1.2 + (0.3 * np.random.rand()**2)  # Non-linear dynamic adjustment\n                self.c2 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                scaling_factor = np.random.uniform(0.5, 1.5, size=self.dim)  # Random scaling\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor + \n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                perturbation = np.random.randn(self.dim) * 0.01 * np.exp(-self.evaluations/self.budget) * (bounds[:, 1] - bounds[:, 0]) # Exponential decay\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                diversity = np.mean(np.std(self.particles, axis=0))\n                self.w = max(0.4, 0.9 - (0.9 - 0.4) * (self.evaluations/self.budget) * (1 + 0.5 * diversity))\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Enhance dynamic adaptation by introducing non-linear adjustments to the cognitive and social coefficients.", "configspace": "", "generation": 27, "fitness": 0.1131477316681601, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.113 with standard deviation 0.001. And the mean value of best solutions found was 0.115 (0. is the best).", "error": "", "parent_id": "b33d4f2a-0b71-4ebc-969b-00180e7d53e9", "metadata": {"aucs": [0.11214688590472766, 0.11295238113421946, 0.11434392796553317], "final_y": [0.11405207517115246, 0.12003914016285033, 0.1113353475845823]}, "mutation_prompt": null}
{"id": "f61ce0cc-1ea3-4f80-8efa-0b09e6b6d722", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.c1 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                self.c2 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                scaling_factor = np.random.uniform(0.5, 1.5, size=self.dim)  # Random scaling\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor + \n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                perturbation = np.random.randn(self.dim) * 0.01 * np.exp(-self.evaluations/self.budget) * (bounds[:, 1] - bounds[:, 0]) # Exponential decay\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                diversity = np.mean(np.std(self.particles, axis=0))\n                self.w = max(0.4, 0.9 - (0.9 - 0.4) * (self.evaluations/self.budget) * (1 + 0.5 * diversity))\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Introduce dynamic inertia weight influenced by both the iteration progress and diversity of the swarm to enhance exploration and exploitation balance.", "configspace": "", "generation": 20, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('list index out of range').", "error": "IndexError('list index out of range')", "parent_id": "b33d4f2a-0b71-4ebc-969b-00180e7d53e9", "metadata": {"aucs": [0.11226079713997039, 0.11332469464504846, 0.11403411392480411], "final_y": [0.11391204572228575, 0.11949655738460652, 0.11154445444864092]}, "mutation_prompt": null}
{"id": "bd76e219-7db7-4058-b3b8-f28653648efe", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.c1 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                self.c2 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                scaling_factor = np.random.uniform(0.5, 1.5, size=self.dim)  # Random scaling\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor + \n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                levy_flight = np.random.standard_cauchy(size=self.dim)  # Lvy flight-inspired perturbation\n                perturbation = levy_flight * 0.01 * np.exp(-self.evaluations/self.budget) * (bounds[:, 1] - bounds[:, 0]) \n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                diversity = np.mean(np.std(self.particles, axis=0))\n                self.w = max(0.4, 0.9 - (0.9 - 0.4) * (self.evaluations/self.budget) * (1 + 0.5 * diversity))\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Improve the exploration phase by introducing a Lvy flight-inspired perturbation for particles to better escape local optima.", "configspace": "", "generation": 29, "fitness": 0.11245910050271472, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.112 with standard deviation 0.001. And the mean value of best solutions found was 0.118 (0. is the best).", "error": "", "parent_id": "b33d4f2a-0b71-4ebc-969b-00180e7d53e9", "metadata": {"aucs": [0.11122995623879428, 0.11296465692789026, 0.11318268834145961], "final_y": [0.11858777484242033, 0.12189251210696839, 0.11250453745203037]}, "mutation_prompt": null}
{"id": "a1dd07e9-11ad-45cb-bcd7-906150267459", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.c1 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                self.c2 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                scaling_factor = np.random.uniform(0.7, 1.5, size=self.dim)  # Random scaling\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor + \n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                perturbation = np.random.randn(self.dim) * 0.01 * np.exp(-self.evaluations/self.budget) * (bounds[:, 1] - bounds[:, 0]) # Exponential decay\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                diversity = np.mean(np.std(self.particles, axis=0))\n                self.w = max(0.4, 0.9 - (0.9 - 0.4) * (self.evaluations/self.budget) * (1 + 0.5 * diversity))\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Introduce multi-dimensional scaling factor to the velocity update for enhanced exploration.", "configspace": "", "generation": 30, "fitness": 0.11209473081550325, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.112 with standard deviation 0.001. And the mean value of best solutions found was 0.118 (0. is the best).", "error": "", "parent_id": "b33d4f2a-0b71-4ebc-969b-00180e7d53e9", "metadata": {"aucs": [0.11006406024131654, 0.11289499957796834, 0.11332513262722488], "final_y": [0.1190034444284328, 0.12078001606776001, 0.11385912560539135]}, "mutation_prompt": null}
{"id": "7be277bf-ef03-4472-bcd4-2896b4bf63f0", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.12  # Slightly increased adaptation rate\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.c1 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                self.c2 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                scaling_factor = np.random.uniform(0.5, 1.5, size=self.dim)  # Random scaling\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor + \n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                perturbation = np.random.randn(self.dim) * 0.01 * np.exp(-self.evaluations/self.budget) * (bounds[:, 1] - bounds[:, 0]) # Exponential decay\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                diversity = np.mean(np.std(self.particles, axis=0))\n                self.w = max(0.4, 0.9 - (0.9 - 0.4) * (self.evaluations/self.budget) * (1 + 0.5 * diversity))\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Slightly increase the adaptation rate to fine-tune the dynamic adjustment of the weighting coefficients in the HybridAdaptivePSO algorithm.", "configspace": "", "generation": 31, "fitness": 0.11320653523660766, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.113 with standard deviation 0.001. And the mean value of best solutions found was 0.115 (0. is the best).", "error": "", "parent_id": "b33d4f2a-0b71-4ebc-969b-00180e7d53e9", "metadata": {"aucs": [0.11226079713997039, 0.11332469464504846, 0.11403411392480411], "final_y": [0.11391204572228575, 0.11949655738460652, 0.11154445444864092]}, "mutation_prompt": null}
{"id": "c46f2127-569d-4e98-a0fc-33c6ce1bbffd", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  \n        self.c2 = 1.5 \n        self.w = 0.7   \n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.c1 = 1.2 + (0.3 * np.random.rand())\n                self.c2 = 1.2 + (0.3 * np.random.rand())\n                scaling_factor = np.random.uniform(0.5, 1.5, size=self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor + \n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                perturbation = np.random.randn(self.dim) * 0.01 * np.exp(-self.evaluations/self.budget) * (bounds[:, 1] - bounds[:, 0])\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                diversity = np.mean(np.std(self.particles, axis=0))\n                chaos_factor = np.sin(2 * np.pi * (self.evaluations/self.budget))  # Chaotic influence\n                self.w = max(0.4, 0.9 - (0.9 - 0.4) * (self.evaluations/self.budget) * (1 + 0.5 * diversity) + chaos_factor)\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Introduce chaotic local search and dynamic boundary adjustment to enhance convergence and diversity.", "configspace": "", "generation": 32, "fitness": 0.11201913538089621, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.112 with standard deviation 0.002. And the mean value of best solutions found was 0.120 (0. is the best).", "error": "", "parent_id": "b33d4f2a-0b71-4ebc-969b-00180e7d53e9", "metadata": {"aucs": [0.1131877191980114, 0.11344458473756902, 0.10942510220710822], "final_y": [0.11639146742960971, 0.11839710724181907, 0.12470698466154018]}, "mutation_prompt": null}
{"id": "b96bf811-4cd0-49d7-8c8d-fc92467d6bd7", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.c1 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                self.c2 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                scaling_factor = np.random.uniform(0.5, 1.5, size=self.dim)  # Random scaling\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor + \n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                perturbation = np.random.randn(self.dim) * 0.01 * (1 - self.evaluations/self.budget) * (bounds[:, 1] - bounds[:, 0])  # Linear decay\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                diversity = np.mean(np.std(self.particles, axis=0))\n                self.w = max(0.4, 0.9 - (0.9 - 0.4) * (self.evaluations/self.budget) * (1 + 0.5 * diversity))\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Replace exponential decay perturbation with linear decay for more consistent exploration across iterations.", "configspace": "", "generation": 33, "fitness": 0.1131734920955656, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.113 with standard deviation 0.001. And the mean value of best solutions found was 0.115 (0. is the best).", "error": "", "parent_id": "b33d4f2a-0b71-4ebc-969b-00180e7d53e9", "metadata": {"aucs": [0.11218113512268202, 0.11338002076716824, 0.11395932039684653], "final_y": [0.11410204053083683, 0.1186790740924224, 0.11242713005208504]}, "mutation_prompt": null}
{"id": "dc1ad66f-ff1f-469a-a7a9-b3d6c847f183", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.c1 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                self.c2 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                scaling_factor = np.random.uniform(0.5, 1.5, size=self.dim)  # Random scaling\n                random_factor = np.random.rand()  # New random factor\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor + \n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]) * random_factor)\n\n                # Update particle position\n                perturbation = np.random.randn(self.dim) * 0.01 * np.exp(-self.evaluations/self.budget) * (bounds[:, 1] - bounds[:, 0]) # Exponential decay\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                diversity = np.mean(np.std(self.particles, axis=0))\n                self.w = max(0.4, 0.9 - (0.9 - 0.4) * (self.evaluations/self.budget) * (1 + 0.5 * diversity))\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Introduce a random factor in cognitive and social components to enhance exploration in HybridAdaptivePSO.", "configspace": "", "generation": 34, "fitness": 0.11239785539378677, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.112 with standard deviation 0.001. And the mean value of best solutions found was 0.115 (0. is the best).", "error": "", "parent_id": "b33d4f2a-0b71-4ebc-969b-00180e7d53e9", "metadata": {"aucs": [0.11042120806105449, 0.1134662532596582, 0.11330610486064763], "final_y": [0.11324978260011864, 0.11785849896940193, 0.11277492248395082]}, "mutation_prompt": null}
{"id": "17b7171c-c2e4-4aff-92ce-6c098bebca1e", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.72   # Inertia weight (slight perturbation to original value)\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.c1 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                self.c2 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                scaling_factor = np.random.uniform(0.5, 1.5, size=self.dim)  # Random scaling\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor + \n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                perturbation = np.random.randn(self.dim) * 0.01 * np.exp(-self.evaluations/self.budget) * (bounds[:, 1] - bounds[:, 0]) # Exponential decay\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                diversity = np.mean(np.std(self.particles, axis=0))\n                self.w = max(0.4, 0.9 - (0.9 - 0.4) * (self.evaluations/self.budget) * (1 + 0.5 * diversity))\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Introduce a small perturbation in inertia weight initialization for better diversity control.", "configspace": "", "generation": 35, "fitness": 0.11060746083662387, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.111 with standard deviation 0.002. And the mean value of best solutions found was 0.121 (0. is the best).", "error": "", "parent_id": "b33d4f2a-0b71-4ebc-969b-00180e7d53e9", "metadata": {"aucs": [0.10909530933035572, 0.11290818688121251, 0.10981888629830339], "final_y": [0.11885592885524321, 0.12057531367067831, 0.12481206956780866]}, "mutation_prompt": null}
{"id": "57673ada-510f-41ea-ac10-6fe665e0d7df", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.12  # Changed from 0.1 to 0.12\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.c1 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                self.c2 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                scaling_factor = np.random.uniform(0.5, 1.5, size=self.dim)  # Random scaling\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor + \n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                perturbation = np.random.randn(self.dim) * 0.01 * np.exp(-self.evaluations/self.budget) * (bounds[:, 1] - bounds[:, 0]) # Exponential decay\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                diversity = np.mean(np.std(self.particles, axis=0))\n                self.w = max(0.4, 0.9 - (0.9 - 0.4) * (self.evaluations/self.budget) * (1 + 0.5 * diversity))\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Implement a small increase in the adaptation rate for the dynamic inertia weight to enhance performance convergence.", "configspace": "", "generation": 36, "fitness": 0.11320653523660766, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.113 with standard deviation 0.001. And the mean value of best solutions found was 0.115 (0. is the best).", "error": "", "parent_id": "b33d4f2a-0b71-4ebc-969b-00180e7d53e9", "metadata": {"aucs": [0.11226079713997039, 0.11332469464504846, 0.11403411392480411], "final_y": [0.11391204572228575, 0.11949655738460652, 0.11154445444864092]}, "mutation_prompt": null}
{"id": "64fd5bd7-f61d-4fba-b993-403f64086acb", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.c1 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                self.c2 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                scaling_factor = np.random.uniform(0.5, 1.5, size=self.dim)  # Random scaling\n                budget_scaling = 1 + 0.5 * (self.evaluations/self.budget)  # New scaling based on budget progression\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor * budget_scaling + \n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                perturbation = np.random.randn(self.dim) * 0.01 * np.exp(-self.evaluations/self.budget) * (bounds[:, 1] - bounds[:, 0]) # Exponential decay\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                diversity = np.mean(np.std(self.particles, axis=0))\n                self.w = max(0.4, 0.9 - (0.9 - 0.4) * (self.evaluations/self.budget) * (1 + 0.5 * diversity))\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Refine the velocity update formula by introducing an additional scaling factor based on the budget progression to enhance convergence speed.", "configspace": "", "generation": 37, "fitness": 0.11134862406318224, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.111 with standard deviation 0.001. And the mean value of best solutions found was 0.118 (0. is the best).", "error": "", "parent_id": "b33d4f2a-0b71-4ebc-969b-00180e7d53e9", "metadata": {"aucs": [0.10980819589836965, 0.11281488922693617, 0.11142278706424091], "final_y": [0.1216997272848569, 0.12082653582389014, 0.11135726644047672]}, "mutation_prompt": null}
{"id": "2487a8f4-b346-4c15-b89b-2b47425ccc30", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.c1 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                self.c2 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                scaling_factor = np.random.uniform(0.5, 1.5, size=self.dim)  # Random scaling\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor + \n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                perturbation = np.random.randn(self.dim) * 0.01 * np.exp(-self.evaluations/self.budget) * (bounds[:, 1] - bounds[:, 0]) # Exponential decay\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                diversity = np.mean(np.std(self.particles, axis=0))\n                self.w = max(0.4, 0.9 - (0.9 - 0.4) * (self.evaluations/self.budget) * (1 + 0.5 * diversity))\n                # New adaptive learning rate for personal best\n                self.c1 *= 1 + 0.01 * np.random.randn()\n                # New adaptive learning rate for global best\n                self.c2 *= 1 + 0.01 * np.random.randn()\n                \n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Introduce adaptive learning rates for personal and global best updates to better balance exploration and exploitation.", "configspace": "", "generation": 38, "fitness": 0.11139553643044446, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.111 with standard deviation 0.003. And the mean value of best solutions found was 0.121 (0. is the best).", "error": "", "parent_id": "b33d4f2a-0b71-4ebc-969b-00180e7d53e9", "metadata": {"aucs": [0.1071575700867754, 0.11239488931525632, 0.11463414988930165], "final_y": [0.13153058526809502, 0.12033422034023822, 0.11003840122517228]}, "mutation_prompt": null}
{"id": "58b37e19-0dfd-48d3-ac74-70062aa9cba2", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.c1 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                self.c2 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                scaling_factor = np.random.uniform(0.5, 1.5, size=self.dim)  # Random scaling\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor + \n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                perturbation = np.random.randn(self.dim) * 0.01 * np.exp(-self.evaluations/self.budget) * (bounds[:, 1] - bounds[:, 0]) # Exponential decay\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                diversity = np.mean(np.std(self.particles, axis=0))\n                self.w = max(0.4, 0.9 - (0.9 - 0.4) * (self.evaluations/self.budget) * (1 + 0.5 * diversity))\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Introduce dynamic inertia weight influenced by both the iteration progress and diversity of the swarm to enhance exploration and exploitation balance.", "configspace": "", "generation": 20, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('list index out of range').", "error": "IndexError('list index out of range')", "parent_id": "b33d4f2a-0b71-4ebc-969b-00180e7d53e9", "metadata": {"aucs": [0.11226079713997039, 0.11332469464504846, 0.11403411392480411], "final_y": [0.11391204572228575, 0.11949655738460652, 0.11154445444864092]}, "mutation_prompt": null}
{"id": "e8131948-b0fd-49bf-9dee-f16527e5d1a9", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.c1 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                self.c2 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                scaling_factor = np.random.uniform(0.5, 1.5, size=self.dim)  # Random scaling\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor + \n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                perturbation = np.random.randn(self.dim) * 0.01 * np.exp(-self.evaluations/self.budget) * (bounds[:, 1] - bounds[:, 0]) # Exponential decay\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                diversity = np.mean(np.std(self.particles, axis=0))\n                self.w = max(0.4, 0.9 - (0.9 - 0.4) * (self.evaluations/self.budget) * (1 + 0.5 * diversity))\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Introduce dynamic inertia weight influenced by both the iteration progress and diversity of the swarm to enhance exploration and exploitation balance.", "configspace": "", "generation": 20, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('list index out of range').", "error": "IndexError('list index out of range')", "parent_id": "b33d4f2a-0b71-4ebc-969b-00180e7d53e9", "metadata": {"aucs": [0.11226079713997039, 0.11332469464504846, 0.11403411392480411], "final_y": [0.11391204572228575, 0.11949655738460652, 0.11154445444864092]}, "mutation_prompt": null}
{"id": "3e8e538b-b6ab-4e59-b458-fded9ddbd12f", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.c1 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                self.c2 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                scaling_factor = np.random.uniform(0.5, 1.5, size=self.dim)  # Random scaling\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor + \n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                perturbation = np.random.randn(self.dim) * 0.01 * np.exp(-self.evaluations/self.budget) * (bounds[:, 1] - bounds[:, 0]) # Exponential decay\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                diversity = np.mean(np.std(self.particles, axis=0))\n                self.w = max(0.4, 0.9 - (0.9 - 0.4) * (self.evaluations/self.budget) * (1 + 0.5 * diversity))\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        # Introduce chaotic map for initial velocity\n        chaotic_map = np.sin(np.linspace(0, np.pi, self.population_size))\n        self.velocities = (chaotic_map[:, None] * np.random.randn(self.population_size, self.dim) * \n                           (bounds[:, 1] - bounds[:, 0]) * 0.1)\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Introduce chaotic map-based velocity initialization to enhance exploration capabilities in early iterations.", "configspace": "", "generation": 41, "fitness": 0.11298189044471596, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.113 with standard deviation 0.001. And the mean value of best solutions found was 0.116 (0. is the best).", "error": "", "parent_id": "b33d4f2a-0b71-4ebc-969b-00180e7d53e9", "metadata": {"aucs": [0.11431529881967062, 0.11256002423685652, 0.11207034827762075], "final_y": [0.10981734087265549, 0.12006995944699894, 0.1180216366534631]}, "mutation_prompt": null}
{"id": "ba9b6f46-0aee-45c3-8e89-d1b14a1f5e41", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.c1 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                self.c2 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                scaling_factor = np.random.uniform(0.5, 1.5, size=self.dim)  # Random scaling\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor + \n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                perturbation = np.random.randn(self.dim) * 0.01 * np.exp(-self.evaluations/self.budget) * (bounds[:, 1] - bounds[:, 0]) # Exponential decay\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight with additional dynamic factor\n                diversity = np.mean(np.std(self.particles, axis=0))\n                dynamic_factor = np.abs(np.sin(self.evaluations * np.pi / self.budget))\n                self.w = max(0.4, 0.9 - (0.9 - 0.4) * (self.evaluations/self.budget) * (1 + 0.5 * diversity) * dynamic_factor)\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Introduced a dynamic adjustment factor for the inertia weight to further enhance the balance between exploration and exploitation.", "configspace": "", "generation": 42, "fitness": 0.11314229540861043, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.113 with standard deviation 0.000. And the mean value of best solutions found was 0.114 (0. is the best).", "error": "", "parent_id": "b33d4f2a-0b71-4ebc-969b-00180e7d53e9", "metadata": {"aucs": [0.1132177207167715, 0.11287821599077441, 0.11333094951828537], "final_y": [0.11085596141345777, 0.11807871142621629, 0.11217877155128897]}, "mutation_prompt": null}
{"id": "a482d43f-5e61-42cc-a542-d6f6777e3a93", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.c1 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                self.c2 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                scaling_factor = np.random.uniform(0.5, 1.5, size=self.dim)  # Random scaling\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor + \n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Introduce Levy flight perturbation\n                levy = np.random.normal(0, 0.1, self.dim) * (1.0 / (np.abs(np.random.randn(self.dim))**(1/3)))\n                perturbation = np.random.randn(self.dim) * 0.01 * np.exp(-self.evaluations/self.budget) * (bounds[:, 1] - bounds[:, 0]) + levy\n\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                diversity = np.mean(np.std(self.particles, axis=0))\n                self.w = max(0.4, 0.9 - (0.9 - 0.4) * (self.evaluations/self.budget) * (1 + 0.5 * diversity))\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Enhance the exploration by introducing Levy flights in particle updates and adaptive velocity limits.", "configspace": "", "generation": 43, "fitness": 0.11253113089404361, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.113 with standard deviation 0.005. And the mean value of best solutions found was 0.119 (0. is the best).", "error": "", "parent_id": "b33d4f2a-0b71-4ebc-969b-00180e7d53e9", "metadata": {"aucs": [0.10598095418450804, 0.11633469167793098, 0.11527774681969183], "final_y": [0.13493626736071251, 0.11174003382478304, 0.10968299682704308]}, "mutation_prompt": null}
{"id": "3fa6d39e-0d91-4153-8827-1190917f6bbb", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.6  # Social coefficient  # Changed from 1.5 to 1.6\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.c1 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                self.c2 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                scaling_factor = np.random.uniform(0.5, 1.5, size=self.dim)  # Random scaling\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor + \n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                perturbation = np.random.randn(self.dim) * 0.01 * np.exp(-self.evaluations/self.budget) * (bounds[:, 1] - bounds[:, 0]) # Exponential decay\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                diversity = np.mean(np.std(self.particles, axis=0))\n                self.w = max(0.4, 0.9 - (0.9 - 0.4) * (self.evaluations/self.budget) * (1 + 0.5 * diversity))\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Enhance convergence by increasing the influence of the global best position with a slight modification in the social coefficient.", "configspace": "", "generation": 44, "fitness": 0.11320653523660766, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.113 with standard deviation 0.001. And the mean value of best solutions found was 0.115 (0. is the best).", "error": "", "parent_id": "b33d4f2a-0b71-4ebc-969b-00180e7d53e9", "metadata": {"aucs": [0.11226079713997039, 0.11332469464504846, 0.11403411392480411], "final_y": [0.11391204572228575, 0.11949655738460652, 0.11154445444864092]}, "mutation_prompt": null}
{"id": "d088f8af-eebb-46cd-98a5-58e185119164", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.c1 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                self.c2 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                scaling_factor = np.random.uniform(0.5, 1.5, size=self.dim)  # Random scaling\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor + \n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                perturbation_scale = 0.05 * np.exp(-self.evaluations/self.budget) * (1 + 0.3 * np.std(self.particles, axis=0))\n                perturbation = np.random.randn(self.dim) * perturbation_scale * (bounds[:, 1] - bounds[:, 0])\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                diversity = np.mean(np.std(self.particles, axis=0))\n                self.w = max(0.4, 0.9 - (0.9 - 0.4) * (self.evaluations/self.budget) * (1 + 0.5 * diversity))\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Introduce a dynamic perturbation factor influenced by the iteration progress and diversity of the swarm to enhance local search capability.", "configspace": "", "generation": 45, "fitness": 0.0977290921221855, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.098 with standard deviation 0.002. And the mean value of best solutions found was 0.162 (0. is the best).", "error": "", "parent_id": "b33d4f2a-0b71-4ebc-969b-00180e7d53e9", "metadata": {"aucs": [0.09452654387708725, 0.10012745636358078, 0.09853327612588847], "final_y": [0.17024136367429088, 0.15589132495341607, 0.161066184144524]}, "mutation_prompt": null}
{"id": "99dcaf8e-73c4-49be-aac2-7b0a898edf8c", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.c1 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                self.c2 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                scaling_factor = np.random.uniform(0.5, 1.5, size=self.dim)  # Random scaling\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor + \n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                perturbation = np.random.randn(self.dim) * 0.05 * np.exp(-self.evaluations/self.budget) * (bounds[:, 1] - bounds[:, 0]) # Exponential decay\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                diversity = np.mean(np.std(self.particles, axis=0))\n                self.w = max(0.4, 0.9 - (0.9 - 0.4) * (self.evaluations/self.budget) * (1 + 0.5 * diversity))\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Improve exploration by adjusting the perturbation factor for better convergence.", "configspace": "", "generation": 46, "fitness": 0.11230628014924697, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.112 with standard deviation 0.001. And the mean value of best solutions found was 0.118 (0. is the best).", "error": "", "parent_id": "b33d4f2a-0b71-4ebc-969b-00180e7d53e9", "metadata": {"aucs": [0.11131240214616867, 0.11308860314022029, 0.11251783516135194], "final_y": [0.11996720364576796, 0.12035992076289714, 0.11322664829427753]}, "mutation_prompt": null}
{"id": "2aae9244-e48b-4995-9ac3-acc003b3df9a", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                proximity_factor = np.linalg.norm(self.particles[i] - self.global_best_position) / np.linalg.norm(bounds[:, 1] - bounds[:, 0])\n                self.c1 = 1.0 + (0.5 * proximity_factor)  # Adaptive cognitive adjustment\n                self.c2 = 1.0 + (0.5 * (1 - proximity_factor))  # Adaptive social adjustment\n                scaling_factor = np.random.uniform(0.5, 1.5, size=self.dim)  # Random scaling\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor + \n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                velocity_randomization = np.random.randn(self.dim) * 0.1 * (bounds[:, 1] - bounds[:, 0])  # Random velocity perturbation\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + velocity_randomization, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                diversity = np.mean(np.std(self.particles, axis=0))\n                self.w = max(0.4, 0.9 - (0.9 - 0.4) * (self.evaluations/self.budget) * (1 + 0.5 * diversity))\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Improve exploration by introducing velocity randomization and adaptive cognitive/social coefficients based on proximity to global best.", "configspace": "", "generation": 47, "fitness": 0.10669698405449994, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.107 with standard deviation 0.003. And the mean value of best solutions found was 0.137 (0. is the best).", "error": "", "parent_id": "b33d4f2a-0b71-4ebc-969b-00180e7d53e9", "metadata": {"aucs": [0.10213420724255096, 0.10775873161191996, 0.1101980133090289], "final_y": [0.14933538983212558, 0.13595583891977736, 0.12702726192232916]}, "mutation_prompt": null}
{"id": "d8884714-f64d-496a-b451-1e912f9de86a", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.c1 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                self.c2 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                scaling_factor = np.random.uniform(0.5, 1.5, size=self.dim)  # Random scaling\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor + \n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]) +\n                                      0.01 * np.random.randn(self.dim))  # Small random perturbation\n\n                # Update particle position\n                perturbation = np.random.randn(self.dim) * 0.01 * np.exp(-self.evaluations/self.budget) * (bounds[:, 1] - bounds[:, 0]) # Exponential decay\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                diversity = np.mean(np.std(self.particles, axis=0))\n                self.w = max(0.4, 0.9 - (0.9 - 0.4) * (self.evaluations/self.budget) * (1 + 0.5 * diversity))\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Enhance the update mechanism by introducing a small random perturbation to the velocities to improve convergence diversity.", "configspace": "", "generation": 48, "fitness": 0.11233447032375858, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.112 with standard deviation 0.001. And the mean value of best solutions found was 0.120 (0. is the best).", "error": "", "parent_id": "b33d4f2a-0b71-4ebc-969b-00180e7d53e9", "metadata": {"aucs": [0.11315750789372503, 0.11099515181102759, 0.11285075126652311], "final_y": [0.11639377544847185, 0.12505713084225656, 0.1172896582022217]}, "mutation_prompt": null}
{"id": "44f7ff4e-b0a2-4c99-a91d-305c236d4d39", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.c1 = 1.2 + (0.4 * np.random.rand())  # Changed from 0.3 to 0.4 for better adaptation\n                self.c2 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                scaling_factor = np.random.uniform(0.5, 1.5, size=self.dim)  # Random scaling\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor + \n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                perturbation = np.random.randn(self.dim) * 0.01 * np.exp(-self.evaluations/self.budget) * (bounds[:, 1] - bounds[:, 0]) # Exponential decay\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                diversity = np.mean(np.std(self.particles, axis=0))\n                self.w = max(0.4, 0.9 - (0.9 - 0.4) * (self.evaluations/self.budget) * (1 + 0.5 * diversity))\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Enhance performance by refining the dynamic factor adjustment for cognitive and social coefficients.", "configspace": "", "generation": 49, "fitness": 0.11174673155540986, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.112 with standard deviation 0.001. And the mean value of best solutions found was 0.120 (0. is the best).", "error": "", "parent_id": "b33d4f2a-0b71-4ebc-969b-00180e7d53e9", "metadata": {"aucs": [0.11220363107429554, 0.11318853965159437, 0.10984802394033966], "final_y": [0.11418413293502361, 0.12037024590741374, 0.12510514927836147]}, "mutation_prompt": null}
{"id": "ca37b711-18c4-402e-978e-9af0fcf78e68", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.c1 = 1.2 + (0.3 * np.cos(np.pi * self.evaluations/self.budget))  # Dynamic adjustment\n                self.c2 = 1.2 + (0.3 * np.sin(np.pi * self.evaluations/self.budget))  # Dynamic adjustment\n                scaling_factor = np.random.uniform(0.5, 1.5, size=self.dim)  # Random scaling\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor + \n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                perturbation = np.random.randn(self.dim) * 0.01 * np.exp(-self.evaluations/self.budget) * (bounds[:, 1] - bounds[:, 0]) # Exponential decay\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                diversity = np.mean(np.std(self.particles, axis=0))\n                self.w = max(0.4, 0.9 - (0.9 - 0.4) * (self.evaluations/self.budget) * (1 + 0.5 * diversity))\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Enhance particle diversity and convergence by implementing dynamic cognitive and social coefficients based on iteration progress.", "configspace": "", "generation": 50, "fitness": 0.11241256100456605, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.112 with standard deviation 0.002. And the mean value of best solutions found was 0.118 (0. is the best).", "error": "", "parent_id": "b33d4f2a-0b71-4ebc-969b-00180e7d53e9", "metadata": {"aucs": [0.11026842058544539, 0.11335208574032019, 0.11361717668793259], "final_y": [0.12132498000378344, 0.11849926212800821, 0.11295478119985358]}, "mutation_prompt": null}
{"id": "b968ac1f-a5cd-4129-95b8-22a2bbde47ba", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.c1 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                self.c2 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                scaling_factor = np.random.uniform(0.5, 1.5, size=self.dim)  # Random scaling\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor + \n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                perturbation = np.random.randn(self.dim) * 0.01 * np.exp(-self.evaluations/self.budget) * (bounds[:, 1] - bounds[:, 0]) # Exponential decay\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                diversity = np.mean(np.std(self.particles, axis=0))\n                self.w = max(0.4, 0.9 - (0.9 - 0.4) * (self.evaluations/self.budget) * (1 + 0.5 * diversity * np.random.rand()))\n                \n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Enhanced inertia weight adaptation using dynamic learning elements linked to particle diversity and iteration progress.", "configspace": "", "generation": 51, "fitness": 0.11150299444668584, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.112 with standard deviation 0.002. And the mean value of best solutions found was 0.121 (0. is the best).", "error": "", "parent_id": "b33d4f2a-0b71-4ebc-969b-00180e7d53e9", "metadata": {"aucs": [0.10874492847852302, 0.11303234717428845, 0.11273170768724605], "final_y": [0.12721705982569087, 0.11883076909877133, 0.11753822484379717]}, "mutation_prompt": null}
{"id": "6ec0274d-8a7e-43dc-8951-464e1ae34aed", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.c1 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                self.c2 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                scaling_factor = np.random.uniform(0.5, 1.5, size=self.dim)  # Random scaling\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor + \n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                perturbation = np.random.randn(self.dim) * 0.01 * np.log1p(self.budget - self.evaluations) * (bounds[:, 1] - bounds[:, 0]) # Logarithmic decay\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                diversity = np.mean(np.std(self.particles, axis=0))\n                self.w = max(0.4, 0.9 - (0.9 - 0.4) * (self.evaluations/self.budget) * (1 + 0.5 * diversity))\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Enhancing the PSO algorithm by replacing exponential perturbation decay with a logarithmic decay to balance exploration.", "configspace": "", "generation": 52, "fitness": 0.10973389153421131, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.110 with standard deviation 0.001. And the mean value of best solutions found was 0.128 (0. is the best).", "error": "", "parent_id": "b33d4f2a-0b71-4ebc-969b-00180e7d53e9", "metadata": {"aucs": [0.10953801908752503, 0.11074997286425958, 0.10891368265084933], "final_y": [0.12798513863036098, 0.12339767280794534, 0.13119162019080022]}, "mutation_prompt": null}
{"id": "df9849b5-9721-4243-a4df-fa6f7340bf03", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.c1 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                self.c2 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                scaling_factor = np.random.uniform(0.5, 1.5, size=self.dim)  # Random scaling\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor + \n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                perturbation_strength = 0.01 * np.exp(-self.evaluations/self.budget) * (self.personal_best_scores[i] / self.global_best_score)\n                perturbation = np.random.randn(self.dim) * perturbation_strength * (bounds[:, 1] - bounds[:, 0]) # Dynamic perturbation\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                diversity = np.mean(np.std(self.particles, axis=0))\n                self.w = max(0.4, 0.9 - (0.9 - 0.4) * (self.evaluations/self.budget) * (1 + 0.5 * diversity))\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Introduce adaptive local search through dynamic perturbation influenced by particle performance to improve exploitation capability.", "configspace": "", "generation": 53, "fitness": 0.11251478441352143, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.113 with standard deviation 0.001. And the mean value of best solutions found was 0.117 (0. is the best).", "error": "", "parent_id": "b33d4f2a-0b71-4ebc-969b-00180e7d53e9", "metadata": {"aucs": [0.11264998268413928, 0.1134748033545484, 0.11141956720187662], "final_y": [0.116410866545677, 0.11762379414177904, 0.1165079275894374]}, "mutation_prompt": null}
{"id": "986723e1-3348-4211-99bc-39191f38f7aa", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.c1 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                self.c2 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                scaling_factor = np.random.uniform(0.5, 1.5, size=self.dim)\n                # Adaptive velocity scaling\n                velocity_scaling = 1 - (self.evaluations / self.budget)\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor * velocity_scaling +\n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                perturbation = np.random.randn(self.dim) * 0.01 * np.exp(-self.evaluations/self.budget) * (bounds[:, 1] - bounds[:, 0])\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                diversity = np.mean(np.std(self.particles, axis=0))\n                self.w = max(0.4, 0.9 - (0.9 - 0.4) * (self.evaluations/self.budget) * (1 + 0.5 * diversity))\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Integrate a convergence acceleration mechanism using a decaying perturbation factor and adaptive velocity scaling to enhance convergence speed and solution precision.", "configspace": "", "generation": 54, "fitness": 0.1126243819742269, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.113 with standard deviation 0.001. And the mean value of best solutions found was 0.117 (0. is the best).", "error": "", "parent_id": "b33d4f2a-0b71-4ebc-969b-00180e7d53e9", "metadata": {"aucs": [0.11236819263249076, 0.11337878976530369, 0.11212616352488625], "final_y": [0.11261280146093844, 0.118941487594315, 0.1186760513467755]}, "mutation_prompt": null}
{"id": "d545f061-ddcf-48eb-9da4-52d9d1a89c8f", "solution": "import numpy as np\n\nclass ChaoticAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.7\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n        self.chaotic_sequence = self.generate_chaotic_sequence(self.budget, logistic_map=True)\n\n    def generate_chaotic_sequence(self, length, logistic_map=False):\n        x = np.random.rand()\n        sequence = []\n        for _ in range(length):\n            if logistic_map:\n                x = 4 * x * (1 - x)  # Logistic map\n            sequence.append(x)\n        return np.array(sequence)\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                r1 = self.chaotic_sequence[self.evaluations % len(self.chaotic_sequence)]\n                r2 = np.random.rand(self.dim)\n\n                self.c1 = 1.2 + (0.3 * r1)  # Dynamic adjustment with chaotic influence\n                self.c2 = 1.2 + (0.3 * np.random.rand())\n\n                scaling_factor = np.random.uniform(0.5, 1.5, size=self.dim)\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor +\n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) +\n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                perturbation = np.random.randn(self.dim) * 0.01 * np.exp(-self.evaluations/self.budget) * (bounds[:, 1] - bounds[:, 0])\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation, bounds[:, 0], bounds[:, 1])\n\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                diversity = np.mean(np.std(self.particles, axis=0))\n                self.w = max(0.4, 0.9 - (0.9 - 0.4) * (self.evaluations/self.budget) * (1 + 0.5 * diversity))\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "ChaoticAdaptivePSO", "description": "Enhance exploration and exploitation balance by incorporating chaotic maps and adaptive parameters to improve convergence behavior in dynamic environments.", "configspace": "", "generation": 55, "fitness": 0.1121512038843195, "feedback": "The algorithm ChaoticAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.112 with standard deviation 0.001. And the mean value of best solutions found was 0.116 (0. is the best).", "error": "", "parent_id": "b33d4f2a-0b71-4ebc-969b-00180e7d53e9", "metadata": {"aucs": [0.11281046517917559, 0.11252730146100409, 0.11111584501277882], "final_y": [0.11309169015083598, 0.11733496374365726, 0.11767012297840673]}, "mutation_prompt": null}
{"id": "1d5c8da9-b4f2-4c24-bf90-0f8213066832", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.c1 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                self.c2 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                scaling_factor = np.random.uniform(0.5, 1.5, size=self.dim)  # Random scaling\n                leader_influence = np.random.rand() * (self.global_best_position - self.particles[i])  # Leader-based search\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor + \n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * leader_influence)\n\n                # Update particle position\n                perturbation = np.random.randn(self.dim) * 0.01 * np.exp(-self.evaluations/self.budget) * (bounds[:, 1] - bounds[:, 0]) * (1 + 0.1 * np.random.rand())  # Adaptive perturbation\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                diversity = np.mean(np.std(self.particles, axis=0))\n                self.w = max(0.4, 0.9 - (0.9 - 0.4) * (self.evaluations/self.budget) * (1 + 0.5 * diversity))\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Enhance the PSO by integrating a leader-based search mechanism and adaptive perturbation for improved exploration.", "configspace": "", "generation": 56, "fitness": 0.1121394786884109, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.112 with standard deviation 0.001. And the mean value of best solutions found was 0.116 (0. is the best).", "error": "", "parent_id": "b33d4f2a-0b71-4ebc-969b-00180e7d53e9", "metadata": {"aucs": [0.11227252852329628, 0.11301025462044734, 0.11113565292148908], "final_y": [0.11779509190585791, 0.11177048171797033, 0.1197933203812499]}, "mutation_prompt": null}
{"id": "76b0e802-59b2-4605-b2a6-68a1fc2d6207", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.c1 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                self.c2 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                scaling_factor = np.random.uniform(0.5, 1.5, size=self.dim)  # Random scaling\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor + \n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                perturbation = np.random.randn(self.dim) * 0.01 * np.exp(-self.evaluations/self.budget) * (bounds[:, 1] - bounds[:, 0]) # Exponential decay\n                diff_perturbation = 0.1 * (self.personal_best_positions[np.random.randint(self.population_size)] - self.personal_best_positions[np.random.randint(self.population_size)])  # DE inspired\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation + diff_perturbation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                diversity = np.mean(np.std(self.particles, axis=0))\n                self.w = max(0.4, 0.9 - (0.9 - 0.4) * (self.evaluations/self.budget) * (1 + 0.5 * diversity))\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Enhance exploration by integrating differential evolution inspired perturbations with the dynamic inertia weight strategy.", "configspace": "", "generation": 57, "fitness": 0.11285257441265006, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.113 with standard deviation 0.003. And the mean value of best solutions found was 0.116 (0. is the best).", "error": "", "parent_id": "b33d4f2a-0b71-4ebc-969b-00180e7d53e9", "metadata": {"aucs": [0.10892331757243268, 0.11598769009522103, 0.11364671557029649], "final_y": [0.1262567468605722, 0.10989403227225514, 0.1115584029508655]}, "mutation_prompt": null}
{"id": "5b7f7d26-7686-45bf-a049-f0425f94e817", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.c1 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                self.c2 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                scaling_factor = np.random.uniform(0.5, 1.5, size=self.dim)  # Random scaling\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor + \n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                perturbation_scale = np.exp(-self.evaluations/self.budget)\n                perturbation = np.random.randn(self.dim) * 0.01 * perturbation_scale * (bounds[:, 1] - bounds[:, 0])\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                diversity = np.mean(np.std(self.particles, axis=0))\n                self.w = max(0.4, 0.9 - (0.9 - 0.4) * (self.evaluations/self.budget) * (1 + 0.5 * diversity))\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Introduce adaptive perturbation scaling based on the remaining budget to balance exploration and exploitation.", "configspace": "", "generation": 58, "fitness": 0.11320653523660766, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.113 with standard deviation 0.001. And the mean value of best solutions found was 0.115 (0. is the best).", "error": "", "parent_id": "b33d4f2a-0b71-4ebc-969b-00180e7d53e9", "metadata": {"aucs": [0.11226079713997039, 0.11332469464504846, 0.11403411392480411], "final_y": [0.11391204572228575, 0.11949655738460652, 0.11154445444864092]}, "mutation_prompt": null}
{"id": "76bb949d-0e5e-40d2-bfc9-22d703df747c", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.c1 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                self.c2 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                scaling_factor = np.random.uniform(0.5, 1.5, size=self.dim)  # Random scaling\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor + \n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                perturbation = np.random.randn(self.dim) * 0.01 * np.exp(-self.evaluations/self.budget) * (bounds[:, 1] - bounds[:, 0]) # Exponential decay\n                mutation = np.random.randn(self.dim) * 0.001 * np.mean(np.std(self.particles, axis=0)) # Mutation based on diversity\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation + mutation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                diversity = np.mean(np.std(self.particles, axis=0))\n                self.w = max(0.4, 0.9 - (0.9 - 0.4) * (self.evaluations/self.budget) * (1 + 0.5 * diversity))\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Integrate a mutation mechanism influenced by population diversity to enhance exploration without sacrificing convergence.", "configspace": "", "generation": 59, "fitness": 0.1134174342911038, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.113 with standard deviation 0.002. And the mean value of best solutions found was 0.115 (0. is the best).", "error": "", "parent_id": "b33d4f2a-0b71-4ebc-969b-00180e7d53e9", "metadata": {"aucs": [0.11148377040411939, 0.11264996434789543, 0.11611856812129662], "final_y": [0.11784981797418059, 0.11853290786514004, 0.11003881526706116]}, "mutation_prompt": null}
{"id": "b6b06f34-bfc3-4393-a9dc-cde23aeedfb3", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.c1 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                self.c2 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                scaling_factor = np.random.uniform(0.5, 1.5, size=self.dim)  # Random scaling\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor + \n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                perturbation = np.random.randn(self.dim) * 0.01 * np.exp(-self.evaluations/self.budget) * (bounds[:, 1] - bounds[:, 0]) # Exponential decay\n                mutation = np.random.randn(self.dim) * 0.001 * np.mean(np.std(self.particles, axis=0)) # Mutation based on diversity\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation + mutation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                diversity = np.mean(np.std(self.particles, axis=0))\n                self.w = max(0.4, 0.9 - (0.9 - 0.4) * (self.evaluations/self.budget) * (1 + 0.5 * diversity))\n                if self.evaluations % 10 == 0: self.w *= 0.9  # Convergence feedback\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Enhance convergence by incorporating adaptive learning rates and a feedback mechanism based on recent improvements.", "configspace": "", "generation": 60, "fitness": 0.11382898204512475, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.114 with standard deviation 0.002. And the mean value of best solutions found was 0.115 (0. is the best).", "error": "", "parent_id": "76bb949d-0e5e-40d2-bfc9-22d703df747c", "metadata": {"aucs": [0.11172670886786273, 0.1133357782728216, 0.1164244589946899], "final_y": [0.11756241179347182, 0.11785581396316547, 0.10987988854332675]}, "mutation_prompt": null}
{"id": "39feea89-c64b-4672-af11-8779970ba5c1", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.c1 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                self.c2 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                scaling_factor = np.random.uniform(0.5, 1.5, size=self.dim)  # Random scaling\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor + \n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                perturbation = np.random.randn(self.dim) * 0.01 * np.exp(-self.evaluations/self.budget) * (bounds[:, 1] - bounds[:, 0]) # Exponential decay\n                mutation = np.random.randn(self.dim) * 0.001 * np.mean(np.std(self.particles, axis=0)) # Mutation based on diversity\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation + mutation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight and personal learning rate\n                diversity = np.mean(np.std(self.particles, axis=0))\n                self.w = max(0.4, 0.9 - (0.9 - 0.4) * (self.evaluations/self.budget) * (1 + 0.5 * diversity))\n                self.c1 *= (1.1 if diversity > 0.1 else 0.9)  # New adaptation mechanism\n                if self.evaluations % 10 == 0: self.w *= 0.9  # Convergence feedback\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Introduce adaptive personal learning rates and improved diversity mechanisms for enhanced convergence.", "configspace": "", "generation": 61, "fitness": 0.11382898204512475, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.114 with standard deviation 0.002. And the mean value of best solutions found was 0.115 (0. is the best).", "error": "", "parent_id": "b6b06f34-bfc3-4393-a9dc-cde23aeedfb3", "metadata": {"aucs": [0.11172670886786273, 0.1133357782728216, 0.1164244589946899], "final_y": [0.11756241179347182, 0.11785581396316547, 0.10987988854332675]}, "mutation_prompt": null}
{"id": "080159b2-a1d8-4b69-9929-67ecdb8c9edf", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.c1 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                self.c2 = 1.2 + (0.3 * np.random.rand())  # Dynamic adjustment\n                scaling_factor = np.random.uniform(0.5, 1.5, size=self.dim)  # Random scaling\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor + \n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                perturbation = np.random.randn(self.dim) * 0.01 * np.exp(-self.evaluations/self.budget) * (bounds[:, 1] - bounds[:, 0]) # Exponential decay\n                mutation = np.random.randn(self.dim) * 0.001 * np.mean(np.std(self.particles, axis=0)) # Mutation based on diversity\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation + mutation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                diversity = np.mean(np.std(self.particles, axis=0))\n                self.w = max(0.2, 0.9 - (0.9 - 0.2) * (self.evaluations/self.budget) * (1 + 0.5 * diversity))\n                if self.evaluations % 10 == 0: self.w *= 0.9  # Convergence feedback\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Improved convergence by refining the inertia weight adaptation to better balance exploration and exploitation.", "configspace": "", "generation": 62, "fitness": 0.11424276397539346, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.114 with standard deviation 0.003. And the mean value of best solutions found was 0.116 (0. is the best).", "error": "", "parent_id": "b6b06f34-bfc3-4393-a9dc-cde23aeedfb3", "metadata": {"aucs": [0.11019394590782638, 0.11672325652659932, 0.11581108949175467], "final_y": [0.12465263368008661, 0.11151704313713184, 0.1125853985300257]}, "mutation_prompt": null}
{"id": "1da72819-3eeb-4f0f-842e-c71988fa4546", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                decay_factor = 1 - (self.evaluations / self.budget)  # Linear decay factor\n                self.c1 = (1.2 + (0.3 * np.random.rand())) * decay_factor  # Apply decay\n                self.c2 = (1.2 + (0.3 * np.random.rand())) * decay_factor  # Apply decay\n                scaling_factor = np.random.uniform(0.5, 1.5, size=self.dim)  # Random scaling\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor + \n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                perturbation = np.random.randn(self.dim) * 0.01 * np.exp(-self.evaluations/self.budget) * (bounds[:, 1] - bounds[:, 0]) # Exponential decay\n                mutation = np.random.randn(self.dim) * 0.001 * np.mean(np.std(self.particles, axis=0)) # Mutation based on diversity\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation + mutation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                diversity = np.mean(np.std(self.particles, axis=0))\n                self.w = max(0.2, 0.9 - (0.9 - 0.2) * (self.evaluations/self.budget) * (1 + 0.5 * diversity))\n                if self.evaluations % 10 == 0: self.w *= 0.9  # Convergence feedback\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Enhanced convergence by introducing a linear decay factor to the cognitive and social coefficients for better exploration and exploitation balance.", "configspace": "", "generation": 63, "fitness": 0.11446238378030027, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.114 with standard deviation 0.001. And the mean value of best solutions found was 0.116 (0. is the best).", "error": "", "parent_id": "080159b2-a1d8-4b69-9929-67ecdb8c9edf", "metadata": {"aucs": [0.11360673778476393, 0.11411502896529035, 0.11566538459084652], "final_y": [0.11807893117105073, 0.11853442140235393, 0.11003348455928985]}, "mutation_prompt": null}
{"id": "75c45eb7-95cb-4be2-ad78-889d68dcb3f8", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                decay_factor = 1 - (self.evaluations / self.budget)  # Linear decay factor\n                self.c1 = 2 * decay_factor  # Updated adaptive coefficient\n                self.c2 = 2 * decay_factor  # Updated adaptive coefficient\n                scaling_factor = np.random.uniform(0.5, 1.5, size=self.dim)  # Random scaling\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor + \n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                dynamic_perturb = np.random.randn(self.dim) * 0.02 * np.exp(-self.evaluations/self.budget) * (bounds[:, 1] - bounds[:, 0]) # Dynamic perturbation\n                mutation = np.random.randn(self.dim) * 0.001 * np.mean(np.std(self.particles, axis=0)) # Mutation based on diversity\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + dynamic_perturb + mutation, bounds[:, 0], bounds[:, 1])\n                \n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                diversity = np.mean(np.std(self.particles, axis=0))\n                self.w = max(0.2, 0.9 - (0.9 - 0.2) * (self.evaluations/self.budget) * (1 + 0.5 * diversity))\n                if self.evaluations % 10 == 0: self.w *= 0.9  # Convergence feedback\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Introducing adaptive coefficients and a dynamic perturbation factor to improve convergence and exploration.", "configspace": "", "generation": 64, "fitness": 0.1102603541236656, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.110 with standard deviation 0.001. And the mean value of best solutions found was 0.123 (0. is the best).", "error": "", "parent_id": "1da72819-3eeb-4f0f-842e-c71988fa4546", "metadata": {"aucs": [0.11025943159657947, 0.10953141406031519, 0.11099021671410214], "final_y": [0.12450666982026892, 0.1266755072900566, 0.1173372470482622]}, "mutation_prompt": null}
{"id": "2b55dd99-0560-45cd-9d9f-cf4f7ec220a9", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                decay_factor = 1 - (self.evaluations / self.budget)  # Linear decay factor\n                self.c1 = (1.2 + (0.3 * np.random.rand())) * decay_factor  # Apply decay\n                self.c2 = (1.2 + (0.3 * np.random.rand())) * decay_factor  # Apply decay\n                scaling_factor = np.random.uniform(0.5, 1.5, size=self.dim)  # Random scaling\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor + \n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) * scaling_factor +  # Change\n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n                \n                # Update particle position\n                perturbation = np.random.randn(self.dim) * 0.01 * np.exp(-self.evaluations/self.budget) * (bounds[:, 1] - bounds[:, 0]) # Exponential decay\n                mutation = np.random.randn(self.dim) * 0.001 * np.mean(np.std(self.particles, axis=0)) # Mutation based on diversity\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation + mutation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                diversity = np.mean(np.std(self.particles, axis=0))\n                self.w = max(0.2, 0.9 - (0.9 - 0.2) * (self.evaluations/self.budget) * (1 + 0.5 * diversity))\n                if self.evaluations % 10 == 0: self.w *= 0.9  # Convergence feedback\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Introduced adaptive scaling factors to velocity components for improved exploration and convergence balance.", "configspace": "", "generation": 65, "fitness": 0.11434961632179508, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.114 with standard deviation 0.001. And the mean value of best solutions found was 0.116 (0. is the best).", "error": "", "parent_id": "1da72819-3eeb-4f0f-842e-c71988fa4546", "metadata": {"aucs": [0.11359841705943607, 0.11413268191746506, 0.1153177499884841], "final_y": [0.11806720740687204, 0.11834522835684191, 0.11058640640368222]}, "mutation_prompt": null}
{"id": "82558fe6-b629-4141-b377-6a44e036fd92", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                decay_factor = 1 - (self.evaluations / self.budget)  # Linear decay factor\n                self.c1 = (1.2 + (0.3 * np.random.rand())) * decay_factor  # Apply decay\n                self.c2 = (1.2 + (0.3 * np.random.rand())) * decay_factor  # Apply decay\n                scaling_factor = np.random.uniform(0.5, 1.5, size=self.dim)  # Random scaling\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor + \n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                perturbation = np.random.randn(self.dim) * 0.01 * np.exp(-self.evaluations/self.budget) * (bounds[:, 1] - bounds[:, 0]) # Exponential decay\n                mutation = np.random.randn(self.dim) * 0.001 * np.mean(np.std(self.particles, axis=0)) # Mutation based on diversity\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation + mutation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                diversity = np.mean(np.std(self.particles, axis=0))\n                self.w = max(0.1, 0.9 - (0.9 - 0.1) * (self.evaluations/self.budget) * (1 + 0.5 * diversity))\n                if self.evaluations % 10 == 0: self.w *= 0.9  # Convergence feedback\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Improved convergence by adjusting inertia weight decay to a more dynamic range for enhanced exploration.", "configspace": "", "generation": 66, "fitness": 0.11358489171698942, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.114 with standard deviation 0.000. And the mean value of best solutions found was 0.119 (0. is the best).", "error": "", "parent_id": "1da72819-3eeb-4f0f-842e-c71988fa4546", "metadata": {"aucs": [0.11390530775703311, 0.11344837848282663, 0.1134009889111085], "final_y": [0.11809290955514706, 0.12128082963249409, 0.11841148193479767]}, "mutation_prompt": null}
{"id": "5925c593-22fa-49f9-b186-3dd5b91c674e", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                decay_factor = 1 - (self.evaluations / self.budget)  # Linear decay factor\n                self.c1 = (1.2 + (0.3 * np.random.rand())) * decay_factor  # Apply decay\n                self.c2 = (1.2 + (0.3 * np.random.rand())) * decay_factor  # Apply decay\n                scaling_factor = np.random.uniform(0.5, 1.5, size=self.dim)  # Random scaling\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor * 0.99 +  # Added damping factor\n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                perturbation = np.random.randn(self.dim) * 0.01 * np.exp(-self.evaluations/self.budget) * (bounds[:, 1] - bounds[:, 0]) # Exponential decay\n                mutation = np.random.randn(self.dim) * 0.001 * np.mean(np.std(self.particles, axis=0)) # Mutation based on diversity\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation + mutation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                diversity = np.mean(np.std(self.particles, axis=0))\n                self.w = max(0.2, 0.9 - (0.9 - 0.2) * (self.evaluations/self.budget) * (1 + 0.5 * diversity))\n                if self.evaluations % 10 == 0: self.w *= 0.9  # Convergence feedback\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Enhanced convergence by integrating a small velocity damping factor to reduce oscillations.", "configspace": "", "generation": 67, "fitness": 0.1145547712045651, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.115 with standard deviation 0.001. And the mean value of best solutions found was 0.116 (0. is the best).", "error": "", "parent_id": "1da72819-3eeb-4f0f-842e-c71988fa4546", "metadata": {"aucs": [0.11377257949263986, 0.11408164405144328, 0.11581009006961218], "final_y": [0.11775167032667377, 0.11959953150141578, 0.11000276741931492]}, "mutation_prompt": null}
{"id": "3170cfac-e20d-48b3-b5e7-fd7a4241b497", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                decay_factor = 1 - (self.evaluations / self.budget)  # Linear decay factor\n                self.c1 = (1.2 + (0.3 * np.random.rand())) * decay_factor  # Apply decay\n                self.c2 = (1.2 + (0.3 * np.random.rand())) * decay_factor  # Apply decay\n                scaling_factor = np.random.uniform(0.5, 1.5, size=self.dim)  # Random scaling\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor * 0.99 +  # Added damping factor\n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                perturbation = np.random.randn(self.dim) * 0.01 * np.exp(-self.evaluations/self.budget) * (bounds[:, 1] - bounds[:, 0]) # Exponential decay\n                mutation = np.random.randn(self.dim) * 0.001 * np.mean(np.std(self.particles, axis=0)) # Mutation based on diversity\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation + mutation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                diversity = np.mean(np.std(self.particles, axis=0))\n                self.w = max(0.2, 0.9 - (0.9 - 0.2) * (self.evaluations/self.budget) * (1 + 0.5 * diversity))\n                if self.evaluations % 10 == 0: self.w *= 0.9  # Convergence feedback\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Enhanced convergence by integrating a small velocity damping factor to reduce oscillations.", "configspace": "", "generation": 68, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('list index out of range').", "error": "IndexError('list index out of range')", "parent_id": "5925c593-22fa-49f9-b186-3dd5b91c674e", "metadata": {"aucs": [0.11377257949263986, 0.11408164405144328, 0.11581009006961218], "final_y": [0.11775167032667377, 0.11959953150141578, 0.11000276741931492]}, "mutation_prompt": null}
{"id": "7a6cea36-e88b-4e0d-8ab4-89b5b3394f59", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                decay_factor = 1 - (self.evaluations / self.budget)  # Linear decay factor\n                self.c1 = (1.2 + (0.3 * np.random.rand())) * decay_factor  # Apply decay\n                self.c2 = (1.2 + (0.3 * np.random.rand())) * decay_factor  # Apply decay\n                scaling_factor = np.random.uniform(0.5, 1.5, size=self.dim)  # Random scaling\n                constriction_factor = 0.729  # Line added: Standard constriction factor\n                self.velocities[i] = constriction_factor * (self.w * self.velocities[i] + \n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                perturbation = np.random.randn(self.dim) * 0.01 * np.exp(-self.evaluations/self.budget) * (bounds[:, 1] - bounds[:, 0]) * (1 + 0.1 * decay_factor)  # Line altered: Adaptive perturbation\n                mutation = np.random.randn(self.dim) * 0.001 * np.mean(np.std(self.particles, axis=0)) # Mutation based on diversity\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation + mutation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                diversity = np.mean(np.std(self.particles, axis=0))\n                self.w = max(0.2, 0.9 - (0.9 - 0.2) * (self.evaluations/self.budget) * (1 + 0.5 * diversity))\n                if self.evaluations % 10 == 0: self.w *= 0.9  # Convergence feedback\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Enhanced stability and convergence by incorporating a dynamic constriction factor and adaptive perturbation.", "configspace": "", "generation": 69, "fitness": 0.11308681359628973, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.113 with standard deviation 0.001. And the mean value of best solutions found was 0.119 (0. is the best).", "error": "", "parent_id": "5925c593-22fa-49f9-b186-3dd5b91c674e", "metadata": {"aucs": [0.1138172593343284, 0.11321525892076079, 0.11222792253378], "final_y": [0.11729798552453263, 0.1202448707262046, 0.11989294825950758]}, "mutation_prompt": null}
{"id": "a1169668-ac05-4943-804a-ec3a4f5e0c7f", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                decay_factor = 1 - (self.evaluations / self.budget)  # Linear decay factor\n                diversity = np.mean(np.std(self.particles, axis=0))  # Added line: compute diversity\n                self.c1 = (1.2 + (0.3 * np.random.rand())) * decay_factor * (1 + diversity)  # Apply decay\n                self.c2 = (1.2 + (0.3 * np.random.rand())) * decay_factor  # Apply decay\n                scaling_factor = np.random.uniform(0.5, 1.5, size=self.dim)  # Random scaling\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor * 0.99 +  # Added damping factor\n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                perturbation = np.random.randn(self.dim) * 0.01 * np.exp(-self.evaluations/self.budget) * (bounds[:, 1] - bounds[:, 0]) # Exponential decay\n                mutation = np.random.randn(self.dim) * 0.001 * np.mean(np.std(self.particles, axis=0)) # Mutation based on diversity\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation + mutation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                diversity = np.mean(np.std(self.particles, axis=0))\n                self.w = max(0.2, 0.9 - (0.9 - 0.2) * (self.evaluations/self.budget) * (1 + 0.5 * diversity))\n                if self.evaluations % 10 == 0: self.w *= 0.9  # Convergence feedback\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Enhanced convergence by adjusting cognitive and social coefficients dynamically based on swarm diversity.", "configspace": "", "generation": 70, "fitness": 0.11386288295985802, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.114 with standard deviation 0.000. And the mean value of best solutions found was 0.118 (0. is the best).", "error": "", "parent_id": "5925c593-22fa-49f9-b186-3dd5b91c674e", "metadata": {"aucs": [0.11364266301454684, 0.11367474950000056, 0.11427123636502667], "final_y": [0.11831740596941565, 0.12079094001275237, 0.11392213728088851]}, "mutation_prompt": null}
{"id": "416e608a-a72c-412f-a3eb-a8625d4b4066", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                decay_factor = 1 - (self.evaluations / self.budget)  # Linear decay factor\n                self.c1 = (1.2 + (0.3 * np.random.rand())) * decay_factor  # Apply decay\n                self.c2 = (1.2 + (0.3 * np.random.rand())) * decay_factor  # Apply decay\n                scaling_factor = np.random.uniform(0.5, 1.5, size=self.dim)  # Random scaling\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor * 0.99 +  # Added damping factor\n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                perturbation = np.random.randn(self.dim) * 0.01 * np.exp(-self.evaluations/self.budget) * (bounds[:, 1] - bounds[:, 0]) # Exponential decay\n                convergence_speed = np.linalg.norm(self.global_best_position - self.personal_best_positions[i])  # Convergence speed\n                diversity = np.mean(np.std(self.particles, axis=0))\n                mutation = np.random.randn(self.dim) * 0.001 * np.mean(convergence_speed * diversity)  # Adaptive mutation\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation + mutation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                diversity = np.mean(np.std(self.particles, axis=0))\n                self.w = max(0.2, 0.9 - (0.9 - 0.2) * (self.evaluations/self.budget) * (1 + 0.5 * diversity))\n                if self.evaluations % 10 == 0: self.w *= 0.9  # Convergence feedback\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Introduced adaptive mutation based on convergence speed and diversity to enhance exploration-exploitation balance.", "configspace": "", "generation": 71, "fitness": 0.11304702767163062, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.113 with standard deviation 0.000. And the mean value of best solutions found was 0.119 (0. is the best).", "error": "", "parent_id": "5925c593-22fa-49f9-b186-3dd5b91c674e", "metadata": {"aucs": [0.11262386115715872, 0.11323642177524984, 0.11328080008248331], "final_y": [0.11818940006908751, 0.12002757058376379, 0.11744705232573527]}, "mutation_prompt": null}
{"id": "39d03665-6dbe-45a6-bcf4-8597fcacd813", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                decay_factor = 1 - (self.evaluations / self.budget)  # Linear decay factor\n                self.c1 = (1.2 + (0.3 * np.random.rand())) * decay_factor  # Apply decay\n                self.c2 = (1.2 + (0.3 * np.random.rand())) * decay_factor  # Apply decay\n                scaling_factor = np.random.uniform(0.5, 1.5, size=self.dim)  # Random scaling\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor * 0.99 +  # Added damping factor\n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                perturbation = np.random.randn(self.dim) * 0.01 * np.exp(-self.evaluations/self.budget) * (bounds[:, 1] - bounds[:, 0]) # Exponential decay\n                mutation_scale = np.linalg.norm(self.particles[i] - self.global_best_position) / np.linalg.norm(bounds[:, 1] - bounds[:, 0])  # New line\n                mutation = np.random.randn(self.dim) * 0.001 * np.mean(np.std(self.particles, axis=0)) * mutation_scale  # Modified line\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation + mutation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                diversity = np.mean(np.std(self.particles, axis=0))\n                self.w = max(0.2, 0.9 - (0.9 - 0.2) * (self.evaluations/self.budget) * (1 + 0.5 * diversity))\n                if self.evaluations % 10 == 0: self.w *= 0.9  # Convergence feedback\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Introduced adaptive mutation scaling based on the particle position to enhance exploration capabilities.", "configspace": "", "generation": 72, "fitness": 0.11454816544441793, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.115 with standard deviation 0.001. And the mean value of best solutions found was 0.116 (0. is the best).", "error": "", "parent_id": "5925c593-22fa-49f9-b186-3dd5b91c674e", "metadata": {"aucs": [0.11376536378941604, 0.11408165199338272, 0.11579748055045502], "final_y": [0.11773419150754016, 0.11942693913972136, 0.11008005959430389]}, "mutation_prompt": null}
{"id": "efcab88c-da47-4995-b204-8e0b8ab251e2", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                decay_factor = 1 - (self.evaluations / self.budget)  # Linear decay factor\n                diversity = np.mean(np.std(self.particles, axis=0))  # Compute diversity\n                adaptive_learning_rate = 1 + 0.5 * diversity  # Adaptive change\n                self.c1 = (1.2 + (0.3 * np.random.rand())) * decay_factor * adaptive_learning_rate\n                self.c2 = (1.2 + (0.3 * np.random.rand())) * decay_factor * adaptive_learning_rate\n                scaling_factor = np.random.uniform(0.5, 1.5, size=self.dim)  # Random scaling\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor * 0.99 +  # Added damping factor\n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                perturbation = np.random.randn(self.dim) * 0.01 * np.exp(-self.evaluations/self.budget) * (bounds[:, 1] - bounds[:, 0]) # Exponential decay\n                mutation = np.random.randn(self.dim) * 0.001 * np.mean(np.std(self.particles, axis=0)) # Mutation based on diversity\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation + mutation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                self.w = max(0.2, 0.9 - (0.9 - 0.2) * (self.evaluations/self.budget) * (1 + 0.5 * diversity))\n                if self.evaluations % 10 == 0: self.w *= 0.9  # Convergence feedback\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Improved velocity update by adding adaptive learning factors based on diversity.", "configspace": "", "generation": 73, "fitness": 0.09630994030413027, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.096 with standard deviation 0.003. And the mean value of best solutions found was 0.168 (0. is the best).", "error": "", "parent_id": "5925c593-22fa-49f9-b186-3dd5b91c674e", "metadata": {"aucs": [0.09340024792408241, 0.09970283006494629, 0.09582674292336213], "final_y": [0.1717038767125737, 0.16009449749953297, 0.1719371736110774]}, "mutation_prompt": null}
{"id": "f67505b0-c845-42ca-9595-90bafc039615", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            diversity = np.mean(np.std(self.particles, axis=0))  # Moved to loop for dynamic updates\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                decay_factor = 1 - (self.evaluations / self.budget)  # Linear decay factor\n                self.c1 = (1.2 + (0.3 * np.random.rand())) * decay_factor  # Apply decay\n                self.c2 = (1.2 + (0.3 * np.random.rand())) * decay_factor  # Apply decay\n                self.velocities[i] = (self.w * self.velocities[i] +  # Removed scaling factor\n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]) * (1 + diversity))  # Scaled by diversity\n\n                # Update particle position\n                perturbation = np.random.randn(self.dim) * 0.01 * np.exp(-self.evaluations/self.budget) * (bounds[:, 1] - bounds[:, 0]) # Exponential decay\n                mutation = np.random.randn(self.dim) * 0.001 * np.mean(np.std(self.particles, axis=0)) # Mutation based on diversity\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation + mutation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                self.w = max(0.2, 0.9 - (0.9 - 0.2) * (self.evaluations/self.budget) * (1 + 0.5 * diversity))\n                if self.evaluations % 10 == 0: self.w *= 0.9  # Convergence feedback\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Improved convergence by incorporating dynamic social influence scaling based on diversity and adaptive local search intensity.", "configspace": "", "generation": 74, "fitness": 0.09632140301889962, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.096 with standard deviation 0.003. And the mean value of best solutions found was 0.170 (0. is the best).", "error": "", "parent_id": "5925c593-22fa-49f9-b186-3dd5b91c674e", "metadata": {"aucs": [0.09336259794654311, 0.09970283006494629, 0.09589878104520944], "final_y": [0.1794756856631502, 0.16009449749953297, 0.1716965832603109]}, "mutation_prompt": null}
{"id": "4efe90e1-3430-475c-a6af-7258c20cf065", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                decay_factor = 1 - (self.evaluations / self.budget)  # Linear decay factor\n                self.c1 = (1.2 + (0.3 * np.random.rand())) * decay_factor  # Apply decay\n                self.c2 = (1.2 + (0.3 * np.random.rand())) * decay_factor  # Apply decay\n                scaling_factor = np.random.uniform(0.5, 1.5, size=self.dim)  # Random scaling\n                distance_factor = np.linalg.norm(self.global_best_position - self.particles[i]) / np.linalg.norm(bounds[:, 1] - bounds[:, 0])  # New line\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor * 0.99 * (1 - distance_factor) +  # Changed line\n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                perturbation = np.random.randn(self.dim) * 0.01 * np.exp(-self.evaluations/self.budget) * (bounds[:, 1] - bounds[:, 0]) # Exponential decay\n                mutation = np.random.randn(self.dim) * 0.001 * np.mean(np.std(self.particles, axis=0)) # Mutation based on diversity\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation + mutation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                diversity = np.mean(np.std(self.particles, axis=0))\n                self.w = max(0.2, 0.9 - (0.9 - 0.2) * (self.evaluations/self.budget) * (1 + 0.5 * diversity))\n                if self.evaluations % 10 == 0: self.w *= 0.9  # Convergence feedback\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Incorporate an adaptive velocity damping factor based on distance to the global best to enhance convergence speed.", "configspace": "", "generation": 75, "fitness": 0.11426800572254114, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.114 with standard deviation 0.001. And the mean value of best solutions found was 0.116 (0. is the best).", "error": "", "parent_id": "5925c593-22fa-49f9-b186-3dd5b91c674e", "metadata": {"aucs": [0.11389749262789173, 0.1132055410236612, 0.1157009835160705], "final_y": [0.11771007355239405, 0.12102692735504017, 0.11037579398724251]}, "mutation_prompt": null}
{"id": "6ff1b28a-44c2-48ad-808b-108d8ca745ad", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                decay_factor = 1 - (self.evaluations / self.budget)  # Linear decay factor\n                self.c1 = (1.2 + (0.3 * np.random.rand())) * decay_factor  # Apply decay\n                self.c2 = (1.2 + (0.3 * np.random.rand())) * decay_factor  # Apply decay\n                scaling_factor = np.random.uniform(0.5, 1.5, size=self.dim)  # Random scaling\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor * 0.99 +  # Added damping factor\n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                perturbation = np.random.randn(self.dim) * 0.01 * np.exp(-self.evaluations/self.budget) * (bounds[:, 1] - bounds[:, 0]) # Exponential decay\n                mutation = np.random.randn(self.dim) * 0.001 * np.mean(np.std(self.particles, axis=0)) # Mutation based on diversity\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation + mutation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                diversity = np.mean(np.std(self.particles, axis=0))\n                self.w = max(0.2, 0.9 - (0.9 - 0.2) * (self.evaluations/self.budget) * (1 + 0.5 * diversity))\n                if self.evaluations % 10 == 0: self.w *= 0.9  # Convergence feedback\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Enhanced convergence by integrating a small velocity damping factor to reduce oscillations.", "configspace": "", "generation": 68, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('list index out of range').", "error": "IndexError('list index out of range')", "parent_id": "5925c593-22fa-49f9-b186-3dd5b91c674e", "metadata": {"aucs": [0.11377257949263986, 0.11408164405144328, 0.11581009006961218], "final_y": [0.11775167032667377, 0.11959953150141578, 0.11000276741931492]}, "mutation_prompt": null}
{"id": "5482cf2f-d4a4-4dcf-8d81-feea4065d076", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.7\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                decay_factor = 1 - (self.evaluations / self.budget)\n                self.c1 = (1.2 + (0.3 * np.random.rand())) * decay_factor\n                self.c2 = (1.2 + (0.3 * np.random.rand())) * decay_factor\n                # Adaptive velocity scaling\n                scaling_factor = np.random.uniform(0.3, 1.7, size=self.dim) \n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor * 0.98 +  # Tweak damping\n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                perturbation = np.random.randn(self.dim) * 0.01 * np.exp(-self.evaluations/self.budget) * (bounds[:, 1] - bounds[:, 0])\n                mutation = np.random.randn(self.dim) * 0.002 * np.mean(np.std(self.particles, axis=0))  # Adjusted mutation\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation + mutation, bounds[:, 0], bounds[:, 1])\n                \n                # Local search integration\n                if np.random.rand() < 0.1: \n                    local_search = self.particles[i] + np.random.uniform(-0.05, 0.05, self.dim)\n                    local_search = np.clip(local_search, bounds[:, 0], bounds[:, 1])\n                    if self.evaluate(func, local_search) < self.evaluate(func, self.particles[i]):\n                        self.particles[i] = local_search\n\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                diversity = np.mean(np.std(self.particles, axis=0))\n                self.w = max(0.2, 0.9 - (0.9 - 0.2) * (self.evaluations/self.budget) * (1 + 0.5 * diversity))\n                if self.evaluations % 10 == 0: self.w *= 0.9\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Enhanced oscillation control and diversity through adaptive velocity scaling and local search integration.", "configspace": "", "generation": 77, "fitness": 0.11396457464831411, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.114 with standard deviation 0.001. And the mean value of best solutions found was 0.116 (0. is the best).", "error": "", "parent_id": "5925c593-22fa-49f9-b186-3dd5b91c674e", "metadata": {"aucs": [0.11229315409249208, 0.1138371708497381, 0.11576339900271215], "final_y": [0.11829317026433694, 0.11940166741052283, 0.11171014970948123]}, "mutation_prompt": null}
{"id": "d898168d-6898-4879-ab3d-e7c56db12f8b", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                decay_factor = 1 - (self.evaluations / self.budget)  # Linear decay factor\n                self.c1 = (1.2 + (0.3 * np.random.rand())) * decay_factor  # Apply decay\n                self.c2 = (1.2 + (0.3 * np.random.rand())) * decay_factor  # Apply decay\n                scaling_factor = np.random.uniform(0.5, 1.5, size=self.dim)  # Random scaling\n                diversity = np.mean(np.std(self.particles, axis=0))\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor * (0.98 + 0.02 * diversity) +  # Adjusted damping factor\n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                perturbation = np.random.randn(self.dim) * 0.01 * np.exp(-self.evaluations/self.budget) * (bounds[:, 1] - bounds[:, 0]) # Exponential decay\n                mutation = np.random.randn(self.dim) * 0.001 * np.mean(np.std(self.particles, axis=0)) # Mutation based on diversity\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation + mutation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                diversity = np.mean(np.std(self.particles, axis=0))\n                self.w = max(0.2, 0.9 - (0.9 - 0.2) * (self.evaluations/self.budget) * (1 + 0.5 * diversity))\n                if self.evaluations % 10 == 0: self.w *= 0.9  # Convergence feedback\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Enhanced convergence and solution quality by adjusting the damping factor based on diversity.", "configspace": "", "generation": 78, "fitness": 0.1130017216397895, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.113 with standard deviation 0.002. And the mean value of best solutions found was 0.117 (0. is the best).", "error": "", "parent_id": "5925c593-22fa-49f9-b186-3dd5b91c674e", "metadata": {"aucs": [0.11532464416352695, 0.11234542674534398, 0.11133509401049757], "final_y": [0.11020369268533947, 0.12073715146050812, 0.12133410278482182]}, "mutation_prompt": null}
{"id": "d82d630c-16a8-4d1a-923b-a5f446f7f63c", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                decay_factor = 1 - (self.evaluations / self.budget)  # Linear decay factor\n                self.c1 = (1.2 + (0.3 * np.random.rand())) * decay_factor  # Apply decay\n                self.c2 = (1.2 + (0.3 * np.random.rand())) * decay_factor  # Apply decay\n                scaling_factor = np.random.uniform(0.5, 1.5, size=self.dim)  # Random scaling\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor * 0.985 +  # Change made here\n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                perturbation = np.random.randn(self.dim) * 0.01 * np.exp(-self.evaluations/self.budget) * (bounds[:, 1] - bounds[:, 0]) # Exponential decay\n                mutation = np.random.randn(self.dim) * 0.001 * np.mean(np.std(self.particles, axis=0)) # Mutation based on diversity\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation + mutation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                diversity = np.mean(np.std(self.particles, axis=0))\n                self.w = max(0.2, 0.9 - (0.9 - 0.2) * (self.evaluations/self.budget) * (1 + 0.5 * diversity))\n                if self.evaluations % 10 == 0: self.w *= 0.9  # Convergence feedback\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Enhanced convergence by integrating a velocity dampening factor to reduce oscillations and improve exploration.", "configspace": "", "generation": 79, "fitness": 0.11456801836861226, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.115 with standard deviation 0.001. And the mean value of best solutions found was 0.116 (0. is the best).", "error": "", "parent_id": "5925c593-22fa-49f9-b186-3dd5b91c674e", "metadata": {"aucs": [0.11383016291894876, 0.1140766142733135, 0.11579727791357453], "final_y": [0.11785133216148169, 0.11949059321080524, 0.1100618912251422]}, "mutation_prompt": null}
{"id": "d919cc02-3e96-4f96-a5ba-6894668007a6", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                decay_factor = 1 - (self.evaluations / self.budget)  # Linear decay factor\n                self.c1 = (1.2 + (0.3 * np.random.rand())) * decay_factor  # Apply decay\n                self.c2 = (1.2 + (0.3 * np.random.rand())) * decay_factor  # Apply decay\n                scaling_factor = np.random.uniform(0.5, 1.5, size=self.dim)  # Random scaling\n                turbulence = np.random.randn(self.dim) * 0.05 * (bounds[:, 1] - bounds[:, 0])  # Turbulence factor\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor * 0.985 +  # Change made here\n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]) + \n                                      turbulence)  # Added turbulence\n\n                # Update particle position\n                perturbation = np.random.randn(self.dim) * 0.01 * np.exp(-self.evaluations/self.budget) * (bounds[:, 1] - bounds[:, 0]) # Exponential decay\n                mutation = np.random.randn(self.dim) * 0.001 * np.mean(np.std(self.particles, axis=0)) # Mutation based on diversity\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation + mutation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                diversity = np.mean(np.std(self.particles, axis=0))\n                self.w = max(0.2, 0.9 - (0.9 - 0.2) * (self.evaluations/self.budget) * (1 + 0.5 * diversity))\n                if self.evaluations % 10 == 0: self.w *= 0.9  # Convergence feedback\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Enhance global exploration by introducing a turbulence factor to particle velocities.", "configspace": "", "generation": 80, "fitness": 0.11048577509169766, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.110 with standard deviation 0.001. And the mean value of best solutions found was 0.126 (0. is the best).", "error": "", "parent_id": "d82d630c-16a8-4d1a-923b-a5f446f7f63c", "metadata": {"aucs": [0.10929296225822283, 0.11235913829580269, 0.10980522472106746], "final_y": [0.12919817748624363, 0.12370000216831689, 0.1254548621397601]}, "mutation_prompt": null}
{"id": "023906f3-70f9-4f7b-8e95-d5efe01f116d", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                decay_factor = 1 - (self.evaluations / self.budget)  # Linear decay factor\n                diversity = np.mean(np.std(self.particles, axis=0))  # Diversity\n                self.c1 = (1.2 + (0.3 * np.random.rand())) * decay_factor * (1 + diversity)  # Adjusted cognitive\n                self.c2 = (1.2 + (0.3 * np.random.rand())) * decay_factor / (1 + diversity)  # Adjusted social\n                scaling_factor = np.random.uniform(0.5, 1.5, size=self.dim)  # Random scaling\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor * 0.985 +  # Change made here\n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                perturbation = np.random.randn(self.dim) * 0.01 * np.exp(-self.evaluations/self.budget) * (bounds[:, 1] - bounds[:, 0]) # Exponential decay\n                mutation = np.random.randn(self.dim) * 0.001 * np.mean(np.std(self.particles, axis=0)) # Mutation based on diversity\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation + mutation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                diversity = np.mean(np.std(self.particles, axis=0))\n                self.w = max(0.2, 0.9 - (0.9 - 0.2) * (self.evaluations/self.budget) * (1 + 0.5 * diversity))\n                if self.evaluations % 10 == 0: self.w *= 0.9  # Convergence feedback\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Improved exploration balance by adjusting cognitive and social coefficients dynamically based on diversity.", "configspace": "", "generation": 81, "fitness": 0.09997550247980858, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.100 with standard deviation 0.000. And the mean value of best solutions found was 0.158 (0. is the best).", "error": "", "parent_id": "d82d630c-16a8-4d1a-923b-a5f446f7f63c", "metadata": {"aucs": [0.10012031845285829, 0.09970283006494629, 0.10010335892162114], "final_y": [0.15629087476074455, 0.16009449749953297, 0.15752436683162685]}, "mutation_prompt": null}
{"id": "16613cc2-a179-47fb-a7db-36440efad7ba", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                decay_factor = 1 - (self.evaluations / self.budget)  # Linear decay factor\n                self.c1 = (1.2 + (0.3 * np.random.rand())) * decay_factor  # Apply decay\n                self.c2 = (1.2 + (0.3 * np.random.rand())) * decay_factor  # Apply decay\n                scaling_factor = np.random.uniform(0.5, 1.5, size=self.dim)  # Random scaling\n                dist_factor = np.linalg.norm(self.particles[i] - self.global_best_position) / np.linalg.norm(bounds[:, 1] - bounds[:, 0])\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor * (0.985 + 0.015 * dist_factor) +  # Change made here\n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                perturbation = np.random.randn(self.dim) * 0.01 * np.exp(-self.evaluations/self.budget) * (bounds[:, 1] - bounds[:, 0]) # Exponential decay\n                mutation = np.random.randn(self.dim) * 0.001 * np.mean(np.std(self.particles, axis=0)) # Mutation based on diversity\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation + mutation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                diversity = np.mean(np.std(self.particles, axis=0))\n                self.w = max(0.2, 0.9 - (0.9 - 0.2) * (self.evaluations/self.budget) * (1 + 0.5 * diversity))\n                if self.evaluations % 10 == 0: self.w *= 0.9  # Convergence feedback\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Improved convergence by introducing adaptive scaling of velocity components based on particle's distance from global best.", "configspace": "", "generation": 82, "fitness": 0.11457001212758777, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.115 with standard deviation 0.001. And the mean value of best solutions found was 0.116 (0. is the best).", "error": "", "parent_id": "d82d630c-16a8-4d1a-923b-a5f446f7f63c", "metadata": {"aucs": [0.11382845349510051, 0.11407391866672822, 0.11580766422093458], "final_y": [0.11783799341451051, 0.11964219079475791, 0.11000258446005651]}, "mutation_prompt": null}
{"id": "0a4679ed-234e-42ef-9934-42dc666f558b", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                decay_factor = 1 - (self.evaluations / self.budget)  # Linear decay factor\n                diversity = np.mean(np.std(self.particles, axis=0))\n                self.c1 = (1.2 + (0.5 * np.random.rand())) * decay_factor * (1 - diversity)  # Changed line 1\n                self.c2 = (1.2 + (0.5 * np.random.rand())) * decay_factor * (1 + diversity)  # Changed line 2\n                scaling_factor = np.random.uniform(0.5, 1.5, size=self.dim)  # Random scaling\n                dist_factor = np.linalg.norm(self.particles[i] - self.global_best_position) / np.linalg.norm(bounds[:, 1] - bounds[:, 0])\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor * (0.985 + 0.015 * dist_factor) +  \n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                perturbation = np.random.randn(self.dim) * 0.01 * np.exp(-self.evaluations/self.budget) * (bounds[:, 1] - bounds[:, 0])\n                mutation = np.random.randn(self.dim) * 0.001 * np.mean(np.std(self.particles, axis=0))\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation + mutation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                self.w = max(0.2, 0.9 - (0.9 - 0.2) * (self.evaluations/self.budget) * (1 + 0.5 * diversity))\n                if self.evaluations % 10 == 0: self.w *= 0.9\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Enhanced convergence by adjusting cognitive and social coefficients dynamically based on diversity.", "configspace": "", "generation": 83, "fitness": 0.09632439754141812, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.096 with standard deviation 0.003. And the mean value of best solutions found was 0.166 (0. is the best).", "error": "", "parent_id": "16613cc2-a179-47fb-a7db-36440efad7ba", "metadata": {"aucs": [0.09336508794911713, 0.09970283006494629, 0.09590527461019094], "final_y": [0.17460376685191215, 0.16009449749953297, 0.16432440884941268]}, "mutation_prompt": null}
{"id": "74319b9a-e718-4245-9756-c5663861fe34", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                decay_factor = 1 - (self.evaluations / self.budget)  # Linear decay factor\n                self.c1 = (1.2 + (0.3 * np.random.rand())) * decay_factor  # Apply decay\n                self.c2 = (1.2 + (0.3 * np.random.rand())) * decay_factor  # Apply decay\n                scaling_factor = np.random.uniform(0.5, 1.5, size=self.dim)  # Random scaling\n                dist_factor = np.linalg.norm(self.particles[i] - self.global_best_position) / np.linalg.norm(bounds[:, 1] - bounds[:, 0])\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor * (0.985 + 0.015 * dist_factor) +  # Change made here\n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                perturbation = np.random.randn(self.dim) * 0.01 * np.exp(-self.evaluations/self.budget) * (bounds[:, 1] - bounds[:, 0]) # Exponential decay\n                mutation = np.random.randn(self.dim) * 0.001 * np.mean(np.std(self.particles, axis=0)) # Mutation based on diversity\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation + mutation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning with dynamic probability\n                if np.random.rand() < 0.5 + 0.5 * (self.global_best_score / (self.global_best_score + abs(score - self.global_best_score))):\n                    opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                    opposite_score = self.evaluate(func, opposite_particle)\n                    if opposite_score < score:\n                        self.particles[i] = opposite_particle\n                        if opposite_score < self.personal_best_scores[i]:\n                            self.personal_best_scores[i] = opposite_score\n                            self.personal_best_positions[i] = opposite_particle.copy()\n                        if opposite_score < self.global_best_score:\n                            self.global_best_score = opposite_score\n                            self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                diversity = np.mean(np.std(self.particles, axis=0))\n                self.w = max(0.2, 0.9 - (0.9 - 0.2) * (self.evaluations/self.budget) * (1 + 0.5 * diversity))\n                if self.evaluations % 10 == 0: self.w *= 0.9  # Convergence feedback\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Enhanced the oppositional learning with a dynamic probability for updating particles, improving exploration and exploitation balance.", "configspace": "", "generation": 84, "fitness": 0.1130399638343047, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.113 with standard deviation 0.000. And the mean value of best solutions found was 0.119 (0. is the best).", "error": "", "parent_id": "16613cc2-a179-47fb-a7db-36440efad7ba", "metadata": {"aucs": [0.11277554594599393, 0.1137198827828273, 0.11262446277409288], "final_y": [0.1183774450424927, 0.11944554444661104, 0.12023741408688027]}, "mutation_prompt": null}
{"id": "a8f30037-49d2-45d6-a7f2-8d00f96728d5", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                decay_factor = 1 - (self.evaluations / self.budget)  # Linear decay factor\n                self.c1 = (1.2 + (0.3 * np.random.rand())) * decay_factor  # Apply decay\n                self.c2 = (1.2 + (0.3 * np.random.rand())) * decay_factor  # Apply decay\n                scaling_factor = np.random.uniform(0.5, 1.5, size=self.dim)  # Random scaling\n                dist_factor = np.linalg.norm(self.particles[i] - self.global_best_position) / np.linalg.norm(bounds[:, 1] - bounds[:, 0])\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor * (0.985 + 0.015 * dist_factor) +  # Change made here\n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                perturbation = np.random.randn(self.dim) * 0.01 * np.exp(-self.evaluations/self.budget) * (bounds[:, 1] - bounds[:, 0]) # Exponential decay\n                mutation = np.random.randn(self.dim) * 0.001 * np.mean(np.std(self.particles, axis=0)) # Mutation based on diversity\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation + mutation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                diversity = np.mean(np.std(self.particles, axis=0))\n                self.w = max(0.2, 0.9 - (0.9 - 0.2) * (self.evaluations/self.budget) * (1 + 0.5 * diversity))\n                if self.evaluations % 10 == 0: self.w *= 0.9  # Convergence feedback\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Improved convergence by introducing adaptive scaling of velocity components based on particle's distance from global best.", "configspace": "", "generation": 83, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('list index out of range').", "error": "IndexError('list index out of range')", "parent_id": "16613cc2-a179-47fb-a7db-36440efad7ba", "metadata": {"aucs": [0.11382845349510051, 0.11407391866672822, 0.11580766422093458], "final_y": [0.11783799341451051, 0.11964219079475791, 0.11000258446005651]}, "mutation_prompt": null}
{"id": "ebc360d2-ecd8-4b68-ac77-eb71dfd2bf8e", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            selected_indices = np.random.choice(self.population_size, int(self.population_size * 0.8), replace=False)\n            for i in selected_indices:  # Select a subset of particles based on performance\n                if self.evaluations >= self.budget:\n                    break\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                decay_factor = 1 - (self.evaluations / self.budget)  # Linear decay factor\n                self.c1 = 1.5 * decay_factor  # Apply decay\n                self.c2 = 1.5 * decay_factor  # Apply decay\n                scaling_factor = np.random.uniform(0.8, 1.2, size=self.dim)  # Adjusted scaling\n                dist_factor = np.linalg.norm(self.particles[i] - self.global_best_position) / np.linalg.norm(bounds[:, 1] - bounds[:, 0])\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor * (0.985 + 0.015 * dist_factor) + \n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                perturbation = np.random.randn(self.dim) * 0.01 * np.exp(-self.evaluations/self.budget) * (bounds[:, 1] - bounds[:, 0])\n                mutation = np.random.randn(self.dim) * 0.002 * np.mean(np.std(self.particles, axis=0))  # Adjusted mutation rate\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation + mutation, bounds[:, 0], bounds[:, 1])\n                \n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                diversity = np.mean(np.std(self.particles, axis=0))\n                self.w = max(0.2, 0.9 - (0.9 - 0.2) * (self.evaluations/self.budget) * (1 + 0.5 * diversity))\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Introduced adaptive particle selection and dynamic scaling of mutation rates to enhance convergence precision.", "configspace": "", "generation": 86, "fitness": 0.11376141912717756, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.114 with standard deviation 0.001. And the mean value of best solutions found was 0.117 (0. is the best).", "error": "", "parent_id": "16613cc2-a179-47fb-a7db-36440efad7ba", "metadata": {"aucs": [0.11282534487621898, 0.11566909486819943, 0.11278981763711426], "final_y": [0.1187567758925544, 0.1124928748013383, 0.12084613098489161]}, "mutation_prompt": null}
{"id": "48860b35-bd4f-43ab-ab8c-4c24870296e2", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                decay_factor = 1 - (self.evaluations / self.budget)  # Linear decay factor\n                self.c1 = (1.2 + (0.3 * np.random.rand())) * decay_factor  # Apply decay\n                self.c2 = (1.2 + (0.3 * np.random.rand())) * decay_factor  # Apply decay\n                scaling_factor = np.random.uniform(0.5, 1.5, size=self.dim)  # Random scaling\n                dist_factor = np.linalg.norm(self.particles[i] - self.global_best_position) / np.linalg.norm(bounds[:, 1] - bounds[:, 0])\n                opposite_velocity = bounds[:, 1] + bounds[:, 0] - self.velocities[i]  # Change made here\n                self.velocities[i] = (self.w * opposite_velocity * scaling_factor * (0.985 + 0.015 * dist_factor) + \n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                perturbation = np.random.randn(self.dim) * 0.01 * np.exp(-self.evaluations/self.budget) * (bounds[:, 1] - bounds[:, 0]) # Exponential decay\n                mutation = np.random.randn(self.dim) * 0.001 * np.mean(np.std(self.particles, axis=0)) # Mutation based on diversity\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation + mutation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                diversity = np.mean(np.std(self.particles, axis=0))\n                self.w = max(0.2, 0.9 - (0.9 - 0.2) * (self.evaluations/self.budget) * (1 + 0.5 * diversity))\n                if self.evaluations % 10 == 0: self.w *= 0.9  # Convergence feedback\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Improved convergence by introducing oppositional learning in velocity update for enhanced exploration.", "configspace": "", "generation": 87, "fitness": 0.1014953884830188, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.101 with standard deviation 0.001. And the mean value of best solutions found was 0.147 (0. is the best).", "error": "", "parent_id": "16613cc2-a179-47fb-a7db-36440efad7ba", "metadata": {"aucs": [0.09973817180415756, 0.10307057208605042, 0.1016774215588484], "final_y": [0.1549768949939242, 0.1433848669047667, 0.14202284380830354]}, "mutation_prompt": null}
{"id": "ac1e24b5-5433-4e33-b6c3-a5fde2276c65", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                decay_factor = 1 - (self.evaluations / self.budget)  # Linear decay factor\n                self.c1 = (1.2 + (0.3 * np.random.rand())) * decay_factor  # Apply decay\n                self.c2 = (1.2 + (0.3 * np.random.rand())) * decay_factor  # Apply decay\n                scaling_factor = np.random.uniform(0.5, 1.5, size=self.dim)  # Random scaling\n                dist_factor = np.linalg.norm(self.particles[i] - self.global_best_position) / np.linalg.norm(bounds[:, 1] - bounds[:, 0])\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor * (0.985 + 0.015 * dist_factor) +  # Change made here\n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                perturbation = np.random.randn(self.dim) * 0.01 * np.exp(-self.evaluations/(0.75*self.budget)) * (bounds[:, 1] - bounds[:, 0]) # Exponential decay\n                mutation = np.random.randn(self.dim) * 0.001 * np.mean(np.std(self.particles, axis=0)) # Mutation based on diversity\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation + mutation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                diversity = np.mean(np.std(self.particles, axis=0))\n                self.w = max(0.2, 0.9 - (0.9 - 0.2) * (self.evaluations/self.budget) * (1 + 0.5 * diversity))\n                if self.evaluations % 10 == 0: self.w *= 0.9  # Convergence feedback\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Enhanced diversity by adjusting the perturbation's exponential decay rate to boost exploration.", "configspace": "", "generation": 88, "fitness": 0.11459573576044935, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.115 with standard deviation 0.001. And the mean value of best solutions found was 0.115 (0. is the best).", "error": "", "parent_id": "16613cc2-a179-47fb-a7db-36440efad7ba", "metadata": {"aucs": [0.11382667948945924, 0.11431887677893515, 0.11564165101295365], "final_y": [0.1177633053608067, 0.11859297880339248, 0.10997580126885542]}, "mutation_prompt": null}
{"id": "a9ffc01b-a2ae-46dc-802b-16dd0e605426", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                decay_factor = 1 - (self.evaluations / self.budget)  # Linear decay factor\n                self.c1 = (1.2 + (0.3 * np.random.rand())) * decay_factor  # Apply decay\n                self.c2 = (1.2 + (0.3 * np.random.rand())) * decay_factor  # Apply decay\n                scaling_factor = np.random.uniform(0.5, 1.5, size=self.dim)  # Random scaling\n                dist_factor = np.linalg.norm(self.particles[i] - self.global_best_position) / np.linalg.norm(bounds[:, 1] - bounds[:, 0])\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor * (0.985 + 0.015 * dist_factor) +\n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                perturbation = np.random.randn(self.dim) * 0.01 * np.exp(-self.evaluations/(0.75*self.budget)) * (bounds[:, 1] - bounds[:, 0])\n                mutation = np.random.randn(self.dim) * 0.001 * np.mean(np.std(self.particles, axis=0)) \n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation + mutation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Adaptive local search (stochastic hill climbing)\n                for _ in range(3):  # Perform 3 local searches\n                    local_step = np.random.randn(self.dim) * 0.01 * (bounds[:, 1] - bounds[:, 0])\n                    local_candidate = np.clip(self.particles[i] + local_step, bounds[:, 0], bounds[:, 1])\n                    local_score = self.evaluate(func, local_candidate)\n                    if local_score < score:\n                        self.particles[i] = local_candidate\n                        score = local_score\n                        if score < self.personal_best_scores[i]:\n                            self.personal_best_scores[i] = score\n                            self.personal_best_positions[i] = self.particles[i].copy()\n                        if score < self.global_best_score:\n                            self.global_best_score = score\n                            self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                diversity = np.mean(np.std(self.particles, axis=0))\n                self.w = max(0.2, 0.9 - (0.9 - 0.2) * (self.evaluations/self.budget) * (1 + 0.5 * diversity))\n                if self.evaluations % 10 == 0: self.w *= 0.9  # Convergence feedback\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Enhanced convergence by integrating adaptive local search based on stochastic hill climbing.", "configspace": "", "generation": 89, "fitness": 0.11307877608842028, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.113 with standard deviation 0.002. And the mean value of best solutions found was 0.117 (0. is the best).", "error": "", "parent_id": "ac1e24b5-5433-4e33-b6c3-a5fde2276c65", "metadata": {"aucs": [0.11107087853197484, 0.11288372446230388, 0.11528172527098213], "final_y": [0.11875033444027228, 0.12002994390979582, 0.11279651775320443]}, "mutation_prompt": null}
{"id": "f0b4a364-b606-4825-bff0-817229547099", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                decay_factor = 1 - (self.evaluations / self.budget)  # Linear decay factor\n                diversity = np.mean(np.std(self.particles, axis=0))  # Calculate diversity\n                self.c1 = (1.2 + (0.3 * np.random.rand())) * decay_factor * (1 + 0.5 * diversity)  # Change made here\n                self.c2 = (1.2 + (0.3 * np.random.rand())) * decay_factor * (1 + 0.5 * diversity)  # Change made here\n                scaling_factor = np.random.uniform(0.5, 1.5, size=self.dim)  # Random scaling\n                dist_factor = np.linalg.norm(self.particles[i] - self.global_best_position) / np.linalg.norm(bounds[:, 1] - bounds[:, 0])\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor * (0.985 + 0.015 * dist_factor) + \n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                perturbation = np.random.randn(self.dim) * 0.01 * np.exp(-self.evaluations/(0.75*self.budget)) * (bounds[:, 1] - bounds[:, 0])\n                mutation = np.random.randn(self.dim) * 0.001 * np.mean(np.std(self.particles, axis=0))\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation + mutation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                self.w = max(0.2, 0.9 - (0.9 - 0.2) * (self.evaluations/self.budget) * (1 + 0.5 * diversity))\n                if self.evaluations % 10 == 0: self.w *= 0.9\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Introduced adaptive cognitive and social coefficients based on diversity to enhance exploitation-exploration balance.", "configspace": "", "generation": 90, "fitness": 0.09630660611153141, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.096 with standard deviation 0.003. And the mean value of best solutions found was 0.169 (0. is the best).", "error": "", "parent_id": "ac1e24b5-5433-4e33-b6c3-a5fde2276c65", "metadata": {"aucs": [0.09339024534628582, 0.09970283006494629, 0.09582674292336213], "final_y": [0.17373519259298642, 0.16009449749953297, 0.1719371736110774]}, "mutation_prompt": null}
{"id": "a59ec2a9-2860-455e-b2e9-cd4070963180", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                decay_factor = 1 - (self.evaluations / self.budget)  # Linear decay factor\n                self.c1 = (1.2 + (0.3 * np.random.rand())) * decay_factor  # Apply decay\n                self.c2 = (1.2 + (0.3 * np.random.rand())) * decay_factor  # Apply decay\n                scaling_factor = np.random.uniform(0.5, 1.5, size=self.dim)  # Random scaling\n                dist_factor = np.linalg.norm(self.particles[i] - self.global_best_position) / np.linalg.norm(bounds[:, 1] - bounds[:, 0])\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor * (0.985 + 0.015 * dist_factor) +  # Change made here\n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                perturbation = np.random.randn(self.dim) * 0.01 * np.exp(-self.evaluations/(0.75*self.budget)) * (bounds[:, 1] - bounds[:, 0]) # Exponential decay\n                mutation = np.random.randn(self.dim) * 0.001 * np.mean(np.std(self.particles, axis=0)) # Mutation based on diversity\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation + mutation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.global_best_position  # Change made here\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                diversity = np.mean(np.std(self.particles, axis=0))\n                self.w = max(0.2, 0.9 - (0.9 - 0.2) * (self.evaluations/self.budget) * (1 + 0.5 * diversity))\n                if self.evaluations % 10 == 0: self.w *= 0.9  # Convergence feedback\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Enhanced diversity by modifying the oppositional learning to consider the best particle's opposite.", "configspace": "", "generation": 91, "fitness": 0.11449397388545994, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.114 with standard deviation 0.001. And the mean value of best solutions found was 0.116 (0. is the best).", "error": "", "parent_id": "ac1e24b5-5433-4e33-b6c3-a5fde2276c65", "metadata": {"aucs": [0.11365037720900573, 0.1141472856890905, 0.11568425875828359], "final_y": [0.11807348379039773, 0.11932487528802682, 0.11154323725065085]}, "mutation_prompt": null}
{"id": "aa100766-d5d5-4420-b1d7-3ac609f25bd9", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                decay_factor = 1 - (self.evaluations / self.budget)  # Linear decay factor\n                self.c1 = (1.2 + (0.3 * np.random.rand())) * decay_factor  # Apply decay\n                self.c2 = (1.2 + (0.3 * np.random.rand())) * decay_factor  # Apply decay\n                scaling_factor = np.random.uniform(0.7, 1.5, size=self.dim)  # Adjusted scaling for more effective exploration\n                dist_factor = np.linalg.norm(self.particles[i] - self.global_best_position) / np.linalg.norm(bounds[:, 1] - bounds[:, 0])\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor * (0.985 + 0.015 * dist_factor) +  # Change made here\n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                perturbation = np.random.randn(self.dim) * 0.01 * np.exp(-self.evaluations/(0.75*self.budget)) * (bounds[:, 1] - bounds[:, 0]) # Exponential decay\n                mutation = np.random.randn(self.dim) * 0.001 * np.mean(np.std(self.particles, axis=0)) # Mutation based on diversity\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation + mutation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                diversity = np.mean(np.std(self.particles, axis=0))\n                self.w = max(0.2, 0.9 - (0.9 - 0.2) * (self.evaluations/self.budget) * (1 + 0.5 * diversity))\n                if self.evaluations % 10 == 0: self.w *= 0.9  # Convergence feedback\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Improved velocity update by fine-tuning the scaling factor for enhanced exploration.", "configspace": "", "generation": 92, "fitness": 0.11375154053798464, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.114 with standard deviation 0.002. And the mean value of best solutions found was 0.116 (0. is the best).", "error": "", "parent_id": "ac1e24b5-5433-4e33-b6c3-a5fde2276c65", "metadata": {"aucs": [0.11160689769492882, 0.11387697051315615, 0.11577075340586895], "final_y": [0.11938146449783582, 0.11937935394200416, 0.11026066674297552]}, "mutation_prompt": null}
{"id": "0f1b8c2d-ef0f-4da9-82d1-0886a695ef6b", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                decay_factor = 1 - (self.evaluations / self.budget)  # Linear decay factor\n                self.c1 = (1.2 + (0.3 * np.random.rand())) * decay_factor  # Apply decay\n                self.c2 = (1.2 + (0.3 * np.random.rand())) * decay_factor  # Apply decay\n                scaling_factor = np.random.uniform(0.5, 1.2, size=self.dim)  # Random scaling, adjusted upper bound\n                dist_factor = np.linalg.norm(self.particles[i] - self.global_best_position) / np.linalg.norm(bounds[:, 1] - bounds[:, 0])\n                velocity_adjustment = 0.985 + 0.015 * dist_factor + 0.02 * np.exp(-self.evaluations/self.budget)  # Enhanced velocity control\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor * velocity_adjustment + \n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                perturbation = np.random.randn(self.dim) * 0.015 * np.exp(-self.evaluations/(0.6*self.budget)) * (bounds[:, 1] - bounds[:, 0]) # Adjusted decay\n                mutation_factor = 0.002  # Adjusted mutation impact\n                mutation = np.random.randn(self.dim) * mutation_factor * np.mean(np.std(self.particles, axis=0))\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation + mutation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                diversity = np.mean(np.std(self.particles, axis=0))\n                self.w = max(0.2, 0.9 - (0.9 - 0.2) * (self.evaluations/self.budget) * (1 + 0.5 * diversity))\n                if self.evaluations % 10 == 0: self.w *= 0.93  # Adjusted convergence feedback\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Enhanced exploration and exploitation balance via adaptive mutation control and velocity update mechanism.", "configspace": "", "generation": 93, "fitness": 0.11450122193006695, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.115 with standard deviation 0.001. And the mean value of best solutions found was 0.116 (0. is the best).", "error": "", "parent_id": "ac1e24b5-5433-4e33-b6c3-a5fde2276c65", "metadata": {"aucs": [0.1137868011356028, 0.11399343531612915, 0.11572342933846891], "final_y": [0.11745512594325114, 0.11944991935233262, 0.11045764307499373]}, "mutation_prompt": null}
{"id": "68a2c5dd-c909-467d-ba18-8fd4be8a558b", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                decay_factor = 1 - (self.evaluations / self.budget)  # Linear decay factor\n                self.c1 = (1.2 + (0.3 * np.random.rand())) * decay_factor  # Apply decay\n                self.c2 = (1.2 + (0.3 * np.random.rand())) * decay_factor  # Apply decay\n                scaling_factor = np.random.uniform(0.5, 1.5, size=self.dim)  # Random scaling\n                dist_factor = np.linalg.norm(self.particles[i] - self.global_best_position) / np.linalg.norm(bounds[:, 1] - bounds[:, 0])\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor * (0.985 + 0.015 * dist_factor) +  # Change made here\n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i])) * 1.001  # Minor change for adaptive scaling\n\n                # Update particle position\n                perturbation = np.random.randn(self.dim) * 0.01 * np.exp(-self.evaluations/(0.75*self.budget)) * (bounds[:, 1] - bounds[:, 0]) # Exponential decay\n                mutation = np.random.randn(self.dim) * 0.001 * np.mean(np.std(self.particles, axis=0)) # Mutation based on diversity\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation + mutation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                diversity = np.mean(np.std(self.particles, axis=0))\n                self.w = max(0.2, 0.9 - (0.9 - 0.2) * (self.evaluations/self.budget) * (1 + 0.5 * diversity))\n                if self.evaluations % 10 == 0: self.w *= 0.9  # Convergence feedback\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Introduce a minor adaptive scaling factor to enhance velocity adjustments.", "configspace": "", "generation": 94, "fitness": 0.11445950942223, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.114 with standard deviation 0.001. And the mean value of best solutions found was 0.116 (0. is the best).", "error": "", "parent_id": "ac1e24b5-5433-4e33-b6c3-a5fde2276c65", "metadata": {"aucs": [0.11361076703260731, 0.11412047650072354, 0.11564728473335917], "final_y": [0.11803078668091116, 0.11945965740119247, 0.10997003798524807]}, "mutation_prompt": null}
{"id": "56ec5bb5-4633-47af-b871-893f21ce3532", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                decay_factor = 1 - (self.evaluations / self.budget)  # Linear decay factor\n                self.c1 = (1.2 + (0.3 * np.random.rand())) * decay_factor  # Apply decay\n                self.c2 = (1.2 + (0.3 * np.random.rand())) * decay_factor  # Apply decay\n                scaling_factor = np.random.uniform(0.6, 1.4, size=self.dim)  # Slightly adjusted scaling\n                dist_factor = np.linalg.norm(self.particles[i] - self.global_best_position) / np.linalg.norm(bounds[:, 1] - bounds[:, 0])\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor * (0.985 + 0.015 * dist_factor) +  \n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                perturbation = np.random.randn(self.dim) * 0.01 * np.exp(-self.evaluations/(0.75*self.budget)) * (bounds[:, 1] - bounds[:, 0]) # Exponential decay\n                mutation = np.random.randn(self.dim) * 0.001 * np.mean(np.std(self.particles, axis=0)) # Mutation based on diversity\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation + mutation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                diversity = np.mean(np.std(self.particles, axis=0))\n                self.w = max(0.2, 0.9 - (0.9 - 0.2) * (self.evaluations/self.budget) * (1.1 + 0.5 * diversity))  # Slightly adjusted\n                if self.evaluations % 10 == 0: self.w *= 0.9  # Convergence feedback\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Enhanced exploration using adaptive velocity scaling and dynamic inertia weight adjustment.", "configspace": "", "generation": 95, "fitness": 0.11307125447809807, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.113 with standard deviation 0.004. And the mean value of best solutions found was 0.116 (0. is the best).", "error": "", "parent_id": "ac1e24b5-5433-4e33-b6c3-a5fde2276c65", "metadata": {"aucs": [0.1069049069471879, 0.11648120240125548, 0.11582765408585083], "final_y": [0.12791909332429485, 0.11006321767796379, 0.10995603667781106]}, "mutation_prompt": null}
{"id": "04693263-da21-474b-b969-17f92a0801cf", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                decay_factor = 1 - (self.evaluations / self.budget)  # Linear decay factor\n                self.c1 = (1.2 + (0.3 * np.random.rand())) * decay_factor  # Apply decay\n                self.c2 = (1.2 + (0.3 * np.random.rand())) * decay_factor  # Apply decay\n                scaling_factor = np.random.uniform(0.5, 1.5, size=self.dim)  # Random scaling\n                dist_factor = np.linalg.norm(self.particles[i] - self.global_best_position) / np.linalg.norm(bounds[:, 1] - bounds[:, 0])\n                noise_factor = np.random.randn() * 0.01  # Adaptive noise addition\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor * (0.985 + 0.015 * dist_factor + noise_factor) +  # Change made here\n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                perturbation = np.random.randn(self.dim) * 0.01 * np.exp(-self.evaluations/(0.75*self.budget)) * (bounds[:, 1] - bounds[:, 0]) # Exponential decay\n                mutation = np.random.randn(self.dim) * 0.001 * np.mean(np.std(self.particles, axis=0)) # Mutation based on diversity\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation + mutation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                diversity = np.mean(np.std(self.particles, axis=0))\n                self.w = max(0.2, 0.9 - (0.9 - 0.2) * (self.evaluations/self.budget) * (1 + 0.5 * diversity))\n                if self.evaluations % 10 == 0: self.w *= 0.9  # Convergence feedback\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Improved convergence by enhancing velocity scaling with adaptive noise.", "configspace": "", "generation": 96, "fitness": 0.11349686988415435, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.113 with standard deviation 0.001. And the mean value of best solutions found was 0.118 (0. is the best).", "error": "", "parent_id": "ac1e24b5-5433-4e33-b6c3-a5fde2276c65", "metadata": {"aucs": [0.11208363300620283, 0.1143539064343233, 0.11405307021193689], "final_y": [0.1188742944405391, 0.11793488972811605, 0.11692682905974683]}, "mutation_prompt": null}
{"id": "022a01fc-bc47-4b57-b221-11c825d8d95d", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                decay_factor = 1 - (self.evaluations / self.budget)  # Linear decay factor\n                self.c1 = (1.2 + (0.3 * np.random.rand())) * decay_factor  # Apply decay\n                self.c2 = (1.2 + (0.3 * np.random.rand())) * decay_factor  # Apply decay\n                scaling_factor = np.random.uniform(0.5, 1.5, size=self.dim)  # Random scaling\n                dist_factor = np.linalg.norm(self.particles[i] - self.global_best_position) / np.linalg.norm(bounds[:, 1] - bounds[:, 0])\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor * (0.98 + 0.02 * dist_factor) +  # Change made here\n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                perturbation = np.random.randn(self.dim) * 0.015 * np.exp(-self.evaluations/(0.8*self.budget)) * (bounds[:, 1] - bounds[:, 0]) # Change made here\n                mutation = np.random.randn(self.dim) * 0.002 * np.mean(np.std(self.particles, axis=0)) # Change made here\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation + mutation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                diversity = np.mean(np.std(self.particles, axis=0))\n                self.w = max(0.2, 0.9 - (0.9 - 0.2) * (self.evaluations/self.budget) * (1 + 0.5 * diversity))\n                if self.evaluations % 10 == 0: self.w *= 0.9  # Convergence feedback\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Improved local and global search balance by modifying perturbation and mutation dynamics.", "configspace": "", "generation": 97, "fitness": 0.1142778787361793, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.114 with standard deviation 0.000. And the mean value of best solutions found was 0.116 (0. is the best).", "error": "", "parent_id": "ac1e24b5-5433-4e33-b6c3-a5fde2276c65", "metadata": {"aucs": [0.11397684877431347, 0.11404232534244241, 0.11481446209178203], "final_y": [0.11726150620570852, 0.1192454278661873, 0.11148315834826705]}, "mutation_prompt": null}
{"id": "4b3aeb91-7c7a-44b1-8bfc-2fc74017dd65", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.7\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n\n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                decay_factor = 1 - (self.evaluations / self.budget)\n                self.c1 = max(1.0, 2.0 - decay_factor) * decay_factor  # Changed line\n                self.c2 = max(1.0, 2.0 - decay_factor) * decay_factor  # Changed line\n                scaling_factor = np.random.uniform(0.5, 1.5, size=self.dim)\n                dist_factor = np.linalg.norm(self.particles[i] - self.global_best_position) / np.linalg.norm(bounds[:, 1] - bounds[:, 0])\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor * (0.985 + 0.015 * dist_factor) +\n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                perturbation = np.random.randn(self.dim) * 0.01 * np.exp(-self.evaluations/(0.75*self.budget)) * (bounds[:, 1] - bounds[:, 0])\n                mutation = np.random.normal(0, 0.001 * np.std(self.particles, axis=0), size=self.dim)  # Changed line\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation + mutation, bounds[:, 0], bounds[:, 1])\n\n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n\n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                diversity = np.mean(np.std(self.particles, axis=0))\n                self.w = max(0.2, 0.9 - (0.9 - 0.2) * (self.evaluations/self.budget) * (1 + 0.5 * diversity))\n                if self.evaluations % 10 == 0: self.w *= 0.9\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Introduced adaptive cognitive-social coefficients and Gaussian adaptive mutation for enhanced exploration and convergence.", "configspace": "", "generation": 98, "fitness": 0.11041142162103779, "feedback": "The algorithm HybridAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.110 with standard deviation 0.002. And the mean value of best solutions found was 0.125 (0. is the best).", "error": "", "parent_id": "ac1e24b5-5433-4e33-b6c3-a5fde2276c65", "metadata": {"aucs": [0.11208995674075961, 0.11110374494783926, 0.10804056317451449], "final_y": [0.11950063853249815, 0.12432678759258142, 0.13129174371064112]}, "mutation_prompt": null}
{"id": "0d32d300-3a8a-4214-a8b3-199583ee211d", "solution": "import numpy as np\n\nclass HybridAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.particles = None\n        self.velocities = None\n        self.personal_best_positions = None\n        self.personal_best_scores = None\n        self.global_best_position = None\n        self.global_best_score = float('inf')\n        self.evaluations = 0\n        self.adaptation_rate = 0.1\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.initialize_particles(bounds, func)\n        \n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                    \n                # Update velocity\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                decay_factor = 1 - (self.evaluations / self.budget)\n                self.c1 = (1.2 + (0.3 * np.random.rand())) * decay_factor\n                self.c2 = (1.2 + (0.3 * np.random.rand())) * decay_factor\n                scaling_factor = np.random.uniform(0.6, 1.4, size=self.dim)  # Narrowed scaling range\n                dist_factor = np.linalg.norm(self.particles[i] - self.global_best_position) / np.linalg.norm(bounds[:, 1] - bounds[:, 0])\n                self.velocities[i] = (self.w * self.velocities[i] * scaling_factor * (0.985 + 0.015 * dist_factor) + \n                                      self.c1 * r1 * (self.personal_best_positions[i] - self.particles[i]) + \n                                      self.c2 * r2 * (self.global_best_position - self.particles[i]))\n\n                # Update particle position\n                perturbation = np.random.randn(self.dim) * 0.01 * np.exp(-self.evaluations/(0.75*self.budget)) * (bounds[:, 1] - bounds[:, 0])\n                mutation_intensity = 0.001 * (1 - (score / self.global_best_score + 1e-9))  # Dynamic mutation intensity\n                mutation = np.random.randn(self.dim) * mutation_intensity * np.mean(np.std(self.particles, axis=0))\n                self.particles[i] = np.clip(self.particles[i] + self.velocities[i] + perturbation + mutation, bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate particle\n                score = self.evaluate(func, self.particles[i])\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.particles[i].copy()\n                \n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.particles[i].copy()\n                \n                # Oppositional learning\n                opposite_particle = bounds[:, 1] + bounds[:, 0] - self.particles[i]\n                opposite_score = self.evaluate(func, opposite_particle)\n                if opposite_score < score:\n                    self.particles[i] = opposite_particle\n                    if opposite_score < self.personal_best_scores[i]:\n                        self.personal_best_scores[i] = opposite_score\n                        self.personal_best_positions[i] = opposite_particle.copy()\n                    if opposite_score < self.global_best_score:\n                        self.global_best_score = opposite_score\n                        self.global_best_position = opposite_particle.copy()\n\n                # Adapt inertia weight\n                diversity = np.mean(np.std(self.particles, axis=0))\n                self.w = max(0.2, 0.9 - (0.9 - 0.2) * (self.evaluations/self.budget) * (1 + 0.5 * diversity))\n                if self.evaluations % 10 == 0: self.w *= 0.9\n\n        return self.global_best_position\n\n    def initialize_particles(self, bounds, func):\n        self.particles = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        self.velocities = np.random.randn(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        self.personal_best_positions = self.particles.copy()\n        self.personal_best_scores = np.array([self.evaluate(func, p) for p in self.particles])\n        best_idx = np.argmin(self.personal_best_scores)\n        self.global_best_position = self.personal_best_positions[best_idx].copy()\n        self.global_best_score = self.personal_best_scores[best_idx]\n\n    def evaluate(self, func, individual):\n        if self.evaluations >= self.budget:\n            return float('inf')\n        self.evaluations += 1\n        return func(individual)", "name": "HybridAdaptivePSO", "description": "Improved exploration by utilizing a dynamic scaling factor and mutation intensity based on current particle performance.", "configspace": "", "generation": 99, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'score' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'score' referenced before assignment\")", "parent_id": "ac1e24b5-5433-4e33-b6c3-a5fde2276c65", "metadata": {}, "mutation_prompt": null}
