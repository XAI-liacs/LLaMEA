{"id": "b1bb9ea1-5e18-44c0-bba1-97a370251a04", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Adaptive Swarm Gradient Descent (ASGD): Combines swarm intelligence and gradient estimation to explore and exploit search space efficiently.", "configspace": "", "generation": 0, "fitness": 0.8264407036439118, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.826 with standard deviation 0.020. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": null, "metadata": {"aucs": [0.8041324604654931, 0.8227266579918514, 0.8524629924743906], "final_y": [0.1412466306774247, 0.13112094863304602, 0.12789490696654837]}, "mutation_prompt": null}
{"id": "203a89fa-e05e-494d-81e1-49d5bc0718cd", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 + 0.1 * adaptive_factor  # Slightly adjusted\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved adaptive behavior in inertia weight adjustment enhances exploration and exploitation balance.", "configspace": "", "generation": 1, "fitness": 0.8602745556589749, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.860 with standard deviation 0.023. And the mean value of best solutions found was 0.130 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "b1bb9ea1-5e18-44c0-bba1-97a370251a04", "metadata": {"aucs": [0.8668856396215238, 0.8291900088820735, 0.8847480184733278], "final_y": [0.13416343301268308, 0.13558507740296089, 0.11964060370854257]}, "mutation_prompt": null}
{"id": "7c936d83-5579-43a7-ab10-249bc0243d23", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        last_improvement = evaluations\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    last_improvement = evaluations\n\n            # Dynamically adjust coefficients based on recent improvements\n            if (evaluations - last_improvement) > self.population_size // 2:\n                cognitive_coeff *= 0.9\n                social_coeff *= 1.1\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhancing exploitation by dynamically adjusting cognitive and social coefficients based on performance trends.", "configspace": "", "generation": 1, "fitness": 0.826318652070054, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.826 with standard deviation 0.027. And the mean value of best solutions found was 0.141 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "b1bb9ea1-5e18-44c0-bba1-97a370251a04", "metadata": {"aucs": [0.8501892819562464, 0.840009119872421, 0.7887575543814944], "final_y": [0.13294083449238114, 0.13440844897940085, 0.15471415771654584]}, "mutation_prompt": null}
{"id": "38ffd668-6c14-4efa-ad8d-896a438db169", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i] + adaptive_factor * np.random.normal(0, 0.1, self.dim)\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent (EASGD): Incorporates adaptive mutation for improved exploration-exploitation balance.", "configspace": "", "generation": 1, "fitness": 0.8344858076885067, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.834 with standard deviation 0.018. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "b1bb9ea1-5e18-44c0-bba1-97a370251a04", "metadata": {"aucs": [0.8351390229301311, 0.8556848051427647, 0.8126335949926241], "final_y": [0.13459255659700486, 0.13002269782177633, 0.1358239478234443]}, "mutation_prompt": null}
{"id": "1d6a0c42-dfa9-4d29-a2b5-99ef8b7af744", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * (1 - evaluations / self.budget)  # Changed line\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Refined ASGD with dynamic social coefficient based on evaluation ratio for improved exploration and exploitation balance.", "configspace": "", "generation": 1, "fitness": 0.8445245198517716, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.845 with standard deviation 0.010. And the mean value of best solutions found was 0.130 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "b1bb9ea1-5e18-44c0-bba1-97a370251a04", "metadata": {"aucs": [0.8403444113431185, 0.8348527994826798, 0.8583763487295164], "final_y": [0.12759477322245383, 0.13428025412899047, 0.12774285183324796]}, "mutation_prompt": null}
{"id": "850d2332-47c6-46e0-a1c3-86681b8aa18a", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * adaptive_factor  # Updated line\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent (EASGD): Refines swarm movement with dynamic learning coefficients based on the function landscape complexity.", "configspace": "", "generation": 1, "fitness": 0.851024047286944, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.851 with standard deviation 0.034. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "b1bb9ea1-5e18-44c0-bba1-97a370251a04", "metadata": {"aucs": [0.8132251085235824, 0.843712600719898, 0.8961344326173516], "final_y": [0.145009760445602, 0.13602422406342296, 0.11720867021812453]}, "mutation_prompt": null}
{"id": "03e6175b-69bf-4bbf-a652-cad4a7ac1095", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 + 0.1 * adaptive_factor  # Slightly adjusted\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * (1 + 0.5 * adaptive_factor)  # Adjusted line\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced convergence with dynamic social coefficient adjustment based on evaluation progress.", "configspace": "", "generation": 2, "fitness": 0.8080709440117619, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.808 with standard deviation 0.044. And the mean value of best solutions found was 0.151 (0. is the best) with standard deviation 0.015.", "error": "", "parent_id": "203a89fa-e05e-494d-81e1-49d5bc0718cd", "metadata": {"aucs": [0.7455902474266105, 0.8387062134252583, 0.8399163711834168], "final_y": [0.17137270976432584, 0.138101479164509, 0.14280380637843393]}, "mutation_prompt": null}
{"id": "718ad018-660c-4bb8-9757-1b84a9088a3b", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 + 0.1 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * (1 + 0.1 * adaptive_factor)  # Slightly adjusted\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced balance by dynamic adjustment of cognitive and social coefficients based on evaluations.", "configspace": "", "generation": 2, "fitness": 0.8439697302861253, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.844 with standard deviation 0.001. And the mean value of best solutions found was 0.136 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "203a89fa-e05e-494d-81e1-49d5bc0718cd", "metadata": {"aucs": [0.8442454659547213, 0.8450135589834555, 0.8426501659201993], "final_y": [0.14066802918052235, 0.1330305713953024, 0.1335262065947308]}, "mutation_prompt": null}
{"id": "0b694cd2-4202-4857-8443-6a528482fe3a", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor  # Slightly adjusted to fine-tune\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Fine-tuned inertia weight initialization and dynamic parameters enhance exploration and exploitation.", "configspace": "", "generation": 2, "fitness": 0.8263780944456669, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.826 with standard deviation 0.013. And the mean value of best solutions found was 0.141 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "203a89fa-e05e-494d-81e1-49d5bc0718cd", "metadata": {"aucs": [0.810021883359511, 0.8426995061259368, 0.826412893851553], "final_y": [0.13464959656562403, 0.1412973278961046, 0.14749054780982718]}, "mutation_prompt": null}
{"id": "d58ae711-d78c-465b-b8b2-de842efb1426", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 + 0.1 * adaptive_factor\n            cognitive_coeff = 1.0 + 0.5 * adaptive_factor  # Changed to dynamic adjustment\n            social_coeff = 1.0 + 0.5 * adaptive_factor    # Changed to dynamic adjustment\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Dynamic adjustment of cognitive and social coefficients improves convergence speed and solution quality.", "configspace": "", "generation": 2, "fitness": 0.8259602546558208, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.826 with standard deviation 0.036. And the mean value of best solutions found was 0.143 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "203a89fa-e05e-494d-81e1-49d5bc0718cd", "metadata": {"aucs": [0.7837897943557152, 0.8228984473646961, 0.8711925222470511], "final_y": [0.15367967532260896, 0.14301410347897825, 0.13326292875172185]}, "mutation_prompt": null}
{"id": "9fc66a7d-34a8-4068-81ba-321b58b60b86", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 * adaptive_factor**2 + 0.1  # Non-linear adjustment\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced non-linear decrease in inertia, enhancing early-stage exploration and late-stage exploitation.", "configspace": "", "generation": 2, "fitness": 0.8315010582378424, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.832 with standard deviation 0.041. And the mean value of best solutions found was 0.137 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "203a89fa-e05e-494d-81e1-49d5bc0718cd", "metadata": {"aucs": [0.8819328577627189, 0.8306520636839041, 0.7819182532669038], "final_y": [0.11763650050026053, 0.14613690107009936, 0.14700200891337534]}, "mutation_prompt": null}
{"id": "9754219f-ee46-4723-ad26-899d42308a6f", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 + 0.1 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * (1 + 0.1 * adaptive_factor)  # Slightly adjusted\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Introduce dynamic mutation\n                mutation_strength = adaptive_factor * 0.1 * (ub - lb)\n                mutation = np.random.uniform(-mutation_strength, mutation_strength, self.dim)\n                swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce dynamic mutation for increased exploration at early stages and enhanced exploitation at later stages.", "configspace": "", "generation": 3, "fitness": 0.8207713044292945, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.821 with standard deviation 0.032. And the mean value of best solutions found was 0.147 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "718ad018-660c-4bb8-9757-1b84a9088a3b", "metadata": {"aucs": [0.8029081267572798, 0.7932179270296686, 0.8661878595009347], "final_y": [0.14443420952542174, 0.16071859621458529, 0.13489197508269224]}, "mutation_prompt": null}
{"id": "6698cb78-94f7-4f8a-8869-a654adea0ed4", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 + 0.1 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * (1 + 0.15 * adaptive_factor)  # Adjusted from 0.1\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved social coefficient variability to enhance exploration and exploitation balance.", "configspace": "", "generation": 3, "fitness": 0.8196674464701347, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.820 with standard deviation 0.049. And the mean value of best solutions found was 0.149 (0. is the best) with standard deviation 0.016.", "error": "", "parent_id": "718ad018-660c-4bb8-9757-1b84a9088a3b", "metadata": {"aucs": [0.7828752679806406, 0.7868350642031308, 0.8892920072266329], "final_y": [0.15678880626980007, 0.1625860505543254, 0.12638977399188467]}, "mutation_prompt": null}
{"id": "6f8cf71e-abb5-421e-8be0-a6f4bdc27389", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.cos(2 * np.pi * evaluations / self.budget)  # Oscillating inertia\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * (1 + 0.1 * adaptive_factor)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                exploration_noise = 0.01 * np.random.uniform(lb, ub, self.dim) * adaptive_factor  # Added exploration\n                swarm[i] += self.velocity[i] + exploration_noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Adaptive balance through oscillating inertia, self-adaptive exploration, and selective learning.", "configspace": "", "generation": 3, "fitness": 0.8268718672600803, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.827 with standard deviation 0.030. And the mean value of best solutions found was 0.140 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "718ad018-660c-4bb8-9757-1b84a9088a3b", "metadata": {"aucs": [0.806432536796905, 0.8048515964656642, 0.8693314685176716], "final_y": [0.137886757754217, 0.15143633363616116, 0.13068651446268031]}, "mutation_prompt": null}
{"id": "aa51f814-107b-4b06-b8ef-7b7e8b658c9b", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 + 0.1 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * (1 + adaptive_factor)  # Slightly adjusted (Changed Line)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced adaptive social coefficient scaling based on iteration proportion to improve convergence speed.", "configspace": "", "generation": 3, "fitness": 0.810348772776356, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.810 with standard deviation 0.032. And the mean value of best solutions found was 0.150 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "718ad018-660c-4bb8-9757-1b84a9088a3b", "metadata": {"aucs": [0.7693375216376076, 0.814676731675196, 0.8470320650162642], "final_y": [0.15699324372807344, 0.1528577208306452, 0.14114080537678475]}, "mutation_prompt": null}
{"id": "fd1ad81b-cb63-41e9-979e-e13857166d5a", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.8 + 0.2 * adaptive_factor  # Changed from 0.9\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.7 * (1 + 0.1 * adaptive_factor)  # Changed from 1.5\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced exploration through adaptive population size and improved convergence by dynamic learning rates.", "configspace": "", "generation": 3, "fitness": 0.8101673061990807, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.810 with standard deviation 0.008. And the mean value of best solutions found was 0.150 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "718ad018-660c-4bb8-9757-1b84a9088a3b", "metadata": {"aucs": [0.81781516135908, 0.7985811747683841, 0.814105582469778], "final_y": [0.14203760675516297, 0.15858123361468968, 0.1480885402544072]}, "mutation_prompt": null}
{"id": "38144732-ef7a-4229-942b-6d7f5e75b5c5", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.cos(2 * np.pi * evaluations / self.budget)  # Oscillating inertia\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * (1 + 0.1 * adaptive_factor)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                exploration_noise = 0.02 * np.random.uniform(lb, ub, self.dim) * adaptive_factor**2  # Adjusted noise\n                swarm[i] += self.velocity[i] + exploration_noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced exploration with adaptive noise scaling for improved global search capability.", "configspace": "", "generation": 4, "fitness": 0.8543359504970004, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.854 with standard deviation 0.013. And the mean value of best solutions found was 0.130 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "6f8cf71e-abb5-421e-8be0-a6f4bdc27389", "metadata": {"aucs": [0.8696157349716892, 0.8375341388228885, 0.8558579776964235], "final_y": [0.12397714014160288, 0.13920420340943862, 0.1261137741713947]}, "mutation_prompt": null}
{"id": "1b04982f-7ae8-4148-88a0-07c2be62c171", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.cos(2 * np.pi * evaluations / self.budget)\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * (1 + 0.1 * adaptive_factor)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                # Enhanced exploration with global best distance scaling\n                exploration_noise = 0.01 * np.linalg.norm(global_best - swarm[i]) * np.random.uniform(lb, ub, self.dim) * adaptive_factor\n                swarm[i] += self.velocity[i] + exploration_noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced exploration through adaptive noise scaling based on global best distance.", "configspace": "", "generation": 4, "fitness": 0.8015664098771248, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.802 with standard deviation 0.047. And the mean value of best solutions found was 0.145 (0. is the best) with standard deviation 0.015.", "error": "", "parent_id": "6f8cf71e-abb5-421e-8be0-a6f4bdc27389", "metadata": {"aucs": [0.7367112542427413, 0.8210109537041272, 0.8469770216845056], "final_y": [0.16203306657250227, 0.1454891153485156, 0.12636947923655084]}, "mutation_prompt": null}
{"id": "450d7e06-4446-4551-befa-7304087c0870", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.cos(2 * np.pi * evaluations / self.budget)\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.6 * (1 + 0.1 * adaptive_factor)  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                exploration_noise = 0.02 * np.random.uniform(lb, ub, self.dim) * adaptive_factor  # Enhanced exploration\n                swarm[i] += self.velocity[i] + exploration_noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Refined adaptive search with dynamic learning rate and enhanced exploration.", "configspace": "", "generation": 4, "fitness": 0.8023533374085524, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.802 with standard deviation 0.071. And the mean value of best solutions found was 0.152 (0. is the best) with standard deviation 0.028.", "error": "", "parent_id": "6f8cf71e-abb5-421e-8be0-a6f4bdc27389", "metadata": {"aucs": [0.849093735830406, 0.8559293950277276, 0.702036881367524], "final_y": [0.1333282804687782, 0.13124445349525937, 0.19182221743032546]}, "mutation_prompt": null}
{"id": "29f6d5a1-8ac3-43b5-827a-5266de600fcc", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.cos(2 * np.pi * evaluations / self.budget)  # Oscillating inertia\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * (1 + 0.1 * adaptive_factor)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                exploration_noise = 0.01 * np.random.uniform(lb, ub, self.dim) * adaptive_factor**2  # Adapted exploration\n                swarm[i] += self.velocity[i] + exploration_noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Optimized personal learning via differential adaptation and adaptive exploration noise scaling.", "configspace": "", "generation": 4, "fitness": 0.8369406268614542, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.837 with standard deviation 0.025. And the mean value of best solutions found was 0.137 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "6f8cf71e-abb5-421e-8be0-a6f4bdc27389", "metadata": {"aucs": [0.8708947822926503, 0.8298733744798656, 0.8100537238118468], "final_y": [0.13033791385819138, 0.14235805847736638, 0.13805050966651589]}, "mutation_prompt": null}
{"id": "e1a0451a-90e0-4f15-b687-720f5bc3ba26", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        # Initialize chaotic map parameters\n        self.chaotic_map = np.random.rand(self.population_size)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Update chaotic map\n            self.chaotic_map = 4 * self.chaotic_map * (1 - self.chaotic_map)\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.cos(2 * np.pi * evaluations / self.budget)\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * (1 + 0.1 * adaptive_factor)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                chaotic_influence = self.chaotic_map[i] * 0.1\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    chaotic_influence * (ub - lb) * np.random.randn(self.dim))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Integrates chaotic maps for enhanced exploration and convergence control in swarm optimization.", "configspace": "", "generation": 4, "fitness": 0.8042176386299985, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.804 with standard deviation 0.049. And the mean value of best solutions found was 0.151 (0. is the best) with standard deviation 0.017.", "error": "", "parent_id": "6f8cf71e-abb5-421e-8be0-a6f4bdc27389", "metadata": {"aucs": [0.8494868749299611, 0.8271422319016174, 0.7360238090584168], "final_y": [0.1344935446314336, 0.14365254545189765, 0.1738831890245205]}, "mutation_prompt": null}
{"id": "f666942d-cbbc-40d2-989c-b3e3d50a6732", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.cos(2 * np.pi * evaluations / self.budget)  # Oscillating inertia\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * (1 + 0.15 * np.sin(2 * np.pi * evaluations / self.budget) * adaptive_factor)  # Dynamic change\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                exploration_noise = 0.03 * np.random.uniform(lb, ub, self.dim) * adaptive_factor**2  # Adjusted noise\n                swarm[i] += self.velocity[i] + exploration_noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced adaptive exploration with dynamic social coefficient adjustments for improved convergence.", "configspace": "", "generation": 5, "fitness": 0.8641129650929608, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.864 with standard deviation 0.022. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "38144732-ef7a-4229-942b-6d7f5e75b5c5", "metadata": {"aucs": [0.864570196531226, 0.836559560234136, 0.8912091385135202], "final_y": [0.12358422419581583, 0.13503165190626176, 0.11936980120681218]}, "mutation_prompt": null}
{"id": "3fc36dc6-61a1-49bb-b8b8-a3d713a730ea", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.cos(2 * np.pi * evaluations / self.budget)  \n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * (1 + 0.1 * adaptive_factor)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = 0.9 * (inertia_weight * self.velocity[i] +  # Adjusted inertia weight\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                exploration_noise = 0.03 * np.random.uniform(lb, ub, self.dim) * adaptive_factor**2  # Adjusted noise\n                swarm[i] += self.velocity[i] + exploration_noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 5) == 0:  # Periodic reinitialization\n                swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved global search with adaptive exploration through learning rate modulation and strategic reinitialization.", "configspace": "", "generation": 5, "fitness": 0.8576730802228442, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.858 with standard deviation 0.032. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "38144732-ef7a-4229-942b-6d7f5e75b5c5", "metadata": {"aucs": [0.8167877449592833, 0.8618671340180866, 0.8943643616911625], "final_y": [0.14170091996212408, 0.1308782188656249, 0.12138105725041948]}, "mutation_prompt": null}
{"id": "46ce4deb-4998-415d-a3a9-4566103072bf", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.population_size = self.initial_population_size\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.cos(2 * np.pi * evaluations / self.budget)\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * (1 + 0.1 * adaptive_factor)\n\n            # Adjust population size based on remaining budget\n            self.population_size = max(4, int(self.initial_population_size * adaptive_factor))\n            swarm = swarm[:self.population_size]\n            personal_best = personal_best[:self.population_size]\n            personal_best_value = personal_best_value[:self.population_size]\n            self.velocity = self.velocity[:self.population_size]\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                exploration_noise = 0.02 * np.random.uniform(lb, ub, self.dim) * adaptive_factor**2\n                swarm[i] += self.velocity[i] + exploration_noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Refined exploration strategy with dynamic adjustment of population size for enhanced convergence.", "configspace": "", "generation": 5, "fitness": 0.8686687575941724, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.869 with standard deviation 0.020. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "38144732-ef7a-4229-942b-6d7f5e75b5c5", "metadata": {"aucs": [0.8855700515897627, 0.8402256912242538, 0.880210529968501], "final_y": [0.11782253803553144, 0.1381393615936406, 0.12422803139509608]}, "mutation_prompt": null}
{"id": "541355e3-5ce8-4c19-9e10-7baf2fe862af", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 - 0.2 * adaptive_factor  # Line changed\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * (1 + 0.2 * adaptive_factor)  # Line changed\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                \n                # Generate Lévy flight steps for diversified exploration\n                levy_flight = 0.01 * np.random.standard_cauchy(self.dim) * adaptive_factor**2  # Line changed\n                swarm[i] += self.velocity[i] + levy_flight  # Line changed\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced swarm coordination with adaptive learning rates and diversified exploration using Lévy flights.", "configspace": "", "generation": 5, "fitness": 0.8674928463960274, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.867 with standard deviation 0.022. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "38144732-ef7a-4229-942b-6d7f5e75b5c5", "metadata": {"aucs": [0.839818335384127, 0.8697384194162521, 0.8929217843877033], "final_y": [0.13538549552769996, 0.1300196557520965, 0.11657684159637416]}, "mutation_prompt": null}
{"id": "a2ec1bdf-9b89-45ea-8ae0-aa633ceec528", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.cos(2 * np.pi * evaluations / self.budget)  # Oscillating inertia\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * (1 + 0.1 * adaptive_factor)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                exploration_noise = 0.02 * np.random.uniform(lb, ub, self.dim) * adaptive_factor**3  # Adjusted noise\n                swarm[i] += self.velocity[i] + exploration_noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Incorporate a decaying exploration noise factor to fine-tune the balance between exploration and exploitation.", "configspace": "", "generation": 5, "fitness": 0.8849231617386438, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.885 with standard deviation 0.018. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "38144732-ef7a-4229-942b-6d7f5e75b5c5", "metadata": {"aucs": [0.8761056559664403, 0.8685084252432989, 0.9101554040061919], "final_y": [0.12270963610102781, 0.12982362761498212, 0.11533892804120871]}, "mutation_prompt": null}
{"id": "30b03bef-f03a-4ae2-81d7-da7f5b43812b", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.5 * np.cos(2 * np.pi * evaluations / self.budget)  # Oscillating inertia\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * (1 + 0.1 * adaptive_factor)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                exploration_noise = 0.02 * np.random.uniform(lb, ub, self.dim) * adaptive_factor**3  # Adjusted noise\n                swarm[i] += self.velocity[i] + exploration_noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Utilize an oscillating inertia weight to dynamically adjust exploration and exploitation balance.", "configspace": "", "generation": 6, "fitness": 0.8741717794840635, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.874 with standard deviation 0.039. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "a2ec1bdf-9b89-45ea-8ae0-aa633ceec528", "metadata": {"aucs": [0.823296668239174, 0.881825735667367, 0.9173929345456495], "final_y": [0.13649684126013262, 0.12207464126844458, 0.11438617451918387]}, "mutation_prompt": null}
{"id": "7fb28e71-4e38-43fc-b799-46322edf6c40", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.cos(2 * np.pi * evaluations / self.budget)\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * (1 + 0.1 * adaptive_factor)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                damping_factor = 0.9 + 0.1 * (1 - adaptive_factor)  # Adaptive damping\n                self.velocity[i] = (damping_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                exploration_noise = 0.02 * np.random.uniform(lb, ub, self.dim) * adaptive_factor**3\n                swarm[i] += self.velocity[i] + exploration_noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance swarm diversity by introducing adaptive damping to velocity updates.", "configspace": "", "generation": 6, "fitness": 0.8794322393485879, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.879 with standard deviation 0.017. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "a2ec1bdf-9b89-45ea-8ae0-aa633ceec528", "metadata": {"aucs": [0.8597936462991214, 0.8773368991067966, 0.901166172639846], "final_y": [0.12635428826801276, 0.12572360509147473, 0.1175038574561712]}, "mutation_prompt": null}
{"id": "d8514040-a067-48c5-91c9-217bb102786d", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.cos(2 * np.pi * evaluations / self.budget)  # Oscillating inertia\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * (1 + 0.1 * adaptive_factor)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                mutation_strength = 0.1 * (np.random.rand(self.dim) - 0.5) * adaptive_factor  # Dynamic mutation\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation_strength)  # Updated velocity\n                exploration_noise = 0.02 * np.random.uniform(lb, ub, self.dim) * adaptive_factor**3  # Adjusted noise\n                swarm[i] += self.velocity[i] + exploration_noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance swarm diversity by introducing a dynamic mutation rate to the velocity update.", "configspace": "", "generation": 6, "fitness": 0.87466906846069, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.875 with standard deviation 0.014. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "a2ec1bdf-9b89-45ea-8ae0-aa633ceec528", "metadata": {"aucs": [0.872946093829604, 0.8578811692025932, 0.8931799423498731], "final_y": [0.11935199083706871, 0.12725486603427483, 0.1158219095229468]}, "mutation_prompt": null}
{"id": "b20c7b62-3bac-42d4-a01f-b9c109ffb72f", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.cos(2 * np.pi * evaluations / self.budget)  # Oscillating inertia\n            cognitive_coeff = 1.5 * (1 + 0.1 * np.sin(evaluations / self.budget * np.pi))  # Added oscillation\n            social_coeff = 1.5 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                exploration_noise = 0.02 * np.random.uniform(lb, ub, self.dim) * adaptive_factor**3  # Adjusted noise\n                swarm[i] += self.velocity[i] + exploration_noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce time-varying oscillations in the coefficients for enhanced exploration-exploitation balance.  ", "configspace": "", "generation": 6, "fitness": 0.8720346728963114, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.872 with standard deviation 0.009. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "a2ec1bdf-9b89-45ea-8ae0-aa633ceec528", "metadata": {"aucs": [0.8713711006123077, 0.8834208468122853, 0.8613120712643414], "final_y": [0.12638094966311186, 0.12349755204191781, 0.12464743914777587]}, "mutation_prompt": null}
{"id": "abd117b1-bd8e-4997-93f0-ddc61c84bcc5", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.cos(2 * np.pi * evaluations / self.budget)  # Oscillating inertia\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * (1 + 0.1 * adaptive_factor)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.7 + 0.3 * adaptive_factor  # Adaptive learning rate\n                self.velocity[i] = (learning_rate * (inertia_weight * self.velocity[i] +\n                                                     cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                                     social_coeff * r2 * (global_best - swarm[i])))\n                exploration_noise = 0.02 * np.random.uniform(lb, ub, self.dim) * adaptive_factor**3  # Adjusted noise\n                swarm[i] += self.velocity[i] + exploration_noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce an adaptive learning rate for velocity adjustments to enhance convergence speed and precision.", "configspace": "", "generation": 6, "fitness": 0.8746590522853778, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.875 with standard deviation 0.030. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "a2ec1bdf-9b89-45ea-8ae0-aa633ceec528", "metadata": {"aucs": [0.8381944342230359, 0.8738924189482947, 0.911890303684803], "final_y": [0.13366954719258894, 0.1265791884214681, 0.11472646134173725]}, "mutation_prompt": null}
{"id": "afdc1bd9-3e6f-4896-97f9-82d064660a51", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.cos(2 * np.pi * evaluations / self.budget)\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * (1 + 0.1 * adaptive_factor)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                damping_factor = 0.9 + 0.1 * (1 - adaptive_factor)\n                self.velocity[i] = (damping_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                exploration_noise = 0.02 * np.random.uniform(lb, ub, self.dim) * adaptive_factor**3\n\n                # Introduce adaptive crossover and mutation\n                if np.random.rand() < 0.3:\n                    crossover_partner = swarm[np.random.randint(self.population_size)]\n                    swarm[i] = 0.5 * (swarm[i] + crossover_partner)\n                mutation_strength = adaptive_factor * 0.1\n                swarm[i] += self.velocity[i] + exploration_noise + np.random.normal(0, mutation_strength, self.dim)\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce adaptive crossover and mutation inspired by evolutionary algorithms to enhance exploration in swarm optimization.", "configspace": "", "generation": 7, "fitness": 0.8801811693530994, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.880 with standard deviation 0.018. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "7fb28e71-4e38-43fc-b799-46322edf6c40", "metadata": {"aucs": [0.859307911528726, 0.878748489107199, 0.9024871074233731], "final_y": [0.13200069396056402, 0.12482934923604527, 0.11473760971024727]}, "mutation_prompt": null}
{"id": "6fb74d05-bf3a-4267-b76c-7402ad2bb584", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.cos(2 * np.pi * evaluations / self.budget)\n            # Updated lines start here\n            cognitive_coeff = 1.5 * adaptive_factor + 0.5 * np.random.random()  # Increase randomness\n            social_coeff = 1.5 * (1 + 0.1 * adaptive_factor) + 0.5 * np.random.random()  # Increase randomness\n            # Updated lines end here\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                damping_factor = 0.9 + 0.1 * (1 - adaptive_factor)  # Adaptive damping\n                self.velocity[i] = (damping_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                exploration_noise = 0.02 * np.random.uniform(lb, ub, self.dim) * adaptive_factor**3\n                swarm[i] += self.velocity[i] + exploration_noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Implement adaptive learning rates for cognitive and social components to enhance exploration and exploitation.", "configspace": "", "generation": 7, "fitness": 0.880216287704508, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.880 with standard deviation 0.029. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "7fb28e71-4e38-43fc-b799-46322edf6c40", "metadata": {"aucs": [0.8968084683612186, 0.8398337702801582, 0.9040066244721473], "final_y": [0.1165914969070212, 0.13514007439263087, 0.11451454835127028]}, "mutation_prompt": null}
{"id": "1a51364b-a07c-4feb-9544-c2496ed17a00", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.cos(2 * np.pi * evaluations / self.budget) * np.random.rand()  # Stochastic modification\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * (1 + 0.1 * adaptive_factor)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                damping_factor = 0.9 + 0.1 * (1 - adaptive_factor)  # Adaptive damping\n                self.velocity[i] = (damping_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                exploration_noise = 0.02 * np.random.uniform(lb, ub, self.dim) * adaptive_factor**3\n                swarm[i] += self.velocity[i] + exploration_noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce stochastic inertia weight to enhance exploration in early stages of the search.", "configspace": "", "generation": 7, "fitness": 0.8954748216708387, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.895 with standard deviation 0.015. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "7fb28e71-4e38-43fc-b799-46322edf6c40", "metadata": {"aucs": [0.8975887575282346, 0.8756400577101976, 0.9131956497740839], "final_y": [0.11572720163887729, 0.11740250401360242, 0.11367077198572917]}, "mutation_prompt": null}
{"id": "3514a2ec-7feb-4830-be8e-43a8d9f324c6", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.cos(2 * np.pi * evaluations / self.budget)\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * (1 + 0.1 * adaptive_factor)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                damping_factor = 0.9 + 0.1 * (1 - adaptive_factor)  # Adaptive damping\n                self.velocity[i] = (damping_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                exploration_noise = 0.02 * np.random.uniform(lb, ub, self.dim) * (adaptive_factor**3 + 0.01 * np.sin(2 * np.pi * evaluations / self.budget))  # Modulated exploration noise\n                swarm[i] += self.velocity[i] + exploration_noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce enhanced exploration by modulating exploration noise with a sinusoidal pattern for better global search.", "configspace": "", "generation": 7, "fitness": 0.8994303435078072, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.899 with standard deviation 0.005. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "7fb28e71-4e38-43fc-b799-46322edf6c40", "metadata": {"aucs": [0.9040604102545409, 0.8930536757031212, 0.9011769445657595], "final_y": [0.11794635996273395, 0.11577287942501346, 0.11698449176773673]}, "mutation_prompt": null}
{"id": "1f3b6739-74ba-4516-b3e9-ff7502c0a36a", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.cos(2 * np.pi * evaluations / self.budget)\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * (1 + 0.1 * adaptive_factor)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                damping_factor = 0.9 + 0.1 * (1 - adaptive_factor)  # Adaptive damping\n                self.velocity[i] = (damping_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                exploration_noise = 0.02 * np.random.uniform(lb, ub, self.dim) * adaptive_factor**2.5  # Modified line\n                swarm[i] += self.velocity[i] + exploration_noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance swarm's local exploration by introducing a time-varying exploration noise scaling factor.", "configspace": "", "generation": 7, "fitness": 0.8604583679816695, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.860 with standard deviation 0.041. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.015.", "error": "", "parent_id": "7fb28e71-4e38-43fc-b799-46322edf6c40", "metadata": {"aucs": [0.8110588723909475, 0.8580206013681999, 0.9122956301858614], "final_y": [0.15044629966770862, 0.12985718339739227, 0.1129176616167552]}, "mutation_prompt": null}
{"id": "ef6cd8c5-a6c3-40ef-810f-0071fd69ba3b", "solution": "import numpy as np\n\nclass AdaptiveSwarmLevyFlight:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.population_size = self.initial_population_size\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def levy_flight(self, size, dim):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.normal(0, sigma, size=(size, dim))\n        v = np.random.normal(0, 1, size=(size, dim))\n        step = u / np.abs(v)**(1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.cos(2 * np.pi * evaluations / self.budget)\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * (1 + 0.1 * adaptive_factor)\n\n            if evaluations % 10 == 0:  # Dynamic population adjustment\n                self.population_size = max(2, int(self.initial_population_size * (1 - 0.1 * adaptive_factor)))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                damping_factor = 0.9 + 0.1 * (1 - adaptive_factor)\n                self.velocity[i] = (damping_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                exploration_noise = self.levy_flight(1, self.dim).flatten() * adaptive_factor  # Lévy flight exploration\n                swarm[i] += self.velocity[i] + exploration_noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmLevyFlight", "description": "Enhance swarm intelligence by incorporating a Lévy flight mechanism and dynamic population size adjustment for robust exploration and exploitation balance.", "configspace": "", "generation": 8, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 14 is out of bounds for axis 0 with size 14').", "error": "IndexError('index 14 is out of bounds for axis 0 with size 14')", "parent_id": "3514a2ec-7feb-4830-be8e-43a8d9f324c6", "metadata": {}, "mutation_prompt": null}
{"id": "e2f0e8fd-167a-4442-954a-f6537026e1e3", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.cos(2 * np.pi * evaluations / self.budget)\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * (1 + 0.1 * adaptive_factor)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                damping_factor = 0.9 + 0.1 * (1 - adaptive_factor)  # Adaptive damping\n                self.velocity[i] = (damping_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                exploration_noise = 0.02 * np.random.uniform(lb, ub, self.dim) * (adaptive_factor**3 + 0.02 * np.sin(2 * np.pi * evaluations / self.budget))  # Modulated exploration noise\n                swarm[i] += self.velocity[i] + exploration_noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance exploration by modulating exploration noise with an adaptive sinusoidal pattern for improved global search convergence.", "configspace": "", "generation": 8, "fitness": 0.8578855872099407, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.858 with standard deviation 0.032. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "3514a2ec-7feb-4830-be8e-43a8d9f324c6", "metadata": {"aucs": [0.8544136639344546, 0.8204141654363833, 0.8988289322589842], "final_y": [0.13168570508030242, 0.14304024425972284, 0.11836796105285963]}, "mutation_prompt": null}
{"id": "6b994e26-c370-44cc-8cab-31f1edb7ddbd", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        chaotic_factor = np.random.random()  # Initial chaotic factor\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.cos(2 * np.pi * evaluations / self.budget)\n            cognitive_coeff = 1.5 * adaptive_factor * chaotic_factor\n            social_coeff = 1.5 * (1 + 0.1 * adaptive_factor)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                damping_factor = 0.9 + 0.1 * (1 - adaptive_factor)\n                self.velocity[i] = (damping_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                exploration_noise = 0.02 * np.random.uniform(lb, ub, self.dim) * (adaptive_factor**3 + 0.01 * np.sin(2 * np.pi * evaluations / self.budget))\n                swarm[i] += self.velocity[i] + exploration_noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n            chaotic_factor = 4 * chaotic_factor * (1 - chaotic_factor)  # Logistic map for chaos\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance global search by incorporating chaotic maps to dynamically adjust exploration noise and cognitive coefficients.", "configspace": "", "generation": 8, "fitness": 0.8789745443325803, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.879 with standard deviation 0.018. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "3514a2ec-7feb-4830-be8e-43a8d9f324c6", "metadata": {"aucs": [0.884151195838601, 0.8978010713948699, 0.8549713657642698], "final_y": [0.11794115198464594, 0.11804215502050919, 0.1313986339432921]}, "mutation_prompt": null}
{"id": "f84db021-d39a-4776-871c-e477ded1eaf6", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.cos(2 * np.pi * evaluations / self.budget)\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * (1 + 0.1 * adaptive_factor)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                damping_factor = 0.9 + 0.1 * (1 - adaptive_factor)  # Adaptive damping\n                self.velocity[i] = (damping_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                exploration_noise = 0.02 * np.random.uniform(lb, ub, self.dim) * (adaptive_factor**3 + 0.01 * np.sin(2 * np.pi * (evaluations / self.budget + 0.5)))  # Modulated exploration noise with phase shift\n                swarm[i] += self.velocity[i] + exploration_noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Refine exploration noise modulation by introducing a dynamic phase shift to improve solution diversity and convergence.", "configspace": "", "generation": 8, "fitness": 0.8742403987122674, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.874 with standard deviation 0.020. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "3514a2ec-7feb-4830-be8e-43a8d9f324c6", "metadata": {"aucs": [0.8648344655651536, 0.8563882862442381, 0.9014984443274107], "final_y": [0.1272852412126898, 0.13337203082429683, 0.11641964039908159]}, "mutation_prompt": null}
{"id": "5cd17e65-80b4-436c-9b0e-88bd5bee25d2", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.cos(2 * np.pi * evaluations / self.budget) * np.exp(-0.01 * evaluations)  # Exponential decay\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * (1 + 0.1 * adaptive_factor)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                damping_factor = 0.9 + 0.1 * (1 - adaptive_factor)  # Adaptive damping\n                self.velocity[i] = (damping_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                exploration_noise = 0.02 * np.random.uniform(lb, ub, self.dim) * (adaptive_factor**3 + 0.01 * np.sin(2 * np.pi * evaluations / self.budget))  # Modulated exploration noise\n                swarm[i] += self.velocity[i] + exploration_noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance the convergence by introducing an exponential decay in the inertia weight for improved fine-tuning in later stages.", "configspace": "", "generation": 8, "fitness": 0.8703642207261691, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.870 with standard deviation 0.015. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "3514a2ec-7feb-4830-be8e-43a8d9f324c6", "metadata": {"aucs": [0.8507055266293556, 0.8875005631325062, 0.8728865724166455], "final_y": [0.1370737160262394, 0.12010972547839349, 0.12569432660604996]}, "mutation_prompt": null}
{"id": "fd37cb97-c934-4abf-bf32-29b2528e5ebf", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        chaotic_factor = np.random.random()  # Initial chaotic factor\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.cos(2 * np.pi * evaluations / self.budget)\n            cognitive_coeff = 1.5 * adaptive_factor * chaotic_factor\n            social_coeff = 1.5 * (1 + 0.1 * adaptive_factor)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                damping_factor = 0.9 + 0.1 * (1 - adaptive_factor)\n                self.velocity[i] = (damping_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                levy_noise = 0.01 * np.random.standard_cauchy(self.dim)  # Lévy flight\n                swarm[i] += self.velocity[i] + levy_noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n            chaotic_factor = 4 * chaotic_factor * (1 - chaotic_factor)  # Logistic map for chaos\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce Lévy flight-based random walk to enhance exploration of the solution space.", "configspace": "", "generation": 9, "fitness": 0.8704495673570208, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.870 with standard deviation 0.018. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "6b994e26-c370-44cc-8cab-31f1edb7ddbd", "metadata": {"aucs": [0.8726731212511564, 0.891420405001005, 0.8472551758189013], "final_y": [0.123557566502835, 0.1180106709956028, 0.13604512327997442]}, "mutation_prompt": null}
{"id": "9db42b03-2516-4f5a-b497-b64e3580bc4d", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        chaotic_factor = np.random.random()  # Initial chaotic factor\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.cos(np.pi * evaluations / self.budget)  # Adjusted cosine factor\n            cognitive_coeff = 1.5 * adaptive_factor * chaotic_factor\n            social_coeff = 1.5 * (1 + 0.1 * adaptive_factor)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                damping_factor = 0.9 + 0.1 * (1 - adaptive_factor)\n                self.velocity[i] = (damping_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                exploration_noise = 0.02 * np.random.uniform(lb, ub, self.dim) * (adaptive_factor**3 + 0.01 * np.sin(2 * np.pi * evaluations / self.budget))\n                swarm[i] += self.velocity[i] + exploration_noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n            chaotic_factor = 4 * chaotic_factor * (1 - chaotic_factor)  # Logistic map for chaos\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce adaptive inertia weight modulation for enhanced convergence stability.", "configspace": "", "generation": 9, "fitness": 0.8285891231965925, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.829 with standard deviation 0.039. And the mean value of best solutions found was 0.143 (0. is the best) with standard deviation 0.015.", "error": "", "parent_id": "6b994e26-c370-44cc-8cab-31f1edb7ddbd", "metadata": {"aucs": [0.7776222026132638, 0.8353925165285259, 0.8727526504479877], "final_y": [0.16206654845722324, 0.14103423956299677, 0.12657527488758757]}, "mutation_prompt": null}
{"id": "969686c4-7873-4675-9d97-0388e6dab08b", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        chaotic_factor = np.random.random()  # Initial chaotic factor\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.cos(2 * np.pi * evaluations / self.budget)\n            cognitive_coeff = 1.5 * adaptive_factor * chaotic_factor\n            social_coeff = 1.5 * (1 + 0.1 * adaptive_factor)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                damping_factor = 0.9 + 0.1 * (1 - adaptive_factor)\n                self.velocity[i] = (damping_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                exploration_noise = (0.02 + 0.01 * np.sin(2 * np.pi * evaluations / self.budget)) * np.random.uniform(lb, ub, self.dim) * (adaptive_factor**3 + 0.01 * np.sin(2 * np.pi * evaluations / self.budget))\n                swarm[i] += self.velocity[i] + exploration_noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n            chaotic_factor = 4 * chaotic_factor * (1 - chaotic_factor)  # Logistic map for chaos\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce dynamic adaptivity to exploration noise by adjusting its factor with a sinusoidal component to balance exploration and exploitation.", "configspace": "", "generation": 9, "fitness": 0.8342793693778904, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.834 with standard deviation 0.009. And the mean value of best solutions found was 0.137 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "6b994e26-c370-44cc-8cab-31f1edb7ddbd", "metadata": {"aucs": [0.8451379743620602, 0.8353390873983648, 0.822361046373246], "final_y": [0.13487722082206555, 0.13237492000096462, 0.14514721518948714]}, "mutation_prompt": null}
{"id": "dd140fc3-9621-4ada-86f9-b972b8707b3d", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def levy_flight(self, dim):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                (np.math.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.normal(0, 1, dim) * sigma\n        v = np.random.normal(0, 1, dim)\n        step = u / np.abs(v)**(1 / beta)\n        return step\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        chaotic_factor = np.random.random()  # Initial chaotic factor\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.cos(2 * np.pi * evaluations / self.budget)\n            cognitive_coeff = 1.5 * adaptive_factor * chaotic_factor\n            social_coeff = 1.5 * (1 + 0.1 * adaptive_factor)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                damping_factor = 0.9 + 0.1 * (1 - adaptive_factor)\n                self.velocity[i] = (damping_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                exploration_noise = 0.02 * np.random.uniform(lb, ub, self.dim) * (adaptive_factor**3 + 0.01 * np.sin(2 * np.pi * evaluations / self.budget))\n                levy_step = self.levy_flight(self.dim) * adaptive_factor\n                swarm[i] += self.velocity[i] + exploration_noise + levy_step\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n            chaotic_factor = 4 * chaotic_factor * (1 - chaotic_factor)  # Logistic map for chaos\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance AdaptiveSwarmGradientDescent using Levy flight for enhanced exploration in early iterations.", "configspace": "", "generation": 9, "fitness": 0.8706700429281572, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.871 with standard deviation 0.007. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "6b994e26-c370-44cc-8cab-31f1edb7ddbd", "metadata": {"aucs": [0.8775403319819617, 0.8610114615420466, 0.8734583352604637], "final_y": [0.12089045822971811, 0.12862600509189048, 0.1182327777133938]}, "mutation_prompt": null}
{"id": "dca904f7-884a-4bbc-822e-79a28a4be00e", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        chaotic_factor = np.random.random()  # Initial chaotic factor\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.cos(2 * np.pi * evaluations / self.budget)\n\n            # Modified line: Introduce temporal oscillations in the social coefficient\n            cognitive_coeff = 1.5 * adaptive_factor * chaotic_factor\n            social_coeff = 1.5 * (1 + 0.1 * adaptive_factor) * np.sin(np.pi * evaluations / self.budget)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                damping_factor = 0.9 + 0.1 * (1 - adaptive_factor)\n                self.velocity[i] = (damping_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                exploration_noise = 0.02 * np.random.uniform(lb, ub, self.dim) * (adaptive_factor**3 + 0.01 * np.sin(2 * np.pi * evaluations / self.budget))\n                swarm[i] += self.velocity[i] + exploration_noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n            chaotic_factor = 4 * chaotic_factor * (1 - chaotic_factor)  # Logistic map for chaos\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce temporal oscillations in the social coefficient for enhanced diversity and convergence.", "configspace": "", "generation": 9, "fitness": 0.8981385531632021, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.898 with standard deviation 0.014. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "6b994e26-c370-44cc-8cab-31f1edb7ddbd", "metadata": {"aucs": [0.8798927080121678, 0.8993923237833216, 0.9151306276941168], "final_y": [0.11775730277375529, 0.11974665756197234, 0.11232203746549452]}, "mutation_prompt": null}
{"id": "4b4c2c30-0146-4e02-90c3-127e2c663534", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        chaotic_factor = np.random.random()  # Initial chaotic factor\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.cos(2 * np.pi * evaluations / self.budget)\n\n            # Modified line: Introduce an adaptive chaotic factor\n            cognitive_coeff = 1.5 * adaptive_factor * chaotic_factor\n            social_coeff = 1.5 * (1 + 0.1 * adaptive_factor) * np.sin(np.pi * evaluations / self.budget)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                damping_factor = 0.9 + 0.1 * (1 - adaptive_factor)\n                self.velocity[i] = (damping_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                exploration_noise = 0.02 * np.random.uniform(lb, ub, self.dim) * (adaptive_factor**3 + 0.01 * np.sin(2 * np.pi * evaluations / self.budget))\n                swarm[i] += self.velocity[i] + exploration_noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n            chaotic_factor = 4 * chaotic_factor * (1 - chaotic_factor) * (0.5 + 0.5 * adaptive_factor)  # Adaptive logistic map for chaos\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce an adaptive chaotic factor to enhance exploration and prevent premature convergence.", "configspace": "", "generation": 10, "fitness": 0.851120439575133, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.851 with standard deviation 0.017. And the mean value of best solutions found was 0.134 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "dca904f7-884a-4bbc-822e-79a28a4be00e", "metadata": {"aucs": [0.8464686675901655, 0.8325319834050892, 0.8743606677301441], "final_y": [0.13574239904813712, 0.14304771624554036, 0.12232139329404135]}, "mutation_prompt": null}
{"id": "ef2c2a97-8482-4a40-94ca-348427b8fa3d", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        chaotic_factor = np.random.random()  # Initial chaotic factor\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            # Modified line: Introduce chaotic oscillations in the inertia weight\n            inertia_weight = 0.5 + 0.4 * np.cos(chaotic_factor * np.pi * evaluations / self.budget)\n\n            cognitive_coeff = 1.5 * adaptive_factor * chaotic_factor\n            social_coeff = 1.5 * (1 + 0.1 * adaptive_factor) * np.sin(np.pi * evaluations / self.budget)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                damping_factor = 0.9 + 0.1 * (1 - adaptive_factor)\n                self.velocity[i] = (damping_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                exploration_noise = 0.02 * np.random.uniform(lb, ub, self.dim) * (adaptive_factor**3 + 0.01 * np.sin(2 * np.pi * evaluations / self.budget))\n                swarm[i] += self.velocity[i] + exploration_noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n            chaotic_factor = 4 * chaotic_factor * (1 - chaotic_factor)  # Logistic map for chaos\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce chaotic oscillations in the inertia weight for improved convergence and exploration balance.", "configspace": "", "generation": 10, "fitness": 0.8746710563606697, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.875 with standard deviation 0.026. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "dca904f7-884a-4bbc-822e-79a28a4be00e", "metadata": {"aucs": [0.8669751975751327, 0.8478324902037894, 0.9092054813030868], "final_y": [0.11730605460274857, 0.13360252475085022, 0.11567396084169568]}, "mutation_prompt": null}
{"id": "afefa45b-1f9c-4abe-83ae-c1f9d4db4261", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        chaotic_factor = np.random.random()  # Initial chaotic factor\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.cos(2 * np.pi * evaluations / self.budget)\n\n            cognitive_coeff = 1.5 * adaptive_factor * chaotic_factor\n            social_coeff = 1.5 * (1 + 0.1 * adaptive_factor) * np.sin(np.pi * evaluations / self.budget)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                damping_factor = 0.9 + 0.1 * (1 - adaptive_factor)\n                self.velocity[i] = (damping_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                exploration_noise = 0.02 * np.random.uniform(lb, ub, self.dim) * (adaptive_factor**3 + 0.01 * np.sin(2 * np.pi * evaluations / self.budget))\n                swarm[i] += self.velocity[i] + exploration_noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n            chaotic_factor = 4 * chaotic_factor * (1 - chaotic_factor) * (1 - 0.1 * adaptive_factor)  # Adjusted chaotic factor\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce an adaptive chaotic factor in the cognitive coefficient to enhance exploration.", "configspace": "", "generation": 10, "fitness": 0.864166013568845, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.864 with standard deviation 0.010. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "dca904f7-884a-4bbc-822e-79a28a4be00e", "metadata": {"aucs": [0.8497475733045463, 0.8719252938151454, 0.8708251735868432], "final_y": [0.12753183584673888, 0.1237588557832151, 0.11777174814818547]}, "mutation_prompt": null}
{"id": "0d68bf70-c3bd-4cb0-9c1a-533af5273a9b", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        chaotic_factor = np.random.random()  # Initial chaotic factor\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.4 * (evaluations / self.budget)  # Modified line\n\n            cognitive_coeff = 1.5 * adaptive_factor * chaotic_factor\n            social_coeff = 1.5 * (1 + 0.1 * adaptive_factor) * np.sin(np.pi * evaluations / self.budget)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                damping_factor = 0.9 + 0.1 * (1 - adaptive_factor)\n                self.velocity[i] = (damping_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                exploration_noise = 0.02 * np.random.uniform(lb, ub, self.dim) * (adaptive_factor**3 + 0.01 * np.sin(2 * np.pi * evaluations / self.budget))\n                swarm[i] += self.velocity[i] + exploration_noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n            chaotic_factor = 4 * chaotic_factor * (1 - chaotic_factor)  # Logistic map for chaos\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a dynamic inertia weight decay for improved exploration-exploitation balance.", "configspace": "", "generation": 10, "fitness": 0.8607661908132976, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.861 with standard deviation 0.023. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "dca904f7-884a-4bbc-822e-79a28a4be00e", "metadata": {"aucs": [0.835211014689939, 0.8567695370648332, 0.8903180206851208], "final_y": [0.1289479860784699, 0.13065270389724104, 0.11804247466825124]}, "mutation_prompt": null}
{"id": "640a5ecd-db22-4635-920c-09aa9df487b0", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        chaotic_factor = np.random.random()  # Initial chaotic factor\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.cos(2 * np.pi * evaluations / self.budget)\n\n            # Modified line: Introduce temporal oscillations in the social coefficient\n            cognitive_coeff = 1.5 * adaptive_factor * chaotic_factor\n            social_coeff = 1.5 * (1 + 0.1 * adaptive_factor) * np.sin(np.pi * evaluations / self.budget)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                damping_factor = 0.9 + 0.1 * (1 - adaptive_factor)\n                self.velocity[i] = (damping_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                exploration_noise = 0.02 * np.random.uniform(lb, ub, self.dim) * (adaptive_factor**3 + 0.01 * np.sin(2 * np.pi * evaluations / self.budget))\n                swarm[i] += self.velocity[i] + exploration_noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n            chaotic_factor = 4 * chaotic_factor * (1 - chaotic_factor) * np.exp(-0.01 * evaluations)  # Logistic map for chaos with decay\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Utilize exponential decay in the chaotic factor to enhance exploration-exploitation balance.", "configspace": "", "generation": 10, "fitness": 0.8793736266321828, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.879 with standard deviation 0.028. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "dca904f7-884a-4bbc-822e-79a28a4be00e", "metadata": {"aucs": [0.8421609409183557, 0.8873978991523319, 0.9085620398258605], "final_y": [0.13770655233089835, 0.11981456041080762, 0.11332182376116207]}, "mutation_prompt": null}
{"id": "b012a58e-ad83-41d7-a7a7-c24159bf6260", "solution": "import numpy as np\nfrom scipy.stats import levy\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        chaotic_factor = np.random.random()  # Initial chaotic factor\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.cos(2 * np.pi * evaluations / self.budget)\n\n            cognitive_coeff = 1.5 * adaptive_factor * chaotic_factor\n            social_coeff = 1.5 * (1 + 0.1 * adaptive_factor) * np.sin(np.pi * evaluations / self.budget)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                damping_factor = 0.9 + 0.1 * (1 - adaptive_factor)\n                self.velocity[i] = (damping_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                \n                # Introduced Levy Flight for additional exploration\n                levy_flight = levy.rvs(size=self.dim)\n                exploration_noise = 0.02 * levy_flight * (adaptive_factor**3 + 0.01 * np.sin(2 * np.pi * evaluations / self.budget))\n                \n                swarm[i] += self.velocity[i] + exploration_noise\n                # Dynamic boundary adaptation\n                swarm[i] = np.clip(swarm[i], lb - adaptive_factor, ub + adaptive_factor)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n            chaotic_factor = 4 * chaotic_factor * (1 - chaotic_factor) * np.exp(-0.01 * evaluations)\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Integrate Levy Flight and dynamic boundary adaptation to enhance exploration and exploitation balance.", "configspace": "", "generation": 11, "fitness": 0.8589756729857193, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.859 with standard deviation 0.015. And the mean value of best solutions found was 0.132 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "640a5ecd-db22-4635-920c-09aa9df487b0", "metadata": {"aucs": [0.8746314071384467, 0.8394830106374134, 0.8628126011812982], "final_y": [0.12558201864780372, 0.1393025644828082, 0.13121811231246838]}, "mutation_prompt": null}
{"id": "95a15d0d-cb8c-43cd-a90d-908c9c328419", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        chaotic_factor = np.random.random()  # Initial chaotic factor\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.cos(2 * np.pi * evaluations / self.budget)\n\n            # Modified line: Introduce temporal oscillations in the social coefficient\n            cognitive_coeff = 1.5 * adaptive_factor * chaotic_factor\n            social_coeff = 1.5 * (1 + 0.1 * adaptive_factor) * np.sin(np.pi * evaluations / self.budget)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                damping_factor = 0.9 + 0.1 * (1 - adaptive_factor)\n                self.velocity[i] = (damping_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                exploration_noise = 0.02 * np.random.uniform(lb, ub, self.dim) * (adaptive_factor**3 + 0.01 * np.sin(2 * np.pi * evaluations / self.budget))\n                swarm[i] += self.velocity[i] + exploration_noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n            chaotic_factor = 4 * chaotic_factor * (1 - chaotic_factor) * np.exp(-0.005 * evaluations)  # Adjusted decay for chaos\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a dynamically adjusted chaotic factor to enhance adaptive behavior within the optimization process.", "configspace": "", "generation": 11, "fitness": 0.8646240443287548, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.865 with standard deviation 0.016. And the mean value of best solutions found was 0.129 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "640a5ecd-db22-4635-920c-09aa9df487b0", "metadata": {"aucs": [0.8556314746698112, 0.8512120730820172, 0.887028585234436], "final_y": [0.13169837151146213, 0.13330501320893462, 0.12213942000192979]}, "mutation_prompt": null}
{"id": "4bbba5d6-bf65-4a69-bd3c-74b59f4b24b0", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        chaotic_factor = np.random.random()  # Initial chaotic factor\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.cos(2 * np.pi * evaluations / self.budget)\n\n            # Modified line: Introduce temporal oscillations in the social coefficient\n            cognitive_coeff = 1.5 * adaptive_factor * chaotic_factor\n            social_coeff = 1.5 * (1 + 0.1 * adaptive_factor) * np.sin(2 * np.pi * evaluations / self.budget)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                damping_factor = 0.9 + 0.1 * (1 - adaptive_factor)\n                self.velocity[i] = (damping_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                exploration_noise = 0.02 * np.random.uniform(lb, ub, self.dim) * (adaptive_factor**3 + 0.01 * np.sin(2 * np.pi * evaluations / self.budget))\n                swarm[i] += self.velocity[i] + exploration_noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n            chaotic_factor = 4 * chaotic_factor * (1 - chaotic_factor) * np.exp(-0.01 * evaluations)  # Logistic map for chaos with decay\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce sinusoidal oscillations to enhance exploration-exploitation synergy.", "configspace": "", "generation": 11, "fitness": 0.8292457630544533, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.829 with standard deviation 0.017. And the mean value of best solutions found was 0.145 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "640a5ecd-db22-4635-920c-09aa9df487b0", "metadata": {"aucs": [0.8425589039193493, 0.804596630487498, 0.8405817547565124], "final_y": [0.13988447370175072, 0.15518154627303504, 0.1388650638778558]}, "mutation_prompt": null}
{"id": "f2caf2f5-99f1-41ca-a3e5-ad9545377bc6", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        chaotic_factor = np.random.random()  # Initial chaotic factor\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.cos(2 * np.pi * evaluations / self.budget)\n\n            # Modified line: Introduce dynamic decrease for the cognitive coefficient\n            cognitive_coeff = 1.5 * adaptive_factor * chaotic_factor * np.exp(-0.005 * evaluations)\n            social_coeff = 1.5 * (1 + 0.1 * adaptive_factor) * np.sin(np.pi * evaluations / self.budget)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                damping_factor = 0.9 + 0.1 * (1 - adaptive_factor)\n                self.velocity[i] = (damping_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                exploration_noise = 0.02 * np.random.uniform(lb, ub, self.dim) * (adaptive_factor**3 + 0.01 * np.sin(2 * np.pi * evaluations / self.budget))\n                swarm[i] += self.velocity[i] + exploration_noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n            chaotic_factor = 4 * chaotic_factor * (1 - chaotic_factor) * np.exp(-0.01 * evaluations)  # Logistic map for chaos with decay\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a dynamic decrease in cognitive coefficient to enhance convergence precision.", "configspace": "", "generation": 11, "fitness": 0.8415062999392579, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.842 with standard deviation 0.032. And the mean value of best solutions found was 0.139 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "640a5ecd-db22-4635-920c-09aa9df487b0", "metadata": {"aucs": [0.828628185420154, 0.8098694684530781, 0.8860212459445418], "final_y": [0.14220103654170757, 0.1519506901009966, 0.1221447911500253]}, "mutation_prompt": null}
{"id": "a79022c3-ff22-4623-9bfb-183fbe838d1b", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        chaotic_factor = np.random.random()  # Initial chaotic factor\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n\n            # Modified line: Introduce dynamic inertia weight for better exploration-exploitation balance\n            inertia_weight = 0.5 + 0.4 * np.cos(2 * np.pi * evaluations / self.budget) * (0.9 + 0.1 * np.sin(np.pi * evaluations / self.budget))\n\n            cognitive_coeff = 1.5 * adaptive_factor * chaotic_factor\n            social_coeff = 1.5 * (1 + 0.1 * adaptive_factor) * np.sin(np.pi * evaluations / self.budget)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                damping_factor = 0.9 + 0.1 * (1 - adaptive_factor)\n                self.velocity[i] = (damping_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                exploration_noise = 0.02 * np.random.uniform(lb, ub, self.dim) * (adaptive_factor**3 + 0.01 * np.sin(2 * np.pi * evaluations / self.budget))\n                swarm[i] += self.velocity[i] + exploration_noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n            chaotic_factor = 4 * chaotic_factor * (1 - chaotic_factor) * np.exp(-0.01 * evaluations)  # Logistic map for chaos with decay\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a dynamic inertia weight formula to improve exploration-exploitation balance.", "configspace": "", "generation": 11, "fitness": 0.8441075373630865, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.844 with standard deviation 0.025. And the mean value of best solutions found was 0.139 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "640a5ecd-db22-4635-920c-09aa9df487b0", "metadata": {"aucs": [0.8118797244880249, 0.8477689507343809, 0.8726739368668536], "final_y": [0.14902599128677607, 0.1392113963196313, 0.12770255164030486]}, "mutation_prompt": null}
{"id": "5b1f773a-15a0-4f20-8859-66d1795cb2fe", "solution": "import numpy as np\n\nclass AdaptiveSwarmChaosMemory:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.memory_coeff = np.random.uniform(0.1, 0.3, self.population_size)  # new memory coefficient\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        chaotic_factor = np.random.random()\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.cos(2 * np.pi * evaluations / self.budget)\n\n            cognitive_coeff = 1.5 * adaptive_factor * chaotic_factor\n            social_coeff = 1.5 * (1 + 0.1 * adaptive_factor) * np.sin(np.pi * evaluations / self.budget)\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)  # added r3\n                damping_factor = 0.9 + 0.1 * (1 - adaptive_factor)\n                \n                # Consider memory coefficient in the velocity update\n                self.velocity[i] = (damping_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    self.memory_coeff[i] * r3 * (swarm[np.random.randint(self.population_size)] - swarm[i]))  # memory term\n                \n                exploration_noise = 0.02 * np.random.uniform(lb, ub, self.dim) * (adaptive_factor**3 + 0.01 * np.sin(2 * np.pi * evaluations / self.budget))\n                swarm[i] += self.velocity[i] + exploration_noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n            chaotic_factor = 4 * chaotic_factor * (1 - chaotic_factor) * np.sin(2 * np.pi * evaluations / self.budget)  # modified chaos calculation\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmChaosMemory", "description": "Utilize adaptive chaos-induced memory to enhance exploration and convergence balance in swarm optimization.", "configspace": "", "generation": 12, "fitness": 0.8741679469286616, "feedback": "The algorithm AdaptiveSwarmChaosMemory got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.874 with standard deviation 0.023. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "95a15d0d-cb8c-43cd-a90d-908c9c328419", "metadata": {"aucs": [0.8791833238980665, 0.8441221908254273, 0.8991983260624912], "final_y": [0.12521906437469954, 0.1375548531812547, 0.11233650525974037]}, "mutation_prompt": null}
{"id": "b060991a-5bac-458e-ba74-fe2afd888368", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        chaotic_factor = np.random.random()  # Initial chaotic factor\n\n        while evaluations < self.budget:\n            adaptive_factor = (1 - evaluations / self.budget) ** 2  # Nonlinear adaptive factor\n            inertia_weight = 0.5 + 0.4 * np.cos(2 * np.pi * evaluations / self.budget)\n\n            cognitive_coeff = 1.5 * adaptive_factor * chaotic_factor\n            social_coeff = 1.5 * (1 + 0.1 * adaptive_factor) * np.sin(np.pi * evaluations / self.budget)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                damping_factor = 0.9 + 0.1 * (1 - adaptive_factor)\n                self.velocity[i] = (damping_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                exploration_noise = 0.02 * np.random.uniform(lb, ub, self.dim) * (adaptive_factor**3 + 0.01 * np.sin(2 * np.pi * evaluations / self.budget))\n                swarm[i] += self.velocity[i] + exploration_noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n            chaotic_factor = 4 * chaotic_factor * (1 - chaotic_factor) * (0.99 ** evaluations)  # Enhanced chaotic decay\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Refine chaotic dynamics and exploration by introducing a nonlinear adaptive factor for improved convergence.", "configspace": "", "generation": 12, "fitness": 0.850573507874017, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.851 with standard deviation 0.026. And the mean value of best solutions found was 0.136 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "95a15d0d-cb8c-43cd-a90d-908c9c328419", "metadata": {"aucs": [0.817091897268493, 0.853624565516317, 0.8810040608372407], "final_y": [0.1484114132302461, 0.1353739428732561, 0.12419908552916048]}, "mutation_prompt": null}
{"id": "c5265b25-4198-4a32-ac22-89bb697df311", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        chaotic_factor = np.random.random()  # Initial chaotic factor\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.cos(2 * np.pi * evaluations / self.budget)\n\n            cognitive_coeff = 1.5 * adaptive_factor * chaotic_factor\n            social_coeff = 1.5 * (1 + 0.1 * adaptive_factor) * (np.sin(np.pi * evaluations / self.budget) + 0.05 * np.random.random())  # Added stochastic perturbation\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                damping_factor = 0.9 + 0.1 * (1 - adaptive_factor)\n                self.velocity[i] = (damping_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                exploration_noise = 0.02 * np.random.uniform(lb, ub, self.dim) * (adaptive_factor**3 + 0.01 * np.sin(2 * np.pi * evaluations / self.budget))\n                swarm[i] += self.velocity[i] + exploration_noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n            chaotic_factor = 4 * chaotic_factor * (1 - chaotic_factor) * np.exp(-0.004 * evaluations)  # Fine-tuned decay for chaos\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance exploration by adding stochastic perturbation to the social coefficient and fine-tuning chaotic factor dynamics for improved adaptive behavior.", "configspace": "", "generation": 12, "fitness": 0.8494554241850795, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.849 with standard deviation 0.030. And the mean value of best solutions found was 0.137 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "95a15d0d-cb8c-43cd-a90d-908c9c328419", "metadata": {"aucs": [0.8702582884905062, 0.8063513311403527, 0.8717566529243795], "final_y": [0.1273624323483885, 0.15441779572946268, 0.12897887254484175]}, "mutation_prompt": null}
{"id": "bcec2c70-c2a0-449b-a68c-24641993f0d7", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        chaotic_factor = np.random.random()  # Initial chaotic factor\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.cos(2 * np.pi * evaluations / self.budget)\n\n            # Modified line: Introduce temporal oscillations in the social coefficient\n            cognitive_coeff = 1.5 * adaptive_factor * chaotic_factor\n            social_coeff = 1.5 * (1 + 0.1 * adaptive_factor) * np.sin(np.pi * evaluations / self.budget)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                damping_factor = 0.9 + 0.1 * (1 - adaptive_factor)\n                self.velocity[i] = (damping_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                exploration_noise = 0.02 * np.random.uniform(lb, ub, self.dim) * (adaptive_factor**3 + 0.01 * np.sin(2 * np.pi * evaluations / self.budget))\n                swarm[i] += self.velocity[i] + exploration_noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n            chaotic_factor = 4 * chaotic_factor * (1 - chaotic_factor) * np.exp(-0.005 * evaluations * adaptive_factor)  # Adjusted decay for chaos\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce an adaptive chaotic factor based on evaluations to improve convergence dynamics.", "configspace": "", "generation": 12, "fitness": 0.8404563859390203, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.840 with standard deviation 0.025. And the mean value of best solutions found was 0.136 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "95a15d0d-cb8c-43cd-a90d-908c9c328419", "metadata": {"aucs": [0.8346949355408475, 0.8127031731604737, 0.8739710491157394], "final_y": [0.13297083965752965, 0.1515255396620705, 0.12454040696766022]}, "mutation_prompt": null}
{"id": "546067f3-2358-430f-8d93-2a319234b983", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        chaotic_factor = np.random.random()  # Initial chaotic factor\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.cos(2 * np.pi * evaluations / self.budget)\n\n            cognitive_coeff = 1.5 * adaptive_factor * chaotic_factor\n            social_coeff = 1.5 * (1 + 0.1 * adaptive_factor) * np.sin(np.pi * evaluations / self.budget)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                damping_factor = 0.9 + 0.1 * (1 - adaptive_factor)\n                self.velocity[i] = (damping_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n\n                # New line: Introduce Lévy flight mechanism\n                levy_flight = np.random.normal(size=self.dim) * (adaptive_factor**2)\n                exploration_noise = 0.02 * levy_flight * (adaptive_factor**3 + 0.01 * np.sin(2 * np.pi * evaluations / self.budget))\n                \n                swarm[i] += self.velocity[i] + exploration_noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n            chaotic_factor = 4 * chaotic_factor * (1 - chaotic_factor) * np.exp(-0.005 * evaluations)\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Integrate a Lévy flight mechanism to enhance exploration and prevent premature convergence in the chaotic swarm optimization process.", "configspace": "", "generation": 12, "fitness": 0.8588827630048171, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.859 with standard deviation 0.029. And the mean value of best solutions found was 0.132 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "95a15d0d-cb8c-43cd-a90d-908c9c328419", "metadata": {"aucs": [0.8183810067225737, 0.8854516066785577, 0.87281567561332], "final_y": [0.1453308835724203, 0.12503249063843747, 0.1260105413654875]}, "mutation_prompt": null}
{"id": "b1cf1a58-9a0b-49e4-8a5a-9391ea7c79f6", "solution": "import numpy as np\n\nclass AdaptiveSwarmChaosMemory:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.memory_coeff = np.random.uniform(0.1, 0.3, self.population_size)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        chaotic_factor = np.random.random()\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.cos(2 * np.pi * evaluations / self.budget)\n\n            cognitive_coeff = 1.5 * adaptive_factor * chaotic_factor\n            social_coeff = 1.5 * (1 + 0.1 * adaptive_factor) * np.sin(np.pi * evaluations / self.budget)\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                damping_factor = 0.9 + 0.1 * (1 - adaptive_factor)\n\n                # Introduce chaotic Lévy flights\n                levy_flight = np.random.standard_cauchy(self.dim) * chaotic_factor * 0.5\n\n                self.velocity[i] = (damping_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    self.memory_coeff[i] * r3 * (swarm[np.random.randint(self.population_size)] - swarm[i]) +\n                                    levy_flight)  # add Lévy flight component\n\n                exploration_noise = 0.02 * np.random.uniform(lb, ub, self.dim) * (adaptive_factor**3 + 0.01 * np.sin(2 * np.pi * evaluations / self.budget))\n                swarm[i] += self.velocity[i] + exploration_noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n            chaotic_factor = 4 * chaotic_factor * (1 - chaotic_factor) * np.sin(2 * np.pi * evaluations / self.budget)\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmChaosMemory", "description": "Integrate chaotic Lévy flights for enhanced exploration and convergence in swarm optimization.", "configspace": "", "generation": 13, "fitness": 0.8466912306621593, "feedback": "The algorithm AdaptiveSwarmChaosMemory got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.847 with standard deviation 0.065. And the mean value of best solutions found was 0.137 (0. is the best) with standard deviation 0.024.", "error": "", "parent_id": "5b1f773a-15a0-4f20-8859-66d1795cb2fe", "metadata": {"aucs": [0.8932313842701568, 0.8921464307248104, 0.754695876991511], "final_y": [0.11607193101886326, 0.12340327429789466, 0.1707033983562175]}, "mutation_prompt": null}
{"id": "905f45fb-a8dd-4e83-8446-deae8b2db72e", "solution": "import numpy as np\n\nclass AdaptiveSwarmChaosMemory:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.memory_coeff = np.random.uniform(0.1, 0.3, self.population_size)  # new memory coefficient\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        chaotic_factor = np.random.random()\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.cos(2 * np.pi * evaluations / self.budget)\n\n            cognitive_coeff = 1.5 * adaptive_factor * chaotic_factor\n            social_coeff = 1.5 * (1 + 0.1 * adaptive_factor) * np.sin(np.pi * evaluations / self.budget)\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)  # added r3\n                damping_factor = 0.9 + 0.1 * (1 - adaptive_factor)\n                \n                self.velocity[i] = (damping_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    self.memory_coeff[i] * r3 * (swarm[np.random.randint(self.population_size)] - swarm[i]))  # memory term\n\n                exploration_noise = 0.02 * np.random.uniform(lb, ub, self.dim) * (adaptive_factor**3 + 0.01 * np.sin(2 * np.pi * evaluations / self.budget) * chaotic_factor)  # added chaos factor\n                swarm[i] += self.velocity[i] + exploration_noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n            chaotic_factor = 4 * chaotic_factor * (1 - chaotic_factor) * np.sin(2 * np.pi * evaluations / self.budget)  # modified chaos calculation\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmChaosMemory", "description": "Introduce adaptive memory intensity and chaotic exploration noise to enhance solution diversity and convergence speed.", "configspace": "", "generation": 13, "fitness": 0.8280256837090425, "feedback": "The algorithm AdaptiveSwarmChaosMemory got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.828 with standard deviation 0.064. And the mean value of best solutions found was 0.144 (0. is the best) with standard deviation 0.025.", "error": "", "parent_id": "5b1f773a-15a0-4f20-8859-66d1795cb2fe", "metadata": {"aucs": [0.8932591545992539, 0.8502505080725387, 0.740567388455335], "final_y": [0.11811897447547004, 0.1358523137708021, 0.1769811756760299]}, "mutation_prompt": null}
{"id": "a797ebbb-38a6-471d-bb58-f9ff32c733e1", "solution": "import numpy as np\n\nclass AdaptiveSwarmChaosMemory:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.memory_coeff = np.random.uniform(0.1, 0.3, self.population_size)  # new memory coefficient\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        chaotic_factor = np.random.random()\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.cos(2 * np.pi * evaluations / self.budget)\n\n            cognitive_coeff = 1.5 * adaptive_factor * chaotic_factor\n            social_coeff = 1.5 * (1 + 0.1 * adaptive_factor) * np.sin(np.pi * evaluations / self.budget)\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)  # added r3\n                damping_factor = 0.9 + 0.1 * np.tanh(1 - adaptive_factor)  # modified damping factor\n                \n                # Consider memory coefficient in the velocity update\n                self.velocity[i] = (damping_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    self.memory_coeff[i] * r3 * (swarm[np.random.randint(self.population_size)] - swarm[i]))  # memory term\n                \n                exploration_noise = 0.02 * np.random.uniform(lb, ub, self.dim) * (adaptive_factor**3 + 0.01 * np.sin(2 * np.pi * evaluations / self.budget))\n                swarm[i] += self.velocity[i] + exploration_noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n            chaotic_factor = 4 * chaotic_factor * (1 - chaotic_factor) * np.sin(2 * np.pi * evaluations / self.budget)  # modified chaos calculation\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmChaosMemory", "description": "Introduce nonlinear damping factor to improve convergence dynamics in swarm optimization.", "configspace": "", "generation": 13, "fitness": 0.892573189846627, "feedback": "The algorithm AdaptiveSwarmChaosMemory got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.893 with standard deviation 0.028. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "5b1f773a-15a0-4f20-8859-66d1795cb2fe", "metadata": {"aucs": [0.9245158141673481, 0.8976194068054093, 0.8555843485671238], "final_y": [0.11342846218601144, 0.11951656506016894, 0.12518298624279312]}, "mutation_prompt": null}
{"id": "ffef51cf-3ad1-4a19-b558-5d7b3d7b5555", "solution": "import numpy as np\n\nclass AdaptiveSwarmChaosMemory:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.memory_coeff = np.random.uniform(0.1, 0.3, self.population_size)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        chaotic_factor = np.random.random()  # Initialize with a random chaotic factor\n        multi_chaotic = np.random.random()   # New multi-chaotic map factor\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.cos(2 * np.pi * evaluations / self.budget)\n\n            cognitive_coeff = 1.5 * adaptive_factor * chaotic_factor\n            social_coeff = 1.5 * (1 + 0.1 * adaptive_factor) * np.sin(np.pi * evaluations / self.budget)\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                damping_factor = 0.9 + 0.1 * (1 - adaptive_factor)\n                \n                # Update velocity with an adaptive learning rate\n                self.velocity[i] = (damping_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    self.memory_coeff[i] * r3 * (swarm[np.random.randint(self.population_size)] - swarm[i]))\n                \n                exploration_noise = 0.02 * np.random.uniform(lb, ub, self.dim) * (adaptive_factor**3 + 0.01 * np.sin(2 * np.pi * evaluations / self.budget))\n                swarm[i] += self.velocity[i] + exploration_noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n            chaotic_factor = 4 * chaotic_factor * (1 - chaotic_factor)\n            multi_chaotic = 4 * multi_chaotic * (1 - multi_chaotic) * np.sin(np.pi * evaluations / self.budget)  # Apply multi-chaotic map\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmChaosMemory", "description": "Introduce multi-chaotic maps and adaptive learning rates to enhance swarm diversity and convergence speed.", "configspace": "", "generation": 13, "fitness": 0.8434552384806214, "feedback": "The algorithm AdaptiveSwarmChaosMemory got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.843 with standard deviation 0.069. And the mean value of best solutions found was 0.138 (0. is the best) with standard deviation 0.027.", "error": "", "parent_id": "5b1f773a-15a0-4f20-8859-66d1795cb2fe", "metadata": {"aucs": [0.8924492347357135, 0.8919922082279574, 0.7459242724781935], "final_y": [0.12063150448452986, 0.11687847627641468, 0.17503479411977796]}, "mutation_prompt": null}
{"id": "dc4eef3f-1f81-443b-86d9-14f1da2f5ef2", "solution": "import numpy as np\n\nclass AdaptiveSwarmChaosMemory:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.memory_coeff = np.random.uniform(0.1, 0.3, self.population_size)  # new memory coefficient\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        chaotic_factor = np.random.random()\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.cos(2 * np.pi * evaluations / self.budget)\n\n            cognitive_coeff = 1.5 * adaptive_factor * chaotic_factor\n            social_coeff = 1.5 * (1 + 0.1 * adaptive_factor) * np.sin(np.pi * evaluations / self.budget)\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)  # added r3\n                damping_factor = 0.9 + 0.1 * (1 - adaptive_factor)\n                \n                # Consider memory coefficient in the velocity update\n                self.velocity[i] = (damping_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    self.memory_coeff[i] * r3 * (swarm[np.random.randint(self.population_size)] - swarm[i]))  # memory term\n                \n                exploration_noise = 0.02 * np.random.uniform(lb, ub, self.dim) * (adaptive_factor**3 + 0.01 * np.sin(2 * np.pi * evaluations / self.budget))\n                swarm[i] += self.velocity[i] + exploration_noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n            chaotic_factor = 0.9 * chaotic_factor + 0.1 * np.sin(2 * np.pi * evaluations / self.budget)  # modified chaos calculation\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmChaosMemory", "description": "Introduce a dynamic chaotic factor oscillation to balance exploration and exploitation over the optimization process.", "configspace": "", "generation": 13, "fitness": 0.8353731628306504, "feedback": "The algorithm AdaptiveSwarmChaosMemory got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.835 with standard deviation 0.070. And the mean value of best solutions found was 0.141 (0. is the best) with standard deviation 0.026.", "error": "", "parent_id": "5b1f773a-15a0-4f20-8859-66d1795cb2fe", "metadata": {"aucs": [0.8850074327675547, 0.8851614732305992, 0.7359505824937976], "final_y": [0.1236991753706409, 0.12192019056150671, 0.17793343669226314]}, "mutation_prompt": null}
{"id": "9dc16fe6-7356-45a7-82b7-9bbc49ce9eae", "solution": "import numpy as np\n\nclass AdaptiveSwarmChaosMemory:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.memory_coeff = np.random.uniform(0.1, 0.3, self.population_size)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        chaotic_factor = np.random.random()\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.cos(2 * np.pi * evaluations / self.budget)\n\n            cognitive_coeff = 1.5 * adaptive_factor * chaotic_factor\n            social_coeff = 1.5 * (1 + 0.1 * adaptive_factor) * np.sin(np.pi * evaluations / self.budget)\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                damping_factor = 0.9 + 0.1 * np.tanh(1 - adaptive_factor)\n                \n                self.velocity[i] = (damping_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    self.memory_coeff[i] * r3 * (swarm[np.random.randint(self.population_size)] - swarm[i]))\n                \n                exploration_noise = 0.02 * (np.random.uniform(lb, ub, self.dim) - swarm[i]) * (adaptive_factor**2 + 0.01 * np.sin(2 * np.pi * evaluations / self.budget))\n                swarm[i] += self.velocity[i] + exploration_noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n            chaotic_factor = 4 * chaotic_factor * (1 - chaotic_factor) * np.cos(2 * np.pi * evaluations / self.budget)\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmChaosMemory", "description": "Enhance chaotic factor dynamics and adjust exploration noise to improve convergence and diversity in swarm optimization.", "configspace": "", "generation": 14, "fitness": 0.869479895282966, "feedback": "The algorithm AdaptiveSwarmChaosMemory got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.869 with standard deviation 0.015. And the mean value of best solutions found was 0.129 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "a797ebbb-38a6-471d-bb58-f9ff32c733e1", "metadata": {"aucs": [0.889501573532239, 0.8538630607536769, 0.865075051562982], "final_y": [0.1256027540324125, 0.13449320520230024, 0.1262200257700763]}, "mutation_prompt": null}
{"id": "d0feafd4-8a4f-4cff-bfdf-16a6777d45c6", "solution": "import numpy as np\n\nclass AdaptiveSwarmChaosMemory:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.memory_coeff = np.random.uniform(0.1, 0.3, self.population_size)  # new memory coefficient\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        chaotic_factor = np.random.random()\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.cos(2 * np.pi * evaluations / self.budget)\n\n            cognitive_coeff = 1.5 * adaptive_factor * chaotic_factor\n            social_coeff = 1.5 * (1 + 0.1 * adaptive_factor) * np.sin(np.pi * evaluations / self.budget)\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)  # added r3\n                damping_factor = 0.9 + 0.1 * np.tanh(1 - adaptive_factor)  # modified damping factor\n                \n                # Consider memory coefficient in the velocity update\n                self.velocity[i] = (damping_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    self.memory_coeff[i] * r3 * (swarm[np.random.randint(self.population_size)] - swarm[i]))  # memory term\n                \n                exploration_noise = 0.02 * np.random.uniform(lb, ub, self.dim) * (adaptive_factor**3 + 0.01 * np.sin(2 * np.pi * evaluations / self.budget) * evaluations)  # changed noise scaling\n                swarm[i] += self.velocity[i] + exploration_noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n            chaotic_factor = 4 * chaotic_factor * (1 - chaotic_factor) * np.sin(2 * np.pi * evaluations / self.budget)  # modified chaos calculation\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmChaosMemory", "description": "Enhance swarm exploration by introducing a dynamic noise scaling factor.", "configspace": "", "generation": 14, "fitness": 0.8158046471695787, "feedback": "The algorithm AdaptiveSwarmChaosMemory got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.816 with standard deviation 0.056. And the mean value of best solutions found was 0.151 (0. is the best) with standard deviation 0.021.", "error": "", "parent_id": "a797ebbb-38a6-471d-bb58-f9ff32c733e1", "metadata": {"aucs": [0.8260397471463701, 0.879248766475962, 0.7421254278864037], "final_y": [0.14763388325488358, 0.12674423757333875, 0.17717263694582586]}, "mutation_prompt": null}
{"id": "cc96c582-db37-4955-ab5c-b9a1b4fa6721", "solution": "import numpy as np\n\nclass AdaptiveSwarmChaosMemory:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.memory_coeff = np.random.uniform(0.1, 0.3, self.population_size)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        chaotic_factor = np.random.random()\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.cos(2 * np.pi * evaluations / self.budget)\n\n            cognitive_coeff = 1.5 * adaptive_factor * chaotic_factor\n            social_coeff = 1.5 * (1 + 0.1 * adaptive_factor) * np.sin(np.pi * evaluations / self.budget)\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                damping_factor = 0.9 + 0.1 * np.tanh(1 - adaptive_factor)\n                \n                self.velocity[i] = (damping_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    self.memory_coeff[i] * r3 * (swarm[np.random.randint(self.population_size)] - swarm[i]))\n\n                adaptive_velocity_scaling = np.random.uniform(0.95, 1.05)\n                self.velocity[i] *= adaptive_velocity_scaling\n\n                exploration_noise = 0.02 * np.random.uniform(lb, ub, self.dim) * (adaptive_factor**3 + 0.01 * np.sin(2 * np.pi * evaluations / self.budget))\n                swarm[i] += self.velocity[i] + exploration_noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                if np.random.rand() < 0.1 * adaptive_factor:\n                    swarm[i] = np.random.uniform(lb, ub, self.dim)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n            chaotic_factor = 4 * chaotic_factor * (1 - chaotic_factor) * np.sin(2 * np.pi * evaluations / self.budget)\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmChaosMemory", "description": "Introduce diversity through stochastic position resets and adaptive velocity scaling in swarm optimization.", "configspace": "", "generation": 14, "fitness": 0.8684223484358284, "feedback": "The algorithm AdaptiveSwarmChaosMemory got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.868 with standard deviation 0.008. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "a797ebbb-38a6-471d-bb58-f9ff32c733e1", "metadata": {"aucs": [0.8725347775748304, 0.8572594292173132, 0.8754728385153414], "final_y": [0.12419540025800546, 0.1340217704613157, 0.12202330048378107]}, "mutation_prompt": null}
{"id": "7f340297-e656-47b7-b247-2ae8517193f9", "solution": "import numpy as np\n\nclass AdaptiveSwarmChaosMemory:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.memory_coeff = np.random.uniform(0.1, 0.3, self.population_size)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        chaotic_factor = np.random.random()\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.cos(2 * np.pi * evaluations / self.budget)\n\n            cognitive_coeff = 1.5 * adaptive_factor * chaotic_factor\n            social_coeff = 1.5 * (1 + 0.1 * adaptive_factor) * np.sin(np.pi * evaluations / self.budget)\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                damping_factor = 0.9 + 0.1 * np.tanh(1 - adaptive_factor)\n                \n                dynamic_chaos = chaotic_factor * (1 + 0.05 * np.cos(np.pi * evaluations / self.budget))  # adaptive scaling\n                self.velocity[i] = (damping_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    self.memory_coeff[i] * r3 * (swarm[np.random.randint(self.population_size)] - swarm[i]))\n                \n                exploration_noise = 0.03 * np.random.uniform(lb, ub, self.dim) * (adaptive_factor**3 + 0.01 * np.sin(2 * np.pi * evaluations / self.budget))  # increased diversity\n                swarm[i] += self.velocity[i] + exploration_noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n            chaotic_factor = dynamic_chaos * (1 - dynamic_chaos) * np.sin(2 * np.pi * evaluations / self.budget)  # enhanced chaos\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmChaosMemory", "description": "Introduce adaptive chaos scaling and dynamic exploration to enhance diversity and convergence in swarm optimization.", "configspace": "", "generation": 14, "fitness": 0.7987945304133608, "feedback": "The algorithm AdaptiveSwarmChaosMemory got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.799 with standard deviation 0.057. And the mean value of best solutions found was 0.156 (0. is the best) with standard deviation 0.023.", "error": "", "parent_id": "a797ebbb-38a6-471d-bb58-f9ff32c733e1", "metadata": {"aucs": [0.7795318979062944, 0.8761600252345906, 0.7406916680991973], "final_y": [0.16534112996057737, 0.1247099592266383, 0.17828749440444613]}, "mutation_prompt": null}
{"id": "14d6be40-3563-41d5-85f2-c97e19d95d0a", "solution": "import numpy as np\n\nclass AdaptiveSwarmChaosMemory:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.memory_coeff = np.random.uniform(0.1, 0.3, self.population_size)  # new memory coefficient\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        chaotic_factor = np.random.random()\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.cos(2 * np.pi * evaluations / self.budget)\n\n            cognitive_coeff = 1.5 * adaptive_factor * chaotic_factor * np.cos(np.pi * evaluations / self.budget)  # updated cognitive_coeff\n            social_coeff = 1.5 * (1 + 0.1 * adaptive_factor) * np.sin(np.pi * evaluations / self.budget)\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)  # added r3\n                damping_factor = 0.9 + 0.1 * np.tanh(1 - adaptive_factor)  # modified damping factor\n                \n                # Consider memory coefficient in the velocity update\n                self.velocity[i] = (damping_factor * inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    self.memory_coeff[i] * r3 * (swarm[np.random.randint(self.population_size)] - swarm[i]))  # memory term\n                \n                exploration_noise = 0.02 * np.random.uniform(lb, ub, self.dim) * (adaptive_factor**3 + 0.01 * np.sin(2 * np.pi * evaluations / self.budget))\n                swarm[i] += self.velocity[i] + exploration_noise\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n            chaotic_factor = 4 * chaotic_factor * (1 - chaotic_factor) * np.sin(2 * np.pi * evaluations / self.budget)  # modified chaos calculation\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmChaosMemory", "description": "Optimize swarm stability by dynamically adjusting the cognitive coefficient based on the evaluation ratio.", "configspace": "", "generation": 14, "fitness": 0.8668276071565152, "feedback": "The algorithm AdaptiveSwarmChaosMemory got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.867 with standard deviation 0.016. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "a797ebbb-38a6-471d-bb58-f9ff32c733e1", "metadata": {"aucs": [0.8714588521562072, 0.8453944994690261, 0.8836294698443123], "final_y": [0.12756861318689527, 0.13722085089320768, 0.11979093973354882]}, "mutation_prompt": null}
