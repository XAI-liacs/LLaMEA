{"id": "231098ec-facc-43d8-8545-ca7b9bbabccc", "solution": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.population = np.random.rand(self.population_size, self.dim)\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.5\n\n    def select_parents(self, idx):\n        indices = list(range(self.population_size))\n        indices.remove(idx)\n        np.random.shuffle(indices)\n        return indices[:3]\n\n    def mutate(self, idx):\n        a, b, c = self.select_parents(idx)\n        mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n        lower_bound, upper_bound = self.bounds\n        return np.clip(mutant_vector, lower_bound, upper_bound)\n\n    def crossover(self, target, mutant):\n        crossover_vector = np.copy(target)\n        for i in range(self.dim):\n            if np.random.rand() < self.crossover_rate or i == np.random.randint(self.dim):\n                crossover_vector[i] = mutant[i]\n        return crossover_vector\n\n    def optimize(self, func):\n        while self.eval_count < self.budget:\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                target_vector = self.population[i]\n                mutant_vector = self.mutate(i)\n                trial_vector = self.crossover(target_vector, mutant_vector)\n                trial_fitness = func(trial_vector)\n                self.eval_count += 1\n\n                if trial_fitness < self.best_fitness:\n                    self.best_fitness = trial_fitness\n                    self.best_solution = trial_vector\n\n                if trial_fitness < func(target_vector):\n                    self.population[i] = trial_vector\n\n                # Dynamically adjust mutation and crossover rates\n                self.mutation_factor = 0.5 + 0.3 * (self.best_fitness / trial_fitness)\n                self.crossover_rate = 0.9 - 0.4 * (self.best_fitness / trial_fitness)\n\n        return self.best_solution, self.best_fitness\n\n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        self.population = self.bounds[0] + (self.bounds[1] - self.bounds[0]) * np.random.rand(self.population_size, self.dim)\n        return self.optimize(func)", "name": "AdaptiveDE", "description": "A novel adaptive differential evolution algorithm that dynamically adjusts mutation and crossover rates based on search progress to efficiently explore and exploit the search space.", "configspace": "", "generation": 0, "fitness": 0.7785975871184302, "feedback": "The algorithm AdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.779 with standard deviation 0.022. And the mean value of best solutions found was 0.157 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": null, "metadata": {"aucs": [0.7767552226527894, 0.7531118168648758, 0.8059257218376252], "final_y": [0.159527858381592, 0.16308509580516273, 0.14892772776413565]}, "mutation_prompt": null}
{"id": "507e0262-db3f-4b42-9fd5-7d700d783b47", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.0  # cognitive component\n        self.c2 = 2.0  # social component\n        self.w = 0.7   # inertia weight\n        self.f = 0.8   # differential weight\n        self.cr = 0.9  # crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        \n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Particle Swarm Optimization (PSO) update\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i] if global_best_position is not None else 0))\n\n                candidate_position = np.clip(population[i] + velocities[i], lb, ub)\n                candidate_score = func(candidate_position)\n                evaluations += 1\n\n                # Update personal best\n                if candidate_score < personal_best_scores[i]:\n                    personal_best_scores[i] = candidate_score\n                    personal_best_positions[i] = candidate_position\n\n                # Update global best\n                if candidate_score < global_best_score:\n                    global_best_score = candidate_score\n                    global_best_position = candidate_position\n\n            # Differential Evolution (DE) mutation and crossover\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                mutant_vector = np.clip(personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c]), lb, ub)\n                \n                trial_vector = np.copy(personal_best_positions[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == jrand:\n                        trial_vector[j] = mutant_vector[j]\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                # Selection\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "The algorithm combines particle swarm optimization with differential evolution for enhanced exploration and exploitation in solving black-box optimization problems.", "configspace": "", "generation": 0, "fitness": 0.8183552522414006, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.818 with standard deviation 0.019. And the mean value of best solutions found was 0.144 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": null, "metadata": {"aucs": [0.7914393379281434, 0.8282131790937702, 0.8354132397022883], "final_y": [0.15569693280953156, 0.1367498563556685, 0.14046587680412237]}, "mutation_prompt": null}
{"id": "d24d0341-36a4-485a-aeb3-859e48e41d4a", "solution": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.population = np.random.rand(self.population_size, self.dim)\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.5\n\n    def select_parents(self, idx):\n        indices = list(range(self.population_size))\n        indices.remove(idx)\n        np.random.shuffle(indices)\n        return indices[:3]\n\n    def mutate(self, idx):\n        a, b, c = self.select_parents(idx)\n        mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n        lower_bound, upper_bound = self.bounds\n        return np.clip(mutant_vector, lower_bound, upper_bound)\n\n    def crossover(self, target, mutant):\n        crossover_vector = np.copy(target)\n        for i in range(self.dim):\n            if np.random.rand() < self.crossover_rate or i == np.random.randint(self.dim):\n                crossover_vector[i] = mutant[i]\n        return crossover_vector\n\n    def optimize(self, func):\n        while self.eval_count < self.budget:\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                target_vector = self.population[i]\n                mutant_vector = self.mutate(i)\n                trial_vector = self.crossover(target_vector, mutant_vector)\n                trial_fitness = func(trial_vector)\n                self.eval_count += 1\n\n                if trial_fitness < self.best_fitness:\n                    self.best_fitness = trial_fitness\n                    self.best_solution = trial_vector\n\n                if trial_fitness < func(target_vector):\n                    self.population[i] = trial_vector\n\n                # Dynamically adjust mutation and crossover rates\n                self.mutation_factor = 0.5 + 0.2 * (self.best_fitness / trial_fitness)\n                self.crossover_rate = 0.9 - 0.3 * (self.best_fitness / trial_fitness)\n\n        return self.best_solution, self.best_fitness\n\n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        self.population = self.bounds[0] + (self.bounds[1] - self.bounds[0]) * np.random.rand(self.population_size, self.dim)\n        return self.optimize(func)", "name": "AdaptiveDE", "description": "Enhanced AdaptiveDE where mutation factor and crossover rate adjustments are more conservative to improve stability in exploration and exploitation.", "configspace": "", "generation": 1, "fitness": 0.7791758058395076, "feedback": "The algorithm AdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.779 with standard deviation 0.015. And the mean value of best solutions found was 0.159 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "231098ec-facc-43d8-8545-ca7b9bbabccc", "metadata": {"aucs": [0.776715243195685, 0.762487669735578, 0.7983245045872599], "final_y": [0.16524602120879872, 0.159092115759914, 0.15415893822342497]}, "mutation_prompt": null}
{"id": "662024d5-6bad-476f-b080-724099be052d", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.0  # cognitive component\n        self.c2 = 2.0  # social component\n        self.w = 0.7   # inertia weight\n        self.f = 0.8   # differential weight\n        self.cr = 0.9  # crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        \n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Particle Swarm Optimization (PSO) update\n                r1, r2 = np.random.rand(), np.random.rand()\n                # Dynamic inertia weight adjustment\n                self.w = 0.9 - 0.5 * (evaluations / self.budget)  \n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i] if global_best_position is not None else 0))\n\n                candidate_position = np.clip(population[i] + velocities[i], lb, ub)\n                candidate_score = func(candidate_position)\n                evaluations += 1\n\n                # Update personal best\n                if candidate_score < personal_best_scores[i]:\n                    personal_best_scores[i] = candidate_score\n                    personal_best_positions[i] = candidate_position\n\n                # Update global best\n                if candidate_score < global_best_score:\n                    global_best_score = candidate_score\n                    global_best_position = candidate_position\n\n            # Differential Evolution (DE) mutation and crossover\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                mutant_vector = np.clip(personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c]), lb, ub)\n                \n                trial_vector = np.copy(personal_best_positions[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == jrand:\n                        trial_vector[j] = mutant_vector[j]\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                # Selection\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "The algorithm employs a dynamic adjustment of the inertia weight in PSO to balance exploration and exploitation throughout the search process.", "configspace": "", "generation": 1, "fitness": 0.8056205670282871, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.806 with standard deviation 0.023. And the mean value of best solutions found was 0.138 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "507e0262-db3f-4b42-9fd5-7d700d783b47", "metadata": {"aucs": [0.7972571446832837, 0.7827720824194985, 0.8368324739820789], "final_y": [0.13934324865650372, 0.14772284707556682, 0.12829040118116752]}, "mutation_prompt": null}
{"id": "bb80ecf7-eb63-48ac-a4ca-4ce4b0dff815", "solution": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.population = np.random.rand(self.population_size, self.dim)\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.5\n\n    def select_parents(self, idx):\n        indices = list(range(self.population_size))\n        indices.remove(idx)\n        np.random.shuffle(indices)\n        return indices[:3]\n\n    def mutate(self, idx):\n        a, b, c = self.select_parents(idx)\n        mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n        lower_bound, upper_bound = self.bounds\n        return np.clip(mutant_vector, lower_bound, upper_bound)\n\n    def crossover(self, target, mutant):\n        crossover_vector = np.copy(target)\n        for i in range(self.dim):\n            if np.random.rand() < self.crossover_rate or i == np.random.randint(self.dim):\n                crossover_vector[i] = mutant[i]\n        return crossover_vector\n\n    def optimize(self, func):\n        while self.eval_count < self.budget:\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                target_vector = self.population[i]\n                mutant_vector = self.mutate(i)\n                trial_vector = self.crossover(target_vector, mutant_vector)\n                trial_fitness = func(trial_vector)\n                self.eval_count += 1\n\n                if trial_fitness < self.best_fitness:\n                    self.best_fitness = trial_fitness\n                    self.best_solution = trial_vector\n\n                if trial_fitness < func(target_vector):\n                    self.population[i] = trial_vector\n\n                # Dynamically adjust mutation and crossover rates\n                self.mutation_factor = 0.5 + 0.3 * (self.best_fitness / trial_fitness) * (1 - self.eval_count / self.budget)\n                self.crossover_rate = 0.9 - 0.4 * (self.best_fitness / trial_fitness)\n\n        return self.best_solution, self.best_fitness\n\n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        self.population = self.bounds[0] + (self.bounds[1] - self.bounds[0]) * np.random.rand(self.population_size, self.dim)\n        return self.optimize(func)", "name": "AdaptiveDE", "description": "Introduce a self-adaptive strategy for mutation factor to gradually enhance exploration during optimization.", "configspace": "", "generation": 1, "fitness": 0.7567305317480821, "feedback": "The algorithm AdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.757 with standard deviation 0.013. And the mean value of best solutions found was 0.172 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "231098ec-facc-43d8-8545-ca7b9bbabccc", "metadata": {"aucs": [0.7752127208695133, 0.751254480238861, 0.7437243941358722], "final_y": [0.16524602120879872, 0.1751788628636538, 0.17484225132350684]}, "mutation_prompt": null}
{"id": "605864ce-1be6-427a-97d6-0bc52b49f27b", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.0  # cognitive component\n        self.c2 = 2.0  # social component\n        self.w = 0.7   # inertia weight\n        self.f = 0.8   # differential weight\n        self.cr = 0.9  # crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        \n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Particle Swarm Optimization (PSO) update\n                r1, r2 = np.random.rand(), np.random.rand()\n                self.w = 0.9 - 0.5 * (evaluations / self.budget)  # Dynamic inertia weight\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i] if global_best_position is not None else 0))\n\n                candidate_position = np.clip(population[i] + velocities[i], lb, ub)\n                candidate_score = func(candidate_position)\n                evaluations += 1\n\n                # Update personal best\n                if candidate_score < personal_best_scores[i]:\n                    personal_best_scores[i] = candidate_score\n                    personal_best_positions[i] = candidate_position\n\n                # Update global best\n                if candidate_score < global_best_score:\n                    global_best_score = candidate_score\n                    global_best_position = candidate_position\n\n            # Differential Evolution (DE) mutation and crossover\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                mutant_vector = np.clip(personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c]), lb, ub)\n                \n                trial_vector = np.copy(personal_best_positions[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == jrand:\n                        trial_vector[j] = mutant_vector[j]\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                # Selection\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Improves convergence by using a dynamic inertia weight, which decreases linearly over iterations.", "configspace": "", "generation": 1, "fitness": 0.8228555079529615, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.823 with standard deviation 0.030. And the mean value of best solutions found was 0.139 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "507e0262-db3f-4b42-9fd5-7d700d783b47", "metadata": {"aucs": [0.7855071589183157, 0.8577882713035624, 0.8252710936370062], "final_y": [0.1428897787268556, 0.1299230903035533, 0.14371219924698575]}, "mutation_prompt": null}
{"id": "32c052b5-1153-4394-be75-405f724f8ff9", "solution": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.population = np.random.rand(self.population_size, self.dim)\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.5\n\n    def select_parents(self, idx):\n        indices = list(range(self.population_size))\n        indices.remove(idx)\n        np.random.shuffle(indices)\n        return indices[:3]\n\n    def mutate(self, idx):\n        a, b, c = self.select_parents(idx)\n        mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n        lower_bound, upper_bound = self.bounds\n        return np.clip(mutant_vector, lower_bound, upper_bound)\n\n    def crossover(self, target, mutant):\n        crossover_vector = np.copy(target)\n        for i in range(self.dim):\n            if np.random.rand() < self.crossover_rate or i == np.random.randint(self.dim):\n                crossover_vector[i] = mutant[i]\n        return crossover_vector\n\n    def optimize(self, func):\n        while self.eval_count < self.budget:\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                target_vector = self.population[i]\n                mutant_vector = self.mutate(i)\n                trial_vector = self.crossover(target_vector, mutant_vector)\n                trial_fitness = func(trial_vector)\n                self.eval_count += 1\n\n                if trial_fitness < self.best_fitness:\n                    self.best_fitness = trial_fitness\n                    self.best_solution = trial_vector\n\n                if trial_fitness < func(target_vector):\n                    self.population[i] = trial_vector\n\n                # Dynamically adjust mutation and crossover rates\n                self.mutation_factor = 0.5 + 0.3 * (self.best_fitness / (trial_fitness + 1e-6))\n                self.crossover_rate = 0.9 - 0.4 * (self.best_fitness / (trial_fitness + 1e-6))\n\n        return self.best_solution, self.best_fitness\n\n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        self.population = self.bounds[0] + (self.bounds[1] - self.bounds[0]) * np.random.rand(self.population_size, self.dim)\n        return self.optimize(func)", "name": "AdaptiveDE", "description": "An improved adaptive differential evolution algorithm with an enhanced dynamic adjustment factor for mutation and crossover rates based on search progress.", "configspace": "", "generation": 1, "fitness": 0.7681789480076864, "feedback": "The algorithm AdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.768 with standard deviation 0.005. And the mean value of best solutions found was 0.157 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "231098ec-facc-43d8-8545-ca7b9bbabccc", "metadata": {"aucs": [0.77487372859384, 0.7672322100705716, 0.7624309053586473], "final_y": [0.16443092203397902, 0.16629644672432087, 0.14112093890811628]}, "mutation_prompt": null}
{"id": "4844d7c8-2326-43fb-a96f-d2d4884ea48c", "solution": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.population = np.random.rand(self.population_size, self.dim)\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.5\n\n    def select_parents(self, idx):\n        indices = list(range(self.population_size))\n        indices.remove(idx)\n        np.random.shuffle(indices)\n        return indices[:3]\n\n    def mutate(self, idx):\n        a, b, c = self.select_parents(idx)\n        mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n        lower_bound, upper_bound = self.bounds\n        return np.clip(mutant_vector, lower_bound, upper_bound)\n\n    def crossover(self, target, mutant):\n        crossover_vector = np.copy(target)\n        for i in range(self.dim):\n            if np.random.rand() < self.crossover_rate or i == np.random.randint(self.dim):\n                crossover_vector[i] = mutant[i]\n        return crossover_vector\n\n    def optimize(self, func):\n        while self.eval_count < self.budget:\n            if self.eval_count % (self.budget // 10) == 0:\n                self.population_size = int(self.population_size * 0.9) + 1\n                self.population = self.population[:self.population_size, :]\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                target_vector = self.population[i]\n                mutant_vector = self.mutate(i)\n                trial_vector = self.crossover(target_vector, mutant_vector)\n                trial_fitness = func(trial_vector)\n                self.eval_count += 1\n\n                if trial_fitness < self.best_fitness:\n                    self.best_fitness = trial_fitness\n                    self.best_solution = trial_vector\n\n                if trial_fitness < func(target_vector):\n                    self.population[i] = trial_vector\n\n                diversity = np.std(self.population)\n                self.mutation_factor = 0.5 + 0.3 * (1 - diversity / self.dim)\n                self.crossover_rate = 0.9 - 0.4 * (self.best_fitness / trial_fitness)\n\n        return self.best_solution, self.best_fitness\n\n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        self.population = self.bounds[0] + (self.bounds[1] - self.bounds[0]) * np.random.rand(self.population_size, self.dim)\n        return self.optimize(func)", "name": "AdaptiveDE", "description": "Enhance AdaptiveDE by introducing a dynamic population size and adaptive scaling of mutation factors based on convergence and diversity metrics.", "configspace": "", "generation": 1, "fitness": 0.7668405106990174, "feedback": "The algorithm AdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.767 with standard deviation 0.015. And the mean value of best solutions found was 0.159 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "231098ec-facc-43d8-8545-ca7b9bbabccc", "metadata": {"aucs": [0.787404842766352, 0.7541892766852845, 0.7589274126454156], "final_y": [0.15526772488852603, 0.16990401948221445, 0.1509348710986348]}, "mutation_prompt": null}
{"id": "43ae116a-f413-4319-8297-20eb253de312", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.0  # cognitive component\n        self.c2 = 2.0  # social component\n        self.w_initial = 0.9  # initial inertia weight\n        self.w_final = 0.4    # final inertia weight\n        self.f = 0.8   # differential weight\n        self.cr = 0.9  # crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        \n        while evaluations < self.budget:\n            # Adaptive inertia weight calculation\n            self.w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Particle Swarm Optimization (PSO) update\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i] if global_best_position is not None else 0))\n\n                candidate_position = np.clip(population[i] + velocities[i], lb, ub)\n                candidate_score = func(candidate_position)\n                evaluations += 1\n\n                # Update personal best\n                if candidate_score < personal_best_scores[i]:\n                    personal_best_scores[i] = candidate_score\n                    personal_best_positions[i] = candidate_position\n\n                # Update global best\n                if candidate_score < global_best_score:\n                    global_best_score = candidate_score\n                    global_best_position = candidate_position\n\n            # Differential Evolution (DE) mutation and crossover\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                mutant_vector = np.clip(personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c]), lb, ub)\n                \n                trial_vector = np.copy(personal_best_positions[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == jrand:\n                        trial_vector[j] = mutant_vector[j]\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                # Selection\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A refined HybridPSODE algorithm with adaptive inertia weight for improved convergence in black-box optimization.", "configspace": "", "generation": 1, "fitness": 0.8294882611618113, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.829 with standard deviation 0.004. And the mean value of best solutions found was 0.143 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "507e0262-db3f-4b42-9fd5-7d700d783b47", "metadata": {"aucs": [0.8249102932793411, 0.8299204137702539, 0.8336340764358389], "final_y": [0.14112194563795633, 0.14459193114530033, 0.14312380398046598]}, "mutation_prompt": null}
{"id": "48c57513-87d6-4662-a4b9-2a96a0931f4d", "solution": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.population = np.random.rand(self.population_size, self.dim)\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.5\n\n    def select_parents(self, idx):\n        indices = list(range(self.population_size))\n        indices.remove(idx)\n        np.random.shuffle(indices)\n        return indices[:3]\n\n    def mutate(self, idx):\n        a, b, c = self.select_parents(idx)\n        mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n        lower_bound, upper_bound = self.bounds\n        return np.clip(mutant_vector, lower_bound, upper_bound)\n\n    def crossover(self, target, mutant):\n        crossover_vector = np.copy(target)\n        for i in range(self.dim):\n            if np.random.rand() < self.crossover_rate or i == np.random.randint(self.dim):\n                crossover_vector[i] = mutant[i]\n        return crossover_vector\n\n    def optimize(self, func):\n        while self.eval_count < self.budget:\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                target_vector = self.population[i]\n                mutant_vector = self.mutate(i)\n                trial_vector = self.crossover(target_vector, mutant_vector)\n                trial_fitness = func(trial_vector)\n                self.eval_count += 1\n\n                if trial_fitness < self.best_fitness:\n                    self.best_fitness = trial_fitness\n                    self.best_solution = trial_vector\n\n                if trial_fitness < func(target_vector):\n                    self.population[i] = trial_vector\n\n                # Dynamically adjust mutation and crossover rates\n                self.mutation_factor = 0.6 + 0.3 * (self.best_fitness / trial_fitness)  # Changed line\n                self.crossover_rate = 0.9 - 0.4 * (self.best_fitness / trial_fitness)\n\n        return self.best_solution, self.best_fitness\n\n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        self.population = self.bounds[0] + (self.bounds[1] - self.bounds[0]) * np.random.rand(self.population_size, self.dim)\n        return self.optimize(func)", "name": "AdaptiveDE", "description": "Improved adaptive differential evolution with enhanced mutation factor scaling for increased exploration and exploitation balance.", "configspace": "", "generation": 1, "fitness": 0.7702427585719275, "feedback": "The algorithm AdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.770 with standard deviation 0.009. And the mean value of best solutions found was 0.163 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "231098ec-facc-43d8-8545-ca7b9bbabccc", "metadata": {"aucs": [0.7818968874413859, 0.7588263798075272, 0.7700050084668691], "final_y": [0.161407057686198, 0.16133976956947083, 0.16635382552222444]}, "mutation_prompt": null}
{"id": "622c01ea-3d18-4992-8229-f2319d4b0b29", "solution": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.population = np.random.rand(self.population_size, self.dim)\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.eval_count = 0\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.5\n\n    def select_parents(self, idx):\n        indices = list(range(self.population_size))\n        indices.remove(idx)\n        np.random.shuffle(indices)\n        return indices[:3]\n\n    def mutate(self, idx):\n        a, b, c = self.select_parents(idx)\n        mutant_vector = self.population[a] + self.mutation_factor * (self.population[b] - self.population[c])\n        lower_bound, upper_bound = self.bounds\n        return np.clip(mutant_vector, lower_bound, upper_bound)\n\n    def crossover(self, target, mutant):\n        crossover_vector = np.copy(target)\n        for i in range(self.dim):\n            if np.random.rand() < self.crossover_rate or i == np.random.randint(self.dim):\n                crossover_vector[i] = mutant[i]\n        return crossover_vector\n\n    def optimize(self, func):\n        while self.eval_count < self.budget:\n            for i in range(self.population_size):\n                if self.eval_count >= self.budget:\n                    break\n                target_vector = self.population[i]\n                mutant_vector = self.mutate(i)\n                trial_vector = self.crossover(target_vector, mutant_vector)\n                trial_fitness = func(trial_vector)\n                self.eval_count += 1\n\n                if trial_fitness < self.best_fitness:\n                    self.best_fitness = trial_fitness\n                    self.best_solution = trial_vector\n\n                if trial_fitness < func(target_vector):\n                    self.population[i] = trial_vector\n\n                # Dynamically adjust mutation and crossover rates\n                self.mutation_factor = 0.5 + 0.3 * (self.best_fitness / (trial_fitness + 1e-8))\n                self.crossover_rate = 0.9 - 0.4 * (self.best_fitness / trial_fitness)\n\n        return self.best_solution, self.best_fitness\n\n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        self.population = self.bounds[0] + (self.bounds[1] - self.bounds[0]) * np.random.rand(self.population_size, self.dim)\n        return self.optimize(func)", "name": "AdaptiveDE", "description": "A subtly refined adaptive differential evolution algorithm that adjusts mutation and crossover dynamics with a minor enhancement for better search precision.", "configspace": "", "generation": 1, "fitness": 0.7795586655074603, "feedback": "The algorithm AdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.780 with standard deviation 0.013. And the mean value of best solutions found was 0.160 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "231098ec-facc-43d8-8545-ca7b9bbabccc", "metadata": {"aucs": [0.7923986991936799, 0.7609251335937316, 0.7853521637349694], "final_y": [0.15497054830948076, 0.16869203102539698, 0.1559307420943643]}, "mutation_prompt": null}
{"id": "5db95710-ab0b-41d1-91f6-25ec945d444c", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.0  # cognitive component\n        self.c2 = 2.0  # social component\n        self.w = 0.9   # increased inertia weight for improved exploration\n        self.f = 0.8   # differential weight\n        self.cr = 0.9  # crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        \n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Particle Swarm Optimization (PSO) update\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i] if global_best_position is not None else 0))\n\n                candidate_position = np.clip(population[i] + velocities[i], lb, ub)\n                candidate_score = func(candidate_position)\n                evaluations += 1\n\n                # Update personal best\n                if candidate_score < personal_best_scores[i]:\n                    personal_best_scores[i] = candidate_score\n                    personal_best_positions[i] = candidate_position\n\n                # Update global best\n                if candidate_score < global_best_score:\n                    global_best_score = candidate_score\n                    global_best_position = candidate_position\n\n            # Differential Evolution (DE) mutation and crossover\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                diversity_factor = np.std(personal_best_positions, axis=0)  # new line for diversity-based mutation\n                mutant_vector = np.clip(personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c]) * diversity_factor, lb, ub)\n                \n                trial_vector = np.copy(personal_best_positions[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == jrand:\n                        trial_vector[j] = mutant_vector[j]\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                # Selection\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "An enhanced HybridPSODE algorithm that incorporates adaptive inertia weight and diversity-based mutation strategies to boost exploration-exploitation balance for black-box optimization problems.", "configspace": "", "generation": 1, "fitness": 0.8287760073357218, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.829 with standard deviation 0.039. And the mean value of best solutions found was 0.144 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "507e0262-db3f-4b42-9fd5-7d700d783b47", "metadata": {"aucs": [0.7812823149193767, 0.8767813806832612, 0.8282643264045271], "final_y": [0.16360177990432268, 0.13178468105043228, 0.13675799608903305]}, "mutation_prompt": null}
{"id": "79b1205d-acb5-4be2-a32e-5d10d96b6063", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.0  # cognitive component\n        self.c2 = 2.0  # social component\n        self.w_initial = 0.9  # initial inertia weight\n        self.w_final = 0.4    # final inertia weight\n        self.f = 0.9   # differential weight\n        self.cr = 0.9  # crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        \n        while evaluations < self.budget:\n            # Adaptive inertia weight calculation\n            self.w = self.w_initial - (self.w_initial - self.w_final) * (np.random.rand())\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Particle Swarm Optimization (PSO) update\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i] if global_best_position is not None else 0))\n\n                candidate_position = np.clip(population[i] + velocities[i], lb, ub)\n                candidate_score = func(candidate_position)\n                evaluations += 1\n\n                # Update personal best\n                if candidate_score < personal_best_scores[i]:\n                    personal_best_scores[i] = candidate_score\n                    personal_best_positions[i] = candidate_position\n\n                # Update global best\n                if candidate_score < global_best_score:\n                    global_best_score = candidate_score\n                    global_best_position = candidate_position\n\n            # Differential Evolution (DE) mutation and crossover\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                mutant_vector = np.clip(personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c]), lb, ub)\n                \n                trial_vector = np.copy(personal_best_positions[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == jrand:\n                        trial_vector[j] = mutant_vector[j]\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                # Selection\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Improved HybridPSODE by adjusting differential weight and using random inertia weight for better balance between exploration and exploitation.", "configspace": "", "generation": 2, "fitness": 0.8141302727109446, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.814 with standard deviation 0.032. And the mean value of best solutions found was 0.150 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "43ae116a-f413-4319-8297-20eb253de312", "metadata": {"aucs": [0.7692019441178275, 0.8387760325973082, 0.8344128414176981], "final_y": [0.1686684185589059, 0.14248342114603363, 0.13973909050204103]}, "mutation_prompt": null}
{"id": "af1a77e0-fedd-49dd-8ece-36b94336eac3", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(50 - 45 * (budget / 10000)))  # dynamic swarm size based on budget\n        self.c1 = 2.0  # cognitive component\n        self.c2 = 2.0  # social component\n        self.w = 0.9   # increased inertia weight for improved exploration\n        self.f = 0.8   # differential weight\n        self.cr = 0.9  # crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        \n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Particle Swarm Optimization (PSO) update\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i] if global_best_position is not None else 0))\n\n                candidate_position = np.clip(population[i] + velocities[i], lb, ub)\n                candidate_score = func(candidate_position)\n                evaluations += 1\n\n                # Update personal best\n                if candidate_score < personal_best_scores[i]:\n                    personal_best_scores[i] = candidate_score\n                    personal_best_positions[i] = candidate_position\n\n                # Update global best\n                if candidate_score < global_best_score:\n                    global_best_score = candidate_score\n                    global_best_position = candidate_position\n\n            # Differential Evolution (DE) mutation and crossover\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                diversity_factor = np.std(personal_best_positions, axis=0)  # new line for diversity-based mutation\n                mutant_vector = np.clip(personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c]) * diversity_factor, lb, ub)\n                \n                trial_vector = np.copy(personal_best_positions[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == jrand:\n                        trial_vector[j] = mutant_vector[j]\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                # Selection\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A refined HybridPSODE algorithm with dynamic swarm size for enhanced efficiency in black-box optimization.", "configspace": "", "generation": 2, "fitness": 0.8085703266831669, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.809 with standard deviation 0.044. And the mean value of best solutions found was 0.153 (0. is the best) with standard deviation 0.015.", "error": "", "parent_id": "5db95710-ab0b-41d1-91f6-25ec945d444c", "metadata": {"aucs": [0.7470295189026688, 0.84418204688092, 0.8344994142659117], "final_y": [0.17307567405347113, 0.1401972415064635, 0.1448528166642733]}, "mutation_prompt": null}
{"id": "97bfe40e-29cf-4b0f-bec4-6029aa83593b", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.0  # cognitive component\n        self.c2 = 2.0  # social component\n        self.w_initial = 0.9  # initial inertia weight\n        self.w_final = 0.4    # final inertia weight\n        self.f = 0.8   # differential weight\n        self.cr = 0.9  # crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        \n        while evaluations < self.budget:\n            # Adaptive inertia weight calculation\n            self.w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Particle Swarm Optimization (PSO) update\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i] if global_best_position is not None else 0))\n\n                candidate_position = np.clip(population[i] + velocities[i], lb, ub)\n                candidate_score = func(candidate_position)\n                evaluations += 1\n\n                # Update personal best\n                if candidate_score < personal_best_scores[i]:\n                    personal_best_scores[i] = candidate_score\n                    personal_best_positions[i] = candidate_position\n\n                # Update global best\n                if candidate_score < global_best_score:\n                    global_best_score = candidate_score\n                    global_best_position = candidate_position\n\n            # Differential Evolution (DE) mutation and crossover\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                # Adaptive mutation strategy with dynamic differential weight\n                adaptive_f = self.f * (1 - evaluations / self.budget)\n                mutant_vector = np.clip(personal_best_positions[a] + adaptive_f * (personal_best_positions[b] - personal_best_positions[c]), lb, ub)\n                \n                trial_vector = np.copy(personal_best_positions[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == jrand:\n                        trial_vector[j] = mutant_vector[j]\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                # Selection\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Refined HybridPSODE algorithm with adaptive mutation strategy enhancing exploration capability in black-box optimization.", "configspace": "", "generation": 2, "fitness": 0.8109593619048926, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.811 with standard deviation 0.028. And the mean value of best solutions found was 0.145 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "43ae116a-f413-4319-8297-20eb253de312", "metadata": {"aucs": [0.7879536115500646, 0.7944095320298756, 0.8505149421347374], "final_y": [0.14282085227831431, 0.15558936369421894, 0.13788298427372303]}, "mutation_prompt": null}
{"id": "80facfad-8844-457f-80a9-49c3533751f2", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.0  # cognitive component\n        self.c2 = 2.0  # social component\n        self.w_initial = 0.9  # initial inertia weight\n        self.w_final = 0.4    # final inertia weight\n        self.f = 0.8   # differential weight\n        self.cr = 0.9  # crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        \n        while evaluations < self.budget:\n            # Adaptive inertia weight calculation\n            self.w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Particle Swarm Optimization (PSO) update\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i] if global_best_position is not None else 0))\n\n                candidate_position = np.clip(population[i] + velocities[i], lb, ub)\n                candidate_score = func(candidate_position)\n                evaluations += 1\n\n                # Update personal best\n                if candidate_score < personal_best_scores[i]:\n                    personal_best_scores[i] = candidate_score\n                    personal_best_positions[i] = candidate_position\n\n                # Update global best\n                if candidate_score < global_best_score:\n                    global_best_score = candidate_score\n                    global_best_position = candidate_position\n\n            # Differential Evolution (DE) mutation and crossover\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                self.f = 0.5 + 0.3 * np.random.rand()  # modified line for adaptive differential weight\n\n                mutant_vector = np.clip(personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c]), lb, ub)\n                \n                trial_vector = np.copy(personal_best_positions[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == jrand:\n                        trial_vector[j] = mutant_vector[j]\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                # Selection\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A refined HybridPSODE algorithm with adaptive parameter adjustment for improved convergence in black-box optimization.", "configspace": "", "generation": 2, "fitness": 0.8233734009725465, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.823 with standard deviation 0.056. And the mean value of best solutions found was 0.144 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "43ae116a-f413-4319-8297-20eb253de312", "metadata": {"aucs": [0.7458934891115023, 0.8730666914091307, 0.8511600223970064], "final_y": [0.16405011691931515, 0.13218123040405771, 0.13485351085705166]}, "mutation_prompt": null}
{"id": "4327906e-a39f-42eb-bf4c-e02d3c36a186", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.0  # cognitive component\n        self.c2 = 2.0  # social component\n        self.w = 0.9   # increased inertia weight for improved exploration\n        self.f = 0.8   # differential weight\n        self.cr = 0.9  # crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        \n        while evaluations < self.budget:\n            if evaluations % 100 == 0 and self.population_size > 10:  # Dynamic population adjustment\n                self.population_size -= 1  # Reduce population size to refine search\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Particle Swarm Optimization (PSO) update\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i] if global_best_position is not None else 0))\n\n                candidate_position = np.clip(population[i] + velocities[i], lb, ub)\n                candidate_score = func(candidate_position)\n                evaluations += 1\n\n                # Update personal best\n                if candidate_score < personal_best_scores[i]:\n                    personal_best_scores[i] = candidate_score\n                    personal_best_positions[i] = candidate_position\n\n                # Update global best\n                if candidate_score < global_best_score:\n                    global_best_score = candidate_score\n                    global_best_position = candidate_position\n\n            # Differential Evolution (DE) mutation and crossover\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                diversity_factor = np.std(personal_best_positions, axis=0)  # new line for diversity-based mutation\n                mutant_vector = np.clip(personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c]) * diversity_factor, lb, ub)\n                \n                trial_vector = np.copy(personal_best_positions[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == jrand:\n                        trial_vector[j] = mutant_vector[j]\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                # Selection\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A refined HybridPSODE algorithm that incorporates dynamic population size adjustment for enhanced adaptability in black-box optimization.", "configspace": "", "generation": 2, "fitness": 0.7929329569119878, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.793 with standard deviation 0.035. And the mean value of best solutions found was 0.154 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "5db95710-ab0b-41d1-91f6-25ec945d444c", "metadata": {"aucs": [0.7430222393851696, 0.8192540473031352, 0.8165225840476585], "final_y": [0.1713102151461009, 0.14551148777961143, 0.14594490102183155]}, "mutation_prompt": null}
{"id": "6f637d28-7a64-4b67-95bb-170e396da988", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.0  # cognitive component\n        self.c2 = 2.0  # social component\n        self.w = 0.9   # increased inertia weight for improved exploration\n        self.f = 0.8   # differential weight\n        self.cr = 0.9  # crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        \n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Particle Swarm Optimization (PSO) update\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i] if global_best_position is not None else 0))\n\n                candidate_position = np.clip(population[i] + velocities[i], lb, ub)\n                candidate_score = func(candidate_position)\n                evaluations += 1\n\n                # Update personal best\n                if candidate_score < personal_best_scores[i]:\n                    personal_best_scores[i] = candidate_score\n                    personal_best_positions[i] = candidate_position\n\n                # Update global best\n                if candidate_score < global_best_score:\n                    global_best_score = candidate_score\n                    global_best_position = candidate_position\n\n            # Differential Evolution (DE) mutation and crossover\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                diversity_factor = np.std(personal_best_positions, axis=0) + 1e-8  # slightly modified for stability\n                mutant_vector = np.clip(personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c]) * diversity_factor, lb, ub)\n                \n                trial_vector = np.copy(personal_best_positions[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == jrand:\n                        trial_vector[j] = mutant_vector[j]\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                # Selection\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A refined HybridPSODE algorithm with adaptive inertia weight and enhanced diversity-based mutation strategies to optimize black-box functions.", "configspace": "", "generation": 2, "fitness": 0.8148321012619536, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.815 with standard deviation 0.064. And the mean value of best solutions found was 0.150 (0. is the best) with standard deviation 0.021.", "error": "", "parent_id": "5db95710-ab0b-41d1-91f6-25ec945d444c", "metadata": {"aucs": [0.7288507209027493, 0.8807872758557537, 0.8348583070273579], "final_y": [0.17962430840729238, 0.1285655172526705, 0.14321935451466983]}, "mutation_prompt": null}
{"id": "83ddaccf-a9d0-4b26-8555-84b2ad30349d", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.0  # cognitive component\n        self.c2 = 2.0  # social component\n        self.w_initial = 0.9  # initial inertia weight\n        self.w_final = 0.4    # final inertia weight\n        self.f = 0.8   # differential weight\n        self.cr = 0.9  # crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        \n        while evaluations < self.budget:\n            # Adaptive inertia weight calculation\n            self.w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Particle Swarm Optimization (PSO) update\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i] if global_best_position is not None else 0))\n\n                if np.random.rand() < 0.1:  # Stochastic velocity reset\n                    velocities[i] = np.random.uniform(-1, 1, self.dim)\n                \n                candidate_position = np.clip(population[i] + velocities[i], lb, ub)\n                candidate_score = func(candidate_position)\n                evaluations += 1\n\n                # Update personal best\n                if candidate_score < personal_best_scores[i]:\n                    personal_best_scores[i] = candidate_score\n                    personal_best_positions[i] = candidate_position\n\n                # Update global best\n                if candidate_score < global_best_score:\n                    global_best_score = candidate_score\n                    global_best_position = candidate_position\n\n            # Differential Evolution (DE) mutation and crossover\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                mutant_vector = np.clip(personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c]), lb, ub)\n                \n                trial_vector = np.copy(personal_best_positions[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == jrand:\n                        trial_vector[j] = mutant_vector[j]\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                # Selection\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Refined HybridPSODE with adaptive particle neighborhood and improved exploration using stochastic velocity reset.", "configspace": "", "generation": 2, "fitness": 0.8286647626758109, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.829 with standard deviation 0.016. And the mean value of best solutions found was 0.139 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "43ae116a-f413-4319-8297-20eb253de312", "metadata": {"aucs": [0.8084036080145516, 0.8291996236702142, 0.8483910563426672], "final_y": [0.13826327501356872, 0.1454097837934133, 0.13274488293550835]}, "mutation_prompt": null}
{"id": "3003bfaa-4a7e-42a9-8f0e-78d5a697f872", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.0  # cognitive component\n        self.c2 = 2.0  # social component\n        self.w = 0.9   # increased inertia weight for improved exploration\n        self.f = 0.8   # differential weight\n        self.cr = 0.9  # crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        \n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Particle Swarm Optimization (PSO) update\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i] if global_best_position is not None else 0))\n\n                # Implementing adaptive velocity clamping\n                velocities[i] = np.clip(velocities[i], -np.abs(ub - lb) * 0.1, np.abs(ub - lb) * 0.1)\n\n                candidate_position = np.clip(population[i] + velocities[i], lb, ub)\n                candidate_score = func(candidate_position)\n                evaluations += 1\n\n                # Update personal best\n                if candidate_score < personal_best_scores[i]:\n                    personal_best_scores[i] = candidate_score\n                    personal_best_positions[i] = candidate_position\n\n                # Update global best\n                if candidate_score < global_best_score:\n                    global_best_score = candidate_score\n                    global_best_position = candidate_position\n\n            # Differential Evolution (DE) mutation and crossover\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                diversity_factor = np.std(personal_best_positions, axis=0)  # new line for diversity-based mutation\n                mutant_vector = np.clip(personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c]) * diversity_factor, lb, ub)\n                \n                trial_vector = np.copy(personal_best_positions[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == jrand:\n                        trial_vector[j] = mutant_vector[j]\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                # Selection\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A refined HybridPSODE algorithm with adaptive velocity clamping to enhance global convergence in black-box optimization tasks.", "configspace": "", "generation": 2, "fitness": 0.7987559212511659, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.799 with standard deviation 0.037. And the mean value of best solutions found was 0.151 (0. is the best) with standard deviation 0.020.", "error": "", "parent_id": "5db95710-ab0b-41d1-91f6-25ec945d444c", "metadata": {"aucs": [0.7485915252875026, 0.81262583534025, 0.8350504031257451], "final_y": [0.17785129213129214, 0.14475807311195843, 0.1295831639556415]}, "mutation_prompt": null}
{"id": "87ea08f7-ce55-47aa-bc31-212ae3d3e20e", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.0  # cognitive component\n        self.c2 = 2.0  # social component\n        self.w = 0.9   # increased inertia weight for improved exploration\n        self.f = 0.8   # differential weight\n        self.cr = 0.9  # crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        \n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Particle Swarm Optimization (PSO) update\n                r1, r2 = np.random.rand(), np.random.rand()\n                self.w = 0.5 + 0.4 * np.cos(np.pi * evaluations / self.budget)  # dynamic inertia weight update\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i] if global_best_position is not None else 0))\n\n                candidate_position = np.clip(population[i] + velocities[i], lb, ub)\n                candidate_score = func(candidate_position)\n                evaluations += 1\n\n                # Update personal best\n                if candidate_score < personal_best_scores[i]:\n                    personal_best_scores[i] = candidate_score\n                    personal_best_positions[i] = candidate_position\n\n                # Update global best\n                if candidate_score < global_best_score:\n                    global_best_score = candidate_score\n                    global_best_position = candidate_position\n\n            # Differential Evolution (DE) mutation and crossover\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                diversity_factor = np.std(personal_best_positions, axis=0)  # new line for diversity-based mutation\n                mutant_vector = np.clip(personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c]) * diversity_factor, lb, ub)\n                \n                trial_vector = np.copy(personal_best_positions[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == jrand:\n                        trial_vector[j] = mutant_vector[j]\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                # Selection\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A refined HybridPSODE algorithm with dynamic adaptive inertia weight using cosine function for enhanced optimization.", "configspace": "", "generation": 2, "fitness": 0.8036031641557654, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.804 with standard deviation 0.033. And the mean value of best solutions found was 0.149 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "5db95710-ab0b-41d1-91f6-25ec945d444c", "metadata": {"aucs": [0.774327515291032, 0.7863190474009218, 0.8501629297753424], "final_y": [0.1631374813325971, 0.15205578962525745, 0.1311350751727417]}, "mutation_prompt": null}
{"id": "4853edb5-34e0-4f5c-9d24-53a324b5ed8e", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.0  # cognitive component\n        self.c2 = 2.0  # social component\n        self.w = 0.9   # increased inertia weight for improved exploration\n        self.f = 0.8   # differential weight\n        self.cr = 0.9  # crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        \n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Particle Swarm Optimization (PSO) update\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i] if global_best_position is not None else 0))\n\n                # Dynamic velocity scaling\n                velocities[i] = velocities[i] * (1 - evaluations / self.budget)  # Updated line\n\n                candidate_position = np.clip(population[i] + velocities[i], lb, ub)\n                candidate_score = func(candidate_position)\n                evaluations += 1\n\n                # Update personal best\n                if candidate_score < personal_best_scores[i]:\n                    personal_best_scores[i] = candidate_score\n                    personal_best_positions[i] = candidate_position\n\n                # Update global best\n                if candidate_score < global_best_score:\n                    global_best_score = candidate_score\n                    global_best_position = candidate_position\n\n            # Differential Evolution (DE) mutation and crossover\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                diversity_factor = np.std(personal_best_positions, axis=0)  # new line for diversity-based mutation\n                mutant_vector = np.clip(personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c]) * diversity_factor, lb, ub)\n                \n                trial_vector = np.copy(personal_best_positions[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == jrand:\n                        trial_vector[j] = mutant_vector[j]\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                # Selection\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Optimized HybridPSODE with improved adaptive inertia weight using dynamic velocity scaling for enhanced performance in black-box optimization.", "configspace": "", "generation": 2, "fitness": 0.8048306819610586, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.805 with standard deviation 0.027. And the mean value of best solutions found was 0.150 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "5db95710-ab0b-41d1-91f6-25ec945d444c", "metadata": {"aucs": [0.7762294565034088, 0.7972624842504928, 0.841000105129274], "final_y": [0.16524957817462294, 0.1446884760435051, 0.14055265347283363]}, "mutation_prompt": null}
{"id": "c0134e24-199d-4097-9bfa-73357e83fce3", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.0  # cognitive component\n        self.c2 = 2.0  # social component\n        self.w_initial = 0.9  # initial inertia weight\n        self.w_final = 0.4    # final inertia weight\n        self.f = 0.8   # differential weight\n        self.cr = 0.9  # crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        \n        while evaluations < self.budget:\n            # Adaptive inertia weight calculation\n            self.w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Particle Swarm Optimization (PSO) update\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i] if global_best_position is not None else 0))\n\n                if np.random.rand() < (0.1 + (0.4 * evaluations / self.budget)):  # Adaptive stochastic velocity reset\n                    velocities[i] = np.random.uniform(-1, 1, self.dim)\n                \n                candidate_position = np.clip(population[i] + velocities[i], lb, ub)\n                candidate_score = func(candidate_position)\n                evaluations += 1\n\n                # Update personal best\n                if candidate_score < personal_best_scores[i]:\n                    personal_best_scores[i] = candidate_score\n                    personal_best_positions[i] = candidate_position\n\n                # Update global best\n                if candidate_score < global_best_score:\n                    global_best_score = candidate_score\n                    global_best_position = candidate_position\n\n            # Differential Evolution (DE) mutation and crossover\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                mutant_vector = np.clip(personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c]), lb, ub)\n                \n                trial_vector = np.copy(personal_best_positions[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == jrand:\n                        trial_vector[j] = mutant_vector[j]\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                # Selection\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Enhanced HybridPSODE with adaptive stochastic velocity reset probability for improved exploration-exploitation balance.", "configspace": "", "generation": 3, "fitness": 0.8232857880197949, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.823 with standard deviation 0.022. And the mean value of best solutions found was 0.135 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "83ddaccf-a9d0-4b26-8555-84b2ad30349d", "metadata": {"aucs": [0.8281213006535012, 0.7948236433317928, 0.8469124200740907], "final_y": [0.13582535506056936, 0.1447580705046897, 0.12480359362327786]}, "mutation_prompt": null}
{"id": "da696acb-10f8-404b-a4b1-4837c232b0ad", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.0  # cognitive component\n        self.c2 = 2.0  # social component\n        self.w_initial = 0.9  # initial inertia weight\n        self.w_final = 0.4    # final inertia weight\n        self.f_initial = 0.7  # initial differential weight\n        self.f_final = 0.9    # final differential weight\n        self.cr_initial = 0.9 # initial crossover probability\n        self.cr_final = 0.6   # final crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        \n        while evaluations < self.budget:\n            # Adaptive inertia weight calculation\n            self.w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            self.f = self.f_initial + (self.f_final - self.f_initial) * (evaluations / self.budget)\n            self.cr = self.cr_initial - (self.cr_initial - self.cr_final) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Particle Swarm Optimization (PSO) update\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i] if global_best_position is not None else 0))\n\n                if np.random.rand() < 0.1:  # Stochastic velocity reset\n                    velocities[i] = np.random.uniform(-1, 1, self.dim)\n                \n                candidate_position = np.clip(population[i] + velocities[i], lb, ub)\n                candidate_score = func(candidate_position)\n                evaluations += 1\n\n                # Update personal best\n                if candidate_score < personal_best_scores[i]:\n                    personal_best_scores[i] = candidate_score\n                    personal_best_positions[i] = candidate_position\n\n                # Update global best\n                if candidate_score < global_best_score:\n                    global_best_score = candidate_score\n                    global_best_position = candidate_position\n\n            # Differential Evolution (DE) mutation and crossover\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                mutant_vector = np.clip(personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c]), lb, ub)\n                \n                trial_vector = np.copy(personal_best_positions[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == jrand:\n                        trial_vector[j] = mutant_vector[j]\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                # Selection\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Enhanced HybridPSODE with dynamic crossover rate and adaptive differential weight strategy for improved exploration-exploitation balance.", "configspace": "", "generation": 3, "fitness": 0.8397264621007249, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.840 with standard deviation 0.050. And the mean value of best solutions found was 0.136 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "83ddaccf-a9d0-4b26-8555-84b2ad30349d", "metadata": {"aucs": [0.7691109849833037, 0.8802273601170612, 0.8698410412018098], "final_y": [0.1559288131759773, 0.12298059655772398, 0.12889545215435072]}, "mutation_prompt": null}
{"id": "c595bca5-e120-4db2-8cf2-50c6a4dfc798", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.0  # cognitive component\n        self.c2 = 2.0  # social component\n        self.w_initial = 0.9  # initial inertia weight\n        self.w_final = 0.4    # final inertia weight\n        self.f_initial = 0.8  # initial differential weight\n        self.f_final = 0.5    # final differential weight\n        self.cr = 0.9  # crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        \n        while evaluations < self.budget:\n            # Adaptive inertia weight calculation\n            self.w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Particle Swarm Optimization (PSO) update\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i] if global_best_position is not None else 0))\n\n                if np.random.rand() < 0.15:  # Stochastic velocity reset\n                    velocities[i] = np.random.uniform(-1, 1, self.dim)\n                \n                candidate_position = np.clip(population[i] + velocities[i], lb, ub)\n                candidate_score = func(candidate_position)\n                evaluations += 1\n\n                # Update personal best\n                if candidate_score < personal_best_scores[i]:\n                    personal_best_scores[i] = candidate_score\n                    personal_best_positions[i] = candidate_position\n\n                # Update global best\n                if candidate_score < global_best_score:\n                    global_best_score = candidate_score\n                    global_best_position = candidate_position\n\n            # Differential Evolution (DE) mutation and crossover\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                self.f = self.f_initial - (self.f_initial - self.f_final) * (evaluations / self.budget)  # Adaptive mutation scaling factor\n                mutant_vector = np.clip(personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c]), lb, ub)\n                \n                trial_vector = np.copy(personal_best_positions[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == jrand:\n                        trial_vector[j] = mutant_vector[j]\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                # Selection\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Enhanced HybridPSODE with adaptive mutation scaling factor and improved velocity reset for refined exploration and convergence.", "configspace": "", "generation": 3, "fitness": 0.8446063209469741, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.845 with standard deviation 0.035. And the mean value of best solutions found was 0.132 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "83ddaccf-a9d0-4b26-8555-84b2ad30349d", "metadata": {"aucs": [0.8056988484663712, 0.8912044812734717, 0.8369156331010794], "final_y": [0.145452846766148, 0.1224414281656303, 0.1295777450357214]}, "mutation_prompt": null}
{"id": "db5d9ef4-d320-4d1f-8f3b-e5802875aa4e", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.0  # cognitive component\n        self.c2 = 2.0  # social component\n        self.w_initial = 0.9  # initial inertia weight\n        self.w_final = 0.4    # final inertia weight\n        self.f = 0.8   # differential weight\n        self.cr = 0.9  # crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        \n        while evaluations < self.budget:\n            # Adaptive inertia weight calculation\n            self.w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Particle Swarm Optimization (PSO) update\n                r1, r2 = np.random.rand(), np.random.rand()\n                r2 = 0.7 * (1 - r2**2)  # using logistic map for chaotic behavior\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i] if global_best_position is not None else 0))\n\n                if np.random.rand() < 0.1:  # Stochastic velocity reset\n                    velocities[i] = np.random.uniform(-1, 1, self.dim)\n                \n                candidate_position = np.clip(population[i] + velocities[i], lb, ub)\n                candidate_score = func(candidate_position)\n                evaluations += 1\n\n                # Update personal best\n                if candidate_score < personal_best_scores[i]:\n                    personal_best_scores[i] = candidate_score\n                    personal_best_positions[i] = candidate_position\n\n                # Update global best\n                if candidate_score < global_best_score:\n                    global_best_score = candidate_score\n                    global_best_position = candidate_position\n\n            # Differential Evolution (DE) mutation and crossover\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                f = self.f * (1 - 0.9 * np.random.rand()**2)  # using chaotic factor in differential weight\n                mutant_vector = np.clip(personal_best_positions[a] + f * (personal_best_positions[b] - personal_best_positions[c]), lb, ub)\n                \n                trial_vector = np.copy(personal_best_positions[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == jrand:\n                        trial_vector[j] = mutant_vector[j]\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                # Selection\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Enhanced exploration and convergence by introducing chaotic maps in velocity adjustment and mutation operations.", "configspace": "", "generation": 3, "fitness": 0.8492068488754668, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.849 with standard deviation 0.020. And the mean value of best solutions found was 0.129 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "83ddaccf-a9d0-4b26-8555-84b2ad30349d", "metadata": {"aucs": [0.8225753073762821, 0.8561560732916483, 0.8688891659584701], "final_y": [0.13337798692804437, 0.1330263171953191, 0.12176492465025668]}, "mutation_prompt": null}
{"id": "5cbd0aa9-cf88-43b9-9acf-d3de97fb638f", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.0  # cognitive component\n        self.c2 = 2.0  # social component\n        self.w_initial = 0.9  # initial inertia weight\n        self.w_final = 0.4    # final inertia weight\n        self.f = 0.8   # differential weight\n        self.cr = 0.9  # crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        \n        while evaluations < self.budget:\n            # Adaptive inertia weight calculation\n            self.w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Particle Swarm Optimization (PSO) update\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i] if global_best_position is not None else 0))\n\n                if np.random.rand() < 0.15:  # Stochastic velocity reset (changed from 0.1 to 0.15)\n                    velocities[i] = np.random.uniform(-1, 1, self.dim)\n                \n                candidate_position = np.clip(population[i] + velocities[i], lb, ub)\n                candidate_score = func(candidate_position)\n                evaluations += 1\n\n                # Update personal best\n                if candidate_score < personal_best_scores[i]:\n                    personal_best_scores[i] = candidate_score\n                    personal_best_positions[i] = candidate_position\n\n                # Update global best\n                if candidate_score < global_best_score:\n                    global_best_score = candidate_score\n                    global_best_position = candidate_position\n\n            # Differential Evolution (DE) mutation and crossover\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                mutant_vector = np.clip(personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c]), lb, ub)\n                \n                trial_vector = np.copy(personal_best_positions[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == jrand:\n                        trial_vector[j] = mutant_vector[j]\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                # Selection\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Refined HybridPSODE with improved velocity reset probability for enhanced exploration.", "configspace": "", "generation": 3, "fitness": 0.8619216140972309, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.862 with standard deviation 0.046. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "83ddaccf-a9d0-4b26-8555-84b2ad30349d", "metadata": {"aucs": [0.8115718332202025, 0.9224886157322542, 0.8517043933392356], "final_y": [0.1319127921156953, 0.1188268482147522, 0.1291548212793976]}, "mutation_prompt": null}
{"id": "3faf2541-d0c5-4abe-ba28-c486543adf91", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.0  # cognitive component\n        self.c2 = 2.0  # social component\n        self.w_initial = 0.9  # initial inertia weight\n        self.w_final = 0.4    # final inertia weight\n        self.f = 0.8   # differential weight\n        self.cr_initial = 0.9  # initial crossover probability\n        self.cr_final = 0.6    # final crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        evaluations = 0\n\n        dynamic_neighborhood_size = max(3, self.population_size // 5)\n        \n        while evaluations < self.budget:\n            # Adaptive inertia weight calculation\n            self.w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Particle Swarm Optimization (PSO) update\n                r1, r2 = np.random.rand(), np.random.rand()\n                neighborhood_indices = np.random.choice(self.population_size, dynamic_neighborhood_size, replace=False)\n                local_best_position = min(neighborhood_indices, key=lambda idx: personal_best_scores[idx])\n                \n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (personal_best_positions[local_best_position] - population[i]))\n\n                if np.random.rand() < 0.1:  # Stochastic velocity reset\n                    velocities[i] = np.random.uniform(-1, 1, self.dim)\n                \n                candidate_position = np.clip(population[i] + velocities[i], lb, ub)\n                candidate_score = func(candidate_position)\n                evaluations += 1\n\n                # Update personal best\n                if candidate_score < personal_best_scores[i]:\n                    personal_best_scores[i] = candidate_score\n                    personal_best_positions[i] = candidate_position\n\n                # Update global best\n                if candidate_score < global_best_score:\n                    global_best_score = candidate_score\n                    global_best_position = candidate_position\n\n            # Differential Evolution (DE) mutation and crossover\n            self.cr = self.cr_initial - (self.cr_initial - self.cr_final) * (evaluations / self.budget)\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                mutant_vector = np.clip(personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c]), lb, ub)\n                \n                trial_vector = np.copy(personal_best_positions[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == jrand:\n                        trial_vector[j] = mutant_vector[j]\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                # Selection\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Enhanced HybridPSODE with dynamic neighborhood size and adaptive crossover for improved convergence in challenging optimization landscapes.", "configspace": "", "generation": 3, "fitness": 0.8223587372801533, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.822 with standard deviation 0.019. And the mean value of best solutions found was 0.138 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "83ddaccf-a9d0-4b26-8555-84b2ad30349d", "metadata": {"aucs": [0.7999806255570525, 0.8214699829383286, 0.8456256033450787], "final_y": [0.14213578353474488, 0.1367888918420539, 0.13445553931176923]}, "mutation_prompt": null}
{"id": "a7c30645-7eba-431f-b3eb-6fab21b37c82", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.0  # cognitive component\n        self.c2 = 2.0  # social component\n        self.w_initial = 0.9  # initial inertia weight\n        self.w_final = 0.4    # final inertia weight\n        self.f = 0.8   # differential weight\n        self.cr = 0.9  # crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        \n        while evaluations < self.budget:\n            # Adaptive inertia weight calculation\n            self.w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Particle Swarm Optimization (PSO) update\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i] if global_best_position is not None else 0))\n\n                # Modified line: Add influence of neighboring particles\n                neighboring_influence = np.mean(population[np.random.choice(self.population_size, 5, replace=False)], axis=0)\n                candidate_position = np.clip(population[i] + velocities[i] + 0.1 * (neighboring_influence - population[i]), lb, ub)\n                \n                candidate_score = func(candidate_position)\n                evaluations += 1\n\n                # Update personal best\n                if candidate_score < personal_best_scores[i]:\n                    personal_best_scores[i] = candidate_score\n                    personal_best_positions[i] = candidate_position\n\n                # Update global best\n                if candidate_score < global_best_score:\n                    global_best_score = candidate_score\n                    global_best_position = candidate_position\n\n            # Differential Evolution (DE) mutation and crossover\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                self.f = 0.5 + 0.3 * np.random.rand()  # modified line for adaptive differential weight\n\n                mutant_vector = np.clip(personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c]), lb, ub)\n                \n                trial_vector = np.copy(personal_best_positions[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == jrand:\n                        trial_vector[j] = mutant_vector[j]\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                # Selection\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Improved HybridPSODE by introducing neighbor-based position updates for enhanced exploration.", "configspace": "", "generation": 3, "fitness": 0.8400349911450435, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.840 with standard deviation 0.031. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "80facfad-8844-457f-80a9-49c3533751f2", "metadata": {"aucs": [0.7977806287282915, 0.8710483100940887, 0.8512760346127506], "final_y": [0.143892637839104, 0.122501452528048, 0.12783833488394003]}, "mutation_prompt": null}
{"id": "a0429983-e0ea-470f-a36c-966ab7f85e73", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.0  # initial cognitive component\n        self.c2_initial = 2.0  # initial social component\n        self.w_initial = 0.9  # initial inertia weight\n        self.w_final = 0.4    # final inertia weight\n        self.f = 0.8   # differential weight\n        self.cr = 0.9  # crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        \n        while evaluations < self.budget:\n            # Adaptive inertia weight calculation\n            self.w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            self.c1 = self.c1_initial * (1 - evaluations / self.budget)  # Dynamic cognitive component\n            self.c2 = self.c2_initial * (evaluations / self.budget)  # Dynamic social component\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Particle Swarm Optimization (PSO) update\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i] if global_best_position is not None else 0))\n\n                if np.random.rand() < 0.1:  # Stochastic velocity reset\n                    velocities[i] = np.random.uniform(-1, 1, self.dim)\n                \n                candidate_position = np.clip(population[i] + velocities[i], lb, ub)\n                candidate_score = func(candidate_position)\n                evaluations += 1\n\n                # Update personal best\n                if candidate_score < personal_best_scores[i]:\n                    personal_best_scores[i] = candidate_score\n                    personal_best_positions[i] = candidate_position\n\n                # Update global best\n                if candidate_score < global_best_score:\n                    global_best_score = candidate_score\n                    global_best_position = candidate_position\n\n            # Differential Evolution (DE) mutation and crossover\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                mutant_vector = np.clip(personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c]), lb, ub)\n                \n                trial_vector = np.copy(personal_best_positions[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == jrand:\n                        trial_vector[j] = mutant_vector[j]\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                # Selection\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Improved HybridPSODE with dynamic adjustment of cognitive and social coefficients based on evaluation progression.", "configspace": "", "generation": 3, "fitness": 0.8202262746048565, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.820 with standard deviation 0.019. And the mean value of best solutions found was 0.141 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "83ddaccf-a9d0-4b26-8555-84b2ad30349d", "metadata": {"aucs": [0.8292301260128255, 0.7941733042415815, 0.8372753935601627], "final_y": [0.13958274020372552, 0.14963931310501033, 0.13291726357266453]}, "mutation_prompt": null}
{"id": "60b78be9-7931-4be3-a42c-3f849fc09acd", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.0  # cognitive component\n        self.c2 = 2.0  # social component\n        self.w_initial = 0.9  # initial inertia weight\n        self.w_final = 0.4    # final inertia weight\n        self.f_initial = 0.8   # initial differential weight\n        self.cr_initial = 0.9  # initial crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        \n        while evaluations < self.budget:\n            # Adaptive inertia weight calculation\n            self.w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Particle Swarm Optimization (PSO) update\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i] if global_best_position is not None else 0))\n\n                if np.random.rand() < 0.1:  # Stochastic velocity reset\n                    velocities[i] = np.random.uniform(-1, 1, self.dim)\n                \n                candidate_position = np.clip(population[i] + velocities[i], lb, ub)\n                candidate_score = func(candidate_position)\n                evaluations += 1\n\n                # Update personal best\n                if candidate_score < personal_best_scores[i]:\n                    personal_best_scores[i] = candidate_score\n                    personal_best_positions[i] = candidate_position\n\n                # Update global best\n                if candidate_score < global_best_score:\n                    global_best_score = candidate_score\n                    global_best_position = candidate_position\n\n            # Differential Evolution (DE) mutation and crossover\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                f = self.f_initial * (1 - (evaluations / self.budget))  # Dynamic differential weight\n                mutant_vector = np.clip(personal_best_positions[a] + f * (personal_best_positions[b] - personal_best_positions[c]), lb, ub)\n                \n                cr = self.cr_initial * (1 - (evaluations / self.budget))  # Dynamic crossover probability\n                trial_vector = np.copy(personal_best_positions[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < cr or j == jrand:\n                        trial_vector[j] = mutant_vector[j]\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                # Selection\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Enhanced HybridPSODE with dynamic crossover and mutation rates for improved adaptability in diverse search spaces.", "configspace": "", "generation": 3, "fitness": 0.8250763119878997, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.825 with standard deviation 0.034. And the mean value of best solutions found was 0.143 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "83ddaccf-a9d0-4b26-8555-84b2ad30349d", "metadata": {"aucs": [0.7814236712358883, 0.8304392336013113, 0.863366031126499], "final_y": [0.15498903290600674, 0.14514059895997977, 0.13012357068072644]}, "mutation_prompt": null}
{"id": "f5576381-3d4a-41fb-8f1a-26183e675d9a", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.0  # cognitive component\n        self.c2 = 2.0  # social component\n        self.w_initial = 0.9  # initial inertia weight\n        self.w_final = 0.4    # final inertia weight\n        self.f = 0.8   # differential weight\n        self.cr = 0.9  # crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        \n        while evaluations < self.budget:\n            self.w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i] if global_best_position is not None else 0))\n\n                if np.random.rand() < 0.1:\n                    velocities[i] = np.random.uniform(-1, 1, self.dim)\n                \n                candidate_position = np.clip(population[i] + velocities[i], lb, ub)\n                candidate_score = func(candidate_position)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i]:\n                    personal_best_scores[i] = candidate_score\n                    personal_best_positions[i] = candidate_position\n\n                if candidate_score < global_best_score:\n                    global_best_score = candidate_score\n                    global_best_position = candidate_position\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                mutant_vector = np.clip(personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c]), lb, ub)\n                \n                trial_vector = np.copy(personal_best_positions[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == jrand:\n                        trial_vector[j] = mutant_vector[j]\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n            # Dynamic population size adjustment\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(10, int(50 - 40 * (evaluations / self.budget)))\n                personal_best_positions = personal_best_positions[:self.population_size]\n                personal_best_scores = personal_best_scores[:self.population_size]\n                population = population[:self.population_size]\n                velocities = velocities[:self.population_size]\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Enhanced HybridPSODE with dynamic population size adjustment to improve convergence in black-box optimization.", "configspace": "", "generation": 3, "fitness": 0.8378053964027051, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.838 with standard deviation 0.017. And the mean value of best solutions found was 0.136 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "83ddaccf-a9d0-4b26-8555-84b2ad30349d", "metadata": {"aucs": [0.813470044611575, 0.8537008918907057, 0.8462452527058344], "final_y": [0.14215992253123122, 0.130053556151991, 0.13623383029619918]}, "mutation_prompt": null}
{"id": "1baf5394-09e5-45e9-9225-4f864421c9d7", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.0  # cognitive component\n        self.c2 = 2.0  # social component\n        self.w_initial = 0.9  # initial inertia weight\n        self.w_final = 0.4    # final inertia weight\n        self.f = 0.8   # differential weight\n        self.cr = 0.9  # crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        \n        while evaluations < self.budget:\n            # Adaptive inertia weight calculation\n            self.w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Particle Swarm Optimization (PSO) update\n                r1, r2 = np.random.rand(), np.random.rand()\n                r2 = 0.7 * (1 - r2**2)  # using logistic map for chaotic behavior\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i] if global_best_position is not None else 0))\n\n                if np.random.rand() < (0.1 * (1 - np.random.rand()**2)):  # Chaotic velocity reset\n                    velocities[i] = np.random.uniform(-1, 1, self.dim)\n                \n                candidate_position = np.clip(population[i] + velocities[i], lb, ub)\n                candidate_score = func(candidate_position)\n                evaluations += 1\n\n                # Update personal best\n                if candidate_score < personal_best_scores[i]:\n                    personal_best_scores[i] = candidate_score\n                    personal_best_positions[i] = candidate_position\n\n                # Update global best\n                if candidate_score < global_best_score:\n                    global_best_score = candidate_score\n                    global_best_position = candidate_position\n\n            # Differential Evolution (DE) mutation and crossover\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                f = self.f * (1 - 0.9 * np.random.rand()**2)  # using chaotic factor in differential weight\n                mutant_vector = np.clip(personal_best_positions[a] + f * (personal_best_positions[b] - personal_best_positions[c]), lb, ub)\n                \n                trial_vector = np.copy(personal_best_positions[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == jrand:\n                        trial_vector[j] = mutant_vector[j]\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                # Selection\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Enhanced exploration by introducing a chaotic map in velocity reset probability for diverse search dynamics.", "configspace": "", "generation": 4, "fitness": 0.7969801264613748, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.797 with standard deviation 0.046. And the mean value of best solutions found was 0.146 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "db5d9ef4-d320-4d1f-8f3b-e5802875aa4e", "metadata": {"aucs": [0.7954283443560353, 0.7417992799950652, 0.8537127550330241], "final_y": [0.13857446894332215, 0.16118068919138318, 0.13797204102938299]}, "mutation_prompt": null}
{"id": "7bd69838-ebdd-44fa-9220-2b92ebd0fa34", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.0  # cognitive component\n        self.c2 = 2.0  # social component\n        self.w_initial = 0.9  # initial inertia weight\n        self.w_final = 0.4    # final inertia weight\n        self.f = 0.8   # differential weight\n        self.cr = 0.9  # crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        \n        while evaluations < self.budget:\n            # Adaptive inertia weight calculation\n            self.w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Particle Swarm Optimization (PSO) update\n                r1, r2 = np.random.rand(), np.random.rand()\n                r2 = 0.9 * (1 - r2**2)  # using logistic map for chaotic behavior\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i] if global_best_position is not None else 0))\n\n                if np.random.rand() < 0.1:  # Stochastic velocity reset\n                    velocities[i] = np.random.uniform(-1, 1, self.dim)\n                \n                candidate_position = np.clip(population[i] + velocities[i], lb, ub)\n                candidate_score = func(candidate_position)\n                evaluations += 1\n\n                # Update personal best\n                if candidate_score < personal_best_scores[i]:\n                    personal_best_scores[i] = candidate_score\n                    personal_best_positions[i] = candidate_position\n\n                # Update global best\n                if candidate_score < global_best_score:\n                    global_best_score = candidate_score\n                    global_best_position = candidate_position\n\n            # Differential Evolution (DE) mutation and crossover\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                f = self.f * (1 - 0.9 * np.random.rand()**2)  # using chaotic factor in differential weight\n                mutant_vector = np.clip(personal_best_positions[a] + f * (personal_best_positions[b] - personal_best_positions[c]), lb, ub)\n                \n                trial_vector = np.copy(personal_best_positions[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == jrand:\n                        trial_vector[j] = mutant_vector[j]\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                # Selection\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Improved chaotic behavior by modifying the logistic map factor in velocity updates for enhanced exploration.", "configspace": "", "generation": 4, "fitness": 0.7844310591937186, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.784 with standard deviation 0.034. And the mean value of best solutions found was 0.156 (0. is the best) with standard deviation 0.022.", "error": "", "parent_id": "db5d9ef4-d320-4d1f-8f3b-e5802875aa4e", "metadata": {"aucs": [0.8168679936968986, 0.7367781287145239, 0.7996470551697334], "final_y": [0.13023878343808337, 0.1830130492106834, 0.1559538044097899]}, "mutation_prompt": null}
{"id": "a33eaefe-523a-4cca-85ea-268b82af3b79", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.0  # cognitive component\n        self.c2 = 2.0  # social component\n        self.w_initial = 0.9  # initial inertia weight\n        self.w_final = 0.4    # final inertia weight\n        self.f = 0.8   # differential weight\n        self.cr = 0.9  # crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        \n        while evaluations < self.budget:\n            self.w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                r1, r2 = np.random.rand(), np.random.rand()\n                r2 = 0.7 * (1 - r2**2)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i] if global_best_position is not None else 0))\n\n                if np.random.rand() < 0.2:  # Adjusted stochastic velocity reset probability\n                    velocities[i] = np.random.uniform(-1, 1, self.dim)\n                \n                candidate_position = np.clip(population[i] + velocities[i], lb, ub)\n                candidate_score = func(candidate_position)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i]:\n                    personal_best_scores[i] = candidate_score\n                    personal_best_positions[i] = candidate_position\n\n                if candidate_score < global_best_score:\n                    global_best_score = candidate_score\n                    global_best_position = candidate_position\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                f = self.f * (1 - 0.9 * np.random.rand()**2)\n                mutant_vector = np.clip(personal_best_positions[a] + f * (personal_best_positions[b] - personal_best_positions[c]), lb, ub)\n                \n                trial_vector = np.copy(personal_best_positions[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < (self.cr + np.sin(evaluations/self.budget * np.pi) * 0.1) or j == jrand:  # Adaptive crossover strategy\n                        trial_vector[j] = mutant_vector[j]\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Enhanced exploration and convergence by integrating chaos-enhanced velocity adjustment, selective DE mutation, and adaptive crossover strategy.", "configspace": "", "generation": 4, "fitness": 0.8020415545561753, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.802 with standard deviation 0.034. And the mean value of best solutions found was 0.154 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "db5d9ef4-d320-4d1f-8f3b-e5802875aa4e", "metadata": {"aucs": [0.755171774345079, 0.8367182147642269, 0.8142346745592203], "final_y": [0.16703386998678582, 0.14209579892429014, 0.15292328859466398]}, "mutation_prompt": null}
{"id": "79e0badc-07c8-4008-bef1-5a560f7e52f0", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.0  # cognitive component\n        self.c2 = 2.0  # social component\n        self.w_initial = 0.9  # initial inertia weight\n        self.w_final = 0.4    # final inertia weight\n        self.f = 0.8   # differential weight\n        self.cr_initial = 0.9  # initial crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        \n        while evaluations < self.budget:\n            # Adaptive inertia weight calculation\n            self.w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Particle Swarm Optimization (PSO) update\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i] if global_best_position is not None else 0))\n\n                if np.random.rand() < 0.15:  # Stochastic velocity reset (changed from 0.1 to 0.15)\n                    velocities[i] = np.random.uniform(-1, 1, self.dim)\n                \n                candidate_position = np.clip(population[i] + velocities[i], lb, ub)\n                candidate_score = func(candidate_position)\n                evaluations += 1\n\n                # Update personal best\n                if candidate_score < personal_best_scores[i]:\n                    personal_best_scores[i] = candidate_score\n                    personal_best_positions[i] = candidate_position\n\n                # Update global best\n                if candidate_score < global_best_score:\n                    global_best_score = candidate_score\n                    global_best_position = candidate_position\n\n            # Differential Evolution (DE) mutation and crossover\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                mutant_vector = np.clip(personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c]), lb, ub)\n                \n                trial_vector = np.copy(personal_best_positions[i])\n                jrand = np.random.randint(self.dim)\n                self.cr = self.cr_initial * (1 - evaluations / self.budget)  # Dynamic crossover probability adjustment\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == jrand:\n                        trial_vector[j] = mutant_vector[j]\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                # Selection\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Improved HybridPSODE with dynamic crossover probability adjustment for better exploration-exploitation balance.", "configspace": "", "generation": 4, "fitness": 0.8064657899422739, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.806 with standard deviation 0.052. And the mean value of best solutions found was 0.151 (0. is the best) with standard deviation 0.019.", "error": "", "parent_id": "5cbd0aa9-cf88-43b9-9acf-d3de97fb638f", "metadata": {"aucs": [0.8227167374927914, 0.7357994039745936, 0.8608812283594366], "final_y": [0.13800744666527143, 0.17755868248581308, 0.13653671126629252]}, "mutation_prompt": null}
{"id": "5d4b5201-f19e-4c31-add5-66c1a3aab368", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.0  # cognitive component\n        self.c2 = 2.0  # social component\n        self.w_initial = 0.9  # initial inertia weight\n        self.w_final = 0.4    # final inertia weight\n        self.f = 0.8   # differential weight\n        self.cr = 0.9  # crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        \n        while evaluations < self.budget:\n            # Adaptive inertia weight calculation\n            self.w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Particle Swarm Optimization (PSO) update\n                r1, r2 = np.random.rand(), np.random.rand()\n                r2 = 0.7 * (1 - r2**2)  # using logistic map for chaotic behavior\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i] if global_best_position is not None else 0))\n\n                if np.random.rand() < 0.1:  # Stochastic velocity reset\n                    velocities[i] = np.random.uniform(-1, 1, self.dim)\n                \n                candidate_position = np.clip(population[i] + velocities[i], lb, ub)\n                candidate_score = func(candidate_position)\n                evaluations += 1\n\n                # Update personal best\n                if candidate_score < personal_best_scores[i]:\n                    personal_best_scores[i] = candidate_score\n                    personal_best_positions[i] = candidate_position\n\n                # Update global best\n                if candidate_score < global_best_score:\n                    global_best_score = candidate_score\n                    global_best_position = candidate_position\n\n            # Differential Evolution (DE) mutation and crossover\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                f = self.f * (1 - 0.9 * np.random.rand()**2)  # using chaotic factor in differential weight\n                mutant_vector = np.clip(personal_best_positions[a] + f * np.random.rand() * (personal_best_positions[b] - personal_best_positions[c]), lb, ub)\n                \n                trial_vector = np.copy(personal_best_positions[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == jrand:\n                        trial_vector[j] = mutant_vector[j]\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                # Selection\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Introduce a stochastic step size adjustment in the DE mutation to enhance exploration and balance convergence.", "configspace": "", "generation": 4, "fitness": 0.7828118000894685, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.783 with standard deviation 0.042. And the mean value of best solutions found was 0.160 (0. is the best) with standard deviation 0.021.", "error": "", "parent_id": "db5d9ef4-d320-4d1f-8f3b-e5802875aa4e", "metadata": {"aucs": [0.8085800912057386, 0.7234909172307087, 0.8163643918319583], "final_y": [0.14045586607679694, 0.18877920895042288, 0.1515227675403683]}, "mutation_prompt": null}
{"id": "408143cc-1db5-442c-be06-a66447f98cd9", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.0  # cognitive component\n        self.c2 = 2.0  # social component\n        self.w_initial = 0.9  # initial inertia weight\n        self.w_final = 0.4    # final inertia weight\n        self.f = 0.8   # differential weight\n        self.cr = 0.9  # crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        \n        while evaluations < self.budget:\n            # Adaptive inertia weight calculation\n            self.w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Particle Swarm Optimization (PSO) update\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i] if global_best_position is not None else 0))\n\n                if np.random.rand() < 0.2:  # Stochastic velocity reset (changed from 0.15 to 0.2)\n                    velocities[i] = np.random.uniform(-1, 1, self.dim)\n                \n                candidate_position = np.clip(population[i] + velocities[i], lb, ub)\n                candidate_score = func(candidate_position)\n                evaluations += 1\n\n                # Update personal best\n                if candidate_score < personal_best_scores[i]:\n                    personal_best_scores[i] = candidate_score\n                    personal_best_positions[i] = candidate_position\n\n                # Update global best\n                if candidate_score < global_best_score:\n                    global_best_score = candidate_score\n                    global_best_position = candidate_position\n\n            # Differential Evolution (DE) mutation and crossover\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                mutant_vector = np.clip(personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c]), lb, ub)\n                \n                trial_vector = np.copy(personal_best_positions[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == jrand:\n                        trial_vector[j] = mutant_vector[j]\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                # Selection\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Improved velocity reset probability for better exploration and convergence.", "configspace": "", "generation": 4, "fitness": 0.8162159483239986, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.816 with standard deviation 0.008. And the mean value of best solutions found was 0.150 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "5cbd0aa9-cf88-43b9-9acf-d3de97fb638f", "metadata": {"aucs": [0.8164770266981886, 0.8057764927803821, 0.8263943254934251], "final_y": [0.14983521059106386, 0.15334918628153316, 0.14782336863872558]}, "mutation_prompt": null}
{"id": "33f2151c-91f9-446a-b42c-4b1f6ef9e1b6", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.0  # cognitive component\n        self.c2 = 2.0  # social component\n        self.w_initial = 0.9  # initial inertia weight\n        self.w_final = 0.4    # final inertia weight\n        self.f = 0.8   # differential weight\n        self.cr = 0.9  # crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        \n        while evaluations < self.budget:\n            # Nonlinear inertia weight calculation\n            self.w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)**2\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Particle Swarm Optimization (PSO) update\n                r1, r2 = np.random.rand(), np.random.rand()\n                r2 = 0.7 * (1 - r2**2)  # using logistic map for chaotic behavior\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i] if global_best_position is not None else 0))\n\n                if np.random.rand() < 0.1:  # Stochastic velocity reset\n                    velocities[i] = np.random.uniform(-1, 1, self.dim)\n                \n                candidate_position = np.clip(population[i] + velocities[i], lb, ub)\n                candidate_score = func(candidate_position)\n                evaluations += 1\n\n                # Update personal best\n                if candidate_score < personal_best_scores[i]:\n                    personal_best_scores[i] = candidate_score\n                    personal_best_positions[i] = candidate_position\n\n                # Update global best\n                if candidate_score < global_best_score:\n                    global_best_score = candidate_score\n                    global_best_position = candidate_position\n\n            # Differential Evolution (DE) mutation and crossover\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                f = self.f * (1 - 0.9 * np.random.rand()**2)  # using chaotic factor in differential weight\n                mutant_vector = np.clip(personal_best_positions[a] + f * (personal_best_positions[b] - personal_best_positions[c]), lb, ub)\n                \n                trial_vector = np.copy(personal_best_positions[i])\n                jrand = np.random.randint(self.dim)\n                # Adaptive crossover strategy\n                self.cr = 0.9 * (1 - evaluations / self.budget)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == jrand:\n                        trial_vector[j] = mutant_vector[j]\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                # Selection\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Improved exploration and exploitation by introducing a nonlinear inertia weight and adaptive crossover strategy.", "configspace": "", "generation": 4, "fitness": 0.802590482594526, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.803 with standard deviation 0.032. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.016.", "error": "", "parent_id": "db5d9ef4-d320-4d1f-8f3b-e5802875aa4e", "metadata": {"aucs": [0.8244867412519752, 0.7577287080255708, 0.8255559985060321], "final_y": [0.13377772745252126, 0.17057196984958933, 0.14003587121434535]}, "mutation_prompt": null}
{"id": "199a4cf0-c68b-4524-b55c-8d7b55df9937", "solution": "import numpy as np\nfrom scipy.stats import levy\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.0  # cognitive component\n        self.c2 = 2.0  # social component\n        self.w_initial = 0.9  # initial inertia weight\n        self.w_final = 0.4    # final inertia weight\n        self.f = 0.8   # differential weight\n        self.cr = 0.9  # crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        \n        while evaluations < self.budget:\n            self.w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i] if global_best_position is not None else 0))\n\n                if np.random.rand() < 0.15:\n                    velocities[i] += levy.rvs(size=self.dim)\n\n                candidate_position = np.clip(population[i] + velocities[i], lb, ub)\n                candidate_score = func(candidate_position)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i]:\n                    personal_best_scores[i] = candidate_score\n                    personal_best_positions[i] = candidate_position\n\n                if candidate_score < global_best_score:\n                    global_best_score = candidate_score\n                    global_best_position = candidate_position\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                mutant_vector = np.clip(personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c]) + levy.rvs(size=self.dim), lb, ub)\n                \n                trial_vector = np.copy(personal_best_positions[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == jrand:\n                        trial_vector[j] = mutant_vector[j]\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Enhanced HybridPSODE with adaptive velocity and differential mutation influenced by Levy flight distribution for improved exploration and exploitation balance.", "configspace": "", "generation": 4, "fitness": 0.7920959347860769, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.792 with standard deviation 0.024. And the mean value of best solutions found was 0.157 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "5cbd0aa9-cf88-43b9-9acf-d3de97fb638f", "metadata": {"aucs": [0.7631349850146186, 0.7921853177192792, 0.8209675016243326], "final_y": [0.1668247354244945, 0.15968081722467364, 0.14595471748023225]}, "mutation_prompt": null}
{"id": "f49aab32-1ca4-4427-98d4-b4ccd9216393", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.0  # cognitive component\n        self.c2 = 2.0  # social component\n        self.w_initial = 0.9  # initial inertia weight\n        self.w_final = 0.4    # final inertia weight\n        self.f = 0.8   # differential weight\n        self.cr = 0.9  # crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        \n        while evaluations < self.budget:\n            # Adaptive inertia weight calculation\n            self.w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Particle Swarm Optimization (PSO) update\n                r1, r2 = np.random.rand(), np.random.rand()\n                r2 = 0.7 * (1 - r2**2)  # using logistic map for chaotic behavior\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i] if global_best_position is not None else 0))\n\n                if np.random.rand() < 0.1:  # Stochastic velocity reset\n                    velocities[i] = np.random.uniform(-1, 1, self.dim)\n                \n                candidate_position = np.clip(population[i] + velocities[i], lb, ub)\n\n                # Introduce Lévy flight for enhanced exploration\n                if np.random.rand() < 0.05:\n                    candidate_position += np.random.standard_cauchy(self.dim)\n\n                candidate_score = func(candidate_position)\n                evaluations += 1\n\n                # Update personal best\n                if candidate_score < personal_best_scores[i]:\n                    personal_best_scores[i] = candidate_score\n                    personal_best_positions[i] = candidate_position\n\n                # Update global best\n                if candidate_score < global_best_score:\n                    global_best_score = candidate_score\n                    global_best_position = candidate_position\n\n            # Differential Evolution (DE) mutation and crossover\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                f = self.f * (1 - 0.9 * np.random.rand()**2)  # using chaotic factor in differential weight\n                mutant_vector = np.clip(personal_best_positions[a] + f * (personal_best_positions[b] - personal_best_positions[c]), lb, ub)\n                \n                trial_vector = np.copy(personal_best_positions[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == jrand:\n                        trial_vector[j] = mutant_vector[j]\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                # Selection\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Improved exploration by introducing Lévy flights for occasional large jumps in candidate positions to escape local optima.", "configspace": "", "generation": 4, "fitness": 0.7788700050581617, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.779 with standard deviation 0.052. And the mean value of best solutions found was 0.158 (0. is the best) with standard deviation 0.019.", "error": "", "parent_id": "db5d9ef4-d320-4d1f-8f3b-e5802875aa4e", "metadata": {"aucs": [0.8379367303916616, 0.7109745223960291, 0.7876987623867946], "final_y": [0.13480481893173402, 0.18191654085341258, 0.15677359807738023]}, "mutation_prompt": null}
{"id": "ca809a43-82d3-4ddb-9d7b-adddcbe45b33", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.0  # cognitive component\n        self.c2 = 2.0  # social component\n        self.w_initial = 0.9  # initial inertia weight\n        self.w_final = 0.4    # final inertia weight\n        self.f = 0.8   # differential weight\n        self.cr_initial = 0.9  # initial crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        \n        while evaluations < self.budget:\n            # Adaptive inertia weight calculation\n            self.w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            # Dynamic crossover probability\n            self.cr = self.cr_initial * (1 - evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Particle Swarm Optimization (PSO) update\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i] if global_best_position is not None else 0))\n\n                if np.random.rand() < 0.15:  # Stochastic velocity reset (changed from 0.1 to 0.15)\n                    velocities[i] = np.random.uniform(-1, 1, self.dim)\n                \n                candidate_position = np.clip(population[i] + velocities[i], lb, ub)\n                candidate_score = func(candidate_position)\n                evaluations += 1\n\n                # Update personal best\n                if candidate_score < personal_best_scores[i]:\n                    personal_best_scores[i] = candidate_score\n                    personal_best_positions[i] = candidate_position\n\n                # Update global best\n                if candidate_score < global_best_score:\n                    global_best_score = candidate_score\n                    global_best_position = candidate_position\n\n            # Differential Evolution (DE) mutation and crossover\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                mutant_vector = np.clip(personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c]), lb, ub)\n                \n                trial_vector = np.copy(personal_best_positions[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == jrand:\n                        trial_vector[j] = mutant_vector[j]\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                # Selection\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Enhanced exploration by adjusting the crossover probability dynamically based on evaluations to improve convergence.", "configspace": "", "generation": 4, "fitness": 0.8341909348071428, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.834 with standard deviation 0.016. And the mean value of best solutions found was 0.144 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "5cbd0aa9-cf88-43b9-9acf-d3de97fb638f", "metadata": {"aucs": [0.8177622034019205, 0.8557286019056576, 0.8290819991138502], "final_y": [0.14475227483094955, 0.1389746947775291, 0.14725990245818354]}, "mutation_prompt": null}
{"id": "d2cbc8c8-5e78-4b2f-ae44-c00463c3cbf9", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.0  # cognitive component\n        self.c2 = 2.0  # social component\n        self.w_initial = 0.9  # initial inertia weight\n        self.w_final = 0.4    # final inertia weight\n        self.f = 0.8   # differential weight\n        self.cr = 0.9  # crossover probability\n        self.dynamic_pop_size = True  # Dynamic population size\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        \n        while evaluations < self.budget:\n            self.w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i] if global_best_position is not None else 0))\n\n                if np.random.rand() < 0.25:  # Adjusted velocity reset probability\n                    velocities[i] = np.random.uniform(-1, 1, self.dim)\n                \n                candidate_position = np.clip(population[i] + velocities[i], lb, ub)\n                candidate_score = func(candidate_position)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i]:\n                    personal_best_scores[i] = candidate_score\n                    personal_best_positions[i] = candidate_position\n\n                if candidate_score < global_best_score:\n                    global_best_score = candidate_score\n                    global_best_position = candidate_position\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                mutant_vector = np.clip(personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c]), lb, ub)\n                \n                trial_vector = np.copy(personal_best_positions[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == jrand:\n                        trial_vector[j] = mutant_vector[j]\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n            if self.dynamic_pop_size:\n                self.population_size = max(10, int(self.population_size * 0.9))  # Reduce population size dynamically\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Introduced local search strategies and dynamic population size to enhance exploration and exploitation balance.", "configspace": "", "generation": 5, "fitness": 0.8286011245841793, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.829 with standard deviation 0.004. And the mean value of best solutions found was 0.132 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "408143cc-1db5-442c-be06-a66447f98cd9", "metadata": {"aucs": [0.827244307489599, 0.833511910829971, 0.8250471554329678], "final_y": [0.12660335552384994, 0.14061708660032213, 0.12862269804773652]}, "mutation_prompt": null}
{"id": "eff70187-1bf2-4cdf-9511-27738788a383", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.0  # cognitive component\n        self.c2 = 2.0  # social component\n        self.w_initial = 0.9  # initial inertia weight\n        self.w_final = 0.4    # final inertia weight\n        self.f_initial = 0.6  # initial differential weight\n        self.f_final = 0.9    # final differential weight\n        self.cr_initial = 0.7 # initial crossover probability\n        self.cr_final = 0.95  # final crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        \n        while evaluations < self.budget:\n            # Adaptive inertia weight calculation\n            self.w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            self.f = self.f_initial + (self.f_final - self.f_initial) * (evaluations / self.budget)\n            self.cr = self.cr_initial + (self.cr_final - self.cr_initial) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Particle Swarm Optimization (PSO) update\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i] if global_best_position is not None else 0))\n\n                if np.random.rand() < 0.2:  # Stochastic velocity reset (changed from 0.15 to 0.2)\n                    velocities[i] = np.random.uniform(-1, 1, self.dim)\n                \n                candidate_position = np.clip(population[i] + velocities[i], lb, ub)\n                candidate_score = func(candidate_position)\n                evaluations += 1\n\n                # Update personal best\n                if candidate_score < personal_best_scores[i]:\n                    personal_best_scores[i] = candidate_score\n                    personal_best_positions[i] = candidate_position\n\n                # Update global best\n                if candidate_score < global_best_score:\n                    global_best_score = candidate_score\n                    global_best_position = candidate_position\n\n            # Differential Evolution (DE) mutation and crossover\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                mutant_vector = np.clip(personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c]), lb, ub)\n                \n                trial_vector = np.copy(personal_best_positions[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == jrand:\n                        trial_vector[j] = mutant_vector[j]\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                # Selection\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Enhanced exploration by introducing adaptive crossover probability and variable differential weight to improve convergence and solution quality.", "configspace": "", "generation": 5, "fitness": 0.8176515596188381, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.818 with standard deviation 0.005. And the mean value of best solutions found was 0.142 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "408143cc-1db5-442c-be06-a66447f98cd9", "metadata": {"aucs": [0.8137503686226883, 0.8146967820661167, 0.824507528167709], "final_y": [0.13328418179184498, 0.14893916240449423, 0.14273828485049767]}, "mutation_prompt": null}
{"id": "4cab5dd3-ae25-4fe5-8040-ac90fca5ed16", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.0  # cognitive component\n        self.c2 = 2.0  # social component\n        self.w_initial = 0.9  # initial inertia weight\n        self.w_final = 0.4    # final inertia weight\n        self.f = 0.8   # differential weight\n        self.cr_initial = 0.9  # initial crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        \n        while evaluations < self.budget:\n            # Adaptive inertia weight calculation\n            self.w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            # Dynamic crossover probability\n            self.cr = self.cr_initial * (1 - evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Particle Swarm Optimization (PSO) update\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i] if global_best_position is not None else 0))\n\n                if np.random.rand() < 0.15:  # Stochastic velocity reset (changed from 0.1 to 0.15)\n                    velocities[i] = np.random.uniform(-1, 1, self.dim)\n                \n                candidate_position = np.clip(population[i] + velocities[i], lb, ub)\n                candidate_score = func(candidate_position)\n                evaluations += 1\n\n                # Update personal best\n                if candidate_score < personal_best_scores[i]:\n                    personal_best_scores[i] = candidate_score\n                    personal_best_positions[i] = candidate_position\n\n                # Update global best\n                if candidate_score < global_best_score:\n                    global_best_score = candidate_score\n                    global_best_position = candidate_position\n\n            # Differential Evolution (DE) mutation and crossover\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                # Changed f * (personal_best_positions[b] - personal_best_positions[c]) to f * (population[b] - population[c])\n                mutant_vector = np.clip(personal_best_positions[a] + self.f * (population[b] - population[c]), lb, ub)\n                \n                trial_vector = np.copy(personal_best_positions[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == jrand:\n                        trial_vector[j] = mutant_vector[j]\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                # Selection\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A slight change in the DE mutation strategy to enhance diversity and convergence.", "configspace": "", "generation": 5, "fitness": 0.813230314892026, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.813 with standard deviation 0.010. And the mean value of best solutions found was 0.143 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "ca809a43-82d3-4ddb-9d7b-adddcbe45b33", "metadata": {"aucs": [0.8008439197487643, 0.8253854055222762, 0.8134616194050373], "final_y": [0.14952736567981395, 0.1376424662754141, 0.14043440808108287]}, "mutation_prompt": null}
{"id": "48dbf54e-07b1-4570-97fc-89aca276609b", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 2.0  # initial cognitive component\n        self.c2_initial = 2.0  # initial social component\n        self.c1_final = 1.5    # final cognitive component\n        self.c2_final = 2.5    # final social component\n        self.w_initial = 0.9  # initial inertia weight\n        self.w_final = 0.4    # final inertia weight\n        self.f = 0.8   # differential weight\n        self.cr = 0.9  # crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        \n        while evaluations < self.budget:\n            # Adaptive parameters calculation\n            self.w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            self.c1 = self.c1_initial - (self.c1_initial - self.c1_final) * (evaluations / self.budget)\n            self.c2 = self.c2_initial + (self.c2_final - self.c2_initial) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Particle Swarm Optimization (PSO) update\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i] if global_best_position is not None else 0))\n\n                if np.random.rand() < 0.2:  # Stochastic velocity reset (changed from 0.15 to 0.2)\n                    velocities[i] = np.random.uniform(-1, 1, self.dim)\n                \n                candidate_position = np.clip(population[i] + velocities[i], lb, ub)\n                candidate_score = func(candidate_position)\n                evaluations += 1\n\n                # Update personal best\n                if candidate_score < personal_best_scores[i]:\n                    personal_best_scores[i] = candidate_score\n                    personal_best_positions[i] = candidate_position\n\n                # Update global best\n                if candidate_score < global_best_score:\n                    global_best_score = candidate_score\n                    global_best_position = candidate_position\n\n            # Differential Evolution (DE) mutation and crossover\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                mutant_vector = np.clip(personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c]), lb, ub)\n                \n                trial_vector = np.copy(personal_best_positions[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == jrand:\n                        trial_vector[j] = mutant_vector[j]\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                # Selection\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Introduce adaptive learning rates for cognitive and social components in PSO to enhance convergence efficiency.", "configspace": "", "generation": 5, "fitness": 0.8294694782815978, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.829 with standard deviation 0.021. And the mean value of best solutions found was 0.140 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "408143cc-1db5-442c-be06-a66447f98cd9", "metadata": {"aucs": [0.8107694396892473, 0.818103366861105, 0.8595356282944411], "final_y": [0.14063443485431948, 0.14682834840055436, 0.13388140217533206]}, "mutation_prompt": null}
{"id": "2c90adb2-4f1d-4e52-8290-583d94660d7e", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.0  # cognitive component\n        self.c2 = 2.0  # social component\n        self.w_initial = 0.9  # initial inertia weight\n        self.w_final = 0.4    # final inertia weight\n        self.f_initial = 0.8  # initial differential weight\n        self.f_final = 0.5    # final differential weight\n        self.cr_initial = 0.9  # initial crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        \n        while evaluations < self.budget:\n            self.w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            self.f = self.f_initial - (self.f_initial - self.f_final) * (evaluations / self.budget)\n            self.cr = self.cr_initial * (1 - evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i] if global_best_position is not None else 0))\n\n                if np.random.rand() < 0.15:\n                    velocities[i] = np.random.uniform(-1, 1, self.dim)\n                \n                candidate_position = np.clip(population[i] + velocities[i], lb, ub)\n                candidate_score = func(candidate_position)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i]:\n                    personal_best_scores[i] = candidate_score\n                    personal_best_positions[i] = candidate_position\n\n                if candidate_score < global_best_score:\n                    global_best_score = candidate_score\n                    global_best_position = candidate_position\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                mutant_vector = np.clip(personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c]), lb, ub)\n                \n                trial_vector = np.copy(personal_best_positions[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == jrand:\n                        trial_vector[j] = mutant_vector[j]\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Improved exploration and exploitation by introducing adaptive mutation factor and dual selection pressure in DE.", "configspace": "", "generation": 5, "fitness": 0.8374733037830694, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.837 with standard deviation 0.009. And the mean value of best solutions found was 0.134 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "ca809a43-82d3-4ddb-9d7b-adddcbe45b33", "metadata": {"aucs": [0.8350688310295421, 0.8495757143647074, 0.8277753659549589], "final_y": [0.12957825849771476, 0.133365718464877, 0.13813698996235668]}, "mutation_prompt": null}
{"id": "91e1e3b0-c4cd-4305-9989-bc9e22282739", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.0  # cognitive component\n        self.c2 = 2.0  # social component\n        self.w_initial = 0.9  # initial inertia weight\n        self.w_final = 0.4    # final inertia weight\n        self.f = 0.8   # differential weight\n        self.cr = 0.9  # crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        \n        while evaluations < self.budget:\n            # Adaptive inertia weight calculation\n            self.w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Particle Swarm Optimization (PSO) update\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i] if global_best_position is not None else 0))\n\n                if np.random.rand() < 0.2:  # Stochastic velocity reset (changed from 0.15 to 0.2)\n                    velocities[i] = np.random.uniform(-1, 1, self.dim)\n                \n                candidate_position = np.clip(population[i] + velocities[i], lb, ub)\n                candidate_score = func(candidate_position)\n                evaluations += 1\n\n                # Update personal best\n                if candidate_score < personal_best_scores[i]:\n                    personal_best_scores[i] = candidate_score\n                    personal_best_positions[i] = candidate_position\n\n                # Update global best\n                if candidate_score < global_best_score:\n                    global_best_score = candidate_score\n                    global_best_position = candidate_position\n\n            # Differential Evolution (DE) mutation and crossover\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                # Introduced stochastic adaptive change\n                self.f = np.random.uniform(0.5, 1.0)\n\n                mutant_vector = np.clip(personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c]), lb, ub)\n                \n                trial_vector = np.copy(personal_best_positions[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == jrand:\n                        trial_vector[j] = mutant_vector[j]\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                # Selection\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Introduced stochastic adaptive change in differential weight (f) to enhance exploration.", "configspace": "", "generation": 5, "fitness": 0.8431814796062111, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.843 with standard deviation 0.011. And the mean value of best solutions found was 0.132 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "408143cc-1db5-442c-be06-a66447f98cd9", "metadata": {"aucs": [0.8343319195591741, 0.8368765517412793, 0.8583359675181799], "final_y": [0.13913041198930365, 0.1317797183971009, 0.12606676548339035]}, "mutation_prompt": null}
{"id": "eefb7790-8969-4996-b880-5fc6756a531b", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.0  # cognitive component\n        self.c2 = 2.0  # social component\n        self.w_initial = 0.9  # initial inertia weight\n        self.w_final = 0.4    # final inertia weight\n        self.f_initial = 0.8  # initial differential weight\n        self.cr_initial = 0.9  # initial crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        \n        while evaluations < self.budget:\n            # Adaptive inertia weight and differential weight calculation\n            self.w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            self.f = self.f_initial * (1 - evaluations / self.budget)  # Dynamic differential weight\n            self.cr = self.cr_initial * (1 - evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Particle Swarm Optimization (PSO) update\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i] if global_best_position is not None else 0))\n\n                if np.random.rand() < 0.15:  # Stochastic velocity reset (changed from 0.1 to 0.15)\n                    velocities[i] = np.random.uniform(-1, 1, self.dim)\n                \n                candidate_position = np.clip(population[i] + velocities[i], lb, ub)\n                candidate_score = func(candidate_position)\n                evaluations += 1\n\n                # Update personal best\n                if candidate_score < personal_best_scores[i]:\n                    personal_best_scores[i] = candidate_score\n                    personal_best_positions[i] = candidate_position\n\n                # Update global best\n                if candidate_score < global_best_score:\n                    global_best_score = candidate_score\n                    global_best_position = candidate_position\n\n            # Differential Evolution (DE) mutation and crossover\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                mutant_vector = np.clip(personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c]), lb, ub)\n                \n                trial_vector = np.copy(personal_best_positions[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == jrand:\n                        trial_vector[j] = mutant_vector[j]\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                # Selection\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Enhanced exploration with a dynamic differential weight (f) to balance exploration and exploitation.", "configspace": "", "generation": 5, "fitness": 0.8430732640060628, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.843 with standard deviation 0.015. And the mean value of best solutions found was 0.138 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "ca809a43-82d3-4ddb-9d7b-adddcbe45b33", "metadata": {"aucs": [0.8424304562544951, 0.8254420181852014, 0.8613473175784918], "final_y": [0.1378691032011512, 0.14590710541603535, 0.12944259533511948]}, "mutation_prompt": null}
{"id": "a2a94e6f-4c73-4aa6-8889-c903bd731b36", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.0  # cognitive component\n        self.c2 = 2.0  # social component\n        self.w_initial = 0.9  # initial inertia weight\n        self.w_final = 0.4    # final inertia weight\n        self.f_initial = 0.8  # initial differential weight\n        self.cr_initial = 0.9  # initial crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        \n        while evaluations < self.budget:\n            # Adaptive inertia weight calculation\n            self.w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            # Dynamic crossover probability\n            self.cr = self.cr_initial * (1 - evaluations / self.budget)\n            self.f = self.f_initial * (1 - evaluations / self.budget)  # Time-varying differential weight\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Particle Swarm Optimization (PSO) update\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i] if global_best_position is not None else 0))\n\n                if np.random.rand() < 0.15:  # Stochastic velocity reset (changed from 0.1 to 0.15)\n                    velocities[i] = np.random.uniform(-1, 1, self.dim)\n                \n                candidate_position = np.clip(population[i] + velocities[i], lb, ub)\n                candidate_score = func(candidate_position)\n                evaluations += 1\n\n                # Update personal best\n                if candidate_score < personal_best_scores[i]:\n                    personal_best_scores[i] = candidate_score\n                    personal_best_positions[i] = candidate_position\n\n                # Update global best\n                if candidate_score < global_best_score:\n                    global_best_score = candidate_score\n                    global_best_position = candidate_position\n\n            # Differential Evolution (DE) mutation and crossover\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                mutant_vector = np.clip(personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c]), lb, ub)\n                \n                trial_vector = np.copy(personal_best_positions[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == jrand:\n                        trial_vector[j] = mutant_vector[j]\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                # Selection\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Introduced time-varying differential weight to improve balance between exploration and exploitation.", "configspace": "", "generation": 5, "fitness": 0.8106560482017128, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.811 with standard deviation 0.013. And the mean value of best solutions found was 0.145 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "ca809a43-82d3-4ddb-9d7b-adddcbe45b33", "metadata": {"aucs": [0.803143602038404, 0.8002547045417712, 0.8285698380249632], "final_y": [0.14355701086158623, 0.14913047842382454, 0.14361765939357085]}, "mutation_prompt": null}
{"id": "ac211ea4-e635-4376-b9c7-050a4b1ff43a", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.0  # cognitive component\n        self.c2 = 2.0  # social component\n        self.w_initial = 0.9  # initial inertia weight\n        self.w_final = 0.4    # final inertia weight\n        self.f = 0.8   # differential weight\n        self.cr_initial = 0.9  # initial crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        \n        while evaluations < self.budget:\n            # Adaptive inertia weight calculation\n            self.w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Particle Swarm Optimization (PSO) update\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i] if global_best_position is not None else 0))\n\n                if np.random.rand() < 0.2:  # Stochastic velocity reset\n                    velocities[i] = np.random.uniform(-1, 1, self.dim)\n                \n                candidate_position = np.clip(population[i] + velocities[i], lb, ub)\n                candidate_score = func(candidate_position)\n                evaluations += 1\n\n                # Update personal best\n                if candidate_score < personal_best_scores[i]:\n                    personal_best_scores[i] = candidate_score\n                    personal_best_positions[i] = candidate_position\n\n                # Update global best\n                if candidate_score < global_best_score:\n                    global_best_score = candidate_score\n                    global_best_position = candidate_position\n\n            # Differential Evolution (DE) mutation and crossover\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                mutant_vector = np.clip(personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c]), lb, ub)\n                \n                trial_vector = np.copy(personal_best_positions[i])\n                jrand = np.random.randint(self.dim)\n                self.cr = self.cr_initial * (1 - evaluations / self.budget)  # Dynamic crossover probability\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == jrand:\n                        trial_vector[j] = mutant_vector[j]\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                # Selection\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Adjusted crossover probability dynamically based on the iteration ratio to enhance exploration and exploitation balance.", "configspace": "", "generation": 5, "fitness": 0.8044013949829504, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.804 with standard deviation 0.029. And the mean value of best solutions found was 0.146 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "408143cc-1db5-442c-be06-a66447f98cd9", "metadata": {"aucs": [0.8006326707781465, 0.771109708724103, 0.8414618054466017], "final_y": [0.14258466955353233, 0.1524395341497543, 0.14281654556793777]}, "mutation_prompt": null}
{"id": "e0d7ef6f-b854-4141-a4ae-543bce23a05b", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.0  # cognitive component\n        self.c2 = 2.0  # social component\n        self.w_initial = 0.9  # initial inertia weight\n        self.w_final = 0.4    # final inertia weight\n        self.f_initial = 0.5  # initial differential weight, changed from constant 0.8\n        self.f_final = 0.9    # final differential weight\n        self.cr = 0.9  # crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        \n        while evaluations < self.budget:\n            self.w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            self.f = self.f_initial + (self.f_final - self.f_initial) * (evaluations / self.budget)  # Adaptive differential weight\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i] if global_best_position is not None else 0))\n                \n                if np.random.rand() < 0.2:\n                    velocities[i] = np.random.uniform(-1, 1, self.dim)\n                \n                candidate_position = population[i] + velocities[i]\n                chaotic_factor = 4 * r1 * (1 - r1)  # Logistic map for perturbation\n                candidate_position += chaotic_factor * (ub - lb) * 0.05\n                candidate_position = np.clip(candidate_position, lb, ub)\n\n                candidate_score = func(candidate_position)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i]:\n                    personal_best_scores[i] = candidate_score\n                    personal_best_positions[i] = candidate_position\n\n                if candidate_score < global_best_score:\n                    global_best_score = candidate_score\n                    global_best_position = candidate_position\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                mutant_vector = np.clip(personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c]), lb, ub)\n                trial_vector = np.copy(personal_best_positions[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == jrand:\n                        trial_vector[j] = mutant_vector[j]\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Enhance global search by dynamically adjusting differential weight and introducing chaos theory-based perturbations.", "configspace": "", "generation": 5, "fitness": 0.8090398027209279, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.809 with standard deviation 0.052. And the mean value of best solutions found was 0.142 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "408143cc-1db5-442c-be06-a66447f98cd9", "metadata": {"aucs": [0.7358148069769145, 0.8539201441433143, 0.8373844570425552], "final_y": [0.16115240109060935, 0.13507539739714047, 0.12979582535962964]}, "mutation_prompt": null}
{"id": "6f4ddaf0-24ec-49d0-b6b6-f5889ab71264", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50  # initial population size\n        self.population_size = self.initial_population_size  # adaptive population size\n        self.c1 = 2.0  # cognitive component\n        self.c2 = 2.0  # social component\n        self.w_initial = 0.9  # initial inertia weight\n        self.w_final = 0.4    # final inertia weight\n        self.f_initial = 0.8  # initial differential weight\n        self.cr_initial = 0.9  # initial crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        \n        while evaluations < self.budget:\n            # Adaptive inertia weight and differential weight calculation\n            self.w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            self.f = self.f_initial * (1 - evaluations / self.budget)  # Dynamic differential weight\n            self.cr = self.cr_initial * (1 - evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Particle Swarm Optimization (PSO) update\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i] if global_best_position is not None else 0))\n\n                if np.random.rand() < 0.15:  # Stochastic velocity reset\n                    velocities[i] = np.random.uniform(-1, 1, self.dim)\n                \n                candidate_position = np.clip(population[i] + velocities[i], lb, ub)\n                candidate_score = func(candidate_position)\n                evaluations += 1\n\n                # Update personal best\n                if candidate_score < personal_best_scores[i]:\n                    personal_best_scores[i] = candidate_score\n                    personal_best_positions[i] = candidate_position\n\n                # Update global best\n                if candidate_score < global_best_score:\n                    global_best_score = candidate_score\n                    global_best_position = candidate_position\n\n            # Differential Evolution (DE) mutation and crossover\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                mutant_vector = np.clip(personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c]), lb, ub)\n                \n                trial_vector = np.copy(personal_best_positions[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == jrand:\n                        trial_vector[j] = mutant_vector[j]\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                # Selection\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n            # Adapt population size\n            if evaluations < self.budget // 2:\n                self.population_size = int(self.initial_population_size * (1 + 0.5 * (1 - evaluations / (self.budget // 2))))\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Introduced adaptive population size and incorporated local search to refine solutions.", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 50 is out of bounds for axis 0 with size 50').", "error": "IndexError('index 50 is out of bounds for axis 0 with size 50')", "parent_id": "eefb7790-8969-4996-b880-5fc6756a531b", "metadata": {}, "mutation_prompt": null}
{"id": "2398ebe9-d16b-4538-bc4d-50e854d2d8b0", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.0  # cognitive component\n        self.c2 = 2.0  # social component\n        self.w_initial = 0.9  # initial inertia weight\n        self.w_final = 0.4    # final inertia weight\n        self.f = 0.8   # differential weight\n        self.cr = 0.9  # crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        \n        while evaluations < self.budget:\n            self.w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Particle Swarm Optimization (PSO) update\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i] if global_best_position is not None else 0))\n\n                if np.random.rand() < 0.2:\n                    velocities[i] = np.random.uniform(-1, 1, self.dim)\n                \n                candidate_position = np.clip(population[i] + velocities[i], lb, ub)\n                candidate_score = func(candidate_position)\n                evaluations += 1\n\n                # Update personal best\n                if candidate_score < personal_best_scores[i]:\n                    personal_best_scores[i] = candidate_score\n                    personal_best_positions[i] = candidate_position\n\n                # Update global best\n                if candidate_score < global_best_score:\n                    global_best_score = candidate_score\n                    global_best_position = candidate_position\n\n            # Differential Evolution (DE) mutation and crossover\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                # Introduced stochastic adaptive change\n                self.f = np.random.uniform(0.5, 1.0) + np.random.normal(0, 0.1)\n\n                mutant_vector = np.clip(personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c]), lb, ub)\n                \n                trial_vector = np.copy(personal_best_positions[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == jrand:\n                        trial_vector[j] = mutant_vector[j]\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                # Selection\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Introduced adaptive mutation scaling factor with a noise component to enhance robustness against premature convergence.", "configspace": "", "generation": 6, "fitness": 0.8547255885869588, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.855 with standard deviation 0.029. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "91e1e3b0-c4cd-4305-9989-bc9e22282739", "metadata": {"aucs": [0.8198684932866274, 0.8543754732991742, 0.8899327991750748], "final_y": [0.1430787278163813, 0.13119898519993345, 0.11749288918860723]}, "mutation_prompt": null}
{"id": "3867b618-a138-433f-824d-1f6d02a09cd4", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.0  # cognitive component\n        self.c2 = 2.0  # social component\n        self.w_initial = 0.85  # initial inertia weight (changed from 0.9 to 0.85)\n        self.w_final = 0.4    # final inertia weight\n        self.f_initial = 0.8  # initial differential weight\n        self.cr_initial = 0.9  # initial crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        \n        while evaluations < self.budget:\n            # Adaptive inertia weight and differential weight calculation\n            self.w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            self.f = self.f_initial * (1 - evaluations / self.budget)  # Dynamic differential weight\n            self.cr = self.cr_initial * (1 - evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Particle Swarm Optimization (PSO) update\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i] if global_best_position is not None else 0))\n\n                if np.random.rand() < 0.15:  # Stochastic velocity reset (changed from 0.1 to 0.15)\n                    velocities[i] = np.random.uniform(-1, 1, self.dim)\n                \n                candidate_position = np.clip(population[i] + velocities[i], lb, ub)\n                candidate_score = func(candidate_position)\n                evaluations += 1\n\n                # Update personal best\n                if candidate_score < personal_best_scores[i]:\n                    personal_best_scores[i] = candidate_score\n                    personal_best_positions[i] = candidate_position\n\n                # Update global best\n                if candidate_score < global_best_score:\n                    global_best_score = candidate_score\n                    global_best_position = candidate_position\n\n            # Differential Evolution (DE) mutation and crossover\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                mutant_vector = np.clip(personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c]), lb, ub)\n                \n                trial_vector = np.copy(personal_best_positions[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == jrand:\n                        trial_vector[j] = mutant_vector[j]\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                # Selection\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Improved dynamic exploration by adjusting the inertia weight range to better balance exploration and exploitation.", "configspace": "", "generation": 6, "fitness": 0.8363872494440988, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.836 with standard deviation 0.011. And the mean value of best solutions found was 0.134 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "eefb7790-8969-4996-b880-5fc6756a531b", "metadata": {"aucs": [0.8240537065258592, 0.8335088512410035, 0.8515991905654337], "final_y": [0.13251593906979753, 0.13728256041344888, 0.1311276402747239]}, "mutation_prompt": null}
{"id": "8015a922-89f6-42ce-91d1-64782b6ca41e", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.0  # cognitive component\n        self.c2 = 2.0  # social component\n        self.w_initial = 0.9  # initial inertia weight\n        self.w_final = 0.4    # final inertia weight\n        self.f_initial = 0.8  # initial differential weight\n        self.cr_initial = 0.9  # initial crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        \n        while evaluations < self.budget:\n            # Adaptive inertia weight and differential weight calculation\n            self.w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            self.f = self.f_initial * (1 - evaluations / self.budget)  # Dynamic differential weight\n            self.cr = self.cr_initial * (1 - evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Particle Swarm Optimization (PSO) update\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i] if global_best_position is not None else 0))\n\n                if np.random.rand() < 0.2:  # Stochastic velocity reset (changed from 0.15 to 0.2)\n                    velocities[i] = np.random.uniform(-1, 1, self.dim)\n                \n                candidate_position = np.clip(population[i] + velocities[i], lb, ub)\n                candidate_score = func(candidate_position)\n                evaluations += 1\n\n                # Update personal best\n                if candidate_score < personal_best_scores[i]:\n                    personal_best_scores[i] = candidate_score\n                    personal_best_positions[i] = candidate_position\n\n                # Update global best\n                if candidate_score < global_best_score:\n                    global_best_score = candidate_score\n                    global_best_position = candidate_position\n\n            # Differential Evolution (DE) mutation and crossover\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                mutant_vector = np.clip(personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c]), lb, ub)\n                \n                trial_vector = np.copy(personal_best_positions[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == jrand:\n                        trial_vector[j] = mutant_vector[j]\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                # Selection\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Introduced adaptive learning rates and stochastic reset to enhance exploration and convergence.", "configspace": "", "generation": 6, "fitness": 0.8303759891354904, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.830 with standard deviation 0.039. And the mean value of best solutions found was 0.130 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "eefb7790-8969-4996-b880-5fc6756a531b", "metadata": {"aucs": [0.7783461881325185, 0.842080102115085, 0.8707016771588676], "final_y": [0.14010476475600186, 0.12767978062317709, 0.1236770102847522]}, "mutation_prompt": null}
{"id": "97a86a12-d276-4ccf-b4bd-789c827dfcc7", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.0  # cognitive component\n        self.c2 = 2.0  # social component\n        self.w_initial = 0.9  # initial inertia weight\n        self.w_final = 0.4    # final inertia weight\n        self.f_initial = 0.8  # initial differential weight\n        self.cr_initial = 0.9  # initial crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        \n        while evaluations < self.budget:\n            # Adaptive inertia weight and differential weight calculation\n            self.w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            self.f = self.f_initial * (1 - evaluations / self.budget)  # Dynamic differential weight\n            self.cr = self.cr_initial * (1 - evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Particle Swarm Optimization (PSO) update\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i] if global_best_position is not None else 0)) * (1 - evaluations / self.budget)\n\n                if np.random.rand() < 0.15:  # Stochastic velocity reset (changed from 0.1 to 0.15)\n                    velocities[i] = np.random.uniform(-1, 1, self.dim)\n                \n                candidate_position = np.clip(population[i] + velocities[i], lb, ub)\n                candidate_score = func(candidate_position)\n                evaluations += 1\n\n                # Update personal best\n                if candidate_score < personal_best_scores[i]:\n                    personal_best_scores[i] = candidate_score\n                    personal_best_positions[i] = candidate_position\n\n                # Update global best\n                if candidate_score < global_best_score:\n                    global_best_score = candidate_score\n                    global_best_position = candidate_position\n\n            # Differential Evolution (DE) mutation and crossover\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                mutant_vector = np.clip(personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c]), lb, ub)\n                \n                trial_vector = np.copy(personal_best_positions[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == jrand:\n                        trial_vector[j] = mutant_vector[j]\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                # Selection\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Introduced temporal learning factor into velocity update to enhance convergence rate.", "configspace": "", "generation": 6, "fitness": 0.8129028204463618, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.813 with standard deviation 0.020. And the mean value of best solutions found was 0.136 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "eefb7790-8969-4996-b880-5fc6756a531b", "metadata": {"aucs": [0.810778345033051, 0.7897983151185556, 0.838131801187479], "final_y": [0.13336733487352215, 0.14656486993758733, 0.1267496660570293]}, "mutation_prompt": null}
{"id": "0913934d-28ac-4a83-b0ae-4303f9c0346a", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 1.5  # initial cognitive component\n        self.c2_initial = 1.5  # initial social component\n        self.w_initial = 0.9  # initial inertia weight\n        self.w_final = 0.4    # final inertia weight\n        self.f_initial = 0.8  # initial differential weight\n        self.cr_initial = 0.9  # initial crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        \n        while evaluations < self.budget:\n            self.w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            self.f = self.f_initial * (1 - evaluations / self.budget)\n            self.cr = self.cr_initial * (1 - evaluations / self.budget)\n            \n            # Adaptive cognitive and social components\n            self.c1 = self.c1_initial + 0.5 * np.cos(2 * np.pi * evaluations / self.budget)\n            self.c2 = self.c2_initial + 0.5 * np.sin(2 * np.pi * evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i] if global_best_position is not None else 0))\n\n                if np.random.rand() < 0.15:\n                    velocities[i] = np.random.uniform(-1, 1, self.dim)\n                \n                candidate_position = population[i] + velocities[i]\n                candidate_position = np.clip(candidate_position, lb, ub)\n                candidate_score = func(candidate_position)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i]:\n                    personal_best_scores[i] = candidate_score\n                    personal_best_positions[i] = candidate_position\n\n                if candidate_score < global_best_score:\n                    global_best_score = candidate_score\n                    global_best_position = candidate_position\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                mutant_vector = np.clip(personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c]), lb, ub)\n                \n                trial_vector = np.copy(personal_best_positions[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == jrand:\n                        trial_vector[j] = mutant_vector[j]\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Introduced stochastic c1, c2 adaptation and dynamic boundary handling to enhance convergence speed and solution quality.", "configspace": "", "generation": 6, "fitness": 0.843147989000896, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.843 with standard deviation 0.047. And the mean value of best solutions found was 0.134 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "eefb7790-8969-4996-b880-5fc6756a531b", "metadata": {"aucs": [0.7774551948773454, 0.8815001868044404, 0.8704885853209026], "final_y": [0.15084873409236943, 0.12476089037281524, 0.1253016507114274]}, "mutation_prompt": null}
{"id": "e3d0e8ba-7c7c-446c-a771-133cd2858e8d", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.0  # cognitive component\n        self.c2 = 2.0  # social component\n        self.w_initial = 0.9  # initial inertia weight\n        self.w_final = 0.4    # final inertia weight\n        self.f = 0.8   # differential weight\n        self.cr = 0.9  # crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        \n        while evaluations < self.budget:\n            # Adaptive inertia weight calculation\n            self.w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Particle Swarm Optimization (PSO) update\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i] if global_best_position is not None else 0))\n\n                if np.random.rand() < 0.2:  # Stochastic velocity reset (changed from 0.15 to 0.2)\n                    velocities[i] = np.random.uniform(-1, 1, self.dim)\n                \n                candidate_position = np.clip(population[i] + velocities[i], lb, ub)\n                candidate_score = func(candidate_position)\n                evaluations += 1\n\n                # Update personal best\n                if candidate_score < personal_best_scores[i]:\n                    personal_best_scores[i] = candidate_score\n                    personal_best_positions[i] = candidate_position\n\n                # Update global best\n                if candidate_score < global_best_score:\n                    global_best_score = candidate_score\n                    global_best_position = candidate_position\n\n            # Differential Evolution (DE) mutation and crossover\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                # Introduced stochastic adaptive change\n                self.f = np.random.uniform(0.5, 1.0)\n\n                mutant_vector = np.clip(personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c]), lb, ub)\n                \n                trial_vector = np.copy(personal_best_positions[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < (self.cr * (1 - evaluations / self.budget)) or j == jrand:\n                        trial_vector[j] = mutant_vector[j]\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                # Selection\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Introduced adaptive crossover probability (cr) to balance exploration and exploitation.", "configspace": "", "generation": 6, "fitness": 0.8365268432646052, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.837 with standard deviation 0.018. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "91e1e3b0-c4cd-4305-9989-bc9e22282739", "metadata": {"aucs": [0.8212868583255182, 0.8258993020093635, 0.8623943694589342], "final_y": [0.13948388920284116, 0.12919259412183304, 0.12898820443533177]}, "mutation_prompt": null}
{"id": "fe6f2cce-1085-493d-9bf4-71756ea1a29e", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.0  # cognitive component\n        self.c2 = 2.0  # social component\n        self.w_initial = 0.9  # initial inertia weight\n        self.w_final = 0.4    # final inertia weight\n        self.f_initial = 0.8  # initial differential weight\n        self.cr_initial = 0.9  # initial crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        \n        while evaluations < self.budget:\n            # Adaptive inertia weight and differential weight calculation\n            self.w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            self.f = self.f_initial * (1 - evaluations / self.budget)  # Dynamic differential weight\n            self.cr = self.cr_initial * (1 - evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Particle Swarm Optimization (PSO) update\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i] if global_best_position is not None else 0))\n\n                if np.random.rand() < 0.20:  # Stochastic velocity reset (changed from 0.15 to 0.20)\n                    velocities[i] = np.random.uniform(-1, 1, self.dim)\n                \n                candidate_position = np.clip(population[i] + velocities[i], lb, ub)\n                candidate_score = func(candidate_position)\n                evaluations += 1\n\n                # Update personal best\n                if candidate_score < personal_best_scores[i]:\n                    personal_best_scores[i] = candidate_score\n                    personal_best_positions[i] = candidate_position\n\n                # Update global best\n                if candidate_score < global_best_score:\n                    global_best_score = candidate_score\n                    global_best_position = candidate_position\n\n            # Differential Evolution (DE) mutation and crossover\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                mutant_vector = np.clip(personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c]), lb, ub)\n                \n                trial_vector = np.copy(personal_best_positions[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == jrand:\n                        trial_vector[j] = mutant_vector[j]\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                # Selection\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Enhanced exploration by increasing the stochastic velocity reset probability to 0.20 to diversify search.", "configspace": "", "generation": 6, "fitness": 0.8284169009430579, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.828 with standard deviation 0.024. And the mean value of best solutions found was 0.137 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "eefb7790-8969-4996-b880-5fc6756a531b", "metadata": {"aucs": [0.814947143968086, 0.8078641651974564, 0.8624393936636312], "final_y": [0.13959867762015843, 0.14377518148833213, 0.12900669957964372]}, "mutation_prompt": null}
{"id": "51931a04-7c01-45ab-984a-607840c547b8", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.0  # cognitive component\n        self.c2 = 2.0  # social component\n        self.w_initial = 0.9  # initial inertia weight\n        self.w_final = 0.4    # final inertia weight\n        self.f = 0.8   # differential weight\n        self.cr_initial = 0.9  # initial crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        \n        while evaluations < self.budget:\n            # Adaptive inertia weight calculation\n            self.w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Particle Swarm Optimization (PSO) update\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i] if global_best_position is not None else 0))\n\n                if np.random.rand() < 0.2:  # Stochastic velocity reset (changed from 0.15 to 0.2)\n                    velocities[i] = np.random.uniform(-1, 1, self.dim)\n                \n                candidate_position = np.clip(population[i] + velocities[i], lb, ub)\n                candidate_score = func(candidate_position)\n                evaluations += 1\n\n                # Update personal best\n                if candidate_score < personal_best_scores[i]:\n                    personal_best_scores[i] = candidate_score\n                    personal_best_positions[i] = candidate_position\n\n                # Update global best\n                if candidate_score < global_best_score:\n                    global_best_score = candidate_score\n                    global_best_position = candidate_position\n\n            # Differential Evolution (DE) mutation and crossover\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                # Introduced stochastic adaptive change\n                self.f = np.random.uniform(0.5, 1.0)\n\n                mutant_vector = np.clip(personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c]), lb, ub)\n                \n                # Adaptive crossover probability\n                self.cr = self.cr_initial * (1 - evaluations / self.budget)\n                \n                trial_vector = np.copy(personal_best_positions[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == jrand:\n                        trial_vector[j] = mutant_vector[j]\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                # Selection\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Improved exploration by incorporating adaptive crossover probability based on convergence.", "configspace": "", "generation": 6, "fitness": 0.8343368617039922, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.834 with standard deviation 0.010. And the mean value of best solutions found was 0.134 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "91e1e3b0-c4cd-4305-9989-bc9e22282739", "metadata": {"aucs": [0.8211658021833298, 0.8361256996654802, 0.8457190832631668], "final_y": [0.13704630298832676, 0.13166996630353134, 0.1338932244365425]}, "mutation_prompt": null}
{"id": "573b3c67-9992-414f-868b-efd3031ebeb6", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.0  # cognitive component\n        self.c2 = 2.0  # social component\n        self.w_initial = 0.9  # initial inertia weight\n        self.w_final = 0.4    # final inertia weight\n        self.f_initial = 0.8  # initial differential weight\n        self.cr_initial = 0.9  # initial crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        \n        while evaluations < self.budget:\n            # Adaptive inertia weight and differential weight calculation\n            self.w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            self.f = self.f_initial * (1 - evaluations / self.budget)  # Dynamic differential weight\n            self.cr = self.cr_initial * (1 - evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Particle Swarm Optimization (PSO) update\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocity_scale = 1 + 0.5 * np.sin(np.pi * evaluations / self.budget)  # Adaptive velocity scaling\n                velocities[i] = (velocity_scale * self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i] if global_best_position is not None else 0))\n\n                if np.random.rand() < 0.15:  # Stochastic velocity reset (changed from 0.1 to 0.15)\n                    velocities[i] = np.random.uniform(-1, 1, self.dim)\n                \n                candidate_position = np.clip(population[i] + velocities[i], lb, ub)\n                candidate_score = func(candidate_position)\n                evaluations += 1\n\n                # Update personal best\n                if candidate_score < personal_best_scores[i]:\n                    personal_best_scores[i] = candidate_score\n                    personal_best_positions[i] = candidate_position\n\n                # Update global best\n                if candidate_score < global_best_score:\n                    global_best_score = candidate_score\n                    global_best_position = candidate_position\n\n            # Differential Evolution (DE) mutation and crossover\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                f_adaptive = self.f * (1 + 0.3 * np.sin(2 * np.pi * evaluations / self.budget))  # Enhanced DE mutation\n                mutant_vector = np.clip(personal_best_positions[a] + f_adaptive * (personal_best_positions[b] - personal_best_positions[c]), lb, ub)\n                \n                trial_vector = np.copy(personal_best_positions[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == jrand:\n                        trial_vector[j] = mutant_vector[j]\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                # Selection\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Optimize exploration and convergence by introducing adaptive velocity scaling and enhancing DE mutation strategy.", "configspace": "", "generation": 6, "fitness": 0.8264384530040575, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.826 with standard deviation 0.037. And the mean value of best solutions found was 0.136 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "eefb7790-8969-4996-b880-5fc6756a531b", "metadata": {"aucs": [0.7891405185655693, 0.8127859805893909, 0.8773888598572123], "final_y": [0.14692887988523873, 0.13929477787800937, 0.12253393665524104]}, "mutation_prompt": null}
{"id": "bd233598-de2f-420e-ba8f-6d0b7a6853da", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.0  # cognitive component\n        self.c2 = 2.0  # social component\n        self.w_initial = 0.9  # initial inertia weight\n        self.w_final = 0.4    # final inertia weight\n        self.f = 0.8   # differential weight\n        self.cr = 0.9  # crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        \n        while evaluations < self.budget:\n            self.w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Particle Swarm Optimization (PSO) update\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i] if global_best_position is not None else 0))\n\n                if np.random.rand() < 0.2:\n                    velocities[i] = np.random.uniform(-1, 1, self.dim)\n                \n                candidate_position = np.clip(population[i] + velocities[i], lb, ub)\n                candidate_score = func(candidate_position)\n                evaluations += 1\n\n                # Update personal best\n                if candidate_score < personal_best_scores[i]:\n                    personal_best_scores[i] = candidate_score\n                    personal_best_positions[i] = candidate_position\n\n                # Update global best\n                if candidate_score < global_best_score:\n                    global_best_score = candidate_score\n                    global_best_position = candidate_position\n\n            # Differential Evolution (DE) mutation and crossover\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                # Introduced stochastic adaptive change\n                self.f = np.random.uniform(0.5, 1.0) + np.random.normal(0, 0.2)\n\n                mutant_vector = np.clip(personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c]), lb, ub)\n                \n                trial_vector = np.copy(personal_best_positions[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == jrand:\n                        trial_vector[j] = mutant_vector[j]\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                # Selection\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Enhanced the adaptive mutation scaling factor by increasing variance in the noise component to further improve robustness against premature convergence.", "configspace": "", "generation": 7, "fitness": 0.8310874547195234, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.831 with standard deviation 0.012. And the mean value of best solutions found was 0.137 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "2398ebe9-d16b-4538-bc4d-50e854d2d8b0", "metadata": {"aucs": [0.8180261794803528, 0.8279505774517442, 0.8472856072264731], "final_y": [0.14176534836178678, 0.135390368539259, 0.133231575933633]}, "mutation_prompt": null}
{"id": "5cde9a52-5f1e-4131-8c2a-8e4ab83a9743", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 1.5  # initial cognitive component\n        self.c2_initial = 1.5  # initial social component\n        self.w_initial = 0.9  # initial inertia weight\n        self.w_final = 0.4    # final inertia weight\n        self.f_initial = 0.8  # initial differential weight\n        self.cr_initial = 0.9  # initial crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        \n        while evaluations < self.budget:\n            # Modified: Introduced oscillation in inertia weight\n            self.w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget) * (0.5 + 0.5 * np.cos(2 * np.pi * evaluations / self.budget))\n            self.f = self.f_initial * (1 - evaluations / self.budget)\n            self.cr = self.cr_initial * (1 - evaluations / self.budget)\n            \n            # Adaptive cognitive and social components\n            self.c1 = self.c1_initial + 0.5 * np.cos(2 * np.pi * evaluations / self.budget)\n            self.c2 = self.c2_initial + 0.5 * np.sin(2 * np.pi * evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i] if global_best_position is not None else 0))\n\n                if np.random.rand() < 0.15:\n                    velocities[i] = np.random.uniform(-1, 1, self.dim)\n                \n                candidate_position = population[i] + velocities[i]\n                candidate_position = np.clip(candidate_position, lb, ub)\n                candidate_score = func(candidate_position)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i]:\n                    personal_best_scores[i] = candidate_score\n                    personal_best_positions[i] = candidate_position\n\n                if candidate_score < global_best_score:\n                    global_best_score = candidate_score\n                    global_best_position = candidate_position\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                mutant_vector = np.clip(personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c]), lb, ub)\n                \n                trial_vector = np.copy(personal_best_positions[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == jrand:\n                        trial_vector[j] = mutant_vector[j]\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Introduced inertia weight oscillation to enhance exploration and exploitation balance.", "configspace": "", "generation": 7, "fitness": 0.8264109229449081, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.826 with standard deviation 0.009. And the mean value of best solutions found was 0.134 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "0913934d-28ac-4a83-b0ae-4303f9c0346a", "metadata": {"aucs": [0.8251363164113403, 0.8164973443119001, 0.837599108111484], "final_y": [0.13104879514585732, 0.133597510854214, 0.13828294808290797]}, "mutation_prompt": null}
{"id": "62f6b34c-c538-4a8a-8431-2156cc9a3ab8", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 1.5  # initial cognitive component\n        self.c2_initial = 1.5  # initial social component\n        self.w_initial = 0.9  # initial inertia weight\n        self.w_final = 0.4    # final inertia weight\n        self.f_initial = 0.8  # initial differential weight\n        self.cr_initial = 0.9  # initial crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        \n        while evaluations < self.budget:\n            # Adaptive inertia weight scaling\n            self.w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)**2\n            self.f = self.f_initial * (1 - evaluations / self.budget)\n            self.cr = self.cr_initial * (1 - evaluations / self.budget)\n\n            self.c1 = self.c1_initial + 0.5 * np.cos(2 * np.pi * evaluations / self.budget)\n            self.c2 = self.c2_initial + 0.5 * np.sin(2 * np.pi * evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i] if global_best_position is not None else 0))\n\n                # Random velocity perturbation\n                if np.random.rand() < 0.15:\n                    velocities[i] += np.random.normal(0, 0.1, self.dim)\n                \n                candidate_position = population[i] + velocities[i]\n                candidate_position = np.clip(candidate_position, lb, ub)\n                candidate_score = func(candidate_position)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i]:\n                    personal_best_scores[i] = candidate_score\n                    personal_best_positions[i] = candidate_position\n\n                if candidate_score < global_best_score:\n                    global_best_score = candidate_score\n                    global_best_position = candidate_position\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                mutant_vector = np.clip(personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c]), lb, ub)\n                \n                trial_vector = np.copy(personal_best_positions[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == jrand:\n                        trial_vector[j] = mutant_vector[j]\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Introduced adaptive inertia scaling and random velocity perturbation to balance exploration and exploitation.", "configspace": "", "generation": 7, "fitness": 0.8429463538840455, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.843 with standard deviation 0.012. And the mean value of best solutions found was 0.136 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0913934d-28ac-4a83-b0ae-4303f9c0346a", "metadata": {"aucs": [0.83697970348434, 0.8595371833677552, 0.8323221748000409], "final_y": [0.13623502946409405, 0.13525122944048984, 0.13608963780178573]}, "mutation_prompt": null}
{"id": "09de97ab-a8ea-4181-a0d3-ea6ae2b029b2", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.c1 = 2.0  # cognitive component\n        self.c2 = 2.0  # social component\n        self.w_initial = 0.9  # initial inertia weight\n        self.w_final = 0.4    # final inertia weight\n        self.f = 0.8   # differential weight\n        self.cr = 0.9  # crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.initial_population_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        \n        while evaluations < self.budget:\n            self.w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n\n            for i in range(population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Particle Swarm Optimization (PSO) update\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i] if global_best_position is not None else 0))\n                # Enhanced velocity perturbation\n                if np.random.rand() < 0.3:\n                    velocities[i] += np.random.normal(0, 0.05, self.dim) \n                \n                candidate_position = np.clip(population[i] + velocities[i], lb, ub)\n                candidate_score = func(candidate_position)\n                evaluations += 1\n\n                # Update personal best\n                if candidate_score < personal_best_scores[i]:\n                    personal_best_scores[i] = candidate_score\n                    personal_best_positions[i] = candidate_position\n\n                # Update global best\n                if candidate_score < global_best_score:\n                    global_best_score = candidate_score\n                    global_best_position = candidate_position\n\n            # Differential Evolution (DE) mutation and crossover\n            for i in range(population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                # Introduced stochastic adaptive change\n                self.f = np.random.uniform(0.5, 1.0) + np.random.normal(0, 0.1)\n\n                mutant_vector = np.clip(personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c]), lb, ub)\n                \n                trial_vector = np.copy(personal_best_positions[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == jrand:\n                        trial_vector[j] = mutant_vector[j]\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                # Selection\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n            # Dynamic population size adjustment\n            if evaluations % (self.budget // 10) == 0:\n                population_size = max(10, population_size - 5)\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Introduced dynamic population size adjustment and enhanced velocity perturbation for improved exploration-exploitation balance.", "configspace": "", "generation": 7, "fitness": 0.8439279377768664, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.844 with standard deviation 0.034. And the mean value of best solutions found was 0.132 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "2398ebe9-d16b-4538-bc4d-50e854d2d8b0", "metadata": {"aucs": [0.802519848527882, 0.8437061288511252, 0.8855578359515921], "final_y": [0.14808474858179466, 0.12708877918391148, 0.1222736803521246]}, "mutation_prompt": null}
{"id": "41feac38-db01-4066-820f-3069270b0756", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.0  # cognitive component\n        self.c2 = 2.0  # social component\n        self.w_initial = 0.9  # initial inertia weight\n        self.w_final = 0.4    # final inertia weight\n        self.f = 0.8   # differential weight\n        self.cr = 0.9  # crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        \n        while evaluations < self.budget:\n            self.w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            self.cr = 0.9 - 0.5 * (evaluations / self.budget)  # Dynamic crossover probability\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Particle Swarm Optimization (PSO) update\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i] if global_best_position is not None else 0))\n\n                if np.random.rand() < 0.2:\n                    velocities[i] = np.random.uniform(-1, 1, self.dim)\n                \n                candidate_position = np.clip(population[i] + velocities[i], lb, ub)\n                candidate_score = func(candidate_position)\n                evaluations += 1\n\n                # Update personal best\n                if candidate_score < personal_best_scores[i]:\n                    personal_best_scores[i] = candidate_score\n                    personal_best_positions[i] = candidate_position\n\n                # Update global best\n                if candidate_score < global_best_score:\n                    global_best_score = candidate_score\n                    global_best_position = candidate_position\n\n            # Differential Evolution (DE) mutation and crossover\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                # Introduced stochastic adaptive change\n                self.f = np.random.uniform(0.5, 1.0) + np.random.normal(0, 0.1)\n\n                mutant_vector = np.clip(personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c]), lb, ub)\n                \n                trial_vector = np.copy(personal_best_positions[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == jrand:\n                        trial_vector[j] = mutant_vector[j]\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                # Selection\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Introduced a dynamic crossover probability adaptation to better balance exploration and exploitation over time.", "configspace": "", "generation": 7, "fitness": 0.830896164754121, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.831 with standard deviation 0.017. And the mean value of best solutions found was 0.141 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "2398ebe9-d16b-4538-bc4d-50e854d2d8b0", "metadata": {"aucs": [0.8150014913868374, 0.8542886312013055, 0.8233983716742197], "final_y": [0.1440470729215394, 0.13681768998959842, 0.1406394309589729]}, "mutation_prompt": null}
{"id": "2144da25-8b51-47da-ae7c-cdad3e59c452", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.w_final = 0.4\n        self.f_initial = 0.8\n        self.cr_initial = 0.9\n        self.velocity_bounds = 0.1  # New: adaptive velocity bound factor\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.velocity_bounds, self.velocity_bounds, (self.population_size, self.dim))  # Changed: initialize to smaller range\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        \n        while evaluations < self.budget:\n            self.w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            self.f = self.f_initial * (1 - evaluations / self.budget)\n            self.cr = self.cr_initial * np.random.rand()  # Changed: dynamic crossover probability\n            \n            self.c1 = self.c1_initial + 0.5 * np.cos(2 * np.pi * evaluations / self.budget)\n            self.c2 = self.c2_initial + 0.5 * np.sin(2 * np.pi * evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i] if global_best_position is not None else 0))\n\n                if np.random.rand() < 0.15:\n                    velocities[i] = np.random.uniform(-self.velocity_bounds, self.velocity_bounds, self.dim)  # Changed: constrained velocity\n\n                candidate_position = population[i] + velocities[i]\n                candidate_position = np.clip(candidate_position, lb, ub)\n                candidate_score = func(candidate_position)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i]:\n                    personal_best_scores[i] = candidate_score\n                    personal_best_positions[i] = candidate_position\n\n                if candidate_score < global_best_score:\n                    global_best_score = candidate_score\n                    global_best_position = candidate_position\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                mutant_vector = np.clip(personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c]), lb, ub)\n                \n                trial_vector = np.copy(personal_best_positions[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == jrand:\n                        trial_vector[j] = mutant_vector[j]\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Enhanced hybrid PSODE with adaptive velocity bounds and dynamic crossover probability to improve exploration and exploitation balance.", "configspace": "", "generation": 7, "fitness": 0.8438665175230952, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.844 with standard deviation 0.012. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "0913934d-28ac-4a83-b0ae-4303f9c0346a", "metadata": {"aucs": [0.8329658593153532, 0.8388132368747849, 0.8598204563791473], "final_y": [0.12198622790110014, 0.12745919091457103, 0.1327183790659623]}, "mutation_prompt": null}
{"id": "533af4ac-81fd-4930-9818-4359f0ca995c", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 1.5  # initial cognitive component\n        self.c2_initial = 1.5  # initial social component\n        self.w_initial = 0.9  # initial inertia weight\n        self.w_final = 0.4    # final inertia weight\n        self.f_initial = 0.8  # initial differential weight\n        self.cr_initial = 0.9  # initial crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        \n        while evaluations < self.budget:\n            self.w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            self.f = self.f_initial * (1 - evaluations / self.budget)\n            self.cr = self.cr_initial * (1 - evaluations / self.budget)\n            \n            # Adaptive cognitive and social components\n            self.c1 = self.c1_initial + 0.5 * np.cos(2 * np.pi * evaluations / self.budget)\n            self.c2 = self.c2_initial + 0.5 * np.sin(2 * np.pi * evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i] if global_best_position is not None else 0))\n\n                if np.random.rand() < 0.15:\n                    velocities[i] = np.random.uniform(-1, 1, self.dim)\n                \n                candidate_position = population[i] + velocities[i]\n                candidate_position = np.clip(candidate_position, lb, ub)\n                candidate_score = func(candidate_position)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i]:\n                    personal_best_scores[i] = candidate_score\n                    personal_best_positions[i] = candidate_position\n\n                if candidate_score < global_best_score:\n                    global_best_score = candidate_score\n                    global_best_position = candidate_position\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                # Change: Randomly select between original and new mutation strategy\n                if np.random.rand() < 0.5:\n                    mutant_vector = np.clip(personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c]), lb, ub)\n                else:\n                    mutant_vector = np.clip(population[a] + self.f * (population[b] - population[c]), lb, ub)\n\n                trial_vector = np.copy(personal_best_positions[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == jrand:\n                        trial_vector[j] = mutant_vector[j]\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Introduced a random selection mechanism between mutation strategies to enhance exploration capability.", "configspace": "", "generation": 7, "fitness": 0.831015008297103, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.831 with standard deviation 0.019. And the mean value of best solutions found was 0.135 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "0913934d-28ac-4a83-b0ae-4303f9c0346a", "metadata": {"aucs": [0.8048358891184864, 0.8378252235369887, 0.8503839122358336], "final_y": [0.14111077792475002, 0.12957014122021904, 0.1342273520323234]}, "mutation_prompt": null}
{"id": "5050adb8-55de-4dd7-9ef7-cd3248f9e9b8", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.0  # cognitive component\n        self.c2 = 2.0  # social component\n        self.w_initial = 0.9  # initial inertia weight\n        self.w_final = 0.4    # final inertia weight\n        self.f = 0.8   # differential weight\n        self.cr = 0.9  # crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        \n        while evaluations < self.budget:\n            self.w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Particle Swarm Optimization (PSO) update\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i] if global_best_position is not None else 0))\n\n                if np.random.rand() < 0.2:\n                    velocities[i] = np.random.uniform(-1, 1, self.dim)\n                \n                candidate_position = np.clip(population[i] + velocities[i], lb, ub)\n                candidate_score = func(candidate_position)\n                evaluations += 1\n\n                # Update personal best\n                if candidate_score < personal_best_scores[i]:\n                    personal_best_scores[i] = candidate_score\n                    personal_best_positions[i] = candidate_position\n\n                # Update global best\n                if candidate_score < global_best_score:\n                    global_best_score = candidate_score\n                    global_best_position = candidate_position\n\n            # Differential Evolution (DE) mutation and crossover\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                # Introduced stochastic adaptive change\n                self.f = np.random.uniform(0.5, 1.0) + np.random.normal(0, 0.1)\n\n                mutant_vector = np.clip(personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c]), lb, ub)\n                \n                trial_vector = np.copy(personal_best_positions[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == jrand:\n                        trial_vector[j] = mutant_vector[j]\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                # Selection\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n            # Local Search Intensification\n            if np.random.rand() < 0.1 and global_best_position is not None:\n                refinement_vector = global_best_position + np.random.uniform(-0.01, 0.01, self.dim)\n                refinement_vector = np.clip(refinement_vector, lb, ub)\n                refinement_score = func(refinement_vector)\n                evaluations += 1\n                if refinement_score < global_best_score:\n                    global_best_score = refinement_score\n                    global_best_position = refinement_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Introduced local search intensification strategy based on global best to enhance convergence accuracy.", "configspace": "", "generation": 7, "fitness": 0.8293483142418875, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.829 with standard deviation 0.031. And the mean value of best solutions found was 0.139 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "2398ebe9-d16b-4538-bc4d-50e854d2d8b0", "metadata": {"aucs": [0.7942238817026562, 0.8249247341095549, 0.8688963269134512], "final_y": [0.14378214867866357, 0.14218295712816909, 0.13222378491866105]}, "mutation_prompt": null}
{"id": "56fda1f3-e553-43e6-ad2c-1b747e2c7a9c", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.0  # cognitive component\n        self.c2 = 2.0  # social component\n        self.w_initial = 0.9  # initial inertia weight\n        self.w_final = 0.4    # final inertia weight\n        self.f = 0.8   # differential weight\n        self.cr = 0.9  # crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        \n        while evaluations < self.budget:\n            self.w = self.w_initial - (self.w_initial - self.w_final) * ((evaluations + np.random.normal(0, 0.1)) / self.budget)  # Changed line 21\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Particle Swarm Optimization (PSO) update\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i] if global_best_position is not None else 0))\n\n                if np.random.rand() < 0.2:\n                    velocities[i] = np.random.uniform(-1, 1, self.dim)\n                \n                candidate_position = np.clip(population[i] + velocities[i], lb, ub)\n                candidate_score = func(candidate_position)\n                evaluations += 1\n\n                # Update personal best\n                if candidate_score < personal_best_scores[i]:\n                    personal_best_scores[i] = candidate_score\n                    personal_best_positions[i] = candidate_position\n\n                # Update global best\n                if candidate_score < global_best_score:\n                    global_best_score = candidate_score\n                    global_best_position = candidate_position\n\n            # Differential Evolution (DE) mutation and crossover\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                # Introduced stochastic adaptive change\n                self.f = np.random.uniform(0.5, 1.0) + np.random.normal(0, 0.1)\n\n                mutant_vector = np.clip(personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c]), lb, ub)\n                \n                trial_vector = np.copy(personal_best_positions[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < (self.cr + np.random.normal(0, 0.05)) or j == jrand:  # Changed line 63\n                        trial_vector[j] = mutant_vector[j]\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                # Selection\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Introduced noise in crossover probability and adaptive inertia weights for enhanced exploration.", "configspace": "", "generation": 7, "fitness": 0.8070233374100741, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.807 with standard deviation 0.016. And the mean value of best solutions found was 0.144 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "2398ebe9-d16b-4538-bc4d-50e854d2d8b0", "metadata": {"aucs": [0.7885279333607268, 0.8267272343108092, 0.8058148445586866], "final_y": [0.15077724242011736, 0.13972879816190498, 0.14187041149106072]}, "mutation_prompt": null}
{"id": "c4ab8a78-8fd8-45f4-9c5e-d5e9bd238ef6", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 1.5  # initial cognitive component\n        self.c2_initial = 1.5  # initial social component\n        self.w_initial = 0.9  # initial inertia weight\n        self.w_final = 0.4    # final inertia weight\n        self.f_initial = 0.8  # initial differential weight\n        self.cr_initial = 0.9  # initial crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        \n        while evaluations < self.budget:\n            self.w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            self.f = self.f_initial * (1 - evaluations / self.budget)\n            # Modification: Introduce adaptive crossover probability using sinusoidal pattern\n            self.cr = self.cr_initial * (1 - evaluations / self.budget) + 0.1 * np.sin(2 * np.pi * evaluations / self.budget)\n            \n            # Adaptive cognitive and social components\n            self.c1 = self.c1_initial + 0.5 * np.cos(2 * np.pi * evaluations / self.budget)\n            self.c2 = self.c2_initial + 0.5 * np.sin(2 * np.pi * evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i] if global_best_position is not None else 0))\n\n                if np.random.rand() < 0.15:\n                    velocities[i] = np.random.uniform(-1, 1, self.dim)\n                \n                candidate_position = population[i] + velocities[i]\n                candidate_position = np.clip(candidate_position, lb, ub)\n                candidate_score = func(candidate_position)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i]:\n                    personal_best_scores[i] = candidate_score\n                    personal_best_positions[i] = candidate_position\n\n                if candidate_score < global_best_score:\n                    global_best_score = candidate_score\n                    global_best_position = candidate_position\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                mutant_vector = np.clip(personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c]), lb, ub)\n                \n                trial_vector = np.copy(personal_best_positions[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == jrand:\n                        trial_vector[j] = mutant_vector[j]\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Enhanced exploration with dynamic adjustment of crossover probability to improve diversity and solution quality.", "configspace": "", "generation": 7, "fitness": 0.8313670830993963, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.831 with standard deviation 0.010. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "0913934d-28ac-4a83-b0ae-4303f9c0346a", "metadata": {"aucs": [0.8378383090011792, 0.817629126199689, 0.8386338140973211], "final_y": [0.11897416234498304, 0.14070995783902496, 0.13353688931098318]}, "mutation_prompt": null}
{"id": "19492e50-f98a-4b2e-8c22-589c9733f6bb", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.c1_initial = 2.0  # initial cognitive component\n        self.c2_initial = 2.0  # initial social component\n        self.w_initial = 0.9\n        self.w_final = 0.4\n        self.f_initial = 0.8\n        self.cr = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.initial_population_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            self.w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            self.c1 = self.c1_initial - (self.c1_initial - 1.0) * (evaluations / self.budget)\n            self.c2 = self.c2_initial + (2.5 - self.c2_initial) * (evaluations / self.budget)\n\n            for i in range(population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # PSO update\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i] if global_best_position is not None else 0))\n                \n                if np.random.rand() < 0.3:\n                    velocities[i] += np.random.normal(0, 0.1, self.dim)\n                \n                candidate_position = np.clip(population[i] + velocities[i], lb, ub)\n                candidate_score = func(candidate_position)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i]:\n                    personal_best_scores[i] = candidate_score\n                    personal_best_positions[i] = candidate_position\n\n                if candidate_score < global_best_score:\n                    global_best_score = candidate_score\n                    global_best_position = candidate_position\n\n            # DE mutation and crossover\n            for i in range(population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                self.f = self.f_initial + np.random.uniform(-0.2, 0.2)\n                mutant_vector = np.clip(personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c]), lb, ub)\n                \n                trial_vector = np.copy(personal_best_positions[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == jrand:\n                        trial_vector[j] = mutant_vector[j]\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n            if evaluations % (self.budget // 10) == 0:\n                population_size = max(10, population_size - 5)\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Enhanced HybridPSODE with adaptive learning rates, modified differential weight and improved diversity via mutation.", "configspace": "", "generation": 8, "fitness": 0.8111014861074892, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.811 with standard deviation 0.030. And the mean value of best solutions found was 0.138 (0. is the best) with standard deviation 0.016.", "error": "", "parent_id": "09de97ab-a8ea-4181-a0d3-ea6ae2b029b2", "metadata": {"aucs": [0.7724691532097581, 0.8140720299000581, 0.8467632752126513], "final_y": [0.15937455130832145, 0.13244679606308107, 0.12207684182883294]}, "mutation_prompt": null}
{"id": "33cce2ff-2f25-49ca-ba74-0151707433b3", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.final_population_size = 30  # New: adaptive population size\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.w_final = 0.4\n        self.f_initial = 0.8\n        self.cr_initial = 0.9\n        self.velocity_bounds = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.initial_population_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-self.velocity_bounds, self.velocity_bounds, (population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        \n        while evaluations < self.budget:\n            population_size = int(self.final_population_size + (self.initial_population_size - self.final_population_size) * (1 - evaluations / self.budget))  # New: adaptive population size\n            self.w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            self.f = self.f_initial * (1 - evaluations / self.budget)\n            self.cr = self.cr_initial * np.random.rand()\n            \n            self.c1 = self.c1_initial + 0.5 * np.cos(2 * np.pi * evaluations / self.budget)\n            self.c2 = self.c2_initial + 0.5 * np.sin(2 * np.pi * evaluations / self.budget)\n\n            for i in range(population_size):  # Changed: use adaptive population size\n                if evaluations >= self.budget:\n                    break\n\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i] if global_best_position is not None else 0))\n\n                if np.random.rand() < 0.15:\n                    velocities[i] = np.random.uniform(-self.velocity_bounds, self.velocity_bounds, self.dim)\n\n                candidate_position = population[i] + velocities[i]\n                candidate_position = np.clip(candidate_position, lb, ub)\n                candidate_score = func(candidate_position)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i]:\n                    personal_best_scores[i] = candidate_score\n                    personal_best_positions[i] = candidate_position\n\n                if candidate_score < global_best_score:\n                    global_best_score = candidate_score\n                    global_best_position = candidate_position\n\n            for i in range(population_size):  # Changed: use adaptive population size\n                if evaluations >= self.budget:\n                    break\n                \n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                mutant_vector = np.clip(personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c]), lb, ub)\n                \n                trial_vector = np.copy(personal_best_positions[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == jrand:\n                        trial_vector[j] = mutant_vector[j]\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Hybrid PSODE with adaptive population resizing and velocity adjustment for enhanced convergence speed and solution accuracy.", "configspace": "", "generation": 8, "fitness": 0.8282832577027435, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.828 with standard deviation 0.015. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "2144da25-8b51-47da-ae7c-cdad3e59c452", "metadata": {"aucs": [0.8119187447945937, 0.8255968170478407, 0.8473342112657962], "final_y": [0.12980647892925157, 0.12852626792688893, 0.13382211300480684]}, "mutation_prompt": null}
{"id": "7d29883f-bb3f-494c-8da7-340d1a729e7e", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.w_final = 0.4\n        self.f_initial = 0.8\n        self.cr_initial = 0.9\n        self.velocity_bounds = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.velocity_bounds, self.velocity_bounds, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        \n        while evaluations < self.budget:\n            self.w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            self.f = self.f_initial * (1 - evaluations / self.budget)\n            self.cr = self.cr_initial * np.random.rand()\n            \n            self.c1 = self.c1_initial + 0.5 * np.cos(2 * np.pi * evaluations / self.budget)\n            self.c2 = self.c2_initial + 0.5 * np.sin(2 * np.pi * evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i] if global_best_position is not None else 0))\n\n                if np.random.rand() < 0.15:\n                    velocities[i] = np.random.uniform(-self.velocity_bounds, self.velocity_bounds, self.dim)\n\n                candidate_position = population[i] + velocities[i]\n                candidate_position = np.clip(candidate_position, lb, ub)\n                candidate_score = func(candidate_position)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i]:\n                    personal_best_scores[i] = candidate_score\n                    personal_best_positions[i] = candidate_position\n\n                if candidate_score < global_best_score:\n                    global_best_score = candidate_score\n                    global_best_position = candidate_position\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                mutant_vector = np.clip(personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c]), lb, ub)\n                \n                trial_vector = np.copy(personal_best_positions[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == jrand:\n                        trial_vector[j] = mutant_vector[j]\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Adaptive inertia weight adjustment and mutation strategy enhance exploration and exploitation balance.", "configspace": "", "generation": 8, "fitness": 0.8452038351504555, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.845 with standard deviation 0.020. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "2144da25-8b51-47da-ae7c-cdad3e59c452", "metadata": {"aucs": [0.8240810512719998, 0.8712265931846849, 0.840303860994682], "final_y": [0.1376677838246554, 0.1268821374560647, 0.1279295075174528]}, "mutation_prompt": null}
{"id": "2c875bb4-ee92-40ba-b058-55aab9c8d176", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.w_final = 0.4\n        self.f_initial = 0.8\n        self.cr_initial = 0.9\n        self.velocity_bounds = 0.1  # New: adaptive velocity bound factor\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.velocity_bounds, self.velocity_bounds, (self.population_size, self.dim))  # Changed: initialize to smaller range\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        \n        while evaluations < self.budget:\n            self.w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            self.f = self.f_initial * (1 - evaluations / self.budget)\n            self.cr = self.cr_initial * np.random.rand()  # Changed: dynamic crossover probability\n            \n            self.c1 = self.c1_initial + 0.5 * np.cos(2 * np.pi * evaluations / self.budget)\n            self.c2 = self.c2_initial + 0.5 * np.sin(2 * np.pi * evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i] if global_best_position is not None else 0))\n\n                if np.random.rand() < 0.15:\n                    velocities[i] = np.random.uniform(-self.velocity_bounds, self.velocity_bounds, self.dim)  # Changed: constrained velocity\n\n                candidate_position = population[i] + velocities[i]\n                noise = np.random.normal(0, 0.05, self.dim)  # New: adaptive noise perturbation\n                candidate_position = np.clip(candidate_position + noise, lb, ub)  # Updated: added noise\n                candidate_score = func(candidate_position)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i]:\n                    personal_best_scores[i] = candidate_score\n                    personal_best_positions[i] = candidate_position\n\n                if candidate_score < global_best_score:\n                    global_best_score = candidate_score\n                    global_best_position = candidate_position\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                mutant_vector = np.clip(personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c]), lb, ub)\n                \n                trial_vector = np.copy(personal_best_positions[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == jrand:\n                        trial_vector[j] = mutant_vector[j]\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Introduced a perturbation mechanism based on adaptive noise to enhance exploration during the update of particle positions.", "configspace": "", "generation": 8, "fitness": 0.8453440154980006, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.845 with standard deviation 0.028. And the mean value of best solutions found was 0.129 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "2144da25-8b51-47da-ae7c-cdad3e59c452", "metadata": {"aucs": [0.8088741526033542, 0.8772823487101147, 0.849875545180533], "final_y": [0.13344153042295714, 0.12405149300458551, 0.12922027377572742]}, "mutation_prompt": null}
{"id": "2cf5206a-958e-4d04-939f-f06591a2fbba", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.w_final = 0.4\n        self.f_initial = 0.8\n        self.cr_initial = 0.9\n        self.velocity_bounds = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.velocity_bounds, self.velocity_bounds, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        \n        while evaluations < self.budget:\n            self.w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n            self.f = self.f_initial * (1 - evaluations / self.budget)\n            self.cr = self.cr_initial * np.random.rand()\n            \n            self.c1 = self.c1_initial + 0.5 * np.cos(2 * np.pi * evaluations / self.budget)\n            self.c2 = self.c2_initial + 0.5 * np.sin(2 * np.pi * evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i] if global_best_position is not None else 0))\n\n                if np.random.rand() < 0.15:\n                    velocities[i] = np.random.uniform(-self.velocity_bounds, self.velocity_bounds, self.dim)\n                    # Enhanced perturbation strategy: add random noise to the velocity\n                    velocities[i] += np.random.normal(0, 0.01, self.dim)\n\n                candidate_position = population[i] + velocities[i]\n                candidate_position = np.clip(candidate_position, lb, ub)\n                candidate_score = func(candidate_position)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i]:\n                    personal_best_scores[i] = candidate_score\n                    personal_best_positions[i] = candidate_position\n\n                if candidate_score < global_best_score:\n                    global_best_score = candidate_score\n                    global_best_position = candidate_position\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                mutant_vector = np.clip(personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c]), lb, ub)\n                \n                trial_vector = np.copy(personal_best_positions[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == jrand:\n                        trial_vector[j] = mutant_vector[j]\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Enhanced PSODE with dynamic perturbation strategy and improved diversity maintenance to boost solution quality and convergence speed.", "configspace": "", "generation": 8, "fitness": 0.87387841726808, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.874 with standard deviation 0.019. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "2144da25-8b51-47da-ae7c-cdad3e59c452", "metadata": {"aucs": [0.8481645492718006, 0.8912720460718309, 0.8821986564606088], "final_y": [0.12758068931240762, 0.1241935784500664, 0.12163268391196669]}, "mutation_prompt": null}
{"id": "5606d1d0-b76f-4f91-be9a-36f3a5498287", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.c1 = 2.0  # cognitive component\n        self.c2 = 2.0  # social component\n        self.w_initial = 0.9  # initial inertia weight\n        self.w_final = 0.4    # final inertia weight\n        self.f = 0.8   # differential weight\n        self.cr = 0.9  # crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.initial_population_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        \n        while evaluations < self.budget:\n            self.w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n\n            for i in range(population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Particle Swarm Optimization (PSO) update\n                r1, r2 = np.random.rand(), np.random.rand()\n                self.c1, self.c2 = 1.5 + np.random.rand() * 1.5, 1.5 + np.random.rand() * 1.5  # Changed line\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i] if global_best_position is not None else 0))\n                # Enhanced velocity perturbation\n                if np.random.rand() < 0.3:\n                    velocities[i] += np.random.normal(0, 0.05, self.dim) \n                \n                candidate_position = np.clip(population[i] + velocities[i], lb, ub)\n                candidate_score = func(candidate_position)\n                evaluations += 1\n\n                # Update personal best\n                if candidate_score < personal_best_scores[i]:\n                    personal_best_scores[i] = candidate_score\n                    personal_best_positions[i] = candidate_position\n\n                # Update global best\n                if candidate_score < global_best_score:\n                    global_best_score = candidate_score\n                    global_best_position = candidate_position\n\n            # Differential Evolution (DE) mutation and crossover\n            for i in range(population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                # Introduced stochastic adaptive change\n                self.f = np.random.uniform(0.5, 1.0) + np.random.normal(0, 0.1)\n\n                mutant_vector = np.clip(personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c]), lb, ub)\n                \n                trial_vector = np.copy(personal_best_positions[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == jrand:\n                        trial_vector[j] = mutant_vector[j]\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                # Selection\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n            # Dynamic population size adjustment\n            if evaluations % (self.budget // 10) == 0:\n                population_size = max(10, population_size - 5)\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Enhanced exploration by integrating adaptive cognitive and social coefficients in PSO to balance convergence.", "configspace": "", "generation": 8, "fitness": 0.8528001730991281, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.853 with standard deviation 0.024. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "09de97ab-a8ea-4181-a0d3-ea6ae2b029b2", "metadata": {"aucs": [0.8192069930129351, 0.8667514461066326, 0.8724420801778165], "final_y": [0.1415104553463442, 0.12184178364299003, 0.12082595026088117]}, "mutation_prompt": null}
{"id": "b6dc3cac-c4e2-419b-8b95-d822a858b3e5", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.w_final = 0.4\n        self.f_initial = 0.8\n        self.cr_initial = 0.9\n        self.velocity_bounds = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-self.velocity_bounds, self.velocity_bounds, (self.population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        \n        while evaluations < self.budget:\n            self.w = self.w_initial - (self.w_initial - self.w_final) * ((evaluations / self.budget)**2)  # Changed: dynamic inertia weight adjustment\n            self.f = self.f_initial * (1 - evaluations / self.budget)\n            self.cr = self.cr_initial * np.random.rand()\n            \n            self.c1 = self.c1_initial + 0.5 * np.cos(2 * np.pi * evaluations / self.budget)\n            self.c2 = self.c2_initial + 0.5 * np.sin(2 * np.pi * evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i] if global_best_position is not None else 0))\n\n                if np.random.rand() < 0.15:\n                    velocities[i] *= (0.5 + np.random.rand() / 2)  # Changed: stochastic velocity damping\n\n                candidate_position = population[i] + velocities[i]\n                candidate_position = np.clip(candidate_position, lb, ub)\n                candidate_score = func(candidate_position)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i]:\n                    personal_best_scores[i] = candidate_score\n                    personal_best_positions[i] = candidate_position\n\n                if candidate_score < global_best_score:\n                    global_best_score = candidate_score\n                    global_best_position = candidate_position\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                mutant_vector = np.clip(personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c]), lb, ub)\n                \n                trial_vector = np.copy(personal_best_positions[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == jrand:\n                        trial_vector[j] = mutant_vector[j]\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Introduced dynamic inertia weight adjustment and stochastic velocity damping to refine exploration-exploitation trade-off.", "configspace": "", "generation": 8, "fitness": 0.8654254370180904, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.865 with standard deviation 0.023. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "2144da25-8b51-47da-ae7c-cdad3e59c452", "metadata": {"aucs": [0.8358609542899921, 0.8680291377917632, 0.892386218972516], "final_y": [0.13194375477299636, 0.12397400816422077, 0.12214737859590408]}, "mutation_prompt": null}
{"id": "f83b596e-559a-4503-878d-73e093775afc", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.c1 = 2.0  # cognitive component\n        self.c2 = 2.0  # social component\n        self.w_initial = 0.9  # initial inertia weight\n        self.w_final = 0.4    # final inertia weight\n        self.f = 0.8   # differential weight\n        self.cr = 0.9  # crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.initial_population_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        \n        while evaluations < self.budget:\n            self.w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / (self.budget * 0.8))  # Change 1\n\n            for i in range(population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Particle Swarm Optimization (PSO) update\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i] if global_best_position is not None else 0))\n                # Enhanced velocity perturbation\n                if np.random.rand() < 0.3:\n                    velocities[i] += np.random.normal(0, 0.05, self.dim) \n                \n                candidate_position = np.clip(population[i] + velocities[i], lb, ub)\n                candidate_score = func(candidate_position)\n                evaluations += 1\n\n                # Update personal best\n                if candidate_score < personal_best_scores[i]:\n                    personal_best_scores[i] = candidate_score\n                    personal_best_positions[i] = candidate_position\n\n                # Update global best\n                if candidate_score < global_best_score:\n                    global_best_score = candidate_score\n                    global_best_position = candidate_position\n\n            # Differential Evolution (DE) mutation and crossover\n            for i in range(population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                # Introduced stochastic adaptive change\n                self.f = np.random.uniform(0.5, 1.0) + np.random.normal(0, 0.1)\n\n                mutant_vector = np.clip(personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c]), lb, ub)\n                \n                trial_vector = np.copy(personal_best_positions[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == jrand:\n                        trial_vector[j] = mutant_vector[j]\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                # Selection\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n            # Dynamic population size adjustment\n            if evaluations % (self.budget // 10) == 0:\n                population_size = max(10, population_size - 5 + int(np.random.rand() > 0.7))  # Change 2\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Enhanced HybridPSODE with adaptive inertia weight and stochastic population size increase for improved exploration.", "configspace": "", "generation": 8, "fitness": 0.8461115797199893, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.846 with standard deviation 0.026. And the mean value of best solutions found was 0.130 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "09de97ab-a8ea-4181-a0d3-ea6ae2b029b2", "metadata": {"aucs": [0.8130471128048697, 0.8753000521847545, 0.8499875741703434], "final_y": [0.14812417803105182, 0.12306150546236627, 0.11881486473713532]}, "mutation_prompt": null}
{"id": "4ca48b51-b436-4fe9-a41a-82cc16db247d", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.c1 = 2.0  # cognitive component\n        self.c2 = 2.0  # social component\n        self.w_initial = 0.9  # initial inertia weight\n        self.w_final = 0.4    # final inertia weight\n        self.f = 0.8   # differential weight\n        self.cr = 0.9  # crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.initial_population_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        \n        while evaluations < self.budget:\n            self.w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n\n            for i in range(population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Particle Swarm Optimization (PSO) update\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i] if global_best_position is not None else 0))\n                # Enhanced velocity perturbation\n                if np.random.rand() < 0.5:  # changed from 0.3 to 0.5\n                    velocities[i] += np.random.normal(0, 0.05, self.dim) \n                \n                candidate_position = np.clip(population[i] + velocities[i], lb, ub)\n                candidate_score = func(candidate_position)\n                evaluations += 1\n\n                # Update personal best\n                if candidate_score < personal_best_scores[i]:\n                    personal_best_scores[i] = candidate_score\n                    personal_best_positions[i] = candidate_position\n\n                # Update global best\n                if candidate_score < global_best_score:\n                    global_best_score = candidate_score\n                    global_best_position = candidate_position\n\n            # Differential Evolution (DE) mutation and crossover\n            for i in range(population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                # Introduced stochastic adaptive change\n                self.f = np.random.uniform(0.5, 1.0) + np.random.normal(0, 0.1)\n\n                mutant_vector = np.clip(personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c]), lb, ub)\n                \n                trial_vector = np.copy(personal_best_positions[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == jrand:\n                        trial_vector[j] = mutant_vector[j]\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                # Selection\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n            # Dynamic population size adjustment\n            if evaluations % (self.budget // 10) == 0:\n                population_size = max(10, population_size - 5)\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Enhanced population diversity by adjusting perturbation frequency in the velocity update to improve exploration.", "configspace": "", "generation": 8, "fitness": 0.8542930685660788, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.854 with standard deviation 0.014. And the mean value of best solutions found was 0.132 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "09de97ab-a8ea-4181-a0d3-ea6ae2b029b2", "metadata": {"aucs": [0.8345344121776159, 0.8607050187015698, 0.8676397748190509], "final_y": [0.1432484983197534, 0.1278602325857321, 0.12389080810395425]}, "mutation_prompt": null}
{"id": "d2afe666-8f81-4a0d-b099-80b580b9f9ef", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 50\n        self.c1 = 2.0  # cognitive component\n        self.c2 = 2.0  # social component\n        self.w_initial = 0.9  # initial inertia weight\n        self.w_final = 0.4    # final inertia weight\n        self.f = 0.8   # differential weight\n        self.cr_initial = 0.9  # initial crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.initial_population_size\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (population_size, self.dim))\n        personal_best_positions = np.copy(population)\n        personal_best_scores = np.full(population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        \n        evaluations = 0\n        \n        while evaluations < self.budget:\n            self.w = self.w_initial - (self.w_initial - self.w_final) * (evaluations / self.budget)\n\n            for i in range(population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Particle Swarm Optimization (PSO) update\n                r1, r2 = np.random.rand(), np.random.rand()\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                 self.c2 * r2 * (global_best_position - population[i] if global_best_position is not None else 0))\n                # Enhanced velocity perturbation\n                if np.random.rand() < 0.3:\n                    velocities[i] += np.random.normal(0, 0.05, self.dim) \n                \n                candidate_position = np.clip(population[i] + velocities[i], lb, ub)\n                candidate_score = func(candidate_position)\n                evaluations += 1\n\n                # Update personal best\n                if candidate_score < personal_best_scores[i]:\n                    personal_best_scores[i] = candidate_score\n                    personal_best_positions[i] = candidate_position\n\n                # Update global best\n                if candidate_score < global_best_score:\n                    global_best_score = candidate_score\n                    global_best_position = candidate_position\n\n            # Differential Evolution (DE) mutation and crossover\n            for i in range(population_size):\n                if evaluations >= self.budget:\n                    break\n                \n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                \n                # Introduced stochastic adaptive change\n                self.f = np.random.uniform(0.5, 1.0) + np.random.normal(0, 0.1)\n\n                mutant_vector = np.clip(personal_best_positions[a] + self.f * (personal_best_positions[b] - personal_best_positions[c]), lb, ub)\n                \n                trial_vector = np.copy(personal_best_positions[i])\n                jrand = np.random.randint(self.dim)\n                # Adaptive crossover probability\n                self.cr = self.cr_initial - (self.cr_initial - 0.5) * (evaluations / self.budget)\n                for j in range(self.dim):\n                    if np.random.rand() < self.cr or j == jrand:\n                        trial_vector[j] = mutant_vector[j]\n                \n                trial_score = func(trial_vector)\n                evaluations += 1\n\n                # Selection\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial_vector\n\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial_vector\n\n            # Dynamic population size adjustment\n            if evaluations % (self.budget // 10) == 0:\n                population_size = max(10, population_size - 5)\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Introduced adaptive crossover probability in DE based on the progress of evaluations for improved exploration-exploitation balance.", "configspace": "", "generation": 8, "fitness": 0.8374926247873958, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.837 with standard deviation 0.039. And the mean value of best solutions found was 0.134 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "09de97ab-a8ea-4181-a0d3-ea6ae2b029b2", "metadata": {"aucs": [0.7846315340935497, 0.8514191528715405, 0.8764271873970972], "final_y": [0.15228211246450063, 0.1337802076458554, 0.11702308440702291]}, "mutation_prompt": null}
