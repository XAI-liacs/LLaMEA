{"id": "b05c365c-7078-4931-8895-37150ff25106", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        \n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        \n        for _ in range(10):  # small number of local search iterations\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "A hybrid metaheuristic algorithm combining Differential Evolution (DE) with local search refinement and adaptive complexity management for optimizing multilayered structures.", "configspace": "", "generation": 0, "fitness": 0.7934345130606081, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.793 with standard deviation 0.013. And the mean value of best solutions found was 0.145 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": null, "metadata": {"aucs": [0.7753791132137795, 0.8040000248316164, 0.800924401136428], "final_y": [0.15116913440122715, 0.1494595286273257, 0.13422151900047108]}, "mutation_prompt": null}
{"id": "d074abd8-a4f7-4641-8690-0a4bfaccee36", "solution": "import numpy as np\n\nclass EnhancedHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n        self.min_mutation_factor = 0.5\n        self.max_mutation_factor = 1.0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        \n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.mutation_factor = self.min_mutation_factor + (\n                    np.random.rand() * (self.max_mutation_factor - self.min_mutation_factor)\n                )\n                mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                else:\n                    population[i] = population[i] + 0.01 * np.random.randn(*population[i].shape)  # Perturbation\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        \n        for _ in range(10):  # small number of local search iterations\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "EnhancedHybridMetaheuristic", "description": "An enhanced hybrid metaheuristic that integrates perturbation-based diversity control and dynamic scaling of mutation factors with local search refinement for improved optimization performance.", "configspace": "", "generation": 1, "fitness": 0.8053610423984622, "feedback": "The algorithm EnhancedHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.805 with standard deviation 0.024. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "b05c365c-7078-4931-8895-37150ff25106", "metadata": {"aucs": [0.7772387876631, 0.8369457646685181, 0.8018985748637686], "final_y": [0.15394668477852724, 0.13946218638382535, 0.14952585107600902]}, "mutation_prompt": null}
{"id": "3c40fab3-c10d-40fc-8a94-1c0d3f2193db", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        \n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - self.current_evals / self.budget)  # Adaptive mutation\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        \n        for _ in range(5 + self.dim // 10):  # Dynamic local search iterations\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic using adaptive mutation and dynamic local search for optimized multilayer structures.", "configspace": "", "generation": 1, "fitness": 0.8113287613563562, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.811 with standard deviation 0.009. And the mean value of best solutions found was 0.141 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "b05c365c-7078-4931-8895-37150ff25106", "metadata": {"aucs": [0.824382650166519, 0.8031555867667706, 0.8064480471357792], "final_y": [0.13238927306286408, 0.14456341252182758, 0.14528019163755457]}, "mutation_prompt": null}
{"id": "c14a8f21-1e9f-4f6e-9b1c-ee6922a024fc", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        \n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                # Changed line\n                self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Dynamic mutation factor\n                mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        \n        for _ in range(10):  # small number of local search iterations\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic algorithm by adjusting the mutation factor dynamically to improve convergence speed in optimizing multilayered structures.", "configspace": "", "generation": 1, "fitness": 0.8082365061759774, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.808 with standard deviation 0.015. And the mean value of best solutions found was 0.136 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "b05c365c-7078-4931-8895-37150ff25106", "metadata": {"aucs": [0.7960324524732373, 0.7996809644737791, 0.8289961015809157], "final_y": [0.13936603482448262, 0.13702989052386583, 0.13066719883894695]}, "mutation_prompt": null}
{"id": "a6b91e96-8486-4b7c-8512-75942ac918dc", "solution": "import numpy as np\n\nclass HybridMetaheuristicRefined:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def adaptive_differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        \n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                elif np.random.rand() < 0.1:\n                    self.mutation_factor = np.random.uniform(0.6, 1.0)\n                    self.crossover_rate = np.random.uniform(0.5, 0.9)\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def enhanced_local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        \n        for _ in range(20):  # increased iterations for local search\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        best_solution = self.adaptive_differential_evolution(func)\n        best_solution = self.enhanced_local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristicRefined", "description": "A refined hybrid metaheuristic integrating Adaptive Differential Evolution (ADE) with Enhanced Local Optimization (ELO) and adaptive complexity management for optimized multilayered structures.", "configspace": "", "generation": 1, "fitness": 0.7822761931106927, "feedback": "The algorithm HybridMetaheuristicRefined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.782 with standard deviation 0.014. And the mean value of best solutions found was 0.153 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "b05c365c-7078-4931-8895-37150ff25106", "metadata": {"aucs": [0.7620742640293293, 0.7945901820562783, 0.7901641332464706], "final_y": [0.15673717036062762, 0.1601017669387199, 0.14316260092427546]}, "mutation_prompt": null}
{"id": "8dbae6f1-9424-4234-a366-d904ebdcacd2", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        \n        while self.current_evals < self.budget:\n            elite_idx = np.argmin(fitness)\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n\n                if self.current_evals >= self.budget:\n                    break\n\n            population[elite_idx] = population[np.argmin(fitness)]\n        \n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        \n        for _ in range(10):  # small number of local search iterations\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced HybridMetaheuristic by incorporating elite selection to maintain and exploit high-quality solutions over generations.", "configspace": "", "generation": 1, "fitness": 0.799242776373624, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.799 with standard deviation 0.021. And the mean value of best solutions found was 0.149 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "b05c365c-7078-4931-8895-37150ff25106", "metadata": {"aucs": [0.7774505725918077, 0.8269157148559219, 0.7933620416731422], "final_y": [0.15686612077697792, 0.14342004606559466, 0.14567790066867659]}, "mutation_prompt": null}
{"id": "4ef1de09-758c-4ad5-a15a-046ec6e9d594", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10 * dim // 2, 5)  # Dynamic population size\n        self.mutation_factor = 0.9  # Adjusted mutation factor\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        \n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - self.current_evals / self.budget)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n\n                if self.current_evals >= self.budget:\n                    break\n\n            # Dynamic population resizing\n            if self.current_evals < self.budget // 2:\n                self.population_size = min(self.population_size + 1, 10 * self.dim)\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.05 * (ub - lb)  # Reduced step size for finer search\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Improved hybrid metaheuristic with dynamic population and layered search to enhance solution quality for multilayer structures.", "configspace": "", "generation": 2, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 50 is out of bounds for axis 0 with size 50').", "error": "IndexError('index 50 is out of bounds for axis 0 with size 50')", "parent_id": "3c40fab3-c10d-40fc-8a94-1c0d3f2193db", "metadata": {}, "mutation_prompt": null}
{"id": "46eba9a9-7037-4f07-9c03-372cc3b4c04c", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9  # Modified crossover rate\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        \n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - self.current_evals / self.budget)  # Adaptive mutation\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        \n        for _ in range(5 + self.dim // 10):  # Dynamic local search iterations\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic using adaptive mutation and dynamic local search for optimized multilayer structures with modified crossover strategy.", "configspace": "", "generation": 2, "fitness": 0.7965574904328822, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.797 with standard deviation 0.010. And the mean value of best solutions found was 0.137 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "3c40fab3-c10d-40fc-8a94-1c0d3f2193db", "metadata": {"aucs": [0.7905175976480969, 0.8100500996408518, 0.7891047740096979], "final_y": [0.13273202716738042, 0.13621820200378498, 0.14214782867993103]}, "mutation_prompt": null}
{"id": "2563124b-19ab-4708-9a1e-784d352e1f9a", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        \n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - self.current_evals / self.budget)  # Adaptive mutation\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 - self.current_evals / self.budget)  # Adaptive crossover\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        \n        for _ in range(5 + self.dim // 10):  # Dynamic local search iterations\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Improved hybrid metaheuristic with adaptive crossover rate for enhanced exploration and exploitation balance.", "configspace": "", "generation": 2, "fitness": 0.7970683855683879, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.797 with standard deviation 0.016. And the mean value of best solutions found was 0.137 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "3c40fab3-c10d-40fc-8a94-1c0d3f2193db", "metadata": {"aucs": [0.7747204068625214, 0.8053044241266794, 0.8111803257159628], "final_y": [0.13949690853683583, 0.14123335774587165, 0.13071093707885484]}, "mutation_prompt": null}
{"id": "821e5944-4090-45f4-bd65-a0720d85df26", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim) # Modular structure initialization\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - self.current_evals / self.budget)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3]) # Update modular structure\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0  # Adaptive scaling for local search\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.1  # Increase scale factor if improvement\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Improved hybrid metaheuristic incorporating modular structure identification and adaptive local search to optimize multilayer structures.", "configspace": "", "generation": 2, "fitness": 0.8212863021709892, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.821 with standard deviation 0.026. And the mean value of best solutions found was 0.138 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "3c40fab3-c10d-40fc-8a94-1c0d3f2193db", "metadata": {"aucs": [0.8025484382311292, 0.8583699388494727, 0.8029405294323654], "final_y": [0.13843344370203448, 0.1312826288016573, 0.14326047301557177]}, "mutation_prompt": null}
{"id": "31eeeb6e-936a-46e1-bc50-e56f03e676cc", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        \n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - self.current_evals / self.budget)  # Adaptive mutation\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n\n                if self.current_evals >= self.budget:\n                    break\n\n            # Dynamic adaptation of the population size\n            self.population_size = max(5, self.population_size - 1)  # Reduce population size gradually\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        \n        for _ in range(5 + self.dim // 10):  # Dynamic local search iterations\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Improved hybrid metaheuristic using adaptive population size and dynamic local search for optimized multilayer structures.", "configspace": "", "generation": 2, "fitness": 0.8106995507881845, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.811 with standard deviation 0.018. And the mean value of best solutions found was 0.136 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "3c40fab3-c10d-40fc-8a94-1c0d3f2193db", "metadata": {"aucs": [0.7870276589199423, 0.8305595078426233, 0.8145114856019879], "final_y": [0.13727861618799597, 0.13452145819699612, 0.13491576986639175]}, "mutation_prompt": null}
{"id": "abe4f67a-b6d2-4ff4-a3a7-0f951cd9fbd8", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim) # Modular structure initialization\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - self.current_evals / self.budget)\n                weight = np.linspace(0.5, 1.5, len(b)) # New: weighted mutation\n                mutant = np.clip(a + adaptive_mutation_factor * (weight * (b - c)), lb, ub) # Adjusted mutation application\n                adaptive_crossover_rate = self.crossover_rate + 0.2 * (1 - self.current_evals / self.budget) # New: adaptive crossover rate\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3]) # Update modular structure\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0  # Adaptive scaling for local search\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.1  # Increase scale factor if improvement\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic with weighted mutation and adaptive crossover rates.", "configspace": "", "generation": 3, "fitness": 0.8074966358993807, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.807 with standard deviation 0.032. And the mean value of best solutions found was 0.140 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "821e5944-4090-45f4-bd65-a0720d85df26", "metadata": {"aucs": [0.7650362691578755, 0.8408071646077104, 0.8166464739325563], "final_y": [0.15429859049386818, 0.1362340780277178, 0.13094886853516774]}, "mutation_prompt": null}
{"id": "28df44fa-80d8-48cf-bc9b-0da8c48a647f", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim) # Modular structure initialization\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - self.current_evals / self.budget)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate + 0.3 * (fitness[i] / (np.max(fitness) + 1e-9))\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3]) # Update modular structure\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0  # Adaptive scaling for local search\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor *= 1.2  # Increase scale factor more significantly if improvement\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic with adaptive crossover strategy and improved local search exploration to optimize multilayer structures.", "configspace": "", "generation": 3, "fitness": 0.8029290270349404, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.803 with standard deviation 0.008. And the mean value of best solutions found was 0.143 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "821e5944-4090-45f4-bd65-a0720d85df26", "metadata": {"aucs": [0.7917806312204033, 0.8088056496968619, 0.808200800187556], "final_y": [0.14346840295651375, 0.1499958191704429, 0.1358022034390729]}, "mutation_prompt": null}
{"id": "18297491-e9f5-4ff1-b29a-9aa5e7ae2293", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim) \n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - self.current_evals / self.budget)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + np.random.rand() * 0.1)  # Adaptive crossover\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate  # Adjusted line\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3]) \n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0  \n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * (np.random.randn() + np.random.choice([-1, 1]) * 0.1)  # Stochastic adjustment\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.1  \n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic with adaptive crossover and stochastic local search for optimizing multilayer structures.", "configspace": "", "generation": 3, "fitness": 0.8057541627092935, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.806 with standard deviation 0.019. And the mean value of best solutions found was 0.137 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "821e5944-4090-45f4-bd65-a0720d85df26", "metadata": {"aucs": [0.786648804550555, 0.8319044266245069, 0.7987092569528184], "final_y": [0.12485949076009284, 0.14064205811094965, 0.14667199509117246]}, "mutation_prompt": null}
{"id": "1f8bbc46-b0fd-4cac-8b1f-7300ecfa89be", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim) # Modular structure initialization\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - self.current_evals / self.budget)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                \n                # Change 1: Adaptive crossover rate\n                adaptive_crossover_rate = self.crossover_rate * (0.5 + 0.5 * np.random.rand())\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    \n                    # Change 2: Enhanced modular structure update\n                    modular_structure = (modular_structure + np.random.choice([2, 3], size=self.dim)) // 2\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0  # Adaptive scaling for local search\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.1  # Increase scale factor if improvement\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Refined hybrid metaheuristic with adaptive crossover and enhanced modular updates for improved convergence.", "configspace": "", "generation": 3, "fitness": 0.8034593908569322, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.803 with standard deviation 0.009. And the mean value of best solutions found was 0.142 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "821e5944-4090-45f4-bd65-a0720d85df26", "metadata": {"aucs": [0.8005934479606552, 0.8160081377096396, 0.7937765869005016], "final_y": [0.14149694374902044, 0.13606789201476355, 0.14801554711910303]}, "mutation_prompt": null}
{"id": "3e5b00fb-b1d3-44c2-88e5-fa23e08299f2", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim) # Modular structure initialization\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - self.current_evals / self.budget)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                \n                # Change here: Adapt crossover rate with progress\n                adaptive_crossover_rate = self.crossover_rate * (1 - self.current_evals / self.budget)\n                \n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3]) # Update modular structure\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0  # Adaptive scaling for local search\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.1  # Increase scale factor if improvement\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced hybrid algorithm with an adaptive crossover rate based on convergence progress for better exploration-exploitation balance.", "configspace": "", "generation": 3, "fitness": 0.8054582785740868, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.805 with standard deviation 0.006. And the mean value of best solutions found was 0.142 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "821e5944-4090-45f4-bd65-a0720d85df26", "metadata": {"aucs": [0.8003857544259992, 0.8026156263330838, 0.8133734549631777], "final_y": [0.1429689476267001, 0.14216085876200069, 0.1411319379700099]}, "mutation_prompt": null}
{"id": "180f9fa9-ba36-45a9-9a28-b9c29c803717", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim) # Modular structure initialization\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - self.current_evals / self.budget)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 - self.current_evals / self.budget)\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3]) # Update modular structure\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0  # Adaptive scaling for local search\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.1  # Increase scale factor if improvement\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Incorporate adaptive crossover rate in differential evolution to improve exploration-exploitation balance.", "configspace": "", "generation": 4, "fitness": 0.7991847666868969, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.799 with standard deviation 0.006. And the mean value of best solutions found was 0.145 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "821e5944-4090-45f4-bd65-a0720d85df26", "metadata": {"aucs": [0.7988414177761681, 0.8069613230688113, 0.7917515592157114], "final_y": [0.13626928089233847, 0.14883381666429762, 0.15085589095461116]}, "mutation_prompt": null}
{"id": "43e2a3f3-1d11-4a56-a5bd-e5ce11fc3595", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim) # Modular structure initialization\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - self.current_evals / self.budget)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 - self.current_evals / self.budget)  # Dynamically adjust crossover rate\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3]) # Update modular structure\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0  # Adaptive scaling for local search\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.1  # Increase scale factor if improvement\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced differential evolution by dynamically adjusting crossover rate based on remaining evaluations.", "configspace": "", "generation": 4, "fitness": 0.7990919515115401, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.799 with standard deviation 0.009. And the mean value of best solutions found was 0.147 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "821e5944-4090-45f4-bd65-a0720d85df26", "metadata": {"aucs": [0.7897958585291591, 0.8119448645965314, 0.7955351314089298], "final_y": [0.15129359596289305, 0.14536180178332903, 0.14487993482224792]}, "mutation_prompt": null}
{"id": "0ab24950-dbae-4d37-8243-7b42d23885e7", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.9  # Tweaked mutation factor for better exploration\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim) # Modular structure initialization\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - self.current_evals / self.budget)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3]) # Update modular structure\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.05 * (ub - lb)  # Reduced step size for finer local search refinement\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.1\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic by refining initialization and adaptive search mechanism to optimize multilayer structures efficiently.", "configspace": "", "generation": 4, "fitness": 0.7969196310926158, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.797 with standard deviation 0.013. And the mean value of best solutions found was 0.137 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "821e5944-4090-45f4-bd65-a0720d85df26", "metadata": {"aucs": [0.7782023952994218, 0.8083327946318394, 0.8042237033465858], "final_y": [0.13754519133391596, 0.12740585452498354, 0.145972398647912]}, "mutation_prompt": null}
{"id": "a9a2d920-45e4-4200-8129-6fed8a685e62", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9  # Enhanced crossover rate\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim) # Modular structure initialization\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1.2 - self.current_evals / self.budget)  # Adaptive mutation\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3]) # Update modular structure\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0  # Adaptive scaling for local search\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.1  # Increase scale factor if improvement\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Improved hybrid metaheuristic with enhanced crossover strategy and adaptive mutation for better exploration and convergence.", "configspace": "", "generation": 4, "fitness": 0.8050096481219894, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.805 with standard deviation 0.007. And the mean value of best solutions found was 0.142 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "821e5944-4090-45f4-bd65-a0720d85df26", "metadata": {"aucs": [0.7983683656078057, 0.8154177285126409, 0.8012428502455211], "final_y": [0.14147419384061377, 0.1411764250977331, 0.1432880297025948]}, "mutation_prompt": null}
{"id": "dac28b71-e865-4b1f-9fa5-eb875fa4efe1", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            self.crossover_rate = 0.5 if self.current_evals < self.budget / 2 else 0.9\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - self.current_evals / self.budget)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.1\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic with dynamic adjustment of crossover rates and adaptive population size.", "configspace": "", "generation": 4, "fitness": 0.8037482229630543, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.804 with standard deviation 0.011. And the mean value of best solutions found was 0.142 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "821e5944-4090-45f4-bd65-a0720d85df26", "metadata": {"aucs": [0.7883437028416937, 0.8127328348120385, 0.8101681312354305], "final_y": [0.1469131326632922, 0.13757864927061947, 0.14041492040882564]}, "mutation_prompt": null}
{"id": "f2c73a70-5550-46e5-be77-dd13318f5c48", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim) # Modular structure initialization\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - self.current_evals / self.budget)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 - self.current_evals / self.budget)  # Adaptive crossover rate\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3]) # Update modular structure\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0  # Adaptive scaling for local search\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.1  # Increase scale factor if improvement\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic by introducing adaptive crossover rate based on convergence progress to optimize multilayer structures.", "configspace": "", "generation": 5, "fitness": 0.8081461054547167, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.808 with standard deviation 0.011. And the mean value of best solutions found was 0.138 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "821e5944-4090-45f4-bd65-a0720d85df26", "metadata": {"aucs": [0.8018726661024642, 0.7991720264588149, 0.8233936238028708], "final_y": [0.1386817793074876, 0.14968391932386826, 0.12494111626613147]}, "mutation_prompt": null}
{"id": "831fbd80-7bb7-4fb2-9a50-55660606115b", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - self.current_evals / self.budget)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + 0.5 * np.random.rand())  # Changed line\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor *= 1.2  # Changed line\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic with adaptive crossover and dynamic local search scaling to optimize multilayer structures efficiently.", "configspace": "", "generation": 5, "fitness": 0.8044495001579927, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.804 with standard deviation 0.015. And the mean value of best solutions found was 0.143 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "821e5944-4090-45f4-bd65-a0720d85df26", "metadata": {"aucs": [0.7843804211304076, 0.8193898670618553, 0.8095782122817148], "final_y": [0.144522255127415, 0.14020981862529958, 0.14316653364082121]}, "mutation_prompt": null}
{"id": "5a4396cc-ef21-45e1-ac46-85f77c195eed", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim) # Modular structure initialization\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - self.current_evals / self.budget)\n                self.crossover_rate = 0.7 + 0.3 * (self.current_evals / self.budget) # Dynamic crossover rate\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3]) # Update modular structure\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0  # Adaptive scaling for local search\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.1  # Increase scale factor if improvement\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic adjusting crossover rate dynamically based on progress towards solving the optimization problem.", "configspace": "", "generation": 5, "fitness": 0.8017943411543239, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.802 with standard deviation 0.013. And the mean value of best solutions found was 0.144 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "821e5944-4090-45f4-bd65-a0720d85df26", "metadata": {"aucs": [0.8122584297266876, 0.8098909801884545, 0.7832336135478297], "final_y": [0.14575898383221175, 0.139826226018117, 0.14741021958615286]}, "mutation_prompt": null}
{"id": "783ae106-04aa-46db-8e5e-7869313ebd44", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim) # Modular structure initialization\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - self.current_evals / self.budget)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < (self.crossover_rate + 0.1 * (fitness[i] - np.min(fitness)) / (np.max(fitness) - np.min(fitness)))\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3]) # Update modular structure\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0  # Adaptive scaling for local search\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.1  # Increase scale factor if improvement\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced adaptive crossover leveraging problem-specific feedback to optimize multilayer structures.", "configspace": "", "generation": 5, "fitness": 0.8042970627233256, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.804 with standard deviation 0.014. And the mean value of best solutions found was 0.140 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "821e5944-4090-45f4-bd65-a0720d85df26", "metadata": {"aucs": [0.7866232517634746, 0.821754584847604, 0.8045133515588979], "final_y": [0.1416393906512915, 0.1395806017256025, 0.13788274076965334]}, "mutation_prompt": null}
{"id": "785b04c8-8bd7-4380-8a8e-542f6a71c9c7", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim) # Modular structure initialization\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - self.current_evals / self.budget)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3]) # Update modular structure\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.05 * (ub - lb)  # Reduced step size for finer tuning\n        scale_factor = 1.0  # Adaptive scaling for local search\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.1  # Increase scale factor if improvement\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic with refined local search using adaptive step size and exploration balance.", "configspace": "", "generation": 5, "fitness": 0.8058937044806633, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.806 with standard deviation 0.011. And the mean value of best solutions found was 0.137 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "821e5944-4090-45f4-bd65-a0720d85df26", "metadata": {"aucs": [0.7903759504622736, 0.8132250624993224, 0.8140801004803937], "final_y": [0.13146779419077126, 0.1437942203086111, 0.13439945786894214]}, "mutation_prompt": null}
{"id": "330cf417-9349-4dae-8b53-377b538dbaf7", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim) # Modular structure initialization\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - self.current_evals / self.budget)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3]) # Update modular structure\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0  # Adaptive scaling for local search\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor *= 1.05  # Increase scale factor slightly for dynamic neighborhood\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced local search by incorporating a dynamic neighborhood strategy to improve convergence.", "configspace": "", "generation": 6, "fitness": 0.795732512328243, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.796 with standard deviation 0.016. And the mean value of best solutions found was 0.140 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "821e5944-4090-45f4-bd65-a0720d85df26", "metadata": {"aucs": [0.7764386350231617, 0.8156465157479178, 0.7951123862136498], "final_y": [0.14140877317235756, 0.1392978282776164, 0.13887156719471339]}, "mutation_prompt": null}
{"id": "fa74b0ba-aaf2-4651-bb6a-d35703c1561e", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim) # Modular structure initialization\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - self.current_evals / self.budget)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * np.random.rand()  # Changed line\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate  # Changed line\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3]) # Update modular structure\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0  # Adaptive scaling for local search\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.1  # Increase scale factor if improvement\n                else:\n                    scale_factor *= 0.9  # Changed line\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic integrating adaptive crossover and selective local search steps for optimizing multilayer structures.", "configspace": "", "generation": 6, "fitness": 0.8025999089347357, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.803 with standard deviation 0.011. And the mean value of best solutions found was 0.149 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "821e5944-4090-45f4-bd65-a0720d85df26", "metadata": {"aucs": [0.8033959395912527, 0.8160202355276535, 0.7883835516853006], "final_y": [0.14475825840481493, 0.15006381772707922, 0.1533430847849998]}, "mutation_prompt": null}
{"id": "40c171ff-ff38-4222-b886-bbc4601f3426", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            dynamic_pop_size = max(4, int(self.population_size * (1 - self.current_evals / self.budget)))\n            for i in range(dynamic_pop_size):\n                indices = list(range(dynamic_pop_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - self.current_evals / self.budget)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3]) \n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0 \n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.1 \n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic with dynamic population adaptation and improved modular structure preservation for robust multilayer optimization.", "configspace": "", "generation": 6, "fitness": 0.8096602508184243, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.810 with standard deviation 0.011. And the mean value of best solutions found was 0.139 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "821e5944-4090-45f4-bd65-a0720d85df26", "metadata": {"aucs": [0.7938965674427537, 0.8176237702804412, 0.8174604147320781], "final_y": [0.13463291823182122, 0.14720348281463858, 0.13589859087890988]}, "mutation_prompt": null}
{"id": "b28d287e-0ed1-4a70-9b80-d96f7c782a76", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - self.current_evals / self.budget)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + np.random.rand()) / 2  # Adaptive crossover rate\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate  # Use adaptive crossover rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.1\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.population_size = max(5, self.population_size // 2)  # Dynamically adjust population size\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic incorporating adaptive crossover and dynamic population size to optimize multilayer structures efficiently.", "configspace": "", "generation": 6, "fitness": 0.8221434546634692, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.822 with standard deviation 0.011. And the mean value of best solutions found was 0.139 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "821e5944-4090-45f4-bd65-a0720d85df26", "metadata": {"aucs": [0.834738988830007, 0.8076914453101056, 0.8239999298502951], "final_y": [0.13961859985106817, 0.14381544120272127, 0.13348613011795118]}, "mutation_prompt": null}
{"id": "0096116c-a0ec-4830-b15b-7680a0c43082", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim) # Modular structure initialization\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - self.current_evals / self.budget)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3]) # Update modular structure\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0  # Adaptive scaling for local search\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                direction = np.random.choice([-1, 1])  # New directional exploration\n                perturbed_solution[d] += direction * scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.1  # Increase scale factor if improvement\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced local search with directional exploration to improve convergence in multilayer structure optimization.", "configspace": "", "generation": 6, "fitness": 0.8016651280336419, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.802 with standard deviation 0.015. And the mean value of best solutions found was 0.144 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "821e5944-4090-45f4-bd65-a0720d85df26", "metadata": {"aucs": [0.7805775975355723, 0.8082981426757164, 0.8161196438896369], "final_y": [0.13237368156159368, 0.14984554755711144, 0.14919344108468913]}, "mutation_prompt": null}
{"id": "69677345-9075-4cbb-b66f-946433976417", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 + np.random.rand()) * (1 - self.current_evals / self.budget)  # Dynamic mutation factor\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + np.random.rand()) / 2\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.05 * (ub - lb)  # Adjusted step size\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.1\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.population_size = max(5, self.population_size // 2)\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Improved hybrid metaheuristic by incorporating a dynamic mutation factor and adaptive local search step size.", "configspace": "", "generation": 7, "fitness": 0.816465365096143, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.816 with standard deviation 0.007. And the mean value of best solutions found was 0.132 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "b28d287e-0ed1-4a70-9b80-d96f7c782a76", "metadata": {"aucs": [0.8191414706273975, 0.8233380932040291, 0.806916531457002], "final_y": [0.13086015857546307, 0.132718108501099, 0.13372249630651378]}, "mutation_prompt": null}
{"id": "4541c4e8-07b9-4242-99a9-66084a869a96", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - self.current_evals / self.budget)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + np.random.rand()) / 2  # Adaptive crossover rate\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate  # Use adaptive crossover rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.1\n                    break  # Added this line to improve efficiency by breaking early on success\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.population_size = max(5, self.population_size // 2)  # Dynamically adjust population size\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Optimized hybrid metaheuristic utilizing adaptive mutation and enhanced local search for efficient multilayer structure optimization.", "configspace": "", "generation": 7, "fitness": 0.8235751071934884, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.824 with standard deviation 0.007. And the mean value of best solutions found was 0.132 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "b28d287e-0ed1-4a70-9b80-d96f7c782a76", "metadata": {"aucs": [0.8167118816214602, 0.8323217843536739, 0.8216916556053311], "final_y": [0.13605925933237717, 0.13160019741163098, 0.1274664193658892]}, "mutation_prompt": null}
{"id": "67f070e6-519d-4899-ba26-c9f6bcb9915e", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - self.current_evals / self.budget)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + np.random.rand() * 0.5)  # More adaptive\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate  \n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial) + np.random.normal(0, 0.01)  # Robustness\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.1\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.population_size = max(5, self.population_size // 2)\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic with adaptive layer growth and robust escape mechanism to efficiently explore and optimize high-dimensional spaces.", "configspace": "", "generation": 7, "fitness": 0.833628300605182, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.834 with standard deviation 0.005. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "b28d287e-0ed1-4a70-9b80-d96f7c782a76", "metadata": {"aucs": [0.8318184008748282, 0.8398989013184079, 0.8291675996223097], "final_y": [0.11779319091109874, 0.12576538057432118, 0.13016456769092455]}, "mutation_prompt": null}
{"id": "032facac-9fbb-48cc-ad5b-7ced0f6e860d", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - self.current_evals / self.budget)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + np.random.rand()) / 2  # Adaptive crossover rate\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate  # Use adaptive crossover rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn() * (1 + 0.5 * np.random.rand())  # Changed line\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.1\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.population_size = max(5, self.population_size // 2)  # Dynamically adjust population size\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Introduced an adaptive scaling for the step size in local search to enhance exploration and refinement.", "configspace": "", "generation": 7, "fitness": 0.8219455924495506, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.822 with standard deviation 0.015. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "b28d287e-0ed1-4a70-9b80-d96f7c782a76", "metadata": {"aucs": [0.803409894661199, 0.8214055273894345, 0.8410213552980179], "final_y": [0.13318825332866024, 0.1317249186109446, 0.11810024813975517]}, "mutation_prompt": null}
{"id": "075f235c-105e-413f-88fd-7e44f25d1df1", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - self.current_evals / self.budget)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + np.random.rand()) / 2\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.1\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.population_size = max(5, self.population_size // 2)\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Improved hybrid metaheuristic with adaptive layer-wise modular adjustments and performance-based mutation scaling.", "configspace": "", "generation": 7, "fitness": 0.8285181751408667, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.829 with standard deviation 0.034. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "b28d287e-0ed1-4a70-9b80-d96f7c782a76", "metadata": {"aucs": [0.789368420102919, 0.8240019516475379, 0.8721841536721431], "final_y": [0.1278378287134898, 0.13178047031496964, 0.12542091205460792]}, "mutation_prompt": null}
