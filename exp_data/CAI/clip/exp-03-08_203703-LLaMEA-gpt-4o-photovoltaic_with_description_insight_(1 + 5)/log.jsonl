{"id": "b05c365c-7078-4931-8895-37150ff25106", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        \n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        \n        for _ in range(10):  # small number of local search iterations\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "A hybrid metaheuristic algorithm combining Differential Evolution (DE) with local search refinement and adaptive complexity management for optimizing multilayered structures.", "configspace": "", "generation": 0, "fitness": 0.7934345130606081, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.793 with standard deviation 0.013. And the mean value of best solutions found was 0.145 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": null, "metadata": {"aucs": [0.7753791132137795, 0.8040000248316164, 0.800924401136428], "final_y": [0.15116913440122715, 0.1494595286273257, 0.13422151900047108]}, "mutation_prompt": null}
{"id": "d074abd8-a4f7-4641-8690-0a4bfaccee36", "solution": "import numpy as np\n\nclass EnhancedHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n        self.min_mutation_factor = 0.5\n        self.max_mutation_factor = 1.0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        \n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                self.mutation_factor = self.min_mutation_factor + (\n                    np.random.rand() * (self.max_mutation_factor - self.min_mutation_factor)\n                )\n                mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                else:\n                    population[i] = population[i] + 0.01 * np.random.randn(*population[i].shape)  # Perturbation\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        \n        for _ in range(10):  # small number of local search iterations\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "EnhancedHybridMetaheuristic", "description": "An enhanced hybrid metaheuristic that integrates perturbation-based diversity control and dynamic scaling of mutation factors with local search refinement for improved optimization performance.", "configspace": "", "generation": 1, "fitness": 0.8053610423984622, "feedback": "The algorithm EnhancedHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.805 with standard deviation 0.024. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "b05c365c-7078-4931-8895-37150ff25106", "metadata": {"aucs": [0.7772387876631, 0.8369457646685181, 0.8018985748637686], "final_y": [0.15394668477852724, 0.13946218638382535, 0.14952585107600902]}, "mutation_prompt": null}
{"id": "3c40fab3-c10d-40fc-8a94-1c0d3f2193db", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        \n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - self.current_evals / self.budget)  # Adaptive mutation\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        \n        for _ in range(5 + self.dim // 10):  # Dynamic local search iterations\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic using adaptive mutation and dynamic local search for optimized multilayer structures.", "configspace": "", "generation": 1, "fitness": 0.8113287613563562, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.811 with standard deviation 0.009. And the mean value of best solutions found was 0.141 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "b05c365c-7078-4931-8895-37150ff25106", "metadata": {"aucs": [0.824382650166519, 0.8031555867667706, 0.8064480471357792], "final_y": [0.13238927306286408, 0.14456341252182758, 0.14528019163755457]}, "mutation_prompt": null}
{"id": "c14a8f21-1e9f-4f6e-9b1c-ee6922a024fc", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        \n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                # Changed line\n                self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Dynamic mutation factor\n                mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        \n        for _ in range(10):  # small number of local search iterations\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic algorithm by adjusting the mutation factor dynamically to improve convergence speed in optimizing multilayered structures.", "configspace": "", "generation": 1, "fitness": 0.8082365061759774, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.808 with standard deviation 0.015. And the mean value of best solutions found was 0.136 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "b05c365c-7078-4931-8895-37150ff25106", "metadata": {"aucs": [0.7960324524732373, 0.7996809644737791, 0.8289961015809157], "final_y": [0.13936603482448262, 0.13702989052386583, 0.13066719883894695]}, "mutation_prompt": null}
{"id": "a6b91e96-8486-4b7c-8512-75942ac918dc", "solution": "import numpy as np\n\nclass HybridMetaheuristicRefined:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def adaptive_differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        \n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                elif np.random.rand() < 0.1:\n                    self.mutation_factor = np.random.uniform(0.6, 1.0)\n                    self.crossover_rate = np.random.uniform(0.5, 0.9)\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def enhanced_local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        \n        for _ in range(20):  # increased iterations for local search\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        best_solution = self.adaptive_differential_evolution(func)\n        best_solution = self.enhanced_local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristicRefined", "description": "A refined hybrid metaheuristic integrating Adaptive Differential Evolution (ADE) with Enhanced Local Optimization (ELO) and adaptive complexity management for optimized multilayered structures.", "configspace": "", "generation": 1, "fitness": 0.7822761931106927, "feedback": "The algorithm HybridMetaheuristicRefined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.782 with standard deviation 0.014. And the mean value of best solutions found was 0.153 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "b05c365c-7078-4931-8895-37150ff25106", "metadata": {"aucs": [0.7620742640293293, 0.7945901820562783, 0.7901641332464706], "final_y": [0.15673717036062762, 0.1601017669387199, 0.14316260092427546]}, "mutation_prompt": null}
{"id": "8dbae6f1-9424-4234-a366-d904ebdcacd2", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        \n        while self.current_evals < self.budget:\n            elite_idx = np.argmin(fitness)\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n\n                if self.current_evals >= self.budget:\n                    break\n\n            population[elite_idx] = population[np.argmin(fitness)]\n        \n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        \n        for _ in range(10):  # small number of local search iterations\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced HybridMetaheuristic by incorporating elite selection to maintain and exploit high-quality solutions over generations.", "configspace": "", "generation": 1, "fitness": 0.799242776373624, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.799 with standard deviation 0.021. And the mean value of best solutions found was 0.149 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "b05c365c-7078-4931-8895-37150ff25106", "metadata": {"aucs": [0.7774505725918077, 0.8269157148559219, 0.7933620416731422], "final_y": [0.15686612077697792, 0.14342004606559466, 0.14567790066867659]}, "mutation_prompt": null}
{"id": "4ef1de09-758c-4ad5-a15a-046ec6e9d594", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10 * dim // 2, 5)  # Dynamic population size\n        self.mutation_factor = 0.9  # Adjusted mutation factor\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        \n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - self.current_evals / self.budget)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n\n                if self.current_evals >= self.budget:\n                    break\n\n            # Dynamic population resizing\n            if self.current_evals < self.budget // 2:\n                self.population_size = min(self.population_size + 1, 10 * self.dim)\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.05 * (ub - lb)  # Reduced step size for finer search\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Improved hybrid metaheuristic with dynamic population and layered search to enhance solution quality for multilayer structures.", "configspace": "", "generation": 2, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 50 is out of bounds for axis 0 with size 50').", "error": "IndexError('index 50 is out of bounds for axis 0 with size 50')", "parent_id": "3c40fab3-c10d-40fc-8a94-1c0d3f2193db", "metadata": {}, "mutation_prompt": null}
{"id": "46eba9a9-7037-4f07-9c03-372cc3b4c04c", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9  # Modified crossover rate\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        \n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - self.current_evals / self.budget)  # Adaptive mutation\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        \n        for _ in range(5 + self.dim // 10):  # Dynamic local search iterations\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic using adaptive mutation and dynamic local search for optimized multilayer structures with modified crossover strategy.", "configspace": "", "generation": 2, "fitness": 0.7965574904328822, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.797 with standard deviation 0.010. And the mean value of best solutions found was 0.137 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "3c40fab3-c10d-40fc-8a94-1c0d3f2193db", "metadata": {"aucs": [0.7905175976480969, 0.8100500996408518, 0.7891047740096979], "final_y": [0.13273202716738042, 0.13621820200378498, 0.14214782867993103]}, "mutation_prompt": null}
{"id": "2563124b-19ab-4708-9a1e-784d352e1f9a", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        \n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - self.current_evals / self.budget)  # Adaptive mutation\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 - self.current_evals / self.budget)  # Adaptive crossover\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        \n        for _ in range(5 + self.dim // 10):  # Dynamic local search iterations\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Improved hybrid metaheuristic with adaptive crossover rate for enhanced exploration and exploitation balance.", "configspace": "", "generation": 2, "fitness": 0.7970683855683879, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.797 with standard deviation 0.016. And the mean value of best solutions found was 0.137 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "3c40fab3-c10d-40fc-8a94-1c0d3f2193db", "metadata": {"aucs": [0.7747204068625214, 0.8053044241266794, 0.8111803257159628], "final_y": [0.13949690853683583, 0.14123335774587165, 0.13071093707885484]}, "mutation_prompt": null}
{"id": "821e5944-4090-45f4-bd65-a0720d85df26", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim) # Modular structure initialization\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - self.current_evals / self.budget)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3]) # Update modular structure\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0  # Adaptive scaling for local search\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.1  # Increase scale factor if improvement\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Improved hybrid metaheuristic incorporating modular structure identification and adaptive local search to optimize multilayer structures.", "configspace": "", "generation": 2, "fitness": 0.8212863021709892, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.821 with standard deviation 0.026. And the mean value of best solutions found was 0.138 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "3c40fab3-c10d-40fc-8a94-1c0d3f2193db", "metadata": {"aucs": [0.8025484382311292, 0.8583699388494727, 0.8029405294323654], "final_y": [0.13843344370203448, 0.1312826288016573, 0.14326047301557177]}, "mutation_prompt": null}
{"id": "31eeeb6e-936a-46e1-bc50-e56f03e676cc", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        \n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - self.current_evals / self.budget)  # Adaptive mutation\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n\n                if self.current_evals >= self.budget:\n                    break\n\n            # Dynamic adaptation of the population size\n            self.population_size = max(5, self.population_size - 1)  # Reduce population size gradually\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        \n        for _ in range(5 + self.dim // 10):  # Dynamic local search iterations\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Improved hybrid metaheuristic using adaptive population size and dynamic local search for optimized multilayer structures.", "configspace": "", "generation": 2, "fitness": 0.8106995507881845, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.811 with standard deviation 0.018. And the mean value of best solutions found was 0.136 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "3c40fab3-c10d-40fc-8a94-1c0d3f2193db", "metadata": {"aucs": [0.7870276589199423, 0.8305595078426233, 0.8145114856019879], "final_y": [0.13727861618799597, 0.13452145819699612, 0.13491576986639175]}, "mutation_prompt": null}
{"id": "abe4f67a-b6d2-4ff4-a3a7-0f951cd9fbd8", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim) # Modular structure initialization\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - self.current_evals / self.budget)\n                weight = np.linspace(0.5, 1.5, len(b)) # New: weighted mutation\n                mutant = np.clip(a + adaptive_mutation_factor * (weight * (b - c)), lb, ub) # Adjusted mutation application\n                adaptive_crossover_rate = self.crossover_rate + 0.2 * (1 - self.current_evals / self.budget) # New: adaptive crossover rate\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3]) # Update modular structure\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0  # Adaptive scaling for local search\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.1  # Increase scale factor if improvement\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic with weighted mutation and adaptive crossover rates.", "configspace": "", "generation": 3, "fitness": 0.8074966358993807, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.807 with standard deviation 0.032. And the mean value of best solutions found was 0.140 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "821e5944-4090-45f4-bd65-a0720d85df26", "metadata": {"aucs": [0.7650362691578755, 0.8408071646077104, 0.8166464739325563], "final_y": [0.15429859049386818, 0.1362340780277178, 0.13094886853516774]}, "mutation_prompt": null}
{"id": "28df44fa-80d8-48cf-bc9b-0da8c48a647f", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim) # Modular structure initialization\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - self.current_evals / self.budget)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate + 0.3 * (fitness[i] / (np.max(fitness) + 1e-9))\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3]) # Update modular structure\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0  # Adaptive scaling for local search\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor *= 1.2  # Increase scale factor more significantly if improvement\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic with adaptive crossover strategy and improved local search exploration to optimize multilayer structures.", "configspace": "", "generation": 3, "fitness": 0.8029290270349404, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.803 with standard deviation 0.008. And the mean value of best solutions found was 0.143 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "821e5944-4090-45f4-bd65-a0720d85df26", "metadata": {"aucs": [0.7917806312204033, 0.8088056496968619, 0.808200800187556], "final_y": [0.14346840295651375, 0.1499958191704429, 0.1358022034390729]}, "mutation_prompt": null}
{"id": "18297491-e9f5-4ff1-b29a-9aa5e7ae2293", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim) \n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - self.current_evals / self.budget)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + np.random.rand() * 0.1)  # Adaptive crossover\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate  # Adjusted line\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3]) \n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0  \n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * (np.random.randn() + np.random.choice([-1, 1]) * 0.1)  # Stochastic adjustment\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.1  \n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic with adaptive crossover and stochastic local search for optimizing multilayer structures.", "configspace": "", "generation": 3, "fitness": 0.8057541627092935, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.806 with standard deviation 0.019. And the mean value of best solutions found was 0.137 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "821e5944-4090-45f4-bd65-a0720d85df26", "metadata": {"aucs": [0.786648804550555, 0.8319044266245069, 0.7987092569528184], "final_y": [0.12485949076009284, 0.14064205811094965, 0.14667199509117246]}, "mutation_prompt": null}
{"id": "1f8bbc46-b0fd-4cac-8b1f-7300ecfa89be", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim) # Modular structure initialization\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - self.current_evals / self.budget)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                \n                # Change 1: Adaptive crossover rate\n                adaptive_crossover_rate = self.crossover_rate * (0.5 + 0.5 * np.random.rand())\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    \n                    # Change 2: Enhanced modular structure update\n                    modular_structure = (modular_structure + np.random.choice([2, 3], size=self.dim)) // 2\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0  # Adaptive scaling for local search\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.1  # Increase scale factor if improvement\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Refined hybrid metaheuristic with adaptive crossover and enhanced modular updates for improved convergence.", "configspace": "", "generation": 3, "fitness": 0.8034593908569322, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.803 with standard deviation 0.009. And the mean value of best solutions found was 0.142 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "821e5944-4090-45f4-bd65-a0720d85df26", "metadata": {"aucs": [0.8005934479606552, 0.8160081377096396, 0.7937765869005016], "final_y": [0.14149694374902044, 0.13606789201476355, 0.14801554711910303]}, "mutation_prompt": null}
{"id": "3e5b00fb-b1d3-44c2-88e5-fa23e08299f2", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim) # Modular structure initialization\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - self.current_evals / self.budget)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                \n                # Change here: Adapt crossover rate with progress\n                adaptive_crossover_rate = self.crossover_rate * (1 - self.current_evals / self.budget)\n                \n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3]) # Update modular structure\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0  # Adaptive scaling for local search\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.1  # Increase scale factor if improvement\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced hybrid algorithm with an adaptive crossover rate based on convergence progress for better exploration-exploitation balance.", "configspace": "", "generation": 3, "fitness": 0.8054582785740868, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.805 with standard deviation 0.006. And the mean value of best solutions found was 0.142 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "821e5944-4090-45f4-bd65-a0720d85df26", "metadata": {"aucs": [0.8003857544259992, 0.8026156263330838, 0.8133734549631777], "final_y": [0.1429689476267001, 0.14216085876200069, 0.1411319379700099]}, "mutation_prompt": null}
{"id": "180f9fa9-ba36-45a9-9a28-b9c29c803717", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim) # Modular structure initialization\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - self.current_evals / self.budget)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 - self.current_evals / self.budget)\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3]) # Update modular structure\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0  # Adaptive scaling for local search\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.1  # Increase scale factor if improvement\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Incorporate adaptive crossover rate in differential evolution to improve exploration-exploitation balance.", "configspace": "", "generation": 4, "fitness": 0.7991847666868969, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.799 with standard deviation 0.006. And the mean value of best solutions found was 0.145 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "821e5944-4090-45f4-bd65-a0720d85df26", "metadata": {"aucs": [0.7988414177761681, 0.8069613230688113, 0.7917515592157114], "final_y": [0.13626928089233847, 0.14883381666429762, 0.15085589095461116]}, "mutation_prompt": null}
{"id": "43e2a3f3-1d11-4a56-a5bd-e5ce11fc3595", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim) # Modular structure initialization\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - self.current_evals / self.budget)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 - self.current_evals / self.budget)  # Dynamically adjust crossover rate\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3]) # Update modular structure\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0  # Adaptive scaling for local search\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.1  # Increase scale factor if improvement\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced differential evolution by dynamically adjusting crossover rate based on remaining evaluations.", "configspace": "", "generation": 4, "fitness": 0.7990919515115401, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.799 with standard deviation 0.009. And the mean value of best solutions found was 0.147 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "821e5944-4090-45f4-bd65-a0720d85df26", "metadata": {"aucs": [0.7897958585291591, 0.8119448645965314, 0.7955351314089298], "final_y": [0.15129359596289305, 0.14536180178332903, 0.14487993482224792]}, "mutation_prompt": null}
{"id": "0ab24950-dbae-4d37-8243-7b42d23885e7", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.9  # Tweaked mutation factor for better exploration\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim) # Modular structure initialization\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - self.current_evals / self.budget)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3]) # Update modular structure\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.05 * (ub - lb)  # Reduced step size for finer local search refinement\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.1\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic by refining initialization and adaptive search mechanism to optimize multilayer structures efficiently.", "configspace": "", "generation": 4, "fitness": 0.7969196310926158, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.797 with standard deviation 0.013. And the mean value of best solutions found was 0.137 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "821e5944-4090-45f4-bd65-a0720d85df26", "metadata": {"aucs": [0.7782023952994218, 0.8083327946318394, 0.8042237033465858], "final_y": [0.13754519133391596, 0.12740585452498354, 0.145972398647912]}, "mutation_prompt": null}
{"id": "a9a2d920-45e4-4200-8129-6fed8a685e62", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9  # Enhanced crossover rate\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim) # Modular structure initialization\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1.2 - self.current_evals / self.budget)  # Adaptive mutation\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3]) # Update modular structure\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0  # Adaptive scaling for local search\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.1  # Increase scale factor if improvement\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Improved hybrid metaheuristic with enhanced crossover strategy and adaptive mutation for better exploration and convergence.", "configspace": "", "generation": 4, "fitness": 0.8050096481219894, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.805 with standard deviation 0.007. And the mean value of best solutions found was 0.142 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "821e5944-4090-45f4-bd65-a0720d85df26", "metadata": {"aucs": [0.7983683656078057, 0.8154177285126409, 0.8012428502455211], "final_y": [0.14147419384061377, 0.1411764250977331, 0.1432880297025948]}, "mutation_prompt": null}
{"id": "dac28b71-e865-4b1f-9fa5-eb875fa4efe1", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            self.crossover_rate = 0.5 if self.current_evals < self.budget / 2 else 0.9\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - self.current_evals / self.budget)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.1\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic with dynamic adjustment of crossover rates and adaptive population size.", "configspace": "", "generation": 4, "fitness": 0.8037482229630543, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.804 with standard deviation 0.011. And the mean value of best solutions found was 0.142 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "821e5944-4090-45f4-bd65-a0720d85df26", "metadata": {"aucs": [0.7883437028416937, 0.8127328348120385, 0.8101681312354305], "final_y": [0.1469131326632922, 0.13757864927061947, 0.14041492040882564]}, "mutation_prompt": null}
{"id": "f2c73a70-5550-46e5-be77-dd13318f5c48", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim) # Modular structure initialization\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - self.current_evals / self.budget)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 - self.current_evals / self.budget)  # Adaptive crossover rate\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3]) # Update modular structure\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0  # Adaptive scaling for local search\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.1  # Increase scale factor if improvement\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic by introducing adaptive crossover rate based on convergence progress to optimize multilayer structures.", "configspace": "", "generation": 5, "fitness": 0.8081461054547167, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.808 with standard deviation 0.011. And the mean value of best solutions found was 0.138 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "821e5944-4090-45f4-bd65-a0720d85df26", "metadata": {"aucs": [0.8018726661024642, 0.7991720264588149, 0.8233936238028708], "final_y": [0.1386817793074876, 0.14968391932386826, 0.12494111626613147]}, "mutation_prompt": null}
{"id": "831fbd80-7bb7-4fb2-9a50-55660606115b", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - self.current_evals / self.budget)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + 0.5 * np.random.rand())  # Changed line\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor *= 1.2  # Changed line\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic with adaptive crossover and dynamic local search scaling to optimize multilayer structures efficiently.", "configspace": "", "generation": 5, "fitness": 0.8044495001579927, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.804 with standard deviation 0.015. And the mean value of best solutions found was 0.143 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "821e5944-4090-45f4-bd65-a0720d85df26", "metadata": {"aucs": [0.7843804211304076, 0.8193898670618553, 0.8095782122817148], "final_y": [0.144522255127415, 0.14020981862529958, 0.14316653364082121]}, "mutation_prompt": null}
{"id": "5a4396cc-ef21-45e1-ac46-85f77c195eed", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim) # Modular structure initialization\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - self.current_evals / self.budget)\n                self.crossover_rate = 0.7 + 0.3 * (self.current_evals / self.budget) # Dynamic crossover rate\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3]) # Update modular structure\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0  # Adaptive scaling for local search\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.1  # Increase scale factor if improvement\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic adjusting crossover rate dynamically based on progress towards solving the optimization problem.", "configspace": "", "generation": 5, "fitness": 0.8017943411543239, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.802 with standard deviation 0.013. And the mean value of best solutions found was 0.144 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "821e5944-4090-45f4-bd65-a0720d85df26", "metadata": {"aucs": [0.8122584297266876, 0.8098909801884545, 0.7832336135478297], "final_y": [0.14575898383221175, 0.139826226018117, 0.14741021958615286]}, "mutation_prompt": null}
{"id": "783ae106-04aa-46db-8e5e-7869313ebd44", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim) # Modular structure initialization\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - self.current_evals / self.budget)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < (self.crossover_rate + 0.1 * (fitness[i] - np.min(fitness)) / (np.max(fitness) - np.min(fitness)))\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3]) # Update modular structure\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0  # Adaptive scaling for local search\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.1  # Increase scale factor if improvement\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced adaptive crossover leveraging problem-specific feedback to optimize multilayer structures.", "configspace": "", "generation": 5, "fitness": 0.8042970627233256, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.804 with standard deviation 0.014. And the mean value of best solutions found was 0.140 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "821e5944-4090-45f4-bd65-a0720d85df26", "metadata": {"aucs": [0.7866232517634746, 0.821754584847604, 0.8045133515588979], "final_y": [0.1416393906512915, 0.1395806017256025, 0.13788274076965334]}, "mutation_prompt": null}
{"id": "785b04c8-8bd7-4380-8a8e-542f6a71c9c7", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim) # Modular structure initialization\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - self.current_evals / self.budget)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3]) # Update modular structure\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.05 * (ub - lb)  # Reduced step size for finer tuning\n        scale_factor = 1.0  # Adaptive scaling for local search\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.1  # Increase scale factor if improvement\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic with refined local search using adaptive step size and exploration balance.", "configspace": "", "generation": 5, "fitness": 0.8058937044806633, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.806 with standard deviation 0.011. And the mean value of best solutions found was 0.137 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "821e5944-4090-45f4-bd65-a0720d85df26", "metadata": {"aucs": [0.7903759504622736, 0.8132250624993224, 0.8140801004803937], "final_y": [0.13146779419077126, 0.1437942203086111, 0.13439945786894214]}, "mutation_prompt": null}
{"id": "330cf417-9349-4dae-8b53-377b538dbaf7", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim) # Modular structure initialization\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - self.current_evals / self.budget)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3]) # Update modular structure\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0  # Adaptive scaling for local search\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor *= 1.05  # Increase scale factor slightly for dynamic neighborhood\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced local search by incorporating a dynamic neighborhood strategy to improve convergence.", "configspace": "", "generation": 6, "fitness": 0.795732512328243, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.796 with standard deviation 0.016. And the mean value of best solutions found was 0.140 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "821e5944-4090-45f4-bd65-a0720d85df26", "metadata": {"aucs": [0.7764386350231617, 0.8156465157479178, 0.7951123862136498], "final_y": [0.14140877317235756, 0.1392978282776164, 0.13887156719471339]}, "mutation_prompt": null}
{"id": "fa74b0ba-aaf2-4651-bb6a-d35703c1561e", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim) # Modular structure initialization\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - self.current_evals / self.budget)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * np.random.rand()  # Changed line\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate  # Changed line\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3]) # Update modular structure\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0  # Adaptive scaling for local search\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.1  # Increase scale factor if improvement\n                else:\n                    scale_factor *= 0.9  # Changed line\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic integrating adaptive crossover and selective local search steps for optimizing multilayer structures.", "configspace": "", "generation": 6, "fitness": 0.8025999089347357, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.803 with standard deviation 0.011. And the mean value of best solutions found was 0.149 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "821e5944-4090-45f4-bd65-a0720d85df26", "metadata": {"aucs": [0.8033959395912527, 0.8160202355276535, 0.7883835516853006], "final_y": [0.14475825840481493, 0.15006381772707922, 0.1533430847849998]}, "mutation_prompt": null}
{"id": "40c171ff-ff38-4222-b886-bbc4601f3426", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            dynamic_pop_size = max(4, int(self.population_size * (1 - self.current_evals / self.budget)))\n            for i in range(dynamic_pop_size):\n                indices = list(range(dynamic_pop_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - self.current_evals / self.budget)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3]) \n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0 \n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.1 \n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic with dynamic population adaptation and improved modular structure preservation for robust multilayer optimization.", "configspace": "", "generation": 6, "fitness": 0.8096602508184243, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.810 with standard deviation 0.011. And the mean value of best solutions found was 0.139 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "821e5944-4090-45f4-bd65-a0720d85df26", "metadata": {"aucs": [0.7938965674427537, 0.8176237702804412, 0.8174604147320781], "final_y": [0.13463291823182122, 0.14720348281463858, 0.13589859087890988]}, "mutation_prompt": null}
{"id": "b28d287e-0ed1-4a70-9b80-d96f7c782a76", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - self.current_evals / self.budget)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + np.random.rand()) / 2  # Adaptive crossover rate\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate  # Use adaptive crossover rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.1\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.population_size = max(5, self.population_size // 2)  # Dynamically adjust population size\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic incorporating adaptive crossover and dynamic population size to optimize multilayer structures efficiently.", "configspace": "", "generation": 6, "fitness": 0.8221434546634692, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.822 with standard deviation 0.011. And the mean value of best solutions found was 0.139 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "821e5944-4090-45f4-bd65-a0720d85df26", "metadata": {"aucs": [0.834738988830007, 0.8076914453101056, 0.8239999298502951], "final_y": [0.13961859985106817, 0.14381544120272127, 0.13348613011795118]}, "mutation_prompt": null}
{"id": "0096116c-a0ec-4830-b15b-7680a0c43082", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim) # Modular structure initialization\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - self.current_evals / self.budget)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3]) # Update modular structure\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0  # Adaptive scaling for local search\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                direction = np.random.choice([-1, 1])  # New directional exploration\n                perturbed_solution[d] += direction * scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.1  # Increase scale factor if improvement\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced local search with directional exploration to improve convergence in multilayer structure optimization.", "configspace": "", "generation": 6, "fitness": 0.8016651280336419, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.802 with standard deviation 0.015. And the mean value of best solutions found was 0.144 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "821e5944-4090-45f4-bd65-a0720d85df26", "metadata": {"aucs": [0.7805775975355723, 0.8082981426757164, 0.8161196438896369], "final_y": [0.13237368156159368, 0.14984554755711144, 0.14919344108468913]}, "mutation_prompt": null}
{"id": "69677345-9075-4cbb-b66f-946433976417", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 + np.random.rand()) * (1 - self.current_evals / self.budget)  # Dynamic mutation factor\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + np.random.rand()) / 2\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.05 * (ub - lb)  # Adjusted step size\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.1\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.population_size = max(5, self.population_size // 2)\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Improved hybrid metaheuristic by incorporating a dynamic mutation factor and adaptive local search step size.", "configspace": "", "generation": 7, "fitness": 0.816465365096143, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.816 with standard deviation 0.007. And the mean value of best solutions found was 0.132 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "b28d287e-0ed1-4a70-9b80-d96f7c782a76", "metadata": {"aucs": [0.8191414706273975, 0.8233380932040291, 0.806916531457002], "final_y": [0.13086015857546307, 0.132718108501099, 0.13372249630651378]}, "mutation_prompt": null}
{"id": "4541c4e8-07b9-4242-99a9-66084a869a96", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - self.current_evals / self.budget)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + np.random.rand()) / 2  # Adaptive crossover rate\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate  # Use adaptive crossover rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.1\n                    break  # Added this line to improve efficiency by breaking early on success\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.population_size = max(5, self.population_size // 2)  # Dynamically adjust population size\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Optimized hybrid metaheuristic utilizing adaptive mutation and enhanced local search for efficient multilayer structure optimization.", "configspace": "", "generation": 7, "fitness": 0.8235751071934884, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.824 with standard deviation 0.007. And the mean value of best solutions found was 0.132 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "b28d287e-0ed1-4a70-9b80-d96f7c782a76", "metadata": {"aucs": [0.8167118816214602, 0.8323217843536739, 0.8216916556053311], "final_y": [0.13605925933237717, 0.13160019741163098, 0.1274664193658892]}, "mutation_prompt": null}
{"id": "67f070e6-519d-4899-ba26-c9f6bcb9915e", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - self.current_evals / self.budget)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + np.random.rand() * 0.5)  # More adaptive\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate  \n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial) + np.random.normal(0, 0.01)  # Robustness\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.1\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.population_size = max(5, self.population_size // 2)\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic with adaptive layer growth and robust escape mechanism to efficiently explore and optimize high-dimensional spaces.", "configspace": "", "generation": 7, "fitness": 0.833628300605182, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.834 with standard deviation 0.005. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "b28d287e-0ed1-4a70-9b80-d96f7c782a76", "metadata": {"aucs": [0.8318184008748282, 0.8398989013184079, 0.8291675996223097], "final_y": [0.11779319091109874, 0.12576538057432118, 0.13016456769092455]}, "mutation_prompt": null}
{"id": "032facac-9fbb-48cc-ad5b-7ced0f6e860d", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - self.current_evals / self.budget)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + np.random.rand()) / 2  # Adaptive crossover rate\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate  # Use adaptive crossover rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn() * (1 + 0.5 * np.random.rand())  # Changed line\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.1\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.population_size = max(5, self.population_size // 2)  # Dynamically adjust population size\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Introduced an adaptive scaling for the step size in local search to enhance exploration and refinement.", "configspace": "", "generation": 7, "fitness": 0.8219455924495506, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.822 with standard deviation 0.015. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "b28d287e-0ed1-4a70-9b80-d96f7c782a76", "metadata": {"aucs": [0.803409894661199, 0.8214055273894345, 0.8410213552980179], "final_y": [0.13318825332866024, 0.1317249186109446, 0.11810024813975517]}, "mutation_prompt": null}
{"id": "075f235c-105e-413f-88fd-7e44f25d1df1", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - self.current_evals / self.budget)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + np.random.rand()) / 2\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.1\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.population_size = max(5, self.population_size // 2)\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Improved hybrid metaheuristic with adaptive layer-wise modular adjustments and performance-based mutation scaling.", "configspace": "", "generation": 7, "fitness": 0.8285181751408667, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.829 with standard deviation 0.034. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "b28d287e-0ed1-4a70-9b80-d96f7c782a76", "metadata": {"aucs": [0.789368420102919, 0.8240019516475379, 0.8721841536721431], "final_y": [0.1278378287134898, 0.13178047031496964, 0.12542091205460792]}, "mutation_prompt": null}
{"id": "f73b9f22-6708-42ca-93de-f014c65a70e5", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - self.current_evals / self.budget)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + np.random.rand() * 0.5)  # More adaptive\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate  \n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial) + np.random.normal(0, 0.01)  # Robustness\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.05 * (ub - lb)  # Reduced step size for finer exploration\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.2  # More aggressive scaling\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.population_size = max(5, self.population_size // 2)\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Optimized hybrid metaheuristic with adaptive scaling and enhanced local search for improved robustness against high-dimensional noise.", "configspace": "", "generation": 8, "fitness": 0.816318416297158, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.816 with standard deviation 0.006. And the mean value of best solutions found was 0.134 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "67f070e6-519d-4899-ba26-c9f6bcb9915e", "metadata": {"aucs": [0.8082589155253295, 0.8219006986508027, 0.8187956347153418], "final_y": [0.13008693896736478, 0.1390981947427179, 0.1332557574489106]}, "mutation_prompt": null}
{"id": "0701d207-ba36-4ca6-8eda-651ae9e98be6", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1.2 - self.current_evals / self.budget)  # Changed line\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + np.random.rand() * 0.5)  # More adaptive\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate  \n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial) + np.random.normal(0, 0.01)  # Robustness\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.1\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.population_size = max(5, self.population_size // 2)\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Optimized hybrid metaheuristic leveraging adaptive mutation factors for enhanced exploration and exploitation balance.", "configspace": "", "generation": 8, "fitness": 0.82202906799565, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.822 with standard deviation 0.012. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "67f070e6-519d-4899-ba26-c9f6bcb9915e", "metadata": {"aucs": [0.8054405291945603, 0.8306848755237811, 0.8299617992686088], "final_y": [0.13181278404283758, 0.13233740625425972, 0.12983954913305562]}, "mutation_prompt": null}
{"id": "f92d1088-80e4-4a22-b39d-6391a5641014", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - self.current_evals / self.budget)**1.5  # Modified\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + np.random.rand() * 0.5)  \n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate  \n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial) + np.random.normal(0, 0.01)  \n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.uniform(-1, 1)  # Modified\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.1\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.population_size = max(5, self.population_size // 2)\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic with improved adaptive mutation and diversified local search to efficiently explore and optimize high-dimensional spaces.", "configspace": "", "generation": 8, "fitness": 0.8211108131835555, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.821 with standard deviation 0.000. And the mean value of best solutions found was 0.130 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "67f070e6-519d-4899-ba26-c9f6bcb9915e", "metadata": {"aucs": [0.8217457761104802, 0.8210070504522566, 0.8205796129879297], "final_y": [0.12558315747684523, 0.13058425572452037, 0.13260652916594384]}, "mutation_prompt": null}
{"id": "7ff83a55-1d38-4682-9ec6-50a868cc82ec", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - (self.current_evals / self.budget) ** 0.5)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + np.random.rand() * 0.5)  # More adaptive\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate  \n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial) + np.random.normal(0, 0.01)  # Robustness\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.1\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.population_size = max(5, self.population_size // 2)\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Fine-tuned mutation factor's decay rate to enhance exploration while keeping within the given constraints.", "configspace": "", "generation": 8, "fitness": 0.8341342595383413, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.834 with standard deviation 0.009. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "67f070e6-519d-4899-ba26-c9f6bcb9915e", "metadata": {"aucs": [0.828871143022405, 0.8267471371618333, 0.8467844984307855], "final_y": [0.13050405070514293, 0.12806887571245806, 0.12235052070789731]}, "mutation_prompt": null}
{"id": "321fd10e-7603-4347-8ef9-2e1a3dac4ded", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - (self.current_evals + 1) / self.budget)  # Improved adaptation\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + np.random.rand() * 0.5)\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial) + np.random.normal(0, 0.01)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.1\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.population_size = max(5, self.population_size // 2)\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic with improved adaptive mutation factor reducing linearly over evaluations for efficient exploration.", "configspace": "", "generation": 8, "fitness": 0.8212851011027015, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.821 with standard deviation 0.008. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "67f070e6-519d-4899-ba26-c9f6bcb9915e", "metadata": {"aucs": [0.817904641998325, 0.8323934854445411, 0.8135571758652382], "final_y": [0.1236781652981569, 0.13396583749270408, 0.1347759781752642]}, "mutation_prompt": null}
{"id": "4ab40766-ccc1-4180-8cac-494471b594fc", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            dynamic_population_size = int(self.population_size * (1 - self.current_evals / self.budget))  # Adjusted line\n            for i in range(dynamic_population_size):\n                indices = list(range(dynamic_population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - (self.current_evals / self.budget) ** 0.5)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + np.random.rand() * 0.5)  # More adaptive\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate  \n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial) + np.random.normal(0, 0.01)  # Robustness\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.1\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.population_size = max(5, self.population_size // 2)\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Introduced dynamic population size adjustment during the differential evolution phase based on current evaluations to enhance exploration and resource allocation.", "configspace": "", "generation": 9, "fitness": -Infinity, "feedback": "An exception occurred: ValueError(\"Cannot take a larger sample than population when 'replace=False'\").", "error": "ValueError(\"Cannot take a larger sample than population when 'replace=False'\")", "parent_id": "7ff83a55-1d38-4682-9ec6-50a868cc82ec", "metadata": {}, "mutation_prompt": null}
{"id": "94f0bce9-f7a1-41db-9152-f73d0c67f550", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - (self.current_evals / self.budget) ** 0.5)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + np.random.rand() * 0.5)  # More adaptive\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate  \n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial) + np.random.normal(0, 0.01 * np.abs(func(trial)))  # Robustness\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.1\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.population_size = max(5, self.population_size // 2)\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced robustness by adjusting the noise added during evaluation to be proportional to the fitness, improving exploration and exploitation trade-off.", "configspace": "", "generation": 9, "fitness": -Infinity, "feedback": "An exception occurred: ValueError(\"Cannot take a larger sample than population when 'replace=False'\").", "error": "ValueError(\"Cannot take a larger sample than population when 'replace=False'\")", "parent_id": "7ff83a55-1d38-4682-9ec6-50a868cc82ec", "metadata": {}, "mutation_prompt": null}
{"id": "78dd5915-e663-4715-b145-843352181310", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - (self.current_evals / self.budget) ** 0.5)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + np.random.rand() * 0.5)  # More adaptive\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate  \n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial) + np.random.normal(0, 0.01)  # Robustness\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = np.clip(scale_factor * 1.1, 0.5, 2.0)  # Adaptive scale factor\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.population_size = max(5, self.population_size // 2)\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Introduce an adaptive scale factor to enhance the precision of local search.", "configspace": "", "generation": 9, "fitness": -Infinity, "feedback": "An exception occurred: ValueError(\"Cannot take a larger sample than population when 'replace=False'\").", "error": "ValueError(\"Cannot take a larger sample than population when 'replace=False'\")", "parent_id": "7ff83a55-1d38-4682-9ec6-50a868cc82ec", "metadata": {}, "mutation_prompt": null}
{"id": "83654ec9-dd01-489d-8655-88635bb5fb62", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (0.5 + np.random.rand() * 0.5)  # More dynamic\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + np.random.rand() * 0.5)\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate  \n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial) + np.random.normal(0, 0.01)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.05 * (ub - lb)  # Reduced step size\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * (0.5 + np.random.randn())  # Adaptive step\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor *= 1.1\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.population_size = max(5, self.population_size // 2)\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced HybridMetaheuristic with adaptive mutation and crossover strategies, dynamic modular structure tuning, and improved local search with adaptive step size for more robust convergence.", "configspace": "", "generation": 9, "fitness": -Infinity, "feedback": "An exception occurred: ValueError(\"Cannot take a larger sample than population when 'replace=False'\").", "error": "ValueError(\"Cannot take a larger sample than population when 'replace=False'\")", "parent_id": "7ff83a55-1d38-4682-9ec6-50a868cc82ec", "metadata": {}, "mutation_prompt": null}
{"id": "a86778f4-ec5a-4404-90c8-7b6c5ac8043c", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - (self.current_evals / self.budget) ** 0.55)  # Slightly modified\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + np.random.rand() * 0.4)  # Slightly modified\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate  \n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial) + np.random.normal(0, 0.01)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3], p=[0.5, 0.5])  # Added diversity control\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.1\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.population_size = max(5, self.population_size // 2)\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced adaptive mechanisms and introduced layer diversity control for improved convergence.", "configspace": "", "generation": 9, "fitness": -Infinity, "feedback": "An exception occurred: ValueError(\"Cannot take a larger sample than population when 'replace=False'\").", "error": "ValueError(\"Cannot take a larger sample than population when 'replace=False'\")", "parent_id": "7ff83a55-1d38-4682-9ec6-50a868cc82ec", "metadata": {}, "mutation_prompt": null}
{"id": "ffe53575-3234-4b87-8408-0246acb336e3", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - (self.current_evals / self.budget) ** 0.5)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + np.random.rand() * 0.5)  # More adaptive\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate  \n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial) + np.random.normal(0, 0.01)  # Robustness\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n            \n            # Dynamic population size adjustment\n            self.population_size = max(5, int(10 * self.dim * (1 - self.current_evals / self.budget)))\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.1\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.population_size = max(5, self.population_size // 2)\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced diversity by introducing a dynamic population size that decreases over time, improving convergence.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 61 is out of bounds for axis 0 with size 50').", "error": "IndexError('index 61 is out of bounds for axis 0 with size 50')", "parent_id": "7ff83a55-1d38-4682-9ec6-50a868cc82ec", "metadata": {}, "mutation_prompt": null}
{"id": "d7cfc438-de7e-49e8-b2c1-1a729636d634", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - (self.current_evals / self.budget) ** 0.5)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + np.random.rand() * 0.5)  # More adaptive\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate  \n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial) + np.random.normal(0, 0.01)  # Robustness\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.1\n                else:\n                    scale_factor *= 0.9  # Adaptive scaling factor\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.population_size = max(5, self.population_size // 2)\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Introduced adaptive scaling in local search to refine exploration and exploitation balance.", "configspace": "", "generation": 10, "fitness": 0.8228455995123697, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.823 with standard deviation 0.007. And the mean value of best solutions found was 0.132 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "7ff83a55-1d38-4682-9ec6-50a868cc82ec", "metadata": {"aucs": [0.8293951250840905, 0.8263163364108351, 0.8128253370421837], "final_y": [0.12799568088799962, 0.13910619893004417, 0.1303311107090055]}, "mutation_prompt": null}
{"id": "8c9f22db-d5a7-4cb4-9d07-4cefad131314", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - (self.current_evals / self.budget) ** 0.5)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + np.random.rand() * 0.5)  # More adaptive\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate  \n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial) + np.random.normal(0, 0.01)  # Robustness\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argsort(fitness)[:2]]  # Select top 2 diverse solutions\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.1\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.population_size = max(5, self.population_size // 2)\n        best_solution_candidates = self.differential_evolution(func)  # Changed line\n        best_solution = min(best_solution_candidates, key=func)  # Changed line\n        best_solution = self.local_search(best_solution, func)\n        return best_solution\n", "name": "HybridMetaheuristic", "description": "Improved solution selection by incorporating a fitness diversity mechanism to prevent premature convergence.", "configspace": "", "generation": 10, "fitness": 0.8329031351432151, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.833 with standard deviation 0.010. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "7ff83a55-1d38-4682-9ec6-50a868cc82ec", "metadata": {"aucs": [0.8201045993426679, 0.8350735697570226, 0.843531236329955], "final_y": [0.12614072184078873, 0.1321210599754692, 0.12261198359656755]}, "mutation_prompt": null}
{"id": "4013027a-e7d3-42df-8e4e-2868b4f44c1b", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - (self.current_evals / self.budget) ** 0.5)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + np.random.rand() * 0.7)  # More adaptive\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial) + np.random.normal(0, 0.01)  # Robustness\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.1\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.population_size = max(5, self.population_size // 2)\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Introduced adaptive mutation and crossover strategies to enhance convergence and robustness.", "configspace": "", "generation": 10, "fitness": 0.8269788200108468, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.827 with standard deviation 0.004. And the mean value of best solutions found was 0.130 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "7ff83a55-1d38-4682-9ec6-50a868cc82ec", "metadata": {"aucs": [0.8231071398447609, 0.8324074082410255, 0.8254219119467539], "final_y": [0.12917659975388895, 0.1324399803390649, 0.12829646393948846]}, "mutation_prompt": null}
{"id": "39ec97d7-495c-4540-85dd-7b3bed557d43", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - (self.current_evals / self.budget) ** 0.5)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + np.random.rand() * (0.5 - (self.current_evals / self.budget) * 0.45))  # More adaptive\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate  \n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial) + np.random.normal(0, 0.01)  # Robustness\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.1\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.population_size = max(5, self.population_size // 2)\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Introduce adaptive population resizing and a dynamic crossover rate to enhance the exploration-exploitation balance.", "configspace": "", "generation": 10, "fitness": 0.8328362550480861, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.833 with standard deviation 0.011. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "7ff83a55-1d38-4682-9ec6-50a868cc82ec", "metadata": {"aucs": [0.8410200146349026, 0.8403737049002944, 0.8171150456090612], "final_y": [0.12793647030871602, 0.1268843350317712, 0.13895108813397916]}, "mutation_prompt": null}
{"id": "379f3012-50bb-4982-b8cc-323a4373616f", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - (self.current_evals / self.budget) ** 0.5)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + np.random.rand() * 0.5)  # More adaptive\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate  \n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial) + np.random.normal(0, 0.01)  # Robustness\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.05  # Slightly reduced scaling factor for precision\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.population_size = max(5, self.population_size // 2)\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Improved the scaling factor in local search for enhanced refinement accuracy.", "configspace": "", "generation": 11, "fitness": 0.8495020713126052, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.850 with standard deviation 0.023. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "7ff83a55-1d38-4682-9ec6-50a868cc82ec", "metadata": {"aucs": [0.8178618022892917, 0.8578847671050461, 0.8727596445434775], "final_y": [0.13441045706097632, 0.11982029959862184, 0.11802860173834395]}, "mutation_prompt": null}
{"id": "669cf499-7b45-4f72-a335-f13b1502d3e2", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - (self.current_evals / self.budget) ** 0.5)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + np.random.rand() * 0.3)  # Slightly adjusted rate\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial) + np.random.normal(0, 0.01)  # Robustness\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.1\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.population_size = max(5, self.population_size // 2)\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhancing algorithm efficiency by tweaking the adaptive crossover rate for improved exploration.", "configspace": "", "generation": 11, "fitness": 0.8398363665867885, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.840 with standard deviation 0.027. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "7ff83a55-1d38-4682-9ec6-50a868cc82ec", "metadata": {"aucs": [0.8054157854894008, 0.843066872170047, 0.8710264421009177], "final_y": [0.12950596492287958, 0.12570845018191845, 0.11872837489250854]}, "mutation_prompt": null}
{"id": "fbff3b7b-d0c6-4642-8ed5-707d923b7b26", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - (self.current_evals / self.budget) ** 0.5)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + np.random.rand() * 0.5)  # More adaptive\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate  \n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial) + np.random.normal(0, 0.01)  # Robustness\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor *= 1.2  # Increase scale factor for better exploration\n                    step_size[d] *= 0.9  # Reduce step size to refine search\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.population_size = max(5, self.population_size // 2)\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced local search with adaptive step size and integration of feedback mechanism for improved exploration.", "configspace": "", "generation": 11, "fitness": 0.8381674159650676, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.838 with standard deviation 0.015. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "7ff83a55-1d38-4682-9ec6-50a868cc82ec", "metadata": {"aucs": [0.816743180799033, 0.8477965273400518, 0.8499625397561181], "final_y": [0.12692331141236224, 0.12801526936363916, 0.12694147534321232]}, "mutation_prompt": null}
{"id": "3ef55de4-9180-4dd9-aad1-c7787d584537", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - (self.current_evals / self.budget) ** 0.75)  # Adjusted decay\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + np.random.rand() * 0.5)  # More adaptive\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate  \n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial) + np.random.normal(0, 0.01)  # Robustness\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.1\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.population_size = max(5, self.population_size // 2)\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Improved exploration-exploitation balance by adjusting adaptive mutation factor decay.", "configspace": "", "generation": 11, "fitness": 0.847376500310696, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.847 with standard deviation 0.016. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "7ff83a55-1d38-4682-9ec6-50a868cc82ec", "metadata": {"aucs": [0.8257483803115859, 0.8548897127266817, 0.8614914078938201], "final_y": [0.1266028078058492, 0.12198505996327424, 0.11732913355712471]}, "mutation_prompt": null}
{"id": "c3068e61-f896-4c1a-8f9f-239d66136100", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.initial_population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.initial_population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n        \n        population_size = self.initial_population_size  # Start with initial population size\n\n        while self.current_evals < self.budget:\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - (self.current_evals / self.budget) ** 0.5)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + np.random.rand() * 0.5)\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate  \n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial) + np.random.normal(0, 0.01)  # Robustness\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n\n            # Adjust population size for dynamic exploration\n            if self.current_evals < self.budget // 2:\n                population_size = max(5, int(self.initial_population_size * 0.5))\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.1\n                else:\n                    scale_factor *= 0.9  # Reduce step size if no improvement\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.initial_population_size = max(5, self.initial_population_size // 2)\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced with adaptive population size control and refined local search for improved convergence.", "configspace": "", "generation": 11, "fitness": 0.8486540901432441, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.849 with standard deviation 0.010. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "7ff83a55-1d38-4682-9ec6-50a868cc82ec", "metadata": {"aucs": [0.8347944618051353, 0.8540554294920072, 0.8571123791325896], "final_y": [0.1259843683978472, 0.12210712677264601, 0.12169512221568546]}, "mutation_prompt": null}
{"id": "61505242-c609-46be-ad83-68bec43481b9", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - (self.current_evals / self.budget) ** 0.5)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + np.random.rand() * 0.5)  # More adaptive\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate  \n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial) + np.random.normal(0, 0.01)  # Robustness\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n\n            # Dynamic population size adjustment\n            if self.current_evals % (self.budget // 5) == 0:\n                self.population_size = min(20 * self.dim, self.population_size + 5)\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturb_amount = scale_factor * step_size[d] * np.random.randn() * (0.5 + np.random.rand())  # Improved perturbation\n                perturbed_solution[d] += perturb_amount\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.05  # Slightly reduced scaling factor for precision\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.population_size = max(5, self.population_size // 2)\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced exploration and refinement through dynamic population sizing and improved local search perturbation.", "configspace": "", "generation": 12, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 51 is out of bounds for axis 0 with size 50').", "error": "IndexError('index 51 is out of bounds for axis 0 with size 50')", "parent_id": "379f3012-50bb-4982-b8cc-323a4373616f", "metadata": {}, "mutation_prompt": null}
{"id": "215f6715-eedb-4bfa-bc98-a2bbefc2626f", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - (self.current_evals / self.budget) ** 0.5)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + np.random.rand() * 0.5)  # More adaptive\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate  \n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial) + np.random.normal(0, 0.01)  # Robustness\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.02  # Slightly reduced scaling factor for precision\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.population_size = max(5, self.population_size // 2)\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced local search precision by reducing the local search scale factor increment.", "configspace": "", "generation": 12, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 50 is out of bounds for axis 0 with size 50').", "error": "IndexError('index 50 is out of bounds for axis 0 with size 50')", "parent_id": "379f3012-50bb-4982-b8cc-323a4373616f", "metadata": {}, "mutation_prompt": null}
{"id": "cba0d32e-6e75-4a28-a2f4-dccfdbe41d4c", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.75  # Slightly increased crossover rate\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - (self.current_evals / self.budget) ** 0.5)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + np.random.rand() * 0.5)  # More adaptive\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate  \n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial) + np.random.normal(0, 0.01)  # Robustness\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.05  # Slightly reduced scaling factor for precision\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.population_size = max(5, self.population_size // 2)\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Slightly increase the crossover rate for improved trial solution diversity.", "configspace": "", "generation": 12, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 51 is out of bounds for axis 0 with size 50').", "error": "IndexError('index 51 is out of bounds for axis 0 with size 50')", "parent_id": "379f3012-50bb-4982-b8cc-323a4373616f", "metadata": {}, "mutation_prompt": null}
{"id": "07b86469-0c7b-4671-8d16-3f45b6cdda52", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - (self.current_evals / self.budget) ** 0.5)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + np.random.rand() * 0.5) * (1 - (self.current_evals / self.budget))  # More adaptive with dynamic scaling\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate  \n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial) + np.random.normal(0, 0.01)  # Robustness\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.05  # Slightly reduced scaling factor for precision\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.population_size = max(5, self.population_size // 2)\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced adaptive crossover rate by introducing dynamic scaling based on budget utilization.", "configspace": "", "generation": 12, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 52 is out of bounds for axis 0 with size 50').", "error": "IndexError('index 52 is out of bounds for axis 0 with size 50')", "parent_id": "379f3012-50bb-4982-b8cc-323a4373616f", "metadata": {}, "mutation_prompt": null}
{"id": "2eb6394b-e8f3-4ac0-88a7-481402566644", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - (self.current_evals / self.budget) ** 0.7)  # Changed from 0.5\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + np.random.rand() * 0.5)  # More adaptive\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate  \n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial) + np.random.normal(0, 0.01)  # Robustness\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor *= 1.1  # Changed from 1.05\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.population_size = max(5, self.population_size // 2)\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced local search adaptation and a more robust mutation scaling for better convergence.", "configspace": "", "generation": 12, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 52 is out of bounds for axis 0 with size 50').", "error": "IndexError('index 52 is out of bounds for axis 0 with size 50')", "parent_id": "379f3012-50bb-4982-b8cc-323a4373616f", "metadata": {}, "mutation_prompt": null}
{"id": "5600673c-5008-423d-b55d-8911e660a401", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - (self.current_evals / self.budget) ** 0.5)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + np.random.rand() * 0.5)  # More adaptive\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate  \n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial) + np.random.normal(0, 0.01)  # Robustness\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n\n            self.population_size = max(5, int(10 * self.dim * (1 - self.current_evals / self.budget)))\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.05  # Slightly reduced scaling factor for precision\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.population_size = max(5, self.population_size // 2)\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Introduced dynamic adjustment of population size based on current evaluation progress to enhance exploration-exploitation balance.", "configspace": "", "generation": 13, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 68 is out of bounds for axis 0 with size 50').", "error": "IndexError('index 68 is out of bounds for axis 0 with size 50')", "parent_id": "379f3012-50bb-4982-b8cc-323a4373616f", "metadata": {}, "mutation_prompt": null}
{"id": "d0c52339-5d4f-4c26-848e-6e731f7caf6d", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - (self.current_evals / self.budget) ** 0.5)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + np.random.rand() * (0.8 - 0.5))  # More adaptive\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate  \n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial) + np.random.normal(0, 0.01)  # Robustness\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.05  # Slightly reduced scaling factor for precision\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.population_size = max(5, self.population_size // 2)\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced crossover strategy to dynamically adjust exploration and exploitation balance.", "configspace": "", "generation": 13, "fitness": 0.8261114899653074, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.826 with standard deviation 0.015. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "379f3012-50bb-4982-b8cc-323a4373616f", "metadata": {"aucs": [0.8454225176744317, 0.8250784936400297, 0.8078334585814607], "final_y": [0.12765417717595184, 0.13753342833266136, 0.1291486417380754]}, "mutation_prompt": null}
{"id": "bf8d0802-ccb5-4421-a94a-e83573d54cdc", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - (self.current_evals / self.budget) ** 0.5)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 - self.current_evals / self.budget)  # Adjusted\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate  \n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial) + np.random.normal(0, 0.01)  # Robustness\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.05  # Slightly reduced scaling factor for precision\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.population_size = max(5, self.population_size // 2)\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhancing convergence by adjusting crossover dynamics based on iteration progress.", "configspace": "", "generation": 13, "fitness": 0.8264732966531702, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.826 with standard deviation 0.003. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "379f3012-50bb-4982-b8cc-323a4373616f", "metadata": {"aucs": [0.8271019809505101, 0.8298138083053036, 0.8225041007036971], "final_y": [0.13467741569656078, 0.13558113831590746, 0.13003782860595858]}, "mutation_prompt": null}
{"id": "b780f41d-ebe3-4ff0-9e8b-01a4b8ce8d3e", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - (self.current_evals / self.budget) ** 0.5)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + np.random.rand() * 0.5)  # More adaptive\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate  \n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial) + np.random.normal(0, 0.01)  # Robustness\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.05 * (ub - lb)  # Adjusted step size for precision\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.05  # Slightly reduced scaling factor for precision\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.population_size = max(5, self.population_size // 2)\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced local search accuracy by updating perturbation step size, improving solution refinement.", "configspace": "", "generation": 13, "fitness": 0.834942478863706, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.835 with standard deviation 0.009. And the mean value of best solutions found was 0.130 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "379f3012-50bb-4982-b8cc-323a4373616f", "metadata": {"aucs": [0.8357945775071247, 0.8457813767063035, 0.8232514823776897], "final_y": [0.12342997045458515, 0.13317012738780332, 0.13255913792188356]}, "mutation_prompt": null}
{"id": "f23a753a-2dce-4b38-8f15-218671057305", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - (self.current_evals / self.budget) ** 0.5)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + np.random.rand() * 0.5)  # More adaptive\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate  \n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial) + np.random.normal(0, 0.01)  # Robustness\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.1  # Adjusted scaling factor for better exploration\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.population_size = max(5, self.population_size // 2)\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Introduced adaptive scaling factors for local search to enhance exploration-exploitation balance.", "configspace": "", "generation": 13, "fitness": 0.8219285164498603, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.822 with standard deviation 0.011. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "379f3012-50bb-4982-b8cc-323a4373616f", "metadata": {"aucs": [0.8086734034313828, 0.8218984147615995, 0.8352137311565982], "final_y": [0.13396724724906184, 0.13658179130831705, 0.12777903053423023]}, "mutation_prompt": null}
{"id": "ca831cf8-f198-42f0-af4f-6a8616916d6e", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - (self.current_evals / self.budget) ** 0.5)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + np.random.rand() * (func(ind) / np.mean(fitness)))  # More adaptive\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate  \n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial) + np.random.normal(0, 0.01)  # Robustness\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.05  # Slightly reduced scaling factor for precision\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.population_size = max(5, self.population_size // 2)\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Introduced adaptive crossover rate scaling for improved exploration-exploitation balance.", "configspace": "", "generation": 14, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'ind' is not defined\").", "error": "NameError(\"name 'ind' is not defined\")", "parent_id": "379f3012-50bb-4982-b8cc-323a4373616f", "metadata": {}, "mutation_prompt": null}
{"id": "58900f96-330f-4266-a31b-49f981ca9c3a", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            fitness_rank = np.argsort(fitness)\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - (fitness_rank[i] / self.population_size))\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + np.random.rand() * 0.5)\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate  \n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial) + np.random.normal(0, 0.01) \n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.05  \n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.population_size = max(5, self.population_size // 2)\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced diversity by varying the mutation factor adaptively based on individual's rank.", "configspace": "", "generation": 14, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'ind' is not defined\").", "error": "NameError(\"name 'ind' is not defined\")", "parent_id": "379f3012-50bb-4982-b8cc-323a4373616f", "metadata": {}, "mutation_prompt": null}
{"id": "9ff6183c-5f39-430c-ad6e-0f06e21970e4", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - (self.current_evals / self.budget) ** 0.5)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + np.random.rand() * 0.5)  # More adaptive\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate  \n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial) + np.random.normal(0, 0.01)  # Robustness\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                adaptive_step_size = step_size[d] * (1 - (self.current_evals / self.budget) ** 0.5)  # Adaptive step size\n                perturbed_solution[d] += scale_factor * adaptive_step_size * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.05\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.population_size = max(5, self.population_size // 2)\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Introduced adaptive step size in local search for improved exploration-exploitation balance.", "configspace": "", "generation": 14, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'ind' is not defined\").", "error": "NameError(\"name 'ind' is not defined\")", "parent_id": "379f3012-50bb-4982-b8cc-323a4373616f", "metadata": {}, "mutation_prompt": null}
{"id": "ad8171ef-8431-42d3-8d01-bed98ac23433", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - (self.current_evals / self.budget) ** 0.5)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + np.random.rand() * 0.5)  # More adaptive\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate  \n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial) + np.random.normal(0, 0.01)  # Robustness\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.05  # Slightly reduced scaling factor for precision\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.population_size = max(5, int((10 * self.dim) * (1 - (self.current_evals/self.budget))))  # Dynamic adaptation\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Introduced dynamic population size adaptation for enhanced exploration-exploitation balance.", "configspace": "", "generation": 14, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'ind' is not defined\").", "error": "NameError(\"name 'ind' is not defined\")", "parent_id": "379f3012-50bb-4982-b8cc-323a4373616f", "metadata": {}, "mutation_prompt": null}
{"id": "c2533d46-b628-4972-b698-b5cdd989c9e3", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.85  # Adjusted for better exploration\n        self.crossover_rate = 0.75   # Adjusted for better exploration\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - (self.current_evals / self.budget) ** 0.5)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + np.random.rand() * 0.5)\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate  \n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial) + np.random.normal(0, 0.005)  # Reduced noise for robustness\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    if i % 2 == 0:  # Encourage adaptive modular structure\n                        modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.05 * (ub - lb)  # Reduced step size for precision\n        scale_factor = 0.95  # Reduced for precision\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor *= 0.98  # Further reduce scale for next iterations\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.population_size = max(5, self.population_size // 2)\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Hybrid metaheuristic with adaptive layer structuring and improved local search precision.", "configspace": "", "generation": 14, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'ind' is not defined\").", "error": "NameError(\"name 'ind' is not defined\")", "parent_id": "379f3012-50bb-4982-b8cc-323a4373616f", "metadata": {}, "mutation_prompt": null}
{"id": "10155a42-2d5f-4b5b-9f67-e35127117ec0", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                diversity_factor = 1 + np.random.uniform(-0.1, 0.1)  # Introduce diversity\n                adaptive_mutation_factor = self.mutation_factor * (1 - (self.current_evals / self.budget) ** 0.5) * diversity_factor\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + np.random.rand() * 0.5)  # More adaptive\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate  \n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial) + np.random.normal(0, 0.01)  # Robustness\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.05  # Slightly reduced scaling factor for precision\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.population_size = max(5, self.population_size // 2)\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced exploration by introducing diversity in mutation scaling for better global search.", "configspace": "", "generation": 15, "fitness": 0.8405781880699039, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.841 with standard deviation 0.013. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "379f3012-50bb-4982-b8cc-323a4373616f", "metadata": {"aucs": [0.8295910695181162, 0.8587414358068957, 0.8334020588846999], "final_y": [0.12920356027514124, 0.12210812568987783, 0.12821091915254512]}, "mutation_prompt": null}
{"id": "223583b7-eb9c-42cb-949f-18d97d2a4759", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - (self.current_evals / self.budget) ** 0.75)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + np.random.rand() * 0.8)  # More adaptive\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial) + np.random.normal(0, 0.01)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.05  \n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.population_size = max(5, self.population_size // 2)\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced adaptive mutation and crossover for improved exploitation and exploration balance.", "configspace": "", "generation": 15, "fitness": 0.8368376156386556, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.837 with standard deviation 0.016. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "379f3012-50bb-4982-b8cc-323a4373616f", "metadata": {"aucs": [0.8152909287173828, 0.8543885767682566, 0.840833341430327], "final_y": [0.1315124425999049, 0.12416713727065687, 0.12790358680221414]}, "mutation_prompt": null}
{"id": "16297bbb-1935-41a2-a051-49364075f6c1", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - (self.current_evals / self.budget) ** 0.3)  # Enhanced exploration\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + np.random.rand() * 0.5)\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate  \n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial) + np.random.normal(0, 0.01)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.02  # Adjusted scale factor for improved precision\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.population_size = max(5, self.population_size // 2)\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced exploration by adjusting mutation factor and refined local search with adaptive step size.", "configspace": "", "generation": 15, "fitness": 0.8464688321064139, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.846 with standard deviation 0.019. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "379f3012-50bb-4982-b8cc-323a4373616f", "metadata": {"aucs": [0.8200899271336046, 0.8646689327554488, 0.8546476364301886], "final_y": [0.12525174655117344, 0.121631399348059, 0.1261709686975776]}, "mutation_prompt": null}
{"id": "75039222-4188-46ad-8348-8826d198a52e", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                # Adjusted decay rate in adaptive mutation factor\n                adaptive_mutation_factor = self.mutation_factor * (1 - (self.current_evals / self.budget) ** 0.3)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + np.random.rand() * 0.5)  # More adaptive\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate  \n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial) + np.random.normal(0, 0.01)  # Robustness\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.05  # Slightly reduced scaling factor for precision\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.population_size = max(5, self.population_size // 2)\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Adjusted the mutation factor decay rate in the differential evolution process for a more balanced exploration-exploitation trade-off.", "configspace": "", "generation": 15, "fitness": 0.816296861908565, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.816 with standard deviation 0.009. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "379f3012-50bb-4982-b8cc-323a4373616f", "metadata": {"aucs": [0.8156266923560518, 0.8272561100421683, 0.8060077833274752], "final_y": [0.12932112504954063, 0.12045692308526257, 0.12972402980908226]}, "mutation_prompt": null}
{"id": "8c23af8f-e26c-443f-a029-ec8ba4115c6c", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            self.population_size = max(5, int(self.population_size * (1 - self.current_evals / self.budget)))  # Adaptive population size\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - (self.current_evals / self.budget) ** 0.5)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + np.random.rand() * 0.5)\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate  \n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial) + np.random.normal(0, 0.01)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            dynamic_intensity = int(5 * (1 + (self.current_evals / self.budget)))  # Dynamic local search intensity\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.05\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.population_size = max(5, self.population_size // 2)\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Introducing adaptive population size and dynamic local search intensity to enhance exploration and refinement balance.", "configspace": "", "generation": 15, "fitness": 0.8330658419760074, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.833 with standard deviation 0.020. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "379f3012-50bb-4982-b8cc-323a4373616f", "metadata": {"aucs": [0.8089146284990703, 0.8579058876383694, 0.8323770097905826], "final_y": [0.146100453569448, 0.12084940718957393, 0.1260641696838961]}, "mutation_prompt": null}
{"id": "18b21bb5-3f67-4d8e-9b07-100230b57102", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - (self.current_evals / self.budget) ** 0.3)  # Changed exponent for mutation\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + np.random.rand() * 0.5)  # More adaptive\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate  \n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial) + np.random.normal(0, 0.005)  # Reduced noise for robustness\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.05  # Slightly reduced scaling factor for precision\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.population_size = max(5, self.population_size // 2)\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced mutation strategy and robustness handling in local search for improved exploration and solution quality.", "configspace": "", "generation": 16, "fitness": 0.8335068583639041, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.834 with standard deviation 0.020. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "379f3012-50bb-4982-b8cc-323a4373616f", "metadata": {"aucs": [0.8121374719256416, 0.8607924561595731, 0.8275906470064974], "final_y": [0.1284689516945291, 0.11637752742196883, 0.13029680570496005]}, "mutation_prompt": null}
{"id": "cee8308e-d868-4cd7-9589-47995bdc7332", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * np.sin(np.pi * (1 - (self.current_evals / self.budget)))  # Changed line\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + np.random.rand() * 0.5)  # More adaptive\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate  \n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial) + np.random.normal(0, 0.01)  # Robustness\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.05  # Slightly reduced scaling factor for precision\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.population_size = max(5, self.population_size // 2)\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced mutation factor adaptivity by introducing a sine-based cooling schedule.", "configspace": "", "generation": 16, "fitness": 0.8299819667770865, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.830 with standard deviation 0.020. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "379f3012-50bb-4982-b8cc-323a4373616f", "metadata": {"aucs": [0.8095247352498853, 0.8239090688214123, 0.8565120962599616], "final_y": [0.12752294519997232, 0.13155445329807558, 0.12252590371678773]}, "mutation_prompt": null}
{"id": "f32ed89f-8615-41e6-8c50-cd7195691c07", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - (self.current_evals / self.budget) ** 0.7)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + np.random.rand() * 0.3)  \n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial) + np.random.normal(0, 0.01)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.05\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.population_size = max(5, self.population_size // 2)\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced exploration with adaptive population dynamics and selective layer expansion for improved optimization.", "configspace": "", "generation": 16, "fitness": 0.8137507148536659, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.814 with standard deviation 0.018. And the mean value of best solutions found was 0.139 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "379f3012-50bb-4982-b8cc-323a4373616f", "metadata": {"aucs": [0.791328877257975, 0.8142974957235534, 0.8356257715794695], "final_y": [0.13838933623214245, 0.1471293098546249, 0.1328822285992327]}, "mutation_prompt": null}
{"id": "949810fc-28f1-4171-9039-97cf940550b0", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                convergence_speed = 1 - (self.current_evals / self.budget)\n                adaptive_mutation_factor = self.mutation_factor * (1 - (convergence_speed) ** 0.5)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + convergence_speed * 0.5)  # More adaptive\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate  \n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial) + np.random.normal(0, 0.01)  # Robustness\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.05  # Slightly reduced scaling factor for precision\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.population_size = max(5, self.population_size // 2)\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced exploration by introducing a variable mutation and crossover strategy that adapts based on convergence speed.", "configspace": "", "generation": 16, "fitness": 0.8182513385919371, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.818 with standard deviation 0.011. And the mean value of best solutions found was 0.135 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "379f3012-50bb-4982-b8cc-323a4373616f", "metadata": {"aucs": [0.8056435148518829, 0.832132475170949, 0.8169780257529795], "final_y": [0.13179703517448726, 0.1297321398084642, 0.14213855118143148]}, "mutation_prompt": null}
{"id": "8ed01d8c-6f56-4e62-8ec6-b7135c3a6ab3", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - (self.current_evals / self.budget) ** 0.5)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + np.random.rand() * 0.5)  # More adaptive\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate  \n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial) + np.random.normal(0, 0.01)  # Robustness\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.05 * (ub - lb)  # Reduced step size for enhanced precision\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.05  # Slightly reduced scaling factor for precision\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.population_size = max(5, self.population_size // 2)\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced local search precision by tweaking perturbation step size calculation.", "configspace": "", "generation": 16, "fitness": 0.8353314576348619, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.835 with standard deviation 0.023. And the mean value of best solutions found was 0.137 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "379f3012-50bb-4982-b8cc-323a4373616f", "metadata": {"aucs": [0.8671410267636208, 0.8136924223365556, 0.8251609238044092], "final_y": [0.11746983692836233, 0.14856679269315087, 0.1435729996545655]}, "mutation_prompt": null}
{"id": "4f97b114-0ffb-43b1-abc5-4e489e3bc976", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - (self.current_evals / self.budget) ** 0.5)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + np.random.rand() * 0.7)  # More adaptive\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate  \n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial) + np.random.normal(0, 0.01)  # Robustness\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.05  # Slightly reduced scaling factor for precision\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.population_size = max(5, self.population_size // 2)\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Increased crossover rate adaptivity to enhance exploration and exploitation balance for better solution refinement.", "configspace": "", "generation": 17, "fitness": 0.8273544045662234, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.827 with standard deviation 0.015. And the mean value of best solutions found was 0.129 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "379f3012-50bb-4982-b8cc-323a4373616f", "metadata": {"aucs": [0.8078273438355508, 0.842888183298621, 0.8313476865644984], "final_y": [0.13263481401247113, 0.12786751590555978, 0.12577505072800932]}, "mutation_prompt": null}
{"id": "05a966cc-f3a2-4038-9348-f565121605b4", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - (self.current_evals / self.budget) ** 0.5)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                diversity_factor = np.std(population) / (ub - lb)  # New dynamic adjustment\n                adaptive_crossover_rate = self.crossover_rate * (1 + np.random.rand() * 0.5) + diversity_factor\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate  \n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial) + np.random.normal(0, 0.01)  # Robustness\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.05  # Slightly reduced scaling factor for precision\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.population_size = max(5, self.population_size // 2)\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced crossover strategy by dynamically adjusting crossover rate based on ongoing population diversity.", "configspace": "", "generation": 17, "fitness": 0.8410586294927148, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.841 with standard deviation 0.018. And the mean value of best solutions found was 0.129 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "379f3012-50bb-4982-b8cc-323a4373616f", "metadata": {"aucs": [0.8154584349569867, 0.8523912970911396, 0.8553261564300185], "final_y": [0.1363127867565399, 0.12480871144516581, 0.12597059853795745]}, "mutation_prompt": null}
{"id": "e6b230fa-1b7c-4ce1-a2aa-d18171583594", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - (self.current_evals / self.budget) ** 0.5)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + np.random.rand() * 0.5)  # More adaptive\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate  \n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial) + np.random.normal(0, 0.005)  # Robustness, adjusted noise\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.05  # Slightly reduced scaling factor for precision\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.population_size = max(5, self.population_size // 2)\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced local search precision by adjusting the random noise in the differential evolution step.", "configspace": "", "generation": 17, "fitness": 0.8442220721103683, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.844 with standard deviation 0.005. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "379f3012-50bb-4982-b8cc-323a4373616f", "metadata": {"aucs": [0.8381994460233927, 0.8445766678957158, 0.8498901024119966], "final_y": [0.1340839542141189, 0.12808638811043827, 0.12276194183253641]}, "mutation_prompt": null}
{"id": "96ccbf05-5cea-4549-8923-b36f6b85dcd5", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - (self.current_evals / self.budget) ** 0.5)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + np.random.rand() * 0.5)  # More adaptive\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate  \n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial) + np.random.normal(0, 0.01)  # Robustness\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 8):  # Adjusted local search iterations\n            perturbed_solutions = [np.copy(best_solution) for _ in range(3)]\n            for d in range(self.dim):\n                for i in range(3):  # Elite strategy with multiple perturbations\n                    perturbed_solutions[i][d] += scale_factor * step_size[d] * np.random.randn()\n                    perturbed_solutions[i] = np.clip(perturbed_solutions[i], lb, ub)\n            evaluated_solutions = [(func(pert), pert) for pert in perturbed_solutions]\n            self.current_evals += len(perturbed_solutions)\n            best_evaluation = min(evaluated_solutions, key=lambda x: x[0])\n\n            if best_evaluation[0] < func(best_solution):\n                best_solution = best_evaluation[1]\n                scale_factor = 1.05  # Slightly reduced scaling factor for precision\n\n            if self.current_evals >= self.budget:\n                break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.population_size = max(5, self.population_size // 2)\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced local search by dynamically adjusting the iteration count and incorporating an elite strategy.", "configspace": "", "generation": 17, "fitness": 0.8298129056497915, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.830 with standard deviation 0.028. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "379f3012-50bb-4982-b8cc-323a4373616f", "metadata": {"aucs": [0.7989914614665471, 0.8664188686687789, 0.8240283868140486], "final_y": [0.1389059120144126, 0.12523903122742897, 0.12856302241711515]}, "mutation_prompt": null}
{"id": "d2d05614-ab6a-4a70-86e9-f132862f107f", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - (self.current_evals / self.budget) ** 0.5)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + np.random.rand() * 0.5)  # More adaptive\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate  \n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial) + np.random.normal(0, 0.01)  # Robustness\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.05  # Slightly reduced scaling factor for precision\n                \n                # Adding adaptive restart\n                if self.current_evals % (self.population_size // 2) == 0:  \n                    best_solution = lb + (ub - lb) * np.random.rand(self.dim)\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.population_size = max(5, self.population_size // 2)\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced local deterministic pattern search by adding adaptive restart mechanism for improved exploration.", "configspace": "", "generation": 17, "fitness": 0.8398278622234807, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.840 with standard deviation 0.004. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "379f3012-50bb-4982-b8cc-323a4373616f", "metadata": {"aucs": [0.8338022838919463, 0.84346177661887, 0.8422195261596259], "final_y": [0.122476979594215, 0.12376734188911975, 0.12329119616587092]}, "mutation_prompt": null}
{"id": "14dd6889-e444-4e0d-89cf-82e210a336e2", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - (self.current_evals / self.budget) ** 0.2)  # Changed mutation factor adaptation\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + np.random.rand() * 0.5)\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate  \n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial) + np.random.normal(0, 0.01)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.05\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.population_size = max(5, self.population_size // 2)\n        best_solution = self.differential_evolution(func)\n        self.population_size = max(5, self.population_size * 3 // 4)  # Changed population resizing strategy\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Introduced dynamic population resizing and improved mutation for enhanced exploration.", "configspace": "", "generation": 18, "fitness": 0.8465418901291982, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.847 with standard deviation 0.005. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "379f3012-50bb-4982-b8cc-323a4373616f", "metadata": {"aucs": [0.848262821153483, 0.8521186103187257, 0.839244238915386], "final_y": [0.11986421578989792, 0.12569132839300878, 0.12538738869860744]}, "mutation_prompt": null}
{"id": "70b3a136-8304-48a3-8fbd-526c03b06609", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - (self.current_evals / self.budget) ** 0.7)  # Adjusted power\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + np.random.rand() * 0.3)  # Narrowed range\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate  \n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial) + np.random.normal(0, 0.01)  # Robustness\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.05  # Slightly reduced scaling factor for precision\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.population_size = max(5, self.population_size // 2)\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced adaptive mutation and crossover strategies for improved exploration-exploitation balance.", "configspace": "", "generation": 18, "fitness": 0.820753001441637, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.821 with standard deviation 0.023. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "379f3012-50bb-4982-b8cc-323a4373616f", "metadata": {"aucs": [0.7899908127102224, 0.8264291814041622, 0.8458390102105265], "final_y": [0.13276051078511264, 0.13611261015487652, 0.12506799134815316]}, "mutation_prompt": null}
{"id": "f4789576-b414-47ce-865b-8249a9ffea76", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - (self.current_evals / self.budget) ** 0.5)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + np.random.rand() * 0.5 * (fitness[i] / np.mean(fitness)))  # More adaptive\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate  \n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial) + np.random.normal(0, 0.01)  # Robustness\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.05  # Slightly reduced scaling factor for precision\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.population_size = max(5, self.population_size // 2)\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced exploration with dynamic crossover rate adjustment based on convergence status.", "configspace": "", "generation": 18, "fitness": 0.823792702087788, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.824 with standard deviation 0.001. And the mean value of best solutions found was 0.132 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "379f3012-50bb-4982-b8cc-323a4373616f", "metadata": {"aucs": [0.8257322113980702, 0.8226229654066072, 0.8230229294586867], "final_y": [0.13300385468178744, 0.1355587932892256, 0.12885983967582282]}, "mutation_prompt": null}
{"id": "2940f7e5-0c0c-4d83-a76e-7e067e39983a", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - (self.current_evals / self.budget) ** 0.5)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + np.random.rand() * 0.5)  # More adaptive\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate  \n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial) + np.random.normal(0, 0.01)  # Robustness\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n            if self.current_evals > self.budget // 2:  # Adaptive population resizing strategy\n                self.population_size = max(5, self.population_size - 1)\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.05  # Slightly reduced scaling factor for precision\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.population_size = max(5, self.population_size // 2)\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced exploration by introducing adaptive population resizing and dynamic mutation strategies.", "configspace": "", "generation": 18, "fitness": 0.8242092975536175, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.824 with standard deviation 0.021. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "379f3012-50bb-4982-b8cc-323a4373616f", "metadata": {"aucs": [0.8030973786339115, 0.8522547866054708, 0.8172757274214703], "final_y": [0.1384973290337128, 0.12305371116562147, 0.13149577001852875]}, "mutation_prompt": null}
{"id": "71eab9d6-db3d-4c63-b3a1-f43845cf4cc4", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - (self.current_evals / self.budget) ** 0.5)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + np.random.normal(0.25, 0.1))  # More adaptive\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate  \n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial) + np.random.normal(0, 0.01)  # Robustness\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbation = scale_factor * step_size[d] * np.random.randn() * (0.5 + np.random.rand())\n                perturbed_solution[d] += perturbation\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.05  # Slightly reduced scaling factor for precision\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.population_size = max(5, self.population_size // 2)\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Fine-tune crossover rate adaptation and introduce dynamic perturbation in local search.", "configspace": "", "generation": 18, "fitness": 0.8329327311126296, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.833 with standard deviation 0.015. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "379f3012-50bb-4982-b8cc-323a4373616f", "metadata": {"aucs": [0.8125744774863948, 0.8390358255799993, 0.8471878902714944], "final_y": [0.13030840802970423, 0.12842835758249582, 0.12285500624721679]}, "mutation_prompt": null}
{"id": "d9c88b78-2222-42f3-ab92-e6ec76ce2e3e", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim  # Reduced initial population size\n        self.mutation_factor = 0.85  # Slightly increased for diversity\n        self.crossover_rate = 0.75  # Slightly increased for exploration\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        additional_layers = 0\n\n        while self.current_evals < self.budget:\n            if self.current_evals / self.budget > 0.5 and additional_layers < self.dim / 2:\n                additional_layers += 1\n                self.dim += 1\n                population = np.column_stack((population, np.random.rand(self.population_size)))\n\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - (self.current_evals / self.budget))\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial) + np.random.normal(0, 0.01)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 0.95  # Enhanced precision\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor *= 1.05\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.population_size = max(5, self.population_size // 2)\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced the evolutionary algorithm by integrating adaptive layer growth and diversity preservation mechanisms for robust exploration and exploitation balance.", "configspace": "", "generation": 19, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (11,) (10,) (10,) ').", "error": "ValueError('operands could not be broadcast together with shapes (11,) (10,) (10,) ')", "parent_id": "379f3012-50bb-4982-b8cc-323a4373616f", "metadata": {}, "mutation_prompt": null}
{"id": "3d3f6419-9305-4190-a901-8e2a3bd71766", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - (self.current_evals / self.budget) ** 0.5)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + np.random.rand() * 0.5)  # More adaptive\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate  \n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial) + np.random.normal(0, 0.01)  # Robustness\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0\n\n        for _ in range(7 + self.dim // 10):  # Increased iterations\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor *= 1.1  # Increased growth rate for improved precision\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.population_size = max(5, self.population_size // 2)\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced search precision by adjusting scaling factor dynamics and extending local search iterations.", "configspace": "", "generation": 19, "fitness": 0.82125386527079, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.821 with standard deviation 0.013. And the mean value of best solutions found was 0.132 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "379f3012-50bb-4982-b8cc-323a4373616f", "metadata": {"aucs": [0.8056965710524349, 0.8384186143229726, 0.8196464104369627], "final_y": [0.12672823984419357, 0.13094435600087506, 0.13809026861103024]}, "mutation_prompt": null}
{"id": "687218c6-a8c8-4bda-a3e2-ae2fe53f69f2", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - (self.current_evals / self.budget) ** 0.5) + 0.1  # Adjust mutation factor\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + np.random.rand() * 0.5)  # More adaptive\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate  \n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial) + np.random.normal(0, 0.01)  # Robustness\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.05  # Slightly reduced scaling factor for precision\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.population_size = max(5, self.population_size // 2)\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Adjusted the mutation factor in differential evolution to enhance solution diversity.", "configspace": "", "generation": 19, "fitness": 0.8319309642620479, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.832 with standard deviation 0.034. And the mean value of best solutions found was 0.132 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "379f3012-50bb-4982-b8cc-323a4373616f", "metadata": {"aucs": [0.7854702553678841, 0.8635412337477498, 0.84678140367051], "final_y": [0.14476458864975972, 0.12800097320873638, 0.12448482880725065]}, "mutation_prompt": null}
{"id": "a70be031-6cd3-4ae8-a2cb-f466403962e4", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n        num_islands = 5\n        island_size = self.population_size // num_islands  # Parallel islands\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                island_index = (i // island_size) * island_size\n                island_indices = list(range(island_index, island_index + island_size))\n                indices = [idx for idx in island_indices if idx != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - (self.current_evals / self.budget) ** 0.5)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + np.random.rand() * 0.5)\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate  \n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial) + np.random.normal(0, 0.01)\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.05\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.population_size = max(5, self.population_size // 2)\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced mutation strategy by introducing island-based parallelism to exploit diverse search regions.", "configspace": "", "generation": 19, "fitness": 0.812871652198153, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.813 with standard deviation 0.010. And the mean value of best solutions found was 0.142 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "379f3012-50bb-4982-b8cc-323a4373616f", "metadata": {"aucs": [0.8066096800906064, 0.8274855952766369, 0.8045196812272158], "final_y": [0.13973237258672777, 0.141071523719435, 0.14556436732749178]}, "mutation_prompt": null}
{"id": "b8d12fbc-a4ab-49c6-8e1e-3bf01e101f39", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.75  # Adjusted crossover rate for improved balance\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - (self.current_evals / self.budget) ** 0.5)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + np.random.rand() * 0.5)  # More adaptive\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate  \n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial) + np.random.normal(0, 0.01)  # Robustness\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.05  # Slightly reduced scaling factor for precision\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.population_size = max(5, self.population_size // 2)\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Adjusted the crossover rate for better exploration and exploitation balance in the search process.", "configspace": "", "generation": 19, "fitness": 0.8386884077988391, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.839 with standard deviation 0.013. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "379f3012-50bb-4982-b8cc-323a4373616f", "metadata": {"aucs": [0.836537212519694, 0.8560717095040586, 0.8234563013727649], "final_y": [0.12340612475571333, 0.12617518738664635, 0.12843372749624493]}, "mutation_prompt": null}
{"id": "e3d4a39d-6872-4c6a-a806-fa23bc0e4bcb", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            fitness_variance = np.var(fitness)  # Calculate fitness variance\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - (self.current_evals / self.budget) ** 0.5)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + np.random.rand() * 0.5 + fitness_variance * 0.1)  # Adjust crossover rate with fitness variance\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate  \n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial) + np.random.normal(0, 0.01)  # Robustness\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.05  # Slightly reduced scaling factor for precision\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.population_size = max(5, self.population_size // 2)\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Introduces a dynamic crossover rate adjustment based on fitness variance to improve exploration.", "configspace": "", "generation": 20, "fitness": 0.8251013214923121, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.825 with standard deviation 0.006. And the mean value of best solutions found was 0.134 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "379f3012-50bb-4982-b8cc-323a4373616f", "metadata": {"aucs": [0.8162685768136401, 0.8274589035539693, 0.831576484109327], "final_y": [0.13523564384458298, 0.13280474681339272, 0.13250539686484863]}, "mutation_prompt": null}
{"id": "7848712f-aa1e-4cfd-8459-0be313f27401", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - (self.current_evals / self.budget) ** 0.5)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + np.random.rand() * 0.5)  # More adaptive\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate  \n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial) + np.random.normal(0, 0.01)  # Robustness\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 0.95  # Adjusted scale factor for precision\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.05  # Slightly reduced scaling factor for precision\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.population_size = max(5, self.population_size // 2)\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced exploitation by adjusting convergence criteria for more precise local refinement.", "configspace": "", "generation": 20, "fitness": 0.8195187261022957, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.820 with standard deviation 0.029. And the mean value of best solutions found was 0.134 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "379f3012-50bb-4982-b8cc-323a4373616f", "metadata": {"aucs": [0.779226906381213, 0.8411230152508228, 0.8382062566748517], "final_y": [0.14369598886823953, 0.13426524004056273, 0.12269093420126798]}, "mutation_prompt": null}
{"id": "c9707ca2-fc2e-4ccf-a5e3-57262aa1b6a8", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - (self.current_evals / self.budget) ** 0.5)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + np.random.rand() * 0.5)  # More adaptive\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate  \n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial) + np.random.normal(0, 0.01)  # Robustness\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if i % 5 == 0:  # Introduce layer modularity adaptation\n                    population[i] = np.where(np.random.rand(self.dim) < 0.1, modular_structure, population[i])\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.05  # Slightly reduced scaling factor for precision\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.population_size = max(5, self.population_size // 2)\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced the mutation strategy to better explore high-dimensional spaces by introducing layer modularity adaptation.", "configspace": "", "generation": 20, "fitness": 0.8199025027337686, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.820 with standard deviation 0.016. And the mean value of best solutions found was 0.135 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "379f3012-50bb-4982-b8cc-323a4373616f", "metadata": {"aucs": [0.7968587250762096, 0.8310573803613356, 0.8317914027637604], "final_y": [0.1347894636001138, 0.1331113422328909, 0.1356971378228421]}, "mutation_prompt": null}
{"id": "a1795a3f-077d-430e-b133-4e40c16d122c", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * (1 - (self.current_evals / self.budget) ** 0.5)\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate * (1 + np.random.rand() * 0.5)  # More adaptive\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate  \n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial) + np.random.normal(0, 0.01)  # Robustness\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = scale_factor * 1.05 if f_perturbed < func(best_solution) else scale_factor * 0.95 # Dynamic adjustment\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.population_size = max(5, self.population_size // 2)\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced local search step by dynamically adjusting the scale factor for improved precision.", "configspace": "", "generation": 20, "fitness": 0.8299485571848373, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.830 with standard deviation 0.007. And the mean value of best solutions found was 0.130 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "379f3012-50bb-4982-b8cc-323a4373616f", "metadata": {"aucs": [0.8212842654800594, 0.8380248788033625, 0.8305365272710897], "final_y": [0.1347015370595125, 0.13421652481953983, 0.12248798484745094]}, "mutation_prompt": null}
{"id": "a1ae2ddc-dab5-4c45-b0d5-b125c5069dda", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n        self.current_evals = 0\n\n    def differential_evolution(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evals += self.population_size\n        modular_structure = np.random.choice([2, 3], size=self.dim)\n\n        while self.current_evals < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                adaptive_mutation_factor = self.mutation_factor * np.exp(-self.current_evals / self.budget)  # Enhanced adaptive mutation\n                mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n                adaptive_crossover_rate = self.crossover_rate + 0.2 * np.sin(2 * np.pi * self.current_evals / self.budget)  # Enhanced adaptive crossover\n                cross_points = np.random.rand(self.dim) < adaptive_crossover_rate  \n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                f_trial = func(trial) + np.random.normal(0, 0.01)  # Robustness\n                self.current_evals += 1\n\n                if f_trial < fitness[i]:\n                    fitness[i] = f_trial\n                    population[i] = trial\n                    modular_structure[i % self.dim] = np.random.choice([2, 3])\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return population[np.argmin(fitness)]\n\n    def local_search(self, best_solution, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        step_size = 0.1 * (ub - lb)\n        scale_factor = 1.0\n\n        for _ in range(5 + self.dim // 10):\n            for d in range(self.dim):\n                perturbed_solution = np.copy(best_solution)\n                perturbed_solution[d] += scale_factor * step_size[d] * np.random.randn()\n                perturbed_solution = np.clip(perturbed_solution, lb, ub)\n                f_perturbed = func(perturbed_solution)\n                self.current_evals += 1\n\n                if f_perturbed < func(best_solution):\n                    best_solution = perturbed_solution\n                    scale_factor = 1.05  # Slightly reduced scaling factor for precision\n\n                if self.current_evals >= self.budget:\n                    break\n\n        return best_solution\n    \n    def __call__(self, func):\n        self.population_size = max(5, self.population_size // 2)\n        best_solution = self.differential_evolution(func)\n        best_solution = self.local_search(best_solution, func)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced adaptive mechanisms in mutation and crossover for improved exploration and exploitation.", "configspace": "", "generation": 20, "fitness": 0.8288143047844772, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.829 with standard deviation 0.023. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "379f3012-50bb-4982-b8cc-323a4373616f", "metadata": {"aucs": [0.8153703839023317, 0.8608909899920845, 0.8101815404590155], "final_y": [0.12572415729614106, 0.12359499740502222, 0.13013724741220956]}, "mutation_prompt": null}
