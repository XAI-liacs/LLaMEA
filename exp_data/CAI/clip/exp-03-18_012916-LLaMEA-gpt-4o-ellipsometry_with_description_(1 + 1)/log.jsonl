{"id": "b1d34d43-af89-4591-ad8e-8265afd92fe9", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20  # Number of particles in the swarm\n        self.inertia_weight = 0.7\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social (global) weight\n        self.temperature = 1000  # Initial temperature for simulated annealing\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        # Initialize particle positions and velocities\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        # Initialize personal and global bests\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Update velocities and positions\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)  # Ensure within bounds\n                \n                # Evaluate new position\n                score = func(positions[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                # Simulated annealing perturbation\n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                # Update global best\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            # Decrease temperature\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "A hybrid Particle Swarm Optimization with Simulated Annealing (PSO-SA) that balances exploration and exploitation by adapting velocities and perturbing solutions for diverse search space traversal.", "configspace": "", "generation": 0, "fitness": 0.25955022219596435, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.260 with standard deviation 0.021. And the mean value of best solutions found was 0.083 (0. is the best) with standard deviation 0.039.", "error": "", "parent_id": null, "metadata": {"aucs": [0.2422341662871894, 0.28887611461215323, 0.2475403856885504], "final_y": [0.0669169073401792, 0.045176295952874, 0.1374124566619749]}, "mutation_prompt": null}
{"id": "cac43548-7592-4010-954a-aca88964e5b0", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20  # Number of particles in the swarm\n        self.inertia_weight = 0.7\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social (global) weight\n        self.temperature = 1000  # Initial temperature for simulated annealing\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        # Initialize particle positions and velocities\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        # Initialize personal and global bests\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Update velocities and positions\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], -0.5 * (ub - lb), 0.5 * (ub - lb))  # Adaptive Velocity Clamping\n                \n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)  # Ensure within bounds\n                \n                # Evaluate new position\n                score = func(positions[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                # Simulated annealing perturbation\n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                # Update global best\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            # Decrease temperature\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Introduce Adaptive Velocity Clamping in PSO-SA to enhance convergence by dynamically adjusting particle velocities based on search space boundaries.", "configspace": "", "generation": 1, "fitness": 0.25304231234527497, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.253 with standard deviation 0.025. And the mean value of best solutions found was 0.111 (0. is the best) with standard deviation 0.062.", "error": "", "parent_id": "b1d34d43-af89-4591-ad8e-8265afd92fe9", "metadata": {"aucs": [0.28716835066652113, 0.2445063928580703, 0.22745219351123347], "final_y": [0.030152510531530393, 0.12265036394673487, 0.17981942976765503]}, "mutation_prompt": null}
{"id": "293535d5-e384-43a4-9321-2bdfc4c54fab", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20  # Number of particles in the swarm\n        self.inertia_weight = 0.7\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social (global) weight\n        self.temperature = 1000  # Initial temperature for simulated annealing\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        # Initialize particle positions and velocities\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        # Initialize personal and global bests\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Update velocities and positions\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = ((0.9 - 0.5 * evaluations / self.budget) * velocities[i] +  # Adaptive inertia weight change\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)  # Ensure within bounds\n                \n                # Evaluate new position\n                score = func(positions[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                # Simulated annealing perturbation\n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                # Update global best\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            # Decrease temperature\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "A hybrid Particle Swarm Optimization with Simulated Annealing (PSO-SA) refined to include adaptive inertia weight for enhanced performance.", "configspace": "", "generation": 2, "fitness": 0.23218216446971818, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.232 with standard deviation 0.009. And the mean value of best solutions found was 0.094 (0. is the best) with standard deviation 0.033.", "error": "", "parent_id": "b1d34d43-af89-4591-ad8e-8265afd92fe9", "metadata": {"aucs": [0.24465675624341, 0.22799120315831178, 0.22389853400743276], "final_y": [0.05877461591042604, 0.08481743355991919, 0.13781011364191806]}, "mutation_prompt": null}
{"id": "5ed4afb0-dc42-4845-b0bf-6a5aa0a7fb22", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20  # Number of particles in the swarm\n        self.inertia_weight = 0.9  # Changed from 0.7 to 0.9 for adaptive inertia\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social (global) weight\n        self.temperature = 1000  # Initial temperature for simulated annealing\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        # Initialize particle positions and velocities\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        # Initialize personal and global bests\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Update velocities and positions\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)  # Ensure within bounds\n                \n                # Evaluate new position\n                score = func(positions[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                # Simulated annealing perturbation\n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                # Update global best\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            # Decrease temperature\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "PSO-SA with adaptive inertia weight to dynamically balance exploration and exploitation by adjusting search velocity over iterations.", "configspace": "", "generation": 3, "fitness": 0.19778368923497266, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.198 with standard deviation 0.025. And the mean value of best solutions found was 0.492 (0. is the best) with standard deviation 0.387.", "error": "", "parent_id": "b1d34d43-af89-4591-ad8e-8265afd92fe9", "metadata": {"aucs": [0.21611116866857705, 0.21499557154808369, 0.16224432748825723], "final_y": [0.16675717786644795, 0.2723921417918292, 1.0364415752286467]}, "mutation_prompt": null}
{"id": "6dc05ce8-0adf-465d-8de6-6874e5effab8", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20  # Number of particles in the swarm\n        self.inertia_weight = 0.7\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social (global) weight\n        self.temperature = 1000  # Initial temperature for simulated annealing\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        # Initialize particle positions and velocities\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        # Initialize personal and global bests\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Update velocities and positions\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.inertia_weight = 0.9 - 0.7 * (evaluations / self.budget)  # Adaptive inertia weight\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)  # Ensure within bounds\n                \n                # Evaluate new position\n                score = func(positions[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                # Simulated annealing perturbation\n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                # Update global best\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            # Decrease temperature\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Enhanced PSO-SA with adaptive inertia weight to improve convergence and exploration-exploitation balance.", "configspace": "", "generation": 4, "fitness": 0.235085363247441, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.235 with standard deviation 0.010. And the mean value of best solutions found was 0.051 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "b1d34d43-af89-4591-ad8e-8265afd92fe9", "metadata": {"aucs": [0.2473854756959779, 0.22281165926924373, 0.23505895477710137], "final_y": [0.04423072719692156, 0.06362543706300029, 0.04489631625048598]}, "mutation_prompt": null}
{"id": "a1dcdc3e-261f-4752-971c-2f38f3666ce1", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20  # Number of particles in the swarm\n        self.inertia_weight = 0.9  # Adjusted for adaptive inertia\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social (global) weight\n        self.temperature = 1000  # Initial temperature for simulated annealing\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        # Initialize particle positions and velocities\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        # Initialize personal and global bests\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        max_evaluations = self.budget\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Update velocities and positions\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.inertia_weight = 0.9 - 0.5 * (evaluations / max_evaluations)  # Adaptive inertia\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)  # Ensure within bounds\n                \n                # Evaluate new position\n                score = func(positions[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                # Simulated annealing perturbation\n                if np.random.rand() < (1 - evaluations / self.budget):  # Dynamic acceptance probability\n                    perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                    perturbed_position = np.clip(perturbed_position, lb, ub)\n                    perturbed_score = func(perturbed_position)\n                    evaluations += 1\n\n                    if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                        positions[i] = perturbed_position\n\n                # Update global best\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            # Decrease temperature\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Enhanced PSO-SA by adaptive inertia and selective annealing based on dynamic acceptance probability.", "configspace": "", "generation": 5, "fitness": 0.23682541950925276, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.237 with standard deviation 0.004. And the mean value of best solutions found was 0.012 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "b1d34d43-af89-4591-ad8e-8265afd92fe9", "metadata": {"aucs": [0.23188687846315192, 0.24227697637578915, 0.23631240368881723], "final_y": [0.01168025442750437, 0.00118613990288733, 0.023933806143450774]}, "mutation_prompt": null}
{"id": "83e14072-bef7-4227-8ec0-6ff2c71bcf02", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20  # Number of particles in the swarm\n        self.inertia_weight = 0.7\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social (global) weight\n        self.temperature = 1000  # Initial temperature for simulated annealing\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        # Initialize particle positions and velocities\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        # Initialize personal and global bests\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Update velocities and positions\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = ((0.4 + (self.budget - evaluations) / self.budget * 0.3) * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)  # Ensure within bounds\n                \n                # Evaluate new position\n                score = func(positions[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                # Simulated annealing perturbation\n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                # Update global best\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            # Decrease temperature\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Enhancing PSO-SA by introducing a dynamic inertia weight that decreases over time to improve convergence towards the global best.", "configspace": "", "generation": 6, "fitness": 0.26897253151914047, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.269 with standard deviation 0.023. And the mean value of best solutions found was 0.029 (0. is the best) with standard deviation 0.024.", "error": "", "parent_id": "b1d34d43-af89-4591-ad8e-8265afd92fe9", "metadata": {"aucs": [0.2889829953343176, 0.2807097342925363, 0.2372248649305675], "final_y": [0.01742744362272155, 0.007326226446883149, 0.06322569473477065]}, "mutation_prompt": null}
{"id": "f3d8f3af-5b93-4115-af33-8889292bd47d", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20  # Number of particles in the swarm\n        self.inertia_weight = 0.7\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social (global) weight\n        self.temperature = 1000  # Initial temperature for simulated annealing\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        # Initialize particle positions and velocities\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        # Initialize personal and global bests\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Update velocities and positions\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dynamic_factor = evaluations / self.budget\n                self.c1 = 1.5 + 0.5 * dynamic_factor\n                self.c2 = 1.5 - 0.5 * dynamic_factor\n                velocities[i] = ((0.4 + (self.budget - evaluations) / self.budget * 0.3) * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)  # Ensure within bounds\n                \n                # Evaluate new position\n                score = func(positions[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                # Simulated annealing perturbation\n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                # Update global best\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            # Decrease temperature\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Introduced a dynamic personal and social weight adjustment in PSO-SA to enhance exploration and exploitation balance.", "configspace": "", "generation": 7, "fitness": 0.20493182772449767, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.205 with standard deviation 0.015. And the mean value of best solutions found was 0.136 (0. is the best) with standard deviation 0.062.", "error": "", "parent_id": "83e14072-bef7-4227-8ec0-6ff2c71bcf02", "metadata": {"aucs": [0.1962816819760106, 0.193041897307772, 0.2254719038897104], "final_y": [0.1323435058231208, 0.21416066355506377, 0.06139065828861139]}, "mutation_prompt": null}
{"id": "5b9115c9-dccb-4867-8ce5-d4b7b4ce6c04", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20  # Number of particles in the swarm\n        self.inertia_weight = 0.7\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social (global) weight\n        self.temperature = 1000  # Initial temperature for simulated annealing\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        # Initialize particle positions and velocities\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        # Initialize personal and global bests\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Update velocities and positions\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.c2 = 1.5 + (0.5 * evaluations / self.budget)  # Dynamic adjustment of social weight\n                velocities[i] = ((0.4 + (self.budget - evaluations) / self.budget * 0.3) * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)  # Ensure within bounds\n                \n                # Evaluate new position\n                score = func(positions[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                # Simulated annealing perturbation\n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                # Update global best\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            # Decrease temperature\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Incorporating a dynamic social weight adjustment to balance exploration and exploitation in PSO-SA.", "configspace": "", "generation": 8, "fitness": 0.22613665284415974, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.226 with standard deviation 0.013. And the mean value of best solutions found was 0.101 (0. is the best) with standard deviation 0.044.", "error": "", "parent_id": "83e14072-bef7-4227-8ec0-6ff2c71bcf02", "metadata": {"aucs": [0.21604743692030137, 0.21855263075302878, 0.24380989085914906], "final_y": [0.07757717593559994, 0.16354175477279434, 0.06332031062124814]}, "mutation_prompt": null}
{"id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = ((0.4 + (self.budget - evaluations) / self.budget * 0.3) * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Augment PSO-SA by introducing adaptive parameters based on swarm diversity to strategically balance exploration and exploitation.", "configspace": "", "generation": 9, "fitness": 0.2762988342717243, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.276 with standard deviation 0.015. And the mean value of best solutions found was 0.032 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "83e14072-bef7-4227-8ec0-6ff2c71bcf02", "metadata": {"aucs": [0.2661968055258095, 0.2652192445433653, 0.2974804527459981], "final_y": [0.04528426326361952, 0.023999440341696328, 0.027554340745365703]}, "mutation_prompt": null}
{"id": "c9be0719-f2d6-42f9-ba4e-63a84f3b46b2", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.9  # Updated from 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = ((self.inertia_weight - (evaluations / self.budget * 0.5)) * velocities[i] +  # Modified\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbed_position = positions[i] + np.random.normal(0, 0.05 + (0.1 - 0.05) * (evaluations / self.budget), self.dim)  # Modified\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Enhance PSO-SA by incorporating adaptive inertia and mutation strategies to improve convergence and exploration balance.", "configspace": "", "generation": 10, "fitness": 0.22518898624122388, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.225 with standard deviation 0.012. And the mean value of best solutions found was 0.066 (0. is the best) with standard deviation 0.042.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.215394525044448, 0.2185624921530548, 0.24160994152616888], "final_y": [0.056146495702847646, 0.12142709912603544, 0.02074563868102169]}, "mutation_prompt": null}
{"id": "e55ab79a-b1a8-44b9-b71a-0c39a5f6db37", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = ((0.4 + (self.budget - evaluations) / self.budget * 0.3) * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))\n                positions[i] += velocities[i] * (0.5 + 0.5 * np.random.rand())\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbed_position = positions[i] + np.random.normal(0, 0.1 * (self.budget - evaluations) / self.budget, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Introduce dynamic velocity scaling and adaptive perturbation magnitude to enhance exploration-exploitation balance.", "configspace": "", "generation": 11, "fitness": 0.22252475588332196, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.223 with standard deviation 0.020. And the mean value of best solutions found was 0.019 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.21352663663609928, 0.20425455941257853, 0.24979307160128805], "final_y": [0.011597800505146095, 0.0333474962784026, 0.012288520433279552]}, "mutation_prompt": null}
{"id": "cdc22ead-61ca-447a-83f6-9f763584f378", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        no_improvement_counter = 0  # Added line for tracking no improvement\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = ((0.4 + (self.budget - evaluations) / self.budget * 0.3) * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n                    no_improvement_counter = 0  # Reset no improvement counter\n                else:\n                    no_improvement_counter += 1  # Increment if no improvement\n\n            if no_improvement_counter > 10:  # Random restart condition\n                positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n                no_improvement_counter = 0  # Reset counter after restart\n\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Introduce a random restart mechanism when the global best score does not improve, promoting diversity and escaping local optima.", "configspace": "", "generation": 12, "fitness": 0.16318812344381636, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.163 with standard deviation 0.005. And the mean value of best solutions found was 0.783 (0. is the best) with standard deviation 0.158.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.16990007010861463, 0.15969513861567597, 0.15996916160715846], "final_y": [0.561595200800577, 0.8654840348555679, 0.9221950110746998]}, "mutation_prompt": null}
{"id": "c1071516-becb-4a5c-a966-452eee5b889a", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                \n                # Modified line to dynamically adjust inertia_weight\n                self.inertia_weight = 0.5 + 0.5 * (1 - np.exp(-distance_to_best))\n                \n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Enhance PSO_SA by dynamically adjusting inertia weight based on swarm convergence to improve balance between exploration and exploitation.", "configspace": "", "generation": 13, "fitness": 0.20380099412067396, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.204 with standard deviation 0.032. And the mean value of best solutions found was 0.350 (0. is the best) with standard deviation 0.163.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.24341889043311804, 0.16619246465036253, 0.20179162727854127], "final_y": [0.1263313887780038, 0.5073466611671354, 0.4173733411973681]}, "mutation_prompt": null}
{"id": "5391ea81-c7e3-45e5-8cf5-7fc019840325", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.initial_temp = 1000\n        self.temperature = self.initial_temp\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            diversity_factor = np.mean(np.linalg.norm(positions - global_best_position, axis=1))\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = ((0.4 + (self.budget - evaluations) / self.budget * 0.3) * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.exp(-distance_to_best / (np.sum(np.linalg.norm(velocities, axis=1)) + diversity_factor))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature = self.initial_temp * (1 - evaluations / self.budget)\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Enhance PSO-SA by incorporating dynamic temperature scaling and diversity-based velocity adjustments to improve convergence.", "configspace": "", "generation": 14, "fitness": 0.23670192319083924, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.237 with standard deviation 0.053. And the mean value of best solutions found was 0.366 (0. is the best) with standard deviation 0.485.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.16117728614307536, 0.2776843854490051, 0.27124409798043725], "final_y": [1.0511738121466232, 0.028161122311996457, 0.01774182407200847]}, "mutation_prompt": null}
{"id": "dbf3d605-e13e-48f7-ae3a-668db4b33119", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = ((0.4 + (self.budget - evaluations) / self.budget * 0.3) * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                # Opposition-based learning for better exploration\n                opposite_positions = lb + ub - positions[i]\n                opposite_positions = np.clip(opposite_positions, lb, ub)\n                opposite_score = func(opposite_positions)\n                evaluations += 1\n                \n                if opposite_score < score or np.random.rand() < np.exp((score - opposite_score) / self.temperature):\n                    positions[i] = opposite_positions\n                \n                # Adaptive mutation based on diversity\n                diversity = np.mean(np.linalg.norm(personal_best_positions - global_best_position, axis=1))\n                mutation_strength = 0.1 * (1 - diversity / (ub - lb).mean())\n                perturbed_position = positions[i] + np.random.normal(0, mutation_strength, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Introduce opposition-based learning and adaptive mutation strategy to enhance diversity and convergence in the PSO-SA optimizer.", "configspace": "", "generation": 15, "fitness": 0.1423621912503633, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.142 with standard deviation 0.019. And the mean value of best solutions found was 1.843 (0. is the best) with standard deviation 0.797.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.11832054023927774, 0.16588195614473855, 0.14288407736707365], "final_y": [2.8739826223644225, 0.934172014963687, 1.7205768413128222]}, "mutation_prompt": null}
{"id": "a2118cc2-b26d-431c-82aa-65a9f1f7f901", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = ((0.4 + (self.budget - evaluations) / self.budget * 0.3) * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbed_position = positions[i] + np.random.normal(0, 0.3, self.dim)  # Increased perturbation\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Enhance global exploration by increasing perturbation effect using larger random normal distribution.", "configspace": "", "generation": 16, "fitness": 0.27206432545478576, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.272 with standard deviation 0.013. And the mean value of best solutions found was 0.042 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.2902697877881961, 0.2654469576660732, 0.260476230910088], "final_y": [0.036009966213663896, 0.04188960150398, 0.048103058357532244]}, "mutation_prompt": null}
{"id": "f23cc1d8-be31-4662-9887-5626174b3ce2", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = ((0.4 + (self.budget - evaluations) / self.budget * 0.3) * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))\n                positions[i] += velocities[i] * np.random.uniform(0.9, 1.1)  # Dynamic velocity scaling\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            if np.abs(global_best_score - np.mean(personal_best_scores)) < 1e-6:  # Early stopping condition\n                break\n            \n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Enhance particle diversity by introducing dynamic velocity scaling and an early stopping mechanism to improve convergence efficiency.", "configspace": "", "generation": 17, "fitness": 0.24343904642760805, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.243 with standard deviation 0.012. And the mean value of best solutions found was 0.040 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.259357664296028, 0.2413890424916726, 0.22957043249512354], "final_y": [0.05078411420545477, 0.029299133181242096, 0.04053021538510092]}, "mutation_prompt": null}
{"id": "33ecd51f-6c98-4327-95e9-88c30427ca16", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            velocity_clamp = (ub - lb) / 5  # Dynamic velocity clamping\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i])\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = ((0.4 + (self.budget - evaluations) / self.budget * 0.3) * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))\n                velocities[i] = np.clip(velocities[i], -velocity_clamp, velocity_clamp)  # Apply velocity clamping\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.98  # Adaptive cooling schedule\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Enhance the PSO-SA optimizer by integrating dynamic velocity clamping and adaptive cooling schedule to improve convergence speed and solution quality.", "configspace": "", "generation": 18, "fitness": 0.2596408177358962, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.260 with standard deviation 0.039. And the mean value of best solutions found was 0.064 (0. is the best) with standard deviation 0.044.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.312147365734212, 0.24707694492125065, 0.21969814255222597], "final_y": [0.007183897783208886, 0.07003458049987218, 0.11471331086514207]}, "mutation_prompt": null}
{"id": "55920ea4-7542-4cd0-bbed-5a9178085625", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        self.velocity_clamp = (0.1, 1.0)  # New line: introduce velocity clamping\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = ((0.4 + (self.budget - evaluations) / self.budget * 0.3) * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])  # New line: apply velocity clamping\n                velocities[i] *= np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.97  # Modified line: adjust temperature annealing rate\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Enhance PSO-SA by introducing velocity clamping and dynamic temperature annealing for improved convergence and stability.", "configspace": "", "generation": 19, "fitness": 0.18709889972980057, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.187 with standard deviation 0.006. And the mean value of best solutions found was 0.517 (0. is the best) with standard deviation 0.134.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.1954464767895282, 0.18566346091434383, 0.1801867614855297], "final_y": [0.37081728048048207, 0.4855872035562605, 0.6955374212768393]}, "mutation_prompt": null}
{"id": "2c949dd6-e71f-4a58-bd69-1b92053437de", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = ((0.5 + (self.budget - evaluations) / self.budget * 0.2) * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.exp(-distance_to_best / (np.sum(np.linalg.norm(velocities, axis=1)) + 1e-9))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Enhance swarm diversity and adaptive inertia for improved exploration-exploitation balance.", "configspace": "", "generation": 20, "fitness": 0.24165804446372494, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.242 with standard deviation 0.013. And the mean value of best solutions found was 0.071 (0. is the best) with standard deviation 0.018.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.24192602475406377, 0.2575764341776342, 0.2254716744594768], "final_y": [0.09568728359695115, 0.06431809322354431, 0.05361652806666209]}, "mutation_prompt": null}
{"id": "d25113c6-30c2-421a-8867-4ab015422162", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                # Adjusted line for dynamic inertia weight\n                self.inertia_weight = 0.9 - 0.5 * (evaluations / self.budget)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Introduce dynamic adjustment of inertia weight to enhance exploration-exploitation balance in PSO.", "configspace": "", "generation": 21, "fitness": 0.20965085812918424, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.210 with standard deviation 0.009. And the mean value of best solutions found was 0.141 (0. is the best) with standard deviation 0.039.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.21684879983119787, 0.21548296296728142, 0.1966208115890734], "final_y": [0.17342438038438757, 0.16408471664094781, 0.08566029907530666]}, "mutation_prompt": null}
{"id": "95659901-695e-4532-9a75-c592b99fe91f", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                # Adjust inertia weight based on current temperature\n                velocities[i] = ((0.4 + (self.budget - evaluations) / self.budget * 0.3) * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.99\n            self.inertia_weight = 0.4 + (self.temperature / 1000) * 0.3  # Modified line\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Enhance exploration by dynamically adjusting inertia weight based on temperature decay.", "configspace": "", "generation": 22, "fitness": 0.24256450990680853, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.243 with standard deviation 0.022. And the mean value of best solutions found was 0.043 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.2569151564330293, 0.2590154515236961, 0.21176292176370015], "final_y": [0.05586023391181802, 0.026535481899261176, 0.04551771864569205]}, "mutation_prompt": null}
{"id": "6e8f8e2d-7c6e-4985-9c2c-c18af685989f", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Calculate neighborhood velocity influence\n                neighborhood_best = np.mean(positions, axis=0)\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = ((0.4 + (self.budget - evaluations) / self.budget * 0.3) * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]) +\n                                 0.1 * (neighborhood_best - positions[i]))  # Added neighborhood influence\n                velocities[i] *= np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Enhance PSO-SA by incorporating a neighborhood-based velocity update to intensify local search around promising areas.", "configspace": "", "generation": 23, "fitness": 0.24323666007293124, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.243 with standard deviation 0.016. And the mean value of best solutions found was 0.054 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.25404653864014426, 0.2549886481351651, 0.2206747934434844], "final_y": [0.04333953788900877, 0.044920390287253566, 0.07277820162573533]}, "mutation_prompt": null}
{"id": "ad162eb3-4084-45a7-8920-81c1a425b020", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            diversity = np.std(positions)\n            self.inertia_weight = 0.5 + 0.2 * diversity  # Adjust inertia based on diversity\n\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i])\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +  # Adjusted line\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n\n                velocities[i] += np.random.uniform(-0.1, 0.1, self.dim)  # Introduce adaptive perturbation\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Introduce adaptive velocity components and diversity-based inertia weight adjustment to enhance convergence in PSO-SA.", "configspace": "", "generation": 24, "fitness": 0.1320475256440039, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.132 with standard deviation 0.013. And the mean value of best solutions found was 2.249 (0. is the best) with standard deviation 0.621.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.11585634888146046, 0.14651247403973966, 0.1337737540108116], "final_y": [3.0740236109650305, 1.5748875651143626, 2.0980247135013497]}, "mutation_prompt": null}
{"id": "7517d7f1-0b7d-4897-8bc2-4a6868d1bf13", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                # Adjusted inertia weight strategy\n                inertia_weight = 0.9 - (evaluations / self.budget * 0.5)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Augment PSO-SA by refining the inertia weight strategy to improve convergence speed by gradually decreasing it based on evaluations.", "configspace": "", "generation": 25, "fitness": 0.20515741638389992, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.205 with standard deviation 0.006. And the mean value of best solutions found was 0.099 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.19697362771509963, 0.20570518280183026, 0.21279343863476985], "final_y": [0.08037124317513682, 0.11309487092738948, 0.10442622140744048]}, "mutation_prompt": null}
{"id": "999b1eb5-f9a4-4b34-90a7-d99123eebbc2", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.inertia_weight = 0.7 if personal_best_scores[i] < global_best_score else 0.4\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Introduce adaptive inertia weight based on particle's success to enhance convergence and diversity balance.", "configspace": "", "generation": 26, "fitness": 0.22417827199384588, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.224 with standard deviation 0.042. And the mean value of best solutions found was 0.280 (0. is the best) with standard deviation 0.331.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.1646165754359854, 0.2568705177418362, 0.251047722803716], "final_y": [0.7473667946712566, 0.0414916964806075, 0.0497193763076478]}, "mutation_prompt": null}
{"id": "20749693-a824-4822-9823-3e1196361383", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Update inertia weight based on particle diversity\n                diversity = np.mean(np.linalg.norm(positions - global_best_position, axis=1))\n                inertia_weight = 0.7 * (1 - evaluations / self.budget) + 0.3 * (diversity / np.max(np.linalg.norm(positions, axis=1)))\n                \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.exp(-np.linalg.norm(global_best_position - positions[i]) / np.sum(np.linalg.norm(velocities, axis=1)))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Introduce adaptive inertia based on particle diversity to enhance convergence speed and solution accuracy.", "configspace": "", "generation": 27, "fitness": 0.2508774176921507, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.251 with standard deviation 0.018. And the mean value of best solutions found was 0.037 (0. is the best) with standard deviation 0.016.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.2386120673422134, 0.23796441718854844, 0.27605576854569036], "final_y": [0.05872121409544334, 0.03458818367131963, 0.018785989359562664]}, "mutation_prompt": null}
{"id": "6ab2cae6-21f6-4303-8c7d-05b4f27b7b97", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                adaptive_inertia = 0.4 + (self.budget - evaluations) / self.budget * 0.3\n                adaptive_c1 = self.c1 * (1.0 - evaluations / self.budget)\n                adaptive_c2 = self.c2 * (evaluations / self.budget)\n                velocities[i] = (adaptive_inertia * velocities[i] +\n                                 adaptive_c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 adaptive_c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbation_std = max(0.1, self.temperature / 1000)\n                perturbed_position = positions[i] + np.random.normal(0, perturbation_std, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Enhance PSO-SA by incorporating adaptive learning rates and a self-tuning perturbation mechanism to further refine exploration and exploitation balance.", "configspace": "", "generation": 28, "fitness": 0.19160320609086154, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.192 with standard deviation 0.017. And the mean value of best solutions found was 0.217 (0. is the best) with standard deviation 0.060.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.16899953213149377, 0.20877589410501396, 0.19703419203607686], "final_y": [0.2003891005592107, 0.15328402025698756, 0.29629056163133116]}, "mutation_prompt": null}
{"id": "7deb1680-78e0-42c7-b5be-9e170744662a", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.9  # Changed line (original value: 0.7)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Linearly decrease inertia weight\n                inertia = self.inertia_weight - (0.5 * evaluations / self.budget)  # Changed line\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = (inertia * velocities[i] +  # Changed line\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.95  # Changed line (original value: 0.99)\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Enhance PSO_SA by introducing a linearly decreasing inertia weight and improved exploitation via dynamic temperature adaptation.", "configspace": "", "generation": 29, "fitness": 0.25506206141539556, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.255 with standard deviation 0.032. And the mean value of best solutions found was 0.032 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.21732106806289508, 0.2530747100833002, 0.2947904060999914], "final_y": [0.036945596684113596, 0.03405953392268058, 0.025680168196543264]}, "mutation_prompt": null}
