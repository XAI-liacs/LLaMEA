{"id": "b1d34d43-af89-4591-ad8e-8265afd92fe9", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20  # Number of particles in the swarm\n        self.inertia_weight = 0.7\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social (global) weight\n        self.temperature = 1000  # Initial temperature for simulated annealing\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        # Initialize particle positions and velocities\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        # Initialize personal and global bests\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Update velocities and positions\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)  # Ensure within bounds\n                \n                # Evaluate new position\n                score = func(positions[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                # Simulated annealing perturbation\n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                # Update global best\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            # Decrease temperature\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "A hybrid Particle Swarm Optimization with Simulated Annealing (PSO-SA) that balances exploration and exploitation by adapting velocities and perturbing solutions for diverse search space traversal.", "configspace": "", "generation": 0, "fitness": 0.25955022219596435, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.260 with standard deviation 0.021. And the mean value of best solutions found was 0.083 (0. is the best) with standard deviation 0.039.", "error": "", "parent_id": null, "metadata": {"aucs": [0.2422341662871894, 0.28887611461215323, 0.2475403856885504], "final_y": [0.0669169073401792, 0.045176295952874, 0.1374124566619749]}, "mutation_prompt": null}
{"id": "cac43548-7592-4010-954a-aca88964e5b0", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20  # Number of particles in the swarm\n        self.inertia_weight = 0.7\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social (global) weight\n        self.temperature = 1000  # Initial temperature for simulated annealing\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        # Initialize particle positions and velocities\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        # Initialize personal and global bests\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Update velocities and positions\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], -0.5 * (ub - lb), 0.5 * (ub - lb))  # Adaptive Velocity Clamping\n                \n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)  # Ensure within bounds\n                \n                # Evaluate new position\n                score = func(positions[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                # Simulated annealing perturbation\n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                # Update global best\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            # Decrease temperature\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Introduce Adaptive Velocity Clamping in PSO-SA to enhance convergence by dynamically adjusting particle velocities based on search space boundaries.", "configspace": "", "generation": 1, "fitness": 0.25304231234527497, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.253 with standard deviation 0.025. And the mean value of best solutions found was 0.111 (0. is the best) with standard deviation 0.062.", "error": "", "parent_id": "b1d34d43-af89-4591-ad8e-8265afd92fe9", "metadata": {"aucs": [0.28716835066652113, 0.2445063928580703, 0.22745219351123347], "final_y": [0.030152510531530393, 0.12265036394673487, 0.17981942976765503]}, "mutation_prompt": null}
{"id": "293535d5-e384-43a4-9321-2bdfc4c54fab", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20  # Number of particles in the swarm\n        self.inertia_weight = 0.7\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social (global) weight\n        self.temperature = 1000  # Initial temperature for simulated annealing\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        # Initialize particle positions and velocities\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        # Initialize personal and global bests\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Update velocities and positions\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = ((0.9 - 0.5 * evaluations / self.budget) * velocities[i] +  # Adaptive inertia weight change\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)  # Ensure within bounds\n                \n                # Evaluate new position\n                score = func(positions[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                # Simulated annealing perturbation\n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                # Update global best\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            # Decrease temperature\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "A hybrid Particle Swarm Optimization with Simulated Annealing (PSO-SA) refined to include adaptive inertia weight for enhanced performance.", "configspace": "", "generation": 2, "fitness": 0.23218216446971818, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.232 with standard deviation 0.009. And the mean value of best solutions found was 0.094 (0. is the best) with standard deviation 0.033.", "error": "", "parent_id": "b1d34d43-af89-4591-ad8e-8265afd92fe9", "metadata": {"aucs": [0.24465675624341, 0.22799120315831178, 0.22389853400743276], "final_y": [0.05877461591042604, 0.08481743355991919, 0.13781011364191806]}, "mutation_prompt": null}
{"id": "5ed4afb0-dc42-4845-b0bf-6a5aa0a7fb22", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20  # Number of particles in the swarm\n        self.inertia_weight = 0.9  # Changed from 0.7 to 0.9 for adaptive inertia\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social (global) weight\n        self.temperature = 1000  # Initial temperature for simulated annealing\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        # Initialize particle positions and velocities\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        # Initialize personal and global bests\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Update velocities and positions\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)  # Ensure within bounds\n                \n                # Evaluate new position\n                score = func(positions[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                # Simulated annealing perturbation\n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                # Update global best\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            # Decrease temperature\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "PSO-SA with adaptive inertia weight to dynamically balance exploration and exploitation by adjusting search velocity over iterations.", "configspace": "", "generation": 3, "fitness": 0.19778368923497266, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.198 with standard deviation 0.025. And the mean value of best solutions found was 0.492 (0. is the best) with standard deviation 0.387.", "error": "", "parent_id": "b1d34d43-af89-4591-ad8e-8265afd92fe9", "metadata": {"aucs": [0.21611116866857705, 0.21499557154808369, 0.16224432748825723], "final_y": [0.16675717786644795, 0.2723921417918292, 1.0364415752286467]}, "mutation_prompt": null}
{"id": "6dc05ce8-0adf-465d-8de6-6874e5effab8", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20  # Number of particles in the swarm\n        self.inertia_weight = 0.7\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social (global) weight\n        self.temperature = 1000  # Initial temperature for simulated annealing\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        # Initialize particle positions and velocities\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        # Initialize personal and global bests\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Update velocities and positions\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.inertia_weight = 0.9 - 0.7 * (evaluations / self.budget)  # Adaptive inertia weight\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)  # Ensure within bounds\n                \n                # Evaluate new position\n                score = func(positions[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                # Simulated annealing perturbation\n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                # Update global best\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            # Decrease temperature\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Enhanced PSO-SA with adaptive inertia weight to improve convergence and exploration-exploitation balance.", "configspace": "", "generation": 4, "fitness": 0.235085363247441, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.235 with standard deviation 0.010. And the mean value of best solutions found was 0.051 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "b1d34d43-af89-4591-ad8e-8265afd92fe9", "metadata": {"aucs": [0.2473854756959779, 0.22281165926924373, 0.23505895477710137], "final_y": [0.04423072719692156, 0.06362543706300029, 0.04489631625048598]}, "mutation_prompt": null}
{"id": "a1dcdc3e-261f-4752-971c-2f38f3666ce1", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20  # Number of particles in the swarm\n        self.inertia_weight = 0.9  # Adjusted for adaptive inertia\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social (global) weight\n        self.temperature = 1000  # Initial temperature for simulated annealing\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        # Initialize particle positions and velocities\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        # Initialize personal and global bests\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        max_evaluations = self.budget\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Update velocities and positions\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.inertia_weight = 0.9 - 0.5 * (evaluations / max_evaluations)  # Adaptive inertia\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)  # Ensure within bounds\n                \n                # Evaluate new position\n                score = func(positions[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                # Simulated annealing perturbation\n                if np.random.rand() < (1 - evaluations / self.budget):  # Dynamic acceptance probability\n                    perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                    perturbed_position = np.clip(perturbed_position, lb, ub)\n                    perturbed_score = func(perturbed_position)\n                    evaluations += 1\n\n                    if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                        positions[i] = perturbed_position\n\n                # Update global best\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            # Decrease temperature\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Enhanced PSO-SA by adaptive inertia and selective annealing based on dynamic acceptance probability.", "configspace": "", "generation": 5, "fitness": 0.23682541950925276, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.237 with standard deviation 0.004. And the mean value of best solutions found was 0.012 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "b1d34d43-af89-4591-ad8e-8265afd92fe9", "metadata": {"aucs": [0.23188687846315192, 0.24227697637578915, 0.23631240368881723], "final_y": [0.01168025442750437, 0.00118613990288733, 0.023933806143450774]}, "mutation_prompt": null}
{"id": "83e14072-bef7-4227-8ec0-6ff2c71bcf02", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20  # Number of particles in the swarm\n        self.inertia_weight = 0.7\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social (global) weight\n        self.temperature = 1000  # Initial temperature for simulated annealing\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        # Initialize particle positions and velocities\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        # Initialize personal and global bests\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Update velocities and positions\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = ((0.4 + (self.budget - evaluations) / self.budget * 0.3) * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)  # Ensure within bounds\n                \n                # Evaluate new position\n                score = func(positions[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                # Simulated annealing perturbation\n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                # Update global best\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            # Decrease temperature\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Enhancing PSO-SA by introducing a dynamic inertia weight that decreases over time to improve convergence towards the global best.", "configspace": "", "generation": 6, "fitness": 0.26897253151914047, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.269 with standard deviation 0.023. And the mean value of best solutions found was 0.029 (0. is the best) with standard deviation 0.024.", "error": "", "parent_id": "b1d34d43-af89-4591-ad8e-8265afd92fe9", "metadata": {"aucs": [0.2889829953343176, 0.2807097342925363, 0.2372248649305675], "final_y": [0.01742744362272155, 0.007326226446883149, 0.06322569473477065]}, "mutation_prompt": null}
{"id": "f3d8f3af-5b93-4115-af33-8889292bd47d", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20  # Number of particles in the swarm\n        self.inertia_weight = 0.7\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social (global) weight\n        self.temperature = 1000  # Initial temperature for simulated annealing\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        # Initialize particle positions and velocities\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        # Initialize personal and global bests\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Update velocities and positions\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dynamic_factor = evaluations / self.budget\n                self.c1 = 1.5 + 0.5 * dynamic_factor\n                self.c2 = 1.5 - 0.5 * dynamic_factor\n                velocities[i] = ((0.4 + (self.budget - evaluations) / self.budget * 0.3) * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)  # Ensure within bounds\n                \n                # Evaluate new position\n                score = func(positions[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                # Simulated annealing perturbation\n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                # Update global best\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            # Decrease temperature\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Introduced a dynamic personal and social weight adjustment in PSO-SA to enhance exploration and exploitation balance.", "configspace": "", "generation": 7, "fitness": 0.20493182772449767, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.205 with standard deviation 0.015. And the mean value of best solutions found was 0.136 (0. is the best) with standard deviation 0.062.", "error": "", "parent_id": "83e14072-bef7-4227-8ec0-6ff2c71bcf02", "metadata": {"aucs": [0.1962816819760106, 0.193041897307772, 0.2254719038897104], "final_y": [0.1323435058231208, 0.21416066355506377, 0.06139065828861139]}, "mutation_prompt": null}
{"id": "5b9115c9-dccb-4867-8ce5-d4b7b4ce6c04", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20  # Number of particles in the swarm\n        self.inertia_weight = 0.7\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social (global) weight\n        self.temperature = 1000  # Initial temperature for simulated annealing\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        # Initialize particle positions and velocities\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        # Initialize personal and global bests\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Update velocities and positions\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.c2 = 1.5 + (0.5 * evaluations / self.budget)  # Dynamic adjustment of social weight\n                velocities[i] = ((0.4 + (self.budget - evaluations) / self.budget * 0.3) * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)  # Ensure within bounds\n                \n                # Evaluate new position\n                score = func(positions[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                # Simulated annealing perturbation\n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                # Update global best\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            # Decrease temperature\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Incorporating a dynamic social weight adjustment to balance exploration and exploitation in PSO-SA.", "configspace": "", "generation": 8, "fitness": 0.22613665284415974, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.226 with standard deviation 0.013. And the mean value of best solutions found was 0.101 (0. is the best) with standard deviation 0.044.", "error": "", "parent_id": "83e14072-bef7-4227-8ec0-6ff2c71bcf02", "metadata": {"aucs": [0.21604743692030137, 0.21855263075302878, 0.24380989085914906], "final_y": [0.07757717593559994, 0.16354175477279434, 0.06332031062124814]}, "mutation_prompt": null}
{"id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = ((0.4 + (self.budget - evaluations) / self.budget * 0.3) * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Augment PSO-SA by introducing adaptive parameters based on swarm diversity to strategically balance exploration and exploitation.", "configspace": "", "generation": 9, "fitness": 0.2762988342717243, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.276 with standard deviation 0.015. And the mean value of best solutions found was 0.032 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "83e14072-bef7-4227-8ec0-6ff2c71bcf02", "metadata": {"aucs": [0.2661968055258095, 0.2652192445433653, 0.2974804527459981], "final_y": [0.04528426326361952, 0.023999440341696328, 0.027554340745365703]}, "mutation_prompt": null}
{"id": "c9be0719-f2d6-42f9-ba4e-63a84f3b46b2", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.9  # Updated from 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = ((self.inertia_weight - (evaluations / self.budget * 0.5)) * velocities[i] +  # Modified\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbed_position = positions[i] + np.random.normal(0, 0.05 + (0.1 - 0.05) * (evaluations / self.budget), self.dim)  # Modified\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Enhance PSO-SA by incorporating adaptive inertia and mutation strategies to improve convergence and exploration balance.", "configspace": "", "generation": 10, "fitness": 0.22518898624122388, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.225 with standard deviation 0.012. And the mean value of best solutions found was 0.066 (0. is the best) with standard deviation 0.042.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.215394525044448, 0.2185624921530548, 0.24160994152616888], "final_y": [0.056146495702847646, 0.12142709912603544, 0.02074563868102169]}, "mutation_prompt": null}
{"id": "e55ab79a-b1a8-44b9-b71a-0c39a5f6db37", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = ((0.4 + (self.budget - evaluations) / self.budget * 0.3) * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))\n                positions[i] += velocities[i] * (0.5 + 0.5 * np.random.rand())\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbed_position = positions[i] + np.random.normal(0, 0.1 * (self.budget - evaluations) / self.budget, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Introduce dynamic velocity scaling and adaptive perturbation magnitude to enhance exploration-exploitation balance.", "configspace": "", "generation": 11, "fitness": 0.22252475588332196, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.223 with standard deviation 0.020. And the mean value of best solutions found was 0.019 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.21352663663609928, 0.20425455941257853, 0.24979307160128805], "final_y": [0.011597800505146095, 0.0333474962784026, 0.012288520433279552]}, "mutation_prompt": null}
{"id": "cdc22ead-61ca-447a-83f6-9f763584f378", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        no_improvement_counter = 0  # Added line for tracking no improvement\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = ((0.4 + (self.budget - evaluations) / self.budget * 0.3) * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n                    no_improvement_counter = 0  # Reset no improvement counter\n                else:\n                    no_improvement_counter += 1  # Increment if no improvement\n\n            if no_improvement_counter > 10:  # Random restart condition\n                positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n                no_improvement_counter = 0  # Reset counter after restart\n\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Introduce a random restart mechanism when the global best score does not improve, promoting diversity and escaping local optima.", "configspace": "", "generation": 12, "fitness": 0.16318812344381636, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.163 with standard deviation 0.005. And the mean value of best solutions found was 0.783 (0. is the best) with standard deviation 0.158.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.16990007010861463, 0.15969513861567597, 0.15996916160715846], "final_y": [0.561595200800577, 0.8654840348555679, 0.9221950110746998]}, "mutation_prompt": null}
{"id": "c1071516-becb-4a5c-a966-452eee5b889a", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                \n                # Modified line to dynamically adjust inertia_weight\n                self.inertia_weight = 0.5 + 0.5 * (1 - np.exp(-distance_to_best))\n                \n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Enhance PSO_SA by dynamically adjusting inertia weight based on swarm convergence to improve balance between exploration and exploitation.", "configspace": "", "generation": 13, "fitness": 0.20380099412067396, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.204 with standard deviation 0.032. And the mean value of best solutions found was 0.350 (0. is the best) with standard deviation 0.163.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.24341889043311804, 0.16619246465036253, 0.20179162727854127], "final_y": [0.1263313887780038, 0.5073466611671354, 0.4173733411973681]}, "mutation_prompt": null}
{"id": "5391ea81-c7e3-45e5-8cf5-7fc019840325", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.initial_temp = 1000\n        self.temperature = self.initial_temp\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            diversity_factor = np.mean(np.linalg.norm(positions - global_best_position, axis=1))\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = ((0.4 + (self.budget - evaluations) / self.budget * 0.3) * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.exp(-distance_to_best / (np.sum(np.linalg.norm(velocities, axis=1)) + diversity_factor))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature = self.initial_temp * (1 - evaluations / self.budget)\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Enhance PSO-SA by incorporating dynamic temperature scaling and diversity-based velocity adjustments to improve convergence.", "configspace": "", "generation": 14, "fitness": 0.23670192319083924, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.237 with standard deviation 0.053. And the mean value of best solutions found was 0.366 (0. is the best) with standard deviation 0.485.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.16117728614307536, 0.2776843854490051, 0.27124409798043725], "final_y": [1.0511738121466232, 0.028161122311996457, 0.01774182407200847]}, "mutation_prompt": null}
{"id": "dbf3d605-e13e-48f7-ae3a-668db4b33119", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = ((0.4 + (self.budget - evaluations) / self.budget * 0.3) * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                # Opposition-based learning for better exploration\n                opposite_positions = lb + ub - positions[i]\n                opposite_positions = np.clip(opposite_positions, lb, ub)\n                opposite_score = func(opposite_positions)\n                evaluations += 1\n                \n                if opposite_score < score or np.random.rand() < np.exp((score - opposite_score) / self.temperature):\n                    positions[i] = opposite_positions\n                \n                # Adaptive mutation based on diversity\n                diversity = np.mean(np.linalg.norm(personal_best_positions - global_best_position, axis=1))\n                mutation_strength = 0.1 * (1 - diversity / (ub - lb).mean())\n                perturbed_position = positions[i] + np.random.normal(0, mutation_strength, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Introduce opposition-based learning and adaptive mutation strategy to enhance diversity and convergence in the PSO-SA optimizer.", "configspace": "", "generation": 15, "fitness": 0.1423621912503633, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.142 with standard deviation 0.019. And the mean value of best solutions found was 1.843 (0. is the best) with standard deviation 0.797.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.11832054023927774, 0.16588195614473855, 0.14288407736707365], "final_y": [2.8739826223644225, 0.934172014963687, 1.7205768413128222]}, "mutation_prompt": null}
{"id": "a2118cc2-b26d-431c-82aa-65a9f1f7f901", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = ((0.4 + (self.budget - evaluations) / self.budget * 0.3) * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbed_position = positions[i] + np.random.normal(0, 0.3, self.dim)  # Increased perturbation\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Enhance global exploration by increasing perturbation effect using larger random normal distribution.", "configspace": "", "generation": 16, "fitness": 0.27206432545478576, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.272 with standard deviation 0.013. And the mean value of best solutions found was 0.042 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.2902697877881961, 0.2654469576660732, 0.260476230910088], "final_y": [0.036009966213663896, 0.04188960150398, 0.048103058357532244]}, "mutation_prompt": null}
