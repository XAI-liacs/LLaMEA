{"id": "b1d34d43-af89-4591-ad8e-8265afd92fe9", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20  # Number of particles in the swarm\n        self.inertia_weight = 0.7\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social (global) weight\n        self.temperature = 1000  # Initial temperature for simulated annealing\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        # Initialize particle positions and velocities\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        # Initialize personal and global bests\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Update velocities and positions\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)  # Ensure within bounds\n                \n                # Evaluate new position\n                score = func(positions[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                # Simulated annealing perturbation\n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                # Update global best\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            # Decrease temperature\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "A hybrid Particle Swarm Optimization with Simulated Annealing (PSO-SA) that balances exploration and exploitation by adapting velocities and perturbing solutions for diverse search space traversal.", "configspace": "", "generation": 0, "fitness": 0.25955022219596435, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.260 with standard deviation 0.021. And the mean value of best solutions found was 0.083 (0. is the best) with standard deviation 0.039.", "error": "", "parent_id": null, "metadata": {"aucs": [0.2422341662871894, 0.28887611461215323, 0.2475403856885504], "final_y": [0.0669169073401792, 0.045176295952874, 0.1374124566619749]}, "mutation_prompt": null}
{"id": "cac43548-7592-4010-954a-aca88964e5b0", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20  # Number of particles in the swarm\n        self.inertia_weight = 0.7\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social (global) weight\n        self.temperature = 1000  # Initial temperature for simulated annealing\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        # Initialize particle positions and velocities\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        # Initialize personal and global bests\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Update velocities and positions\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], -0.5 * (ub - lb), 0.5 * (ub - lb))  # Adaptive Velocity Clamping\n                \n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)  # Ensure within bounds\n                \n                # Evaluate new position\n                score = func(positions[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                # Simulated annealing perturbation\n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                # Update global best\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            # Decrease temperature\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Introduce Adaptive Velocity Clamping in PSO-SA to enhance convergence by dynamically adjusting particle velocities based on search space boundaries.", "configspace": "", "generation": 1, "fitness": 0.25304231234527497, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.253 with standard deviation 0.025. And the mean value of best solutions found was 0.111 (0. is the best) with standard deviation 0.062.", "error": "", "parent_id": "b1d34d43-af89-4591-ad8e-8265afd92fe9", "metadata": {"aucs": [0.28716835066652113, 0.2445063928580703, 0.22745219351123347], "final_y": [0.030152510531530393, 0.12265036394673487, 0.17981942976765503]}, "mutation_prompt": null}
{"id": "293535d5-e384-43a4-9321-2bdfc4c54fab", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20  # Number of particles in the swarm\n        self.inertia_weight = 0.7\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social (global) weight\n        self.temperature = 1000  # Initial temperature for simulated annealing\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        # Initialize particle positions and velocities\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        # Initialize personal and global bests\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Update velocities and positions\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = ((0.9 - 0.5 * evaluations / self.budget) * velocities[i] +  # Adaptive inertia weight change\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)  # Ensure within bounds\n                \n                # Evaluate new position\n                score = func(positions[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                # Simulated annealing perturbation\n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                # Update global best\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            # Decrease temperature\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "A hybrid Particle Swarm Optimization with Simulated Annealing (PSO-SA) refined to include adaptive inertia weight for enhanced performance.", "configspace": "", "generation": 2, "fitness": 0.23218216446971818, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.232 with standard deviation 0.009. And the mean value of best solutions found was 0.094 (0. is the best) with standard deviation 0.033.", "error": "", "parent_id": "b1d34d43-af89-4591-ad8e-8265afd92fe9", "metadata": {"aucs": [0.24465675624341, 0.22799120315831178, 0.22389853400743276], "final_y": [0.05877461591042604, 0.08481743355991919, 0.13781011364191806]}, "mutation_prompt": null}
{"id": "5ed4afb0-dc42-4845-b0bf-6a5aa0a7fb22", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20  # Number of particles in the swarm\n        self.inertia_weight = 0.9  # Changed from 0.7 to 0.9 for adaptive inertia\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social (global) weight\n        self.temperature = 1000  # Initial temperature for simulated annealing\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        # Initialize particle positions and velocities\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        # Initialize personal and global bests\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Update velocities and positions\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)  # Ensure within bounds\n                \n                # Evaluate new position\n                score = func(positions[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                # Simulated annealing perturbation\n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                # Update global best\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            # Decrease temperature\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "PSO-SA with adaptive inertia weight to dynamically balance exploration and exploitation by adjusting search velocity over iterations.", "configspace": "", "generation": 3, "fitness": 0.19778368923497266, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.198 with standard deviation 0.025. And the mean value of best solutions found was 0.492 (0. is the best) with standard deviation 0.387.", "error": "", "parent_id": "b1d34d43-af89-4591-ad8e-8265afd92fe9", "metadata": {"aucs": [0.21611116866857705, 0.21499557154808369, 0.16224432748825723], "final_y": [0.16675717786644795, 0.2723921417918292, 1.0364415752286467]}, "mutation_prompt": null}
{"id": "6dc05ce8-0adf-465d-8de6-6874e5effab8", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20  # Number of particles in the swarm\n        self.inertia_weight = 0.7\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social (global) weight\n        self.temperature = 1000  # Initial temperature for simulated annealing\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        # Initialize particle positions and velocities\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        # Initialize personal and global bests\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Update velocities and positions\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.inertia_weight = 0.9 - 0.7 * (evaluations / self.budget)  # Adaptive inertia weight\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)  # Ensure within bounds\n                \n                # Evaluate new position\n                score = func(positions[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                # Simulated annealing perturbation\n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                # Update global best\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            # Decrease temperature\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Enhanced PSO-SA with adaptive inertia weight to improve convergence and exploration-exploitation balance.", "configspace": "", "generation": 4, "fitness": 0.235085363247441, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.235 with standard deviation 0.010. And the mean value of best solutions found was 0.051 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "b1d34d43-af89-4591-ad8e-8265afd92fe9", "metadata": {"aucs": [0.2473854756959779, 0.22281165926924373, 0.23505895477710137], "final_y": [0.04423072719692156, 0.06362543706300029, 0.04489631625048598]}, "mutation_prompt": null}
{"id": "a1dcdc3e-261f-4752-971c-2f38f3666ce1", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20  # Number of particles in the swarm\n        self.inertia_weight = 0.9  # Adjusted for adaptive inertia\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social (global) weight\n        self.temperature = 1000  # Initial temperature for simulated annealing\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        # Initialize particle positions and velocities\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        # Initialize personal and global bests\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        max_evaluations = self.budget\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Update velocities and positions\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.inertia_weight = 0.9 - 0.5 * (evaluations / max_evaluations)  # Adaptive inertia\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)  # Ensure within bounds\n                \n                # Evaluate new position\n                score = func(positions[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                # Simulated annealing perturbation\n                if np.random.rand() < (1 - evaluations / self.budget):  # Dynamic acceptance probability\n                    perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                    perturbed_position = np.clip(perturbed_position, lb, ub)\n                    perturbed_score = func(perturbed_position)\n                    evaluations += 1\n\n                    if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                        positions[i] = perturbed_position\n\n                # Update global best\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            # Decrease temperature\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Enhanced PSO-SA by adaptive inertia and selective annealing based on dynamic acceptance probability.", "configspace": "", "generation": 5, "fitness": 0.23682541950925276, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.237 with standard deviation 0.004. And the mean value of best solutions found was 0.012 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "b1d34d43-af89-4591-ad8e-8265afd92fe9", "metadata": {"aucs": [0.23188687846315192, 0.24227697637578915, 0.23631240368881723], "final_y": [0.01168025442750437, 0.00118613990288733, 0.023933806143450774]}, "mutation_prompt": null}
{"id": "83e14072-bef7-4227-8ec0-6ff2c71bcf02", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20  # Number of particles in the swarm\n        self.inertia_weight = 0.7\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social (global) weight\n        self.temperature = 1000  # Initial temperature for simulated annealing\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        # Initialize particle positions and velocities\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        # Initialize personal and global bests\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Update velocities and positions\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = ((0.4 + (self.budget - evaluations) / self.budget * 0.3) * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)  # Ensure within bounds\n                \n                # Evaluate new position\n                score = func(positions[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                # Simulated annealing perturbation\n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                # Update global best\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            # Decrease temperature\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Enhancing PSO-SA by introducing a dynamic inertia weight that decreases over time to improve convergence towards the global best.", "configspace": "", "generation": 6, "fitness": 0.26897253151914047, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.269 with standard deviation 0.023. And the mean value of best solutions found was 0.029 (0. is the best) with standard deviation 0.024.", "error": "", "parent_id": "b1d34d43-af89-4591-ad8e-8265afd92fe9", "metadata": {"aucs": [0.2889829953343176, 0.2807097342925363, 0.2372248649305675], "final_y": [0.01742744362272155, 0.007326226446883149, 0.06322569473477065]}, "mutation_prompt": null}
{"id": "f3d8f3af-5b93-4115-af33-8889292bd47d", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20  # Number of particles in the swarm\n        self.inertia_weight = 0.7\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social (global) weight\n        self.temperature = 1000  # Initial temperature for simulated annealing\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        # Initialize particle positions and velocities\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        # Initialize personal and global bests\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Update velocities and positions\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dynamic_factor = evaluations / self.budget\n                self.c1 = 1.5 + 0.5 * dynamic_factor\n                self.c2 = 1.5 - 0.5 * dynamic_factor\n                velocities[i] = ((0.4 + (self.budget - evaluations) / self.budget * 0.3) * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)  # Ensure within bounds\n                \n                # Evaluate new position\n                score = func(positions[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                # Simulated annealing perturbation\n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                # Update global best\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            # Decrease temperature\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Introduced a dynamic personal and social weight adjustment in PSO-SA to enhance exploration and exploitation balance.", "configspace": "", "generation": 7, "fitness": 0.20493182772449767, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.205 with standard deviation 0.015. And the mean value of best solutions found was 0.136 (0. is the best) with standard deviation 0.062.", "error": "", "parent_id": "83e14072-bef7-4227-8ec0-6ff2c71bcf02", "metadata": {"aucs": [0.1962816819760106, 0.193041897307772, 0.2254719038897104], "final_y": [0.1323435058231208, 0.21416066355506377, 0.06139065828861139]}, "mutation_prompt": null}
{"id": "5b9115c9-dccb-4867-8ce5-d4b7b4ce6c04", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20  # Number of particles in the swarm\n        self.inertia_weight = 0.7\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social (global) weight\n        self.temperature = 1000  # Initial temperature for simulated annealing\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        # Initialize particle positions and velocities\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        # Initialize personal and global bests\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Update velocities and positions\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.c2 = 1.5 + (0.5 * evaluations / self.budget)  # Dynamic adjustment of social weight\n                velocities[i] = ((0.4 + (self.budget - evaluations) / self.budget * 0.3) * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)  # Ensure within bounds\n                \n                # Evaluate new position\n                score = func(positions[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                # Simulated annealing perturbation\n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                # Update global best\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            # Decrease temperature\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Incorporating a dynamic social weight adjustment to balance exploration and exploitation in PSO-SA.", "configspace": "", "generation": 8, "fitness": 0.22613665284415974, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.226 with standard deviation 0.013. And the mean value of best solutions found was 0.101 (0. is the best) with standard deviation 0.044.", "error": "", "parent_id": "83e14072-bef7-4227-8ec0-6ff2c71bcf02", "metadata": {"aucs": [0.21604743692030137, 0.21855263075302878, 0.24380989085914906], "final_y": [0.07757717593559994, 0.16354175477279434, 0.06332031062124814]}, "mutation_prompt": null}
{"id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = ((0.4 + (self.budget - evaluations) / self.budget * 0.3) * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Augment PSO-SA by introducing adaptive parameters based on swarm diversity to strategically balance exploration and exploitation.", "configspace": "", "generation": 9, "fitness": 0.2762988342717243, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.276 with standard deviation 0.015. And the mean value of best solutions found was 0.032 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "83e14072-bef7-4227-8ec0-6ff2c71bcf02", "metadata": {"aucs": [0.2661968055258095, 0.2652192445433653, 0.2974804527459981], "final_y": [0.04528426326361952, 0.023999440341696328, 0.027554340745365703]}, "mutation_prompt": null}
