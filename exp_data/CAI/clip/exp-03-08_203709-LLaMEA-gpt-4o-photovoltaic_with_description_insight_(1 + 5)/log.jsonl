{"id": "a9e91274-0ed5-4159-bf1f-fe08f9157e57", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates):\n        a, b, c = candidates[np.random.choice(len(candidates), 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_refinement(self, candidate, func, bounds):\n        perturbation_strength = 0.05\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if func(trial) > func(candidate):\n                candidate = trial\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates)\n                trial = self.crossover(self.population[i], mutant)\n                trial = self.local_refinement(trial, func, bounds)\n                \n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "A hybrid metaheuristic combining Differential Evolution (DE) for global exploration and a local greedy search for refinement, which gradually increases problem dimensionality to efficiently allocate computational resources and maintain robustness to perturbations.", "configspace": "", "generation": 0, "fitness": -Infinity, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 192, in initialize_single\n    new_individual = self.evaluate_fitness(new_individual)\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 281, in evaluate_fitness\n    updated_individual = self.f(individual, self.logger)\n  File \"/home/ian/LLaMEA/benchmarks/tuto_global_optimization_photonics/exp_photonic.py\", line 143, in evaluatePhotonic\n    algorithm(problem)\n  File \"<string>\", line 46, in __call__\n  File \"<string>\", line 17, in mutate\nTypeError: only integer scalar arrays can be converted to a scalar index\n.", "error": "TypeError('only integer scalar arrays can be converted to a scalar index')Traceback (most recent call last):\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 192, in initialize_single\n    new_individual = self.evaluate_fitness(new_individual)\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 281, in evaluate_fitness\n    updated_individual = self.f(individual, self.logger)\n  File \"/home/ian/LLaMEA/benchmarks/tuto_global_optimization_photonics/exp_photonic.py\", line 143, in evaluatePhotonic\n    algorithm(problem)\n  File \"<string>\", line 46, in __call__\n  File \"<string>\", line 17, in mutate\nTypeError: only integer scalar arrays can be converted to a scalar index\n", "parent_id": null, "metadata": {}, "mutation_prompt": null}
{"id": "25a3c569-3874-4cd7-8b06-01fec151734e", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates):  # Changed line\n        unique_candidates = np.random.choice(candidates, 3, replace=False)\n        a, b, c = self.population[unique_candidates]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_refinement(self, candidate, func, bounds):\n        perturbation_strength = 0.05\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if func(trial) > func(candidate):\n                candidate = trial\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates)\n                trial = self.crossover(self.population[i], mutant)\n                trial = self.local_refinement(trial, func, bounds)\n                \n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "A modified hybrid metaheuristic that refines the mutation process by selecting unique candidates and utilizes an adaptive crossover probability to improve robustness.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'bounds' is not defined\").", "error": "NameError(\"name 'bounds' is not defined\")", "parent_id": "a9e91274-0ed5-4159-bf1f-fe08f9157e57", "metadata": {}, "mutation_prompt": null}
{"id": "36b3ee97-52af-4e3d-895f-ca5c9cb29fe5", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates):\n        a, b, c = candidates[np.random.choice(len(candidates), 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        # Enhanced: Use a weighted average of target and mutant for crossover\n        trial = (trial + target) / 2\n        return trial\n\n    def local_refinement(self, candidate, func, bounds):\n        perturbation_strength = 0.05\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if func(trial) > func(candidate):\n                candidate = trial\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates)\n                trial = self.crossover(self.population[i], mutant)\n                trial = self.local_refinement(trial, func, bounds)\n                \n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced crossover method to improve candidate solutions in hybrid metaheuristic algorithm for optimizing multilayered photonic structures", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "An exception occurred: TypeError('only integer scalar arrays can be converted to a scalar index').", "error": "TypeError('only integer scalar arrays can be converted to a scalar index')", "parent_id": "a9e91274-0ed5-4159-bf1f-fe08f9157e57", "metadata": {}, "mutation_prompt": null}
{"id": "ef2d5a4d-346c-4050-9ae6-a442f60fb682", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if func(trial) > func(candidate):\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n                \n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "A novel hybrid metaheuristic combining Differential Evolution (DE) with adaptive local search that dynamically balances exploration and exploitation by adjusting mutation and crossover rates based on convergence trends, with progressive dimensionality increase and robustness checks. ", "configspace": "", "generation": 1, "fitness": 0.7689548190749266, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.769 with standard deviation 0.019. And the mean value of best solutions found was 0.168 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "a9e91274-0ed5-4159-bf1f-fe08f9157e57", "metadata": {"aucs": [0.7512004582207262, 0.7945901820562783, 0.7610738169477751], "final_y": [0.16979333661861096, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "9623a4b1-8c6f-472f-811c-b8e6c0053b08", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = np.random.choice(candidates, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_refinement(self, candidate, func, bounds):\n        perturbation_strength = 0.05\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if func(trial) > func(candidate):\n                candidate = trial\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)  # Pass bounds to mutate\n                trial = self.crossover(self.population[i], mutant)\n                trial = self.local_refinement(trial, func, bounds)\n                \n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "An optimized hybrid metaheuristic with a refined mutation strategy to improve solution diversity and robustness in high-dimensional noisy optimization problems.", "configspace": "", "generation": 1, "fitness": 0.7666347468393259, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.767 with standard deviation 0.021. And the mean value of best solutions found was 0.169 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "a9e91274-0ed5-4159-bf1f-fe08f9157e57", "metadata": {"aucs": [0.744240241513924, 0.7945901820562783, 0.7610738169477751], "final_y": [0.17456825053300673, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "5f52d6dc-2994-4298-a030-df90655dde52", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = np.random.choice(candidates, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])  # Fix mutation selection\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_refinement(self, candidate, func, bounds):\n        perturbation_strength = 0.05\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if func(trial) > func(candidate):\n                candidate = trial\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)  # Added bounds parameter\n                trial = self.crossover(self.population[i], mutant)\n                trial = self.local_refinement(trial, func, bounds)\n                \n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "A robust hybrid metaheuristic using Differential Evolution with improved mutation selection and convergence handling, integrating local search for refinement.", "configspace": "", "generation": 1, "fitness": 0.7686321541141382, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.769 with standard deviation 0.019. And the mean value of best solutions found was 0.169 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "a9e91274-0ed5-4159-bf1f-fe08f9157e57", "metadata": {"aucs": [0.750232463338361, 0.7945901820562783, 0.7610738169477751], "final_y": [0.1752357927112017, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "c21741ab-cb05-4c74-8c4b-b62c1b11d855", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.population = None\n        self.adapt_factor = 0.1  # New adaptive factor\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        self.F = self.adapt_factor + np.random.rand() * (1 - self.adapt_factor)  # Dynamic mutation\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if func(trial) > func(candidate):\n                candidate = trial\n                break\n        # Layer-wise refinement\n        for i in range(self.dim):\n            perturbation = np.zeros(self.dim)\n            perturbation[i] = perturbation_strength\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if func(trial) > func(candidate):\n                candidate = trial\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n                \n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced evolutionary strategy integrating Differential Evolution with dynamic mutation rates and adaptive layer-wise refinement, promoting solution robustness and convergence speed.", "configspace": "", "generation": 2, "fitness": 0.7668004694466646, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.767 with standard deviation 0.021. And the mean value of best solutions found was 0.170 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "ef2d5a4d-346c-4050-9ae6-a442f60fb682", "metadata": {"aucs": [0.7423820363094582, 0.7945901820562783, 0.763429189974257], "final_y": [0.17924064183162647, 0.1601017669387199, 0.16994503471183153]}, "mutation_prompt": null}
{"id": "6fb8f2d1-7bc2-46d3-89e1-5b2c6b5723a5", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        diversity = np.mean(np.std(self.population, axis=0))  # Change\n        perturbation_strength = max(0.05 * convergence_speed, 0.01) * diversity\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if func(trial) > func(candidate):\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n                \n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "A refined hybrid metaheuristic that dynamically adjusts perturbation strength in local refinement based on population diversity to enhance exploitation capabilities.", "configspace": "", "generation": 2, "fitness": 0.7929113485273924, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.793 with standard deviation 0.011. And the mean value of best solutions found was 0.159 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "ef2d5a4d-346c-4050-9ae6-a442f60fb682", "metadata": {"aucs": [0.7964709344104117, 0.8037974311586034, 0.7784656800131622], "final_y": [0.1542376976201687, 0.1560641082426233, 0.16534550159554562]}, "mutation_prompt": null}
{"id": "ef06491e-085b-44d3-af35-869de5187333", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Refined hybrid metaheuristic using statistical noise reduction and adaptive crossover, enhancing exploratory search in black box optimization.", "configspace": "", "generation": 2, "fitness": 0.7932884431602875, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.793 with standard deviation 0.010. And the mean value of best solutions found was 0.156 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "ef2d5a4d-346c-4050-9ae6-a442f60fb682", "metadata": {"aucs": [0.8047914220416277, 0.7945901820562783, 0.7804837253829562], "final_y": [0.15209378859051326, 0.1601017669387199, 0.1565672338409151]}, "mutation_prompt": null}
{"id": "3d5e96ac-28e0-4404-b1ac-9b97f7166038", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n        self.reinit_frequency = 0.1  # New feature: reinitialization frequency\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if func(trial) > func(candidate):\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            if num_evaluations % int(self.budget * self.reinit_frequency) == 0:  # Reinitialize some individuals\n                num_reinit = self.pop_size // 10  # Reinitialize 10% of the population\n                reinit_indices = np.random.choice(self.pop_size, num_reinit, replace=False)\n                for idx in reinit_indices:\n                    self.population[idx] = self.initialize_population(bounds)[0]\n                    fitness[idx] = func(self.population[idx])\n                    num_evaluations += 1\n\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n                \n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhancing exploration by increasing Differential Evolution's population diversity and adaptability through random re-initializations.", "configspace": "", "generation": 2, "fitness": 0.7700321836748444, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.770 with standard deviation 0.018. And the mean value of best solutions found was 0.164 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "ef2d5a4d-346c-4050-9ae6-a442f60fb682", "metadata": {"aucs": [0.750725879555134, 0.7945901820562783, 0.7647804894131207], "final_y": [0.1625046757947568, 0.1601017669387199, 0.16872176105188785]}, "mutation_prompt": null}
{"id": "5d205b08-4966-4b9a-be0f-a715a6c46f29", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        adaptive_F = self.F * np.random.uniform(0.8, 1.2)  # Adaptive mutation\n        mutant = a + adaptive_F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.normal(0, perturbation_strength, self.dim)  # Normal perturbation\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if func(trial) > func(candidate):\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n                \n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "An enhanced hybrid metaheuristic with adaptive mutation and layered optimization, leveraging perturbation-based robustness and progressive layer increase for improved convergence.", "configspace": "", "generation": 2, "fitness": 0.7784362665905284, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.778 with standard deviation 0.020. And the mean value of best solutions found was 0.163 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "ef2d5a4d-346c-4050-9ae6-a442f60fb682", "metadata": {"aucs": [0.7500746686546612, 0.7945901820562783, 0.7906439490606456], "final_y": [0.17256950137456617, 0.1601017669387199, 0.1554038781899012]}, "mutation_prompt": null}
{"id": "aed6b912-96c9-4388-86ef-5f67d64cd7a2", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(7):  # small local search steps, increased from 5 to 7\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced local search by increasing iteration steps for better refinement.", "configspace": "", "generation": 3, "fitness": 0.7766959834981125, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.777 with standard deviation 0.020. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7494287067033523, 0.7945901820562783, 0.786069061734707], "final_y": [0.1753006403861338, 0.1601017669387199, 0.16145711389005235]}, "mutation_prompt": null}
{"id": "aa00df4c-2326-4ad0-9f0f-23fb68b6a302", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        fitness_variance = np.var([func(ind) for ind in self.population])  # Calculate variance of fitness\n        perturbation_strength = max(0.05 * convergence_speed * (1 + fitness_variance), 0.01)  # Dynamic scaling\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced adaptive local refinement by incorporating dynamic perturbation scaling based on fitness variance.", "configspace": "", "generation": 3, "fitness": 0.7687188620576272, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.769 with standard deviation 0.021. And the mean value of best solutions found was 0.164 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7423820363094582, 0.7945901820562783, 0.769184367807145], "final_y": [0.17924064183162647, 0.1601017669387199, 0.15379635044308093]}, "mutation_prompt": null}
{"id": "5e655a3b-3ca2-47b8-8bb7-f27c421ee65e", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.normal(0, perturbation_strength, self.dim)  # Changed to normal distribution\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.median([func(trial) for _ in range(5)]) > func(candidate):  # Increased noise sample size\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / max(prev_best_fitness, 1e-6)  # Avoid division by zero\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic with adaptive noise handling and dynamic local search for improved convergence.", "configspace": "", "generation": 3, "fitness": 0.769207951866195, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.769 with standard deviation 0.021. And the mean value of best solutions found was 0.169 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7423820363094582, 0.7945901820562783, 0.7706516372328482], "final_y": [0.17924064183162647, 0.1601017669387199, 0.1662876910968617]}, "mutation_prompt": null}
{"id": "f8c0cab1-2253-4eda-a905-4c8da1b72876", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(7):  # increased local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Improve adaptive local refinement by increasing the number of local search steps for better noise tolerance.", "configspace": "", "generation": 3, "fitness": 0.7727294588324818, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.773 with standard deviation 0.031. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.015.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7423820363094582, 0.8147325232402121, 0.7610738169477751], "final_y": [0.17924064183162647, 0.14520821530639672, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "fd709ad3-1859-4cf0-9791-b9205723e55b", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            self.pop_size = min(max(5 * self.dim, int(self.pop_size * (1 + 0.1 * np.sign(convergence_speed)))), self.budget // 10)\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced exploration strategy through dynamic population size adjustment based on convergence speed.", "configspace": "", "generation": 3, "fitness": 0.7722296327762047, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.772 with standard deviation 0.019. And the mean value of best solutions found was 0.162 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7534695329170054, 0.7983533894217112, 0.7648659759898978], "final_y": [0.1716248503069575, 0.1560256603903608, 0.1585017310236152]}, "mutation_prompt": null}
{"id": "08204894-b766-42f5-bb2b-53740db18bfb", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(7):  # Modified from 5 to 7 small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhance local refinement by increasing perturbation attempts for better exploration.", "configspace": "", "generation": 4, "fitness": 0.7660153451045039, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.766 with standard deviation 0.022. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7423820363094582, 0.7945901820562783, 0.7610738169477751], "final_y": [0.17924064183162647, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "0ebad2bd-56a5-4881-b7eb-c2cfaaa55126", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(7):  # small local search steps, increased iterations for noise reduction\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced the adaptive local refinement by increasing noise reduction iterations for better optimization in noisy environments.", "configspace": "", "generation": 4, "fitness": 0.7694372608224596, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.769 with standard deviation 0.018. And the mean value of best solutions found was 0.169 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.752647783463325, 0.7945901820562783, 0.7610738169477751], "final_y": [0.17249293681791844, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "1c2df54f-166c-4290-b446-d202d3a60f26", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5 * dim, 20)  # Adjusted population size for better exploration\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        scale_factor = np.random.uniform(0.4, 0.8)  # Dynamic scaling factor for mutation\n        mutant = a + scale_factor * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic with dynamic population size adjustment and improved mutation mechanism for better exploration and convergence in noisy environments.", "configspace": "", "generation": 4, "fitness": 0.7628248591102441, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.763 with standard deviation 0.025. And the mean value of best solutions found was 0.170 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7328105783266791, 0.7945901820562783, 0.7610738169477751], "final_y": [0.17780119682218087, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "633538d2-7e6b-4ac1-aa80-8afb0a74c118", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        diversity_factor = np.std(self.population) / self.dim  # Diversity calculation\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength * (1 + diversity_factor), perturbation_strength * (1 + diversity_factor), self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic by incorporating a diversity maintenance mechanism and improved local search adaptability for robust exploration.", "configspace": "", "generation": 4, "fitness": 0.7746875546351366, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.775 with standard deviation 0.019. And the mean value of best solutions found was 0.161 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7489913920920925, 0.7945901820562783, 0.7804810897570391], "final_y": [0.17016191292497995, 0.1601017669387199, 0.15325766775649385]}, "mutation_prompt": null}
{"id": "f98abca3-6cb1-4cd0-a33c-5dd629ab64e6", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5 * dim, 100)  # Dynamic Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Improved hybrid metaheuristic with dynamic population size adjustment for enhanced exploration and convergence.", "configspace": "", "generation": 4, "fitness": 0.7660153451045039, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.766 with standard deviation 0.022. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7423820363094582, 0.7945901820562783, 0.7610738169477751], "final_y": [0.17924064183162647, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "bc53e934-475e-441e-a83c-cb937fc26b71", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            self.pop_size = max(4, int(self.pop_size * (1 + convergence_speed)))\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic with dynamic population sizing based on convergence rates to improve adaptability.", "configspace": "", "generation": 5, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'convergence_speed' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'convergence_speed' referenced before assignment\")", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {}, "mutation_prompt": null}
{"id": "7c54b767-631e-4f6e-b952-72cd42122096", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed, eval_budget):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(min(5, eval_budget // 10)):  # Adjust local search steps dynamically\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed, self.budget - num_evaluations)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Improved hybrid metaheuristic utilizing adaptive population sizing and dynamic local refinement to boost high-dimensional black box optimization.", "configspace": "", "generation": 5, "fitness": 0.7660153451045039, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.766 with standard deviation 0.022. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7423820363094582, 0.7945901820562783, 0.7610738169477751], "final_y": [0.17924064183162647, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "5a05b04d-a49c-4941-bea0-d6ba01e0daed", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def gradually_increase_dimensionality(self, current_dim):\n        return min(self.dim, current_dim + max(1, self.dim // 10))\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_dim = self.dim // 2\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = np.mean([func(trial) for _ in range(3)])  # Noise-resilient fitness evaluation\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n            current_dim = self.gradually_increase_dimensionality(current_dim)\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced hybrid optimization using adaptive layer-wise dimensionality increase and noise-resilient fitness evaluation.", "configspace": "", "generation": 5, "fitness": 0.7896863242647573, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.790 with standard deviation 0.007. And the mean value of best solutions found was 0.155 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7952499188044653, 0.7945901820562783, 0.7792188719335283], "final_y": [0.15583636498013087, 0.1601017669387199, 0.14990468350799935]}, "mutation_prompt": null}
{"id": "2c06059a-0e6f-4651-b946-fe657bfc3c5d", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5 * dim, 50)  # Adjusted population size for better balance\n        self.F = 0.6  # Increased differential weight for diversity\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.03 * convergence_speed, 0.01)  # Adjusted local search strength\n        for _ in range(7):  # Longer local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced refined hybrid metaheuristic with improved local refinement and dynamic population size adjustment for better exploration-exploitation balance.", "configspace": "", "generation": 5, "fitness": 0.7662582563839625, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.766 with standard deviation 0.043. And the mean value of best solutions found was 0.169 (0. is the best) with standard deviation 0.020.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7057753312001642, 0.7945901820562783, 0.7984092558954449], "final_y": [0.1962493555245659, 0.1601017669387199, 0.1504681414031811]}, "mutation_prompt": null}
{"id": "edac7b71-e751-4e67-9683-75865be8f8b3", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        diversity = np.std(self.population) / (bounds.ub - bounds.lb)\n        self.F = 0.3 + 0.4 * (1 - diversity)  # Adjust F based on diversity\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Introduced variable differential weight F based on population diversity to enhance exploration-exploitation balance.", "configspace": "", "generation": 5, "fitness": 0.7731473820208293, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.773 with standard deviation 0.016. And the mean value of best solutions found was 0.163 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7583766688241499, 0.7945901820562783, 0.7664752951820595], "final_y": [0.1599358328528131, 0.1601017669387199, 0.16988310902113224]}, "mutation_prompt": null}
{"id": "22233a6f-9fe8-4c9e-a212-25a55d40c66d", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.03 * convergence_speed, 0.005)  # Changed perturbation coefficients\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Refined hybrid metaheuristic with an enhanced adaptive local refinement strategy for improved precision in black box optimization.", "configspace": "", "generation": 6, "fitness": 0.7660153451045039, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.766 with standard deviation 0.022. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7423820363094582, 0.7945901820562783, 0.7610738169477751], "final_y": [0.17924064183162647, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "f1b203f9-dc35-4608-b5e2-53a0ad214197", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + np.random.uniform(0.4, 0.6) * (b - c)  # Improved mutation strategy\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.02)  # Dynamic perturbation tuning\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic with improved mutation strategy and dynamic perturbation tuning for superior exploration.", "configspace": "", "generation": 6, "fitness": 0.7731689733339602, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.773 with standard deviation 0.022. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7423820363094582, 0.7945901820562783, 0.7825347016361437], "final_y": [0.17924064183162647, 0.1601017669387199, 0.1586300117719177]}, "mutation_prompt": null}
{"id": "1aaed82b-e8fe-4fdf-8522-18d9c85f5e4b", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        dynamic_perturbation = perturbation_strength * (1 + convergence_speed)  # Dynamic neighborhood size\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-dynamic_perturbation, dynamic_perturbation, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced local refinement by incorporating a dynamic neighborhood size based on convergence speed, improving local search adaptability.", "configspace": "", "generation": 6, "fitness": 0.7669080601794538, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.767 with standard deviation 0.023. And the mean value of best solutions found was 0.170 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7423820363094582, 0.7972683272811281, 0.7610738169477751], "final_y": [0.17924064183162647, 0.15684437429242626, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "2d72cdc3-9eb7-4a3c-a39f-e2a9eebb8eaf", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 5 * dim  # Reduced initial population size for better focus\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(5)]) > func(candidate):  # Increased noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic with dynamic population resizing and noise-aware evaluation for improved exploration and convergence.", "configspace": "", "generation": 6, "fitness": 0.7625411567415806, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.763 with standard deviation 0.026. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.731959471220688, 0.7945901820562783, 0.7610738169477751], "final_y": [0.1812292654023231, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "6586818e-b045-4474-92a1-f1a60953668e", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n                # Adjust population size adaptively based on convergence speed\n                self.pop_size = min(int(10 * self.dim * (1 - convergence_speed)), self.budget - num_evaluations)\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic utilizing adaptive population size adjustment for improved exploration and exploitation balance.", "configspace": "", "generation": 6, "fitness": 0.7660153451045039, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.766 with standard deviation 0.022. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7423820363094582, 0.7945901820562783, 0.7610738169477751], "final_y": [0.17924064183162647, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "2879cfb2-477f-4529-b558-9aea3095b3de", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(np.random.randint(3, 7)):  # Adjust search steps probabilistically\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(np.random.randint(2, 4))]) > func(candidate):  # Adaptive evaluation strategy\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced exploration with probabilistic perturbation and adaptive evaluation strategy for improved local search.", "configspace": "", "generation": 7, "fitness": 0.7670295559246156, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.767 with standard deviation 0.021. And the mean value of best solutions found was 0.169 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.744189272763133, 0.7945901820562783, 0.7623092129544353], "final_y": [0.17627002658491686, 0.1601017669387199, 0.16922029897918167]}, "mutation_prompt": null}
{"id": "b7ba897d-d2e3-46d9-87b7-1e7a81969de6", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.03 * convergence_speed, 0.005)  # Modified perturbation strength\n        for _ in range(7):  # Increased local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            self.pop_size = max(5, self.pop_size - 1)  # Dynamic population reduction\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Improved hybrid metaheuristic with dynamic population adjustments and enhanced local refinement for better convergence in black box optimization.", "configspace": "", "generation": 7, "fitness": 0.7661228588658467, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.766 with standard deviation 0.021. And the mean value of best solutions found was 0.170 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7427045775934872, 0.7945901820562783, 0.7610738169477751], "final_y": [0.17795275741016003, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "135067ff-1343-4e67-bec0-92190af6e12c", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(10 * dim, 50)  # Dynamic population size\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                # Layer-by-layer optimization\n                for layer in range(self.dim):\n                    trial[layer] += np.random.normal(0, 0.01)\n                trial = np.clip(trial, bounds.lb, bounds.ub)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic that introduces a dynamic population size adjustment and layer-by-layer optimization for improved convergence in complex black box optimization tasks.", "configspace": "", "generation": 7, "fitness": 0.7660153451045039, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.766 with standard deviation 0.022. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7423820363094582, 0.7945901820562783, 0.7610738169477751], "final_y": [0.17924064183162647, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "b4b5a315-80d2-46e4-8aeb-fd3f9e491524", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.03 * convergence_speed, 0.01)  # Reduced perturbation scale\n        for _ in range(7):  # Increased local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced adaptive refinement through dynamic perturbation scaling and improved noise handling to optimize photovoltaic structures.", "configspace": "", "generation": 7, "fitness": 0.7660153451045039, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.766 with standard deviation 0.022. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7423820363094582, 0.7945901820562783, 0.7610738169477751], "final_y": [0.17924064183162647, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "22a1a06e-1846-406e-a6c5-cedfc093425b", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.median([func(trial) for _ in range(5)]) > func(candidate):  # Improved noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Improved local refinement step by enhancing noise reduction strategy for more robust convergence.", "configspace": "", "generation": 7, "fitness": 0.7660153451045039, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.766 with standard deviation 0.022. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7423820363094582, 0.7945901820562783, 0.7610738169477751], "final_y": [0.17924064183162647, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "0abbf117-a88b-47d2-9385-4d1b4d6b5042", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        # Change 1: Adaptive scaling for mutation\n        adaptive_F = self.F * np.random.uniform(0.5, 1.5)  \n        mutant = a + adaptive_F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        # Change 2: Dynamic crossover probability\n        self.CR = 0.9 * (1 - num_evaluations / self.budget) + 0.1\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Improved hybrid metaheuristic using adaptive scaling for mutation and dynamic crossover for enhanced balance between exploration and exploitation.", "configspace": "", "generation": 8, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'num_evaluations' is not defined\").", "error": "NameError(\"name 'num_evaluations' is not defined\")", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {}, "mutation_prompt": null}
{"id": "a75e1eae-54c4-4c77-a106-d74ae3b7ba27", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + np.random.uniform(0.5, self.F) * (b - c)  # Adaptive F\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(5)]) > func(candidate):  # Noise tolerance increase\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Improved hybrid metaheuristic incorporating adaptive mutation strategies and noise-tolerant local search for enhanced solution accuracy in black box optimization.", "configspace": "", "generation": 8, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'num_evaluations' is not defined\").", "error": "NameError(\"name 'num_evaluations' is not defined\")", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {}, "mutation_prompt": null}
{"id": "169ac9ec-63a9-4ffa-bc39-0cee1d9d0b9c", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        candidate += np.random.uniform(-0.01, 0.01, self.dim) # Minor random exploration\n        return np.clip(candidate, bounds.lb, bounds.ub)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic integrates neighborhood exploration with adaptive refinements for accelerated convergence.", "configspace": "", "generation": 8, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'num_evaluations' is not defined\").", "error": "NameError(\"name 'num_evaluations' is not defined\")", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {}, "mutation_prompt": null}
{"id": "18d90e52-02f8-4115-b542-11e432d74c38", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        perturbation_strength *= (1 + np.std([func(candidate + np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)) for _ in range(5)]))  # Added stochastic perturbation based on fitness variance\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced the adaptive local refinement strategy to introduce stochastic perturbation based on fitness variance to improve robustness against noisy evaluations.", "configspace": "", "generation": 8, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'num_evaluations' is not defined\").", "error": "NameError(\"name 'num_evaluations' is not defined\")", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {}, "mutation_prompt": null}
{"id": "752b1c90-8090-409b-8617-5aa3678fbecd", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        convergence_speed = 1  # Placeholder to use later\n        adaptive_F = self.F + convergence_speed * 0.1  # Adaptive mutation scaling\n        mutant = a + adaptive_F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic with adaptive mutation scaling based on convergence speed for improved exploration.", "configspace": "", "generation": 8, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'num_evaluations' is not defined\").", "error": "NameError(\"name 'num_evaluations' is not defined\")", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {}, "mutation_prompt": null}
