{"id": "53295112-db3a-4502-881d-9656759f25c2", "solution": "import numpy as np\nimport random\n\nclass DynamicPopulationEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Define population size\n        population_size = min(20, self.budget // 2)\n        # Initialize population within bounds\n        population = np.random.uniform(\n            low=func.bounds.lb, \n            high=func.bounds.ub, \n            size=(population_size, self.dim)\n        )\n        fitness = np.array([func(ind) for ind in population])\n        self.budget -= population_size\n        \n        # Evolution loop\n        while self.budget > 0:\n            # Select parents based on fitness proportional selection\n            parents_idx = np.random.choice(\n                population_size, \n                size=population_size, \n                p=fitness / fitness.sum()\n            )\n            parents = population[parents_idx]\n            \n            # Generate offspring through crossover and mutation\n            offspring = []\n            for i in range(population_size):\n                parent1, parent2 = parents[i], parents[(i + 1) % population_size]\n                \n                # Crossover (blend crossover)\n                alpha = np.random.uniform(0, 1, self.dim)\n                child = alpha * parent1 + (1 - alpha) * parent2\n                \n                # Mutation (adaptive Gaussian mutation)\n                mutation_strength = 0.1 * (func.bounds.ub - func.bounds.lb)\n                mutation = np.random.normal(0, mutation_strength, self.dim)\n                child += mutation\n                \n                # Ensure child is within bounds\n                child = np.clip(child, func.bounds.lb, func.bounds.ub)\n                offspring.append(child)\n            \n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            self.budget -= population_size\n            \n            # Combine and select the next generation\n            combined_population = np.vstack((population, offspring))\n            combined_fitness = np.hstack((fitness, offspring_fitness))\n            best_individuals_idx = np.argsort(combined_fitness)[:population_size]\n            population = combined_population[best_individuals_idx]\n            fitness = combined_fitness[best_individuals_idx]\n        \n        # Return the best found solution\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "DynamicPopulationEvolution", "description": "The algorithm leverages a dynamic population-based search with adaptive mutation and crossover strategies inspired by biological evolution to efficiently explore and exploit the search space for optimal solutions.", "configspace": "", "generation": 0, "fitness": 0.2438456795121671, "feedback": "The algorithm DynamicPopulationEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.244 with standard deviation 0.021. And the mean value of best solutions found was 0.099 (0. is the best) with standard deviation 0.046.", "error": "", "parent_id": null, "metadata": {"aucs": [0.21816921349052365, 0.24431891605614198, 0.2690489089898357], "final_y": [0.1532246301597944, 0.10244050118474861, 0.04055519839219992]}, "mutation_prompt": null}
{"id": "eb40be6b-e8f5-44fc-babf-349e22eb25f8", "solution": "import numpy as np\nimport random\n\nclass DynamicPopulationEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Define population size\n        population_size = min(20, self.budget // 2)\n        # Initialize population within bounds\n        population = np.random.uniform(\n            low=func.bounds.lb, \n            high=func.bounds.ub, \n            size=(population_size, self.dim)\n        )\n        fitness = np.array([func(ind) for ind in population])\n        self.budget -= population_size\n        \n        # Evolution loop\n        while self.budget > 0:\n            # Select parents based on fitness proportional selection\n            parents_idx = np.random.choice(\n                population_size, \n                size=population_size, \n                p=fitness / fitness.sum()\n            )\n            parents = population[parents_idx]\n            \n            # Generate offspring through crossover and mutation\n            offspring = []\n            for i in range(population_size):\n                parent1, parent2 = parents[i], parents[(i + 1) % population_size]\n                \n                # Crossover (blend crossover)\n                alpha = np.random.uniform(0.3, 0.7, self.dim)  # refined blend range\n                child = alpha * parent1 + (1 - alpha) * parent2\n                \n                # Mutation (adaptive Gaussian mutation)\n                mutation_strength = 0.05 * (func.bounds.ub - func.bounds.lb) # reduced mutation strength\n                mutation = np.random.normal(0, mutation_strength, self.dim)\n                child += mutation\n                \n                # Ensure child is within bounds\n                child = np.clip(child, func.bounds.lb, func.bounds.ub)\n                offspring.append(child)\n            \n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            self.budget -= population_size\n            \n            # Combine and select the next generation\n            combined_population = np.vstack((population, offspring))\n            combined_fitness = np.hstack((fitness, offspring_fitness))\n            best_individuals_idx = np.argsort(combined_fitness)[:population_size]\n            elitism_idx = np.argmin(combined_fitness) # Elite strategy\n            population = combined_population[best_individuals_idx]\n            population[0] = combined_population[elitism_idx] # Add elite\n            fitness = combined_fitness[best_individuals_idx]\n        \n        # Return the best found solution\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "DynamicPopulationEvolution", "description": "The algorithm enhances the exploration-exploitation balance by implementing an elite strategy and refined mutation, boosting convergence efficiency.", "configspace": "", "generation": 1, "fitness": 0.23334797218017458, "feedback": "The algorithm DynamicPopulationEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.233 with standard deviation 0.010. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.048.", "error": "", "parent_id": "53295112-db3a-4502-881d-9656759f25c2", "metadata": {"aucs": [0.24458023696109743, 0.22114101768219852, 0.23432266189722784], "final_y": [0.1317912153005378, 0.17368849229760278, 0.05681988065064785]}, "mutation_prompt": null}
{"id": "9a669157-7c5a-4076-b5b1-a9c2b381339f", "solution": "import numpy as np\nimport random\n\nclass DynamicPopulationEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Define population size\n        population_size = min(20, self.budget // 2)\n        # Initialize population within bounds\n        population = np.random.uniform(\n            low=func.bounds.lb, \n            high=func.bounds.ub, \n            size=(population_size, self.dim)\n        )\n        fitness = np.array([func(ind) for ind in population])\n        self.budget -= population_size\n        \n        # Evolution loop\n        while self.budget > 0:\n            # Select parents based on fitness proportional selection\n            parents_idx = np.random.choice(\n                population_size, \n                size=population_size, \n                p=fitness / fitness.sum()\n            )\n            parents = population[parents_idx]\n            \n            # Generate offspring through crossover and mutation\n            offspring = []\n            for i in range(population_size):\n                parent1, parent2 = parents[i], parents[(i + 1) % population_size]\n                \n                # Crossover (blend crossover)\n                alpha = np.random.uniform(0, 1, self.dim)\n                child = alpha * parent1 + (1 - alpha) * parent2\n                \n                # Mutation (Lévy flight mutation)\n                levy_flight = np.random.standard_cauchy(self.dim) * 0.1\n                child += levy_flight * (func.bounds.ub - func.bounds.lb)\n                \n                # Ensure child is within bounds\n                child = np.clip(child, func.bounds.lb, func.bounds.ub)\n                offspring.append(child)\n            \n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            self.budget -= population_size\n            \n            # Combine and select the next generation\n            combined_population = np.vstack((population, offspring))\n            combined_fitness = np.hstack((fitness, offspring_fitness))\n            best_individuals_idx = np.argsort(combined_fitness)[:population_size]\n            population = combined_population[best_individuals_idx]\n            fitness = combined_fitness[best_individuals_idx]\n        \n        # Return the best found solution\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "DynamicPopulationEvolution", "description": "The algorithm improves exploration by incorporating Lévy flights for mutation, enhancing the search efficiency in complex landscapes.", "configspace": "", "generation": 2, "fitness": 0.21331015465055372, "feedback": "The algorithm DynamicPopulationEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.213 with standard deviation 0.011. And the mean value of best solutions found was 0.177 (0. is the best) with standard deviation 0.047.", "error": "", "parent_id": "53295112-db3a-4502-881d-9656759f25c2", "metadata": {"aucs": [0.21490767304750746, 0.19887872573060927, 0.22614406517354446], "final_y": [0.15504188232716584, 0.24216468408023165, 0.13295869535821916]}, "mutation_prompt": null}
{"id": "cb4a3ce8-b061-45ce-a330-d8ca797a6f9e", "solution": "import numpy as np\nimport random\n\nclass DynamicPopulationEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Define population size\n        population_size = min(20, self.budget // 2)\n        # Initialize population within bounds\n        population = np.random.uniform(\n            low=func.bounds.lb, \n            high=func.bounds.ub, \n            size=(population_size, self.dim)\n        )\n        fitness = np.array([func(ind) for ind in population])\n        self.budget -= population_size\n        best_idx = np.argmin(fitness)  # Track best solution\n        best_solution = population[best_idx]\n\n        # Evolution loop\n        while self.budget > 0:\n            # Select parents based on fitness proportional selection\n            parents_idx = np.random.choice(\n                population_size, \n                size=population_size, \n                p=fitness / fitness.sum()\n            )\n            parents = population[parents_idx]\n            \n            # Generate offspring through crossover and mutation\n            offspring = []\n            for i in range(population_size):\n                parent1, parent2 = parents[i], parents[(i + 1) % population_size]\n                \n                # Crossover (blend crossover)\n                alpha = np.random.uniform(0, 1, self.dim)\n                child = alpha * parent1 + (1 - alpha) * parent2\n                \n                # Mutation (adaptive Gaussian mutation)\n                mutation_strength = 0.1 * (func.bounds.ub - func.bounds.lb)\n                mutation = np.random.normal(0, mutation_strength, self.dim)\n                child += mutation\n                \n                # Ensure child is within bounds\n                child = np.clip(child, func.bounds.lb, func.bounds.ub)\n                offspring.append(child)\n            \n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            self.budget -= population_size\n            \n            # Combine and select the next generation\n            combined_population = np.vstack((population, offspring, [best_solution]))  # Preserve best solution\n            combined_fitness = np.hstack((fitness, offspring_fitness, [fitness[best_idx]]))\n            best_individuals_idx = np.argsort(combined_fitness)[:population_size]\n            population = combined_population[best_individuals_idx]\n            fitness = combined_fitness[best_individuals_idx]\n            \n            # Update best solution\n            best_idx = np.argmin(fitness)\n            best_solution = population[best_idx]\n        \n        # Return the best found solution\n        return best_solution", "name": "DynamicPopulationEvolution", "description": "Introduce elitism by always preserving the best solution found so far, ensuring that the top candidate is never lost during population updates.", "configspace": "", "generation": 3, "fitness": 0.24701358946899302, "feedback": "The algorithm DynamicPopulationEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.019. And the mean value of best solutions found was 0.077 (0. is the best) with standard deviation 0.044.", "error": "", "parent_id": "53295112-db3a-4502-881d-9656759f25c2", "metadata": {"aucs": [0.24255183167067107, 0.2724225106499747, 0.22606642608633332], "final_y": [0.12177558632167293, 0.01772135932308937, 0.0903189080723321]}, "mutation_prompt": null}
{"id": "a4fa13b1-c8fd-40dd-956e-d3ae32727054", "solution": "import numpy as np\nimport random\n\nclass DynamicPopulationEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        population_size = min(20, self.budget // 2)\n        population = np.random.uniform(\n            low=func.bounds.lb, \n            high=func.bounds.ub, \n            size=(population_size, self.dim)\n        )\n        fitness = np.array([func(ind) for ind in population])\n        self.budget -= population_size\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        \n        no_improvement_count = 0  # Counter to track convergence\n\n        while self.budget > 0:\n            parents_idx = np.random.choice(\n                population_size, \n                size=population_size, \n                p=(1 / (fitness + 1e-9)) / (1 / (fitness + 1e-9)).sum()\n            )\n            parents = population[parents_idx]\n            \n            offspring = []\n            for i in range(population_size):\n                parent1, parent2 = parents[i], parents[(i + 1) % population_size]\n                alpha = np.random.uniform(0, 1, self.dim)\n                child = alpha * parent1 + (1 - alpha) * parent2\n                \n                mutation_strength = 0.1 * (func.bounds.ub - func.bounds.lb) * np.std(fitness)\n                mutation = np.random.normal(0, mutation_strength, self.dim)\n                child += mutation\n                child = np.clip(child, func.bounds.lb, func.bounds.ub)\n                offspring.append(child)\n            \n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            self.budget -= population_size\n            \n            combined_population = np.vstack((population, offspring, [best_solution]))\n            combined_fitness = np.hstack((fitness, offspring_fitness, [fitness[best_idx]]))\n            best_individuals_idx = np.argsort(combined_fitness)[:population_size]\n            population = combined_population[best_individuals_idx]\n            fitness = combined_fitness[best_individuals_idx]\n            \n            new_best_idx = np.argmin(fitness)\n            if fitness[new_best_idx] < fitness[best_idx]:\n                best_idx = new_best_idx\n                best_solution = population[best_idx]\n                no_improvement_count = 0  # Reset convergence counter\n            else:\n                no_improvement_count += 1\n\n            if no_improvement_count > 5:  # Restart if no improvement for 5 iterations\n                population = np.random.uniform(\n                    low=func.bounds.lb, \n                    high=func.bounds.ub, \n                    size=(population_size, self.dim)\n                )\n                fitness = np.array([func(ind) for ind in population])\n                self.budget -= population_size\n                no_improvement_count = 0\n\n        return best_solution", "name": "DynamicPopulationEvolution", "description": "Enhance search efficiency by introducing diversity via a restart mechanism when convergence stalls, and adjust mutation strength dynamically based on fitness variance.", "configspace": "", "generation": 4, "fitness": 0.19034896063130582, "feedback": "The algorithm DynamicPopulationEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.190 with standard deviation 0.022. And the mean value of best solutions found was 0.438 (0. is the best) with standard deviation 0.162.", "error": "", "parent_id": "cb4a3ce8-b061-45ce-a330-d8ca797a6f9e", "metadata": {"aucs": [0.18223006288253873, 0.22018747651931025, 0.1686293424920685], "final_y": [0.5174477332373543, 0.21192945620447948, 0.584254686760048]}, "mutation_prompt": null}
{"id": "1435a9ad-5e2d-4e6d-873d-2e25ee67b93c", "solution": "import numpy as np\nimport random\n\nclass DynamicPopulationEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Define population size\n        population_size = min(20, self.budget // 2)\n        # Initialize population within bounds\n        population = np.random.uniform(\n            low=func.bounds.lb, \n            high=func.bounds.ub, \n            size=(population_size, self.dim)\n        )\n        fitness = np.array([func(ind) for ind in population])\n        self.budget -= population_size\n        best_idx = np.argmin(fitness)  # Track best solution\n        best_solution = population[best_idx]\n\n        # Evolution loop\n        while self.budget > 0:\n            # Select parents based on fitness proportional selection\n            parents_idx = np.random.choice(\n                population_size, \n                size=population_size, \n                p=fitness / fitness.sum()\n            )\n            parents = population[parents_idx]\n            \n            # Generate offspring through crossover and mutation\n            offspring = []\n            for i in range(population_size):\n                parent1, parent2 = parents[i], parents[(i + 1) % population_size]\n                \n                # Crossover (blend crossover)\n                alpha = np.random.uniform(0, 1, self.dim)\n                child = alpha * parent1 + (1 - alpha) * parent2\n                \n                # Mutation (adaptive Gaussian mutation)\n                mutation_strength = 0.1 * (func.bounds.ub - func.bounds.lb) * (fitness[best_idx] / fitness.mean())\n                mutation = np.random.normal(0, mutation_strength, self.dim)\n                child += mutation\n                \n                # Ensure child is within bounds\n                child = np.clip(child, func.bounds.lb, func.bounds.ub)\n                offspring.append(child)\n            \n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            self.budget -= population_size\n            \n            # Combine and select the next generation\n            combined_population = np.vstack((population, offspring, [best_solution]))  # Preserve best solution\n            combined_fitness = np.hstack((fitness, offspring_fitness, [fitness[best_idx]]))\n            best_individuals_idx = np.argsort(combined_fitness)[:population_size]\n            population = combined_population[best_individuals_idx]\n            fitness = combined_fitness[best_individuals_idx]\n            \n            # Update best solution\n            best_idx = np.argmin(fitness)\n            best_solution = population[best_idx]\n        \n        # Return the best found solution\n        return best_solution", "name": "DynamicPopulationEvolution", "description": "Introduce a dynamic mutation strength based on the best solution's fitness relative to the population to enhance exploration and convergence.", "configspace": "", "generation": 5, "fitness": 0.2683079435757411, "feedback": "The algorithm DynamicPopulationEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.268 with standard deviation 0.011. And the mean value of best solutions found was 0.041 (0. is the best) with standard deviation 0.018.", "error": "", "parent_id": "cb4a3ce8-b061-45ce-a330-d8ca797a6f9e", "metadata": {"aucs": [0.2758665883780784, 0.2532069289095866, 0.27585031343955824], "final_y": [0.06112787011361208, 0.04494891236423311, 0.017567005402042413]}, "mutation_prompt": null}
{"id": "04928b9d-c56c-419a-aeed-0792bf554f86", "solution": "import numpy as np\nimport random\n\nclass DynamicPopulationEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        population_size = min(20, self.budget // 2)\n        population = np.random.uniform(\n            low=func.bounds.lb, \n            high=func.bounds.ub, \n            size=(population_size, self.dim)\n        )\n        fitness = np.array([func(ind) for ind in population])\n        self.budget -= population_size\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n\n        while self.budget > 0:\n            parents_idx = np.random.choice(\n                population_size, \n                size=population_size, \n                p=fitness / fitness.sum()\n            )\n            parents = population[parents_idx]\n            \n            offspring = []\n            for i in range(population_size):\n                parent1, parent2 = parents[i], parents[(i + 1) % population_size]\n                \n                alpha = np.random.uniform(0, 1, self.dim)\n                child = alpha * parent1 + (1 - alpha) * parent2\n                \n                mutation_strength = 0.1 * (func.bounds.ub - func.bounds.lb) * (fitness[best_idx] / fitness.mean())\n                \n                if np.std(fitness) > 0.05:  # Switch mutation strategy based on fitness variance\n                    mutation = np.random.standard_cauchy(self.dim) * mutation_strength\n                else:\n                    mutation = np.random.normal(0, mutation_strength, self.dim)\n                child += mutation\n                \n                child = np.clip(child, func.bounds.lb, func.bounds.ub)\n                offspring.append(child)\n            \n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            self.budget -= population_size\n            \n            combined_population = np.vstack((population, offspring, [best_solution]))\n            combined_fitness = np.hstack((fitness, offspring_fitness, [fitness[best_idx]]))\n            best_individuals_idx = np.argsort(combined_fitness)[:population_size]\n            population = combined_population[best_individuals_idx]\n            fitness = combined_fitness[best_individuals_idx]\n            \n            best_idx = np.argmin(fitness)\n            best_solution = population[best_idx]\n        \n        return best_solution", "name": "DynamicPopulationEvolution", "description": "Implement a multi-strategy mutation mechanism that alternates between Gaussian and Cauchy mutations based on fitness variance to improve exploration and robustness.", "configspace": "", "generation": 6, "fitness": 0.2672084385465224, "feedback": "The algorithm DynamicPopulationEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.267 with standard deviation 0.043. And the mean value of best solutions found was 0.098 (0. is the best) with standard deviation 0.110.", "error": "", "parent_id": "1435a9ad-5e2d-4e6d-873d-2e25ee67b93c", "metadata": {"aucs": [0.2969827483367229, 0.20653603966516842, 0.29810652763767576], "final_y": [0.036220115308696434, 0.2527224380963262, 0.004354772655302739]}, "mutation_prompt": null}
{"id": "96e8532f-8983-49f9-8fcd-46dbb3f7006b", "solution": "import numpy as np\nimport random\n\nclass DynamicPopulationEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Define population size\n        population_size = min(20, self.budget // 2)\n        # Initialize population within bounds\n        population = np.random.uniform(\n            low=func.bounds.lb, \n            high=func.bounds.ub, \n            size=(population_size, self.dim)\n        )\n        fitness = np.array([func(ind) for ind in population])\n        self.budget -= population_size\n        best_idx = np.argmin(fitness)  # Track best solution\n        best_solution = population[best_idx]\n\n        # Evolution loop\n        while self.budget > 0:\n            # Rank-based fitness scaling\n            ranks = np.argsort(fitness)\n            scaled_fitness = 1.0 / (1.0 + ranks)\n            parents_idx = np.random.choice(\n                population_size, \n                size=population_size,\n                p=scaled_fitness / scaled_fitness.sum()\n            )\n            parents = population[parents_idx]\n            \n            # Generate offspring through crossover and mutation\n            offspring = []\n            for i in range(population_size):\n                parent1, parent2 = parents[i], parents[(i + 1) % population_size]\n                \n                # Crossover (blend crossover)\n                alpha = np.random.uniform(0, 1, self.dim)\n                child = alpha * parent1 + (1 - alpha) * parent2\n                \n                # Mutation (adaptive Gaussian mutation)\n                mutation_strength = 0.1 * (func.bounds.ub - func.bounds.lb) * (fitness[best_idx] / fitness.mean())\n                mutation = np.random.normal(0, mutation_strength, self.dim)\n                child += mutation\n                \n                # Ensure child is within bounds\n                child = np.clip(child, func.bounds.lb, func.bounds.ub)\n                offspring.append(child)\n            \n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            self.budget -= population_size\n            \n            # Combine and select the next generation\n            combined_population = np.vstack((population, offspring, [best_solution]))  # Preserve best solution\n            combined_fitness = np.hstack((fitness, offspring_fitness, [fitness[best_idx]]))\n            best_individuals_idx = np.argsort(combined_fitness)[:population_size]\n            population = combined_population[best_individuals_idx]\n            fitness = combined_fitness[best_individuals_idx]\n            \n            # Update best solution\n            best_idx = np.argmin(fitness)\n            best_solution = population[best_idx]\n        \n        # Return the best found solution\n        return best_solution", "name": "DynamicPopulationEvolution", "description": "Enhance selection by incorporating a rank-based fitness scaling to improve diversity and maintain exploration.", "configspace": "", "generation": 7, "fitness": 0.272084140043332, "feedback": "The algorithm DynamicPopulationEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.272 with standard deviation 0.015. And the mean value of best solutions found was 0.067 (0. is the best) with standard deviation 0.028.", "error": "", "parent_id": "1435a9ad-5e2d-4e6d-873d-2e25ee67b93c", "metadata": {"aucs": [0.28539091581927345, 0.25074832400012903, 0.2801131803105935], "final_y": [0.044059701488059454, 0.10683482846498608, 0.05052713042325002]}, "mutation_prompt": null}
{"id": "e98dcfb8-8cb7-4f69-ad62-1080d1e93176", "solution": "import numpy as np\nimport random\n\nclass DynamicPopulationEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Define population size\n        population_size = min(20, self.budget // 2)\n        # Initialize population within bounds\n        population = np.random.uniform(\n            low=func.bounds.lb, \n            high=func.bounds.ub, \n            size=(population_size, self.dim)\n        )\n        fitness = np.array([func(ind) for ind in population])\n        self.budget -= population_size\n        best_idx = np.argmin(fitness)  # Track best solution\n        best_solution = population[best_idx]\n\n        # Evolution loop\n        while self.budget > 0:\n            # Rank-based fitness scaling\n            ranks = np.argsort(fitness)\n            scaled_fitness = 1.0 / (1.0 + ranks)\n            parents_idx = np.random.choice(\n                population_size, \n                size=population_size,\n                p=scaled_fitness / scaled_fitness.sum()\n            )\n            parents = population[parents_idx]\n            \n            # Generate offspring through crossover and mutation\n            offspring = []\n            for i in range(population_size):\n                parent1, parent2 = parents[i], parents[(i + 1) % population_size]\n                \n                # Crossover (blend crossover)\n                alpha = np.random.uniform(0, 1, self.dim)\n                child = alpha * parent1 + (1 - alpha) * parent2\n                \n                # Mutation (adaptive Gaussian mutation)\n                mutation_strength = 0.1 * (func.bounds.ub - func.bounds.lb) * (fitness[best_idx] / fitness.mean())\n                mutation_strength *= np.random.uniform(0.9, 1.1)  # Adaptive mutation scaling\n                mutation = np.random.normal(0, mutation_strength, self.dim)\n                child += mutation\n                \n                # Ensure child is within bounds\n                child = np.clip(child, func.bounds.lb, func.bounds.ub)\n                offspring.append(child)\n            \n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            self.budget -= population_size\n            \n            # Combine and select the next generation\n            combined_population = np.vstack((population, offspring, [best_solution]))  # Preserve best solution\n            combined_fitness = np.hstack((fitness, offspring_fitness, [fitness[best_idx]]))\n            best_individuals_idx = np.argsort(combined_fitness)[:population_size]\n            population = combined_population[best_individuals_idx]\n            fitness = combined_fitness[best_individuals_idx]\n            \n            # Update best solution\n            best_idx = np.argmin(fitness)\n            best_solution = population[best_idx]\n        \n        # Return the best found solution\n        return best_solution", "name": "DynamicPopulationEvolution", "description": "Introduce elitism and adaptive mutation scaling to enhance exploitation and achieve better convergence.", "configspace": "", "generation": 8, "fitness": 0.25133620969033194, "feedback": "The algorithm DynamicPopulationEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.251 with standard deviation 0.013. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.032.", "error": "", "parent_id": "96e8532f-8983-49f9-8fcd-46dbb3f7006b", "metadata": {"aucs": [0.24670741971772425, 0.23866652457223658, 0.268634684781035], "final_y": [0.13614526796292004, 0.13408332721514155, 0.06785271885413777]}, "mutation_prompt": null}
{"id": "201c3260-ba4a-4307-9637-ff9308f30de1", "solution": "import numpy as np\nimport random\n\nclass DynamicPopulationEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Define population size\n        population_size = min(20, self.budget // 2)\n        # Initialize population within bounds\n        population = np.random.uniform(\n            low=func.bounds.lb, \n            high=func.bounds.ub, \n            size=(population_size, self.dim)\n        )\n        fitness = np.array([func(ind) for ind in population])\n        self.budget -= population_size\n        best_idx = np.argmin(fitness)  # Track best solution\n        best_solution = population[best_idx]\n\n        # Evolution loop\n        while self.budget > 0:\n            # Rank-based fitness scaling\n            ranks = np.argsort(fitness)\n            scaled_fitness = 1.0 / (1.0 + ranks)\n            parents_idx = np.random.choice(\n                population_size, \n                size=population_size,\n                p=scaled_fitness / scaled_fitness.sum()\n            )\n            parents = population[parents_idx]\n            \n            # Generate offspring through crossover and mutation\n            offspring = []\n            for i in range(population_size):\n                parent1, parent2 = parents[i], parents[(i + 1) % population_size]\n                \n                # Crossover (blend crossover)\n                alpha = np.random.uniform(0, 1, self.dim)\n                child = alpha * parent1 + (1 - alpha) * parent2\n                \n                # Mutation (adaptive Gaussian mutation)\n                mutation_strength = 0.1 * (func.bounds.ub - func.bounds.lb) * (fitness[best_idx] / fitness.mean()) * (self.budget / (self.budget + population_size))\n                mutation = np.random.normal(0, mutation_strength, self.dim)\n                child += mutation\n                \n                # Ensure child is within bounds\n                child = np.clip(child, func.bounds.lb, func.bounds.ub)\n                offspring.append(child)\n            \n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            self.budget -= population_size\n            \n            # Combine and select the next generation\n            combined_population = np.vstack((population, offspring, [best_solution]))  # Preserve best solution\n            combined_fitness = np.hstack((fitness, offspring_fitness, [fitness[best_idx]]))\n            best_individuals_idx = np.argsort(combined_fitness)[:population_size]\n            population = combined_population[best_individuals_idx]\n            fitness = combined_fitness[best_individuals_idx]\n            \n            # Update best solution\n            best_idx = np.argmin(fitness)\n            best_solution = population[best_idx]\n        \n        # Return the best found solution\n        return best_solution", "name": "DynamicPopulationEvolution", "description": "Introduce a more dynamic mutation strength by incorporating the current budget percentage to balance exploration and exploitation dynamically.", "configspace": "", "generation": 9, "fitness": 0.2686239750166652, "feedback": "The algorithm DynamicPopulationEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.269 with standard deviation 0.027. And the mean value of best solutions found was 0.090 (0. is the best) with standard deviation 0.050.", "error": "", "parent_id": "96e8532f-8983-49f9-8fcd-46dbb3f7006b", "metadata": {"aucs": [0.25247905318310004, 0.3063878806002347, 0.24700499126666076], "final_y": [0.13173201549856497, 0.019265611051632065, 0.1196742141959678]}, "mutation_prompt": null}
