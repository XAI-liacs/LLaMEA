{"id": "53295112-db3a-4502-881d-9656759f25c2", "solution": "import numpy as np\nimport random\n\nclass DynamicPopulationEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Define population size\n        population_size = min(20, self.budget // 2)\n        # Initialize population within bounds\n        population = np.random.uniform(\n            low=func.bounds.lb, \n            high=func.bounds.ub, \n            size=(population_size, self.dim)\n        )\n        fitness = np.array([func(ind) for ind in population])\n        self.budget -= population_size\n        \n        # Evolution loop\n        while self.budget > 0:\n            # Select parents based on fitness proportional selection\n            parents_idx = np.random.choice(\n                population_size, \n                size=population_size, \n                p=fitness / fitness.sum()\n            )\n            parents = population[parents_idx]\n            \n            # Generate offspring through crossover and mutation\n            offspring = []\n            for i in range(population_size):\n                parent1, parent2 = parents[i], parents[(i + 1) % population_size]\n                \n                # Crossover (blend crossover)\n                alpha = np.random.uniform(0, 1, self.dim)\n                child = alpha * parent1 + (1 - alpha) * parent2\n                \n                # Mutation (adaptive Gaussian mutation)\n                mutation_strength = 0.1 * (func.bounds.ub - func.bounds.lb)\n                mutation = np.random.normal(0, mutation_strength, self.dim)\n                child += mutation\n                \n                # Ensure child is within bounds\n                child = np.clip(child, func.bounds.lb, func.bounds.ub)\n                offspring.append(child)\n            \n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            self.budget -= population_size\n            \n            # Combine and select the next generation\n            combined_population = np.vstack((population, offspring))\n            combined_fitness = np.hstack((fitness, offspring_fitness))\n            best_individuals_idx = np.argsort(combined_fitness)[:population_size]\n            population = combined_population[best_individuals_idx]\n            fitness = combined_fitness[best_individuals_idx]\n        \n        # Return the best found solution\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "DynamicPopulationEvolution", "description": "The algorithm leverages a dynamic population-based search with adaptive mutation and crossover strategies inspired by biological evolution to efficiently explore and exploit the search space for optimal solutions.", "configspace": "", "generation": 0, "fitness": 0.2438456795121671, "feedback": "The algorithm DynamicPopulationEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.244 with standard deviation 0.021. And the mean value of best solutions found was 0.099 (0. is the best) with standard deviation 0.046.", "error": "", "parent_id": null, "metadata": {"aucs": [0.21816921349052365, 0.24431891605614198, 0.2690489089898357], "final_y": [0.1532246301597944, 0.10244050118474861, 0.04055519839219992]}, "mutation_prompt": null}
{"id": "eb40be6b-e8f5-44fc-babf-349e22eb25f8", "solution": "import numpy as np\nimport random\n\nclass DynamicPopulationEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Define population size\n        population_size = min(20, self.budget // 2)\n        # Initialize population within bounds\n        population = np.random.uniform(\n            low=func.bounds.lb, \n            high=func.bounds.ub, \n            size=(population_size, self.dim)\n        )\n        fitness = np.array([func(ind) for ind in population])\n        self.budget -= population_size\n        \n        # Evolution loop\n        while self.budget > 0:\n            # Select parents based on fitness proportional selection\n            parents_idx = np.random.choice(\n                population_size, \n                size=population_size, \n                p=fitness / fitness.sum()\n            )\n            parents = population[parents_idx]\n            \n            # Generate offspring through crossover and mutation\n            offspring = []\n            for i in range(population_size):\n                parent1, parent2 = parents[i], parents[(i + 1) % population_size]\n                \n                # Crossover (blend crossover)\n                alpha = np.random.uniform(0.3, 0.7, self.dim)  # refined blend range\n                child = alpha * parent1 + (1 - alpha) * parent2\n                \n                # Mutation (adaptive Gaussian mutation)\n                mutation_strength = 0.05 * (func.bounds.ub - func.bounds.lb) # reduced mutation strength\n                mutation = np.random.normal(0, mutation_strength, self.dim)\n                child += mutation\n                \n                # Ensure child is within bounds\n                child = np.clip(child, func.bounds.lb, func.bounds.ub)\n                offspring.append(child)\n            \n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            self.budget -= population_size\n            \n            # Combine and select the next generation\n            combined_population = np.vstack((population, offspring))\n            combined_fitness = np.hstack((fitness, offspring_fitness))\n            best_individuals_idx = np.argsort(combined_fitness)[:population_size]\n            elitism_idx = np.argmin(combined_fitness) # Elite strategy\n            population = combined_population[best_individuals_idx]\n            population[0] = combined_population[elitism_idx] # Add elite\n            fitness = combined_fitness[best_individuals_idx]\n        \n        # Return the best found solution\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "DynamicPopulationEvolution", "description": "The algorithm enhances the exploration-exploitation balance by implementing an elite strategy and refined mutation, boosting convergence efficiency.", "configspace": "", "generation": 1, "fitness": 0.23334797218017458, "feedback": "The algorithm DynamicPopulationEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.233 with standard deviation 0.010. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.048.", "error": "", "parent_id": "53295112-db3a-4502-881d-9656759f25c2", "metadata": {"aucs": [0.24458023696109743, 0.22114101768219852, 0.23432266189722784], "final_y": [0.1317912153005378, 0.17368849229760278, 0.05681988065064785]}, "mutation_prompt": null}
{"id": "9a669157-7c5a-4076-b5b1-a9c2b381339f", "solution": "import numpy as np\nimport random\n\nclass DynamicPopulationEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Define population size\n        population_size = min(20, self.budget // 2)\n        # Initialize population within bounds\n        population = np.random.uniform(\n            low=func.bounds.lb, \n            high=func.bounds.ub, \n            size=(population_size, self.dim)\n        )\n        fitness = np.array([func(ind) for ind in population])\n        self.budget -= population_size\n        \n        # Evolution loop\n        while self.budget > 0:\n            # Select parents based on fitness proportional selection\n            parents_idx = np.random.choice(\n                population_size, \n                size=population_size, \n                p=fitness / fitness.sum()\n            )\n            parents = population[parents_idx]\n            \n            # Generate offspring through crossover and mutation\n            offspring = []\n            for i in range(population_size):\n                parent1, parent2 = parents[i], parents[(i + 1) % population_size]\n                \n                # Crossover (blend crossover)\n                alpha = np.random.uniform(0, 1, self.dim)\n                child = alpha * parent1 + (1 - alpha) * parent2\n                \n                # Mutation (Lévy flight mutation)\n                levy_flight = np.random.standard_cauchy(self.dim) * 0.1\n                child += levy_flight * (func.bounds.ub - func.bounds.lb)\n                \n                # Ensure child is within bounds\n                child = np.clip(child, func.bounds.lb, func.bounds.ub)\n                offspring.append(child)\n            \n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            self.budget -= population_size\n            \n            # Combine and select the next generation\n            combined_population = np.vstack((population, offspring))\n            combined_fitness = np.hstack((fitness, offspring_fitness))\n            best_individuals_idx = np.argsort(combined_fitness)[:population_size]\n            population = combined_population[best_individuals_idx]\n            fitness = combined_fitness[best_individuals_idx]\n        \n        # Return the best found solution\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "DynamicPopulationEvolution", "description": "The algorithm improves exploration by incorporating Lévy flights for mutation, enhancing the search efficiency in complex landscapes.", "configspace": "", "generation": 2, "fitness": 0.21331015465055372, "feedback": "The algorithm DynamicPopulationEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.213 with standard deviation 0.011. And the mean value of best solutions found was 0.177 (0. is the best) with standard deviation 0.047.", "error": "", "parent_id": "53295112-db3a-4502-881d-9656759f25c2", "metadata": {"aucs": [0.21490767304750746, 0.19887872573060927, 0.22614406517354446], "final_y": [0.15504188232716584, 0.24216468408023165, 0.13295869535821916]}, "mutation_prompt": null}
{"id": "cb4a3ce8-b061-45ce-a330-d8ca797a6f9e", "solution": "import numpy as np\nimport random\n\nclass DynamicPopulationEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Define population size\n        population_size = min(20, self.budget // 2)\n        # Initialize population within bounds\n        population = np.random.uniform(\n            low=func.bounds.lb, \n            high=func.bounds.ub, \n            size=(population_size, self.dim)\n        )\n        fitness = np.array([func(ind) for ind in population])\n        self.budget -= population_size\n        best_idx = np.argmin(fitness)  # Track best solution\n        best_solution = population[best_idx]\n\n        # Evolution loop\n        while self.budget > 0:\n            # Select parents based on fitness proportional selection\n            parents_idx = np.random.choice(\n                population_size, \n                size=population_size, \n                p=fitness / fitness.sum()\n            )\n            parents = population[parents_idx]\n            \n            # Generate offspring through crossover and mutation\n            offspring = []\n            for i in range(population_size):\n                parent1, parent2 = parents[i], parents[(i + 1) % population_size]\n                \n                # Crossover (blend crossover)\n                alpha = np.random.uniform(0, 1, self.dim)\n                child = alpha * parent1 + (1 - alpha) * parent2\n                \n                # Mutation (adaptive Gaussian mutation)\n                mutation_strength = 0.1 * (func.bounds.ub - func.bounds.lb)\n                mutation = np.random.normal(0, mutation_strength, self.dim)\n                child += mutation\n                \n                # Ensure child is within bounds\n                child = np.clip(child, func.bounds.lb, func.bounds.ub)\n                offspring.append(child)\n            \n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            self.budget -= population_size\n            \n            # Combine and select the next generation\n            combined_population = np.vstack((population, offspring, [best_solution]))  # Preserve best solution\n            combined_fitness = np.hstack((fitness, offspring_fitness, [fitness[best_idx]]))\n            best_individuals_idx = np.argsort(combined_fitness)[:population_size]\n            population = combined_population[best_individuals_idx]\n            fitness = combined_fitness[best_individuals_idx]\n            \n            # Update best solution\n            best_idx = np.argmin(fitness)\n            best_solution = population[best_idx]\n        \n        # Return the best found solution\n        return best_solution", "name": "DynamicPopulationEvolution", "description": "Introduce elitism by always preserving the best solution found so far, ensuring that the top candidate is never lost during population updates.", "configspace": "", "generation": 3, "fitness": 0.24701358946899302, "feedback": "The algorithm DynamicPopulationEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.019. And the mean value of best solutions found was 0.077 (0. is the best) with standard deviation 0.044.", "error": "", "parent_id": "53295112-db3a-4502-881d-9656759f25c2", "metadata": {"aucs": [0.24255183167067107, 0.2724225106499747, 0.22606642608633332], "final_y": [0.12177558632167293, 0.01772135932308937, 0.0903189080723321]}, "mutation_prompt": null}
{"id": "a4fa13b1-c8fd-40dd-956e-d3ae32727054", "solution": "import numpy as np\nimport random\n\nclass DynamicPopulationEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        population_size = min(20, self.budget // 2)\n        population = np.random.uniform(\n            low=func.bounds.lb, \n            high=func.bounds.ub, \n            size=(population_size, self.dim)\n        )\n        fitness = np.array([func(ind) for ind in population])\n        self.budget -= population_size\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        \n        no_improvement_count = 0  # Counter to track convergence\n\n        while self.budget > 0:\n            parents_idx = np.random.choice(\n                population_size, \n                size=population_size, \n                p=(1 / (fitness + 1e-9)) / (1 / (fitness + 1e-9)).sum()\n            )\n            parents = population[parents_idx]\n            \n            offspring = []\n            for i in range(population_size):\n                parent1, parent2 = parents[i], parents[(i + 1) % population_size]\n                alpha = np.random.uniform(0, 1, self.dim)\n                child = alpha * parent1 + (1 - alpha) * parent2\n                \n                mutation_strength = 0.1 * (func.bounds.ub - func.bounds.lb) * np.std(fitness)\n                mutation = np.random.normal(0, mutation_strength, self.dim)\n                child += mutation\n                child = np.clip(child, func.bounds.lb, func.bounds.ub)\n                offspring.append(child)\n            \n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            self.budget -= population_size\n            \n            combined_population = np.vstack((population, offspring, [best_solution]))\n            combined_fitness = np.hstack((fitness, offspring_fitness, [fitness[best_idx]]))\n            best_individuals_idx = np.argsort(combined_fitness)[:population_size]\n            population = combined_population[best_individuals_idx]\n            fitness = combined_fitness[best_individuals_idx]\n            \n            new_best_idx = np.argmin(fitness)\n            if fitness[new_best_idx] < fitness[best_idx]:\n                best_idx = new_best_idx\n                best_solution = population[best_idx]\n                no_improvement_count = 0  # Reset convergence counter\n            else:\n                no_improvement_count += 1\n\n            if no_improvement_count > 5:  # Restart if no improvement for 5 iterations\n                population = np.random.uniform(\n                    low=func.bounds.lb, \n                    high=func.bounds.ub, \n                    size=(population_size, self.dim)\n                )\n                fitness = np.array([func(ind) for ind in population])\n                self.budget -= population_size\n                no_improvement_count = 0\n\n        return best_solution", "name": "DynamicPopulationEvolution", "description": "Enhance search efficiency by introducing diversity via a restart mechanism when convergence stalls, and adjust mutation strength dynamically based on fitness variance.", "configspace": "", "generation": 4, "fitness": 0.19034896063130582, "feedback": "The algorithm DynamicPopulationEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.190 with standard deviation 0.022. And the mean value of best solutions found was 0.438 (0. is the best) with standard deviation 0.162.", "error": "", "parent_id": "cb4a3ce8-b061-45ce-a330-d8ca797a6f9e", "metadata": {"aucs": [0.18223006288253873, 0.22018747651931025, 0.1686293424920685], "final_y": [0.5174477332373543, 0.21192945620447948, 0.584254686760048]}, "mutation_prompt": null}
{"id": "1435a9ad-5e2d-4e6d-873d-2e25ee67b93c", "solution": "import numpy as np\nimport random\n\nclass DynamicPopulationEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Define population size\n        population_size = min(20, self.budget // 2)\n        # Initialize population within bounds\n        population = np.random.uniform(\n            low=func.bounds.lb, \n            high=func.bounds.ub, \n            size=(population_size, self.dim)\n        )\n        fitness = np.array([func(ind) for ind in population])\n        self.budget -= population_size\n        best_idx = np.argmin(fitness)  # Track best solution\n        best_solution = population[best_idx]\n\n        # Evolution loop\n        while self.budget > 0:\n            # Select parents based on fitness proportional selection\n            parents_idx = np.random.choice(\n                population_size, \n                size=population_size, \n                p=fitness / fitness.sum()\n            )\n            parents = population[parents_idx]\n            \n            # Generate offspring through crossover and mutation\n            offspring = []\n            for i in range(population_size):\n                parent1, parent2 = parents[i], parents[(i + 1) % population_size]\n                \n                # Crossover (blend crossover)\n                alpha = np.random.uniform(0, 1, self.dim)\n                child = alpha * parent1 + (1 - alpha) * parent2\n                \n                # Mutation (adaptive Gaussian mutation)\n                mutation_strength = 0.1 * (func.bounds.ub - func.bounds.lb) * (fitness[best_idx] / fitness.mean())\n                mutation = np.random.normal(0, mutation_strength, self.dim)\n                child += mutation\n                \n                # Ensure child is within bounds\n                child = np.clip(child, func.bounds.lb, func.bounds.ub)\n                offspring.append(child)\n            \n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            self.budget -= population_size\n            \n            # Combine and select the next generation\n            combined_population = np.vstack((population, offspring, [best_solution]))  # Preserve best solution\n            combined_fitness = np.hstack((fitness, offspring_fitness, [fitness[best_idx]]))\n            best_individuals_idx = np.argsort(combined_fitness)[:population_size]\n            population = combined_population[best_individuals_idx]\n            fitness = combined_fitness[best_individuals_idx]\n            \n            # Update best solution\n            best_idx = np.argmin(fitness)\n            best_solution = population[best_idx]\n        \n        # Return the best found solution\n        return best_solution", "name": "DynamicPopulationEvolution", "description": "Introduce a dynamic mutation strength based on the best solution's fitness relative to the population to enhance exploration and convergence.", "configspace": "", "generation": 5, "fitness": 0.2683079435757411, "feedback": "The algorithm DynamicPopulationEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.268 with standard deviation 0.011. And the mean value of best solutions found was 0.041 (0. is the best) with standard deviation 0.018.", "error": "", "parent_id": "cb4a3ce8-b061-45ce-a330-d8ca797a6f9e", "metadata": {"aucs": [0.2758665883780784, 0.2532069289095866, 0.27585031343955824], "final_y": [0.06112787011361208, 0.04494891236423311, 0.017567005402042413]}, "mutation_prompt": null}
{"id": "04928b9d-c56c-419a-aeed-0792bf554f86", "solution": "import numpy as np\nimport random\n\nclass DynamicPopulationEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        population_size = min(20, self.budget // 2)\n        population = np.random.uniform(\n            low=func.bounds.lb, \n            high=func.bounds.ub, \n            size=(population_size, self.dim)\n        )\n        fitness = np.array([func(ind) for ind in population])\n        self.budget -= population_size\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n\n        while self.budget > 0:\n            parents_idx = np.random.choice(\n                population_size, \n                size=population_size, \n                p=fitness / fitness.sum()\n            )\n            parents = population[parents_idx]\n            \n            offspring = []\n            for i in range(population_size):\n                parent1, parent2 = parents[i], parents[(i + 1) % population_size]\n                \n                alpha = np.random.uniform(0, 1, self.dim)\n                child = alpha * parent1 + (1 - alpha) * parent2\n                \n                mutation_strength = 0.1 * (func.bounds.ub - func.bounds.lb) * (fitness[best_idx] / fitness.mean())\n                \n                if np.std(fitness) > 0.05:  # Switch mutation strategy based on fitness variance\n                    mutation = np.random.standard_cauchy(self.dim) * mutation_strength\n                else:\n                    mutation = np.random.normal(0, mutation_strength, self.dim)\n                child += mutation\n                \n                child = np.clip(child, func.bounds.lb, func.bounds.ub)\n                offspring.append(child)\n            \n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            self.budget -= population_size\n            \n            combined_population = np.vstack((population, offspring, [best_solution]))\n            combined_fitness = np.hstack((fitness, offspring_fitness, [fitness[best_idx]]))\n            best_individuals_idx = np.argsort(combined_fitness)[:population_size]\n            population = combined_population[best_individuals_idx]\n            fitness = combined_fitness[best_individuals_idx]\n            \n            best_idx = np.argmin(fitness)\n            best_solution = population[best_idx]\n        \n        return best_solution", "name": "DynamicPopulationEvolution", "description": "Implement a multi-strategy mutation mechanism that alternates between Gaussian and Cauchy mutations based on fitness variance to improve exploration and robustness.", "configspace": "", "generation": 6, "fitness": 0.2672084385465224, "feedback": "The algorithm DynamicPopulationEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.267 with standard deviation 0.043. And the mean value of best solutions found was 0.098 (0. is the best) with standard deviation 0.110.", "error": "", "parent_id": "1435a9ad-5e2d-4e6d-873d-2e25ee67b93c", "metadata": {"aucs": [0.2969827483367229, 0.20653603966516842, 0.29810652763767576], "final_y": [0.036220115308696434, 0.2527224380963262, 0.004354772655302739]}, "mutation_prompt": null}
{"id": "96e8532f-8983-49f9-8fcd-46dbb3f7006b", "solution": "import numpy as np\nimport random\n\nclass DynamicPopulationEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Define population size\n        population_size = min(20, self.budget // 2)\n        # Initialize population within bounds\n        population = np.random.uniform(\n            low=func.bounds.lb, \n            high=func.bounds.ub, \n            size=(population_size, self.dim)\n        )\n        fitness = np.array([func(ind) for ind in population])\n        self.budget -= population_size\n        best_idx = np.argmin(fitness)  # Track best solution\n        best_solution = population[best_idx]\n\n        # Evolution loop\n        while self.budget > 0:\n            # Rank-based fitness scaling\n            ranks = np.argsort(fitness)\n            scaled_fitness = 1.0 / (1.0 + ranks)\n            parents_idx = np.random.choice(\n                population_size, \n                size=population_size,\n                p=scaled_fitness / scaled_fitness.sum()\n            )\n            parents = population[parents_idx]\n            \n            # Generate offspring through crossover and mutation\n            offspring = []\n            for i in range(population_size):\n                parent1, parent2 = parents[i], parents[(i + 1) % population_size]\n                \n                # Crossover (blend crossover)\n                alpha = np.random.uniform(0, 1, self.dim)\n                child = alpha * parent1 + (1 - alpha) * parent2\n                \n                # Mutation (adaptive Gaussian mutation)\n                mutation_strength = 0.1 * (func.bounds.ub - func.bounds.lb) * (fitness[best_idx] / fitness.mean())\n                mutation = np.random.normal(0, mutation_strength, self.dim)\n                child += mutation\n                \n                # Ensure child is within bounds\n                child = np.clip(child, func.bounds.lb, func.bounds.ub)\n                offspring.append(child)\n            \n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            self.budget -= population_size\n            \n            # Combine and select the next generation\n            combined_population = np.vstack((population, offspring, [best_solution]))  # Preserve best solution\n            combined_fitness = np.hstack((fitness, offspring_fitness, [fitness[best_idx]]))\n            best_individuals_idx = np.argsort(combined_fitness)[:population_size]\n            population = combined_population[best_individuals_idx]\n            fitness = combined_fitness[best_individuals_idx]\n            \n            # Update best solution\n            best_idx = np.argmin(fitness)\n            best_solution = population[best_idx]\n        \n        # Return the best found solution\n        return best_solution", "name": "DynamicPopulationEvolution", "description": "Enhance selection by incorporating a rank-based fitness scaling to improve diversity and maintain exploration.", "configspace": "", "generation": 7, "fitness": 0.272084140043332, "feedback": "The algorithm DynamicPopulationEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.272 with standard deviation 0.015. And the mean value of best solutions found was 0.067 (0. is the best) with standard deviation 0.028.", "error": "", "parent_id": "1435a9ad-5e2d-4e6d-873d-2e25ee67b93c", "metadata": {"aucs": [0.28539091581927345, 0.25074832400012903, 0.2801131803105935], "final_y": [0.044059701488059454, 0.10683482846498608, 0.05052713042325002]}, "mutation_prompt": null}
{"id": "e98dcfb8-8cb7-4f69-ad62-1080d1e93176", "solution": "import numpy as np\nimport random\n\nclass DynamicPopulationEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Define population size\n        population_size = min(20, self.budget // 2)\n        # Initialize population within bounds\n        population = np.random.uniform(\n            low=func.bounds.lb, \n            high=func.bounds.ub, \n            size=(population_size, self.dim)\n        )\n        fitness = np.array([func(ind) for ind in population])\n        self.budget -= population_size\n        best_idx = np.argmin(fitness)  # Track best solution\n        best_solution = population[best_idx]\n\n        # Evolution loop\n        while self.budget > 0:\n            # Rank-based fitness scaling\n            ranks = np.argsort(fitness)\n            scaled_fitness = 1.0 / (1.0 + ranks)\n            parents_idx = np.random.choice(\n                population_size, \n                size=population_size,\n                p=scaled_fitness / scaled_fitness.sum()\n            )\n            parents = population[parents_idx]\n            \n            # Generate offspring through crossover and mutation\n            offspring = []\n            for i in range(population_size):\n                parent1, parent2 = parents[i], parents[(i + 1) % population_size]\n                \n                # Crossover (blend crossover)\n                alpha = np.random.uniform(0, 1, self.dim)\n                child = alpha * parent1 + (1 - alpha) * parent2\n                \n                # Mutation (adaptive Gaussian mutation)\n                mutation_strength = 0.1 * (func.bounds.ub - func.bounds.lb) * (fitness[best_idx] / fitness.mean())\n                mutation_strength *= np.random.uniform(0.9, 1.1)  # Adaptive mutation scaling\n                mutation = np.random.normal(0, mutation_strength, self.dim)\n                child += mutation\n                \n                # Ensure child is within bounds\n                child = np.clip(child, func.bounds.lb, func.bounds.ub)\n                offspring.append(child)\n            \n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            self.budget -= population_size\n            \n            # Combine and select the next generation\n            combined_population = np.vstack((population, offspring, [best_solution]))  # Preserve best solution\n            combined_fitness = np.hstack((fitness, offspring_fitness, [fitness[best_idx]]))\n            best_individuals_idx = np.argsort(combined_fitness)[:population_size]\n            population = combined_population[best_individuals_idx]\n            fitness = combined_fitness[best_individuals_idx]\n            \n            # Update best solution\n            best_idx = np.argmin(fitness)\n            best_solution = population[best_idx]\n        \n        # Return the best found solution\n        return best_solution", "name": "DynamicPopulationEvolution", "description": "Introduce elitism and adaptive mutation scaling to enhance exploitation and achieve better convergence.", "configspace": "", "generation": 8, "fitness": 0.25133620969033194, "feedback": "The algorithm DynamicPopulationEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.251 with standard deviation 0.013. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.032.", "error": "", "parent_id": "96e8532f-8983-49f9-8fcd-46dbb3f7006b", "metadata": {"aucs": [0.24670741971772425, 0.23866652457223658, 0.268634684781035], "final_y": [0.13614526796292004, 0.13408332721514155, 0.06785271885413777]}, "mutation_prompt": null}
{"id": "201c3260-ba4a-4307-9637-ff9308f30de1", "solution": "import numpy as np\nimport random\n\nclass DynamicPopulationEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Define population size\n        population_size = min(20, self.budget // 2)\n        # Initialize population within bounds\n        population = np.random.uniform(\n            low=func.bounds.lb, \n            high=func.bounds.ub, \n            size=(population_size, self.dim)\n        )\n        fitness = np.array([func(ind) for ind in population])\n        self.budget -= population_size\n        best_idx = np.argmin(fitness)  # Track best solution\n        best_solution = population[best_idx]\n\n        # Evolution loop\n        while self.budget > 0:\n            # Rank-based fitness scaling\n            ranks = np.argsort(fitness)\n            scaled_fitness = 1.0 / (1.0 + ranks)\n            parents_idx = np.random.choice(\n                population_size, \n                size=population_size,\n                p=scaled_fitness / scaled_fitness.sum()\n            )\n            parents = population[parents_idx]\n            \n            # Generate offspring through crossover and mutation\n            offspring = []\n            for i in range(population_size):\n                parent1, parent2 = parents[i], parents[(i + 1) % population_size]\n                \n                # Crossover (blend crossover)\n                alpha = np.random.uniform(0, 1, self.dim)\n                child = alpha * parent1 + (1 - alpha) * parent2\n                \n                # Mutation (adaptive Gaussian mutation)\n                mutation_strength = 0.1 * (func.bounds.ub - func.bounds.lb) * (fitness[best_idx] / fitness.mean()) * (self.budget / (self.budget + population_size))\n                mutation = np.random.normal(0, mutation_strength, self.dim)\n                child += mutation\n                \n                # Ensure child is within bounds\n                child = np.clip(child, func.bounds.lb, func.bounds.ub)\n                offspring.append(child)\n            \n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            self.budget -= population_size\n            \n            # Combine and select the next generation\n            combined_population = np.vstack((population, offspring, [best_solution]))  # Preserve best solution\n            combined_fitness = np.hstack((fitness, offspring_fitness, [fitness[best_idx]]))\n            best_individuals_idx = np.argsort(combined_fitness)[:population_size]\n            population = combined_population[best_individuals_idx]\n            fitness = combined_fitness[best_individuals_idx]\n            \n            # Update best solution\n            best_idx = np.argmin(fitness)\n            best_solution = population[best_idx]\n        \n        # Return the best found solution\n        return best_solution", "name": "DynamicPopulationEvolution", "description": "Introduce a more dynamic mutation strength by incorporating the current budget percentage to balance exploration and exploitation dynamically.", "configspace": "", "generation": 9, "fitness": 0.2686239750166652, "feedback": "The algorithm DynamicPopulationEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.269 with standard deviation 0.027. And the mean value of best solutions found was 0.090 (0. is the best) with standard deviation 0.050.", "error": "", "parent_id": "96e8532f-8983-49f9-8fcd-46dbb3f7006b", "metadata": {"aucs": [0.25247905318310004, 0.3063878806002347, 0.24700499126666076], "final_y": [0.13173201549856497, 0.019265611051632065, 0.1196742141959678]}, "mutation_prompt": null}
{"id": "71251e46-8fdd-4c8a-818e-b10e3989cac8", "solution": "import numpy as np\nimport random\n\nclass DynamicPopulationEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Define population size\n        population_size = min(20, self.budget // 2)\n        # Initialize population within bounds\n        population = np.random.uniform(\n            low=func.bounds.lb, \n            high=func.bounds.ub, \n            size=(population_size, self.dim)\n        )\n        fitness = np.array([func(ind) for ind in population])\n        self.budget -= population_size\n        best_idx = np.argmin(fitness)  # Track best solution\n        best_solution = population[best_idx]\n\n        # Evolution loop\n        while self.budget > 0:\n            # Rank-based fitness scaling\n            ranks = np.argsort(fitness)\n            scaled_fitness = 1.0 / (1.0 + ranks)\n            parents_idx = np.random.choice(\n                population_size, \n                size=population_size,\n                p=scaled_fitness / scaled_fitness.sum()\n            )\n            parents = population[parents_idx]\n            \n            # Generate offspring through crossover and mutation\n            offspring = []\n            adaptive_mutation_prob = 0.1 + 0.4 * (fitness[best_idx] / fitness.mean())  # Adaptive mutation probability\n            for i in range(population_size):\n                parent1, parent2 = parents[i], parents[(i + 1) % population_size]\n                \n                # Crossover (blend crossover)\n                alpha = np.random.uniform(0, 1, self.dim)\n                child = alpha * parent1 + (1 - alpha) * parent2\n                \n                # Mutation (adaptive Gaussian mutation)\n                mutation_strength = 0.1 * (func.bounds.ub - func.bounds.lb) * (fitness[best_idx] / fitness.mean())\n                mutation = np.random.normal(0, mutation_strength, self.dim)\n                if np.random.rand() < adaptive_mutation_prob:\n                    child += mutation\n                \n                # Ensure child is within bounds\n                child = np.clip(child, func.bounds.lb, func.bounds.ub)\n                offspring.append(child)\n            \n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            self.budget -= population_size\n            \n            # Combine and select the next generation\n            combined_population = np.vstack((population, offspring, [best_solution]))  # Preserve best solution\n            combined_fitness = np.hstack((fitness, offspring_fitness, [fitness[best_idx]]))\n            best_individuals_idx = np.argsort(combined_fitness)[:population_size]\n            population = combined_population[best_individuals_idx]\n            fitness = combined_fitness[best_individuals_idx]\n            \n            # Update best solution\n            best_idx = np.argmin(fitness)\n            best_solution = population[best_idx]\n        \n        # Return the best found solution\n        return best_solution", "name": "DynamicPopulationEvolution", "description": "Introduces an adaptive mutation probability in offspring generation to enhance exploration and convergence speed.", "configspace": "", "generation": 10, "fitness": 0.34244446605676654, "feedback": "The algorithm DynamicPopulationEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.342 with standard deviation 0.032. And the mean value of best solutions found was 0.007 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "96e8532f-8983-49f9-8fcd-46dbb3f7006b", "metadata": {"aucs": [0.37844372083969935, 0.30005826159664006, 0.34883141573396026], "final_y": [0.0019814248757511334, 0.01571056834596914, 0.003829127220022387]}, "mutation_prompt": null}
{"id": "55fc9074-2140-4b23-b88d-9dc433b39994", "solution": "import numpy as np\nimport random\n\nclass DynamicPopulationEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Define population size\n        population_size = min(20, self.budget // 2)\n        # Initialize population within bounds\n        population = np.random.uniform(\n            low=func.bounds.lb, \n            high=func.bounds.ub, \n            size=(population_size, self.dim)\n        )\n        fitness = np.array([func(ind) for ind in population])\n        self.budget -= population_size\n        best_idx = np.argmin(fitness)  # Track best solution\n        best_solution = population[best_idx]\n\n        # Evolution loop\n        while self.budget > 0:\n            # Rank-based fitness scaling\n            ranks = np.argsort(fitness)\n            scaled_fitness = 1.0 / (1.0 + ranks)\n            parents_idx = np.random.choice(\n                population_size, \n                size=population_size,\n                p=scaled_fitness / scaled_fitness.sum()\n            )\n            parents = population[parents_idx]\n            \n            # Generate offspring through crossover and mutation\n            offspring = []\n            adaptive_mutation_prob = 0.1 + 0.4 * (fitness[best_idx] / fitness.mean())  # Adaptive mutation probability\n            for i in range(population_size):\n                parent1, parent2 = parents[i], parents[(i + 1) % population_size]\n                \n                # Crossover (blend crossover)\n                alpha = np.random.uniform(0, 1, self.dim)\n                child = alpha * parent1 + (1 - alpha) * parent2\n                \n                # Mutation (adaptive Gaussian mutation)\n                mutation_strength = 0.1 * (func.bounds.ub - func.bounds.lb) * (fitness.std() / fitness.mean())  # Changed line\n                mutation = np.random.normal(0, mutation_strength, self.dim)\n                if np.random.rand() < adaptive_mutation_prob:\n                    child += mutation\n                \n                # Ensure child is within bounds\n                child = np.clip(child, func.bounds.lb, func.bounds.ub)\n                offspring.append(child)\n            \n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            self.budget -= population_size\n            \n            # Combine and select the next generation\n            combined_population = np.vstack((population, offspring, [best_solution]))  # Preserve best solution\n            combined_fitness = np.hstack((fitness, offspring_fitness, [fitness[best_idx]]))\n            best_individuals_idx = np.argsort(combined_fitness)[:population_size]\n            population = combined_population[best_individuals_idx]\n            fitness = combined_fitness[best_individuals_idx]\n            \n            # Update best solution\n            best_idx = np.argmin(fitness)\n            best_solution = population[best_idx]\n        \n        # Return the best found solution\n        return best_solution", "name": "DynamicPopulationEvolution", "description": "Introduces a dynamic mutation strength based on the fitness variance to enhance exploration and convergence.", "configspace": "", "generation": 11, "fitness": 0.33927807559094, "feedback": "The algorithm DynamicPopulationEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.339 with standard deviation 0.011. And the mean value of best solutions found was 0.001 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "71251e46-8fdd-4c8a-818e-b10e3989cac8", "metadata": {"aucs": [0.35374677151206124, 0.3269005625480156, 0.33718689271274316], "final_y": [0.0005014602625626267, 0.0003639658006434595, 0.002046504848259306]}, "mutation_prompt": null}
{"id": "b46d405d-ecab-4731-ae53-3e519f53675e", "solution": "import numpy as np\nimport random\n\nclass DynamicPopulationEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Define population size\n        population_size = min(20, self.budget // 2)\n        # Initialize population within bounds\n        population = np.random.uniform(\n            low=func.bounds.lb, \n            high=func.bounds.ub, \n            size=(population_size, self.dim)\n        )\n        fitness = np.array([func(ind) for ind in population])\n        self.budget -= population_size\n        best_idx = np.argmin(fitness)  # Track best solution\n        best_solution = population[best_idx]\n\n        # Evolution loop\n        while self.budget > 0:\n            # Rank-based fitness scaling\n            ranks = np.argsort(fitness)\n            scaled_fitness = 1.0 / (1.0 + ranks)\n            parents_idx = np.random.choice(\n                population_size, \n                size=population_size,\n                p=scaled_fitness / scaled_fitness.sum()\n            )\n            parents = population[parents_idx]\n            \n            # Generate offspring through crossover and mutation\n            offspring = []\n            adaptive_mutation_prob = 0.1 + 0.4 * (fitness[best_idx] / fitness.mean())  # Adaptive mutation probability\n            for i in range(population_size):\n                parent1, parent2 = parents[i], parents[(i + 1) % population_size]\n                \n                # Crossover (blend crossover)\n                alpha = np.random.uniform(0, 1, self.dim)\n                child = alpha * parent1 + (1 - alpha) * parent2\n                \n                # Mutation (adaptive Gaussian mutation)\n                mutation_strength = 0.1 * (func.bounds.ub - func.bounds.lb) * (fitness[best_idx] / fitness.mean())\n                mutation = np.random.normal(0, mutation_strength, self.dim)\n                if np.random.rand() < adaptive_mutation_prob:\n                    child += mutation\n                \n                # Ensure child is within bounds\n                child = np.clip(child, func.bounds.lb, func.bounds.ub)\n                offspring.append(child)\n            \n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            self.budget -= population_size\n            \n            # Combine and select the next generation\n            combined_population = np.vstack((population, offspring, [best_solution]))  # Preserve best solution\n            combined_fitness = np.hstack((fitness, offspring_fitness, [fitness[best_idx]]))\n            best_individuals_idx = np.argsort(combined_fitness)[:population_size - 1]  # Preserve top two solutions\n            population = combined_population[best_individuals_idx]\n            fitness = combined_fitness[best_individuals_idx]\n            \n            # Update best solution\n            best_idx = np.argmin(fitness)\n            best_solution = population[best_idx]\n        \n        # Return the best found solution\n        return best_solution", "name": "DynamicPopulationEvolution", "description": "Introduces elitism by always preserving the top two solutions for improved solution quality and convergence reliability.", "configspace": "", "generation": 12, "fitness": -Infinity, "feedback": "An exception occurred: ValueError(\"'a' and 'p' must have same size\").", "error": "ValueError(\"'a' and 'p' must have same size\")", "parent_id": "71251e46-8fdd-4c8a-818e-b10e3989cac8", "metadata": {}, "mutation_prompt": null}
{"id": "2ccad727-5250-4135-ba31-34b300e3c2ec", "solution": "import numpy as np\nimport random\n\nclass DynamicPopulationEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        population_size = min(20, self.budget // 2)\n        population = np.random.uniform(\n            low=func.bounds.lb, \n            high=func.bounds.ub, \n            size=(population_size, self.dim)\n        )\n        fitness = np.array([func(ind) for ind in population])\n        self.budget -= population_size\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n\n        while self.budget > 0:\n            ranks = np.argsort(fitness)\n            scaled_fitness = 1.0 / (1.0 + ranks)\n            parents_idx = np.random.choice(\n                population_size, \n                size=population_size,\n                p=scaled_fitness / scaled_fitness.sum()\n            )\n            parents = population[parents_idx]\n            \n            offspring = []\n            adaptive_mutation_prob = 0.1 + 0.4 * (fitness[best_idx] / fitness.mean())\n            for i in range(population_size):\n                parent1, parent2 = parents[i], parents[(i + 1) % population_size]\n                \n                alpha = np.random.uniform(0, 1, self.dim)\n                child = alpha * parent1 + (1 - alpha) * parent2\n\n                mutation_strength = 0.1 * (func.bounds.ub - func.bounds.lb) * (fitness[best_idx] / fitness.mean())\n                mutation = np.random.normal(0, mutation_strength, self.dim)\n                levy_flight = np.random.standard_cauchy(self.dim)  # Levy flight modification\n                if np.random.rand() < adaptive_mutation_prob:\n                    child += mutation + levy_flight  # Incorporate Levy flight\n                \n                child = np.clip(child, func.bounds.lb, func.bounds.ub)\n                offspring.append(child)\n            \n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            self.budget -= population_size\n            \n            combined_population = np.vstack((population, offspring, [best_solution]))\n            combined_fitness = np.hstack((fitness, offspring_fitness, [fitness[best_idx]]))\n            best_individuals_idx = np.argsort(combined_fitness)[:population_size]\n            population = combined_population[best_individuals_idx]\n            fitness = combined_fitness[best_individuals_idx]\n            \n            best_idx = np.argmin(fitness)\n            best_solution = population[best_idx]\n        \n        return best_solution", "name": "DynamicPopulationEvolution", "description": "Enhances exploration by introducing a random shift using Levy flights in offspring mutation.", "configspace": "", "generation": 13, "fitness": 0.2684856279246937, "feedback": "The algorithm DynamicPopulationEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.268 with standard deviation 0.086. And the mean value of best solutions found was 0.203 (0. is the best) with standard deviation 0.163.", "error": "", "parent_id": "71251e46-8fdd-4c8a-818e-b10e3989cac8", "metadata": {"aucs": [0.20448298906530205, 0.3899723388850169, 0.21100155582376212], "final_y": [0.40337537317320843, 0.004339444887254424, 0.20061091943226061]}, "mutation_prompt": null}
{"id": "91e782c7-84ad-40c8-a750-93358a4e3f84", "solution": "import numpy as np\nimport random\n\nclass DynamicPopulationEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        population_size = min(20, self.budget // 2)\n        population = np.random.uniform(\n            low=func.bounds.lb, \n            high=func.bounds.ub, \n            size=(population_size, self.dim)\n        )\n        fitness = np.array([func(ind) for ind in population])\n        self.budget -= population_size\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        while self.budget > 0:\n            ranks = np.argsort(fitness)\n            scaled_fitness = 1.0 / (1.0 + ranks)\n            parents_idx = np.random.choice(\n                population_size, \n                size=population_size,\n                p=scaled_fitness / scaled_fitness.sum()\n            )\n            parents = population[parents_idx]\n            offspring = []\n            adaptive_mutation_prob = 0.15 + 0.35 * (fitness[best_idx] / fitness.mean())  # Adjusted adaptive probability\n            for i in range(population_size):\n                parent1, parent2 = parents[i], parents[(i + 1) % population_size]\n                alpha = np.random.uniform(0, 1, self.dim)\n                child = alpha * parent1 + (1 - alpha) * parent2\n                mutation_strength = 0.1 * (func.bounds.ub - func.bounds.lb) * (fitness[best_idx] / fitness.mean())\n                mutation = np.random.normal(0, mutation_strength, self.dim)\n                if np.random.rand() < adaptive_mutation_prob:\n                    child += mutation\n                # Diversity-enhancing mutation\n                diversity_strength = 0.05 * (func.bounds.ub - func.bounds.lb)\n                diversity_mutation = np.random.uniform(-diversity_strength, diversity_strength, self.dim)\n                if np.random.rand() < 0.1:\n                    child += diversity_mutation\n\n                child = np.clip(child, func.bounds.lb, func.bounds.ub)\n                offspring.append(child)\n            \n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            self.budget -= population_size\n            \n            combined_population = np.vstack((population, offspring, [best_solution]))\n            combined_fitness = np.hstack((fitness, offspring_fitness, [fitness[best_idx]]))\n            best_individuals_idx = np.argsort(combined_fitness)[:population_size]\n            population = combined_population[best_individuals_idx]\n            fitness = combined_fitness[best_individuals_idx]\n            best_idx = np.argmin(fitness)\n            best_solution = population[best_idx]\n        \n        return best_solution", "name": "DynamicPopulationEvolution", "description": "Enhances convergence by introducing a diversity-enhancing mutation and elitist selection strategy.", "configspace": "", "generation": 14, "fitness": 0.27183440729711233, "feedback": "The algorithm DynamicPopulationEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.272 with standard deviation 0.005. And the mean value of best solutions found was 0.045 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "71251e46-8fdd-4c8a-818e-b10e3989cac8", "metadata": {"aucs": [0.2657661971666003, 0.27806666538667024, 0.2716703593380664], "final_y": [0.03632555516094848, 0.06287616348470793, 0.035942680029765396]}, "mutation_prompt": null}
{"id": "10e9f0e0-1a4c-4307-9e9e-8b2b39c7fc18", "solution": "import numpy as np\nimport random\n\nclass DynamicPopulationEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Define population size\n        population_size = min(20, self.budget // 2)\n        # Initialize population within bounds\n        population = np.random.uniform(\n            low=func.bounds.lb, \n            high=func.bounds.ub, \n            size=(population_size, self.dim)\n        )\n        fitness = np.array([func(ind) for ind in population])\n        self.budget -= population_size\n        best_idx = np.argmin(fitness)  # Track best solution\n        best_solution = population[best_idx]\n\n        # Evolution loop\n        while self.budget > 0:\n            # Rank-based fitness scaling\n            ranks = np.argsort(fitness)\n            scaled_fitness = 1.0 / (1.0 + ranks)\n            parents_idx = np.random.choice(\n                population_size, \n                size=population_size,\n                p=scaled_fitness / scaled_fitness.sum()\n            )\n            parents = population[parents_idx]\n            \n            # Generate offspring through crossover and mutation\n            offspring = []\n            adaptive_mutation_prob = 0.1 + 0.4 * (fitness[best_idx] / fitness.mean())  # Adaptive mutation probability\n            for i in range(population_size):\n                parent1, parent2 = parents[i], parents[(i + 1) % population_size]\n                \n                # Crossover (blend crossover)\n                alpha = np.random.uniform(0, 1, self.dim)\n                child = alpha * parent1 + (1 - alpha) * parent2\n                \n                # Mutation (adaptive Gaussian mutation)\n                mutation_strength = 0.12 * (func.bounds.ub - func.bounds.lb) * (fitness[best_idx] / fitness.mean())  # Increased mutation strength\n                mutation = np.random.normal(0, mutation_strength, self.dim)\n                if np.random.rand() < adaptive_mutation_prob:\n                    child += mutation\n                \n                # Ensure child is within bounds\n                child = np.clip(child, func.bounds.lb, func.bounds.ub)\n                offspring.append(child)\n            \n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            self.budget -= population_size\n            \n            # Combine and select the next generation\n            combined_population = np.vstack((population, offspring, [best_solution]))  # Preserve best solution\n            combined_fitness = np.hstack((fitness, offspring_fitness, [fitness[best_idx]]))\n            best_individuals_idx = np.argsort(combined_fitness)[:population_size]\n            population = combined_population[best_individuals_idx]\n            fitness = combined_fitness[best_individuals_idx]\n            \n            # Update best solution\n            best_idx = np.argmin(fitness)\n            best_solution = population[best_idx]\n        \n        # Return the best found solution\n        return best_solution", "name": "DynamicPopulationEvolution", "description": "Implements a small modification in the mutation strategy to improve solution diversity by slightly increasing mutation strength.", "configspace": "", "generation": 15, "fitness": 0.2274398496419486, "feedback": "The algorithm DynamicPopulationEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.227 with standard deviation 0.022. And the mean value of best solutions found was 0.150 (0. is the best) with standard deviation 0.070.", "error": "", "parent_id": "71251e46-8fdd-4c8a-818e-b10e3989cac8", "metadata": {"aucs": [0.2580134828391084, 0.2084701478465696, 0.2158359182401678], "final_y": [0.12212492125080855, 0.08181327478836019, 0.24720350188604312]}, "mutation_prompt": null}
{"id": "5050ab5c-e93f-4e44-b75f-118389e8abf3", "solution": "import numpy as np\nimport random\n\nclass DynamicPopulationEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Define population size\n        population_size = min(20, self.budget // 2)\n        # Initialize population within bounds\n        population = np.random.uniform(\n            low=func.bounds.lb, \n            high=func.bounds.ub, \n            size=(population_size, self.dim)\n        )\n        fitness = np.array([func(ind) for ind in population])\n        self.budget -= population_size\n        best_idx = np.argmin(fitness)  # Track best solution\n        best_solution = population[best_idx]\n\n        # Evolution loop\n        while self.budget > 0:\n            # Rank-based fitness scaling\n            ranks = np.argsort(fitness)\n            scaled_fitness = 1.0 / (1.0 + ranks)\n            parents_idx = np.random.choice(\n                population_size, \n                size=population_size,\n                p=scaled_fitness / scaled_fitness.sum()\n            )\n            parents = population[parents_idx]\n            \n            # Generate offspring through crossover and mutation\n            offspring = []\n            adaptive_mutation_prob = 0.1 + 0.4 * (fitness[best_idx] / fitness.mean())  # Adaptive mutation probability\n            for i in range(population_size):\n                parent1, parent2 = parents[i], parents[(i + 1) % population_size]\n                \n                # Crossover (blend crossover)\n                alpha = np.random.uniform(0, 1, self.dim)\n                child = alpha * parent1 + (1 - alpha) * parent2\n                \n                # Mutation (adaptive Gaussian mutation)\n                mutation_strength = 0.1 * (func.bounds.ub - func.bounds.lb) * np.std(fitness)  # Adjusted line\n                mutation = np.random.normal(0, mutation_strength, self.dim)\n                if np.random.rand() < adaptive_mutation_prob:\n                    child += mutation\n                \n                # Ensure child is within bounds\n                child = np.clip(child, func.bounds.lb, func.bounds.ub)\n                offspring.append(child)\n            \n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            self.budget -= population_size\n            \n            # Combine and select the next generation\n            combined_population = np.vstack((population, offspring, [best_solution]))  # Preserve best solution\n            combined_fitness = np.hstack((fitness, offspring_fitness, [fitness[best_idx]]))\n            best_individuals_idx = np.argsort(combined_fitness)[:population_size]\n            population = combined_population[best_individuals_idx]\n            fitness = combined_fitness[best_individuals_idx]\n            \n            # Update best solution\n            best_idx = np.argmin(fitness)\n            best_solution = population[best_idx]\n        \n        # Return the best found solution\n        return best_solution", "name": "DynamicPopulationEvolution", "description": "Adjusts mutation strength dynamically based on the current generation's fitness variability to better explore the search space.", "configspace": "", "generation": 16, "fitness": 0.25934616116233355, "feedback": "The algorithm DynamicPopulationEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.259 with standard deviation 0.063. And the mean value of best solutions found was 0.153 (0. is the best) with standard deviation 0.150.", "error": "", "parent_id": "71251e46-8fdd-4c8a-818e-b10e3989cac8", "metadata": {"aucs": [0.34190621894463336, 0.18800969211780705, 0.24812257242456026], "final_y": [0.004998960598385526, 0.359274603682764, 0.09430272908872105]}, "mutation_prompt": null}
{"id": "669f8ea2-7910-401e-b13d-9bf9efe155c7", "solution": "import numpy as np\nimport random\n\nclass DynamicPopulationEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Define population size\n        population_size = min(20, self.budget // 2)\n        # Initialize population within bounds\n        population = np.random.uniform(\n            low=func.bounds.lb, \n            high=func.bounds.ub, \n            size=(population_size, self.dim)\n        )\n        fitness = np.array([func(ind) for ind in population])\n        self.budget -= population_size\n        best_idx = np.argmin(fitness)  # Track best solution\n        best_solution = population[best_idx]\n\n        # Evolution loop\n        while self.budget > 0:\n            # Rank-based fitness scaling\n            ranks = np.argsort(fitness)\n            scaled_fitness = 1.0 / (1.0 + ranks)\n            parents_idx = np.random.choice(\n                population_size, \n                size=population_size,\n                p=scaled_fitness / scaled_fitness.sum()\n            )\n            parents = population[parents_idx]\n            \n            # Generate offspring through crossover and mutation\n            offspring = []\n            adaptive_mutation_prob = 0.1 + 0.4 * (fitness[best_idx] / fitness.mean())  # Adaptive mutation probability\n            for i in range(population_size):\n                parent1, parent2 = parents[i], parents[(i + 1) % population_size]\n                \n                # Crossover (blend crossover)\n                alpha = np.random.uniform(0.3, 0.7, self.dim)  # Adjusted blend factor\n                child = alpha * parent1 + (1 - alpha) * parent2\n                \n                # Mutation (adaptive Gaussian mutation)\n                mutation_strength = 0.1 * (func.bounds.ub - func.bounds.lb) * (fitness[best_idx] / fitness.mean())\n                mutation = np.random.normal(0, mutation_strength, self.dim)\n                if np.random.rand() < adaptive_mutation_prob:\n                    child += mutation\n                \n                # Ensure child is within bounds\n                child = np.clip(child, func.bounds.lb, func.bounds.ub)\n                offspring.append(child)\n            \n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            self.budget -= population_size\n            \n            # Combine and select the next generation\n            combined_population = np.vstack((population, offspring, [best_solution]))  # Preserve best solution\n            combined_fitness = np.hstack((fitness, offspring_fitness, [fitness[best_idx]]))\n            best_individuals_idx = np.argsort(combined_fitness)[:population_size]\n            population = combined_population[best_individuals_idx]\n            fitness = combined_fitness[best_individuals_idx]\n            \n            # Update best solution\n            best_idx = np.argmin(fitness)\n            best_solution = population[best_idx]\n        \n        # Return the best found solution\n        return best_solution", "name": "DynamicPopulationEvolution", "description": "Adjust crossover mechanism by modifying the blend factor for improved exploration.", "configspace": "", "generation": 17, "fitness": 0.26255652558380416, "feedback": "The algorithm DynamicPopulationEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.263 with standard deviation 0.046. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.093.", "error": "", "parent_id": "71251e46-8fdd-4c8a-818e-b10e3989cac8", "metadata": {"aucs": [0.23829196506902728, 0.2224724901671461, 0.3269051215152391], "final_y": [0.13628881464489423, 0.2344545904790562, 0.006718134935442481]}, "mutation_prompt": null}
{"id": "eb9d4682-cc3c-478f-8fcb-11bc13536475", "solution": "import numpy as np\nimport random\n\nclass DynamicPopulationEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Define initial population size\n        population_size = min(20, self.budget // 2)\n        # Initialize population within bounds\n        population = np.random.uniform(\n            low=func.bounds.lb, \n            high=func.bounds.ub, \n            size=(population_size, self.dim)\n        )\n        fitness = np.array([func(ind) for ind in population])\n        self.budget -= population_size\n        best_idx = np.argmin(fitness)  # Track best solution\n        best_solution = population[best_idx]\n\n        # Evolution loop\n        while self.budget > 0:\n            # Rank-based fitness scaling\n            ranks = np.argsort(fitness)\n            scaled_fitness = 1.0 / (1.0 + ranks)\n            parents_idx = np.random.choice(\n                population_size, \n                size=population_size,\n                p=scaled_fitness / scaled_fitness.sum()\n            )\n            parents = population[parents_idx]\n            \n            # Generate offspring through crossover and mutation\n            offspring = []\n            adaptive_mutation_prob = 0.1 + 0.4 * (fitness[best_idx] / fitness.mean())  # Adaptive mutation probability\n            for i in range(population_size):\n                parent1, parent2 = parents[i], parents[(i + 1) % population_size]\n                \n                # Crossover (blend crossover)\n                alpha = np.random.uniform(0, 1, self.dim)\n                child = alpha * parent1 + (1 - alpha) * parent2\n                \n                # Mutation (adaptive Gaussian mutation)\n                mutation_strength = 0.1 * (func.bounds.ub - func.bounds.lb) * (fitness[best_idx] / fitness.mean())\n                mutation = np.random.normal(0, mutation_strength, self.dim)\n                if np.random.rand() < adaptive_mutation_prob:\n                    child += mutation\n                \n                # Ensure child is within bounds\n                child = np.clip(child, func.bounds.lb, func.bounds.ub)\n                offspring.append(child)\n            \n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            self.budget -= population_size\n            \n            # Combine and select the next generation\n            combined_population = np.vstack((population, offspring, [best_solution]))  # Preserve best solution\n            combined_fitness = np.hstack((fitness, offspring_fitness, [fitness[best_idx]]))\n            best_individuals_idx = np.argsort(combined_fitness)[:population_size]\n            population = combined_population[best_individuals_idx]\n            fitness = combined_fitness[best_individuals_idx]\n            \n            # Adjust population size based on fitness diversity\n            population_size = max(10, min(30, int(np.std(fitness) * 100)))\n\n            # Update best solution\n            best_idx = np.argmin(fitness)\n            best_solution = population[best_idx]\n        \n        # Return the best found solution\n        return best_solution", "name": "DynamicPopulationEvolution", "description": "Introduces a dynamic population size based on fitness diversity to further improve exploration and convergence.", "configspace": "", "generation": 18, "fitness": -Infinity, "feedback": "An exception occurred: ValueError(\"'a' and 'p' must have same size\").", "error": "ValueError(\"'a' and 'p' must have same size\")", "parent_id": "71251e46-8fdd-4c8a-818e-b10e3989cac8", "metadata": {}, "mutation_prompt": null}
{"id": "7946baa7-cee6-4d46-b578-dd5846b45a09", "solution": "import numpy as np\nimport random\n\nclass DynamicPopulationEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Define initial population size\n        population_size = min(20, self.budget // 2)\n        # Initialize population within bounds\n        population = np.random.uniform(\n            low=func.bounds.lb, \n            high=func.bounds.ub, \n            size=(population_size, self.dim)\n        )\n        fitness = np.array([func(ind) for ind in population])\n        self.budget -= population_size\n        best_idx = np.argmin(fitness)  # Track best solution\n        best_solution = population[best_idx]\n\n        # Evolution loop\n        while self.budget > 0:\n            # Rank-based fitness scaling\n            ranks = np.argsort(fitness)\n            scaled_fitness = 1.0 / (1.0 + ranks)\n            parents_idx = np.random.choice(\n                population_size, \n                size=population_size,\n                p=scaled_fitness / scaled_fitness.sum()\n            )\n            parents = population[parents_idx]\n            \n            # Dynamic population size adjustment based on fitness variance\n            variance = np.var(fitness)\n            population_size = max(10, int(variance * 10))  # Adjust population size\n            \n            # Generate offspring through crossover and mutation\n            offspring = []\n            adaptive_mutation_prob = 0.1 + 0.4 * (fitness[best_idx] / fitness.mean())  # Adaptive mutation probability\n            for i in range(population_size):\n                parent1, parent2 = parents[i], parents[(i + 1) % population_size]\n                \n                # Crossover (blend crossover)\n                alpha = np.random.uniform(0, 1, self.dim)\n                child = alpha * parent1 + (1 - alpha) * parent2\n                \n                # Mutation (adaptive Gaussian mutation)\n                mutation_strength = 0.1 * (func.bounds.ub - func.bounds.lb) * (fitness[best_idx] / fitness.mean())\n                mutation = np.random.normal(0, mutation_strength, self.dim)\n                if np.random.rand() < adaptive_mutation_prob:\n                    child += mutation\n                \n                # Ensure child is within bounds\n                child = np.clip(child, func.bounds.lb, func.bounds.ub)\n                offspring.append(child)\n            \n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            self.budget -= population_size\n            \n            # Combine and select the next generation\n            combined_population = np.vstack((population, offspring, [best_solution]))  # Preserve best solution\n            combined_fitness = np.hstack((fitness, offspring_fitness, [fitness[best_idx]]))\n            best_individuals_idx = np.argsort(combined_fitness)[:population_size]\n            population = combined_population[best_individuals_idx]\n            fitness = combined_fitness[best_individuals_idx]\n            \n            # Update best solution\n            best_idx = np.argmin(fitness)\n            best_solution = population[best_idx]\n        \n        # Return the best found solution\n        return best_solution", "name": "DynamicPopulationEvolution", "description": "Introduces a dynamic population size adjustment based on current fitness variance to improve exploration and exploitation balance.", "configspace": "", "generation": 19, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 20 is out of bounds for axis 0 with size 20').", "error": "IndexError('index 20 is out of bounds for axis 0 with size 20')", "parent_id": "71251e46-8fdd-4c8a-818e-b10e3989cac8", "metadata": {}, "mutation_prompt": null}
