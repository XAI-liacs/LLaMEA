{"id": "53295112-db3a-4502-881d-9656759f25c2", "solution": "import numpy as np\nimport random\n\nclass DynamicPopulationEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Define population size\n        population_size = min(20, self.budget // 2)\n        # Initialize population within bounds\n        population = np.random.uniform(\n            low=func.bounds.lb, \n            high=func.bounds.ub, \n            size=(population_size, self.dim)\n        )\n        fitness = np.array([func(ind) for ind in population])\n        self.budget -= population_size\n        \n        # Evolution loop\n        while self.budget > 0:\n            # Select parents based on fitness proportional selection\n            parents_idx = np.random.choice(\n                population_size, \n                size=population_size, \n                p=fitness / fitness.sum()\n            )\n            parents = population[parents_idx]\n            \n            # Generate offspring through crossover and mutation\n            offspring = []\n            for i in range(population_size):\n                parent1, parent2 = parents[i], parents[(i + 1) % population_size]\n                \n                # Crossover (blend crossover)\n                alpha = np.random.uniform(0, 1, self.dim)\n                child = alpha * parent1 + (1 - alpha) * parent2\n                \n                # Mutation (adaptive Gaussian mutation)\n                mutation_strength = 0.1 * (func.bounds.ub - func.bounds.lb)\n                mutation = np.random.normal(0, mutation_strength, self.dim)\n                child += mutation\n                \n                # Ensure child is within bounds\n                child = np.clip(child, func.bounds.lb, func.bounds.ub)\n                offspring.append(child)\n            \n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            self.budget -= population_size\n            \n            # Combine and select the next generation\n            combined_population = np.vstack((population, offspring))\n            combined_fitness = np.hstack((fitness, offspring_fitness))\n            best_individuals_idx = np.argsort(combined_fitness)[:population_size]\n            population = combined_population[best_individuals_idx]\n            fitness = combined_fitness[best_individuals_idx]\n        \n        # Return the best found solution\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "DynamicPopulationEvolution", "description": "The algorithm leverages a dynamic population-based search with adaptive mutation and crossover strategies inspired by biological evolution to efficiently explore and exploit the search space for optimal solutions.", "configspace": "", "generation": 0, "fitness": 0.2438456795121671, "feedback": "The algorithm DynamicPopulationEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.244 with standard deviation 0.021. And the mean value of best solutions found was 0.099 (0. is the best) with standard deviation 0.046.", "error": "", "parent_id": null, "metadata": {"aucs": [0.21816921349052365, 0.24431891605614198, 0.2690489089898357], "final_y": [0.1532246301597944, 0.10244050118474861, 0.04055519839219992]}, "mutation_prompt": null}
{"id": "eb40be6b-e8f5-44fc-babf-349e22eb25f8", "solution": "import numpy as np\nimport random\n\nclass DynamicPopulationEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Define population size\n        population_size = min(20, self.budget // 2)\n        # Initialize population within bounds\n        population = np.random.uniform(\n            low=func.bounds.lb, \n            high=func.bounds.ub, \n            size=(population_size, self.dim)\n        )\n        fitness = np.array([func(ind) for ind in population])\n        self.budget -= population_size\n        \n        # Evolution loop\n        while self.budget > 0:\n            # Select parents based on fitness proportional selection\n            parents_idx = np.random.choice(\n                population_size, \n                size=population_size, \n                p=fitness / fitness.sum()\n            )\n            parents = population[parents_idx]\n            \n            # Generate offspring through crossover and mutation\n            offspring = []\n            for i in range(population_size):\n                parent1, parent2 = parents[i], parents[(i + 1) % population_size]\n                \n                # Crossover (blend crossover)\n                alpha = np.random.uniform(0.3, 0.7, self.dim)  # refined blend range\n                child = alpha * parent1 + (1 - alpha) * parent2\n                \n                # Mutation (adaptive Gaussian mutation)\n                mutation_strength = 0.05 * (func.bounds.ub - func.bounds.lb) # reduced mutation strength\n                mutation = np.random.normal(0, mutation_strength, self.dim)\n                child += mutation\n                \n                # Ensure child is within bounds\n                child = np.clip(child, func.bounds.lb, func.bounds.ub)\n                offspring.append(child)\n            \n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            self.budget -= population_size\n            \n            # Combine and select the next generation\n            combined_population = np.vstack((population, offspring))\n            combined_fitness = np.hstack((fitness, offspring_fitness))\n            best_individuals_idx = np.argsort(combined_fitness)[:population_size]\n            elitism_idx = np.argmin(combined_fitness) # Elite strategy\n            population = combined_population[best_individuals_idx]\n            population[0] = combined_population[elitism_idx] # Add elite\n            fitness = combined_fitness[best_individuals_idx]\n        \n        # Return the best found solution\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "DynamicPopulationEvolution", "description": "The algorithm enhances the exploration-exploitation balance by implementing an elite strategy and refined mutation, boosting convergence efficiency.", "configspace": "", "generation": 1, "fitness": 0.23334797218017458, "feedback": "The algorithm DynamicPopulationEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.233 with standard deviation 0.010. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.048.", "error": "", "parent_id": "53295112-db3a-4502-881d-9656759f25c2", "metadata": {"aucs": [0.24458023696109743, 0.22114101768219852, 0.23432266189722784], "final_y": [0.1317912153005378, 0.17368849229760278, 0.05681988065064785]}, "mutation_prompt": null}
{"id": "9a669157-7c5a-4076-b5b1-a9c2b381339f", "solution": "import numpy as np\nimport random\n\nclass DynamicPopulationEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Define population size\n        population_size = min(20, self.budget // 2)\n        # Initialize population within bounds\n        population = np.random.uniform(\n            low=func.bounds.lb, \n            high=func.bounds.ub, \n            size=(population_size, self.dim)\n        )\n        fitness = np.array([func(ind) for ind in population])\n        self.budget -= population_size\n        \n        # Evolution loop\n        while self.budget > 0:\n            # Select parents based on fitness proportional selection\n            parents_idx = np.random.choice(\n                population_size, \n                size=population_size, \n                p=fitness / fitness.sum()\n            )\n            parents = population[parents_idx]\n            \n            # Generate offspring through crossover and mutation\n            offspring = []\n            for i in range(population_size):\n                parent1, parent2 = parents[i], parents[(i + 1) % population_size]\n                \n                # Crossover (blend crossover)\n                alpha = np.random.uniform(0, 1, self.dim)\n                child = alpha * parent1 + (1 - alpha) * parent2\n                \n                # Mutation (Lévy flight mutation)\n                levy_flight = np.random.standard_cauchy(self.dim) * 0.1\n                child += levy_flight * (func.bounds.ub - func.bounds.lb)\n                \n                # Ensure child is within bounds\n                child = np.clip(child, func.bounds.lb, func.bounds.ub)\n                offspring.append(child)\n            \n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            self.budget -= population_size\n            \n            # Combine and select the next generation\n            combined_population = np.vstack((population, offspring))\n            combined_fitness = np.hstack((fitness, offspring_fitness))\n            best_individuals_idx = np.argsort(combined_fitness)[:population_size]\n            population = combined_population[best_individuals_idx]\n            fitness = combined_fitness[best_individuals_idx]\n        \n        # Return the best found solution\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "DynamicPopulationEvolution", "description": "The algorithm improves exploration by incorporating Lévy flights for mutation, enhancing the search efficiency in complex landscapes.", "configspace": "", "generation": 2, "fitness": 0.21331015465055372, "feedback": "The algorithm DynamicPopulationEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.213 with standard deviation 0.011. And the mean value of best solutions found was 0.177 (0. is the best) with standard deviation 0.047.", "error": "", "parent_id": "53295112-db3a-4502-881d-9656759f25c2", "metadata": {"aucs": [0.21490767304750746, 0.19887872573060927, 0.22614406517354446], "final_y": [0.15504188232716584, 0.24216468408023165, 0.13295869535821916]}, "mutation_prompt": null}
{"id": "cb4a3ce8-b061-45ce-a330-d8ca797a6f9e", "solution": "import numpy as np\nimport random\n\nclass DynamicPopulationEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Define population size\n        population_size = min(20, self.budget // 2)\n        # Initialize population within bounds\n        population = np.random.uniform(\n            low=func.bounds.lb, \n            high=func.bounds.ub, \n            size=(population_size, self.dim)\n        )\n        fitness = np.array([func(ind) for ind in population])\n        self.budget -= population_size\n        best_idx = np.argmin(fitness)  # Track best solution\n        best_solution = population[best_idx]\n\n        # Evolution loop\n        while self.budget > 0:\n            # Select parents based on fitness proportional selection\n            parents_idx = np.random.choice(\n                population_size, \n                size=population_size, \n                p=fitness / fitness.sum()\n            )\n            parents = population[parents_idx]\n            \n            # Generate offspring through crossover and mutation\n            offspring = []\n            for i in range(population_size):\n                parent1, parent2 = parents[i], parents[(i + 1) % population_size]\n                \n                # Crossover (blend crossover)\n                alpha = np.random.uniform(0, 1, self.dim)\n                child = alpha * parent1 + (1 - alpha) * parent2\n                \n                # Mutation (adaptive Gaussian mutation)\n                mutation_strength = 0.1 * (func.bounds.ub - func.bounds.lb)\n                mutation = np.random.normal(0, mutation_strength, self.dim)\n                child += mutation\n                \n                # Ensure child is within bounds\n                child = np.clip(child, func.bounds.lb, func.bounds.ub)\n                offspring.append(child)\n            \n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            self.budget -= population_size\n            \n            # Combine and select the next generation\n            combined_population = np.vstack((population, offspring, [best_solution]))  # Preserve best solution\n            combined_fitness = np.hstack((fitness, offspring_fitness, [fitness[best_idx]]))\n            best_individuals_idx = np.argsort(combined_fitness)[:population_size]\n            population = combined_population[best_individuals_idx]\n            fitness = combined_fitness[best_individuals_idx]\n            \n            # Update best solution\n            best_idx = np.argmin(fitness)\n            best_solution = population[best_idx]\n        \n        # Return the best found solution\n        return best_solution", "name": "DynamicPopulationEvolution", "description": "Introduce elitism by always preserving the best solution found so far, ensuring that the top candidate is never lost during population updates.", "configspace": "", "generation": 3, "fitness": 0.24701358946899302, "feedback": "The algorithm DynamicPopulationEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.019. And the mean value of best solutions found was 0.077 (0. is the best) with standard deviation 0.044.", "error": "", "parent_id": "53295112-db3a-4502-881d-9656759f25c2", "metadata": {"aucs": [0.24255183167067107, 0.2724225106499747, 0.22606642608633332], "final_y": [0.12177558632167293, 0.01772135932308937, 0.0903189080723321]}, "mutation_prompt": null}
{"id": "a4fa13b1-c8fd-40dd-956e-d3ae32727054", "solution": "import numpy as np\nimport random\n\nclass DynamicPopulationEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        population_size = min(20, self.budget // 2)\n        population = np.random.uniform(\n            low=func.bounds.lb, \n            high=func.bounds.ub, \n            size=(population_size, self.dim)\n        )\n        fitness = np.array([func(ind) for ind in population])\n        self.budget -= population_size\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        \n        no_improvement_count = 0  # Counter to track convergence\n\n        while self.budget > 0:\n            parents_idx = np.random.choice(\n                population_size, \n                size=population_size, \n                p=(1 / (fitness + 1e-9)) / (1 / (fitness + 1e-9)).sum()\n            )\n            parents = population[parents_idx]\n            \n            offspring = []\n            for i in range(population_size):\n                parent1, parent2 = parents[i], parents[(i + 1) % population_size]\n                alpha = np.random.uniform(0, 1, self.dim)\n                child = alpha * parent1 + (1 - alpha) * parent2\n                \n                mutation_strength = 0.1 * (func.bounds.ub - func.bounds.lb) * np.std(fitness)\n                mutation = np.random.normal(0, mutation_strength, self.dim)\n                child += mutation\n                child = np.clip(child, func.bounds.lb, func.bounds.ub)\n                offspring.append(child)\n            \n            offspring = np.array(offspring)\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n            self.budget -= population_size\n            \n            combined_population = np.vstack((population, offspring, [best_solution]))\n            combined_fitness = np.hstack((fitness, offspring_fitness, [fitness[best_idx]]))\n            best_individuals_idx = np.argsort(combined_fitness)[:population_size]\n            population = combined_population[best_individuals_idx]\n            fitness = combined_fitness[best_individuals_idx]\n            \n            new_best_idx = np.argmin(fitness)\n            if fitness[new_best_idx] < fitness[best_idx]:\n                best_idx = new_best_idx\n                best_solution = population[best_idx]\n                no_improvement_count = 0  # Reset convergence counter\n            else:\n                no_improvement_count += 1\n\n            if no_improvement_count > 5:  # Restart if no improvement for 5 iterations\n                population = np.random.uniform(\n                    low=func.bounds.lb, \n                    high=func.bounds.ub, \n                    size=(population_size, self.dim)\n                )\n                fitness = np.array([func(ind) for ind in population])\n                self.budget -= population_size\n                no_improvement_count = 0\n\n        return best_solution", "name": "DynamicPopulationEvolution", "description": "Enhance search efficiency by introducing diversity via a restart mechanism when convergence stalls, and adjust mutation strength dynamically based on fitness variance.", "configspace": "", "generation": 4, "fitness": 0.19034896063130582, "feedback": "The algorithm DynamicPopulationEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.190 with standard deviation 0.022. And the mean value of best solutions found was 0.438 (0. is the best) with standard deviation 0.162.", "error": "", "parent_id": "cb4a3ce8-b061-45ce-a330-d8ca797a6f9e", "metadata": {"aucs": [0.18223006288253873, 0.22018747651931025, 0.1686293424920685], "final_y": [0.5174477332373543, 0.21192945620447948, 0.584254686760048]}, "mutation_prompt": null}
