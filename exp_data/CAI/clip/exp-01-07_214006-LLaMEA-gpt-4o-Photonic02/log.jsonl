{"id": "9c1f7daf-1ccd-4839-9698-d9c8e5b28673", "solution": "import numpy as np\n\nclass HybridAnnealingDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            # Simulated annealing step\n            for i in range(self.population_size):\n                candidate = population[i] + self.temperature * (np.random.rand(self.dim) - 0.5)\n                candidate = np.clip(candidate, bounds[:,0], bounds[:,1])\n                candidate_fitness = func(candidate)\n                self.current_evaluations += 1\n                \n                if candidate_fitness < fitness[i] or np.exp((fitness[i] - candidate_fitness) / self.temperature) > np.random.rand():\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n            \n            self.temperature *= self.cooling_rate\n            \n            # Differential evolution step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = np.clip(x0 + 0.8 * (x1 - x2), bounds[:,0], bounds[:,1])\n                cross_points = np.random.rand(self.dim) < 0.9\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                \n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.current_evaluations += 1\n                \n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n            \n            if self.current_evaluations >= self.budget:\n                break\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridAnnealingDifferentialEvolution", "description": "The algorithm combines simulated annealing and differential evolution to balance exploration and exploitation for efficient black-box optimization.", "configspace": "", "generation": 0, "fitness": 0.2347265745590966, "feedback": "The algorithm HybridAnnealingDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.235 with standard deviation 0.012. And the mean value of best solutions found was 0.043 (0. is the best).", "error": "", "parent_id": null, "metadata": {"aucs": [0.25138768968424374, 0.22241069690764181, 0.2303813370854042], "final_y": [0.027604775003725362, 0.05387206494941319, 0.04765398221705823]}, "mutation_prompt": null}
{"id": "1ecfabe8-ab8e-4702-9281-8cd50fe59c67", "solution": "import numpy as np\n\nclass HybridAnnealingDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            # Simulated annealing step with adaptive cooling\n            for i in range(self.population_size):\n                candidate = population[i] + self.temperature * (np.random.rand(self.dim) - 0.5)\n                candidate = np.clip(candidate, bounds[:,0], bounds[:,1])\n                candidate_fitness = func(candidate)\n                self.current_evaluations += 1\n                \n                if candidate_fitness < fitness[i] or np.exp((fitness[i] - candidate_fitness) / self.temperature) > np.random.rand():\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n            \n            self.temperature *= self.cooling_rate * (0.5 + 0.5 * np.random.rand())\n            \n            # Differential evolution step with adaptive crossover\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = np.clip(x0 + 0.8 * (x1 - x2), bounds[:,0], bounds[:,1])\n                crossover_prob = 0.7 + 0.2 * np.random.rand()\n                cross_points = np.random.rand(self.dim) < crossover_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                \n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.current_evaluations += 1\n                \n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridAnnealingDifferentialEvolution", "description": "Enhanced hybrid algorithm integrating adaptive cooling and crossover mechanisms to improve exploration and exploitation balance.", "configspace": "", "generation": 1, "fitness": 0.2723896251107047, "feedback": "The algorithm HybridAnnealingDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.272 with standard deviation 0.013. And the mean value of best solutions found was 0.007 (0. is the best).", "error": "", "parent_id": "9c1f7daf-1ccd-4839-9698-d9c8e5b28673", "metadata": {"aucs": [0.26019834735392633, 0.2911369358776009, 0.26583359210058677], "final_y": [0.008772177034957529, 0.0011313438810704526, 0.010881277512630856]}, "mutation_prompt": null}
{"id": "ad87c4fe-0592-46b2-9c51-d86733f1ab4d", "solution": "import numpy as np\n\nclass HybridAnnealingDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            # Simulated annealing step with adaptive cooling\n            for i in range(self.population_size):\n                candidate = population[i] + self.temperature * (np.random.rand(self.dim) - 0.5)\n                candidate = np.clip(candidate, bounds[:,0], bounds[:,1])\n                candidate_fitness = func(candidate)\n                self.current_evaluations += 1\n                \n                if candidate_fitness < fitness[i] or np.exp((fitness[i] - candidate_fitness) / self.temperature) > np.random.rand():\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n            \n            self.temperature *= self.cooling_rate * (0.5 + 0.5 * np.random.rand())\n            \n            # Differential evolution step with adaptive crossover\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = np.clip(x0 + 0.8 * (x1 - x2), bounds[:,0], bounds[:,1])\n                crossover_prob = 0.75 + 0.2 * np.random.rand()  # Increased crossover probability range\n                cross_points = np.random.rand(self.dim) < crossover_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                \n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.current_evaluations += 1\n                \n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "HybridAnnealingDifferentialEvolution", "description": "Improved exploration by slightly increasing the crossover probability range to enhance diversity.", "configspace": "", "generation": 2, "fitness": 0.2898099902133548, "feedback": "The algorithm HybridAnnealingDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.290 with standard deviation 0.020. And the mean value of best solutions found was 0.005 (0. is the best).", "error": "", "parent_id": "1ecfabe8-ab8e-4702-9281-8cd50fe59c67", "metadata": {"aucs": [0.3179075547644632, 0.2748271240152853, 0.27669529186031583], "final_y": [0.001597572165010664, 0.003898156937735821, 0.009943191514061528]}, "mutation_prompt": null}
{"id": "97e97653-8fc8-4fc2-bf4d-ff6ea4653c65", "solution": "import numpy as np\n\nclass ChaoticHybridAnnealingDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.temperature = 1.0\n        self.cooling_rate = 0.99\n        self.chaos_map = self.logistic_map\n        self.chaos_param = 0.7\n\n    def logistic_map(self, x, r=3.99):\n        return r * x * (1 - x)\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            # Simulated annealing step with chaotic cooling\n            for i in range(self.population_size):\n                candidate = population[i] + self.temperature * (np.random.rand(self.dim) - 0.5)\n                candidate = np.clip(candidate, bounds[:,0], bounds[:,1])\n                candidate_fitness = func(candidate)\n                self.current_evaluations += 1\n                \n                if candidate_fitness < fitness[i] or np.exp((fitness[i] - candidate_fitness) / self.temperature) > np.random.rand():\n                    population[i] = candidate\n                    fitness[i] = candidate_fitness\n            \n            self.temperature *= self.cooling_rate * self.chaos_map(self.chaos_param)\n            self.chaos_param = self.chaos_map(self.chaos_param)\n            \n            # Differential evolution step with chaotic crossover\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = population[indices]\n                mutant = np.clip(x0 + 0.8 * (x1 - x2), bounds[:,0], bounds[:,1])\n                crossover_prob = 0.75 + 0.2 * self.chaos_map(self.chaos_param)\n                cross_points = np.random.rand(self.dim) < crossover_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                \n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.current_evaluations += 1\n                \n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n            \n            if self.current_evaluations >= self.budget:\n                break\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "ChaoticHybridAnnealingDifferentialEvolution", "description": "Incorporate chaotic maps for dynamic parameter adjustment to enhance diversity and convergence.", "configspace": "", "generation": 3, "fitness": 0.2519303891215236, "feedback": "The algorithm ChaoticHybridAnnealingDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.252 with standard deviation 0.026. And the mean value of best solutions found was 0.020 (0. is the best).", "error": "", "parent_id": "ad87c4fe-0592-46b2-9c51-d86733f1ab4d", "metadata": {"aucs": [0.24540260926354585, 0.2869380078001418, 0.22345055030088312], "final_y": [0.031390303242307654, 0.003699606824095078, 0.02387644026815859]}, "mutation_prompt": null}
{"id": "377d5c38-b4be-4be0-b5b2-b27212606e13", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                velocities[i] = self.alpha * velocities[i] + \\\n                                np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) + \\\n                                np.random.rand(self.dim) * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n            \n            # Quantum swarm re-positioning\n            if self.current_evaluations < self.budget:\n                for i in range(self.population_size):\n                    quantum_shift = self.beta * (np.random.rand(self.dim) - 0.5)\n                    quantum_position = global_best_position + quantum_shift\n                    quantum_position = np.clip(quantum_position, bounds[:,0], bounds[:,1])\n                    quantum_fitness = func(quantum_position)\n                    self.current_evaluations += 1\n                    \n                    if quantum_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = quantum_position\n                        personal_best_fitness[i] = quantum_fitness\n                        if quantum_fitness < personal_best_fitness[global_best_index]:\n                            global_best_position = quantum_position\n                            global_best_index = i\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Adaptive Quantum Particle Swarm Optimization (AQPSO) with dynamic re-positioning for enhanced global search capabilities.", "configspace": "", "generation": 4, "fitness": 0.29281434761142194, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.293 with standard deviation 0.005. And the mean value of best solutions found was 0.005 (0. is the best).", "error": "", "parent_id": "ad87c4fe-0592-46b2-9c51-d86733f1ab4d", "metadata": {"aucs": [0.2856130112232538, 0.2953161313653262, 0.2975139002456858], "final_y": [0.010679678250720227, 0.0026172305212807433, 0.0026679989351250442]}, "mutation_prompt": null}
{"id": "2fcb3b19-9d14-4133-b24c-53f1f0db5dac", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                velocities[i] = self.alpha * velocities[i] + \\\n                                np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) + \\\n                                np.random.rand(self.dim) * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n            \n            # Quantum swarm re-positioning\n            if self.current_evaluations < self.budget:\n                for i in range(self.population_size):\n                    self.beta = 0.5 + (0.5 * self.current_evaluations/self.budget)  # Adaptive beta\n                    quantum_shift = self.beta * (np.random.rand(self.dim) - 0.5)\n                    quantum_position = global_best_position + quantum_shift\n                    quantum_position = np.clip(quantum_position, bounds[:,0], bounds[:,1])\n                    quantum_fitness = func(quantum_position)\n                    self.current_evaluations += 1\n                    \n                    if quantum_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = quantum_position\n                        personal_best_fitness[i] = quantum_fitness\n                        if quantum_fitness < personal_best_fitness[global_best_index]:\n                            global_best_position = quantum_position\n                            global_best_index = i\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Improved AQPSO with adaptive beta for enhanced convergence speed.", "configspace": "", "generation": 5, "fitness": 0.3036699653715404, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.304 with standard deviation 0.018. And the mean value of best solutions found was 0.002 (0. is the best).", "error": "", "parent_id": "377d5c38-b4be-4be0-b5b2-b27212606e13", "metadata": {"aucs": [0.32834481792364445, 0.28787661898550754, 0.29478845920546926], "final_y": [5.0299991197840535e-05, 0.004693766396371177, 0.0024164472020281034]}, "mutation_prompt": null}
{"id": "42a98f8e-b3d8-4ca0-89c9-bcff52674c7b", "solution": "import numpy as np\n\nclass QuantumInspiredParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.w_max = 0.9  # Maximum inertia weight\n        self.w_min = 0.4  # Minimum inertia weight\n        self.c1 = 2.05  # Cognitive coefficient\n        self.c2 = 2.05  # Social coefficient\n        self.beta = 0.5  # Initial quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n\n        while self.current_evaluations < self.budget:\n            w = self.w_max - ((self.w_max - self.w_min) * (self.current_evaluations / self.budget))\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                self.c1 * r1 * (personal_best_positions[i] - population[i]) +\n                                self.c2 * r2 * (global_best_position - population[i]))\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n\n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n\n            # Quantum tunneling strategy\n            if self.current_evaluations < self.budget:\n                for i in range(self.population_size):\n                    self.beta = 0.5 * (1 - self.current_evaluations / self.budget)\n                    quantum_shift = self.beta * (np.random.rand(self.dim) - 0.5)\n                    quantum_position = global_best_position + quantum_shift\n                    quantum_position = np.clip(quantum_position, bounds[:,0], bounds[:,1])\n                    quantum_fitness = func(quantum_position)\n                    self.current_evaluations += 1\n\n                    if quantum_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = quantum_position\n                        personal_best_fitness[i] = quantum_fitness\n                        if quantum_fitness < personal_best_fitness[global_best_index]:\n                            global_best_position = quantum_position\n                            global_best_index = i\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "QuantumInspiredParticleSwarmOptimization", "description": "Quantum-inspired Particle Swarm Optimization with adaptive inertia weight and quantum tunneling for enhanced exploration and exploitation balance.", "configspace": "", "generation": 6, "fitness": 0.21623024719029973, "feedback": "The algorithm QuantumInspiredParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.216 with standard deviation 0.038. And the mean value of best solutions found was 0.132 (0. is the best).", "error": "", "parent_id": "2fcb3b19-9d14-4133-b24c-53f1f0db5dac", "metadata": {"aucs": [0.19833861597467917, 0.269195096877041, 0.18115702871917905], "final_y": [0.0796699862018822, 0.030008798221180716, 0.28640631017447404]}, "mutation_prompt": null}
{"id": "844e9ce1-ecbc-4643-8e2a-d6f5b4f9dfcd", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                self.alpha = 0.4 + 0.1 * (self.current_evaluations/self.budget)  # Adjusted alpha\n                velocities[i] = self.alpha * velocities[i] + \\\n                                np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) + \\\n                                np.random.rand(self.dim) * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n            \n            # Quantum swarm re-positioning\n            if self.current_evaluations < self.budget:\n                for i in range(self.population_size):\n                    self.beta = 0.5 + (0.5 * self.current_evaluations/self.budget)  # Adaptive beta\n                    quantum_shift = self.beta * (np.random.rand(self.dim) - 0.5)\n                    quantum_position = global_best_position + quantum_shift\n                    quantum_position = np.clip(quantum_position, bounds[:,0], bounds[:,1])\n                    quantum_fitness = func(quantum_position)\n                    self.current_evaluations += 1\n                    \n                    if quantum_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = quantum_position\n                        personal_best_fitness[i] = quantum_fitness\n                        if quantum_fitness < personal_best_fitness[global_best_index]:\n                            global_best_position = quantum_position\n                            global_best_index = i\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Enhanced AQPSO by modulating alpha for improved balance between exploration and exploitation.", "configspace": "", "generation": 7, "fitness": 0.3138063641648448, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.314 with standard deviation 0.029. And the mean value of best solutions found was 0.002 (0. is the best).", "error": "", "parent_id": "2fcb3b19-9d14-4133-b24c-53f1f0db5dac", "metadata": {"aucs": [0.32955373827847223, 0.3392316085398046, 0.27263374567625753], "final_y": [0.0010356103737884062, 0.0006171027267848765, 0.005713768469016572]}, "mutation_prompt": null}
{"id": "c30ab23b-6c23-40d1-b8e1-86e6ec3d0aef", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n        \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                neighborhood_best = np.copy(personal_best_positions[i])\n                if i > 0:\n                    neighborhood_best = min(neighborhood_best, personal_best_positions[i-1], key=func)\n                if i < self.population_size - 1:\n                    neighborhood_best = min(neighborhood_best, personal_best_positions[i+1], key=func)\n                \n                velocities[i] = self.alpha * velocities[i] + \\\n                                np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) + \\\n                                np.random.rand(self.dim) * (neighborhood_best - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n            \n            # Quantum swarm re-positioning\n            if self.current_evaluations < self.budget:\n                for i in range(self.population_size):\n                    self.beta = 0.5 + (0.5 * np.sin(self.current_evaluations/self.budget * np.pi))  # Sine based beta\n                    quantum_shift = self.beta * (np.random.rand(self.dim) - 0.5)\n                    quantum_position = global_best_position + quantum_shift\n                    quantum_position = np.clip(quantum_position, bounds[:,0], bounds[:,1])\n                    quantum_fitness = func(quantum_position)\n                    self.current_evaluations += 1\n                    \n                    if quantum_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = quantum_position\n                        personal_best_fitness[i] = quantum_fitness\n                        if quantum_fitness < personal_best_fitness[global_best_index]:\n                            global_best_position = quantum_position\n                            global_best_index = i\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Enhanced AQPSO with Dynamic Neighborhood-Based Quantum Swarm Strategy for improved convergence speed and robustness.", "configspace": "", "generation": 8, "fitness": 0.20480702830234518, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.205 with standard deviation 0.007. And the mean value of best solutions found was 0.205 (0. is the best).", "error": "", "parent_id": "844e9ce1-ecbc-4643-8e2a-d6f5b4f9dfcd", "metadata": {"aucs": [0.20856794792854472, 0.21020400760375768, 0.1956491293747331], "final_y": [0.05754301506249515, 0.2821912160031043, 0.2748848413792886]}, "mutation_prompt": null}
{"id": "ce5abd86-af20-47c5-8ad8-d463692e771f", "solution": "import numpy as np\n\nclass QuantumInspiredDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.F = 0.8  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.beta_min = 0.5  # Minimum quantum shift\n        self.beta_max = 1.0  # Maximum quantum shift\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        fitness = np.array([func(ind) for ind in population])\n        self.current_evaluations += self.population_size\n\n        while self.current_evaluations < self.budget:\n            new_population = np.copy(population)\n            \n            for i in range(self.population_size):\n                # Mutation\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = population[idxs]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, bounds[:,0], bounds[:,1])\n\n                # Quantum-inspired crossover\n                beta = self.beta_min + (self.beta_max - self.beta_min) * (self.current_evaluations / self.budget)\n                crossover = np.random.rand(self.dim) < self.CR\n                quantum_shift = beta * (np.random.rand(self.dim) - 0.5)\n                trial = np.where(crossover, mutant + quantum_shift, population[i])\n                trial = np.clip(trial, bounds[:,0], bounds[:,1])\n\n                # Selection\n                trial_fitness = func(trial)\n                self.current_evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    new_population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if self.current_evaluations >= self.budget:\n                    break\n            \n            population = new_population\n\n        best_index = np.argmin(fitness)\n        return population[best_index], fitness[best_index]", "name": "QuantumInspiredDifferentialEvolution", "description": "Quantum-Inspired Differential Evolution (QIDE) utilizes quantum superposition principles to explore the search space, enhancing DE with adaptive quantum-inspired mutation and crossover.", "configspace": "", "generation": 9, "fitness": 0.20030879600899798, "feedback": "The algorithm QuantumInspiredDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.200 with standard deviation 0.019. And the mean value of best solutions found was 0.150 (0. is the best).", "error": "", "parent_id": "844e9ce1-ecbc-4643-8e2a-d6f5b4f9dfcd", "metadata": {"aucs": [0.17344905360804752, 0.21762120815865704, 0.20985612626028938], "final_y": [0.29838355459880167, 0.05249825138378254, 0.09826794093601021]}, "mutation_prompt": null}
{"id": "695c8832-cc24-45fa-8e41-cda0116b3ba9", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                self.alpha = 0.4 + 0.1 * (self.current_evaluations/self.budget)  # Adjusted alpha\n                inertia_weight = 0.9 - 0.5 * (self.current_evaluations/self.budget)  # Dynamic inertia weight\n                velocities[i] = inertia_weight * velocities[i] + \\\n                                np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) + \\\n                                np.random.rand(self.dim) * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n            \n            # Quantum swarm re-positioning\n            if self.current_evaluations < self.budget:\n                for i in range(self.population_size):\n                    self.beta = 0.5 + (0.5 * self.current_evaluations/self.budget)  # Adaptive beta\n                    quantum_shift = self.beta * (np.random.rand(self.dim) - 0.5)\n                    quantum_position = global_best_position + quantum_shift\n                    quantum_position = np.clip(quantum_position, bounds[:,0], bounds[:,1])\n                    quantum_fitness = func(quantum_position)\n                    self.current_evaluations += 1\n                    \n                    if quantum_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = quantum_position\n                        personal_best_fitness[i] = quantum_fitness\n                        if quantum_fitness < personal_best_fitness[global_best_index]:\n                            global_best_position = quantum_position\n                            global_best_index = i\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Improved AQPSO by introducing a dynamic inertia weight for enhanced convergence speed.", "configspace": "", "generation": 10, "fitness": 0.2872482794494547, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.287 with standard deviation 0.036. And the mean value of best solutions found was 0.010 (0. is the best).", "error": "", "parent_id": "844e9ce1-ecbc-4643-8e2a-d6f5b4f9dfcd", "metadata": {"aucs": [0.27216966209365157, 0.3372278784896111, 0.25234729776510134], "final_y": [0.010491591615409683, 0.004150143898972503, 0.015695032805326352]}, "mutation_prompt": null}
{"id": "f2de634a-6505-45c0-8df2-6ac0c6e62ff4", "solution": "import numpy as np\n\nclass GradientInformedParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.w = 0.5  # Inertia weight\n        self.c1 = 2.0  # Cognitive component\n        self.c2 = 2.0  # Social component\n        self.gradient_step_size = 0.01\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n\n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                # Velocity update\n                velocities[i] = (self.w * velocities[i] +\n                                self.c1 * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) +\n                                self.c2 * np.random.rand(self.dim) * (global_best_position - population[i]))\n                # Position update\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n                \n                # Gradient-informed search adjustment\n                gradient_estimate = self.estimate_gradient(func, population[i], bounds)\n                population[i] = population[i] - self.gradient_step_size * gradient_estimate\n                population[i] = np.clip(population[i], bounds[:, 0], bounds[:, 1])\n                \n                # Evaluate and update personal and global bests\n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]\n\n    def estimate_gradient(self, func, position, bounds):\n        # Estimate gradient via finite differences\n        epsilon = 1e-8\n        gradient = np.zeros(self.dim)\n        for d in range(self.dim):\n            pos = np.copy(position)\n            pos[d] += epsilon\n            pos = np.clip(pos, bounds[d, 0], bounds[d, 1])\n            gradient[d] = (func(pos) - func(position)) / epsilon\n            self.current_evaluations += 1\n            if self.current_evaluations >= self.budget:\n                break\n        return gradient", "name": "GradientInformedParticleSwarmOptimization", "description": "Gradient-Informed Particle Swarm Optimization (GIPSO) integrates gradient estimates to guide particles towards optimal solutions in complex search spaces.", "configspace": "", "generation": 11, "fitness": 0.1591158422474207, "feedback": "The algorithm GradientInformedParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.159 with standard deviation 0.031. And the mean value of best solutions found was 1.264 (0. is the best).", "error": "", "parent_id": "844e9ce1-ecbc-4643-8e2a-d6f5b4f9dfcd", "metadata": {"aucs": [0.1312720545769419, 0.20243486593218607, 0.14364060623313413], "final_y": [1.8916465032964012, 0.4459719779137783, 1.4529084859562522]}, "mutation_prompt": null}
{"id": "0a5037bd-ff0a-485f-b56c-6e627759c67c", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                self.alpha = 0.4 + 0.1 * (self.current_evaluations/self.budget)  # Adjusted alpha\n                velocities[i] = self.alpha * velocities[i] + \\\n                                np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) + \\\n                                np.random.rand(self.dim) * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n            \n            # Quantum swarm re-positioning\n            if self.current_evaluations < self.budget:\n                for i in range(self.population_size):\n                    self.beta = 0.5 + (0.5 * self.current_evaluations/self.budget)  # Adaptive beta\n                    quantum_shift = self.beta * (np.random.rand(self.dim) - 0.5)\n                    quantum_position = global_best_position + quantum_shift\n                    quantum_position = np.clip(quantum_position, bounds[:,0], bounds[:,1])\n                    quantum_fitness = func(quantum_position)\n                    self.current_evaluations += 1\n                    \n                    if quantum_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = quantum_position\n                        personal_best_fitness[i] = quantum_fitness\n                        if quantum_fitness < personal_best_fitness[global_best_index]:\n                            global_best_position = quantum_position\n                            global_best_index = i\n\n            # Dynamic adaptation of the population size\n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Introducing dynamic population size adaptation to enhance exploration in later stages of optimization.", "configspace": "", "generation": 12, "fitness": 0.42605192907990536, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.426 with standard deviation 0.034. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "844e9ce1-ecbc-4643-8e2a-d6f5b4f9dfcd", "metadata": {"aucs": [0.44168139246962235, 0.37881267045488853, 0.457661724315205], "final_y": [9.232217217578383e-07, 2.178783122323633e-05, 1.386978210342906e-05]}, "mutation_prompt": null}
{"id": "a42c558c-9398-4601-81b5-76adcbf6d27d", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n        self.inertia_weight = 0.9  # Added inertia weight\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                self.alpha = 0.4 + 0.1 * (self.current_evaluations/self.budget)  # Adjusted alpha\n                velocities[i] = self.inertia_weight * velocities[i] + \\\n                                self.alpha * np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) + \\\n                                np.random.rand(self.dim) * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n            \n            # Quantum swarm re-positioning\n            if self.current_evaluations < self.budget:\n                for i in range(self.population_size):\n                    self.beta = 0.5 + (0.5 * self.current_evaluations/self.budget)  # Adaptive beta\n                    quantum_shift = self.beta * (np.random.rand(self.dim) - 0.5)\n                    quantum_position = global_best_position + quantum_shift\n                    quantum_position = np.clip(quantum_position, bounds[:,0], bounds[:,1])\n                    quantum_fitness = func(quantum_position)\n                    self.current_evaluations += 1\n                    \n                    if quantum_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = quantum_position\n                        personal_best_fitness[i] = quantum_fitness\n                        if quantum_fitness < personal_best_fitness[global_best_index]:\n                            global_best_position = quantum_position\n                            global_best_index = i\n\n            # Dynamic adaptation of the population size\n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Enhanced velocity update by introducing inertia to improve convergence stability.", "configspace": "", "generation": 13, "fitness": 0.20654227732667926, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.207 with standard deviation 0.026. And the mean value of best solutions found was 0.152 (0. is the best).", "error": "", "parent_id": "0a5037bd-ff0a-485f-b56c-6e627759c67c", "metadata": {"aucs": [0.18186457243138932, 0.19596634738479546, 0.241795912163853], "final_y": [0.09911578784232783, 0.26323610031556693, 0.09425142936097432]}, "mutation_prompt": null}
{"id": "06aa2ec0-6eb3-49da-b188-62617a70dd6f", "solution": "import numpy as np\n\nclass EnvironmentalFeedbackPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.w = 0.7  # Inertia weight\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n\n        while self.current_evaluations < self.budget:\n            # Calculate diversity as the standard deviation of the population\n            diversity = np.mean(np.std(population, axis=0))\n\n            for i in range(self.population_size):\n                self.w = 0.5 + 0.5 * (1 - diversity)  # Adjust inertia based on diversity\n                r1, r2 = np.random.rand(2, self.dim)\n                velocities[i] = self.w * velocities[i] + \\\n                                self.c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                self.c2 * r2 * (global_best_position - population[i])\n                population[i] += velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n\n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n\n            # Dynamically adjust cognitive and social components based on progress\n            progress = 1 - (self.current_evaluations / self.budget)\n            self.c1 = 2.0 - progress * 1.0  # Increase cognitive component as progress decreases\n            self.c2 = 1.0 + progress * 1.0  # Decrease social component as progress decreases\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "EnvironmentalFeedbackPSO", "description": "Introducing environmental feedback loops to dynamically adjust exploration-exploitation balance in Particle Swarm Optimization.", "configspace": "", "generation": 14, "fitness": 0.10362422569798639, "feedback": "The algorithm EnvironmentalFeedbackPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.104 with standard deviation 0.026. And the mean value of best solutions found was 4.717 (0. is the best).", "error": "", "parent_id": "0a5037bd-ff0a-485f-b56c-6e627759c67c", "metadata": {"aucs": [0.09987041762518711, 0.07414822072017613, 0.13685403874859592], "final_y": [4.378827522930273, 7.85595370739234, 1.9160177536057992]}, "mutation_prompt": null}
{"id": "156a2c20-2439-4633-8697-f80317346f91", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                self.alpha = 0.4 + 0.1 * (self.current_evaluations/self.budget)  # Adjusted alpha\n                velocities[i] = self.alpha * velocities[i] + \\\n                                np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) + \\\n                                np.random.rand(self.dim) * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n            \n            # Quantum swarm re-positioning with local search refinement\n            if self.current_evaluations < self.budget:\n                for i in range(self.population_size):\n                    self.beta = 0.5 + (0.5 * self.current_evaluations/self.budget)  # Adaptive beta\n                    quantum_shift = self.beta * (np.random.rand(self.dim) - 0.5)\n                    quantum_position = global_best_position + quantum_shift\n                    local_refinement = 0.01 * (np.random.rand(self.dim) - 0.5)  # Local search refinement\n                    quantum_position = np.clip(quantum_position + local_refinement, bounds[:,0], bounds[:,1])\n                    quantum_fitness = func(quantum_position)\n                    self.current_evaluations += 1\n                    \n                    if quantum_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = quantum_position\n                        personal_best_fitness[i] = quantum_fitness\n                        if quantum_fitness < personal_best_fitness[global_best_index]:\n                            global_best_position = quantum_position\n                            global_best_index = i\n\n            # Dynamic adaptation of the population size\n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Enhance convergence by introducing local search refinement in quantum re-positioning.", "configspace": "", "generation": 15, "fitness": 0.3977574434041986, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.398 with standard deviation 0.025. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "0a5037bd-ff0a-485f-b56c-6e627759c67c", "metadata": {"aucs": [0.3788827776463902, 0.4327964085792466, 0.381593143986959], "final_y": [8.753426280519136e-06, 1.8982228003505602e-07, 0.00015228234296596582]}, "mutation_prompt": null}
{"id": "59bdb03c-650d-4772-90d6-421a7cda8336", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                self.alpha = 0.4 + 0.1 * (self.current_evaluations/self.budget)  # Adjusted alpha\n                velocities[i] = self.alpha * velocities[i] + \\\n                                np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) + \\\n                                np.random.rand(self.dim) * (global_best_position - population[i]) + \\\n                                0.05 * (np.mean(population, axis=0) - population[i])  # New collective influence\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n            \n            # Quantum swarm re-positioning\n            if self.current_evaluations < self.budget:\n                for i in range(self.population_size):\n                    self.beta = 0.5 + (0.5 * self.current_evaluations/self.budget)  # Adaptive beta\n                    quantum_shift = self.beta * (np.random.rand(self.dim) - 0.5)\n                    quantum_position = global_best_position + quantum_shift\n                    quantum_position = np.clip(quantum_position, bounds[:,0], bounds[:,1])\n                    quantum_fitness = func(quantum_position)\n                    self.current_evaluations += 1\n                    \n                    if quantum_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = quantum_position\n                        personal_best_fitness[i] = quantum_fitness\n                        if quantum_fitness < personal_best_fitness[global_best_index]:\n                            global_best_position = quantum_position\n                            global_best_index = i\n\n            # Dynamic adaptation of the population size\n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Enhance the dynamic adaptation by refining the velocity update mechanism with an additional term to improve convergence.", "configspace": "", "generation": 16, "fitness": 0.31893103354631674, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.319 with standard deviation 0.027. And the mean value of best solutions found was 0.006 (0. is the best).", "error": "", "parent_id": "0a5037bd-ff0a-485f-b56c-6e627759c67c", "metadata": {"aucs": [0.3281698335816291, 0.28244003998993017, 0.346183227067391], "final_y": [0.004544230095347582, 0.012374591397227694, 0.0017081696969157383]}, "mutation_prompt": null}
{"id": "b4ca46d5-d995-4f95-9a04-18cfbea28875", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                inertia_weight = 0.9 - 0.5 * (self.current_evaluations/self.budget)  # Dynamic inertia\n                velocities[i] = inertia_weight * velocities[i] + \\\n                                np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) + \\\n                                np.random.rand(self.dim) * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n            \n            # Quantum swarm re-positioning\n            if self.current_evaluations < self.budget:\n                for i in range(self.population_size):\n                    self.beta = 0.5 + (0.5 * self.current_evaluations/self.budget)  # Adaptive beta\n                    quantum_shift = self.beta * (np.random.rand(self.dim) - 0.5)\n                    quantum_position = global_best_position + quantum_shift\n                    quantum_position = np.clip(quantum_position, bounds[:,0], bounds[:,1])\n                    quantum_fitness = func(quantum_position)\n                    self.current_evaluations += 1\n                    \n                    if quantum_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = quantum_position\n                        personal_best_fitness[i] = quantum_fitness\n                        if quantum_fitness < personal_best_fitness[global_best_index]:\n                            global_best_position = quantum_position\n                            global_best_index = i\n\n            # Dynamic adaptation of the population size\n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Enhance convergence by dynamically adjusting inertia weight for velocity and incorporating stochastic rank-based re-evaluation.", "configspace": "", "generation": 17, "fitness": 0.25698956759101466, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.257 with standard deviation 0.026. And the mean value of best solutions found was 0.008 (0. is the best).", "error": "", "parent_id": "0a5037bd-ff0a-485f-b56c-6e627759c67c", "metadata": {"aucs": [0.262511823638757, 0.22284608350553736, 0.2856107956287496], "final_y": [0.0008395287577666681, 0.022992051433336363, 1.8253258031890972e-05]}, "mutation_prompt": null}
{"id": "30ec4bed-5d58-47b6-9b87-bbbbcaea769d", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                self.alpha = 0.4 + 0.2 * np.sin(np.pi * self.current_evaluations/self.budget)  # Nonlinear alpha\n                velocities[i] = self.alpha * velocities[i] + \\\n                                np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) + \\\n                                np.random.rand(self.dim) * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n            \n            # Quantum swarm re-positioning\n            if self.current_evaluations < self.budget:\n                for i in range(self.population_size):\n                    self.beta = 0.5 + (0.5 * np.cos(np.pi * self.current_evaluations/self.budget))  # Adaptive beta\n                    quantum_shift = self.beta * (np.random.rand(self.dim) - 0.5)\n                    quantum_position = global_best_position + quantum_shift\n                    quantum_position = np.clip(quantum_position, bounds[:,0], bounds[:,1])\n                    quantum_fitness = func(quantum_position)\n                    self.current_evaluations += 1\n                    \n                    if quantum_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = quantum_position\n                        personal_best_fitness[i] = quantum_fitness\n                        if quantum_fitness < personal_best_fitness[global_best_index]:\n                            global_best_position = quantum_position\n                            global_best_index = i\n\n            # Dynamic adaptation of the population size\n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Introducing nonlinear velocity reduction and adaptive quantum shift for enhanced global exploration.", "configspace": "", "generation": 18, "fitness": 0.3429347412086073, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.343 with standard deviation 0.034. And the mean value of best solutions found was 0.001 (0. is the best).", "error": "", "parent_id": "0a5037bd-ff0a-485f-b56c-6e627759c67c", "metadata": {"aucs": [0.3902989092677497, 0.32133688213991085, 0.3171684322181615], "final_y": [0.0002053370725677082, 0.00012130420174432074, 0.0022112575819793127]}, "mutation_prompt": null}
{"id": "51ce0060-215e-4405-bb2a-d9edc3488f7a", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                self.alpha = 0.4 + 0.1 * (self.current_evaluations/self.budget)  # Adjusted alpha\n                velocities[i] = self.alpha * velocities[i] + \\\n                                np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) + \\\n                                np.random.rand(self.dim) * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                \n                # Apply mutation to enhance exploration\n                mutation_factor = 0.1 * (1 - self.current_evaluations / self.budget)\n                population[i] += mutation_factor * np.random.normal(size=self.dim)\n                \n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n            \n            # Quantum swarm re-positioning\n            if self.current_evaluations < self.budget:\n                for i in range(self.population_size):\n                    self.beta = 0.5 + (0.5 * self.current_evaluations/self.budget)  # Adaptive beta\n                    quantum_shift = self.beta * (np.random.rand(self.dim) - 0.5)\n                    quantum_position = global_best_position + quantum_shift\n                    quantum_position = np.clip(quantum_position, bounds[:,0], bounds[:,1])\n                    quantum_fitness = func(quantum_position)\n                    self.current_evaluations += 1\n                    \n                    if quantum_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = quantum_position\n                        personal_best_fitness[i] = quantum_fitness\n                        if quantum_fitness < personal_best_fitness[global_best_index]:\n                            global_best_position = quantum_position\n                            global_best_index = i\n\n            # Dynamic adaptation of the population size\n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Enhancing diversity by introducing an adaptive mutation operator based on budget consumption.", "configspace": "", "generation": 19, "fitness": 0.257761308080427, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.258 with standard deviation 0.035. And the mean value of best solutions found was 0.050 (0. is the best).", "error": "", "parent_id": "0a5037bd-ff0a-485f-b56c-6e627759c67c", "metadata": {"aucs": [0.25776592367571927, 0.30006447394909663, 0.2154535266164651], "final_y": [0.00917858203812464, 0.004237729027460996, 0.1376103424396756]}, "mutation_prompt": null}
{"id": "27f0ead0-9991-4080-bd97-d44cb3e73cd6", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n        self.inertia_weight = 0.9  # Inertia weight for velocity update\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                self.alpha = 0.4 + 0.1 * (self.current_evaluations/self.budget)  # Adjusted alpha\n                velocities[i] = self.inertia_weight * velocities[i] + \\  # Added inertia weight\n                                np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) + \\\n                                np.random.rand(self.dim) * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n            \n            # Quantum swarm re-positioning\n            if self.current_evaluations < self.budget:\n                for i in range(self.population_size):\n                    self.beta = 0.5 + (0.5 * self.current_evaluations/self.budget)  # Adaptive beta\n                    quantum_shift = self.beta * (np.random.rand(self.dim) - 0.5)\n                    quantum_position = global_best_position + quantum_shift\n                    quantum_position = np.clip(quantum_position, bounds[:,0], bounds[:,1])\n                    quantum_fitness = func(quantum_position)\n                    self.current_evaluations += 1\n                    \n                    if quantum_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = quantum_position\n                        personal_best_fitness[i] = quantum_fitness\n                        if quantum_fitness < personal_best_fitness[global_best_index]:\n                            global_best_position = quantum_position\n                            global_best_index = i\n\n            # Dynamic adaptation of the population size\n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Introducing an inertia weight parameter to balance exploration and exploitation within the swarm dynamics.", "configspace": "", "generation": 20, "fitness": -Infinity, "feedback": "An exception occurred: SyntaxError('unexpected character after line continuation character', ('<string>', 27, 96, '                velocities[i] = self.inertia_weight * velocities[i] + \\\\  # Added inertia weight\\n')).", "error": "SyntaxError('unexpected character after line continuation character', ('<string>', 27, 96, '                velocities[i] = self.inertia_weight * velocities[i] + \\\\  # Added inertia weight\\n'))", "parent_id": "0a5037bd-ff0a-485f-b56c-6e627759c67c", "metadata": {}, "mutation_prompt": null}
{"id": "93d929d3-f3b4-4174-98da-76ac35769c02", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def levy_flight(self, L):\n        return np.random.randn(self.dim) * (1.0 / (np.abs(np.random.randn()) ** (1.0 / L)))\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                self.alpha = 0.3 + 0.2 * (self.current_evaluations/self.budget)  # Adjusted alpha\n                velocities[i] = self.alpha * velocities[i] + \\\n                                np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) + \\\n                                np.random.rand(self.dim) * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n            \n            # Quantum swarm re-positioning with Levy Flights\n            if self.current_evaluations < self.budget:\n                for i in range(self.population_size):\n                    self.beta = 0.4 + (0.6 * self.current_evaluations/self.budget)  # Adaptive beta\n                    quantum_shift = self.levy_flight(1.5) * self.beta  # Levy flight enhanced\n                    quantum_position = global_best_position + quantum_shift\n                    quantum_position = np.clip(quantum_position, bounds[:,0], bounds[:,1])\n                    quantum_fitness = func(quantum_position)\n                    self.current_evaluations += 1\n                    \n                    if quantum_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = quantum_position\n                        personal_best_fitness[i] = quantum_fitness\n                        if quantum_fitness < personal_best_fitness[global_best_index]:\n                            global_best_position = quantum_position\n                            global_best_index = i\n\n            # Dynamic adaptation of the population size\n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Enhance exploration and exploitation by incorporating Levy flights and adaptive parameter tuning in quantum particle swarm optimization.", "configspace": "", "generation": 21, "fitness": 0.30242113468250564, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.302 with standard deviation 0.056. And the mean value of best solutions found was 0.041 (0. is the best).", "error": "", "parent_id": "0a5037bd-ff0a-485f-b56c-6e627759c67c", "metadata": {"aucs": [0.28894335633052703, 0.37730185114442316, 0.24101819657256673], "final_y": [0.001311296407843909, 3.579451392405238e-05, 0.12181581117152986]}, "mutation_prompt": null}
{"id": "6919964f-28ea-471a-99a9-ad2c10c9cd38", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                self.alpha = 0.4 + 0.1 * (self.current_evaluations/self.budget)  # Adjusted alpha\n                velocities[i] = self.alpha * velocities[i] + \\\n                                np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) + \\\n                                np.random.rand(self.dim) * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n            \n            # Quantum swarm re-positioning\n            if self.current_evaluations < self.budget:\n                for i in range(self.population_size):\n                    self.beta = 0.5 * np.exp(-5 * self.current_evaluations/self.budget)  # Exponential decay for beta\n                    quantum_shift = self.beta * (np.random.rand(self.dim) - 0.5)\n                    quantum_position = global_best_position + quantum_shift\n                    quantum_position = np.clip(quantum_position, bounds[:,0], bounds[:,1])\n                    quantum_fitness = func(quantum_position)\n                    self.current_evaluations += 1\n                    \n                    if quantum_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = quantum_position\n                        personal_best_fitness[i] = quantum_fitness\n                        if quantum_fitness < personal_best_fitness[global_best_index]:\n                            global_best_position = quantum_position\n                            global_best_index = i\n\n            # Dynamic adaptation of the population size\n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Enhancing convergence by adapting beta using exponential decay for quantum shifts.", "configspace": "", "generation": 22, "fitness": 0.27926834131430045, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.279 with standard deviation 0.008. And the mean value of best solutions found was 0.028 (0. is the best).", "error": "", "parent_id": "0a5037bd-ff0a-485f-b56c-6e627759c67c", "metadata": {"aucs": [0.2774850730800842, 0.27007164747313894, 0.2902483033896782], "final_y": [0.00035940771124954733, 0.07081292495662571, 0.012970144883221738]}, "mutation_prompt": null}
{"id": "6ac7ab25-7571-43ec-a86c-8e1b02e68781", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                inertia_weight = 0.9 - 0.5 * (self.current_evaluations / self.budget)  # Added inertia weight\n                self.alpha = 0.4 + 0.1 * (self.current_evaluations/self.budget)  # Adjusted alpha\n                velocities[i] = inertia_weight * velocities[i] + \\\n                                np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) + \\\n                                np.random.rand(self.dim) * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n            \n            # Quantum swarm re-positioning\n            if self.current_evaluations < self.budget:\n                for i in range(self.population_size):\n                    self.beta = 0.5 + (0.5 * self.current_evaluations/self.budget)  # Adaptive beta\n                    quantum_shift = self.beta * (np.random.rand(self.dim) - 0.5)\n                    quantum_position = global_best_position + quantum_shift\n                    quantum_position = np.clip(quantum_position, bounds[:,0], bounds[:,1])\n                    quantum_fitness = func(quantum_position)\n                    self.current_evaluations += 1\n                    \n                    if quantum_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = quantum_position\n                        personal_best_fitness[i] = quantum_fitness\n                        if quantum_fitness < personal_best_fitness[global_best_index]:\n                            global_best_position = quantum_position\n                            global_best_index = i\n\n            # Dynamic adaptation of the population size\n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Enhancing convergence by incorporating an adaptive inertia weight factor based on the current evaluation ratio.", "configspace": "", "generation": 23, "fitness": 0.25698956759101466, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.257 with standard deviation 0.026. And the mean value of best solutions found was 0.008 (0. is the best).", "error": "", "parent_id": "0a5037bd-ff0a-485f-b56c-6e627759c67c", "metadata": {"aucs": [0.262511823638757, 0.22284608350553736, 0.2856107956287496], "final_y": [0.0008395287577666681, 0.022992051433336363, 1.8253258031890972e-05]}, "mutation_prompt": null}
{"id": "f80fcf00-6d9f-4093-afe9-c8296e8bdd46", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                self.alpha = 0.4 + 0.1 * np.sin(np.pi * self.current_evaluations/self.budget)  # Nonlinear alpha\n                velocities[i] = self.alpha * velocities[i] + \\\n                                np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) + \\\n                                np.random.rand(self.dim) * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n            \n            # Quantum swarm re-positioning\n            if self.current_evaluations < self.budget:\n                for i in range(self.population_size):\n                    self.beta = 0.5 + (0.5 * self.current_evaluations/self.budget)  # Adaptive beta\n                    quantum_shift = self.beta * (np.random.rand(self.dim) - 0.5)\n                    quantum_position = global_best_position + quantum_shift\n                    quantum_position = np.clip(quantum_position, bounds[:,0], bounds[:,1])\n                    quantum_fitness = func(quantum_position)\n                    self.current_evaluations += 1\n                    \n                    if quantum_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = quantum_position\n                        personal_best_fitness[i] = quantum_fitness\n                        if quantum_fitness < personal_best_fitness[global_best_index]:\n                            global_best_position = quantum_position\n                            global_best_index = i\n\n            # Dynamic adaptation of the population size\n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Introduce a nonlinear decay for the constriction factor to better balance exploration and exploitation.", "configspace": "", "generation": 24, "fitness": 0.34914889352583317, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.349 with standard deviation 0.045. And the mean value of best solutions found was 0.002 (0. is the best).", "error": "", "parent_id": "0a5037bd-ff0a-485f-b56c-6e627759c67c", "metadata": {"aucs": [0.37202075289293046, 0.28573424834114625, 0.38969167934342275], "final_y": [6.744237359361586e-05, 0.005356886217867209, 4.1596531675596635e-05]}, "mutation_prompt": null}
{"id": "dee6b352-06df-4ec1-85ff-c64b7a818473", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                self.alpha = 0.4 + 0.1 * (self.current_evaluations/self.budget)  # Adjusted alpha\n                velocities[i] = self.alpha * velocities[i] + \\\n                                np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) + \\\n                                np.random.rand(self.dim) * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n            \n            # Quantum swarm re-positioning\n            if self.current_evaluations < self.budget:\n                for i in range(self.population_size):\n                    self.beta = 0.5 + (0.5 * self.current_evaluations/self.budget)  # Adaptive beta\n                    quantum_shift = self.beta * (np.random.rand(self.dim) - 0.5)\n                    quantum_position = global_best_position + quantum_shift\n                    quantum_position = np.clip(quantum_position, bounds[:,0], bounds[:,1])\n                    quantum_fitness = func(quantum_position)\n                    self.current_evaluations += 1\n                    \n                    if quantum_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = quantum_position\n                        personal_best_fitness[i] = quantum_fitness\n                        if quantum_fitness < personal_best_fitness[global_best_index]:\n                            global_best_position = quantum_position\n                            global_best_index = i\n\n            # Dynamic adaptation of the population size\n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            # Mutation for diversity enhancement\n            mutation_prob = 0.05\n            for i in range(self.population_size):\n                if np.random.rand() < mutation_prob:\n                    population[i] += np.random.normal(0, 0.1, self.dim) * (bounds[:,1] - bounds[:,0])\n                    population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Implement mutation-based particle diversity to enhance exploration and prevent local optima entrapment.", "configspace": "", "generation": 25, "fitness": 0.3179565737138685, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.318 with standard deviation 0.039. And the mean value of best solutions found was 0.009 (0. is the best).", "error": "", "parent_id": "0a5037bd-ff0a-485f-b56c-6e627759c67c", "metadata": {"aucs": [0.26707744970657166, 0.36264660181637953, 0.3241456696186543], "final_y": [0.023817490080393827, 0.000621630856353943, 0.002921896806785218]}, "mutation_prompt": null}
{"id": "a0c2a2d4-3fb3-40de-beec-ba73c572fcf5", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                inertia_weight = 0.9 - 0.5 * (self.current_evaluations / self.budget)  # Adaptive inertia weight\n                self.alpha = 0.4 + 0.1 * (self.current_evaluations/self.budget)  # Adjusted alpha\n                velocities[i] = inertia_weight * velocities[i] + \\\n                                np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) + \\\n                                np.random.rand(self.dim) * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n            \n            # Quantum swarm re-positioning\n            if self.current_evaluations < self.budget:\n                for i in range(self.population_size):\n                    self.beta = 0.5 + (0.5 * self.current_evaluations/self.budget)  # Adaptive beta\n                    quantum_shift = self.beta * (np.random.rand(self.dim) - 0.5)\n                    quantum_position = global_best_position + quantum_shift\n                    quantum_position = np.clip(quantum_position, bounds[:,0], bounds[:,1])\n                    quantum_fitness = func(quantum_position)\n                    self.current_evaluations += 1\n                    \n                    if quantum_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = quantum_position\n                        personal_best_fitness[i] = quantum_fitness\n                        if quantum_fitness < personal_best_fitness[global_best_index]:\n                            global_best_position = quantum_position\n                            global_best_index = i\n\n            # Dynamic adaptation of the population size\n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Introducing adaptive inertia weight to improve convergence speed in early stages.", "configspace": "", "generation": 26, "fitness": 0.27815997676675613, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.278 with standard deviation 0.045. And the mean value of best solutions found was 0.018 (0. is the best).", "error": "", "parent_id": "0a5037bd-ff0a-485f-b56c-6e627759c67c", "metadata": {"aucs": [0.21559931028332568, 0.30181272487328226, 0.3170678951436605], "final_y": [0.05296003537255961, 0.0009326366172667936, 1.3047377932438048e-05]}, "mutation_prompt": null}
{"id": "217b8571-885e-47a0-bdd0-30762a0b9f92", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                self.alpha = 0.4 + 0.1 * (self.current_evaluations/self.budget)  # Adjusted alpha\n                velocities[i] = self.alpha * velocities[i] + \\\n                                np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) + \\\n                                np.random.rand(self.dim) * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n            \n            # Quantum swarm re-positioning\n            if self.current_evaluations < self.budget:\n                for i in range(self.population_size):\n                    self.beta = 0.5 + (0.5 * self.current_evaluations/self.budget)  # Adaptive beta\n                    quantum_shift = self.beta * (np.random.rand(self.dim) - 0.5)\n                    quantum_position = global_best_position + quantum_shift\n                    quantum_position = np.clip(quantum_position, bounds[:,0], bounds[:,1])\n                    quantum_fitness = func(quantum_position)\n                    self.current_evaluations += 1\n                    \n                    if quantum_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = quantum_position\n                        personal_best_fitness[i] = quantum_fitness\n                        if quantum_fitness < personal_best_fitness[global_best_index]:\n                            global_best_position = quantum_position\n                            global_best_index = i\n\n            # Random restart mechanism for diversity\n            if self.current_evaluations % (self.budget // 10) == 0:  \n                population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0] \n\n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Enhance particle diversity and convergence by introducing random restart and adaptive cognitive component in the swarm mechanism.", "configspace": "", "generation": 27, "fitness": 0.30937801165143813, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.309 with standard deviation 0.015. And the mean value of best solutions found was 0.004 (0. is the best).", "error": "", "parent_id": "0a5037bd-ff0a-485f-b56c-6e627759c67c", "metadata": {"aucs": [0.3302803328920484, 0.3036779709126741, 0.29417573114959195], "final_y": [0.0023915388854967483, 0.0027373799397027044, 0.007256713891920283]}, "mutation_prompt": null}
{"id": "a71e0f76-6263-4ffa-b7dc-9639ab1c9594", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                # Modification 1: Adjusted alpha to enhance exploration\n                self.alpha = 0.3 + 0.2 * (self.current_evaluations/self.budget)\n                velocities[i] = self.alpha * velocities[i] + \\\n                                np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) + \\\n                                np.random.rand(self.dim) * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n            \n            # Modification 2: Removed quantum swarm repositioning for simplicity\n            # if self.current_evaluations < self.budget:\n            #     for i in range(self.population_size):\n            #         self.beta = 0.5 + (0.5 * self.current_evaluations/self.budget)  # Adaptive beta\n            #         quantum_shift = self.beta * (np.random.rand(self.dim) - 0.5)\n            #         quantum_position = global_best_position + quantum_shift\n            #         quantum_position = np.clip(quantum_position, bounds[:,0], bounds[:,1])\n            #         quantum_fitness = func(quantum_position)\n            #         self.current_evaluations += 1\n                    \n            #         if quantum_fitness < personal_best_fitness[i]:\n            #             personal_best_positions[i] = quantum_position\n            #             personal_best_fitness[i] = quantum_fitness\n            #             if quantum_fitness < personal_best_fitness[global_best_index]:\n            #                 global_best_position = quantum_position\n            #                 global_best_index = i\n\n            # Dynamic adaptation of the population size\n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Enhanced exploration via adaptive constriction and mutation rate for improved optimization.", "configspace": "", "generation": 28, "fitness": 0.45992381973361524, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.460 with standard deviation 0.222. And the mean value of best solutions found was 0.336 (0. is the best).", "error": "", "parent_id": "0a5037bd-ff0a-485f-b56c-6e627759c67c", "metadata": {"aucs": [0.675993044953432, 0.5491108015562487, 0.1546676126911648], "final_y": [1.2979684766193942e-10, 9.380646817836127e-07, 1.0090232765443163]}, "mutation_prompt": null}
{"id": "8fa79f2e-7557-4d63-b525-01b2292714c2", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n        self.inertia_weight = 0.9  # Initial inertia weight\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                # Modification 1: Adjusted alpha to enhance exploration\n                self.alpha = 0.3 + 0.2 * (self.current_evaluations/self.budget)\n                self.inertia_weight = 0.9 - (0.5 * self.current_evaluations/self.budget)  # Adaptive inertia\n                velocities[i] = self.inertia_weight * velocities[i] + \\\n                                np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) + \\\n                                np.random.rand(self.dim) * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n\n            # Dynamic adaptation of the population size\n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Improved local search by integrating adaptive inertia to balance exploration and exploitation.", "configspace": "", "generation": 29, "fitness": 0.24309842958575442, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.243 with standard deviation 0.085. And the mean value of best solutions found was 0.429 (0. is the best).", "error": "", "parent_id": "a71e0f76-6263-4ffa-b7dc-9639ab1c9594", "metadata": {"aucs": [0.36029418102941024, 0.20858462505593323, 0.16041648267191977], "final_y": [2.2309883232506273e-06, 0.29688149481821596, 0.9909755538170557]}, "mutation_prompt": null}
{"id": "9359cd86-d52b-4272-8c17-fcb7f6c8b1b1", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                self.alpha = 0.3 + 0.2 * (self.current_evaluations/self.budget)\n                velocities[i] = self.alpha * (2 * velocities[i] * np.random.rand(self.dim)) / (velocities[i] + np.random.rand(self.dim)) + \\\n                                np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) + \\\n                                np.random.rand(self.dim) * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n            \n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Enhanced particle update rule with a harmonic mean velocity for improved convergence.", "configspace": "", "generation": 30, "fitness": 0.24808742483008575, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.248 with standard deviation 0.077. And the mean value of best solutions found was 0.189 (0. is the best).", "error": "", "parent_id": "a71e0f76-6263-4ffa-b7dc-9639ab1c9594", "metadata": {"aucs": [0.2197467648111303, 0.3534622375025256, 0.17105327217660138], "final_y": [0.28640193026517063, 0.008630474988795262, 0.2706096552248153]}, "mutation_prompt": null}
{"id": "d2c87982-c4b4-4f06-b1c9-9e3a0ae38647", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                # Modification 1: Adjusted alpha to enhance exploration\n                self.alpha = 0.3 + 0.2 * (self.current_evaluations/self.budget)\n                # Modification 2: Added adaptive inertia weight\n                inertia_weight = 0.9 - 0.5 * (self.current_evaluations / self.budget)\n                velocities[i] = inertia_weight * velocities[i] + \\\n                                np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) + \\\n                                np.random.rand(self.dim) * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n            \n            # Dynamic adaptation of the population size\n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Introduced adaptive personal inertia weight to balance exploration and exploitation in the quantum swarm optimization.", "configspace": "", "generation": 31, "fitness": 0.3236313090847098, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.324 with standard deviation 0.026. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "a71e0f76-6263-4ffa-b7dc-9639ab1c9594", "metadata": {"aucs": [0.33795742490280734, 0.34624725150062763, 0.2866892508506943], "final_y": [0.0005177839913725837, 1.6116085462649295e-06, 0.00028973113120929353]}, "mutation_prompt": null}
{"id": "7e141f4c-8247-4bcb-96ef-c34d378e70aa", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            velocity_scale = 0.9 - 0.4 * (self.current_evaluations / self.budget)  # New dynamic velocity scaling\n            for i in range(self.population_size):\n                self.alpha = 0.3 + 0.2 * (self.current_evaluations/self.budget)\n                velocities[i] = velocity_scale * (self.alpha * velocities[i] +  # Apply velocity scaling\n                                np.random.rand(self.dim) * (personal_best_positions[i] - population[i]) + \n                                np.random.rand(self.dim) * (global_best_position - population[i]))\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n            \n            if self.current_evaluations % (self.budget // 10) == 0:  # Periodic quantum shifts\n                for i in range(self.population_size):\n                    quantum_shift = self.beta * (np.random.rand(self.dim) - 0.5)\n                    quantum_position = global_best_position + quantum_shift\n                    quantum_position = np.clip(quantum_position, bounds[:,0], bounds[:,1])\n                    quantum_fitness = func(quantum_position)\n                    self.current_evaluations += 1\n                    \n                    if quantum_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = quantum_position\n                        personal_best_fitness[i] = quantum_fitness\n                        if quantum_fitness < personal_best_fitness[global_best_index]:\n                            global_best_position = quantum_position\n                            global_best_index = i\n\n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Introduced dynamic velocity scaling and periodic quantum shifts to improve convergence and exploration in particle swarm optimization.", "configspace": "", "generation": 32, "fitness": 0.45702180650425833, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.457 with standard deviation 0.095. And the mean value of best solutions found was 0.002 (0. is the best).", "error": "", "parent_id": "a71e0f76-6263-4ffa-b7dc-9639ab1c9594", "metadata": {"aucs": [0.41059369833002846, 0.37139952278063604, 0.5890721984021106], "final_y": [0.0011813105519636023, 0.0038803479688661584, 9.393949099877895e-07]}, "mutation_prompt": null}
{"id": "b5d6c111-efd8-4b2b-8a2c-98b13a3a6469", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                self.alpha = 0.3 + 0.2 * (self.current_evaluations/self.budget)  # Dynamic inertia\n                c1 = 1.5  # Personal acceleration coefficient\n                c2 = 1.5 + (self.current_evaluations/self.budget)  # Dynamic social acceleration\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.alpha * velocities[i] + \\\n                                c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                c2 * r2 * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n            \n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Introduced dynamic inertia and social acceleration to enhance convergence and diversity balance.", "configspace": "", "generation": 33, "fitness": 0.5394479975150176, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.539 with standard deviation 0.029. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "a71e0f76-6263-4ffa-b7dc-9639ab1c9594", "metadata": {"aucs": [0.5237561890351413, 0.5796274084251782, 0.5149603950847331], "final_y": [3.949709331848306e-06, 2.269967193158426e-08, 2.5601132943161943e-07]}, "mutation_prompt": null}
{"id": "19f45f82-e091-435f-8091-d29fff581b03", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                self.alpha = 0.3 + 0.2 * (self.current_evaluations/self.budget)  # Dynamic inertia\n                c1 = 1.5  # Personal acceleration coefficient\n                c2 = 1.5 + (self.current_evaluations/self.budget)  # Dynamic social acceleration\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.alpha * velocities[i] + \\\n                                c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                c2 * r2 * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n            \n            self.beta = 0.5 + 0.1 * np.sin(2 * np.pi * self.current_evaluations / self.budget)  # Dynamic beta\n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Introduced adaptive quantum position shift factor to further balance exploration and exploitation.", "configspace": "", "generation": 34, "fitness": 0.4814482955951141, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.481 with standard deviation 0.020. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "b5d6c111-efd8-4b2b-8a2c-98b13a3a6469", "metadata": {"aucs": [0.4525192480221114, 0.49719719600903045, 0.4946284427542005], "final_y": [1.052337780548669e-06, 6.47822987578786e-07, 6.949884642899745e-07]}, "mutation_prompt": null}
{"id": "d02c32ce-52ff-4ad7-9be8-497394672a0b", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                self.alpha = 0.3 + 0.15 * (self.current_evaluations/self.budget)  # Adjusted dynamic inertia\n                c1 = 1.5  # Personal acceleration coefficient\n                c2 = 1.5 + (self.current_evaluations/self.budget)  # Dynamic social acceleration\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.alpha * velocities[i] + \\\n                                c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                c2 * r2 * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n\n            # Introduced local restart mechanism for better exploration\n            if self.current_evaluations % (self.budget // 5) == 0:\n                restart_indices = np.random.choice(self.population_size, self.population_size // 5, replace=False)\n                population[restart_indices] = np.random.rand(len(restart_indices), self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n\n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Enhanced exploration by dynamically adjusting the constriction factor and introduced a local restart mechanism.", "configspace": "", "generation": 35, "fitness": 0.43382648555707776, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.434 with standard deviation 0.087. And the mean value of best solutions found was 0.006 (0. is the best).", "error": "", "parent_id": "b5d6c111-efd8-4b2b-8a2c-98b13a3a6469", "metadata": {"aucs": [0.43651451366648353, 0.3257355635961424, 0.5392293794086075], "final_y": [4.86801010246553e-05, 0.017780850586961928, 4.1183656621473926e-08]}, "mutation_prompt": null}
{"id": "0ac3b5ed-a451-455a-881a-2b3eabe44caa", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                self.alpha = 0.3 + 0.2 * (self.current_evaluations/self.budget)  # Dynamic inertia\n                c1 = 1.5  # Personal acceleration coefficient\n                c2 = 1.5 + (self.current_evaluations/self.budget)  # Dynamic social acceleration\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.alpha * velocities[i] + \\\n                                c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                c2 * r2 * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n\n            # Local search around global best\n            local_perturbation = np.random.normal(scale=0.1, size=self.dim)  # Size of perturbation\n            candidate_position = np.clip(global_best_position + local_perturbation, bounds[:,0], bounds[:,1])\n            candidate_fitness = func(candidate_position)\n            self.current_evaluations += 1\n            \n            if candidate_fitness < personal_best_fitness[global_best_index]:\n                global_best_position = candidate_position\n                global_best_index = np.argmin(personal_best_fitness)\n            \n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Enhanced convergence precision by incorporating local search around the global best position using random perturbations.", "configspace": "", "generation": 36, "fitness": 0.6428081738469278, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.643 with standard deviation 0.027. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "b5d6c111-efd8-4b2b-8a2c-98b13a3a6469", "metadata": {"aucs": [0.6308514697814127, 0.6803697835099013, 0.6172032682494695], "final_y": [2.93029721097033e-09, 1.8794834106609196e-10, 1.2434470077291766e-09]}, "mutation_prompt": null}
{"id": "53a14089-29ce-4aba-b890-8302c75171f9", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                self.alpha = 0.3 + 0.2 * (self.current_evaluations/self.budget)  # Dynamic inertia\n                c1 = 1.5  # Personal acceleration coefficient\n                c2 = 1.5 + (self.current_evaluations/self.budget)  # Dynamic social acceleration\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.alpha * velocities[i] + \\\n                                c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                c2 * r2 * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n\n            # Local search around global best with adaptive mutation\n            mutation_scale = np.linspace(0.1, 0.01, self.budget)  # Adaptive mutation scale\n            local_perturbation = np.random.normal(scale=mutation_scale[self.current_evaluations], size=self.dim)\n            candidate_position = np.clip(global_best_position + local_perturbation, bounds[:,0], bounds[:,1])\n            candidate_fitness = func(candidate_position)\n            self.current_evaluations += 1\n            \n            if candidate_fitness < personal_best_fitness[global_best_index]:\n                global_best_position = candidate_position\n                global_best_index = np.argmin(personal_best_fitness)\n            \n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Enhanced convergence by integrating adaptive mutation during local search to diversify exploration.", "configspace": "", "generation": 37, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 1000 is out of bounds for axis 0 with size 1000').", "error": "IndexError('index 1000 is out of bounds for axis 0 with size 1000')", "parent_id": "0ac3b5ed-a451-455a-881a-2b3eabe44caa", "metadata": {}, "mutation_prompt": null}
{"id": "9c55a80b-7fa7-4e79-8fe3-d46e5b5799c7", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                self.alpha = 0.3 + 0.2 * (self.current_evaluations/self.budget)  # Dynamic inertia\n                c1 = 1.5  # Personal acceleration coefficient\n                c2 = 1.5 + (self.current_evaluations/self.budget)  # Dynamic social acceleration\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.alpha * velocities[i] + \\\n                                c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                c2 * r2 * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n\n            # Dual local search\n            local_perturbation_1 = np.random.normal(scale=0.05, size=self.dim) \n            candidate_position_1 = np.clip(global_best_position + local_perturbation_1, bounds[:,0], bounds[:,1])\n            candidate_fitness_1 = func(candidate_position_1)\n            self.current_evaluations += 1\n            \n            if candidate_fitness_1 < personal_best_fitness[global_best_index]:\n                global_best_position = candidate_position_1\n                global_best_index = np.argmin(personal_best_fitness)\n            \n            local_perturbation_2 = np.random.normal(scale=0.05, size=self.dim)  \n            candidate_position_2 = np.clip(global_best_position + local_perturbation_2, bounds[:,0], bounds[:,1])\n            candidate_fitness_2 = func(candidate_position_2)\n            self.current_evaluations += 1\n            \n            if candidate_fitness_2 < personal_best_fitness[global_best_index]:\n                global_best_position = candidate_position_2\n                global_best_index = np.argmin(personal_best_fitness)\n            \n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Introduced dual local searches around the best positions to improve exploration and exploitation balance.", "configspace": "", "generation": 38, "fitness": 0.33331569819602047, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.333 with standard deviation 0.052. And the mean value of best solutions found was 0.033 (0. is the best).", "error": "", "parent_id": "0ac3b5ed-a451-455a-881a-2b3eabe44caa", "metadata": {"aucs": [0.2644556011562368, 0.3446107000746317, 0.39088079335719295], "final_y": [0.09713972232690214, 0.0007859594834567849, 0.00018311134811342585]}, "mutation_prompt": null}
{"id": "00999641-5e05-4316-a062-0257a57149e0", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                self.alpha = 0.3 + 0.2 * (self.current_evaluations/self.budget)  # Dynamic inertia\n                c1 = 1.5  # Personal acceleration coefficient\n                c2 = 1.5 + (self.current_evaluations/self.budget)  # Dynamic social acceleration\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.alpha * velocities[i] + \\\n                                c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                c2 * r2 * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n\n            # Local search around global best\n            perturbation_scale = 0.1 * (1 - self.current_evaluations / self.budget)  # Dynamic perturbation scale\n            local_perturbation = np.random.normal(scale=perturbation_scale, size=self.dim)\n            candidate_position = np.clip(global_best_position + local_perturbation, bounds[:,0], bounds[:,1])\n            candidate_fitness = func(candidate_position)\n            self.current_evaluations += 1\n            \n            if candidate_fitness < personal_best_fitness[global_best_index]:\n                global_best_position = candidate_position\n                global_best_index = np.argmin(personal_best_fitness)\n            \n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Improved convergence by integrating dynamic adjustment of local search perturbation scale based on current evaluations.", "configspace": "", "generation": 39, "fitness": 0.45063569178268886, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.451 with standard deviation 0.005. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "0ac3b5ed-a451-455a-881a-2b3eabe44caa", "metadata": {"aucs": [0.45686486116662506, 0.44521376284961356, 0.44982845133182814], "final_y": [3.80524016249442e-07, 7.907554527381042e-06, 5.89582773801093e-07]}, "mutation_prompt": null}
{"id": "efa0c2df-b062-4d3d-949c-92b621bf5bf4", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                self.alpha = 0.3 + 0.2 * (self.current_evaluations/self.budget)  # Dynamic inertia\n                c1 = 1.5  # Personal acceleration coefficient\n                c2 = 1.5 + (self.current_evaluations/self.budget)  # Dynamic social acceleration\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.alpha * velocities[i] + \\\n                                c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                c2 * r2 * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n\n            # Local search around global best\n            local_perturbation = np.random.normal(scale=0.1 * (1 - self.current_evaluations/self.budget), size=self.dim)\n            candidate_position = np.clip(global_best_position + local_perturbation, bounds[:,0], bounds[:,1])\n            candidate_fitness = func(candidate_position)\n            self.current_evaluations += 1\n            \n            if candidate_fitness < personal_best_fitness[global_best_index]:\n                global_best_position = candidate_position\n            \n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Enhanced exploration by dynamically adjusting the range of local perturbations and refining the global best update condition.", "configspace": "", "generation": 40, "fitness": 0.47776174529803433, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.478 with standard deviation 0.018. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "0ac3b5ed-a451-455a-881a-2b3eabe44caa", "metadata": {"aucs": [0.4516291974296669, 0.48995536561373365, 0.4917006728507026], "final_y": [4.479783578946148e-07, 4.1717538205853814e-07, 2.6890052028698237e-06]}, "mutation_prompt": null}
{"id": "5845e1c8-8446-422b-bb1c-d07197a693d8", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                self.alpha = 0.3 + 0.2 * (self.current_evaluations/self.budget)  # Dynamic inertia\n                c1 = 1.5  # Personal acceleration coefficient\n                c2 = 1.5 + (self.current_evaluations/self.budget)  # Dynamic social acceleration\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.alpha * velocities[i] + \\\n                                c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                c2 * r2 * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n\n            # Local search around global best\n            local_perturbation = np.random.normal(scale=0.1, size=self.dim)  # Size of perturbation\n            candidate_position = np.clip(global_best_position + local_perturbation, bounds[:,0], bounds[:,1])\n            candidate_fitness = func(candidate_position)\n            self.current_evaluations += 1\n            \n            if candidate_fitness < personal_best_fitness[global_best_index]:\n                global_best_position = candidate_position\n                global_best_index = np.argmin(personal_best_fitness)\n            \n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Enhanced convergence precision by incorporating local search around the global best position using random perturbations and dynamic constriction factor.", "configspace": "", "generation": 41, "fitness": 0.5119389189635952, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.512 with standard deviation 0.016. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "0ac3b5ed-a451-455a-881a-2b3eabe44caa", "metadata": {"aucs": [0.5207491900363145, 0.48995536561373365, 0.5251122012407375], "final_y": [2.0990121095828123e-08, 4.1717538205853814e-07, 6.625590680111827e-08]}, "mutation_prompt": null}
{"id": "088cc184-9b73-4dde-a34e-b0530f43d0a8", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                self.alpha = 0.3 + 0.25 * (self.current_evaluations/self.budget)  # Dynamic inertia\n                c1 = 1.7  # Personal acceleration coefficient\n                c2 = 1.6 + (self.current_evaluations/self.budget)  # Dynamic social acceleration\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.alpha * velocities[i] + \\\n                                c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                c2 * r2 * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n\n            # Local search around global best\n            local_perturbation = np.random.normal(scale=0.05, size=self.dim)  # Size of perturbation\n            candidate_position = np.clip(global_best_position + local_perturbation, bounds[:,0], bounds[:,1])\n            candidate_fitness = func(candidate_position)\n            self.current_evaluations += 1\n            \n            if candidate_fitness < personal_best_fitness[global_best_index]:\n                global_best_position = candidate_position\n                global_best_index = np.argmin(personal_best_fitness)\n            \n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Augmented dynamic parameters and enhanced local search precision around the global best for improved adaptation and convergence.", "configspace": "", "generation": 42, "fitness": 0.46216493975909484, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.462 with standard deviation 0.024. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "0ac3b5ed-a451-455a-881a-2b3eabe44caa", "metadata": {"aucs": [0.4338479425568219, 0.46116724641428, 0.4914796303061827], "final_y": [3.9416089502318876e-05, 1.9899619440418884e-05, 3.543356865522801e-07]}, "mutation_prompt": null}
{"id": "cb20e9fb-acb7-4608-9f21-1770f4a9983f", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            diversity = np.std(population, axis=0) / (bounds[:,1] - bounds[:,0])  # Calculate diversity\n            adaptive_bounds = bounds + diversity * (bounds[:,1] - bounds[:,0])  # Calculate adaptive boundaries\n\n            for i in range(self.population_size):\n                self.alpha = 0.3 + 0.2 * (self.current_evaluations/self.budget)  # Dynamic inertia\n                c1 = 1.5  # Personal acceleration coefficient\n                c2 = 1.5 + (self.current_evaluations/self.budget)  # Dynamic social acceleration\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.alpha * velocities[i] + \\\n                                c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                c2 * r2 * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], adaptive_bounds[:,0], adaptive_bounds[:,1])  # Use adaptive bounds\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n\n            local_perturbation = np.random.normal(scale=0.1, size=self.dim)  # Size of perturbation\n            candidate_position = np.clip(global_best_position + local_perturbation, bounds[:,0], bounds[:,1])\n            candidate_fitness = func(candidate_position)\n            self.current_evaluations += 1\n            \n            if candidate_fitness < personal_best_fitness[global_best_index]:\n                global_best_position = candidate_position\n                global_best_index = np.argmin(personal_best_fitness)\n            \n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Enhanced exploration by introducing adaptive boundary scaling based on population diversity.", "configspace": "", "generation": 43, "fitness": 0.5028475602039753, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.503 with standard deviation 0.018. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "0ac3b5ed-a451-455a-881a-2b3eabe44caa", "metadata": {"aucs": [0.5017662876253082, 0.48166419174588004, 0.5251122012407375], "final_y": [5.642482903713826e-08, 1.2271432550552096e-08, 6.625590680111827e-08]}, "mutation_prompt": null}
{"id": "ac0d7c8a-b5bc-4fd2-a18b-5b516b8f4fa3", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                self.alpha = 0.3 + 0.2 * (self.current_evaluations/self.budget)  # Dynamic inertia\n                c1 = 1.5  # Personal acceleration coefficient\n                c2 = 1.5 + (self.current_evaluations/self.budget)  # Dynamic social acceleration\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.alpha * velocities[i] + \\\n                                c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                c2 * r2 * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n\n            # Local search around global best\n            local_perturbation = np.random.normal(scale=0.05, size=self.dim)  # Size of perturbation\n            candidate_position = np.clip(global_best_position + local_perturbation, bounds[:,0], bounds[:,1])\n            candidate_fitness = func(candidate_position)\n            self.current_evaluations += 1\n            \n            if candidate_fitness < personal_best_fitness[global_best_index]:\n                global_best_position = candidate_position\n                global_best_index = np.argmin(personal_best_fitness)\n            \n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Enhanced convergence by changing perturbation scale to 0.05 for finer local search.", "configspace": "", "generation": 44, "fitness": 0.5200495861450879, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.520 with standard deviation 0.039. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "0ac3b5ed-a451-455a-881a-2b3eabe44caa", "metadata": {"aucs": [0.5080888967294298, 0.4790330066565842, 0.5730268550492499], "final_y": [2.05397829194479e-08, 3.024955377262168e-08, 1.3228298609893764e-08]}, "mutation_prompt": null}
{"id": "2bb85895-f8bf-4aab-b475-58d4170a4938", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                self.alpha = 0.3 + 0.2 * (self.current_evaluations/self.budget)  # Dynamic inertia\n                c1 = 1.5  # Personal acceleration coefficient\n                c2 = 1.5 + (self.current_evaluations/self.budget)  # Dynamic social acceleration\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.alpha * velocities[i] + \\\n                                c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                c2 * r2 * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n\n            # Local search around global best\n            local_perturbation = np.random.normal(scale=0.1 * (1 - self.current_evaluations/self.budget), size=self.dim)  # Size of perturbation\n            candidate_position = np.clip(global_best_position + local_perturbation, bounds[:,0], bounds[:,1])\n            candidate_fitness = func(candidate_position)\n            self.current_evaluations += 1\n            \n            if candidate_fitness < personal_best_fitness[global_best_index]:\n                global_best_position = candidate_position\n                global_best_index = np.argmin(personal_best_fitness)\n            \n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Enhanced convergence by tuning perturbation scale dynamically based on evaluations.", "configspace": "", "generation": 45, "fitness": 0.47776174529803433, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.478 with standard deviation 0.018. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "0ac3b5ed-a451-455a-881a-2b3eabe44caa", "metadata": {"aucs": [0.4516291974296669, 0.48995536561373365, 0.4917006728507026], "final_y": [4.479783578946148e-07, 4.1717538205853814e-07, 2.6890052028698237e-06]}, "mutation_prompt": null}
{"id": "bca67fab-780b-46d6-8446-82524cbe1f3d", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                self.alpha = 0.3 + 0.2 * (self.current_evaluations/self.budget)  # Dynamic inertia\n                c1 = 1.5  # Personal acceleration coefficient\n                c2 = 1.5 + (self.current_evaluations/self.budget)  # Dynamic social acceleration\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.alpha * velocities[i] + \\\n                                c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                c2 * r2 * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n\n            # Local search around global best\n            local_perturbation = np.random.normal(scale=0.1, size=self.dim)  # Size of perturbation\n            candidate_position = np.clip(global_best_position + local_perturbation, bounds[:,0], bounds[:,1])\n            candidate_fitness = func(candidate_position)\n            self.current_evaluations += 1\n            \n            if candidate_fitness < personal_best_fitness[global_best_index]:\n                global_best_position = candidate_position\n                global_best_index = np.argmin(personal_best_fitness)\n            \n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n            self.beta = 0.5 + 0.5 * (self.current_evaluations/self.budget)  # Dynamic position shift factor\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Introduced adaptive quantum position shift factor to enhance exploration-exploitation balance dynamically.", "configspace": "", "generation": 46, "fitness": 0.5119389189635952, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.512 with standard deviation 0.016. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "0ac3b5ed-a451-455a-881a-2b3eabe44caa", "metadata": {"aucs": [0.5207491900363145, 0.48995536561373365, 0.5251122012407375], "final_y": [2.0990121095828123e-08, 4.1717538205853814e-07, 6.625590680111827e-08]}, "mutation_prompt": null}
{"id": "55479e25-4af0-4c30-bd6b-d4b96db0b6da", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Change 1: Increase initial population size slightly\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)\n        self.alpha = 0.5\n        self.beta = 0.5\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                self.alpha = 0.3 + 0.2 * (self.current_evaluations/self.budget)  # Dynamic inertia\n                c1 = 1.5\n                c2 = 1.5 + (self.current_evaluations/self.budget)\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.alpha * velocities[i] + \\\n                                c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                c2 * r2 * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n\n            # Enhanced local search around global best\n            local_perturbation = np.random.normal(scale=0.05, size=self.dim)  # Change 2: Alter perturbation scale\n            candidate_position = np.clip(global_best_position + local_perturbation, bounds[:,0], bounds[:,1])\n            candidate_fitness = func(candidate_position)\n            self.current_evaluations += 1\n            \n            if candidate_fitness < personal_best_fitness[global_best_index]:\n                global_best_position = candidate_position\n                global_best_index = np.argmin(personal_best_fitness)\n            \n            self.population_size = max(1, int(8 * self.dim * (1 - self.current_evaluations / self.budget)))  # Change 3: Adjust population size decay rate\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Improved convergence precision through adaptive parameter tuning and enhanced local search strategy.", "configspace": "", "generation": 47, "fitness": 0.5890530039642433, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.589 with standard deviation 0.019. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "0ac3b5ed-a451-455a-881a-2b3eabe44caa", "metadata": {"aucs": [0.6113069620964728, 0.5659611704116417, 0.5898908793846153], "final_y": [5.6466406688078815e-09, 4.891236314757012e-07, 1.3415906912728752e-08]}, "mutation_prompt": null}
{"id": "11317e7a-0590-49c8-95a9-c06ab38f2323", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                self.alpha = 0.3 + 0.2 * (self.current_evaluations/self.budget)  # Dynamic inertia\n                c1 = 1.5  # Personal acceleration coefficient\n                c2 = 1.5 + (self.current_evaluations/self.budget)  # Dynamic social acceleration\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.alpha * velocities[i] + \\\n                                c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                c2 * r2 * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n\n            # Local search around global best\n            scale_factor = 0.1 * (1 - self.current_evaluations/self.budget)  # Adaptive scaling\n            local_perturbation = np.random.normal(scale=scale_factor, size=self.dim)  # Size of perturbation\n            candidate_position = np.clip(global_best_position + local_perturbation, bounds[:,0], bounds[:,1])\n            candidate_fitness = func(candidate_position)\n            self.current_evaluations += 1\n            \n            if candidate_fitness < personal_best_fitness[global_best_index]:\n                global_best_position = candidate_position\n                global_best_index = np.argmin(personal_best_fitness)\n            \n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Enhanced local search efficiency by using adaptive scaling for perturbations around the global best.", "configspace": "", "generation": 48, "fitness": 0.5102617178728315, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.510 with standard deviation 0.005. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "0ac3b5ed-a451-455a-881a-2b3eabe44caa", "metadata": {"aucs": [0.5041172395466413, 0.5159379661370554, 0.5107299479347975], "final_y": [3.6703460001449325e-07, 1.3335219580371948e-07, 8.944504410027877e-08]}, "mutation_prompt": null}
{"id": "35010108-94a8-4ea5-8e4e-485f3a9af058", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                self.alpha = 0.3 + 0.2 * (self.current_evaluations/self.budget)  # Dynamic inertia\n                c1 = 1.5  # Personal acceleration coefficient\n                c2 = 1.5 + (self.current_evaluations/self.budget)  # Dynamic social acceleration\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.alpha * velocities[i] + \\\n                                c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                c2 * r2 * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n\n            # Local search around global best\n            local_perturbation = np.random.normal(scale=0.1 - 0.05 * (self.current_evaluations/self.budget), size=self.dim)  # Adaptive perturbation\n            candidate_position = np.clip(global_best_position + local_perturbation, bounds[:,0], bounds[:,1])\n            candidate_fitness = func(candidate_position)\n            self.current_evaluations += 1\n            \n            if candidate_fitness < personal_best_fitness[global_best_index]:\n                global_best_position = candidate_position\n                global_best_index = np.argmin(personal_best_fitness)\n            \n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Enhanced local search through adaptive perturbation and refined velocity update mechanism to improve convergence precision.", "configspace": "", "generation": 49, "fitness": 0.47984649321353484, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.480 with standard deviation 0.010. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "0ac3b5ed-a451-455a-881a-2b3eabe44caa", "metadata": {"aucs": [0.48350760612144417, 0.48995536561373365, 0.46607650790542654], "final_y": [6.58118116089336e-08, 4.1717538205853814e-07, 2.3777456468286577e-06]}, "mutation_prompt": null}
{"id": "f50e0087-b03b-4578-8cdf-ec9c808e9d58", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            fitness_diversity = np.std(personal_best_fitness) / (np.mean(personal_best_fitness) + 1e-9)  # Line changed\n            for i in range(self.population_size):\n                self.alpha = 0.3 + 0.2 * (self.current_evaluations/self.budget)  # Dynamic inertia\n                c1 = 1.5  # Personal acceleration coefficient\n                c2 = 1.5 + (self.current_evaluations/self.budget)  # Dynamic social acceleration\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.alpha * velocities[i] + \\\n                                c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                c2 * r2 * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n\n            # Local search around global best\n            local_perturbation = np.random.normal(scale=0.1 * (1 + fitness_diversity), size=self.dim)  # Line changed\n            candidate_position = np.clip(global_best_position + local_perturbation, bounds[:,0], bounds[:,1])\n            candidate_fitness = func(candidate_position)\n            self.current_evaluations += 1\n            \n            if candidate_fitness < personal_best_fitness[global_best_index]:\n                global_best_position = candidate_position\n                global_best_index = np.argmin(personal_best_fitness)\n            \n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Enhanced convergence precision by introducing adaptive mutation based on fitness diversity.", "configspace": "", "generation": 50, "fitness": 0.5497836446031265, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.550 with standard deviation 0.044. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "0ac3b5ed-a451-455a-881a-2b3eabe44caa", "metadata": {"aucs": [0.5663007661744146, 0.48995536561373365, 0.5930948020212312], "final_y": [7.27976465116681e-08, 4.1717538205853814e-07, 6.235343227872968e-09]}, "mutation_prompt": null}
{"id": "f0bbc8bc-a56d-475f-89b7-c369c63822db", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                self.alpha = 0.3 + 0.2 * (self.current_evaluations/self.budget)  # Dynamic inertia\n                c1 = 1.5  # Personal acceleration coefficient\n                c2 = 1.5 + (self.current_evaluations/self.budget)  # Dynamic social acceleration\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.alpha * velocities[i] + \\\n                                c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                c2 * r2 * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n\n            # Adaptive local search around global best\n            local_perturbation = np.random.normal(scale=0.1 * (1 - self.current_evaluations/self.budget), size=self.dim)\n            candidate_position = np.clip(global_best_position + local_perturbation, bounds[:,0], bounds[:,1])\n            candidate_fitness = func(candidate_position)\n            self.current_evaluations += 1\n            \n            if candidate_fitness < personal_best_fitness[global_best_index]:\n                global_best_position = candidate_position\n                global_best_index = np.argmin(personal_best_fitness)\n            \n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Improved global exploration by introducing adaptive quantum perturbation near the global best position.", "configspace": "", "generation": 51, "fitness": 0.47776174529803433, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.478 with standard deviation 0.018. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "0ac3b5ed-a451-455a-881a-2b3eabe44caa", "metadata": {"aucs": [0.4516291974296669, 0.48995536561373365, 0.4917006728507026], "final_y": [4.479783578946148e-07, 4.1717538205853814e-07, 2.6890052028698237e-06]}, "mutation_prompt": null}
{"id": "751aa82f-b2a0-46bf-84aa-0f5122f97c5f", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                self.alpha = 0.3 + 0.2 * (self.current_evaluations/self.budget)  # Dynamic inertia\n                c1 = 1.5  # Personal acceleration coefficient\n                c2 = 1.5 + (self.current_evaluations/self.budget)  # Dynamic social acceleration\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.alpha * velocities[i] + \\\n                                c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                c2 * r2 * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n\n            # Local search around global best\n            local_perturbation = np.random.normal(scale=0.1 * (1 - self.current_evaluations/self.budget), size=self.dim)  # Dynamic perturbation scale\n            candidate_position = np.clip(global_best_position + local_perturbation, bounds[:,0], bounds[:,1])\n            candidate_fitness = func(candidate_position)\n            self.current_evaluations += 1\n            \n            if candidate_fitness < personal_best_fitness[global_best_index]:\n                global_best_position = candidate_position\n                global_best_index = np.argmin(personal_best_fitness)\n            \n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Introduced dynamic local perturbation scaling based on the current budget usage to balance exploration and exploitation effectively.", "configspace": "", "generation": 52, "fitness": 0.47776174529803433, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.478 with standard deviation 0.018. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "0ac3b5ed-a451-455a-881a-2b3eabe44caa", "metadata": {"aucs": [0.4516291974296669, 0.48995536561373365, 0.4917006728507026], "final_y": [4.479783578946148e-07, 4.1717538205853814e-07, 2.6890052028698237e-06]}, "mutation_prompt": null}
{"id": "a69cde00-b65f-4731-b3f2-3cf59c09f0d1", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                self.alpha = 0.3 + 0.2 * (self.current_evaluations/self.budget)  # Dynamic inertia\n                c1 = 1.5  # Personal acceleration coefficient\n                c2 = 1.5 + (self.current_evaluations/self.budget)  # Dynamic social acceleration\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.alpha * velocities[i] + \\\n                                c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                c2 * r2 * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n\n            # Local search around global best\n            local_perturbation = np.random.normal(scale=0.1 * (1 - self.current_evaluations/self.budget), size=self.dim)  # Dynamic perturbation\n            candidate_position = np.clip(global_best_position + local_perturbation, bounds[:,0], bounds[:,1])\n            candidate_fitness = func(candidate_position)\n            self.current_evaluations += 1\n            \n            if candidate_fitness < personal_best_fitness[global_best_index]:\n                global_best_position = candidate_position\n                global_best_index = np.argmin(personal_best_fitness)\n            \n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Improved convergence by adjusting the local perturbation scale dynamically based on the progress of evaluations.", "configspace": "", "generation": 53, "fitness": 0.47776174529803433, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.478 with standard deviation 0.018. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "0ac3b5ed-a451-455a-881a-2b3eabe44caa", "metadata": {"aucs": [0.4516291974296669, 0.48995536561373365, 0.4917006728507026], "final_y": [4.479783578946148e-07, 4.1717538205853814e-07, 2.6890052028698237e-06]}, "mutation_prompt": null}
{"id": "87e1059a-af20-49fd-986a-fd08804a5e52", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                self.alpha = 0.3 + 0.2 * (self.current_evaluations/self.budget)  # Dynamic inertia\n                c1 = 1.5  # Personal acceleration coefficient\n                c2 = 1.5 + (self.current_evaluations/self.budget)  # Dynamic social acceleration\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.alpha * velocities[i] + \\\n                                c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                c2 * r2 * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n\n            # Lvy flight for enhanced exploration\n            levy_step = np.random.standard_cauchy(size=self.dim) * 0.1\n            candidate_position = np.clip(global_best_position + levy_step, bounds[:,0], bounds[:,1])\n            candidate_fitness = func(candidate_position)\n            self.current_evaluations += 1\n            \n            if candidate_fitness < personal_best_fitness[global_best_index]:\n                global_best_position = candidate_position\n                global_best_index = np.argmin(personal_best_fitness)\n            \n            # Adjust population size adaptively\n            self.population_size = max(1, int(5 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Improved exploration and exploitation balance by integrating a Lvy flight mechanism and adaptive population size adjustment.", "configspace": "", "generation": 54, "fitness": 0.637461477856732, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.637 with standard deviation 0.015. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "0ac3b5ed-a451-455a-881a-2b3eabe44caa", "metadata": {"aucs": [0.6589155404731983, 0.629972448485266, 0.6234964446117317], "final_y": [1.8785039554935748e-10, 1.0014541588581755e-07, 5.4484138257760005e-08]}, "mutation_prompt": null}
{"id": "7694ceb0-5ae7-4620-87a3-a5ad1279d6a4", "solution": "import numpy as np\n\nclass EnhancedAQPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)\n        self.alpha = 0.5\n        self.beta = 0.5\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            diversity_factor = np.std(population, axis=0).mean()\n            for i in range(self.population_size):\n                self.alpha = 0.3 + 0.2 * (self.current_evaluations/self.budget)\n                c1 = 1.5\n                c2 = 1.5 + (self.current_evaluations/self.budget)\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.alpha * velocities[i] + \\\n                                c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                c2 * r2 * (global_best_position - population[i])\n                population[i] = np.clip(population[i] + velocities[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n\n            if diversity_factor < 1e-3:\n                for i in range(self.population_size):\n                    candidates = np.random.choice(self.population_size, 3, replace=False)\n                    mutant_vector = (population[candidates[0]] + \n                                     0.5 * (population[candidates[1]] - population[candidates[2]]))\n                    mutant_vector = np.clip(mutant_vector, bounds[:,0], bounds[:,1])\n                    mutant_fitness = func(mutant_vector)\n                    self.current_evaluations += 1\n                    if mutant_fitness < personal_best_fitness[i]:\n                        personal_best_positions[i] = mutant_vector\n                        personal_best_fitness[i] = mutant_fitness\n                        if mutant_fitness < personal_best_fitness[global_best_index]:\n                            global_best_position = mutant_vector\n                            global_best_index = i\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "EnhancedAQPSO", "description": "Incorporate adaptive diversity control and differential evolution inspired mutation for improved exploration and exploitation balance.", "configspace": "", "generation": 55, "fitness": 0.369837445139926, "feedback": "The algorithm EnhancedAQPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.370 with standard deviation 0.039. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "0ac3b5ed-a451-455a-881a-2b3eabe44caa", "metadata": {"aucs": [0.3333299293036087, 0.42334089067842295, 0.35284151543774633], "final_y": [0.00027214939806701724, 6.707200229119455e-05, 1.5961533226784615e-05]}, "mutation_prompt": null}
{"id": "7f34cded-610e-4fde-aa45-a2a314297485", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                self.alpha = 0.3 + 0.2 * (self.current_evaluations/self.budget)  # Dynamic inertia\n                c1 = 1.5  # Personal acceleration coefficient\n                c2 = 1.5 + (self.current_evaluations/self.budget)  # Dynamic social acceleration\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.alpha * velocities[i] + \\\n                                c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                c2 * r2 * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n\n            # Local search around global best\n            local_perturbation = np.random.normal(scale=0.1, size=self.dim)  # Size of perturbation\n            candidate_position = np.clip(global_best_position + local_perturbation, bounds[:,0], bounds[:,1])\n            candidate_fitness = func(candidate_position)\n            self.current_evaluations += 1\n            \n            if candidate_fitness < personal_best_fitness[global_best_index]:\n                global_best_position = candidate_position\n                global_best_index = np.argmin(personal_best_fitness)\n            \n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n            \n            self.beta = 0.3 + 0.4 * (self.current_evaluations/self.budget)  # Updated quantum position shift factor\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Introducing a dynamic quantum position shift factor to enhance exploration and exploitation balance.", "configspace": "", "generation": 56, "fitness": 0.42367270582972755, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.424 with standard deviation 0.023. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "0ac3b5ed-a451-455a-881a-2b3eabe44caa", "metadata": {"aucs": [0.4477504962045209, 0.4303374355745979, 0.3929301857100639], "final_y": [3.270908718547317e-06, 1.2353527823335263e-05, 9.64571518259816e-05]}, "mutation_prompt": null}
{"id": "a1643351-5b8c-4e8a-8600-088cda8814e2", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                self.alpha = 0.3 + 0.2 * (self.current_evaluations/self.budget)  # Dynamic inertia\n                c1 = 1.5  # Personal acceleration coefficient\n                c2 = 1.5 + (self.current_evaluations/self.budget)  # Dynamic social acceleration\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.alpha * velocities[i] + \\\n                                c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                c2 * r2 * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n\n            # Local search around global best\n            decay_factor = 0.1 * (1 - self.current_evaluations / self.budget)\n            local_perturbation = np.random.normal(scale=decay_factor, size=self.dim)  # Size of perturbation\n            candidate_position = np.clip(global_best_position + local_perturbation, bounds[:,0], bounds[:,1])\n            candidate_fitness = func(candidate_position)\n            self.current_evaluations += 1\n            \n            if candidate_fitness < personal_best_fitness[global_best_index]:\n                global_best_position = candidate_position\n                global_best_index = np.argmin(personal_best_fitness)\n            \n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Introduced a decay factor in the local perturbation scale to enhance exploration in early stages and exploitation in later stages.", "configspace": "", "generation": 57, "fitness": 0.47776174529803433, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.478 with standard deviation 0.018. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "0ac3b5ed-a451-455a-881a-2b3eabe44caa", "metadata": {"aucs": [0.4516291974296669, 0.48995536561373365, 0.4917006728507026], "final_y": [4.479783578946148e-07, 4.1717538205853814e-07, 2.6890052028698237e-06]}, "mutation_prompt": null}
{"id": "3e833794-9ca1-4f27-9bf0-9472dddf4402", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                self.alpha = 0.3 + 0.2 * (self.current_evaluations/self.budget)  # Dynamic inertia\n                c1 = 1.5  # Personal acceleration coefficient\n                c2 = 1.5 + (self.current_evaluations/self.budget)  # Dynamic social acceleration\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.alpha * velocities[i] + \\\n                                c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                c2 * r2 * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n\n            # Adaptive local search around global best\n            local_perturbation_scale = 0.1 * (1 - self.current_evaluations / self.budget)  # Adapt perturbation\n            local_perturbation = np.random.normal(scale=local_perturbation_scale, size=self.dim)\n            candidate_position = np.clip(global_best_position + local_perturbation, bounds[:,0], bounds[:,1])\n            candidate_fitness = func(candidate_position)\n            self.current_evaluations += 1\n            \n            if candidate_fitness < personal_best_fitness[global_best_index]:\n                global_best_position = candidate_position\n                global_best_index = np.argmin(personal_best_fitness)\n            \n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Introduced adaptive local exploration by adjusting the perturbation size based on the evaluation ratio to enhance diversification.", "configspace": "", "generation": 58, "fitness": 0.47776174529803433, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.478 with standard deviation 0.018. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "0ac3b5ed-a451-455a-881a-2b3eabe44caa", "metadata": {"aucs": [0.4516291974296669, 0.48995536561373365, 0.4917006728507026], "final_y": [4.479783578946148e-07, 4.1717538205853814e-07, 2.6890052028698237e-06]}, "mutation_prompt": null}
{"id": "fd062488-456d-472e-a9d4-fbb1b15355da", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                self.alpha = 0.3 + 0.2 * (self.current_evaluations/self.budget)  # Dynamic inertia\n                c1 = 1.5  # Personal acceleration coefficient\n                c2 = 1.5 + (self.current_evaluations/self.budget)  # Dynamic social acceleration\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.alpha * velocities[i] + \\\n                                c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                c2 * r2 * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n\n            # Local search around global best\n            local_perturbation = np.random.normal(scale=0.2, size=self.dim)  # **Increased size of perturbation**\n            candidate_position = np.clip(global_best_position + local_perturbation, bounds[:,0], bounds[:,1])\n            candidate_fitness = func(candidate_position)\n            self.current_evaluations += 1\n            \n            if candidate_fitness < personal_best_fitness[global_best_index]:\n                global_best_position = candidate_position\n                global_best_index = np.argmin(personal_best_fitness)\n            \n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Enhanced convergence precision by incorporating local search around the global best position using increased local perturbation scale, improving exploration.", "configspace": "", "generation": 59, "fitness": 0.5181031576398193, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.518 with standard deviation 0.034. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "0ac3b5ed-a451-455a-881a-2b3eabe44caa", "metadata": {"aucs": [0.5663007661744146, 0.48995536561373365, 0.4980533411313096], "final_y": [7.27976465116681e-08, 4.1717538205853814e-07, 3.6793978093883517e-07]}, "mutation_prompt": null}
{"id": "01e2a681-d05c-4254-b0b6-4157b051f685", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                self.alpha = 0.3 + 0.2 * (self.current_evaluations/self.budget)  # Dynamic inertia\n                c1 = 1.5  # Personal acceleration coefficient\n                c2 = 1.5 + (self.current_evaluations/self.budget)  # Dynamic social acceleration\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.alpha * velocities[i] + \\\n                                c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                c2 * r2 * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n\n            # Local search around global best\n            dynamic_scale = 0.1 * (1 - self.current_evaluations/self.budget)\n            local_perturbation = np.random.normal(scale=dynamic_scale, size=self.dim)\n            candidate_position = np.clip(global_best_position + local_perturbation, bounds[:,0], bounds[:,1])\n            candidate_fitness = func(candidate_position)\n            self.current_evaluations += 1\n            \n            if candidate_fitness < personal_best_fitness[global_best_index]:\n                global_best_position = candidate_position\n                global_best_index = np.argmin(personal_best_fitness)\n            \n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Improved the global best position update by incorporating a dynamic scaling factor for local search perturbations, enhancing exploration-exploitation balance.", "configspace": "", "generation": 60, "fitness": 0.47776174529803433, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.478 with standard deviation 0.018. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "0ac3b5ed-a451-455a-881a-2b3eabe44caa", "metadata": {"aucs": [0.4516291974296669, 0.48995536561373365, 0.4917006728507026], "final_y": [4.479783578946148e-07, 4.1717538205853814e-07, 2.6890052028698237e-06]}, "mutation_prompt": null}
{"id": "9cdb8354-6118-4fe6-b2b9-6bc01e48fe9c", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                self.alpha = 0.3 + 0.2 * (self.current_evaluations/self.budget)  # Dynamic inertia\n                c1 = 1.5  # Personal acceleration coefficient\n                c2 = 1.5 + (self.current_evaluations/self.budget)  # Dynamic social acceleration\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.alpha * velocities[i] + \\\n                                c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                c2 * r2 * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n\n            # Local search around global best\n            local_perturbation = np.random.normal(scale=0.1 + 0.1 * (self.current_evaluations/self.budget), size=self.dim)  # Adaptive perturbation\n            candidate_position = np.clip(global_best_position + local_perturbation, bounds[:,0], bounds[:,1])\n            candidate_fitness = func(candidate_position)\n            self.current_evaluations += 1\n            \n            if candidate_fitness < personal_best_fitness[global_best_index]:\n                global_best_position = candidate_position\n                global_best_index = np.argmin(personal_best_fitness)\n            \n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Introduced adaptive quantum position shift for improved convergence precision.", "configspace": "", "generation": 61, "fitness": 0.5181866577166282, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.518 with standard deviation 0.022. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "0ac3b5ed-a451-455a-881a-2b3eabe44caa", "metadata": {"aucs": [0.5443045372540276, 0.48995536561373365, 0.5203000702821233], "final_y": [5.360005408894701e-08, 4.1717538205853814e-07, 7.655323825626557e-08]}, "mutation_prompt": null}
{"id": "54770140-11da-4ce2-a272-8ae521349ccc", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                self.alpha = 0.3 + 0.2 * (self.current_evaluations/self.budget)  # Dynamic inertia\n                c1 = 1.5  # Personal acceleration coefficient\n                c2 = 1.5 + (self.current_evaluations/self.budget)  # Dynamic social acceleration\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.alpha * velocities[i] + \\\n                                c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                c2 * r2 * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n\n            # Local search around global best\n            local_perturbation = np.random.normal(scale=0.1, size=self.dim)  # Size of perturbation\n            candidate_position = np.clip(global_best_position + local_perturbation, bounds[:,0], bounds[:,1])\n            candidate_fitness = func(candidate_position)\n            self.current_evaluations += 1\n            \n            if candidate_fitness < personal_best_fitness[global_best_index]:\n                global_best_position = candidate_position\n                global_best_index = np.argmin(personal_best_fitness)\n            \n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n            \n            self.beta = 0.5 + 0.5 * (self.current_evaluations/self.budget)  # Dynamic beta adjustment\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Introduced a dynamic quantum position shift factor to enhance exploration-exploitation balance.", "configspace": "", "generation": 62, "fitness": 0.5119389189635952, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.512 with standard deviation 0.016. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "0ac3b5ed-a451-455a-881a-2b3eabe44caa", "metadata": {"aucs": [0.5207491900363145, 0.48995536561373365, 0.5251122012407375], "final_y": [2.0990121095828123e-08, 4.1717538205853814e-07, 6.625590680111827e-08]}, "mutation_prompt": null}
{"id": "d51eb9ff-97f2-430b-a339-44ed7b00e656", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                self.alpha = 0.3 + 0.2 * (self.current_evaluations/self.budget)  # Dynamic inertia\n                c1 = 1.5  # Personal acceleration coefficient\n                c2 = 1.5 + (self.current_evaluations/self.budget)  # Dynamic social acceleration\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.alpha * velocities[i] + \\\n                                c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                c2 * r2 * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n\n            # Local search around global best\n            local_perturbation = np.random.normal(\n                scale=0.1 * (1 - self.current_evaluations / self.budget), size=self.dim)  # Scale perturbation\n            candidate_position = np.clip(global_best_position + local_perturbation, bounds[:,0], bounds[:,1])\n            candidate_fitness = func(candidate_position)\n            self.current_evaluations += 1\n            \n            if candidate_fitness < personal_best_fitness[global_best_index]:\n                global_best_position = candidate_position\n                global_best_index = np.argmin(personal_best_fitness)\n            \n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Improved exploration by adapting the scale of local perturbations based on the budget usage.", "configspace": "", "generation": 63, "fitness": 0.47776174529803433, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.478 with standard deviation 0.018. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "0ac3b5ed-a451-455a-881a-2b3eabe44caa", "metadata": {"aucs": [0.4516291974296669, 0.48995536561373365, 0.4917006728507026], "final_y": [4.479783578946148e-07, 4.1717538205853814e-07, 2.6890052028698237e-06]}, "mutation_prompt": null}
{"id": "d5029ce3-ea19-4a50-a156-48ee978bcf8c", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                self.alpha = 0.3 + 0.2 * (self.current_evaluations/self.budget)  # Dynamic inertia\n                c1 = 1.5  # Personal acceleration coefficient\n                c2 = 1.5 + (self.current_evaluations/self.budget)  # Dynamic social acceleration\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.alpha * velocities[i] + \\\n                                c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                c2 * r2 * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n\n            # Local search around global best\n            local_perturbation = np.random.normal(scale=0.05, size=self.dim)  # Adjusted size of perturbation\n            candidate_position = np.clip(global_best_position + local_perturbation, bounds[:,0], bounds[:,1])\n            candidate_fitness = func(candidate_position)\n            self.current_evaluations += 1\n            \n            if candidate_fitness < personal_best_fitness[global_best_index]:\n                global_best_position = candidate_position\n                global_best_index = np.argmin(personal_best_fitness)\n            \n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Refined convergence by adjusting the local perturbation scale to enhance local search precision.", "configspace": "", "generation": 64, "fitness": 0.5200495861450879, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.520 with standard deviation 0.039. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "0ac3b5ed-a451-455a-881a-2b3eabe44caa", "metadata": {"aucs": [0.5080888967294298, 0.4790330066565842, 0.5730268550492499], "final_y": [2.05397829194479e-08, 3.024955377262168e-08, 1.3228298609893764e-08]}, "mutation_prompt": null}
{"id": "12a054ea-3ffe-4ddd-a210-c98ac0e26059", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                self.alpha = 0.3 + 0.2 * (self.current_evaluations/self.budget)  # Dynamic inertia\n                c1 = 1.5  # Personal acceleration coefficient\n                c2 = 1.5 + (self.current_evaluations/self.budget)  # Dynamic social acceleration\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.alpha * velocities[i] + \\\n                                c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                c2 * r2 * (global_best_position - population[i])\n                velocities[i] = np.clip(velocities[i], -(bounds[:,1] - bounds[:,0]) / 10, (bounds[:,1] - bounds[:,0]) / 10)  # Adaptive velocity limit\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n\n            # Local search around global best with elite perturbation\n            local_perturbation = np.random.normal(scale=0.05, size=self.dim)  # Reduced perturbation\n            candidate_position = np.clip(global_best_position + local_perturbation, bounds[:,0], bounds[:,1])\n            candidate_fitness = func(candidate_position)\n            self.current_evaluations += 1\n            \n            if candidate_fitness < personal_best_fitness[global_best_index]:\n                global_best_position = candidate_position\n                global_best_index = np.argmin(personal_best_fitness)\n            \n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Improved convergence by introducing elite perturbation and adaptive velocity limits based on convergence progress.", "configspace": "", "generation": 65, "fitness": 0.513794449449357, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.514 with standard deviation 0.061. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "0ac3b5ed-a451-455a-881a-2b3eabe44caa", "metadata": {"aucs": [0.45247862075543976, 0.4918587531926112, 0.5970459744000199], "final_y": [8.98007878745925e-07, 1.806172732400758e-06, 7.636792209301634e-09]}, "mutation_prompt": null}
{"id": "e6729bab-54b3-4801-9097-a6cfa82c2a1e", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                self.alpha = 0.3 + 0.2 * (self.current_evaluations/self.budget)  # Dynamic inertia\n                c1 = 1.5  # Personal acceleration coefficient\n                c2 = 1.5 + (self.current_evaluations/self.budget)  # Dynamic social acceleration\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.alpha * velocities[i] + \\\n                                c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                c2 * r2 * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n\n            # Local search around global best\n            local_perturbation = np.random.normal(scale=0.15, size=self.dim)  # Adjusted size of perturbation\n            candidate_position = np.clip(global_best_position + local_perturbation, bounds[:,0], bounds[:,1])\n            candidate_fitness = func(candidate_position)\n            self.current_evaluations += 1\n            \n            if candidate_fitness < personal_best_fitness[global_best_index]:\n                global_best_position = candidate_position\n                global_best_index = np.argmin(personal_best_fitness)\n            \n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Improve convergence by slightly increasing the local search perturbation scale.", "configspace": "", "generation": 66, "fitness": 0.5209925526559115, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.521 with standard deviation 0.033. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "0ac3b5ed-a451-455a-881a-2b3eabe44caa", "metadata": {"aucs": [0.5663007661744146, 0.48995536561373365, 0.5067215261795861], "final_y": [7.27976465116681e-08, 4.1717538205853814e-07, 5.714508768478343e-07]}, "mutation_prompt": null}
{"id": "4759a56f-24d3-49b5-b19a-7944ed07bbba", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                self.alpha = 0.3 + 0.2 * (self.current_evaluations/self.budget)  # Dynamic inertia\n                c1 = 1.5  # Personal acceleration coefficient\n                c2 = 1.5 + (self.current_evaluations/self.budget)  # Dynamic social acceleration\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.alpha * velocities[i] + \\\n                                c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                c2 * r2 * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n\n            # Local search around global best\n            local_perturbation_scale = 0.1 * (1 - self.current_evaluations / self.budget)  # Dynamic perturbation scale\n            local_perturbation = np.random.normal(scale=local_perturbation_scale, size=self.dim)  # Size of perturbation\n            candidate_position = np.clip(global_best_position + local_perturbation, bounds[:,0], bounds[:,1])\n            candidate_fitness = func(candidate_position)\n            self.current_evaluations += 1\n            \n            if candidate_fitness < personal_best_fitness[global_best_index]:\n                global_best_position = candidate_position\n                global_best_index = np.argmin(personal_best_fitness)\n            \n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Improved solution exploration by dynamically adjusting the scale of the local search perturbation based on the current progress in the search.", "configspace": "", "generation": 67, "fitness": 0.47776174529803433, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.478 with standard deviation 0.018. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "0ac3b5ed-a451-455a-881a-2b3eabe44caa", "metadata": {"aucs": [0.4516291974296669, 0.48995536561373365, 0.4917006728507026], "final_y": [4.479783578946148e-07, 4.1717538205853814e-07, 2.6890052028698237e-06]}, "mutation_prompt": null}
{"id": "8c990a7e-b541-4d83-bc93-f9e0ed5a1ae9", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            diversity = np.std(population, axis=0).mean()  # Compute population diversity\n            for i in range(self.population_size):\n                self.alpha = 0.3 + 0.2 * (self.current_evaluations/self.budget)  # Dynamic inertia\n                c1 = 1.5  # Personal acceleration coefficient\n                c2 = 1.5 + (self.current_evaluations/self.budget)  # Dynamic social acceleration\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.alpha * velocities[i] + \\\n                                c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                c2 * r2 * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n\n            # Local search around global best\n            local_perturbation = np.random.normal(scale=0.1 * diversity, size=self.dim)  # Adaptive perturbation\n            candidate_position = np.clip(global_best_position + local_perturbation, bounds[:,0], bounds[:,1])\n            candidate_fitness = func(candidate_position)\n            self.current_evaluations += 1\n            \n            if candidate_fitness < personal_best_fitness[global_best_index]:\n                global_best_position = candidate_position\n                global_best_index = np.argmin(personal_best_fitness)\n            \n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Enhanced convergence by integrating dynamic diversity adjustment and adaptive perturbation scaling.", "configspace": "", "generation": 68, "fitness": 0.5352107846917467, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.535 with standard deviation 0.033. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "0ac3b5ed-a451-455a-881a-2b3eabe44caa", "metadata": {"aucs": [0.5663007661744146, 0.48995536561373365, 0.5493762222870917], "final_y": [7.27976465116681e-08, 4.1717538205853814e-07, 1.305489785202018e-07]}, "mutation_prompt": null}
{"id": "fa343186-e3ea-4316-9193-5175f52d6ac2", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                self.alpha = 0.3 + 0.2 * (self.current_evaluations/self.budget)  # Dynamic inertia\n                c1 = 1.5  # Personal acceleration coefficient\n                c2 = 1.5 + (self.current_evaluations/self.budget)  # Dynamic social acceleration\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.alpha * velocities[i] + \\\n                                c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                c2 * r2 * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n\n            # Local search around global best\n            local_perturbation = np.random.normal(scale=0.05, size=self.dim)  # Reduced size of perturbation\n            candidate_position = np.clip(global_best_position + local_perturbation, bounds[:,0], bounds[:,1])\n            candidate_fitness = func(candidate_position)\n            self.current_evaluations += 1\n            \n            if candidate_fitness < personal_best_fitness[global_best_index]:\n                global_best_position = candidate_position\n                global_best_index = np.argmin(personal_best_fitness)\n            \n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Improved local search precision by reducing the perturbation scale for better exploitation of the global best position.", "configspace": "", "generation": 69, "fitness": 0.5200495861450879, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.520 with standard deviation 0.039. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "0ac3b5ed-a451-455a-881a-2b3eabe44caa", "metadata": {"aucs": [0.5080888967294298, 0.4790330066565842, 0.5730268550492499], "final_y": [2.05397829194479e-08, 3.024955377262168e-08, 1.3228298609893764e-08]}, "mutation_prompt": null}
{"id": "93480ee6-988d-47a0-9944-401e4e25219e", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                self.alpha = 0.3 + 0.4 * (np.sin(np.pi * self.current_evaluations/self.budget))  # Sine-based inertia\n                c1 = 1.5  # Personal acceleration coefficient\n                c2 = 1.5 + (self.current_evaluations/self.budget)  # Dynamic social acceleration\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.alpha * velocities[i] + \\\n                                c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                c2 * r2 * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n\n            # Local search around global best\n            local_perturbation = np.random.normal(scale=0.05, size=self.dim)  # Reduced perturbation size\n            candidate_position = np.clip(global_best_position + local_perturbation, bounds[:,0], bounds[:,1])\n            candidate_fitness = func(candidate_position)\n            self.current_evaluations += 1\n            \n            if candidate_fitness < personal_best_fitness[global_best_index]:\n                global_best_position = candidate_position\n                global_best_index = np.argmin(personal_best_fitness)\n            \n            self.population_size = max(1, int(10 * self.dim * np.cos(np.pi * self.current_evaluations / self.budget)))  # Adaptive resizing\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Improved convergence by introducing adaptive local search and dynamic population resizing for better exploration-exploitation balance.", "configspace": "", "generation": 70, "fitness": 0.3389993600385219, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.339 with standard deviation 0.038. And the mean value of best solutions found was 0.007 (0. is the best).", "error": "", "parent_id": "0ac3b5ed-a451-455a-881a-2b3eabe44caa", "metadata": {"aucs": [0.3077583940957439, 0.3167712425826953, 0.3924684434371264], "final_y": [0.009139247231278843, 0.011604033151585706, 0.0014108451659251115]}, "mutation_prompt": null}
{"id": "3547f502-bb28-4173-95e5-713b8cbf254a", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                self.alpha = 0.3 + 0.2 * (self.current_evaluations/self.budget)  # Dynamic inertia\n                c1 = 1.5  # Personal acceleration coefficient\n                c2 = 1.5 + (self.current_evaluations/self.budget)  # Dynamic social acceleration\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.alpha * velocities[i] + \\\n                                c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                c2 * r2 * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n\n            # Local search around global best\n            local_perturbation = np.random.normal(scale=0.1 * (1 - self.current_evaluations / self.budget), size=self.dim)  # Adjust perturbation\n            candidate_position = np.clip(global_best_position + local_perturbation, bounds[:,0], bounds[:,1])\n            candidate_fitness = func(candidate_position)\n            self.current_evaluations += 1\n            \n            if candidate_fitness < personal_best_fitness[global_best_index]:\n                global_best_position = candidate_position\n                global_best_index = np.argmin(personal_best_fitness)\n            \n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Improve local search by adjusting the local perturbation scale based on convergence progress.", "configspace": "", "generation": 71, "fitness": 0.5462513147987726, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.546 with standard deviation 0.030. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "0ac3b5ed-a451-455a-881a-2b3eabe44caa", "metadata": {"aucs": [0.5226859609151722, 0.5892038206459548, 0.5268641628351908], "final_y": [1.6932689814208778e-07, 1.2397427063836139e-08, 6.143581551464293e-07]}, "mutation_prompt": null}
{"id": "40b934df-e014-474c-bfb5-38904dc4d66f", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                self.alpha = 0.3 + 0.2 * (self.current_evaluations/self.budget)  # Dynamic inertia\n                c1 = 1.5  # Personal acceleration coefficient\n                c2 = 1.5 + (self.current_evaluations/self.budget)  # Dynamic social acceleration\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.alpha * velocities[i] + \\\n                                c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                c2 * r2 * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n\n            # Local search around global best\n            local_perturbation = np.random.normal(scale=0.1 * (1 - self.current_evaluations / self.budget), size=self.dim)  # Size of perturbation\n            candidate_position = np.clip(global_best_position + local_perturbation, bounds[:,0], bounds[:,1])\n            candidate_fitness = func(candidate_position)\n            self.current_evaluations += 1\n            \n            if candidate_fitness < personal_best_fitness[global_best_index]:\n                global_best_position = candidate_position\n                global_best_index = np.argmin(personal_best_fitness)\n            \n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Introduced dynamic scaling to local perturbations for enhanced exploration during local search.", "configspace": "", "generation": 72, "fitness": 0.47776174529803433, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.478 with standard deviation 0.018. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "0ac3b5ed-a451-455a-881a-2b3eabe44caa", "metadata": {"aucs": [0.4516291974296669, 0.48995536561373365, 0.4917006728507026], "final_y": [4.479783578946148e-07, 4.1717538205853814e-07, 2.6890052028698237e-06]}, "mutation_prompt": null}
{"id": "f4bf7f66-d1e7-44f7-9d25-39c78b97e0a1", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                self.alpha = 0.3 + 0.2 * (self.current_evaluations/self.budget)  # Dynamic inertia\n                c1 = 1.5  # Personal acceleration coefficient\n                c2 = 1.5 + (self.current_evaluations/self.budget)  # Dynamic social acceleration\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.alpha * velocities[i] + \\\n                                c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                c2 * r2 * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n\n            # Enhanced local search around global best\n            local_perturbation_scale = 0.1 * (1 - self.current_evaluations / self.budget)\n            local_perturbation = np.random.normal(scale=local_perturbation_scale, size=self.dim)\n            candidate_position = np.clip(global_best_position + local_perturbation, bounds[:,0], bounds[:,1])\n            candidate_fitness = func(candidate_position)\n            self.current_evaluations += 1\n            \n            if candidate_fitness < personal_best_fitness[global_best_index]:\n                global_best_position = candidate_position\n                global_best_index = np.argmin(personal_best_fitness)\n            \n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Enhanced local exploration by adaptive perturbation scaling near the global best position.", "configspace": "", "generation": 73, "fitness": 0.47776174529803433, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.478 with standard deviation 0.018. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "0ac3b5ed-a451-455a-881a-2b3eabe44caa", "metadata": {"aucs": [0.4516291974296669, 0.48995536561373365, 0.4917006728507026], "final_y": [4.479783578946148e-07, 4.1717538205853814e-07, 2.6890052028698237e-06]}, "mutation_prompt": null}
{"id": "8b1cff74-063e-4754-8394-49afbad0a0c9", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.7  # Quantum position shift factor (changed from 0.5 to 0.7)\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                self.alpha = 0.3 + 0.2 * (self.current_evaluations/self.budget)  # Dynamic inertia\n                c1 = 1.5  # Personal acceleration coefficient\n                c2 = 1.5 + (self.current_evaluations/self.budget)  # Dynamic social acceleration\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.alpha * velocities[i] + \\\n                                c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                c2 * r2 * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n\n            # Local search around global best\n            local_perturbation = np.random.normal(scale=0.1, size=self.dim)  # Size of perturbation\n            candidate_position = np.clip(global_best_position + local_perturbation, bounds[:,0], bounds[:,1])\n            candidate_fitness = func(candidate_position)\n            self.current_evaluations += 1\n            \n            if candidate_fitness < personal_best_fitness[global_best_index]:\n                global_best_position = candidate_position\n                global_best_index = np.argmin(personal_best_fitness)\n            \n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Improved global exploration by increasing the quantum position shift factor to enhance particle diversity.", "configspace": "", "generation": 74, "fitness": 0.5119389189635952, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.512 with standard deviation 0.016. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "0ac3b5ed-a451-455a-881a-2b3eabe44caa", "metadata": {"aucs": [0.5207491900363145, 0.48995536561373365, 0.5251122012407375], "final_y": [2.0990121095828123e-08, 4.1717538205853814e-07, 6.625590680111827e-08]}, "mutation_prompt": null}
{"id": "aa8c04ce-7daf-4b01-ab9b-c72251f2893d", "solution": "import numpy as np\n\nclass HybridSineCosineGravitationalSearchOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.G0 = 100  # Initial gravitational constant\n        self.alpha = 0.7  # Control parameter for sine-cosine mechanism\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        fitness = np.array([func(ind) for ind in population])\n        best_index = np.argmin(fitness)\n        best_position = np.copy(population[best_index])\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            G = self.G0 * (1 - self.current_evaluations / self.budget)  # Decaying gravitational constant\n            mass = 1 / (fitness - fitness.min() + 1e-10)\n            mass /= mass.sum()\n            \n            # Update velocities and positions\n            for i in range(self.population_size):\n                force = np.zeros(self.dim)\n                for j in range(self.population_size):\n                    if i != j:\n                        dist = np.linalg.norm(population[j] - population[i])\n                        force += G * mass[j] * (population[j] - population[i]) / (dist + 1e-10)\n                acceleration = force * mass[i]\n                \n                r1 = np.random.rand(self.dim)\n                r2 = np.random.rand(self.dim)\n                population[i] += self.alpha * np.sin(r1) * np.abs(acceleration) + self.alpha * np.cos(r2) * np.abs(best_position - population[i])\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < fitness[i]:\n                    fitness[i] = current_fitness\n                    if current_fitness < fitness[best_index]:\n                        best_position = population[i]\n                        best_index = i\n            \n            if self.current_evaluations >= self.budget:\n                break\n            \n        return best_position, fitness[best_index]", "name": "HybridSineCosineGravitationalSearchOptimization", "description": "\"Hybrid Sine-Cosine Gravitational Search Optimization\" combines the exploration of Gravitational Search Algorithm with the exploitation capability of Sine-Cosine mechanism to efficiently search the solution space.", "configspace": "", "generation": 75, "fitness": 0.09519198070818646, "feedback": "The algorithm HybridSineCosineGravitationalSearchOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.095 with standard deviation 0.029. And the mean value of best solutions found was 5.829 (0. is the best).", "error": "", "parent_id": "0ac3b5ed-a451-455a-881a-2b3eabe44caa", "metadata": {"aucs": [0.0656442696559767, 0.08611304705955514, 0.13381862540902756], "final_y": [9.47645735755345, 5.948623278509264, 2.061115613793573]}, "mutation_prompt": null}
{"id": "b50093e8-1fee-4216-9e34-ceab2d4d284c", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                self.alpha = 0.3 + 0.2 * (self.current_evaluations/self.budget)  # Dynamic inertia\n                c1 = 1.5  # Personal acceleration coefficient\n                c2 = 1.5 + (self.current_evaluations/self.budget)  # Dynamic social acceleration\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.alpha * velocities[i] + \\\n                                c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                c2 * r2 * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n\n            # Local search around global best\n            local_perturbation = np.random.normal(scale=0.1, size=self.dim)  # Size of perturbation\n            candidate_position = np.clip(global_best_position + local_perturbation, bounds[:,0], bounds[:,1])\n            candidate_fitness = func(candidate_position)\n            self.current_evaluations += 1\n            \n            if candidate_fitness < personal_best_fitness[global_best_index]:\n                global_best_position = candidate_position\n                global_best_index = np.argmin(personal_best_fitness)\n            \n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Introduced adaptive quantum position shift factor to enhance exploration during early iterations.", "configspace": "", "generation": 76, "fitness": 0.4283159333872814, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.428 with standard deviation 0.012. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "0ac3b5ed-a451-455a-881a-2b3eabe44caa", "metadata": {"aucs": [0.4443460937812337, 0.41543991553069926, 0.4251617908499111], "final_y": [2.796431663456145e-07, 1.314639784275947e-05, 1.817481069851031e-05]}, "mutation_prompt": null}
{"id": "f58d16f5-81c2-4db7-8454-ab349870b47f", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                self.alpha = 0.3 + 0.2 * (self.current_evaluations/self.budget)  # Dynamic inertia\n                c1 = 1.5  # Personal acceleration coefficient\n                c2 = 1.5 + (self.current_evaluations/self.budget)  # Dynamic social acceleration\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.alpha * velocities[i] + \\\n                                c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                c2 * r2 * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n\n            # Local search around global best\n            local_perturbation = np.random.normal(scale=0.1 * (1.0 - self.current_evaluations/self.budget), size=self.dim)  # Adaptive perturbation\n            candidate_position = np.clip(global_best_position + local_perturbation, bounds[:,0], bounds[:,1])\n            candidate_fitness = func(candidate_position)\n            self.current_evaluations += 1\n            \n            if candidate_fitness < personal_best_fitness[global_best_index]:\n                global_best_position = candidate_position\n                global_best_index = np.argmin(personal_best_fitness)\n            \n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Enhanced convergence by adjusting the local perturbation to be adaptive based on the current best solution.", "configspace": "", "generation": 77, "fitness": 0.47776174529803433, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.478 with standard deviation 0.018. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "0ac3b5ed-a451-455a-881a-2b3eabe44caa", "metadata": {"aucs": [0.4516291974296669, 0.48995536561373365, 0.4917006728507026], "final_y": [4.479783578946148e-07, 4.1717538205853814e-07, 2.6890052028698237e-06]}, "mutation_prompt": null}
{"id": "18c03c44-d2ac-4c27-a9c4-7fcf5e134f4a", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                self.alpha = 0.3 + 0.2 * (self.current_evaluations/self.budget)  # Dynamic inertia\n                c1 = 1.5  # Personal acceleration coefficient\n                c2 = 1.5 + (self.current_evaluations/self.budget)  # Dynamic social acceleration\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.alpha * velocities[i] + \\\n                                c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                c2 * r2 * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n\n            # Local search around global best\n            perturbation_scale = 0.1 + 0.1 * (self.current_evaluations / self.budget)\n            local_perturbation = np.random.normal(scale=perturbation_scale, size=self.dim)\n            candidate_position = np.clip(global_best_position + local_perturbation, bounds[:,0], bounds[:,1])\n            candidate_fitness = func(candidate_position)\n            self.current_evaluations += 1\n            \n            if candidate_fitness < personal_best_fitness[global_best_index]:\n                global_best_position = candidate_position\n                global_best_index = np.argmin(personal_best_fitness)\n            \n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Improved local search by increasing the perturbation scale during later stages of the optimization process.", "configspace": "", "generation": 78, "fitness": 0.5181866577166282, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.518 with standard deviation 0.022. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "0ac3b5ed-a451-455a-881a-2b3eabe44caa", "metadata": {"aucs": [0.5443045372540276, 0.48995536561373365, 0.5203000702821233], "final_y": [5.360005408894701e-08, 4.1717538205853814e-07, 7.655323825626557e-08]}, "mutation_prompt": null}
{"id": "1c2013f9-7646-43a1-8832-2fe76b0e1dfb", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                self.alpha = 0.3 + 0.2 * (self.current_evaluations/self.budget)  # Dynamic inertia\n                c1 = 1.5  # Personal acceleration coefficient\n                c2 = 1.5 + (self.current_evaluations/self.budget)  # Dynamic social acceleration\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.alpha * velocities[i] + \\\n                                c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                c2 * r2 * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i] + 0.1 * np.sin(np.pi * r1)  # Sinusoidal component\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n\n            local_perturbation = np.random.normal(scale=0.1 + 0.1 * np.sin(self.current_evaluations), size=self.dim)  # Sinusoidal adaptive perturbation\n            candidate_position = np.clip(global_best_position + local_perturbation, bounds[:,0], bounds[:,1])\n            candidate_fitness = func(candidate_position)\n            self.current_evaluations += 1\n            \n            if candidate_fitness < personal_best_fitness[global_best_index]:\n                global_best_position = candidate_position\n                global_best_index = np.argmin(personal_best_fitness)\n            \n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Improves exploration by integrating a sinusoidal search component and adaptive quantum perturbations for enhanced diversity.", "configspace": "", "generation": 79, "fitness": 0.27306160883167696, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.273 with standard deviation 0.026. And the mean value of best solutions found was 0.019 (0. is the best).", "error": "", "parent_id": "0ac3b5ed-a451-455a-881a-2b3eabe44caa", "metadata": {"aucs": [0.30875065267440027, 0.26246327227296207, 0.24797090154766854], "final_y": [0.016059076618926475, 0.03362924709960022, 0.008548701246399603]}, "mutation_prompt": null}
{"id": "97daa541-2b11-45b8-ba4d-d09dc9ab4938", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                self.alpha = 0.3 + 0.2 * (self.current_evaluations/self.budget)  # Dynamic inertia\n                c1 = 1.5  # Personal acceleration coefficient\n                c2 = 1.5 + (self.current_evaluations/self.budget)  # Dynamic social acceleration\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.alpha * velocities[i] + \\\n                                c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                c2 * r2 * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n\n            # Local search around global best\n            local_perturbation = np.random.normal(scale=0.1, size=self.dim)  # Size of perturbation\n            candidate_position = np.clip(global_best_position + local_perturbation, bounds[:,0], bounds[:,1])\n            candidate_fitness = func(candidate_position)\n            self.current_evaluations += 1\n            \n            if candidate_fitness < personal_best_fitness[global_best_index]:\n                global_best_position = candidate_position\n                global_best_index = np.argmin(personal_best_fitness)\n            \n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n            self.beta = 0.5 * (1 - self.current_evaluations / self.budget)  # Dynamic scaling of quantum shift factor\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Introduced dynamic scaling of quantum position shift factor to enhance exploration.", "configspace": "", "generation": 80, "fitness": 0.5119389189635952, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.512 with standard deviation 0.016. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "0ac3b5ed-a451-455a-881a-2b3eabe44caa", "metadata": {"aucs": [0.5207491900363145, 0.48995536561373365, 0.5251122012407375], "final_y": [2.0990121095828123e-08, 4.1717538205853814e-07, 6.625590680111827e-08]}, "mutation_prompt": null}
{"id": "aefef6cd-f118-4699-8b20-8c0b6fe67811", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                self.alpha = 0.3 + 0.2 * (self.current_evaluations/self.budget)  # Dynamic inertia\n                c1 = 1.5  # Personal acceleration coefficient\n                c2 = 1.5 + (self.current_evaluations/self.budget)  # Dynamic social acceleration\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.alpha * velocities[i] + \\\n                                c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                c2 * r2 * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n\n            # Local search around global best\n            local_perturbation = np.random.normal(scale=0.1 * (1 - self.current_evaluations / self.budget), size=self.dim)  # Adjusted perturbation\n            candidate_position = np.clip(global_best_position + local_perturbation, bounds[:,0], bounds[:,1])\n            candidate_fitness = func(candidate_position)\n            self.current_evaluations += 1\n            \n            if candidate_fitness < personal_best_fitness[global_best_index]:\n                global_best_position = candidate_position\n                global_best_index = np.argmin(personal_best_fitness)\n            \n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Improved the local search mechanism by adjusting perturbation scale dynamically based on remaining budget to enhance convergence precision.", "configspace": "", "generation": 81, "fitness": 0.47776174529803433, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.478 with standard deviation 0.018. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "0ac3b5ed-a451-455a-881a-2b3eabe44caa", "metadata": {"aucs": [0.4516291974296669, 0.48995536561373365, 0.4917006728507026], "final_y": [4.479783578946148e-07, 4.1717538205853814e-07, 2.6890052028698237e-06]}, "mutation_prompt": null}
{"id": "06021f00-2607-4c3a-b798-e35d4e0f9f81", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                self.alpha = 0.3 + 0.2 * (self.current_evaluations/self.budget)  # Dynamic inertia\n                c1 = 1.5  # Personal acceleration coefficient\n                c2 = 1.5 + (self.current_evaluations/self.budget)  # Dynamic social acceleration\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.alpha * velocities[i] + \\\n                                c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                c2 * r2 * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n\n            # Local search around global best\n            local_perturbation_scale = 0.1 + 0.1 * (1 - self.current_evaluations/self.budget)  # Adjust scale\n            local_perturbation = np.random.normal(scale=local_perturbation_scale, size=self.dim)\n            candidate_position = np.clip(global_best_position + local_perturbation, bounds[:,0], bounds[:,1])\n            candidate_fitness = func(candidate_position)\n            self.current_evaluations += 1\n            \n            if candidate_fitness < personal_best_fitness[global_best_index]:\n                global_best_position = candidate_position\n                global_best_index = np.argmin(personal_best_fitness)\n            \n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Enhanced global exploration by introducing adaptive perturbations and adjusting local search scale based on convergence progress.", "configspace": "", "generation": 82, "fitness": 0.5307352009718284, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.531 with standard deviation 0.031. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "0ac3b5ed-a451-455a-881a-2b3eabe44caa", "metadata": {"aucs": [0.5663007661744146, 0.48995536561373365, 0.5359494711273367], "final_y": [7.27976465116681e-08, 4.1717538205853814e-07, 3.6138739378769374e-08]}, "mutation_prompt": null}
{"id": "564bbe21-383a-487b-b5ae-8da614864ed5", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                self.alpha = 0.3 + 0.2 * (self.current_evaluations/self.budget)  # Dynamic inertia\n                c1 = 1.5  # Personal acceleration coefficient\n                c2 = 1.5 + (self.current_evaluations/self.budget)  # Dynamic social acceleration\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.alpha * velocities[i] + \\\n                                c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                c2 * r2 * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n\n            # Local search around global best\n            local_perturbation = np.random.normal(scale=0.1 + 0.4 * (1 - self.current_evaluations / self.budget), size=self.dim)  # Dynamic perturbation\n            candidate_position = np.clip(global_best_position + local_perturbation, bounds[:,0], bounds[:,1])\n            candidate_fitness = func(candidate_position)\n            self.current_evaluations += 1\n            \n            if candidate_fitness < personal_best_fitness[global_best_index]:\n                global_best_position = candidate_position\n                global_best_index = np.argmin(personal_best_fitness)\n            \n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Improved convergence by increasing the local perturbation scale dynamically based on remaining budget.", "configspace": "", "generation": 83, "fitness": 0.5166350419474665, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.517 with standard deviation 0.035. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "0ac3b5ed-a451-455a-881a-2b3eabe44caa", "metadata": {"aucs": [0.5663007661744146, 0.48995536561373365, 0.493648994054251], "final_y": [7.27976465116681e-08, 4.1717538205853814e-07, 1.3903364780356252e-06]}, "mutation_prompt": null}
{"id": "45c39d7a-55fa-4fe4-98e1-b97f8baeb4d2", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                self.alpha = 0.3 + 0.2 * (self.current_evaluations/self.budget)  # Dynamic inertia\n                c1 = 1.5  # Personal acceleration coefficient\n                c2 = 1.5 + (self.current_evaluations/self.budget)  # Dynamic social acceleration\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.alpha * velocities[i] + \\\n                                c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                c2 * r2 * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n\n            # Local search around global best\n            local_perturbation = np.random.normal(scale=(0.1 + 0.1 * (self.current_evaluations/self.budget)), size=self.dim)  # Dynamic perturbation\n            candidate_position = np.clip(global_best_position + local_perturbation, bounds[:,0], bounds[:,1])\n            candidate_fitness = func(candidate_position)\n            self.current_evaluations += 1\n            \n            if candidate_fitness < personal_best_fitness[global_best_index]:\n                global_best_position = candidate_position\n                global_best_index = np.argmin(personal_best_fitness)\n            \n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Improved exploration by introducing a dynamic scaling factor for perturbations in the local search phase.", "configspace": "", "generation": 84, "fitness": 0.5181866577166282, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.518 with standard deviation 0.022. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "0ac3b5ed-a451-455a-881a-2b3eabe44caa", "metadata": {"aucs": [0.5443045372540276, 0.48995536561373365, 0.5203000702821233], "final_y": [5.360005408894701e-08, 4.1717538205853814e-07, 7.655323825626557e-08]}, "mutation_prompt": null}
{"id": "dede9da0-a06e-4fe3-8715-298f70c8752f", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                self.alpha = 0.3 + 0.2 * (self.current_evaluations/self.budget)  # Dynamic inertia\n                c1 = 1.5  # Personal acceleration coefficient\n                c2 = 1.5 + (self.current_evaluations/self.budget)  # Dynamic social acceleration\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.alpha * velocities[i] + \\\n                                c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                c2 * r2 * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n\n            # Local search around global best\n            local_perturbation = np.random.normal(scale=0.1 * (1 - self.current_evaluations / self.budget), size=self.dim)  # Adjusted perturbation\n            candidate_position = np.clip(global_best_position + local_perturbation, bounds[:,0], bounds[:,1])\n            candidate_fitness = func(candidate_position)\n            self.current_evaluations += 1\n            \n            if candidate_fitness < personal_best_fitness[global_best_index]:\n                global_best_position = candidate_position\n                global_best_index = np.argmin(personal_best_fitness)\n            \n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Improved convergence by adjusting the scale of local perturbations based on current budget usage.", "configspace": "", "generation": 85, "fitness": 0.47776174529803433, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.478 with standard deviation 0.018. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "0ac3b5ed-a451-455a-881a-2b3eabe44caa", "metadata": {"aucs": [0.4516291974296669, 0.48995536561373365, 0.4917006728507026], "final_y": [4.479783578946148e-07, 4.1717538205853814e-07, 2.6890052028698237e-06]}, "mutation_prompt": null}
{"id": "68d4e033-bc7d-4841-af96-89c6d093d3af", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                self.alpha = 0.3 + 0.2 * (self.current_evaluations/self.budget)  # Dynamic inertia\n                c1 = 1.5  # Personal acceleration coefficient\n                c2 = 1.5 + (self.current_evaluations/self.budget)  # Dynamic social acceleration\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.alpha * velocities[i] + \\\n                                c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                c2 * r2 * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n\n            # Local search around global best\n            local_perturbation = np.random.normal(scale=0.1 * (1 - self.current_evaluations / self.budget), size=self.dim)  # Size of perturbation\n            candidate_position = np.clip(global_best_position + local_perturbation, bounds[:,0], bounds[:,1])\n            candidate_fitness = func(candidate_position)\n            self.current_evaluations += 1\n            \n            if candidate_fitness < personal_best_fitness[global_best_index]:\n                global_best_position = candidate_position\n                global_best_index = np.argmin(personal_best_fitness)\n            \n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Enhance exploration by adjusting the local perturbation scale dynamically based on the budget.", "configspace": "", "generation": 86, "fitness": 0.47776174529803433, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.478 with standard deviation 0.018. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "0ac3b5ed-a451-455a-881a-2b3eabe44caa", "metadata": {"aucs": [0.4516291974296669, 0.48995536561373365, 0.4917006728507026], "final_y": [4.479783578946148e-07, 4.1717538205853814e-07, 2.6890052028698237e-06]}, "mutation_prompt": null}
{"id": "4d00d761-63df-4cc9-85f5-b22b536c36d4", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                self.alpha = 0.3 + 0.2 * (self.current_evaluations/self.budget)  # Dynamic inertia\n                c1 = 1.5  # Personal acceleration coefficient\n                c2 = 1.5 + (self.current_evaluations/self.budget)  # Dynamic social acceleration\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.alpha * velocities[i] + \\\n                                c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                c2 * r2 * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n\n            # Local search around global best\n            local_perturbation = np.random.normal(scale=0.1 * (1 - self.current_evaluations / self.budget), size=self.dim)  # Size of perturbation\n            candidate_position = np.clip(global_best_position + local_perturbation, bounds[:,0], bounds[:,1])\n            candidate_fitness = func(candidate_position)\n            self.current_evaluations += 1\n            \n            if candidate_fitness < personal_best_fitness[global_best_index]:\n                global_best_position = candidate_position\n                global_best_index = np.argmin(personal_best_fitness)\n            \n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Introduced a dynamic scaling factor for local perturbations to enhance exploration near the global best.", "configspace": "", "generation": 87, "fitness": 0.47776174529803433, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.478 with standard deviation 0.018. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "0ac3b5ed-a451-455a-881a-2b3eabe44caa", "metadata": {"aucs": [0.4516291974296669, 0.48995536561373365, 0.4917006728507026], "final_y": [4.479783578946148e-07, 4.1717538205853814e-07, 2.6890052028698237e-06]}, "mutation_prompt": null}
{"id": "34a41ac5-ae1b-47c7-9140-847e3b6db72c", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Initial constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                self.alpha = 0.3 + 0.2 * (self.current_evaluations/self.budget)  # Dynamic inertia\n                c1 = 1.5  # Personal acceleration coefficient\n                c2 = 1.5 + (self.current_evaluations/self.budget)  # Dynamic social acceleration\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.alpha * velocities[i] + \\\n                                c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                c2 * r2 * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n\n            # Local search around global best\n            local_perturbation = np.random.normal(scale=0.1, size=self.dim)  # Size of perturbation\n            candidate_position = np.clip(global_best_position + local_perturbation, bounds[:,0], bounds[:,1])\n            candidate_fitness = func(candidate_position)\n            self.current_evaluations += 1\n            \n            if candidate_fitness < personal_best_fitness[global_best_index]:\n                global_best_position = candidate_position\n                global_best_index = np.argmin(personal_best_fitness)\n            \n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n            self.alpha *= 0.99  # Decaying constriction factor over iterations\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Improved convergence by adjusting the constriction factor to decay over time, allowing more exploration initially and more exploitation towards the end.", "configspace": "", "generation": 88, "fitness": 0.5119389189635952, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.512 with standard deviation 0.016. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "0ac3b5ed-a451-455a-881a-2b3eabe44caa", "metadata": {"aucs": [0.5207491900363145, 0.48995536561373365, 0.5251122012407375], "final_y": [2.0990121095828123e-08, 4.1717538205853814e-07, 6.625590680111827e-08]}, "mutation_prompt": null}
{"id": "80ccf36a-ecb2-408a-af7d-a636d8d89039", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                self.alpha = 0.3 + 0.2 * (self.current_evaluations/self.budget)  # Dynamic inertia\n                c1 = 1.5  # Personal acceleration coefficient\n                c2 = 1.5 + (self.current_evaluations/self.budget)  # Dynamic social acceleration\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.alpha * velocities[i] + \\\n                                c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                c2 * r2 * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n\n            # Local search around global best\n            local_perturbation = np.random.normal(scale=0.05, size=self.dim)  # Smaller perturbation scale\n            candidate_position = np.clip(global_best_position + local_perturbation, bounds[:,0], bounds[:,1])\n            candidate_fitness = func(candidate_position)\n            self.current_evaluations += 1\n            \n            if candidate_fitness < personal_best_fitness[global_best_index]:\n                global_best_position = candidate_position\n                global_best_index = np.argmin(personal_best_fitness)\n            \n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Integrate a Gaussian perturbation mechanism to enhance local exploration and convergence precision.", "configspace": "", "generation": 89, "fitness": 0.5200495861450879, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.520 with standard deviation 0.039. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "0ac3b5ed-a451-455a-881a-2b3eabe44caa", "metadata": {"aucs": [0.5080888967294298, 0.4790330066565842, 0.5730268550492499], "final_y": [2.05397829194479e-08, 3.024955377262168e-08, 1.3228298609893764e-08]}, "mutation_prompt": null}
{"id": "3cc13a51-2014-412d-9f3b-97a64223947b", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                self.alpha = 0.3 + 0.2 * (self.current_evaluations/self.budget)  # Dynamic inertia\n                c1 = 1.5  # Personal acceleration coefficient\n                c2 = 1.5 + (self.current_evaluations/self.budget)  # Dynamic social acceleration\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.alpha * velocities[i] + \\\n                                c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                c2 * r2 * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n\n            # Local search around global best\n            decay_factor = 1 - (self.current_evaluations / self.budget)\n            local_perturbation = np.random.normal(scale=0.1 * decay_factor, size=self.dim)  # Size of perturbation\n            candidate_position = np.clip(global_best_position + local_perturbation, bounds[:,0], bounds[:,1])\n            candidate_fitness = func(candidate_position)\n            self.current_evaluations += 1\n            \n            if candidate_fitness < personal_best_fitness[global_best_index]:\n                global_best_position = candidate_position\n                global_best_index = np.argmin(personal_best_fitness)\n            \n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Improved by introducing a decay factor in the local perturbation scale to enhance local search precision over time.", "configspace": "", "generation": 90, "fitness": 0.47776174529803433, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.478 with standard deviation 0.018. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "0ac3b5ed-a451-455a-881a-2b3eabe44caa", "metadata": {"aucs": [0.4516291974296669, 0.48995536561373365, 0.4917006728507026], "final_y": [4.479783578946148e-07, 4.1717538205853814e-07, 2.6890052028698237e-06]}, "mutation_prompt": null}
{"id": "8101732a-3df3-4b7e-91a8-eca0a17104f3", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                self.alpha = 0.3 + 0.2 * (self.current_evaluations/self.budget)  # Dynamic inertia\n                c1 = 1.5  # Personal acceleration coefficient\n                c2 = 1.5 + (self.current_evaluations/self.budget)  # Dynamic social acceleration\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.alpha * velocities[i] + \\\n                                c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                c2 * r2 * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n\n            # Local search around global best\n            convergence_rate = (self.budget - self.current_evaluations) / self.budget\n            local_perturbation = np.random.normal(scale=0.1 * convergence_rate, size=self.dim)  # Adaptive perturbation\n            candidate_position = np.clip(global_best_position + local_perturbation, bounds[:,0], bounds[:,1])\n            candidate_fitness = func(candidate_position)\n            self.current_evaluations += 1\n            \n            if candidate_fitness < personal_best_fitness[global_best_index]:\n                global_best_position = candidate_position\n                global_best_index = np.argmin(personal_best_fitness)\n            \n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Improved local search by adaptive perturbation scaling based on convergence rate.", "configspace": "", "generation": 91, "fitness": 0.47776174529803433, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.478 with standard deviation 0.018. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "0ac3b5ed-a451-455a-881a-2b3eabe44caa", "metadata": {"aucs": [0.4516291974296669, 0.48995536561373365, 0.4917006728507026], "final_y": [4.479783578946148e-07, 4.1717538205853814e-07, 2.6890052028698237e-06]}, "mutation_prompt": null}
{"id": "f2f8b52b-f67c-456d-b2f6-d27628b6d127", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        prev_global_best_fitness = personal_best_fitness[global_best_index]\n\n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                improvement_factor = (prev_global_best_fitness - personal_best_fitness[global_best_index]) / abs(prev_global_best_fitness)\n                self.alpha = 0.3 + 0.2 * improvement_factor  # Adjusted dynamic inertia\n                c1 = 1.5  # Personal acceleration coefficient\n                c2 = 1.5 + improvement_factor  # Adjusted dynamic social acceleration\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.alpha * velocities[i] + \\\n                                c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                c2 * r2 * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n\n            # Local search around global best\n            local_perturbation = np.random.normal(scale=0.1, size=self.dim)  # Size of perturbation\n            candidate_position = np.clip(global_best_position + local_perturbation, bounds[:,0], bounds[:,1])\n            candidate_fitness = func(candidate_position)\n            self.current_evaluations += 1\n            \n            if candidate_fitness < personal_best_fitness[global_best_index]:\n                global_best_position = candidate_position\n                global_best_index = np.argmin(personal_best_fitness)\n\n            prev_global_best_fitness = personal_best_fitness[global_best_index]\n\n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Introduce a dynamic learning strategy by adjusting dynamic inertia and social acceleration based on recent performance.", "configspace": "", "generation": 92, "fitness": 0.5828281986149682, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.583 with standard deviation 0.025. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "0ac3b5ed-a451-455a-881a-2b3eabe44caa", "metadata": {"aucs": [0.5472259188949427, 0.6027526989472468, 0.5985059780027151], "final_y": [4.591223089560825e-08, 1.0655403603341788e-12, 1.0849990928986932e-08]}, "mutation_prompt": null}
{"id": "708093bc-0484-4691-8032-86c7c2d55be2", "solution": "import numpy as np\n\nclass EnhancedParticleSwarmWithMutation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.alpha = 0.9  # Initial inertia\n        self.alpha_min = 0.4  # Minimum inertia\n        self.beta = 0.1  # Mutation rate\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n\n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                self.alpha = self.alpha_min + (0.9 - self.alpha_min) * (1 - self.current_evaluations/self.budget)  # Decrease inertia over time\n                c1, c2 = 1.5, 1.5 + (self.current_evaluations/self.budget)  # Adaptive social acceleration\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.alpha * velocities[i] + \\\n                                c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                c2 * r2 * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                # Mutation-based exploration\n                if np.random.rand() < self.beta:\n                    mutation = np.random.normal(scale=0.1, size=self.dim)\n                    population[i] += mutation\n                    population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n\n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "EnhancedParticleSwarmWithMutation", "description": "Incorporating adaptive inertia and mutation-based exploration to enhance convergence speed and precision in dynamic environments.", "configspace": "", "generation": 93, "fitness": 0.21128134537263896, "feedback": "The algorithm EnhancedParticleSwarmWithMutation got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.211 with standard deviation 0.016. And the mean value of best solutions found was 0.047 (0. is the best).", "error": "", "parent_id": "0ac3b5ed-a451-455a-881a-2b3eabe44caa", "metadata": {"aucs": [0.21266523650878089, 0.2305879577918445, 0.19059084181729147], "final_y": [0.06240284425686125, 0.03805822792163633, 0.04090933859491036]}, "mutation_prompt": null}
{"id": "0517cbcd-f300-4109-b1bf-0bb269b12ae1", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                self.alpha = 0.3 + 0.2 * (self.current_evaluations/self.budget)  # Dynamic inertia\n                c1 = 1.5  # Personal acceleration coefficient\n                c2 = 1.5 + (self.current_evaluations/self.budget)  # Dynamic social acceleration\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.alpha * velocities[i] + \\\n                                c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                c2 * r2 * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n\n            # Local search around global best\n            local_perturbation = np.random.normal(scale=0.05, size=self.dim)  # Reduced perturbation size\n            candidate_position = np.clip(global_best_position + local_perturbation, bounds[:,0], bounds[:,1])\n            candidate_fitness = func(candidate_position)\n            self.current_evaluations += 1\n            \n            if candidate_fitness < personal_best_fitness[global_best_index]:\n                global_best_position = candidate_position\n                global_best_index = np.argmin(personal_best_fitness)\n            \n            # Introduce Lvy flight for exploration\n            if np.random.rand() < 0.1:  # 10% chance to explore\n                levy_flight = np.random.normal(size=self.dim) * (bounds[:,1] - bounds[:,0]) / 3\n                population[i] = np.clip(global_best_position + levy_flight, bounds[:,0], bounds[:,1])\n\n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Enhanced exploration by introducing Lvy flight for global search and refining local search intensity.", "configspace": "", "generation": 94, "fitness": 0.5077208476212824, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.508 with standard deviation 0.019. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "0ac3b5ed-a451-455a-881a-2b3eabe44caa", "metadata": {"aucs": [0.5143090453709218, 0.5269032073142583, 0.4819502901786671], "final_y": [2.8986729138946652e-05, 6.432206998951763e-07, 1.3287997198293829e-05]}, "mutation_prompt": null}
{"id": "e843e89e-ef3d-4bc0-b319-627b9b8fad93", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                self.alpha = 0.3 + 0.2 * (self.current_evaluations/self.budget)  # Dynamic inertia\n                c1 = 1.5  # Personal acceleration coefficient\n                c2 = 1.5 + (self.current_evaluations/self.budget)  # Dynamic social acceleration\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.alpha * velocities[i] + \\\n                                c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                c2 * r2 * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n\n            # Local search around global best\n            local_perturbation = np.random.normal(scale=0.05, size=self.dim)  # Size of perturbation\n            candidate_position = np.clip(global_best_position + local_perturbation, bounds[:,0], bounds[:,1])\n            candidate_fitness = func(candidate_position)\n            self.current_evaluations += 1\n            \n            if candidate_fitness < personal_best_fitness[global_best_index]:\n                global_best_position = candidate_position\n                global_best_index = np.argmin(personal_best_fitness)\n            \n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Enhanced the local search precision by reducing the scale of perturbation around the global best position.", "configspace": "", "generation": 95, "fitness": 0.6052848793699641, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.605 with standard deviation 0.013. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "0ac3b5ed-a451-455a-881a-2b3eabe44caa", "metadata": {"aucs": [0.6177517079237362, 0.5870279232967128, 0.6110750068894433], "final_y": [5.909303794742115e-10, 4.7934909725167724e-09, 1.005445168066588e-08]}, "mutation_prompt": null}
{"id": "9e605f9d-bf4b-4514-86eb-a98a20616662", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                self.alpha = 0.3 + 0.2 * (self.current_evaluations/self.budget)  # Dynamic inertia\n                c1 = 1.5  # Personal acceleration coefficient\n                c2 = 1.5 + (self.current_evaluations/self.budget)  # Dynamic social acceleration\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.alpha * velocities[i] + \\\n                                c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                c2 * r2 * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n\n            # Local search around global best\n            scale_factor = 0.1 * (1 - self.current_evaluations/self.budget)\n            local_perturbation = np.random.normal(scale=scale_factor, size=self.dim)  # Adaptive perturbation\n            candidate_position = np.clip(global_best_position + local_perturbation, bounds[:,0], bounds[:,1])\n            candidate_fitness = func(candidate_position)\n            self.current_evaluations += 1\n            \n            if candidate_fitness < personal_best_fitness[global_best_index]:\n                global_best_position = candidate_position\n                global_best_index = np.argmin(personal_best_fitness)\n            \n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Enhanced local search using adaptive Gaussian perturbation for improved convergence.", "configspace": "", "generation": 96, "fitness": 0.47776174529803433, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.478 with standard deviation 0.018. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "0ac3b5ed-a451-455a-881a-2b3eabe44caa", "metadata": {"aucs": [0.4516291974296669, 0.48995536561373365, 0.4917006728507026], "final_y": [4.479783578946148e-07, 4.1717538205853814e-07, 2.6890052028698237e-06]}, "mutation_prompt": null}
{"id": "178be305-1cf0-4af3-96d8-e00348d8a272", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                self.alpha = 0.3 + 0.2 * (self.current_evaluations/self.budget)  # Dynamic inertia\n                c1 = 1.5  # Personal acceleration coefficient\n                c2 = 1.5 + (self.current_evaluations/self.budget)  # Dynamic social acceleration\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.alpha * velocities[i] + \\\n                                c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                c2 * r2 * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n\n            # Local search around global best\n            local_perturbation = np.random.normal(scale=0.05, size=self.dim)  # Reduced scale of perturbation\n            candidate_position = np.clip(global_best_position + local_perturbation, bounds[:,0], bounds[:,1])\n            candidate_fitness = func(candidate_position)\n            self.current_evaluations += 1\n            \n            if candidate_fitness < personal_best_fitness[global_best_index]:\n                global_best_position = candidate_position\n                global_best_index = np.argmin(personal_best_fitness)\n            \n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Improved global best retention by increasing perturbation specificity around it.", "configspace": "", "generation": 97, "fitness": 0.5200495861450879, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.520 with standard deviation 0.039. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "0ac3b5ed-a451-455a-881a-2b3eabe44caa", "metadata": {"aucs": [0.5080888967294298, 0.4790330066565842, 0.5730268550492499], "final_y": [2.05397829194479e-08, 3.024955377262168e-08, 1.3228298609893764e-08]}, "mutation_prompt": null}
{"id": "570d7db1-b482-4f6e-8469-4922f8dbb5f8", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                self.alpha = 0.3 + 0.2 * (self.current_evaluations/self.budget)  # Dynamic inertia\n                c1 = 1.5  # Personal acceleration coefficient\n                c2 = 1.7 + (self.current_evaluations/self.budget)  # Dynamic social acceleration\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.alpha * velocities[i] + \\\n                                c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                c2 * r2 * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n\n            # Local search around global best\n            local_perturbation = np.random.normal(scale=0.05, size=self.dim)  # Modified perturbation scale\n            candidate_position = np.clip(global_best_position + local_perturbation, bounds[:,0], bounds[:,1])\n            candidate_fitness = func(candidate_position)\n            self.current_evaluations += 1\n            \n            if candidate_fitness < personal_best_fitness[global_best_index]:\n                global_best_position = candidate_position\n                global_best_index = np.argmin(personal_best_fitness)\n            \n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Improved adaptive exploration-exploitation balance by modifying velocity update and perturbation scale.", "configspace": "", "generation": 98, "fitness": 0.4603789360702794, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.460 with standard deviation 0.034. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "0ac3b5ed-a451-455a-881a-2b3eabe44caa", "metadata": {"aucs": [0.4133943731447297, 0.4931277053596733, 0.47461472970643515], "final_y": [2.726073607415559e-05, 6.91331383258927e-07, 3.997275678153776e-06]}, "mutation_prompt": null}
{"id": "9da16c83-7a65-4cb7-bda2-23ddbdd6c6f9", "solution": "import numpy as np\n\nclass AdaptiveQuantumParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.current_evaluations = 0\n        self.phi = 0.5 + np.log(2)  # Golden ratio for attraction\n        self.alpha = 0.5  # Constriction factor\n        self.beta = 0.5  # Quantum position shift factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) + bounds[:,0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:,1] - bounds[:,0]) / 20\n        personal_best_positions = np.copy(population)\n        personal_best_fitness = np.array([func(ind) for ind in population])\n        global_best_index = np.argmin(personal_best_fitness)\n        global_best_position = personal_best_positions[global_best_index]\n        self.current_evaluations += self.population_size\n        \n        while self.current_evaluations < self.budget:\n            for i in range(self.population_size):\n                self.alpha = 0.3 + 0.2 * (self.current_evaluations/self.budget)  # Dynamic inertia\n                c1 = 1.5  # Personal acceleration coefficient\n                c2 = 1.5 + (self.current_evaluations/self.budget)  # Dynamic social acceleration\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = self.alpha * velocities[i] + \\\n                                c1 * r1 * (personal_best_positions[i] - population[i]) + \\\n                                c2 * r2 * (global_best_position - population[i])\n                population[i] = population[i] + velocities[i]\n                population[i] = np.clip(population[i], bounds[:,0], bounds[:,1])\n                \n                current_fitness = func(population[i])\n                self.current_evaluations += 1\n                \n                if current_fitness < personal_best_fitness[i]:\n                    personal_best_positions[i] = population[i]\n                    personal_best_fitness[i] = current_fitness\n                    if current_fitness < personal_best_fitness[global_best_index]:\n                        global_best_position = population[i]\n                        global_best_index = i\n\n            # Local search around global best\n            self.beta = 0.3 + 0.2 * (self.current_evaluations/self.budget)  # Dynamic beta\n            local_perturbation = np.random.normal(scale=self.beta, size=self.dim)  # Size of perturbation\n            candidate_position = np.clip(global_best_position + local_perturbation, bounds[:,0], bounds[:,1])\n            candidate_fitness = func(candidate_position)\n            self.current_evaluations += 1\n            \n            if candidate_fitness < personal_best_fitness[global_best_index]:\n                global_best_position = candidate_position\n                global_best_index = np.argmin(personal_best_fitness)\n            \n            self.population_size = max(1, int(10 * self.dim * (1 - self.current_evaluations / self.budget)))\n\n            if self.current_evaluations >= self.budget:\n                break\n\n        return global_best_position, personal_best_fitness[global_best_index]", "name": "AdaptiveQuantumParticleSwarmOptimization", "description": "Introduced adaptive beta for enhanced local search and convergence.", "configspace": "", "generation": 99, "fitness": 0.5107009423748922, "feedback": "The algorithm AdaptiveQuantumParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.511 with standard deviation 0.040. And the mean value of best solutions found was 0.000 (0. is the best).", "error": "", "parent_id": "0ac3b5ed-a451-455a-881a-2b3eabe44caa", "metadata": {"aucs": [0.5663007661744146, 0.48995536561373365, 0.4758466953365281], "final_y": [7.27976465116681e-08, 4.1717538205853814e-07, 1.873607500278341e-06]}, "mutation_prompt": null}
