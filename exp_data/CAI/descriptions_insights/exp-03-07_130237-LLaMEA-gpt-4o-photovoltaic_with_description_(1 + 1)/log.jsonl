{"id": "258b606b-54ac-43ff-8fd2-27216ab97cf2", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A hybrid metaheuristic combining Particle Swarm Optimization (PSO) and Differential Evolution (DE) that dynamically adapts exploration and exploitation strategies to efficiently navigate complex, noisy search spaces.", "configspace": "", "generation": 0, "fitness": 0.820136597104063, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.820 with standard deviation 0.012. And the mean value of best solutions found was 0.138 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": null, "metadata": {"aucs": [0.8038245870096075, 0.8337995263650095, 0.8227856779375718], "final_y": [0.1399517045236106, 0.1365292971883224, 0.13663909242518502]}, "mutation_prompt": null}
{"id": "bd15055b-c5b3-47b9-a5fe-45a98559405e", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.w = 0.9 - 0.5 * (eval_count / self.budget)  # Adaptive inertia weight\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Introduce adaptive inertia weight to enhance exploration and exploitation balance in noisy search spaces.", "configspace": "", "generation": 1, "fitness": 0.8076757110355642, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.808 with standard deviation 0.010. And the mean value of best solutions found was 0.138 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "258b606b-54ac-43ff-8fd2-27216ab97cf2", "metadata": {"aucs": [0.8054844733024238, 0.8212041139633567, 0.796338545840912], "final_y": [0.13132727046106074, 0.1390781858131267, 0.14317694252317037]}, "mutation_prompt": null}
{"id": "7de6ea21-cd5a-4750-8862-23b674696af7", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.w = 0.9 - (0.5 * eval_count / self.budget)  # Adaptive inertia weight\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Introduced adaptive inertia weight to enhance convergence by balancing exploration and exploitation dynamically.", "configspace": "", "generation": 2, "fitness": 0.8076757110355642, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.808 with standard deviation 0.010. And the mean value of best solutions found was 0.138 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "258b606b-54ac-43ff-8fd2-27216ab97cf2", "metadata": {"aucs": [0.8054844733024238, 0.8212041139633567, 0.796338545840912], "final_y": [0.13132727046106074, 0.1390781858131267, 0.14317694252317037]}, "mutation_prompt": null}
{"id": "101216af-8d1f-4c8a-a8f3-cbb9be5e398f", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.85  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Improved HybridPSODE by fine-tuning crossover probability for better exploration-exploitation balance.", "configspace": "", "generation": 3, "fitness": 0.8162481726494818, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.816 with standard deviation 0.010. And the mean value of best solutions found was 0.137 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "258b606b-54ac-43ff-8fd2-27216ab97cf2", "metadata": {"aucs": [0.8040908457809421, 0.8278427135284924, 0.8168109586390111], "final_y": [0.13745620355924582, 0.13480747690386363, 0.13980390847020918]}, "mutation_prompt": null}
{"id": "59800581-71c3-4e6e-b9af-92888d31d7c0", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w_max = 0.9   # Maximum inertia weight\n        self.w_min = 0.4   # Minimum inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            w = self.w_max - (self.w_max - self.w_min) * (eval_count / self.budget)  # Adaptive inertia weight\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "HybridPSODE with adaptive inertia weight to enhance exploration and exploitation balance.", "configspace": "", "generation": 4, "fitness": 0.8076757110355642, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.808 with standard deviation 0.010. And the mean value of best solutions found was 0.138 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "258b606b-54ac-43ff-8fd2-27216ab97cf2", "metadata": {"aucs": [0.8054844733024238, 0.8212041139633567, 0.796338545840912], "final_y": [0.13132727046106074, 0.1390781858131267, 0.14317694252317037]}, "mutation_prompt": null}
{"id": "41a5d52e-102a-4f4e-8471-f4f64e15960f", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                # Changed line for adaptive inertia weight\n                self.w = 0.9 - (0.5 * (eval_count / self.budget))\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A hybrid metaheuristic combining Particle Swarm Optimization (PSO) and Differential Evolution (DE) with adaptive inertia weight to enhance convergence efficiency in complex, noisy search spaces.", "configspace": "", "generation": 5, "fitness": 0.8076757110355642, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.808 with standard deviation 0.010. And the mean value of best solutions found was 0.138 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "258b606b-54ac-43ff-8fd2-27216ab97cf2", "metadata": {"aucs": [0.8054844733024238, 0.8212041139633567, 0.796338545840912], "final_y": [0.13132727046106074, 0.1390781858131267, 0.14317694252317037]}, "mutation_prompt": null}
{"id": "453ba690-ade1-4063-a7f7-d9e2d5a35523", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.w = 0.9 - eval_count / self.budget * 0.4  # Dynamic inertia weight adjustment\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A hybrid metaheuristic combining Particle Swarm Optimization (PSO) and Differential Evolution (DE) with a dynamic inertia weight adjustment to enhance convergence in noisy search spaces.", "configspace": "", "generation": 6, "fitness": 0.7952233097816682, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.795 with standard deviation 0.008. And the mean value of best solutions found was 0.138 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "258b606b-54ac-43ff-8fd2-27216ab97cf2", "metadata": {"aucs": [0.8036564812942357, 0.7968011707828706, 0.785212277267898], "final_y": [0.14198886704491442, 0.13762878415182356, 0.13520819139610152]}, "mutation_prompt": null}
{"id": "9d8a926e-e686-40d9-b88e-3d9ee2ec454c", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Dynamically adjust inertia weight\n            self.w = 0.4 + (0.7 - 0.4) * (1 - eval_count / self.budget)\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Enhanced HybridPSODE by modifying inertia weight dynamically based on iteration to improve convergence.", "configspace": "", "generation": 7, "fitness": 0.8221084889573738, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.822 with standard deviation 0.008. And the mean value of best solutions found was 0.136 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "258b606b-54ac-43ff-8fd2-27216ab97cf2", "metadata": {"aucs": [0.8189719929116867, 0.8335708459494006, 0.813782628011034], "final_y": [0.13409309683531112, 0.13733415103964697, 0.13762089589743798]}, "mutation_prompt": null}
{"id": "fc08803c-f253-4425-bfb6-b8050dd60b59", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10  # New line\n\n        while eval_count < self.budget:\n            # Dynamically adjust inertia weight\n            self.w = 0.4 + (0.7 - 0.4) * (1 - eval_count / self.budget)\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0  # Reset stagnation counter on improvement\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0    # Reset counter after reinitialization\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Enhanced HybridPSODE by introducing random reinitialization of particles upon stagnation to escape local optima.", "configspace": "", "generation": 8, "fitness": 0.8240194755501197, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.824 with standard deviation 0.014. And the mean value of best solutions found was 0.132 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "9d8a926e-e686-40d9-b88e-3d9ee2ec454c", "metadata": {"aucs": [0.8410979299370461, 0.8252936150837968, 0.8056668816295158], "final_y": [0.12488004209551506, 0.12630492215136158, 0.14430005557314196]}, "mutation_prompt": null}
{"id": "18620584-1660-4b80-b34d-b9d2e9a06eab", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10  # New line\n\n        while eval_count < self.budget:\n            # Dynamically adjust inertia weight\n            self.w = 0.4 + (0.7 - 0.4) * (1 - eval_count / self.budget)\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Differential Evolution Step\n            self.F = 0.5 + 0.3 * np.sin(eval_count / self.budget * np.pi)  # Change here\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0  # Reset stagnation counter on improvement\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0    # Reset counter after reinitialization\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Enhanced HybridPSODE by using adaptive differential weight to improve exploration and exploitation balance.", "configspace": "", "generation": 9, "fitness": 0.8176976546510173, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.818 with standard deviation 0.014. And the mean value of best solutions found was 0.139 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "fc08803c-f253-4425-bfb6-b8050dd60b59", "metadata": {"aucs": [0.8257572374876418, 0.829678475164893, 0.7976572513005169], "final_y": [0.13475238226095954, 0.1367167757227763, 0.1460327952115812]}, "mutation_prompt": null}
{"id": "065940df-fab4-459a-b57a-159cd7847b08", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            self.w = 0.4 + (0.7 - 0.4) * (1 - eval_count / self.budget)\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adaptive Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                self.F = 0.7 + 0.3 * np.random.rand()  # Adaptive F\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                self.CR = 0.8 + 0.1 * np.random.rand()  # Adaptive CR\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0 \n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        perturbation = np.random.uniform(-0.1, 0.1, self.dim)  # Stochastic perturbation\n                        pop[i] = np.clip(pop[i] + perturbation, lb, ub)\n                        stagnation_counter = 0\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Introduced adaptive differential evolution parameters and stochastic perturbation based on stagnation to improve exploration capabilities.", "configspace": "", "generation": 10, "fitness": 0.8149872344933531, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.815 with standard deviation 0.011. And the mean value of best solutions found was 0.135 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "fc08803c-f253-4425-bfb6-b8050dd60b59", "metadata": {"aucs": [0.8181616118749049, 0.8264754360616353, 0.8003246555435191], "final_y": [0.13652704662657522, 0.1265920684835652, 0.14276052115803928]}, "mutation_prompt": null}
{"id": "3de28898-5a2d-4ea3-98f4-e3990a2f4ced", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10  # New line\n\n        while eval_count < self.budget:\n            self.w = 0.4 + (0.7 - 0.4) * (1 - eval_count / self.budget)\n            self.c1 = 2.0 * (1 - eval_count / self.budget) + 1.0  # Line changed\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0  # Reset stagnation counter on improvement\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0    # Reset counter after reinitialization\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Improved HybridPSODE by dynamically adjusting cognitive and social coefficients to strengthen exploration and exploitation balance.", "configspace": "", "generation": 11, "fitness": 0.7983894855905124, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.798 with standard deviation 0.008. And the mean value of best solutions found was 0.145 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "fc08803c-f253-4425-bfb6-b8050dd60b59", "metadata": {"aucs": [0.7870537155559777, 0.8054229412663068, 0.8026917999492525], "final_y": [0.14198960392676963, 0.14693151781575553, 0.14601093254849395]}, "mutation_prompt": null}
{"id": "cc750936-59d3-4d59-ae2d-bf70ccf8ef92", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10  # New line\n\n        while eval_count < self.budget:\n            # Dynamically adjust inertia weight\n            self.w = 0.4 + (0.7 - 0.4) * (1 - eval_count / self.budget)\n            # Adaptive population size reduction\n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))  \n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0  # Reset stagnation counter on improvement\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0    # Reset counter after reinitialization\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Enhanced HybridPSODE by introducing adaptive population size reduction to accelerate convergence in later stages.", "configspace": "", "generation": 12, "fitness": 0.8183036212430536, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.818 with standard deviation 0.003. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "fc08803c-f253-4425-bfb6-b8050dd60b59", "metadata": {"aucs": [0.8215987998559056, 0.813718536978855, 0.8195935268943999], "final_y": [0.12809578102095687, 0.12115656555762522, 0.12506992277767415]}, "mutation_prompt": null}
{"id": "3623bdfb-0207-4493-9465-514b557c032c", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            # Dynamically adjust inertia weight\n            self.w = 0.4 + (0.7 - 0.4) * (1 - eval_count / self.budget)\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Differential Evolution Step\n            self.F = 0.5 + 0.3 * (1 - eval_count / self.budget)  # Adaptive differential weight\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Introducing adaptive differential weight to enhance exploration-exploitation balance in the Enhanced HybridPSODE.", "configspace": "", "generation": 13, "fitness": 0.8151081043213857, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.815 with standard deviation 0.025. And the mean value of best solutions found was 0.138 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "fc08803c-f253-4425-bfb6-b8050dd60b59", "metadata": {"aucs": [0.7812669128988998, 0.8238562538152279, 0.8402011462500295], "final_y": [0.1473106052707125, 0.137492065860507, 0.12784585638990276]}, "mutation_prompt": null}
{"id": "69b0e08d-4e2c-4a3a-aee8-f44701ef11f5", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            self.w = 0.4 + (0.5 - 0.4) * (1 - eval_count / self.budget)  # Changed line\n            self.F = 0.7 + 0.3 * np.random.rand()  # Changed line\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                if np.random.rand() < 0.1:  # New line\n                    velocities[i] += np.random.normal(0, 0.1, self.dim)  # New line\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Enhanced HybridPSODE with adaptive parameters and random velocity perturbations for improved exploration and convergence.", "configspace": "", "generation": 14, "fitness": 0.8061017110745987, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.806 with standard deviation 0.007. And the mean value of best solutions found was 0.144 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "fc08803c-f253-4425-bfb6-b8050dd60b59", "metadata": {"aucs": [0.7963919889375728, 0.8093179730991173, 0.8125951711871059], "final_y": [0.1462089699298359, 0.1402656334785911, 0.14514640034996007]}, "mutation_prompt": null}
{"id": "27eef7f5-ba8f-4199-bf86-132b43c79915", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.6  # Cognitive coefficient (changed from 1.5)\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            # Dynamically adjust inertia weight\n            self.w = 0.4 + (0.7 - 0.4) * (1 - eval_count / self.budget)\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0  # Reset stagnation counter on improvement\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0    # Reset counter after reinitialization\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Enhanced HybridPSODE by slightly increasing the cognitive coefficient to improve exploration capabilities and escape local optima.", "configspace": "", "generation": 15, "fitness": 0.8088841293978991, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.809 with standard deviation 0.003. And the mean value of best solutions found was 0.139 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "fc08803c-f253-4425-bfb6-b8050dd60b59", "metadata": {"aucs": [0.8063754959003083, 0.8131186097030874, 0.8071582825903018], "final_y": [0.13557959561392463, 0.13977756702690514, 0.14082031837441045]}, "mutation_prompt": null}
{"id": "8fa84223-5245-4dc0-a33a-1ffef82a524b", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            # Dynamically adjust inertia weight\n            self.w = 0.4 + (0.7 - 0.4) * (1 - eval_count / self.budget)\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Introduce mutation for diversity\n                mutation_chance = 0.1\n                if np.random.rand() < mutation_chance:\n                    trial += np.random.normal(0, 0.1, self.dim)\n                    trial = np.clip(trial, lb, ub)\n                \n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Adaptive HybridPSODE improves convergence by dynamically adjusting parameters based on individual improvement rates and introducing mutation for more diversity.", "configspace": "", "generation": 16, "fitness": 0.7941348417674748, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.794 with standard deviation 0.022. And the mean value of best solutions found was 0.145 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "fc08803c-f253-4425-bfb6-b8050dd60b59", "metadata": {"aucs": [0.7852569766595183, 0.8248135449939185, 0.7723340036489876], "final_y": [0.13391562888289132, 0.1426789247934256, 0.15977058146089562]}, "mutation_prompt": null}
{"id": "802db772-62bc-43f0-8aa9-cba0ba922f12", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10  # New line\n\n        while eval_count < self.budget:\n            # Dynamically adjust inertia weight\n            self.w = 0.4 + (0.7 - 0.4) * (1 - eval_count / self.budget)\n            # Adjust cognitive and social coefficients dynamically\n            self.c1 = 1.0 + (1.5 - 1.0) * eval_count / self.budget\n            self.c2 = 2.0 - (1.5 - 1.0) * eval_count / self.budget\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0  # Reset stagnation counter on improvement\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0    # Reset counter after reinitialization\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Improved HybridPSODE by adapting cognitive and social coefficients dynamically based on iteration progress.", "configspace": "", "generation": 17, "fitness": 0.8123883159409634, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.812 with standard deviation 0.015. And the mean value of best solutions found was 0.135 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "fc08803c-f253-4425-bfb6-b8050dd60b59", "metadata": {"aucs": [0.7933520278575298, 0.8127735629291657, 0.8310393570361945], "final_y": [0.13179673389363666, 0.1434245738690293, 0.12865338207549104]}, "mutation_prompt": null}
{"id": "a468113a-ecc1-4e49-9c2d-3ee0ab749848", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10  # New line\n\n        while eval_count < self.budget:\n            self.w = 0.4 + (0.7 - 0.4) * (1 - eval_count / self.budget)  # Existing line\n            self.CR = 0.6 + 0.3 * (global_best_score / np.max(personal_best_scores))  # Modified line\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0  # Reset stagnation counter on improvement\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0    # Reset counter after reinitialization\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Enhanced HybridPSODE with adaptive crossover probability to dynamically balance exploration and exploitation.", "configspace": "", "generation": 18, "fitness": 0.8202861628555403, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.820 with standard deviation 0.005. And the mean value of best solutions found was 0.136 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "fc08803c-f253-4425-bfb6-b8050dd60b59", "metadata": {"aucs": [0.8258109661553898, 0.8128051647978418, 0.8222423576133893], "final_y": [0.13264143742215384, 0.13782704727924133, 0.1388156492080136]}, "mutation_prompt": null}
{"id": "4c711dbc-d9f1-4aec-ab01-5a07666f4462", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10  # New line\n\n        while eval_count < self.budget:\n            # Dynamically adjust inertia weight\n            self.w = 0.4 + (0.7 - 0.4) * (1 - eval_count / self.budget)\n            # Dynamically adjust cognitive and social coefficients\n            self.c1 = 1.5 + (0.5 * eval_count / self.budget)\n            self.c2 = 1.5 - (0.5 * eval_count / self.budget)\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0  # Reset stagnation counter on improvement\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0    # Reset counter after reinitialization\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Improved HybridPSODE by dynamically adjusting the cognitive and social coefficients over iterations to better balance exploration and exploitation.", "configspace": "", "generation": 19, "fitness": 0.8128296904025666, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.813 with standard deviation 0.004. And the mean value of best solutions found was 0.138 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "fc08803c-f253-4425-bfb6-b8050dd60b59", "metadata": {"aucs": [0.8079871070250473, 0.8168537536024889, 0.8136482105801638], "final_y": [0.14374788961233298, 0.13913615904203447, 0.13043395408064107]}, "mutation_prompt": null}
{"id": "214c504c-84be-46a2-90b4-e5562b283669", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10  # New line\n\n        while eval_count < self.budget:\n            # Dynamically adjust inertia weight\n            self.w = 0.4 + (0.7 - 0.4) * (1 - eval_count / self.budget)\n            self.c1 = 1.0 + (2.0 - 1.0) * (1 - eval_count / self.budget)  # Adjusting line\n            self.c2 = 1.0 + (2.0 - 1.0) * (eval_count / self.budget)  # Adjusting line\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0  # Reset stagnation counter on improvement\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0    # Reset counter after reinitialization\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Improved HybridPSODE by dynamically adjusting the cognitive and social coefficients based on the current evaluation ratio to better balance exploration and exploitation.", "configspace": "", "generation": 20, "fitness": 0.809679602071054, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.810 with standard deviation 0.022. And the mean value of best solutions found was 0.141 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "fc08803c-f253-4425-bfb6-b8050dd60b59", "metadata": {"aucs": [0.785262356719506, 0.8385686838413031, 0.8052077656523533], "final_y": [0.14052320500492788, 0.13669061325030274, 0.1466970037223616]}, "mutation_prompt": null}
{"id": "2d2b4655-a285-46e8-93ad-261f416efc8a", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10  # New line\n\n        while eval_count < self.budget:\n            # Dynamically adjust inertia weight\n            self.w = 0.6 + (0.9 - 0.6) * (1 - eval_count / self.budget)  # Changed line\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0  # Reset stagnation counter on improvement\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0    # Reset counter after reinitialization\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Improved HybridPSODE by fine-tuning the inertia weight decay to enhance convergence speed and solution quality.", "configspace": "", "generation": 21, "fitness": 0.7844104398570373, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.784 with standard deviation 0.016. And the mean value of best solutions found was 0.146 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "fc08803c-f253-4425-bfb6-b8050dd60b59", "metadata": {"aucs": [0.7704642391669392, 0.8070095897362002, 0.7757574906679723], "final_y": [0.14335385762024044, 0.14540517637212103, 0.14801217475762163]}, "mutation_prompt": null}
{"id": "3e0b864c-ca42-489d-9dbc-909220efe509", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10  # New line\n\n        while eval_count < self.budget:\n            # Dynamically adjust inertia weight\n            self.w = 0.4 + (0.7 - 0.4) * (1 - eval_count / self.budget)\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                # Slightly modified this line\n                mutant = np.clip(a + self.F * (b - c) + 0.1 * np.random.randn(self.dim), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0  # Reset stagnation counter on improvement\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0    # Reset counter after reinitialization\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Enhanced HybridPSODE by optimizing stochastic perturbation in differential evolution step to improve exploration efficiency.", "configspace": "", "generation": 22, "fitness": 0.8096438366117185, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.810 with standard deviation 0.018. And the mean value of best solutions found was 0.138 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "fc08803c-f253-4425-bfb6-b8050dd60b59", "metadata": {"aucs": [0.7845260970542203, 0.8217360631106966, 0.8226693496702385], "final_y": [0.1366888516911664, 0.1475558607429489, 0.13094287240660696]}, "mutation_prompt": null}
{"id": "d767ce2e-d408-49a2-8ec1-3e4df54f1541", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10  # New line\n\n        while eval_count < self.budget:\n            # Dynamically adjust inertia weight\n            self.w = 0.4 + (0.7 - 0.4) * (1 - eval_count / self.budget)\n            self.CR = 0.5 + (0.9 - 0.5) * (eval_count / self.budget)  # Change 1: Adaptive crossover probability\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0  # Reset stagnation counter on improvement\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0    # Reset counter after reinitialization\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Improved HybridPSODE by introducing adaptive crossover probability for faster convergence.", "configspace": "", "generation": 23, "fitness": 0.815601679073529, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.816 with standard deviation 0.023. And the mean value of best solutions found was 0.138 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "fc08803c-f253-4425-bfb6-b8050dd60b59", "metadata": {"aucs": [0.8328823751215072, 0.8303007332300972, 0.7836219288689825], "final_y": [0.1327194942689096, 0.13418058615002182, 0.14570168141322548]}, "mutation_prompt": null}
{"id": "438cfce0-5342-4acf-9201-021de48b08da", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10  # New line\n\n        while eval_count < self.budget:\n            # Dynamically adjust inertia weight\n            self.w = 0.4 + (0.7 - 0.4) * (1 - eval_count / self.budget)\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                mutant = np.clip(a + self.F * (b - c) * (1 - eval_count / self.budget), lb, ub)  # Modifying this line\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0  # Reset stagnation counter on improvement\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0    # Reset counter after reinitialization\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Improved HybridPSODE by adjusting the Differential Evolution step to more effectively balance exploration and exploitation.", "configspace": "", "generation": 24, "fitness": 0.8224787299499464, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.822 with standard deviation 0.014. And the mean value of best solutions found was 0.130 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "fc08803c-f253-4425-bfb6-b8050dd60b59", "metadata": {"aucs": [0.8034678172797456, 0.8344823780087631, 0.8294859945613307], "final_y": [0.13558868008918346, 0.1255644825393475, 0.12952359164392013]}, "mutation_prompt": null}
{"id": "022cbd81-a75c-42f5-ae23-75f6dc30d87f", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = np.zeros(self.population_size)  # Changed to array\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            self.w = 0.5 + (0.9 - 0.5) * (1 - eval_count / self.budget)  # Modified\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter[i] = 0  # Modified to array\n                    else:\n                        stagnation_counter[i] += 1  # Modified to array\n                    if stagnation_counter[i] >= stagnation_threshold:  # Modified\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter[i] = 0  # Modified\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Improved HybridPSODE through adaptive parameters and dynamic reinitialization based on individual particle performance for enhanced exploration.", "configspace": "", "generation": 25, "fitness": 0.7952233097816682, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.795 with standard deviation 0.008. And the mean value of best solutions found was 0.138 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "fc08803c-f253-4425-bfb6-b8050dd60b59", "metadata": {"aucs": [0.8036564812942357, 0.7968011707828706, 0.785212277267898], "final_y": [0.14198886704491454, 0.13762878415182322, 0.1352081913961014]}, "mutation_prompt": null}
{"id": "9c856a6b-e5fe-4ad5-9980-1c2d52e32b5e", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            # Dynamically adjust inertia weight\n            self.w = 0.4 + (0.7 - 0.4) * (1 - eval_count / self.budget)\n            self.c1 = 1.2 + (1.5 - 1.2) * (eval_count / self.budget)  # Adjust cognitive coefficient\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0  # Reset stagnation counter on improvement\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0    # Reset counter after reinitialization\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Enhanced HybridPSODE by dynamically adjusting the cognitive coefficient to improve convergence speed and solution quality.", "configspace": "", "generation": 26, "fitness": 0.8256549414881302, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.826 with standard deviation 0.006. And the mean value of best solutions found was 0.135 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "fc08803c-f253-4425-bfb6-b8050dd60b59", "metadata": {"aucs": [0.8207956614972376, 0.8347990375729625, 0.8213701253941907], "final_y": [0.13237526150101742, 0.13352038716525483, 0.1397400729841235]}, "mutation_prompt": null}
{"id": "23c2fbe1-f758-4b99-898e-de735f368bcf", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            # Dynamically adjust inertia weight\n            self.w = 0.4 + (0.7 - 0.4) * (1 - eval_count / self.budget)\n            self.c1 = 1.2 + (1.5 - 1.2) * (eval_count / self.budget)  # Adjust cognitive coefficient\n            self.F = 0.5 + 0.3 * np.cos(np.pi * eval_count / self.budget)  # Adaptive differential weight\n            self.CR = 0.7 + 0.2 * np.sin(np.pi * eval_count / self.budget)  # Dynamic crossover probability\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0  # Reset stagnation counter on improvement\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0    # Reset counter after reinitialization\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Enhanced HybridPSODE with adaptive differential weight and dynamic crossover probability for diversified exploration and exploitation balance.", "configspace": "", "generation": 27, "fitness": 0.822064002578356, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.822 with standard deviation 0.008. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "9c856a6b-e5fe-4ad5-9980-1c2d52e32b5e", "metadata": {"aucs": [0.8139147854722917, 0.8320961036065488, 0.8201811186562276], "final_y": [0.12365521809050717, 0.12575170697615357, 0.13106325733347401]}, "mutation_prompt": null}
{"id": "6a985a81-48ea-4030-964e-4dd2ad5b1988", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            # Dynamically adjust inertia weight\n            self.w = 0.5 + (0.9 - 0.5) * (1 - eval_count / self.budget)  # Changed inertia weight bounds\n            self.c1 = 1.2 + (1.5 - 1.2) * (eval_count / self.budget)\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0  # Reset stagnation counter on improvement\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        velocities[i] = np.random.uniform(-abs(ub - lb), abs(ub - lb), self.dim)  # Reset velocity\n                        stagnation_counter = 0  # Reset counter after reinitialization\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Modify inertia weight and introduce a dynamic reset mechanism to enhance exploration and exploitation balance.", "configspace": "", "generation": 28, "fitness": 0.7831412966221913, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.783 with standard deviation 0.011. And the mean value of best solutions found was 0.150 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "9c856a6b-e5fe-4ad5-9980-1c2d52e32b5e", "metadata": {"aucs": [0.7682530233423606, 0.794985682378356, 0.7861851841458574], "final_y": [0.14479953962646275, 0.15935197978848237, 0.1455855431740385]}, "mutation_prompt": null}
{"id": "5c0ee661-816c-4011-a2ee-4a5807542f4d", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            # Dynamically adjust inertia weight\n            self.w = 0.4 + (0.7 - 0.4) * (1 - eval_count / self.budget)\n            self.c1 = 1.2 + (1.5 - 1.2) * (eval_count / self.budget)  # Adjust cognitive coefficient\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                velocities[i] = np.clip(velocities[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  # Velocity clamping\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0  # Reset stagnation counter on improvement\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0    # Reset counter after reinitialization\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Enhanced HybridPSODE by introducing velocity clamping to prevent particles from overshooting the target region and improve convergence stability.", "configspace": "", "generation": 29, "fitness": 0.8475088343972882, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.848 with standard deviation 0.016. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "9c856a6b-e5fe-4ad5-9980-1c2d52e32b5e", "metadata": {"aucs": [0.8258725265384402, 0.8651065875128724, 0.8515473891405522], "final_y": [0.12363378899742894, 0.12381465116395718, 0.11683648911840083]}, "mutation_prompt": null}
{"id": "16b9675f-9533-44b0-9b2a-e6a24039b042", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            # Dynamically adjust inertia weight\n            self.w = 0.4 + (0.7 - 0.4) * (1 - eval_count / self.budget)\n            self.c1 = 1.2 + (1.5 - 1.2) * (eval_count / self.budget)  # Adjust cognitive coefficient\n            self.CR = 0.6 + 0.4 * (1 - eval_count / self.budget)  # Dynamic Crossover probability\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                velocities[i] = np.clip(velocities[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  # Velocity clamping\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0  # Reset stagnation counter on improvement\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0    # Reset counter after reinitialization\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Enhanced HybridPSODE by implementing a dynamic crossover probability to balance exploration and exploitation.", "configspace": "", "generation": 30, "fitness": 0.845839807822002, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.846 with standard deviation 0.009. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "5c0ee661-816c-4011-a2ee-4a5807542f4d", "metadata": {"aucs": [0.8506465231441898, 0.8542536656833856, 0.8326192346384305], "final_y": [0.12819474874096504, 0.11614959309206252, 0.12384053387483351]}, "mutation_prompt": null}
{"id": "d5b14d52-4f02-4dec-a4ea-6e1042d97a0b", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            # Dynamically adjust inertia weight\n            self.w = 0.4 + (0.7 - 0.4) * (1 - eval_count / self.budget)\n            self.c1 = 1.2 + (1.5 - 1.2) * (eval_count / self.budget)  # Adjust cognitive coefficient\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                velocities[i] = np.clip(velocities[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  # Velocity clamping\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < (self.CR - 0.5 * eval_count / self.budget)  # Adaptive CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0  # Reset stagnation counter on improvement\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0    # Reset counter after reinitialization\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Introduced adaptive crossover probability to balance exploration and exploitation.", "configspace": "", "generation": 31, "fitness": 0.8514635206172053, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.851 with standard deviation 0.007. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "5c0ee661-816c-4011-a2ee-4a5807542f4d", "metadata": {"aucs": [0.8535144518563527, 0.8590714341852403, 0.841804675810023], "final_y": [0.1170228521942892, 0.11405434394124647, 0.12330870165159735]}, "mutation_prompt": null}
{"id": "8920d517-d6a7-4343-9e35-50a7a51535d6", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            # Dynamically adjust inertia weight\n            self.w = 0.4 + (0.7 - 0.4) * (1 - eval_count / self.budget)\n            self.c1 = 1.2 + (1.5 - 1.2) * (eval_count / self.budget)  # Adjust cognitive coefficient\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                velocities[i] = np.clip(velocities[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  # Velocity clamping\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                self.F = 0.8 + 0.2 * np.random.rand()  # Adaptive Differential weight\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < (self.CR - 0.5 * eval_count / self.budget)  # Adaptive CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0  # Reset stagnation counter on improvement\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0    # Reset counter after reinitialization\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Introduced adaptive differential weight to enhance exploration adaptivity.", "configspace": "", "generation": 32, "fitness": 0.8573975400140125, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.857 with standard deviation 0.020. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "d5b14d52-4f02-4dec-a4ea-6e1042d97a0b", "metadata": {"aucs": [0.8452779225134581, 0.8850436523210272, 0.8418710452075524], "final_y": [0.11444469168696514, 0.11558440005978854, 0.122125915123098]}, "mutation_prompt": null}
{"id": "42e4e620-f32a-46a0-9bfb-36f5adaf4826", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            # Dynamically adjust inertia weight\n            self.w = 0.4 + (0.7 - 0.4) * (1 - eval_count / self.budget)\n            self.c1 = 1.2 + (1.5 - 1.2) * (eval_count / self.budget)  # Adjust cognitive coefficient\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                velocities[i] = np.clip(velocities[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  # Velocity clamping\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                self.F = 0.8 + 0.2 * np.random.rand()  # Adaptive Differential weight\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                self.CR = 0.8 + 0.1 * np.sin(np.pi * eval_count / self.budget)  # Adaptive CR\n                cross_points = np.random.rand(self.dim) < (self.CR - 0.5 * eval_count / self.budget)  # Adaptive CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0  # Reset stagnation counter on improvement\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0    # Reset counter after reinitialization\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Introduced dynamic adjustment of crossover probability to further enhance exploration and exploitation balance.", "configspace": "", "generation": 33, "fitness": 0.8474219949384553, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.847 with standard deviation 0.005. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "8920d517-d6a7-4343-9e35-50a7a51535d6", "metadata": {"aucs": [0.8409813481578186, 0.8495062728093953, 0.8517783638481521], "final_y": [0.11900872337282375, 0.11981800810470822, 0.11424604975060348]}, "mutation_prompt": null}
{"id": "e5f00906-d33b-414f-8836-17bc24ddd8db", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            # Dynamically adjust inertia weight\n            self.w = 0.4 + (0.7 - 0.4) * (1 - eval_count / self.budget)\n            self.c1 = 1.2 + (1.5 - 1.2) * (eval_count / self.budget)  # Adjust cognitive coefficient\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                # Adjusted line for dynamic velocity clamping\n                velocities[i] = np.clip(velocities[i], -0.1 * np.std(pop, axis=0), 0.1 * np.std(pop, axis=0))\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                self.F = 0.8 + 0.2 * np.random.rand()  # Adaptive Differential weight\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < (self.CR - 0.5 * eval_count / self.budget)  # Adaptive CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0  # Reset stagnation counter on improvement\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0    # Reset counter after reinitialization\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Enhanced exploration by adjusting velocity clamping dynamically based on population diversity.", "configspace": "", "generation": 34, "fitness": 0.8123614043506304, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.812 with standard deviation 0.013. And the mean value of best solutions found was 0.135 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "8920d517-d6a7-4343-9e35-50a7a51535d6", "metadata": {"aucs": [0.7946611164066342, 0.8167562353382286, 0.8256668613070286], "final_y": [0.12304019707996972, 0.1419421049967231, 0.13907856442815503]}, "mutation_prompt": null}
{"id": "8560b321-8f1d-4a1c-b07b-e540644a318b", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            # Dynamically adjust inertia weight\n            self.w = 0.3 + (0.9 - 0.3) * (1 - eval_count / self.budget)  # Changed\n            self.c1 = 1.2 + (1.5 - 1.2) * (eval_count / self.budget)  # Adjust cognitive coefficient\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                velocities[i] = np.clip(velocities[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  # Velocity clamping\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                self.F = 0.7 + 0.3 * np.random.rand()  # Adaptive Differential weight, Changed\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < (self.CR - 0.5 * eval_count / self.budget)  # Adaptive CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0  # Reset stagnation counter on improvement\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0    # Reset counter after reinitialization\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Adaptive inertia weight and mutation factor adjustment for improved convergence.", "configspace": "", "generation": 35, "fitness": 0.8535350102711826, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.854 with standard deviation 0.003. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "8920d517-d6a7-4343-9e35-50a7a51535d6", "metadata": {"aucs": [0.853029519197234, 0.8501616403971071, 0.857413871219207], "final_y": [0.12068534277132781, 0.12194615221594018, 0.11737239805512711]}, "mutation_prompt": null}
{"id": "1986d979-35f7-4efe-9f73-52f3893dc983", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            # Dynamically adjust inertia weight\n            self.w = 0.4 + (0.7 - 0.4) * (1 - eval_count / self.budget)\n            self.c1 = 1.2 + (1.5 - 1.2) * (eval_count / self.budget)  # Adjust cognitive coefficient\n            self.population_size = int(50 * (1 - eval_count / self.budget)) + 10  # Adaptive population size\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                velocities[i] = np.clip(velocities[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  # Velocity clamping\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                self.F = 0.8 + 0.2 * np.random.rand()  # Adaptive Differential weight\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < (self.CR - 0.5 * eval_count / self.budget)  # Adaptive CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0  # Reset stagnation counter on improvement\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0    # Reset counter after reinitialization\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Incorporated adaptive population size to dynamically balance exploration and exploitation.", "configspace": "", "generation": 36, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 50 is out of bounds for axis 0 with size 50').", "error": "IndexError('index 50 is out of bounds for axis 0 with size 50')", "parent_id": "8920d517-d6a7-4343-9e35-50a7a51535d6", "metadata": {}, "mutation_prompt": null}
{"id": "004530ac-0620-474d-876a-cc9f02116aef", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            # Dynamically adjust inertia weight\n            self.w = 0.4 + (0.7 - 0.4) * (1 - eval_count / self.budget)\n            improvement_rate = min(1.0, 0.5 * stagnation_counter / stagnation_threshold)\n            self.c1 = 1.2 + (1.5 - 1.2) * (eval_count / self.budget) * improvement_rate  # Adjust cognitive coefficient\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                velocities[i] = np.clip(velocities[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  # Velocity clamping\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                self.F = 0.8 + 0.2 * np.random.rand()  # Adaptive Differential weight\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < (self.CR - 0.5 * eval_count / self.budget)  # Adaptive CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0  # Reset stagnation counter on improvement\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0    # Reset counter after reinitialization\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Enhanced adaptivity by introducing a dynamic cognitive coefficient scaling based on improvement rate.", "configspace": "", "generation": 37, "fitness": 0.8533789790370748, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.853 with standard deviation 0.015. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "8920d517-d6a7-4343-9e35-50a7a51535d6", "metadata": {"aucs": [0.8470533035493942, 0.8738233276525246, 0.8392603059093058], "final_y": [0.11449252722743397, 0.1192001144316246, 0.11926223188847895]}, "mutation_prompt": null}
{"id": "a50a2979-5995-401b-bf07-1f195833c994", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            # Dynamically adjust inertia weight\n            self.w = 0.4 + (0.7 - 0.4) * (1 - eval_count / self.budget)\n            self.c1 = 1.2 + (1.5 - 1.2) * (eval_count / self.budget)  # Adjust cognitive coefficient\n            self.c2 = 1.0 + (2.0 - 1.0) * (1 - eval_count / self.budget)  # Adaptive social coefficient\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                velocities[i] = np.clip(velocities[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  # Velocity clamping\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                self.F = 0.8 + 0.2 * np.random.rand()  # Adaptive Differential weight\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < (self.CR - 0.5 * eval_count / self.budget)  # Adaptive CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0  # Reset stagnation counter on improvement\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)  # Reintroduce diversity\n                        stagnation_counter = 0  # Reset counter after reinitialization\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Improved global exploration through adaptive social coefficient and reintroduction strategy to tackle convergence stagnation.", "configspace": "", "generation": 38, "fitness": 0.8553511816969426, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.855 with standard deviation 0.021. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "8920d517-d6a7-4343-9e35-50a7a51535d6", "metadata": {"aucs": [0.8259299788165676, 0.8765054763003747, 0.8636180899738857], "final_y": [0.12046246547120165, 0.11486234185486444, 0.12162027332079972]}, "mutation_prompt": null}
{"id": "d7facc5e-a102-4590-bce1-0c543ec22c3d", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            # Dynamically adjust inertia weight\n            self.w = 0.4 + (0.7 - 0.4) * (1 - eval_count / self.budget)\n            self.c1 = 1.2 + (1.5 - 1.2) * (eval_count / self.budget)  # Adjust cognitive coefficient\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                velocities[i] = np.clip(velocities[i], -0.15 * (ub - lb), 0.15 * (ub - lb))  # Velocity clamping\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                self.F = 0.8 + 0.2 * np.random.rand()  # Adaptive Differential weight\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < (self.CR - 0.5 * eval_count / self.budget)  # Adaptive CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0  # Reset stagnation counter on improvement\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0    # Reset counter after reinitialization\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Slightly adjusted the velocity clamping to increase exploration capabilities.", "configspace": "", "generation": 39, "fitness": 0.8484642710072262, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.848 with standard deviation 0.006. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "8920d517-d6a7-4343-9e35-50a7a51535d6", "metadata": {"aucs": [0.8438053387646596, 0.8562731627409337, 0.8453143115160854], "final_y": [0.11688675092950529, 0.12617794429710816, 0.12241007375009172]}, "mutation_prompt": null}
{"id": "a8327033-2866-452b-a0e8-4943ac9c76c7", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            # Dynamically adjust inertia weight\n            self.w = 0.4 + (0.7 - 0.4) * (1 - eval_count / self.budget)\n            self.c1 = 1.2 + (1.5 - 1.2) * (eval_count / self.budget)  # Adjust cognitive coefficient\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                velocities[i] = np.clip(velocities[i], -0.1 * (ub - lb) * (1 - eval_count / self.budget), 0.1 * (ub - lb) * (1 - eval_count / self.budget))  # Adaptive velocity clamping\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                self.F = 0.8 + 0.2 * np.random.rand()  # Adaptive Differential weight\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < (self.CR - 0.5 * eval_count / self.budget)  # Adaptive CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0  # Reset stagnation counter on improvement\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0    # Reset counter after reinitialization\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Introduced adaptive velocity clamping to enhance convergence adaptability.", "configspace": "", "generation": 40, "fitness": 0.847425948956324, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.847 with standard deviation 0.011. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "8920d517-d6a7-4343-9e35-50a7a51535d6", "metadata": {"aucs": [0.838775937598451, 0.8629984744309633, 0.8405034348395575], "final_y": [0.11767421489541696, 0.12327690755553555, 0.12314571010718756]}, "mutation_prompt": null}
{"id": "f8cac418-f780-4184-9918-2bd4e5c1fe51", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            # Dynamically adjust inertia weight\n            self.w = 0.9 - (0.5 * eval_count / self.budget)  # Adjusted inertia weight decay\n            self.c1 = 1.2 + (1.5 - 1.2) * (eval_count / self.budget)  # Adjust cognitive coefficient\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                velocities[i] = np.clip(velocities[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  # Velocity clamping\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                self.F = 0.8 + 0.2 * np.random.rand()  # Adaptive Differential weight\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < (self.CR - 0.5 * eval_count / self.budget)  # Adaptive CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0  # Reset stagnation counter on improvement\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0    # Reset counter after reinitialization\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Introduced adaptive inertia weight decay for enhanced balance in exploration and exploitation.", "configspace": "", "generation": 41, "fitness": 0.8406643543463517, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.841 with standard deviation 0.011. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "8920d517-d6a7-4343-9e35-50a7a51535d6", "metadata": {"aucs": [0.8402505895182198, 0.8548922550296234, 0.8268502184912114], "final_y": [0.12184784999914666, 0.11858839935304322, 0.12745034947555778]}, "mutation_prompt": null}
{"id": "afb7a790-e16e-4977-afd1-09567b01d16d", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            # Dynamically adjust inertia weight\n            self.w = 0.4 + (0.6 - 0.4) * np.cos(np.pi * eval_count / (2 * self.budget))\n            self.c2 = 1.2 + (1.7 - 1.2) * np.sin(np.pi * eval_count / (2 * self.budget))  # Modified social coefficient\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                velocities[i] = np.clip(velocities[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  # Velocity clamping\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                self.F = 0.6 + 0.4 * np.random.rand()  # Modified adaptive Differential weight\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < (self.CR - 0.3 * eval_count / self.budget)  # Adaptive CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0  # Reset stagnation counter on improvement\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0    # Reset counter after reinitialization\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Enhanced adaptive mechanisms with dynamic parameter control for improved convergence and diversity management.", "configspace": "", "generation": 42, "fitness": 0.8399854104565881, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.840 with standard deviation 0.025. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "8920d517-d6a7-4343-9e35-50a7a51535d6", "metadata": {"aucs": [0.8091875714967394, 0.8711513704265068, 0.8396172894465183], "final_y": [0.1304555480843852, 0.12102753618971451, 0.12666151167674533]}, "mutation_prompt": null}
{"id": "ac2c7a06-485f-4c76-b7e8-009394b4451e", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            # Dynamically adjust inertia weight\n            self.w = 0.4 + (0.7 - 0.4) * (1 - eval_count / self.budget)\n            self.c1 = 1.2 + (1.5 - 1.2) * (eval_count / self.budget)  # Adjust cognitive coefficient\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                velocities[i] = np.clip(velocities[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  # Velocity clamping\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                self.F = 0.8 + 0.2 * np.random.rand()  # Adaptive Differential weight\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < (self.CR - 0.5 * eval_count / self.budget) ** 0.5  # Adaptive CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0  # Reset stagnation counter on improvement\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0    # Reset counter after reinitialization\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Enhanced adaptive crossover probability for better exploration during early evaluations.", "configspace": "", "generation": 43, "fitness": 0.8314231387742735, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.831 with standard deviation 0.008. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "8920d517-d6a7-4343-9e35-50a7a51535d6", "metadata": {"aucs": [0.8197921203952228, 0.8351014016554105, 0.8393758942721873], "final_y": [0.12432440691397362, 0.1256538088490774, 0.12189730763637852]}, "mutation_prompt": null}
{"id": "5ab6f9a7-c465-4982-9fa5-3874725a322b", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            # Dynamically adjust inertia weight\n            self.w = 0.4 + (0.7 - 0.4) * (1 - eval_count / self.budget)\n            self.c1 = 1.2 + (1.5 - 1.2) * (eval_count / self.budget)  # Adjust cognitive coefficient\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                velocities[i] = np.clip(velocities[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  # Velocity clamping\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                self.F = 0.8 + 0.2 * np.random.rand()  # Adaptive Differential weight\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < (self.CR - 0.25 * eval_count / self.budget)  # Enhanced adaptive CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0  # Reset stagnation counter on improvement\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0    # Reset counter after reinitialization\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Enhanced the adaptivity of crossover probability to better balance exploration and exploitation.", "configspace": "", "generation": 44, "fitness": 0.8504311038756338, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.850 with standard deviation 0.004. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "8920d517-d6a7-4343-9e35-50a7a51535d6", "metadata": {"aucs": [0.8462277806452525, 0.8565467604791868, 0.8485187705024622], "final_y": [0.12028820234843762, 0.12455894397769685, 0.11976592657228091]}, "mutation_prompt": null}
{"id": "510dcb70-d171-4e00-967c-6bbcbb83ab4e", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            # Dynamically adjust inertia weight\n            self.w = 0.4 + (0.7 - 0.4) * (1 - eval_count / self.budget)\n            self.c1 = 1.2 + (1.5 - 1.2) * (eval_count / self.budget)  # Adjust cognitive coefficient\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                velocities[i] = np.clip(velocities[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  # Velocity clamping\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                self.F = 0.8 + 0.2 * np.random.rand()  # Adaptive Differential weight\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < (self.CR - 0.5 * eval_count / self.budget)  # Adaptive CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0  # Reset stagnation counter on improvement\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim) * np.random.rand()\n                        stagnation_counter = 0    # Reset counter after reinitialization\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Introduced stagnation-triggered dynamic reinitialization to enhance exploration diversity.", "configspace": "", "generation": 45, "fitness": 0.8522592082800422, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.852 with standard deviation 0.006. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "8920d517-d6a7-4343-9e35-50a7a51535d6", "metadata": {"aucs": [0.8498558787031378, 0.860774407947268, 0.846147338189721], "final_y": [0.12211251380561128, 0.11578605929187258, 0.11799652189484322]}, "mutation_prompt": null}
{"id": "97632f0b-9ca2-4e9a-8797-25eedcd4c573", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            # Dynamically adjust inertia weight\n            self.w = 0.4 + (0.7 - 0.4) * (1 - eval_count / self.budget)\n            self.c1 = 1.2 + (1.5 - 1.2) * (eval_count / self.budget)  # Adjust cognitive coefficient\n            dynamic_population_size = int(self.population_size * (1 - eval_count / self.budget))  # Adaptive population size\n            for i in range(dynamic_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                velocities[i] = np.clip(velocities[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  # Velocity clamping\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Differential Evolution Step\n            for i in range(dynamic_population_size):\n                indices = np.random.choice(dynamic_population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                self.F = 0.8 + 0.2 * np.random.rand()  # Adaptive Differential weight\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < (self.CR - 0.5 * eval_count / self.budget)  # Adaptive CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0  # Reset stagnation counter on improvement\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0    # Reset counter after reinitialization\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Introduced adaptive population size reduction to enhance exploitation during convergence.", "configspace": "", "generation": 46, "fitness": -Infinity, "feedback": "An exception occurred: ValueError(\"Cannot take a larger sample than population when 'replace=False'\").", "error": "ValueError(\"Cannot take a larger sample than population when 'replace=False'\")", "parent_id": "8920d517-d6a7-4343-9e35-50a7a51535d6", "metadata": {}, "mutation_prompt": null}
{"id": "f3fec1f1-b6c4-45fd-9f68-6627b3bbc09d", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            # Dynamically adjust inertia weight\n            self.w = 0.4 + (0.7 - 0.4) * (1 - eval_count / self.budget)\n            self.c1 = 1.2 + (1.5 - 1.2) * (eval_count / self.budget)  # Adjust cognitive coefficient\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                velocities[i] = np.clip(velocities[i], -0.2 * (ub - lb), 0.2 * (ub - lb))  # Updated velocity clamping range\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                self.F = 0.8 + 0.2 * np.random.rand()  # Adaptive Differential weight\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < (self.CR - 0.5 * eval_count / self.budget)  # Adaptive CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0  # Reset stagnation counter on improvement\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0    # Reset counter after reinitialization\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Enhanced exploration by increasing velocity clamping range for better exploration in large search spaces.", "configspace": "", "generation": 47, "fitness": 0.8453605938407924, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.845 with standard deviation 0.009. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "8920d517-d6a7-4343-9e35-50a7a51535d6", "metadata": {"aucs": [0.835558879044972, 0.8570474446496392, 0.8434754578277662], "final_y": [0.12499921518349177, 0.12105008395473349, 0.12412431773325638]}, "mutation_prompt": null}
{"id": "0231a722-15e1-44db-b653-4ff2360d89d4", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            # Dynamically adjust inertia weight\n            self.w = 0.4 + (0.7 - 0.4) * (1 - eval_count / self.budget)\n            self.c1 = 1.2 + (1.5 - 1.2) * (eval_count / self.budget)  # Adjust cognitive coefficient\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                velocities[i] = np.clip(velocities[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  # Velocity clamping\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                self.F = 0.9 + 0.1 * np.random.rand()  # Slightly increased adaptive differential weight\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < (self.CR - 0.4 * eval_count / self.budget)  # More adaptive CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0  # Reset stagnation counter on improvement\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0    # Reset counter after reinitialization\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Enhanced mutation and crossover strategies to improve diversity and convergence.", "configspace": "", "generation": 48, "fitness": 0.8380827524827869, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.838 with standard deviation 0.007. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "8920d517-d6a7-4343-9e35-50a7a51535d6", "metadata": {"aucs": [0.8365775422647967, 0.8471664440521798, 0.8305042711313843], "final_y": [0.12179471225651717, 0.12084773451317898, 0.12447636165942444]}, "mutation_prompt": null}
{"id": "d7d7b755-5f12-4a5c-b7fa-b4a5319d294a", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.min_population_size = 10  # Minimum population size threshold\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            # Dynamically adjust inertia weight\n            self.w = 0.4 + (0.7 - 0.4) * (1 - eval_count / self.budget)\n            self.c1 = 1.2 + (1.5 - 1.2) * (eval_count / self.budget)  # Adjust cognitive coefficient\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                velocities[i] = np.clip(velocities[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  # Velocity clamping\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                self.F = 0.8 + 0.2 * np.random.rand()  # Adaptive Differential weight\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < (self.CR - 0.5 * eval_count / self.budget)  # Adaptive CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0  # Reset stagnation counter on improvement\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0    # Reset counter after reinitialization\n\n            # Reduce population size dynamically\n            if self.population_size > self.min_population_size:\n                self.population_size -= 1\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Introduced a dynamic population size reduction strategy for improved convergence.", "configspace": "", "generation": 49, "fitness": 0.8426233030741722, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.843 with standard deviation 0.020. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "8920d517-d6a7-4343-9e35-50a7a51535d6", "metadata": {"aucs": [0.8144438359814179, 0.8576685785059764, 0.8557574947351225], "final_y": [0.11834287053750747, 0.11306661581869637, 0.11936208487620104]}, "mutation_prompt": null}
{"id": "f1fecc8d-d0b4-4af1-82a6-90f8cde4a74e", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            self.w = 0.4 + (0.7 - 0.4) * (1 - eval_count / self.budget)\n            self.c1 = 1.2 + (1.5 - 1.2) * (eval_count / self.budget)\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                velocities[i] = np.clip(velocities[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                self.F = 0.6 + 0.4 * np.random.rand()  # More variability in F\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < (self.CR - 0.3 * eval_count / self.budget)  # Adjusted CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Enhanced exploration by introducing adaptive mutation and stochasticity in crossover rates.", "configspace": "", "generation": 50, "fitness": 0.8518826822441351, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.852 with standard deviation 0.015. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "8920d517-d6a7-4343-9e35-50a7a51535d6", "metadata": {"aucs": [0.8308936161434215, 0.8604331431544421, 0.8643212874345418], "final_y": [0.12276694599127913, 0.119663845222434, 0.1190752384310485]}, "mutation_prompt": null}
{"id": "a9073ba5-d571-4943-8ec1-d028c146f3f4", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 52  # Increased population size for better exploration\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            # Dynamically adjust inertia weight\n            self.w = 0.4 + (0.7 - 0.4) * (1 - eval_count / self.budget)\n            self.c1 = 1.2 + (1.5 - 1.2) * (eval_count / self.budget)  # Adjust cognitive coefficient\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                velocities[i] = np.clip(velocities[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  # Velocity clamping\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                self.F = 0.8 + 0.2 * np.random.rand()  # Adaptive Differential weight\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < (self.CR - 0.5 * eval_count / self.budget)  # Adaptive CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0  # Reset stagnation counter on improvement\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0    # Reset counter after reinitialization\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Enhanced global exploration by increasing the population size for better diversity.", "configspace": "", "generation": 51, "fitness": 0.8539272177743471, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.854 with standard deviation 0.004. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "8920d517-d6a7-4343-9e35-50a7a51535d6", "metadata": {"aucs": [0.8598451650558145, 0.8493360655763156, 0.8526004226909112], "final_y": [0.11955852297708525, 0.12023692012238496, 0.11842480022125113]}, "mutation_prompt": null}
{"id": "7f2b710e-3d71-46df-8482-21491269d9cc", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            # Dynamically adjust inertia weight\n            self.w = 0.4 + (0.7 - 0.4) * (1 - eval_count / self.budget)\n            self.c1 = 1.2 + (1.5 - 1.2) * (eval_count / self.budget)  # Adjust cognitive coefficient\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                velocities[i] = np.clip(velocities[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  # Velocity clamping\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                self.F = 0.8 + 0.4 * np.random.rand()  # Adaptive Differential weight\n                cross_points = np.random.rand(self.dim) < (self.CR - 0.5 * eval_count / self.budget)  # Adaptive CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0  # Reset stagnation counter on improvement\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0    # Reset counter after reinitialization\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Enhance adaptive differential weight and crossover probability for improved convergence.", "configspace": "", "generation": 52, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'mutant' is not defined\").", "error": "NameError(\"name 'mutant' is not defined\")", "parent_id": "8920d517-d6a7-4343-9e35-50a7a51535d6", "metadata": {}, "mutation_prompt": null}
{"id": "f3056d22-2a9c-4238-b128-e431751c5efd", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            # Dynamically adjust inertia weight\n            self.w = 0.4 + (0.7 - 0.4) * (1 - eval_count / self.budget)\n            self.c1 = 1.2 + (1.5 - 1.2) * (eval_count / self.budget)  # Adjust cognitive coefficient\n            \n            if stagnation_counter >= stagnation_threshold:\n                self.population_size = min(self.population_size + 5, 100)  # Increase population size\n                pop = np.vstack((pop, np.random.uniform(lb, ub, (5, self.dim))))\n                velocities = np.vstack((velocities, np.random.uniform(-abs(ub - lb), abs(ub - lb), (5, self.dim))))\n                stagnation_counter = 0\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                velocities[i] = np.clip(velocities[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  # Velocity clamping\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                self.F = 0.8 + 0.2 * np.random.rand()  # Adaptive Differential weight\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < (self.CR - 0.5 * eval_count / self.budget)  # Adaptive CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0  # Reset stagnation counter on improvement\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0    # Reset counter after reinitialization\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Enhanced HybridPSODE by introducing dynamic population size adjustment and adaptive restart strategy.", "configspace": "", "generation": 53, "fitness": 0.8573975400140125, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.857 with standard deviation 0.020. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "8920d517-d6a7-4343-9e35-50a7a51535d6", "metadata": {"aucs": [0.8452779225134581, 0.8850436523210272, 0.8418710452075524], "final_y": [0.11444469168696514, 0.11558440005978854, 0.122125915123098]}, "mutation_prompt": null}
{"id": "c974acca-1477-4b6f-824b-b0dd1d8af9e8", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            # Dynamically adjust inertia weight\n            self.w = 0.4 + (0.7 - 0.4) * (1 - eval_count / self.budget)\n            self.c1 = 1.2 + (1.5 - 1.2) * (eval_count / self.budget)  # Adjust cognitive coefficient\n            self.c2 = 1.2 + (1.8 - 1.2) * (1 - eval_count / self.budget)  # Adjust social coefficient\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                velocities[i] = np.clip(velocities[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  # Velocity clamping\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                self.F = 0.8 + 0.2 * np.random.rand()  # Adaptive Differential weight\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < (self.CR - 0.5 * eval_count / self.budget)  # Adaptive CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0  # Reset stagnation counter on improvement\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0    # Reset counter after reinitialization\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Enhanced global exploration by dynamically adapting the social coefficient.", "configspace": "", "generation": 54, "fitness": 0.8611737673702727, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.861 with standard deviation 0.013. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "8920d517-d6a7-4343-9e35-50a7a51535d6", "metadata": {"aucs": [0.8484143989578945, 0.8792897923385186, 0.8558171108144051], "final_y": [0.12174873428137734, 0.11564300962275798, 0.12262543530378167]}, "mutation_prompt": null}
{"id": "474a1b21-51ce-448e-a1da-b5dc38db0fe9", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            # Dynamically adjust inertia weight\n            self.w = 0.4 + (0.7 - 0.4) * (1 - eval_count / self.budget)\n            self.c1 = 1.2 + (1.5 - 1.2) * (eval_count / self.budget)  # Adjust cognitive coefficient\n            self.c2 = 1.2 + (1.8 - 1.2) * (1 - eval_count / self.budget)  # Adjust social coefficient\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                velocities[i] = np.clip(velocities[i], -0.05 * (ub - lb), 0.1 * (ub - lb))  # Velocity clamping\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                self.F = 0.8 + 0.2 * np.random.rand()  # Adaptive Differential weight\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < (self.CR - 0.5 * eval_count / self.budget)  # Adaptive CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0  # Reset stagnation counter on improvement\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0    # Reset counter after reinitialization\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Improved exploitation by reducing the minimum velocity clamp.", "configspace": "", "generation": 55, "fitness": 0.8318182761467252, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.832 with standard deviation 0.021. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "c974acca-1477-4b6f-824b-b0dd1d8af9e8", "metadata": {"aucs": [0.8382954478249719, 0.8533939940197356, 0.803765386595468], "final_y": [0.12022767929514389, 0.12372978563539583, 0.14080806251866496]}, "mutation_prompt": null}
{"id": "90ec0156-328b-49a5-8fe3-a15eea223d21", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            # Dynamically adjust inertia weight\n            self.w = 0.4 + (0.7 - 0.4) * (1 - eval_count / self.budget)\n            self.c1 = 1.2 + (1.5 - 1.2) * (eval_count / self.budget)  # Adjust cognitive coefficient\n            self.c2 = 1.2 + (1.8 - 1.2) * (1 - eval_count / self.budget)  # Adjust social coefficient\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                velocities[i] = np.clip(velocities[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  # Velocity clamping\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                self.F = 0.8 + 0.2 * np.random.rand()  # Adaptive Differential weight\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < (self.CR - 0.5 * eval_count / self.budget)  # Adaptive CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0  # Reset stagnation counter on improvement\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0    # Reset counter after reinitialization\n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))  # Adaptive population size\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Introduced adaptive population size reduction to improve convergence speed and solution quality.", "configspace": "", "generation": 56, "fitness": 0.8596288039122665, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.860 with standard deviation 0.014. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "c974acca-1477-4b6f-824b-b0dd1d8af9e8", "metadata": {"aucs": [0.8504944801135652, 0.8790416309396037, 0.8493503006836306], "final_y": [0.11876219891134376, 0.11075560089958658, 0.12124839109186836]}, "mutation_prompt": null}
{"id": "b048a5e5-6edd-4d6d-94c3-a64833da2a1a", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            # Dynamically adjust inertia weight\n            self.w = 0.4 + (0.7 - 0.4) * (1 - eval_count / self.budget)\n            self.c1 = 1.2 + (1.5 - 1.2) * (eval_count / self.budget)  # Adjust cognitive coefficient\n            self.c2 = 1.2 + (1.8 - 1.2) * (1 - eval_count / self.budget)  # Adjust social coefficient\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                velocities[i] = np.clip(velocities[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  # Velocity clamping\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                self.F = 0.8 + 0.2 * np.random.rand()  # Adaptive Differential weight\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < (self.CR - 0.5 * eval_count / self.budget)  # Adaptive CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0  # Reset stagnation counter on improvement\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[np.random.randint(0, self.population_size)] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0    # Reset counter after reinitialization\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Enhanced global exploration by dynamically adapting the social coefficient, now with random reinitialization on stagnation.", "configspace": "", "generation": 57, "fitness": 0.8343145667121507, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.834 with standard deviation 0.024. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "c974acca-1477-4b6f-824b-b0dd1d8af9e8", "metadata": {"aucs": [0.8376463096942002, 0.8625043188751068, 0.8027930715671447], "final_y": [0.12421620641892095, 0.11414678700509251, 0.13989170881594504]}, "mutation_prompt": null}
{"id": "0d18523f-6565-4c2c-8e01-313a448147de", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            # Dynamically adjust inertia weight\n            self.w = 0.4 + (0.7 - 0.4) * (1 - eval_count / self.budget)\n            self.c1 = 1.2 + (1.5 - 1.2) * (eval_count / self.budget)  # Adjust cognitive coefficient\n            self.c2 = 1.2 + (1.8 - 1.2) * (1 - eval_count / self.budget)  # Adjust social coefficient\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                velocities[i] = np.clip(velocities[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  # Velocity clamping\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                self.F = 0.7 + 0.3 * (1 - eval_count / self.budget)  # Adaptive Differential weight\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < (self.CR - 0.5 * eval_count / self.budget)  # Adaptive CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0  # Reset stagnation counter on improvement\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0    # Reset counter after reinitialization\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Introduce adaptive mutation scaling in the Differential Evolution step to enhance local exploration.", "configspace": "", "generation": 58, "fitness": 0.8488511211611939, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.849 with standard deviation 0.005. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "c974acca-1477-4b6f-824b-b0dd1d8af9e8", "metadata": {"aucs": [0.8423597161414008, 0.8534886166289151, 0.8507050307132658], "final_y": [0.11955603020859495, 0.12198968940883259, 0.11983813181535385]}, "mutation_prompt": null}
{"id": "ec5ca183-5f2d-4d29-ad1c-e7dcdd17af10", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            # Dynamically adjust inertia weight\n            self.w = 0.4 + (0.7 - 0.4) * (1 - eval_count / self.budget)\n            self.c1 = 1.5 + (1.8 - 1.5) * (1 - eval_count / self.budget)  # Adjust cognitive coefficient\n            self.c2 = 1.2 + (1.8 - 1.2) * (1 - eval_count / self.budget)  # Adjust social coefficient\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                velocities[i] = np.clip(velocities[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  # Velocity clamping\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                self.F = 0.8 + 0.2 * np.random.rand()  # Adaptive Differential weight\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < (self.CR - 0.5 * eval_count / self.budget)  # Adaptive CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0  # Reset stagnation counter on improvement\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0    # Reset counter after reinitialization\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Enhance local exploitation by dynamically adapting the cognitive coefficient.", "configspace": "", "generation": 59, "fitness": 0.8490525753979264, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.849 with standard deviation 0.008. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "c974acca-1477-4b6f-824b-b0dd1d8af9e8", "metadata": {"aucs": [0.8384323585001304, 0.8589291039825078, 0.8497962637111409], "final_y": [0.12240491189585967, 0.11927948505955377, 0.12428943433761375]}, "mutation_prompt": null}
{"id": "22f4dbe0-ebf3-4ace-9842-dae6a374e5b9", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            # Dynamically adjust inertia weight\n            self.w = 0.4 + (0.7 - 0.4) * (1 - eval_count / self.budget)\n            self.c1 = 1.2 + (1.5 - 1.2) * (eval_count / self.budget)  # Adjust cognitive coefficient\n            self.c2 = 1.2 + (1.8 - 1.2) * (1 - eval_count / self.budget)  # Adjust social coefficient\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                velocities[i] = np.clip(velocities[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  # Velocity clamping\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                self.F = 0.8 + 0.4 * np.random.rand()  # Adaptive Differential weight\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < (self.CR - 0.5 * eval_count / self.budget)  # Adaptive CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0  # Reset stagnation counter on improvement\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0    # Reset counter after reinitialization\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Introduced adaptive mutation rate for enhanced global exploration and convergence.", "configspace": "", "generation": 60, "fitness": 0.8394744918028731, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.839 with standard deviation 0.014. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "c974acca-1477-4b6f-824b-b0dd1d8af9e8", "metadata": {"aucs": [0.8330443565214525, 0.8595447491992111, 0.8258343696879555], "final_y": [0.12043642571541391, 0.11674485950322333, 0.12808830775096747]}, "mutation_prompt": null}
{"id": "0adb6c4e-fc4c-44c4-99a5-988e286d5d00", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            # Dynamically adjust inertia weight\n            self.w = 0.5 + (0.7 - 0.5) * (1 - eval_count / self.budget)  # Fine-tuned inertia weight\n            self.c1 = 1.2 + (1.5 - 1.2) * (eval_count / self.budget)  # Adjust cognitive coefficient\n            self.c2 = 1.0 + (1.8 - 1.0) * (1 - eval_count / self.budget)  # Fine-tuned social coefficient\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                velocities[i] = np.clip(velocities[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  # Velocity clamping\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                self.F = 0.8 + 0.2 * np.random.rand()  # Adaptive Differential weight\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < (self.CR - 0.5 * eval_count / self.budget)  # Adaptive CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0  # Reset stagnation counter on improvement\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0    # Reset counter after reinitialization\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Enhance local exploitation and convergence speed by fine-tuning inertia and social coefficients.", "configspace": "", "generation": 61, "fitness": 0.8625347121716228, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.863 with standard deviation 0.014. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "c974acca-1477-4b6f-824b-b0dd1d8af9e8", "metadata": {"aucs": [0.8463434991435348, 0.880380231496167, 0.8608804058751665], "final_y": [0.12597283841625784, 0.11636204872905842, 0.1196969616037491]}, "mutation_prompt": null}
{"id": "63c67837-9d2d-4da5-b272-49f720ba7305", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.beta = 0.5 + np.random.rand() * 0.5  # Introduce a new parameter for adaptive mutation\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            self.w = 0.5 + (0.7 - 0.5) * (1 - eval_count / self.budget)  # Fine-tuned inertia weight\n            self.c1 = 1.2 + (1.5 - 1.2) * (eval_count / self.budget)  # Adjust cognitive coefficient\n            self.c2 = 1.0 + (1.8 - 1.0) * (1 - eval_count / self.budget)  # Fine-tuned social coefficient\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                velocities[i] = np.clip(velocities[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  # Velocity clamping\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Differential Evolution Step\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                self.F = 0.8 + 0.2 * np.random.rand()  # Adaptive Differential weight\n                mutant = np.clip(a + self.F * (b - c) + self.beta * (global_best_position - a), lb, ub)  # Hybrid exploration\n                cross_points = np.random.rand(self.dim) < (self.CR - 0.5 * eval_count / self.budget)  # Adaptive CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0  # Reset stagnation counter on improvement\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0    # Reset counter after reinitialization\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Improve convergence by introducing adaptive weight and hybrid exploration strategy.", "configspace": "", "generation": 62, "fitness": 0.8494478223491416, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.849 with standard deviation 0.019. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "0adb6c4e-fc4c-44c4-99a5-988e286d5d00", "metadata": {"aucs": [0.8669814110644988, 0.8580070573968921, 0.8233549985860342], "final_y": [0.1189695809245761, 0.11945447729613545, 0.1306812726392197]}, "mutation_prompt": null}
{"id": "b530ccb6-8f6f-4a12-9108-7bf7d10863bc", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            self.w = 0.5 + (0.7 - 0.5) * (1 - eval_count / self.budget)\n            self.c1 = 1.2 + (1.5 - 1.2) * (eval_count / self.budget)\n            self.c2 = 1.0 + (1.8 - 1.0) * (1 - eval_count / self.budget)\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                velocities[i] = np.clip(velocities[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                self.F = 0.8 + 0.2 * np.random.rand()\n                self.CR = 0.7 + 0.3 * (global_best_score / np.max(personal_best_scores))  # Dynamic CR\n                cross_points = np.random.rand(self.dim) < (self.CR - 0.5 * eval_count / self.budget)\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Introduce a dynamic crossover probability that adapts based on the solution's progress to balance exploration and exploitation.", "configspace": "", "generation": 63, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'mutant' is not defined\").", "error": "NameError(\"name 'mutant' is not defined\")", "parent_id": "0adb6c4e-fc4c-44c4-99a5-988e286d5d00", "metadata": {}, "mutation_prompt": null}
{"id": "05227aa8-fbfc-47c9-ba7c-375bcba464c3", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            self.w = 0.5 + (0.7 - 0.5) * (1 - eval_count / self.budget)\n            self.c1 = 1.2 + (1.5 - 1.2) * (eval_count / self.budget)\n            self.c2 = 1.0 + (1.8 - 1.0) * (1 - eval_count / self.budget)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                velocities[i] = np.clip(velocities[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                if np.random.rand() < 0.3:\n                    velocities[i] *= (1 + np.random.rand())  # Adaptive velocity scaling\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                self.F = 0.8 + 0.2 * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                neighborhood_factor = np.mean(pop, axis=0) + 0.1 * np.random.randn(self.dim)  # Neighborhood-based mutation\n                mutant = 0.5 * (mutant + neighborhood_factor)\n                cross_points = np.random.rand(self.dim) < (self.CR - 0.5 * eval_count / self.budget)\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Integrate adaptive neighborhood-based mutation and velocity adaptation to enhance exploration and exploitation balance.", "configspace": "", "generation": 64, "fitness": 0.8860207593960499, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.886 with standard deviation 0.005. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "0adb6c4e-fc4c-44c4-99a5-988e286d5d00", "metadata": {"aucs": [0.8853256397896618, 0.8919456613854478, 0.8807909770130399], "final_y": [0.1132916569331468, 0.1186542050958308, 0.11932968195267546]}, "mutation_prompt": null}
{"id": "4defe8aa-795b-4c3b-adaf-45bfc8eccb33", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            self.w = 0.5 + (0.7 - 0.5) * (1 - eval_count / self.budget)\n            self.c1 = 1.2 + (1.5 - 1.2) * (eval_count / self.budget)\n            self.c2 = 1.0 + (1.8 - 1.0) * (1 - eval_count / self.budget)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                velocities[i] = np.clip(velocities[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                if np.random.rand() < 0.3:\n                    chaotic_factor = 4 * np.random.rand() * (1 - np.random.rand())  # Chaotic logistic map\n                    velocities[i] *= (1 + chaotic_factor)  # Adaptive velocity scaling with chaos\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                self.F = 0.8 + 0.2 * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                neighborhood_factor = np.mean(pop, axis=0) + 0.1 * np.random.randn(self.dim)  # Neighborhood-based mutation\n                mutant = 0.5 * (mutant + neighborhood_factor)\n                cross_points = np.random.rand(self.dim) < (self.CR - 0.5 * eval_count / self.budget)\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Enhance exploration by introducing chaotic logistic mapping to velocity scaling for better convergence.", "configspace": "", "generation": 65, "fitness": 0.8833947615674479, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.883 with standard deviation 0.007. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "05227aa8-fbfc-47c9-ba7c-375bcba464c3", "metadata": {"aucs": [0.8846248189351481, 0.8908763470537132, 0.8746831187134826], "final_y": [0.11739471909773347, 0.11851769858213534, 0.11901017385492552]}, "mutation_prompt": null}
{"id": "2ce848e9-42ef-43ca-b853-b3105b69a8c8", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            self.w = 0.5 + (0.7 - 0.5) * (1 - eval_count / self.budget)\n            self.c1 = 1.2 + (1.5 - 1.2) * (eval_count / self.budget)\n            self.c2 = 1.0 + (1.8 - 1.0) * (1 - eval_count / self.budget)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                velocities[i] = np.clip(velocities[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                if np.random.rand() < 0.3:\n                    velocities[i] *= (1 + np.random.uniform(0.5, 1.5))  # Improved adaptive velocity scaling\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                self.F = 0.8 + 0.2 * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                neighborhood_factor = np.mean(pop, axis=0) + 0.1 * np.random.randn(self.dim)  # Neighborhood-based mutation\n                if np.random.rand() < 0.5:  # Employ Lvy flight for enhanced exploration\n                    step = np.random.standard_cauchy(size=self.dim)\n                    mutant = np.clip(mutant + 0.01 * step, lb, ub)\n                cross_points = np.random.rand(self.dim) < (self.CR - 0.5 * eval_count / self.budget)\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Enhance exploration by incorporating Lvy flight strategy and improving adaptive velocity scaling based on stagnation.", "configspace": "", "generation": 66, "fitness": 0.8299240209234098, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.830 with standard deviation 0.025. And the mean value of best solutions found was 0.134 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "05227aa8-fbfc-47c9-ba7c-375bcba464c3", "metadata": {"aucs": [0.7953100726737351, 0.8541112618386975, 0.8403507282577966], "final_y": [0.1473241432046296, 0.12659519423450283, 0.12699312791865958]}, "mutation_prompt": null}
{"id": "a0f5d439-51ae-42ef-a845-ae929c33d184", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Initial inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            self.w = 0.5 + (0.7 - 0.5) * (1 - eval_count / self.budget)\n            self.c1 = 1.2 + (1.5 - 1.2) * (eval_count / self.budget)\n            self.c2 = 1.0 + (1.8 - 1.0) * (1 - eval_count / self.budget)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                velocities[i] = np.clip(velocities[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                if np.random.rand() < 0.3:\n                    velocities[i] *= (1 + np.random.rand())  # Adaptive velocity scaling\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Introduce diversity preservation mechanism\n            diversity_threshold = 0.1 * (ub - lb)\n            for i in range(self.population_size):\n                if np.linalg.norm(pop[i] - global_best_position) < diversity_threshold:\n                    pop[i] = np.random.uniform(lb, ub, self.dim)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                self.F = 0.8 + 0.2 * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                neighborhood_factor = np.mean(pop, axis=0) + 0.1 * np.random.randn(self.dim)  # Neighborhood-based mutation\n                mutant = 0.5 * (mutant + neighborhood_factor)\n                cross_points = np.random.rand(self.dim) < (self.CR - 0.5 * eval_count / self.budget)\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Enhance the HybridPSODE by incorporating adaptive inertia weights and a diversity preservation mechanism to improve exploration and exploitation balance.", "configspace": "", "generation": 67, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()').", "error": "ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()')", "parent_id": "05227aa8-fbfc-47c9-ba7c-375bcba464c3", "metadata": {}, "mutation_prompt": null}
{"id": "d3604ea8-8f46-45bb-a491-53c419c6da64", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            self.w = 0.5 + (0.7 - 0.5) * (1 - eval_count / self.budget)\n            self.c1 = 1.2 + (1.5 - 1.2) * (eval_count / self.budget)\n            self.c2 = 1.0 + (1.8 - 1.0) * (1 - eval_count / self.budget)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                velocities[i] = np.clip(velocities[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                if np.random.rand() < 0.3:\n                    velocities[i] *= (1 + np.random.rand())  # Adaptive velocity scaling\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                self.F = 0.8 + 0.2 * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                neighborhood_factor = np.mean(pop, axis=0) + 0.1 * np.random.randn(self.dim)  # Neighborhood-based mutation\n                mutant = 0.5 * (mutant + neighborhood_factor)\n                cross_points = np.random.rand(self.dim) < (self.CR - 0.5 * eval_count / self.budget)\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0\n                        self.w = 0.9  # Adaptive inertia weight reset\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Introduce adaptive inertia weight reset to enhance exploration in stagnated states.", "configspace": "", "generation": 68, "fitness": 0.8860207593960499, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.886 with standard deviation 0.005. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "05227aa8-fbfc-47c9-ba7c-375bcba464c3", "metadata": {"aucs": [0.8853256397896618, 0.8919456613854478, 0.8807909770130399], "final_y": [0.1132916569331468, 0.1186542050958308, 0.11932968195267546]}, "mutation_prompt": null}
{"id": "3ab84b5a-7bd0-42f7-b9c3-c7c69e6b55df", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            self.w = 0.5 + (0.7 - 0.5) * (1 - eval_count / self.budget)\n            self.c1 = 1.2 + (1.5 - 1.2) * (eval_count / self.budget)\n            self.c2 = 1.0 + (1.8 - 1.0) * (1 - eval_count / self.budget)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                velocities[i] = np.clip(velocities[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                if np.random.rand() < 0.3:\n                    velocities[i] *= (1 + np.random.rand())  # Adaptive velocity scaling\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                self.F = 0.8 + 0.2 * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                neighborhood_factor = np.mean(pop, axis=0) + 0.1 * np.random.randn(self.dim)  # Neighborhood-based mutation\n                mutant = 0.5 * (mutant + neighborhood_factor)\n                cross_points = np.random.rand(self.dim) < (self.CR - 0.5 * eval_count / self.budget) * (1 - eval_count / self.budget)  # Introduced decay factor\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Introduce a decay factor to the crossover probability to improve convergence dynamics and control exploration-exploitation trade-off.", "configspace": "", "generation": 69, "fitness": 0.8817186615486533, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.882 with standard deviation 0.007. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "05227aa8-fbfc-47c9-ba7c-375bcba464c3", "metadata": {"aucs": [0.872208326862344, 0.8848010541294203, 0.8881466036541955], "final_y": [0.11903761723100792, 0.11889531397440933, 0.1144674988857508]}, "mutation_prompt": null}
{"id": "5ceaf4c6-87b2-4023-837e-bd5d29422a34", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            self.w = 0.4 + 0.3 * np.cos(np.pi * eval_count / self.budget)  # Dynamic inertia weight adaptation\n            self.c1 = 1.2 + (1.5 - 1.2) * (eval_count / self.budget)\n            self.c2 = 1.0 + (1.8 - 1.0) * (1 - eval_count / self.budget)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                velocities[i] = np.clip(velocities[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                if np.random.rand() < 0.3:\n                    velocities[i] *= (1 + np.random.rand())  # Adaptive velocity scaling\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                self.F = 0.8 + 0.2 * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                neighborhood_factor = np.mean(pop, axis=0) + 0.2 * np.random.randn(self.dim)  # More diverse neighborhood-based mutation\n                mutant = 0.5 * (mutant + neighborhood_factor)\n                cross_points = np.random.rand(self.dim) < (self.CR - 0.5 * eval_count / self.budget)\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Introduce dynamic inertia weight adaptation and enhance mutation by incorporating more diversity in neighborhood-based mutation.", "configspace": "", "generation": 70, "fitness": 0.8904442365395656, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.890 with standard deviation 0.004. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "05227aa8-fbfc-47c9-ba7c-375bcba464c3", "metadata": {"aucs": [0.8851035474744444, 0.8918371273519692, 0.8943920347922832], "final_y": [0.11037617860700188, 0.11786564488749363, 0.11188484834999124]}, "mutation_prompt": null}
{"id": "929a2d00-7a21-48e5-bfcf-cc9deb9cf4b3", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            self.w = 0.4 + 0.3 * np.cos(np.pi * eval_count / self.budget)  # Dynamic inertia weight adaptation\n            self.c1 = 1.2 + (1.5 - 1.2) * (eval_count / self.budget)\n            self.c2 = 1.0 + (1.8 - 1.0) * (1 - eval_count / self.budget)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                velocities[i] = np.clip(velocities[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                if np.random.rand() < 0.3:\n                    velocities[i] *= (1 + np.random.rand())  # Adaptive velocity scaling\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                self.F = 0.8 + 0.2 * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                neighborhood_factor = np.mean(pop, axis=0) + 0.2 * np.random.randn(self.dim)  # More diverse neighborhood-based mutation\n                mutant = 0.5 * (mutant + neighborhood_factor)\n                cross_points = np.random.rand(self.dim) < (self.CR - 0.5 * eval_count / self.budget)\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        velocities[i] = np.random.uniform(-abs(ub - lb), abs(ub - lb))  # Reset velocities\n                        stagnation_counter = 0\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Enhance diversity by introducing periodic resetting of velocities for stagnation prevention.", "configspace": "", "generation": 71, "fitness": 0.8899953224699747, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.890 with standard deviation 0.007. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "5ceaf4c6-87b2-4023-837e-bd5d29422a34", "metadata": {"aucs": [0.8801515072360206, 0.8981996429018062, 0.8916348172720976], "final_y": [0.11059920114953758, 0.11721238532894662, 0.11431519622869146]}, "mutation_prompt": null}
{"id": "743c87bf-18d4-49ff-87b6-0fcea9c86d6c", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            self.w = 0.4 + 0.3 * np.cos(np.pi * eval_count / self.budget)  # Dynamic inertia weight adaptation\n            self.c1 = 1.2 + (1.5 - 1.2) * (eval_count / self.budget)\n            self.c2 = 1.0 + (1.8 - 1.0) * (1 - eval_count / self.budget)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                velocities[i] = np.clip(velocities[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                if np.random.rand() < 0.3:\n                    velocities[i] *= (1 + np.random.rand())  # Adaptive velocity scaling\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                self.F = 0.8 + 0.2 * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                neighborhood_factor = np.mean(pop, axis=0) + 0.2 * np.random.randn(self.dim)\n                mutant = 0.5 * (mutant + neighborhood_factor)\n                cross_points = np.random.rand(self.dim) < (self.CR + 0.2 * np.sin(np.pi * eval_count / self.budget))\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial + 0.05 * (np.random.rand(self.dim) - 0.5)\n                        global_best_score = trial_score\n                        stagnation_counter = 0\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Enhance global best exploration by introducing a perturbation mechanism and adaptive crossover strategy for improved convergence.", "configspace": "", "generation": 72, "fitness": 0.8884750081913305, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.888 with standard deviation 0.007. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "5ceaf4c6-87b2-4023-837e-bd5d29422a34", "metadata": {"aucs": [0.8880292731572282, 0.8966982200955044, 0.8806975313212588], "final_y": [0.11259719038966398, 0.1150084578311803, 0.12138976351776398]}, "mutation_prompt": null}
{"id": "de43d584-be55-4e68-acf2-ead0a40fedd7", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            self.w = 0.4 + 0.3 * np.cos(np.pi * eval_count / self.budget)  # Dynamic inertia weight adaptation\n            self.c1 = 1.2 + (1.5 - 1.2) * (np.sin(np.pi * eval_count / self.budget))  # Adaptive cognitive coefficient\n            self.c2 = 1.0 + (1.8 - 1.0) * (1 - eval_count / self.budget)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                velocities[i] = np.clip(velocities[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                if np.random.rand() < 0.3:\n                    velocities[i] *= (1 + np.random.rand())  # Adaptive velocity scaling\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                self.F = 0.8 + 0.2 * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                neighborhood_factor = np.mean(pop, axis=0) + 0.2 * np.random.randn(self.dim)  # More diverse neighborhood-based mutation\n                mutant = 0.5 * (mutant + neighborhood_factor)\n                cross_points = np.random.rand(self.dim) < (self.CR - 0.5 * eval_count / self.budget)\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Incorporate adaptive cognitive and social coefficients to enhance convergence and diversity dynamically.", "configspace": "", "generation": 73, "fitness": 0.8865938243981716, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.887 with standard deviation 0.009. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "5ceaf4c6-87b2-4023-837e-bd5d29422a34", "metadata": {"aucs": [0.8744871308956389, 0.8924455025642033, 0.8928488397346728], "final_y": [0.11196546457668877, 0.1172133193232977, 0.11145415112491153]}, "mutation_prompt": null}
{"id": "de013f74-a0d8-4071-b28b-cd16f8509cf4", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w = 0.7\n        self.F = 0.8\n        self.CR = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            self.w = 0.5 + 0.3 * np.cos(np.pi * eval_count / self.budget)  # Adjusted inertia weight adaptation\n            self.c1 = 1.1 + (1.6 - 1.1) * (eval_count / self.budget)  # Adjusted cognitive coefficient\n            self.c2 = 1.0 + (2.0 - 1.0) * (1 - eval_count / self.budget)  # Adjusted social coefficient\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) +\n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                velocities[i] = np.clip(velocities[i], -0.2 * (ub - lb), 0.2 * (ub - lb))  # Adjusted velocity clipping\n                if np.random.rand() < 0.4:  # Adaptive velocity scaling\n                    velocities[i] *= (1 + 0.5 * np.random.rand())\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                self.F = 0.7 + 0.3 * np.random.rand()  # Adjusted differential weight\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                neighborhood_factor = np.mean(pop, axis=0) + 0.3 * np.random.randn(self.dim)  # More diverse neighborhood-based mutation\n                mutant = 0.6 * (mutant + neighborhood_factor)  # Adjusted combination factor\n                cross_points = np.random.rand(self.dim) < (self.CR - 0.4 * eval_count / self.budget)\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Enhance dynamic mutation strategies and adaptive parameters to improve global exploration and convergence stability.", "configspace": "", "generation": 74, "fitness": 0.797415614646118, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.797 with standard deviation 0.014. And the mean value of best solutions found was 0.152 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "5ceaf4c6-87b2-4023-837e-bd5d29422a34", "metadata": {"aucs": [0.77843622299605, 0.8034829700346536, 0.8103276509076506], "final_y": [0.1498732126137542, 0.1549414672194166, 0.1519200218276494]}, "mutation_prompt": null}
{"id": "861a1a70-0f73-4a0d-820b-29ecce46ef2c", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            self.w = 0.4 + 0.3 * np.cos(np.pi * eval_count / self.budget)  # Dynamic inertia weight adaptation\n            self.c1 = 1.2 + (1.5 - 1.2) * (eval_count / self.budget)\n            self.c2 = 1.0 + (1.8 - 1.0) * (1 - eval_count / self.budget)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                velocities[i] = np.clip(velocities[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                if np.random.rand() < 0.3:\n                    velocities[i] *= (1 + np.random.rand())  # Adaptive velocity scaling\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                elite_idx = np.argmin(personal_best_scores)  # Select elite solution\n                self.F = 0.8 + 0.2 * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                neighborhood_factor = pop[elite_idx] + 0.2 * np.random.randn(self.dim)  # Focus on elite neighborhood\n                neighborhood_factor *= 0.5 * (1 + np.cos(np.pi * eval_count / self.budget))  # Adaptive diversity\n                mutant = 0.5 * (mutant + neighborhood_factor)\n                cross_points = np.random.rand(self.dim) < (self.CR - 0.5 * eval_count / self.budget)\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Enhance exploration by adjusting the mutation strategy to integrate elite solutions and adaptively control neighborhood diversity.", "configspace": "", "generation": 75, "fitness": 0.8827065639728033, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.883 with standard deviation 0.011. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "5ceaf4c6-87b2-4023-837e-bd5d29422a34", "metadata": {"aucs": [0.8854662940420369, 0.894257536894565, 0.8683958609818079], "final_y": [0.12086606541302192, 0.11862153724686608, 0.12657375456052944]}, "mutation_prompt": null}
{"id": "3797d2d1-d339-42d7-a036-f0030663f8bb", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            self.w = 0.4 + 0.3 * np.cos(np.pi * eval_count / self.budget)  # Dynamic inertia weight adaptation\n            self.c1 = 1.2 + (1.5 - 1.2) * (eval_count / self.budget)\n            self.c2 = 1.0 + (1.8 - 1.0) * (1 - eval_count / self.budget)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                velocities[i] = np.clip(velocities[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                if np.random.rand() < 0.5:  # Adaptive velocity scaling probability changed to 0.5\n                    velocities[i] *= (1 + np.random.rand())  \n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                self.F = 0.8 + 0.2 * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                neighborhood_factor = np.mean(pop, axis=0) + 0.2 * np.random.randn(self.dim)  # More diverse neighborhood-based mutation\n                mutant = 0.5 * (mutant + neighborhood_factor)\n                cross_points = np.random.rand(self.dim) < (self.CR - 0.5 * eval_count / self.budget)\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Enhance global exploration by tweaking adaptive velocity scaling probability to 0.5.", "configspace": "", "generation": 76, "fitness": 0.8863648853498537, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.886 with standard deviation 0.005. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "5ceaf4c6-87b2-4023-837e-bd5d29422a34", "metadata": {"aucs": [0.8796054761451771, 0.8884858707829754, 0.8910033091214082], "final_y": [0.11717141743784187, 0.11746375757376226, 0.11166209819684936]}, "mutation_prompt": null}
{"id": "f8c16afd-7d11-4e22-9de9-340929e89792", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            self.w = 0.4 + 0.3 * np.cos(np.pi * eval_count / self.budget)  # Dynamic inertia weight adaptation\n            self.c1 = 1.2 + (1.5 - 1.2) * (eval_count / self.budget)\n            self.c2 = 1.0 + (1.8 - 1.0) * (1 - eval_count / self.budget)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                velocities[i] = np.clip(velocities[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                if np.random.rand() < 0.3:\n                    velocities[i] *= (1 + np.random.rand())  # Adaptive velocity scaling\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                self.F = 0.8 + 0.2 * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                neighborhood_factor = np.mean(pop, axis=0) + 0.2 * np.random.randn(self.dim)  # More diverse neighborhood-based mutation\n                mutant = 0.5 * (mutant + neighborhood_factor)\n                cross_points = np.random.rand(self.dim) < (self.CR - 0.5 * eval_count / self.budget)\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Enhance the balance between exploration and exploitation by adjusting the crossover probability dynamically.", "configspace": "", "generation": 77, "fitness": 0.8904442365395656, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.890 with standard deviation 0.004. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "5ceaf4c6-87b2-4023-837e-bd5d29422a34", "metadata": {"aucs": [0.8851035474744444, 0.8918371273519692, 0.8943920347922832], "final_y": [0.11037617860700188, 0.11786564488749363, 0.11188484834999124]}, "mutation_prompt": null}
{"id": "4b7c8618-1591-40e0-ba51-382a57dd1d97", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            self.w = 0.4 + 0.3 * np.cos(np.pi * eval_count / self.budget)  # Dynamic inertia weight adaptation\n            self.c1 = 1.2 + (1.5 - 1.2) * (eval_count / self.budget)\n            self.c2 = 1.0 + (1.8 - 1.0) * (1 - eval_count / self.budget)\n            self.CR = max(0.6, self.CR - stagnation_counter / self.budget)  # Adaptive crossover probability\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                velocities[i] = np.clip(velocities[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                if np.random.rand() < 0.3:\n                    velocities[i] *= (1 + np.random.rand())  # Adaptive velocity scaling\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                self.F = 0.8 + 0.2 * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                neighborhood_factor = np.mean(pop, axis=0) + 0.2 * np.random.randn(self.dim)  # More diverse neighborhood-based mutation\n                mutant = 0.5 * (mutant + neighborhood_factor)\n                cross_points = np.random.rand(self.dim) < (self.CR - 0.5 * eval_count / self.budget)\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Introduce adaptive crossover probability based on stagnation to improve convergence and diversity.", "configspace": "", "generation": 78, "fitness": 0.8855242158501709, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.886 with standard deviation 0.005. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "5ceaf4c6-87b2-4023-837e-bd5d29422a34", "metadata": {"aucs": [0.8789502293803237, 0.885560688988284, 0.8920617291819052], "final_y": [0.11149309717296207, 0.11827740877310378, 0.1120593165297612]}, "mutation_prompt": null}
{"id": "0589bdc9-4ce6-469c-94a5-7d41e5ec061c", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            self.w = 0.4 + 0.3 * np.cos(np.pi * eval_count / self.budget)  # Dynamic inertia weight adaptation\n            self.c1 = 1.2 + (1.5 - 1.2) * (eval_count / self.budget)\n            self.c2 = 1.0 + (1.8 - 1.0) * (1 - eval_count / self.budget)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                velocities[i] = np.clip(velocities[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                velocities[i] += np.random.normal(0, 0.05, self.dim)  # Random perturbation for exploration\n                if np.random.rand() < 0.3:\n                    velocities[i] *= (1 + np.random.rand())  # Adaptive velocity scaling\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                self.F = 0.8 + 0.2 * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                neighborhood_factor = np.mean(pop, axis=0) + 0.2 * np.random.randn(self.dim)  # More diverse neighborhood-based mutation\n                mutant = 0.5 * (mutant + neighborhood_factor)\n                cross_points = np.random.rand(self.dim) < (self.CR - 0.5 * eval_count / self.budget)\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Improve velocity update by introducing a random perturbation to enhance exploration capability.", "configspace": "", "generation": 79, "fitness": 0.8902662392380171, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.890 with standard deviation 0.009. And the mean value of best solutions found was 0.111 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "5ceaf4c6-87b2-4023-837e-bd5d29422a34", "metadata": {"aucs": [0.8791180630386842, 0.8997518401160268, 0.8919288145593403], "final_y": [0.11196769672421203, 0.1109777427989932, 0.11095809497679754]}, "mutation_prompt": null}
{"id": "1c9954c6-1ccd-42a5-8ce6-2bea2f5c854d", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            self.w = 0.4 + 0.3 * np.cos(np.pi * eval_count / self.budget)  # Dynamic inertia weight adaptation\n            self.c1 = 1.2 + (1.5 - 1.2) * (eval_count / self.budget)\n            self.c2 = 1.0 + (1.8 - 1.0) * (1 - eval_count / self.budget)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                velocities[i] = np.clip(velocities[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                if np.random.rand() < 0.3:\n                    velocities[i] *= (1 + np.random.rand())  # Adaptive velocity scaling\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                self.F = 0.8 + 0.2 * np.random.rand() * (1 + np.std(personal_best_scores))\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                neighborhood_factor = np.mean(pop, axis=0) + 0.2 * np.random.randn(self.dim)  # More diverse neighborhood-based mutation\n                mutant = 0.5 * (mutant + neighborhood_factor)\n                cross_points = np.random.rand(self.dim) < (self.CR - 0.5 * eval_count / self.budget)\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Enhance exploration by introducing adaptive mutation scale based on population diversity.", "configspace": "", "generation": 80, "fitness": 0.8890175144375628, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.889 with standard deviation 0.003. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "5ceaf4c6-87b2-4023-837e-bd5d29422a34", "metadata": {"aucs": [0.8845720344052871, 0.8919919298537755, 0.8904885790536258], "final_y": [0.1105286494263833, 0.11790989836665511, 0.11267301172143096]}, "mutation_prompt": null}
{"id": "70797634-5d6b-464a-9734-3a501eb7dc77", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = lb + (ub - lb) * np.sin(np.random.rand(self.population_size, self.dim) * np.pi)  # Chaos-based initialization\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            self.w = 0.4 + 0.3 * np.cos(np.pi * eval_count / self.budget)  # Dynamic inertia weight adaptation\n            self.c1 = 1.2 + (1.5 - 1.2) * (eval_count / self.budget)\n            self.c2 = 1.0 + (1.8 - 1.0) * (1 - eval_count / self.budget)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                velocities[i] = np.clip(velocities[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                if np.random.rand() < 0.3:\n                    velocities[i] *= (1 + np.random.rand())  # Adaptive velocity scaling\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                self.F = 0.8 + 0.2 * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                neighborhood_factor = np.mean(pop, axis=0) + 0.2 * np.random.randn(self.dim)  # More diverse neighborhood-based mutation\n                mutant = 0.5 * (mutant + neighborhood_factor)\n                cross_points = np.random.rand(self.dim) < (self.CR + 0.2 * np.sin(eval_count / self.budget * np.pi))  # Adaptive crossover rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Introduce chaos-based initialization and adaptive crossover rates to enhance exploration and convergence in dynamic environments.", "configspace": "", "generation": 81, "fitness": 0.8452444284020362, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.845 with standard deviation 0.016. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "5ceaf4c6-87b2-4023-837e-bd5d29422a34", "metadata": {"aucs": [0.8236532814441574, 0.8514458606235786, 0.8606341431383724], "final_y": [0.1281704400672482, 0.1190839516599217, 0.11825399408740134]}, "mutation_prompt": null}
{"id": "00bd4e88-c73d-4646-8355-d0a92380c7f8", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            self.w = 0.4 + 0.3 * np.cos(np.pi * eval_count / self.budget)  # Dynamic inertia weight adaptation\n            self.c1 = 1.2 + (1.5 - 1.2) * (eval_count / self.budget)\n            self.c2 = 1.0 + (1.8 - 1.0) * (1 - eval_count / self.budget)\n            self.CR = 0.9 - 0.4 * eval_count / self.budget  # Adaptive crossover probability\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                velocities[i] = np.clip(velocities[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                if np.random.rand() < 0.3:\n                    velocities[i] *= (1 + np.random.rand())  # Adaptive velocity scaling\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                self.F = 0.8 + 0.2 * np.random.rand()\n                mutant = a + self.F * (b - c) if np.random.rand() < 0.5 else a - self.F * (b - c)  # Improved mutation strategy\n                mutant = np.clip(mutant, lb, ub)\n                neighborhood_factor = np.mean(pop, axis=0) + 0.2 * np.random.randn(self.dim)  # More diverse neighborhood-based mutation\n                mutant = 0.5 * (mutant + neighborhood_factor)\n                cross_points = np.random.rand(self.dim) < (self.CR - 0.5 * eval_count / self.budget)\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Introduce adaptive crossover probability and improve mutation strategy to enhance exploration and prevent premature convergence.", "configspace": "", "generation": 82, "fitness": 0.8835436792256485, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.884 with standard deviation 0.012. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "5ceaf4c6-87b2-4023-837e-bd5d29422a34", "metadata": {"aucs": [0.8703426601615781, 0.8997853665976183, 0.8805030109177491], "final_y": [0.11905331496550786, 0.11115989660904146, 0.1119134109175014]}, "mutation_prompt": null}
{"id": "0f29846f-08e0-42cc-9c62-2894639032c2", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            diversity = np.std(pop, axis=0).mean()\n            self.F = 0.8 + 0.3 * (diversity / self.dim)  # Adaptive differential weight\n            self.w = 0.7 * (1 - eval_count / self.budget)  # Inertia decay based on eval_count\n            self.c1 = 1.2 + (1.5 - 1.2) * (eval_count / self.budget)\n            self.c2 = 1.0 + (1.8 - 1.0) * (1 - eval_count / self.budget)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                velocities[i] = np.clip(velocities[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                if np.random.rand() < 0.3:\n                    velocities[i] *= (1 + np.random.rand())  # Adaptive velocity scaling\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                neighborhood_factor = np.mean(pop, axis=0) + 0.2 * np.random.randn(self.dim)  # More diverse neighborhood-based mutation\n                mutant = 0.5 * (mutant + neighborhood_factor)\n                cross_points = np.random.rand(self.dim) < (self.CR - 0.5 * eval_count / self.budget)\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Introduce adaptive differential weight and inertia decay based on population diversity to improve convergence in HybridPSODE.", "configspace": "", "generation": 83, "fitness": 0.8861616024514761, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.886 with standard deviation 0.010. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "5ceaf4c6-87b2-4023-837e-bd5d29422a34", "metadata": {"aucs": [0.875793822263039, 0.8829687071197595, 0.8997222779716301], "final_y": [0.1110230148728415, 0.11787298656849465, 0.11284560498007146]}, "mutation_prompt": null}
{"id": "f103f161-2e87-4f78-960f-323e67f3a821", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            self.w = 0.4 + 0.3 * np.cos(np.pi * eval_count / self.budget)  # Dynamic inertia weight adaptation\n            self.c1 = 1.2 + (1.5 - 1.2) * (eval_count / self.budget)\n            self.c2 = 1.0 + (1.8 - 1.0) * (1 - eval_count / self.budget)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]) + 0.1 * (personal_best_positions[i] - global_best_position))  # Incorporate historical best influence\n                velocities[i] = np.clip(velocities[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                if np.random.rand() < 0.3:\n                    velocities[i] *= (1 + np.random.rand())  # Adaptive velocity scaling\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                self.F = 0.8 + 0.2 * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                neighborhood_factor = np.mean(pop, axis=0) + 0.2 * np.random.randn(self.dim)  # More diverse neighborhood-based mutation\n                mutant = 0.5 * (mutant + neighborhood_factor)\n                cross_points = np.random.rand(self.dim) < (self.CR - 0.5 * eval_count / self.budget)\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Refine velocity update by incorporating historical best's influence for enhanced exploration.", "configspace": "", "generation": 84, "fitness": 0.8825130751123981, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.883 with standard deviation 0.012. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "5ceaf4c6-87b2-4023-837e-bd5d29422a34", "metadata": {"aucs": [0.8658929883687957, 0.8870601003305332, 0.8945861366378651], "final_y": [0.11338094273770927, 0.11752725565785815, 0.11130099363539314]}, "mutation_prompt": null}
{"id": "f76fb690-5e10-47b0-a73d-737b60091c3c", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            self.w = 0.4 + 0.3 * np.cos(np.pi * eval_count / self.budget)  # Dynamic inertia weight adaptation\n            self.c1 = 1.2 + (1.5 - 1.2) * (eval_count / self.budget)\n            self.c2 = 1.0 + (1.8 - 1.0) * (1 - eval_count / self.budget)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                velocities[i] = np.clip(velocities[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                if np.random.rand() < 0.3:\n                    velocities[i] *= (1 + np.random.rand())  # Adaptive velocity scaling\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                self.F = 0.8 + 0.2 * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                neighborhood_factor = np.mean(pop, axis=0) + 0.2 * np.random.randn(self.dim)  # More diverse neighborhood-based mutation\n                mutant = 0.5 * (mutant + neighborhood_factor)\n                cross_points = np.random.rand(self.dim) < (self.CR - 0.5 * np.cos(eval_count / self.budget)) # Changed line\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Introduce adaptive crossover probability to vary over iterations for increased exploration.", "configspace": "", "generation": 85, "fitness": 0.8891035592820895, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.889 with standard deviation 0.010. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "5ceaf4c6-87b2-4023-837e-bd5d29422a34", "metadata": {"aucs": [0.890106661156257, 0.9007359814248606, 0.8764680352651507], "final_y": [0.11403670494312157, 0.1174222741802925, 0.12068043734384448]}, "mutation_prompt": null}
{"id": "4583361b-dfe7-477a-8d4e-dcd36f82d040", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            self.w = 0.4 + 0.3 * np.cos(np.pi * eval_count / self.budget)  # Dynamic inertia weight adaptation\n            self.c1 = 1.2 + (1.5 - 1.2) * (eval_count / self.budget)\n            self.c2 = 1.0 + (1.8 - 1.0) * (1 - eval_count / self.budget)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                velocities[i] = np.clip(velocities[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                if np.random.rand() < 0.3:\n                    velocities[i] *= (1 + np.random.rand()) * (1 + 0.2 * np.random.rand())  # Enhanced adaptive velocity scaling\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                self.F = 0.8 + 0.2 * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                neighborhood_factor = np.mean(pop, axis=0) + 0.2 * np.random.randn(self.dim)  # More diverse neighborhood-based mutation\n                mutant = 0.5 * (mutant + neighborhood_factor)\n                cross_points = np.random.rand(self.dim) < (self.CR - 0.5 * eval_count / self.budget)\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Enhance global exploration by modifying the velocity scaling with a random factor to improve diversity in exploration.", "configspace": "", "generation": 86, "fitness": 0.8868585934588257, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.887 with standard deviation 0.013. And the mean value of best solutions found was 0.112 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "5ceaf4c6-87b2-4023-837e-bd5d29422a34", "metadata": {"aucs": [0.8833414968874854, 0.9042422741505571, 0.8729920093384342], "final_y": [0.11187492851027814, 0.11175023577331589, 0.1133970953475798]}, "mutation_prompt": null}
{"id": "4bfb8ca2-8fcc-4f83-8531-ffc9a15410d8", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            self.w = 0.4 + 0.3 * np.cos(np.pi * eval_count / self.budget)  # Dynamic inertia weight adaptation\n            self.c1 = 1.2 + (1.5 - 1.2) * (eval_count / self.budget)\n            self.c2 = 1.0 + (1.8 - 1.0) * (1 - eval_count / self.budget)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                velocities[i] = np.clip(velocities[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                if np.random.rand() < 0.3:\n                    velocities[i] *= (1 + np.random.rand())  # Adaptive velocity scaling\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                self.F = 0.8 + 0.2 * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                neighborhood_factor = np.mean(pop, axis=0) + 0.2 * np.random.randn(self.dim)  # More diverse neighborhood-based mutation\n                mutant = 0.5 * (mutant + neighborhood_factor)\n                self.CR = 0.9 * np.sin(np.pi * eval_count / self.budget)  # Non-linear dynamic adjustment of CR\n                cross_points = np.random.rand(self.dim) < (self.CR - 0.5 * eval_count / self.budget)\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Enhance exploration by introducing a non-linear dynamic adjustment to the crossover probability (CR) using a sine function.", "configspace": "", "generation": 87, "fitness": 0.8866402620480409, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.887 with standard deviation 0.009. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "5ceaf4c6-87b2-4023-837e-bd5d29422a34", "metadata": {"aucs": [0.8961972122453933, 0.8899530137982796, 0.8737705601004497], "final_y": [0.11173074164352204, 0.11796155633658467, 0.12049056966282334]}, "mutation_prompt": null}
{"id": "fab59b67-b42f-4b80-b928-3bafb509500e", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            self.w = 0.4 + 0.3 * np.cos(np.pi * eval_count / self.budget)  # Dynamic inertia weight adaptation\n            self.c1 = 1.2 + (1.5 - 1.2) * (eval_count / self.budget)\n            self.c2 = 1.0 + (1.8 - 1.0) * (1 - eval_count / self.budget)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                velocities[i] = np.clip(velocities[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                if np.random.rand() < 0.3:\n                    velocities[i] *= (1 + np.random.rand())  # Adaptive velocity scaling\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                self.F = 0.8 + 0.2 * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                neighborhood_factor = np.mean(pop, axis=0) + 0.1 * np.random.randn(self.dim)  # More diverse neighborhood-based mutation\n                mutant = 0.5 * (mutant + neighborhood_factor)\n                cross_points = np.random.rand(self.dim) < (self.CR - 0.5 * eval_count / self.budget)\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Enhance mutation diversity by incorporating a normal distribution shift in the neighborhood factor.", "configspace": "", "generation": 88, "fitness": 0.8893580939557874, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.889 with standard deviation 0.006. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "5ceaf4c6-87b2-4023-837e-bd5d29422a34", "metadata": {"aucs": [0.8815964567088738, 0.8918775799831933, 0.894600245175295], "final_y": [0.11116805770567229, 0.11784012800082277, 0.1128847055128428]}, "mutation_prompt": null}
{"id": "221bf2da-115d-4e91-aeb8-047eaff57d5a", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Initial crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n\n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        chaotic_map = np.random.rand()\n        \n        while eval_count < self.budget:\n            self.w = 0.4 + 0.3 * np.cos(np.pi * eval_count / self.budget)  # Dynamic inertia weight adaptation\n            self.c1 = 1.2 + (1.5 - 1.2) * (eval_count / self.budget)\n            self.c2 = 1.0 + (1.8 - 1.0) * (1 - eval_count / self.budget)\n            chaotic_map = 4 * chaotic_map * (1 - chaotic_map)  # Logistic map for parameter tuning\n            self.CR = 0.5 + 0.4 * chaotic_map  # Dynamic crossover probability adaptation\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                velocities[i] = np.clip(velocities[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                self.F = 0.8 + 0.2 * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                neighborhood_factor = np.mean(pop, axis=0) + 0.2 * np.random.randn(self.dim)\n                mutant = 0.5 * (mutant + neighborhood_factor)\n                cross_points = np.random.rand(self.dim) < (self.CR - 0.5 * eval_count / self.budget)\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Enhance the exploration-exploitation balance by adapting the crossover probability dynamically and introducing chaotic maps for parameter tuning.", "configspace": "", "generation": 89, "fitness": 0.8857470161926887, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.886 with standard deviation 0.013. And the mean value of best solutions found was 0.112 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "5ceaf4c6-87b2-4023-837e-bd5d29422a34", "metadata": {"aucs": [0.8741987581926159, 0.9031352175508466, 0.8799070728346035], "final_y": [0.11276025152754365, 0.11052985194268539, 0.1139417498883819]}, "mutation_prompt": null}
{"id": "6353cee3-6ac8-4aea-8b80-6dadf9f6b61c", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            self.w = 0.4 + 0.3 * np.cos(np.pi * eval_count / self.budget)  # Dynamic inertia weight adaptation\n            self.c1 = 1.2 + (1.5 - 1.2) * (eval_count / self.budget)\n            self.c2 = 1.0 + (1.8 - 1.0) * (1 - eval_count / self.budget)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                velocities[i] = np.clip(velocities[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                if np.random.rand() < 0.3:\n                    velocities[i] *= (1 + np.random.rand())  # Adaptive velocity scaling\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                self.F = 0.8 + 0.2 * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                neighborhood_factor = np.mean(pop, axis=0) + 0.2 * np.random.randn(self.dim)  # More diverse neighborhood-based mutation\n                mutant = 0.5 * (mutant + neighborhood_factor)\n                cross_points = np.random.rand(self.dim) < (self.CR - 0.5 * eval_count / self.budget)\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        global_best_position = np.random.uniform(lb, ub, self.dim)  # Introducing restart mechanism\n                        stagnation_counter = 0\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Introduce a restart mechanism to diversify exploration when stagnation is detected.", "configspace": "", "generation": 90, "fitness": 0.8299730446652572, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.830 with standard deviation 0.008. And the mean value of best solutions found was 0.141 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "5ceaf4c6-87b2-4023-837e-bd5d29422a34", "metadata": {"aucs": [0.841164318494056, 0.824834791559468, 0.8239200239422477], "final_y": [0.1370488937833909, 0.14859846254676068, 0.137112203783901]}, "mutation_prompt": null}
{"id": "66681a5c-aa8c-463a-96ea-7f9a7f6b04bc", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            self.w = 0.4 + 0.3 * np.cos(np.pi * eval_count / self.budget)  # Dynamic inertia weight adaptation\n            self.c1 = 1.2 + (1.5 - 1.2) * (eval_count / self.budget)\n            self.c2 = 1.0 + (1.8 - 1.0) * (1 - eval_count / self.budget)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                velocities[i] = np.clip(velocities[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                if np.random.rand() < 0.3:\n                    velocities[i] *= (1 + np.random.rand())  # Adaptive velocity scaling\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adjust population size dynamically\n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))  \n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                self.F = 0.8 + 0.2 * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                neighborhood_factor = np.mean(pop, axis=0) + 0.2 * np.random.randn(self.dim)  # More diverse neighborhood-based mutation\n                mutant = 0.5 * (mutant + neighborhood_factor)\n                cross_points = np.random.rand(self.dim) < (self.CR - 0.5 * eval_count / self.budget)\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Introduce adaptive population resizing based on the convergence rate to enhance exploration and exploitation dynamically.", "configspace": "", "generation": 91, "fitness": 0.8982270150601032, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.898 with standard deviation 0.018. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "5ceaf4c6-87b2-4023-837e-bd5d29422a34", "metadata": {"aucs": [0.8740708865902942, 0.9163482718487743, 0.9042618867412408], "final_y": [0.1199556903915826, 0.11169410439371008, 0.11427754957103031]}, "mutation_prompt": null}
{"id": "1f3c76ec-8efd-4dda-bbff-bc593a1f5b82", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            self.w = 0.4 + 0.3 * np.cos(np.pi * eval_count / self.budget)  # Dynamic inertia weight adaptation\n            self.c1 = 1.2 + (1.5 - 1.2) * (eval_count / self.budget)\n            self.c2 = 1.0 + (1.8 - 1.0) * (1 - eval_count / self.budget)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                velocities[i] = np.clip(velocities[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                if np.random.rand() < 0.3:\n                    velocities[i] *= (1 + np.random.rand())  # Adaptive velocity scaling\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adjust population size dynamically\n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))  \n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                self.F = 0.8 + 0.2 * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                neighborhood_factor = np.mean(pop, axis=0) + 0.2 * np.random.randn(self.dim)  # More diverse neighborhood-based mutation\n                mutant = 0.5 * (mutant + neighborhood_factor)\n                cross_points = np.random.rand(self.dim) < (self.CR - 0.5 * eval_count / self.budget)\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0\n                    else:\n                        stagnation_counter += 1\n                        if stagnation_counter >= stagnation_threshold and np.random.rand() < 0.5:\n                            pop[i] = np.random.uniform(lb, ub, self.dim)\n                            stagnation_counter = 0\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Introduce a randomized re-evaluation of stagnated solutions to enhance diversity.", "configspace": "", "generation": 92, "fitness": 0.8800953473485477, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.880 with standard deviation 0.011. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "66681a5c-aa8c-463a-96ea-7f9a7f6b04bc", "metadata": {"aucs": [0.8687096213751578, 0.895301058137676, 0.8762753625328094], "final_y": [0.12101665958593866, 0.11801088908979607, 0.11886700324086819]}, "mutation_prompt": null}
{"id": "5efd9808-a801-4638-a7e4-275b06a0b618", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            self.w = 0.4 + 0.3 * np.cos(np.pi * eval_count / self.budget)  # Dynamic inertia weight adaptation\n            self.c1 = 1.2 + (1.5 - 1.2) * (eval_count / self.budget)\n            self.c2 = 1.0 + (1.8 - 1.0) * (1 - eval_count / self.budget)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                random_factor = np.random.uniform(0.8, 1.2)  # Dynamic random factor\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i])) * random_factor\n                velocities[i] = np.clip(velocities[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                if np.random.rand() < 0.3:\n                    velocities[i] *= (1 + np.random.rand())  # Adaptive velocity scaling\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adjust population size dynamically\n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))  \n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                self.F = 0.8 + 0.2 * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                neighborhood_factor = np.mean(pop, axis=0) + 0.2 * np.random.randn(self.dim)  # More diverse neighborhood-based mutation\n                mutant = 0.5 * (mutant + neighborhood_factor)\n                cross_points = np.random.rand(self.dim) < (self.CR - 0.5 * eval_count / self.budget)\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Enhance velocity updating by incorporating a dynamic random factor to improve convergence.", "configspace": "", "generation": 93, "fitness": 0.8809059415109796, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.881 with standard deviation 0.012. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "66681a5c-aa8c-463a-96ea-7f9a7f6b04bc", "metadata": {"aucs": [0.8649539548198913, 0.8938394253264326, 0.8839244443866145], "final_y": [0.12408408192410592, 0.11875934114081654, 0.12186203139543639]}, "mutation_prompt": null}
{"id": "3e40cb6e-53a5-46ca-8d0e-c8f841a81f6b", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            self.w = 0.4 + 0.3 * np.cos(np.pi * eval_count / self.budget)  # Dynamic inertia weight adaptation\n            self.c1 = 1.2 + (1.5 - 1.2) * (eval_count / self.budget)\n            self.c2 = 1.0 + (1.8 - 1.0) * (1 - eval_count / self.budget)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                velocities[i] = np.clip(velocities[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                if np.random.rand() < 0.3:\n                    velocities[i] *= (1 + np.random.rand())  # Adaptive velocity scaling\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adjust population size dynamically\n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))  \n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                self.F = 0.8 + 0.2 * np.random.rand() * (1 - eval_count / self.budget)  # Dynamic F adaptation\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                neighborhood_factor = np.mean(pop, axis=0) + 0.2 * np.random.randn(self.dim)  # More diverse neighborhood-based mutation\n                mutant = 0.5 * (mutant + neighborhood_factor)\n                cross_points = np.random.rand(self.dim) < (self.CR - 0.5 * eval_count / self.budget)\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Enhance convergence by implementing a dynamic mutation factor adjustment based on the evaluation count.", "configspace": "", "generation": 94, "fitness": 0.8891108280618715, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.889 with standard deviation 0.019. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "66681a5c-aa8c-463a-96ea-7f9a7f6b04bc", "metadata": {"aucs": [0.864353286196845, 0.9115419784618551, 0.8914372195269141], "final_y": [0.1231183745066533, 0.11264694801067598, 0.11959428919146264]}, "mutation_prompt": null}
{"id": "8d1b6e8e-8108-4684-87da-1b0a5d7e7140", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.reinit_period = 20  # Reinitialization period\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            self.w = 0.4 + 0.3 * np.cos(np.pi * eval_count / self.budget)  # Dynamic inertia weight adaptation\n            self.c1 = 1.2 + (1.5 - 1.2) * (eval_count / self.budget)\n            self.c2 = 1.0 + (1.8 - 1.0) * (1 - eval_count / self.budget)\n\n            # Periodic random reinitialization\n            if eval_count % self.reinit_period == 0:\n                pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                \n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                velocities[i] = np.clip(velocities[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                if np.random.rand() < 0.3:\n                    velocities[i] *= (1 + np.random.rand())  # Adaptive velocity scaling\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adjust population size dynamically\n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))  \n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                self.F = 0.8 + 0.2 * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                neighborhood_factor = np.mean(pop, axis=0) + 0.2 * np.random.randn(self.dim)  # More diverse neighborhood-based mutation\n                mutant = 0.5 * (mutant + neighborhood_factor)\n                cross_points = np.random.rand(self.dim) < (self.CR - 0.5 * eval_count / self.budget)\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Introduce periodic random reinitialization to overcome local optima and improve exploration.", "configspace": "", "generation": 95, "fitness": 0.8982270150601032, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.898 with standard deviation 0.018. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "66681a5c-aa8c-463a-96ea-7f9a7f6b04bc", "metadata": {"aucs": [0.8740708865902942, 0.9163482718487743, 0.9042618867412408], "final_y": [0.1199556903915826, 0.11169410439371008, 0.11427754957103031]}, "mutation_prompt": null}
{"id": "1341f6be-2028-44b0-9d1c-d9c09745d2c0", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            self.w = 0.4 + 0.3 * np.cos(np.pi * eval_count / self.budget)  # Dynamic inertia weight adaptation\n            self.c1 = 1.2 + (1.5 - 1.2) * (eval_count / self.budget)\n            self.c2 = 1.0 + (1.8 - 1.0) * (1 - eval_count / self.budget)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                velocities[i] = np.clip(velocities[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                if np.random.rand() < 0.3:\n                    velocities[i] *= (1 + np.std(pop))  # Adaptive velocity scaling based on population diversity\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adjust population size dynamically\n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))  \n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                self.F = 0.8 + 0.2 * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                neighborhood_factor = np.mean(pop, axis=0) + 0.2 * np.random.randn(self.dim)  # More diverse neighborhood-based mutation\n                mutant = 0.5 * (mutant + neighborhood_factor)\n                cross_points = np.random.rand(self.dim) < (self.CR - 0.5 * eval_count / self.budget)\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Enhance exploration by integrating adaptive velocity scaling based on population diversity.", "configspace": "", "generation": 96, "fitness": 0.8222641011865252, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.822 with standard deviation 0.015. And the mean value of best solutions found was 0.140 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "66681a5c-aa8c-463a-96ea-7f9a7f6b04bc", "metadata": {"aucs": [0.8041674044075658, 0.8408274594580591, 0.8217974396939505], "final_y": [0.13541665167376127, 0.1419839014147677, 0.1418614861404589]}, "mutation_prompt": null}
{"id": "615d6cf4-ff33-49dd-b7a2-69f1d4bb7ec0", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            self.w = 0.4 + 0.3 * np.cos(np.pi * eval_count / self.budget)  # Dynamic inertia weight adaptation\n            self.c1 = 1.2 + (1.5 - 1.2) * (eval_count / self.budget)\n            self.c2 = 1.0 + (1.8 - 1.0) * (1 - eval_count / self.budget)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                velocities[i] = np.clip(velocities[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                if np.random.rand() < 0.3:\n                    velocities[i] *= (1 + np.random.rand())  # Adaptive velocity scaling\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adjust population size dynamically\n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))  \n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                self.F = 0.8 + 0.2 * np.random.rand() * (1 - eval_count / self.budget)  # Introduce decay in F\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                neighborhood_factor = np.mean(pop, axis=0) + 0.2 * np.random.randn(self.dim)  # More diverse neighborhood-based mutation\n                mutant = 0.5 * (mutant + neighborhood_factor)\n                cross_points = np.random.rand(self.dim) < (self.CR - 0.5 * eval_count / self.budget)\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Introduce a decay factor to the differential weight (F) for more adaptive exploration-exploitation balance.", "configspace": "", "generation": 97, "fitness": 0.8891108280618715, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.889 with standard deviation 0.019. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "66681a5c-aa8c-463a-96ea-7f9a7f6b04bc", "metadata": {"aucs": [0.864353286196845, 0.9115419784618551, 0.8914372195269141], "final_y": [0.1231183745066533, 0.11264694801067598, 0.11959428919146264]}, "mutation_prompt": null}
{"id": "efb44611-e7b2-410f-97c3-2eba53784f9c", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            self.w = 0.4 + 0.3 * np.cos(np.pi * eval_count / self.budget)  # Dynamic inertia weight adaptation\n            self.c1 = 1.2 + (1.5 - 1.2) * (eval_count / self.budget)\n            self.c2 = 1.0 + (1.8 - 1.0) * (1 - eval_count / self.budget)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                velocities[i] = np.clip(velocities[i], -0.15 * (ub - lb), 0.15 * (ub - lb))\n                if np.random.rand() < 0.25:\n                    velocities[i] *= (1 + np.random.rand())  # Adaptive velocity scaling\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adjust population size dynamically\n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))  \n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                self.F = 0.7 + 0.3 * np.random.rand()\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                neighborhood_factor = np.mean(pop, axis=0) + 0.2 * np.random.randn(self.dim)  # More diverse neighborhood-based mutation\n                mutant = 0.6 * (mutant + neighborhood_factor)\n                cross_points = np.random.rand(self.dim) < (self.CR - 0.5 * eval_count / self.budget)\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Enhance mutation strategies and introduce environment-based adaptation in velocity to improve convergence.", "configspace": "", "generation": 98, "fitness": 0.7664706725628786, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.766 with standard deviation 0.027. And the mean value of best solutions found was 0.162 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "66681a5c-aa8c-463a-96ea-7f9a7f6b04bc", "metadata": {"aucs": [0.7321932584605231, 0.7979181546655748, 0.7693006045625379], "final_y": [0.16810971140770603, 0.15371672028708094, 0.1637419414482928]}, "mutation_prompt": null}
{"id": "b69fa9e1-d80e-4f0d-a313-dffdd8ff9ee1", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 1.5  # Cognitive coefficient\n        self.c2 = 1.5  # Social coefficient\n        self.w = 0.7   # Inertia weight\n        self.F = 0.8   # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        velocities = np.random.uniform(-abs(ub - lb), abs(ub - lb), (self.population_size, self.dim))\n        personal_best_positions = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in pop])\n        global_best_idx = np.argmin(personal_best_scores)\n        global_best_position = personal_best_positions[global_best_idx]\n        global_best_score = personal_best_scores[global_best_idx]\n        \n        eval_count = self.population_size\n        stagnation_counter = 0\n        stagnation_threshold = 10\n\n        while eval_count < self.budget:\n            self.w = 0.4 + 0.3 * np.cos(np.pi * eval_count / self.budget)  # Dynamic inertia weight adaptation\n            self.c1 = 1.2 + (1.5 - 1.2) * (eval_count / self.budget)\n            self.c2 = 1.0 + (1.8 - 1.0) * (1 - eval_count / self.budget)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - pop[i]) + \n                                 self.c2 * r2 * (global_best_position - pop[i]))\n                velocities[i] = np.clip(velocities[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                if np.random.rand() < 0.3:\n                    velocities[i] *= (1 + np.random.rand())  # Adaptive velocity scaling\n                pop[i] = np.clip(pop[i] + velocities[i], lb, ub)\n\n            # Adjust population size dynamically\n            self.population_size = max(10, int(50 * (1 - eval_count / self.budget)))  \n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                self.F = 0.8 + 0.4 * np.random.rand()  # Increased mutation diversity\n                mutant = np.clip(a + self.F * (b - c), lb, ub)\n                neighborhood_factor = np.mean(pop, axis=0) + 0.2 * np.random.randn(self.dim)  # More diverse neighborhood-based mutation\n                mutant = 0.5 * (mutant + neighborhood_factor)\n                cross_points = np.random.rand(self.dim) < (self.CR - 0.5 * eval_count / self.budget)\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n                if trial_score < personal_best_scores[i]:\n                    personal_best_positions[i] = trial\n                    personal_best_scores[i] = trial_score\n                    if trial_score < global_best_score:\n                        global_best_position = trial\n                        global_best_score = trial_score\n                        stagnation_counter = 0\n                    else:\n                        stagnation_counter += 1\n                    if stagnation_counter >= stagnation_threshold:\n                        pop[i] = np.random.uniform(lb, ub, self.dim)\n                        stagnation_counter = 0\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Introduce mutation diversity through an adaptive scaling factor based on exploration rate.", "configspace": "", "generation": 99, "fitness": 0.881978448673188, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.882 with standard deviation 0.018. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "66681a5c-aa8c-463a-96ea-7f9a7f6b04bc", "metadata": {"aucs": [0.8574817919692007, 0.8887443638117573, 0.8997091902386057], "final_y": [0.12274672782402885, 0.11883931071545861, 0.11361904376360976]}, "mutation_prompt": null}
