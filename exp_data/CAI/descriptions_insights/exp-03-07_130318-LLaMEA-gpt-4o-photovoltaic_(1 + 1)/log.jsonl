{"id": "17c3aa3a-5b81-4171-94fc-4bbc816d86e9", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):  # Ensure at least one parameter is from mutant\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "A novel metaheuristic algorithm combining differential evolution and adaptive local search to efficiently explore and exploit the search space for black-box optimization problems.", "configspace": "", "generation": 0, "fitness": -Infinity, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 192, in initialize_single\n    new_individual = self.evaluate_fitness(new_individual)\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 281, in evaluate_fitness\n    updated_individual = self.f(individual, self.logger)\n  File \"/home/ian/LLaMEA/benchmarks/tuto_global_optimization_photonics/exp_photonic.py\", line 143, in evaluatePhotonic\n    algorithm(problem)\n  File \"<string>\", line 45, in __call__\n  File \"<string>\", line 20, in mutate\nNameError: name 'lb' is not defined\n.", "error": "NameError(\"name 'lb' is not defined\")Traceback (most recent call last):\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 192, in initialize_single\n    new_individual = self.evaluate_fitness(new_individual)\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 281, in evaluate_fitness\n    updated_individual = self.f(individual, self.logger)\n  File \"/home/ian/LLaMEA/benchmarks/tuto_global_optimization_photonics/exp_photonic.py\", line 143, in evaluatePhotonic\n    algorithm(problem)\n  File \"<string>\", line 45, in __call__\n  File \"<string>\", line 20, in mutate\nNameError: name 'lb' is not defined\n", "parent_id": null, "metadata": {}, "mutation_prompt": null}
{"id": "653c0f1b-d173-4d88-910e-602f4562a9f2", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):  # Added lb, ub as parameters\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):  # Ensure at least one parameter is from mutant\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)  # Added bounds.lb, bounds.ub\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "A refined differential evolution algorithm with enhanced local search to address black-box optimization challenges efficiently.", "configspace": "", "generation": 1, "fitness": 0.7809554800732211, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.781 with standard deviation 0.012. And the mean value of best solutions found was 0.158 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "17c3aa3a-5b81-4171-94fc-4bbc816d86e9", "metadata": {"aucs": [0.7814157195816009, 0.7948338286633891, 0.7666168919746733], "final_y": [0.15346243098821544, 0.15612035519749923, 0.16555142087503072]}, "mutation_prompt": null}
{"id": "2105c538-b1ff-40b4-bacb-3a6986cbf368", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) + self.mutation_factor\n        mutant = a + dynamic_factor * (b - c)\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Improved Adaptive Differential Evolution with dynamic mutation and diversity-based population update for enhanced black-box optimization.", "configspace": "", "generation": 2, "fitness": 0.81107335259543, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.811 with standard deviation 0.009. And the mean value of best solutions found was 0.151 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "653c0f1b-d173-4d88-910e-602f4562a9f2", "metadata": {"aucs": [0.8053795255153005, 0.8046184181313597, 0.8232221141396296], "final_y": [0.14873112362924767, 0.15567199978573687, 0.14912599963272888]}, "mutation_prompt": null}
{"id": "020dc63e-350b-4c86-b7cd-c29ddaeef4d8", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.5 + np.random.rand() * 0.2  # Adaptive crossover rate\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) + self.mutation_factor\n        mutant = a + dynamic_factor * (b - c)\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population, elite):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n        new_population.append(elite)  # Elitist selection\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            elite = None\n            elite_fitness = np.inf\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < elite_fitness:\n                    elite_fitness = trial_fitness\n                    elite = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population, elite)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Enhanced Adaptive Differential Evolution with adaptive crossover rate and elitist selection to improve diversity and convergence.", "configspace": "", "generation": 3, "fitness": 0.7913524498784374, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.791 with standard deviation 0.009. And the mean value of best solutions found was 0.146 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "2105c538-b1ff-40b4-bacb-3a6986cbf368", "metadata": {"aucs": [0.7987560191214933, 0.7784368521810292, 0.7968644783327901], "final_y": [0.14312290144206563, 0.14360525738157592, 0.15083693390371034]}, "mutation_prompt": null}
{"id": "bd4f4513-c4df-44cd-ba50-736da46be60a", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) + self.mutation_factor\n        mutant = a + dynamic_factor * (b - c)\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        # Adaptive crossover rate based on function evaluations\n        self.crossover_rate = 0.7 - 0.5 * (self.func_evals / self.budget)\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        # Improved local search with dynamic step size\n        step_size = 0.01 * (bounds.ub - bounds.lb) * (1 - (self.func_evals / self.budget))\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Enhanced Adaptive Differential Evolution with adaptive crossover rate and improved local search for better exploration and convergence.", "configspace": "", "generation": 4, "fitness": 0.8089525406311123, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.809 with standard deviation 0.011. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "2105c538-b1ff-40b4-bacb-3a6986cbf368", "metadata": {"aucs": [0.8057879651427826, 0.7979154698992978, 0.8231541868512562], "final_y": [0.1481045826118672, 0.14796152728447054, 0.14915007232190414]}, "mutation_prompt": null}
{"id": "86868e2f-2a4b-40ed-a355-09df4bb1c37c", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) + self.mutation_factor\n        mutant = a + dynamic_factor * (b - c)\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        self.crossover_rate = 0.5 + 0.5 * (1 - self.func_evals / self.budget)  # Adaptive crossover rate\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = 0.05 * (bounds.ub - bounds.lb)  # Increased step size\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Enhanced Adaptive Differential Evolution with adaptive crossover rate and improved local search for better diversity management and solution quality.", "configspace": "", "generation": 5, "fitness": 0.7913350440760204, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.791 with standard deviation 0.017. And the mean value of best solutions found was 0.155 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "2105c538-b1ff-40b4-bacb-3a6986cbf368", "metadata": {"aucs": [0.7700182160205337, 0.812795601993676, 0.7911913142138518], "final_y": [0.15451226312975108, 0.1517541232635522, 0.15739270329891608]}, "mutation_prompt": null}
{"id": "91835581-7539-4943-b8f6-a75acbce19db", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) + self.mutation_factor\n        mutant = a + dynamic_factor * (b - c)\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        adaptive_crossover_rate = self.crossover_rate + 0.1 * (np.std(self.population) / self.dim)\n        crossover_mask = np.random.rand(self.dim) < adaptive_crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population, bounds):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population, bounds)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Enhanced Adaptive Differential Evolution with adaptive crossover and mutation strategies for improved convergence and solution quality.", "configspace": "", "generation": 6, "fitness": 0.7796682998632246, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.780 with standard deviation 0.027. And the mean value of best solutions found was 0.160 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "2105c538-b1ff-40b4-bacb-3a6986cbf368", "metadata": {"aucs": [0.7478730406538692, 0.8141541678870111, 0.7769776910487937], "final_y": [0.17590131444562906, 0.14175149927551323, 0.16195500843516675]}, "mutation_prompt": null}
{"id": "e46ae0df-7cfc-49ff-8852-445b0efe48ab", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.population = None\n        self.func_evals = 0\n        self.best_solution_archive = []\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) + self.mutation_factor\n        mutant = a + dynamic_factor * (b - c)\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n\n    def elitist_selection(self, new_population, new_population_fitness):\n        sorted_indices = np.argsort(new_population_fitness)\n        self.population = np.array([new_population[i] for i in sorted_indices[:self.population_size]])\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            new_population_fitness = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n                    self.best_solution_archive.append(best_solution)\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                    new_population_fitness.append(trial_fitness)\n                else:\n                    new_population.append(target)\n                    new_population_fitness.append(func(target))\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population)\n            self.elitist_selection(new_population, new_population_fitness)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Enhanced Adaptive Differential Evolution utilizing adaptive memory and elitist strategy for improved convergence.", "configspace": "", "generation": 7, "fitness": 0.7990042742711091, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.799 with standard deviation 0.021. And the mean value of best solutions found was 0.156 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "2105c538-b1ff-40b4-bacb-3a6986cbf368", "metadata": {"aucs": [0.7710149830019997, 0.8037437407015556, 0.8222540991097721], "final_y": [0.1635009347898515, 0.15567199978573687, 0.14912599963272888]}, "mutation_prompt": null}
{"id": "a7d657fb-8d06-4254-9a78-fe2490e4f015", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) + self.mutation_factor\n        # Enhanced mutation strategy with additional factor for improved exploration\n        mutant = a + dynamic_factor * (b - c) + 0.1 * (np.mean(self.population, axis=0) - a)\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Enhanced Adaptive Differential Evolution with refined mutation strategy for improved exploration and exploitation balance.", "configspace": "", "generation": 8, "fitness": 0.8197908094663552, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.820 with standard deviation 0.009. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "2105c538-b1ff-40b4-bacb-3a6986cbf368", "metadata": {"aucs": [0.8096701205755844, 0.8172499052545985, 0.8324524025688824], "final_y": [0.14819936786811694, 0.15020769695008984, 0.1458906345248696]}, "mutation_prompt": null}
{"id": "2fb8c1f2-42fc-44e6-9799-de963fb2e144", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) + self.mutation_factor\n        mutant = a + dynamic_factor * (b - c) + 0.1 * (np.mean(self.population, axis=0) - a)\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = 0.01 * (bounds.ub - bounds.lb)\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def adaptive_population_size(self):\n        self.population_size = int(max(4, self.population_size * (1 - self.func_evals / self.budget)))\n\n    def update_population(self, new_population, bounds):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n        self.adaptive_population_size()\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population, bounds)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Enhanced Adaptive Differential Evolution with Adaptive Population Size for Dynamic Exploration and Exploitation.", "configspace": "", "generation": 9, "fitness": 0.8119691694116858, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.812 with standard deviation 0.021. And the mean value of best solutions found was 0.129 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "a7d657fb-8d06-4254-9a78-fe2490e4f015", "metadata": {"aucs": [0.7842196530425711, 0.8180353213897463, 0.83365253380274], "final_y": [0.13195066581163006, 0.1330970207636124, 0.12148196624775531]}, "mutation_prompt": null}
{"id": "30360dbd-5419-4f4d-a950-c846292094f8", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) + self.mutation_factor\n        mutant = a + dynamic_factor * (b - c) + 0.1 * (np.mean(self.population, axis=0) - a)\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        # Changed step size from 0.01 to 0.005 to improve fine-tuning\n        step_size = 0.005 * (bounds.ub - bounds.lb)  \n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Refinement in local search perturbation scale to enhance fine-tuning capabilities.", "configspace": "", "generation": 10, "fitness": 0.8202904207672774, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.820 with standard deviation 0.010. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "a7d657fb-8d06-4254-9a78-fe2490e4f015", "metadata": {"aucs": [0.8100288342198477, 0.8165312370265331, 0.8343111910554515], "final_y": [0.1480008877946004, 0.15032140971794739, 0.14492937967321495]}, "mutation_prompt": null}
{"id": "31c0467a-cfbe-4825-be56-8334ba9d8794", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) + self.mutation_factor\n        dynamic_factor *= np.std(self.population, axis=0) / np.mean(self.population, axis=0)  # Improved mutation\n        mutant = a + dynamic_factor * (b - c) + 0.1 * (np.mean(self.population, axis=0) - a)\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        dynamic_crossover_rate = self.crossover_rate + 0.1 * (np.std(self.population) / np.mean(self.population))\n        # Dynamic crossover rate\n        crossover_mask = np.random.rand(self.dim) < dynamic_crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = 0.005 * (bounds.ub - bounds.lb)  \n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Improved adaptive mutation factor and dynamic crossover rate for enhanced exploration and exploitation balance.", "configspace": "", "generation": 11, "fitness": 0.7895125075809893, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.790 with standard deviation 0.015. And the mean value of best solutions found was 0.152 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "30360dbd-5419-4f4d-a950-c846292094f8", "metadata": {"aucs": [0.7708960839549569, 0.8087207942856708, 0.7889206445023405], "final_y": [0.1533262004835878, 0.1532562955556962, 0.14929708975852962]}, "mutation_prompt": null}
{"id": "148fe3b5-51ed-49ea-9fc3-e4215a37d32a", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) + self.mutation_factor\n        mutant = a + dynamic_factor * (b - c) + 0.1 * (np.mean(self.population, axis=0) - a)\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        adaptive_crossover_rate = self.crossover_rate + 0.1 * np.sin(self.func_evals / self.budget * 2 * np.pi)\n        crossover_mask = np.random.rand(self.dim) < adaptive_crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = 0.005 * (bounds.ub - bounds.lb) * (1 - (self.func_evals / self.budget))\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Introduced adaptive crossover rates and enhanced local search with dynamic step sizes to improve convergence speed and solution quality.", "configspace": "", "generation": 12, "fitness": 0.8197580332536819, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.820 with standard deviation 0.011. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "30360dbd-5419-4f4d-a950-c846292094f8", "metadata": {"aucs": [0.8087432782223709, 0.8161961247658074, 0.8343346967728675], "final_y": [0.1483547492972973, 0.15114219162459153, 0.14523989637016377]}, "mutation_prompt": null}
{"id": "a9c0f3d3-25c9-4e28-9a19-0d5438426d7a", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.base_population_size = 10 * dim  # Renamed for clarity\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.base_population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(len(self.population)) if i != idx]  # Adjusted to dynamic population size\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) + self.mutation_factor\n        mutant = a + dynamic_factor * (b - c) + 0.1 * (np.mean(self.population, axis=0) - a)\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = 0.005 * (bounds.ub - bounds.lb)\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population, bounds):\n        self.population = np.array(new_population)\n        diversity_threshold = 0.1 * self.dim\n        if np.std(self.population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n        # Dynamic population adjustment based on convergence rate\n        if self.func_evals > 0.5 * self.budget:\n            self.population = self.population[:int(len(self.population) * 0.8)]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(len(self.population)):  # Adjusted to dynamic population size\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population, bounds)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Introducing a dynamic population size adjustment mechanism based on the convergence rate to enhance exploration and exploitation balance.", "configspace": "", "generation": 13, "fitness": 0.8202904207672774, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.820 with standard deviation 0.010. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "30360dbd-5419-4f4d-a950-c846292094f8", "metadata": {"aucs": [0.8100288342198477, 0.8165312370265331, 0.8343111910554515], "final_y": [0.1480008877946004, 0.15032140971794739, 0.14492937967321495]}, "mutation_prompt": null}
{"id": "3e1061cc-8a2e-4c82-a443-b2ae98b85557", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.9  # Increased mutation factor for better exploration\n        self.crossover_rate = 0.5  # Lowered crossover rate to introduce more variability\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) + self.mutation_factor\n        adaptive_component = 0.2 * (np.mean(self.population, axis=0) - self.population[idx])  # New adaptive component\n        mutant = a + dynamic_factor * (b - c) + adaptive_component\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = 0.005 * (bounds.ub - bounds.lb)\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Improved mutation strategy and adaptive crossover for better exploration and exploitation balance.", "configspace": "", "generation": 14, "fitness": 0.7899157538168903, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.790 with standard deviation 0.020. And the mean value of best solutions found was 0.157 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "30360dbd-5419-4f4d-a950-c846292094f8", "metadata": {"aucs": [0.8121437806735592, 0.7934343388232475, 0.764169141953864], "final_y": [0.15093864616810226, 0.15961359842304068, 0.15991245322192849]}, "mutation_prompt": null}
{"id": "9352a98d-bde7-42e7-ae25-d1ad523ae8db", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) + self.mutation_factor\n        mutant = a + dynamic_factor * (b - c) + 0.1 * (np.mean(self.population, axis=0) - a)\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        # Dynamic crossover rate adaptation\n        dynamic_crossover_rate = np.random.rand() * (1 - self.crossover_rate) + self.crossover_rate\n        crossover_mask = np.random.rand(self.dim) < dynamic_crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = 0.005 * (bounds.ub - bounds.lb)  \n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        # Enhanced diversity management to reset population if needed\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            print(\"Diversity too low, reinitializing population\")  # Debugging info\n            self.initialize_population(bounds.lb, bounds.ub)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Introduced dynamic crossover rate adaptation and enhanced diversity management in the population update phase to improve exploration and exploitation balance.", "configspace": "", "generation": 15, "fitness": 0.7829821724969116, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.783 with standard deviation 0.014. And the mean value of best solutions found was 0.159 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "30360dbd-5419-4f4d-a950-c846292094f8", "metadata": {"aucs": [0.7651662836669572, 0.7992283152834284, 0.7845519185403493], "final_y": [0.16000302493317808, 0.15411331505019832, 0.1615723861864231]}, "mutation_prompt": null}
{"id": "966eec46-49fe-429f-a52c-a291b85134da", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) + self.mutation_factor\n        mutant = a + dynamic_factor * (b - c) + 0.1 * (np.mean(self.population, axis=0) - a)\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        # Changed crossover rate to be dynamic based on function evaluations\n        dynamic_crossover_rate = self.crossover_rate + 0.3 * (1 - self.func_evals / self.budget)\n        crossover_mask = np.random.rand(self.dim) < dynamic_crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = 0.005 * (bounds.ub - bounds.lb)\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Introduced dynamic crossover rate adjustment to enhance exploration-exploitation balance.", "configspace": "", "generation": 16, "fitness": 0.7862441887914886, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.786 with standard deviation 0.024. And the mean value of best solutions found was 0.156 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "30360dbd-5419-4f4d-a950-c846292094f8", "metadata": {"aucs": [0.7542839872589405, 0.7935086373474695, 0.8109399417680557], "final_y": [0.16747130406176058, 0.1601017669387199, 0.1402758603592842]}, "mutation_prompt": null}
{"id": "4ab7a87a-698b-4160-9567-4ac47616fcf7", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        # Adaptive mutation factor based on iteration\n        adaptive_factor = self.mutation_factor + (0.1 * (self.func_evals / self.budget))\n        mutant = a + adaptive_factor * (b - c) + 0.1 * (np.mean(self.population, axis=0) - a)\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        # Dynamic crossover rate\n        dynamic_crossover_rate = self.crossover_rate + 0.1 * np.cos(np.pi * self.func_evals / self.budget)\n        crossover_mask = np.random.rand(self.dim) < dynamic_crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = 0.005 * (bounds.ub - bounds.lb)  \n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Introduce a dynamic crossover rate and adaptive mutation strategy to enhance exploration and exploitation balance.", "configspace": "", "generation": 17, "fitness": 0.7899257684375257, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.790 with standard deviation 0.016. And the mean value of best solutions found was 0.156 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "30360dbd-5419-4f4d-a950-c846292094f8", "metadata": {"aucs": [0.7889237900098638, 0.809415907963972, 0.7714376073387413], "final_y": [0.15764362196264115, 0.15475507722539383, 0.1560082965688555]}, "mutation_prompt": null}
{"id": "4f128a64-6328-432f-985f-811f574a82ba", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.population = None\n        self.func_evals = 0\n        \n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        # Self-adaptive mutation factor adjustment\n        dynamic_factor = self.mutation_factor + np.random.rand() * (1 - self.mutation_factor)\n        mutant = a + dynamic_factor * (b - c) + 0.1 * (np.mean(self.population, axis=0) - a)\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        # Dynamic crossover rate based on fitness improvement\n        fitness_improvement = np.abs(func(target) - func(mutant))\n        self.crossover_rate = 0.5 if fitness_improvement < 1e-5 else 0.9\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = 0.005 * (bounds.ub - bounds.lb)  \n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Incorporate self-adaptive mutation and dynamic crossover rates to enhance exploration and exploitation balance.", "configspace": "", "generation": 18, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_id": "30360dbd-5419-4f4d-a950-c846292094f8", "metadata": {}, "mutation_prompt": null}
{"id": "820217ee-3407-4423-832a-b04a31624663", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) + self.mutation_factor\n        mutant = a + dynamic_factor * (b - c) + 0.1 * (np.mean(self.population, axis=0) - a)\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant, fitness, best_fitness):\n        adaptive_crossover_rate = self.crossover_rate * (fitness / (best_fitness + 1e-12))\n        crossover_mask = np.random.rand(self.dim) < adaptive_crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = 0.005 * (bounds.ub - bounds.lb)  \n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant, func(target), best_fitness)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Integrate fitness-based dynamic crossover rate to enhance exploration and exploitation trade-off.", "configspace": "", "generation": 19, "fitness": 0.7899989783856771, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.790 with standard deviation 0.017. And the mean value of best solutions found was 0.157 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "30360dbd-5419-4f4d-a950-c846292094f8", "metadata": {"aucs": [0.7830491075788314, 0.8137012956589258, 0.7732465319192744], "final_y": [0.1531046627857705, 0.15112667748602482, 0.1676361433416419]}, "mutation_prompt": null}
{"id": "bc6fb616-bb7b-4ac4-b62a-89f73c3670ec", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) + self.mutation_factor\n        mutant = a + dynamic_factor * (b - c) + 0.1 * (np.mean(self.population, axis=0) - a)\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = 0.005 * (bounds.ub - bounds.lb)  \n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                # Change: Added fitness-based scaling factor for trial selection\n                scaling_factor = 1 - (trial_fitness / (func(target) + 1e-12))\n                if trial_fitness < func(target) or np.random.rand() < scaling_factor:\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Refined trial selection using a fitness-based scaling factor enhances the convergence speed.", "configspace": "", "generation": 20, "fitness": 0.7829635237981089, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.783 with standard deviation 0.007. And the mean value of best solutions found was 0.160 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "30360dbd-5419-4f4d-a950-c846292094f8", "metadata": {"aucs": [0.7760214409952698, 0.7924349572698215, 0.780434173129235], "final_y": [0.1596415009909633, 0.1601017669387199, 0.16112251330456262]}, "mutation_prompt": null}
{"id": "b7302f34-8b40-49dc-bbee-d8cc0fb9a0e9", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) + self.mutation_factor\n        mutant = a + dynamic_factor * (b - c) + 0.1 * (np.mean(self.population, axis=0) - a)\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        # Adaptive crossover rate improving exploration-exploitation balance\n        current_crossover_rate = self.crossover_rate * (0.5 + 0.5 * np.random.rand())  \n        crossover_mask = np.random.rand(self.dim) < current_crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = 0.005 * (bounds.ub - bounds.lb)  \n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Introduce adaptive mutation and crossover rates to enhance exploration and exploitation balance.", "configspace": "", "generation": 21, "fitness": 0.7967173292170724, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.797 with standard deviation 0.015. And the mean value of best solutions found was 0.151 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "30360dbd-5419-4f4d-a950-c846292094f8", "metadata": {"aucs": [0.7968071250757591, 0.8155019015433658, 0.777842961032092], "final_y": [0.1487761311883724, 0.1486420135622728, 0.15541310176114298]}, "mutation_prompt": null}
{"id": "97ae304c-6c12-4cf4-97b9-142e20ab0939", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        initial_population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        fitness = np.array([func(ind) for ind in initial_population])\n        tournament_size = 3\n        best_indices = np.argpartition(fitness, tournament_size)[:tournament_size]\n        self.population = initial_population[best_indices]\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) + self.mutation_factor\n        mutant = a + dynamic_factor * (b - c) + 0.1 * (np.mean(self.population, axis=0) - a)\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = 0.005 * (bounds.ub - bounds.lb)\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Enhanced mutation strategy by adapting dynamic factor and adding tournament selection for initial population.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_id": "30360dbd-5419-4f4d-a950-c846292094f8", "metadata": {}, "mutation_prompt": null}
{"id": "4e01dd45-c973-4784-a54a-e0d7c80e7432", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) + self.mutation_factor\n        mutant = a + dynamic_factor * (b - c) + 0.1 * (np.mean(self.population, axis=0) - a)\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        # Dynamically adjust crossover rate based on current best fitness\n        self.crossover_rate = 0.5 + 0.5 * np.exp(-self.func_evals / (self.budget / 2))\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = 0.005 * (bounds.ub - bounds.lb)\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Enhanced mutation strategy with dynamic crossover rate adjustment for improved exploration.", "configspace": "", "generation": 23, "fitness": 0.7920869408340631, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.792 with standard deviation 0.003. And the mean value of best solutions found was 0.158 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "30360dbd-5419-4f4d-a950-c846292094f8", "metadata": {"aucs": [0.7950319458967011, 0.7935086373474695, 0.7877202392580185], "final_y": [0.15297686263872923, 0.1601017669387199, 0.1622750999237097]}, "mutation_prompt": null}
{"id": "b0f1493e-3ad9-40cc-9a10-c0d146a6dfb1", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) + self.mutation_factor\n        mutant = a + dynamic_factor * (b - c) + 0.1 * (np.mean(self.population, axis=0) - a)\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        # Adaptive crossover rate based on evaluation progress\n        adaptive_crossover_rate = max(0.4, self.crossover_rate * (1 - self.func_evals / self.budget))\n        crossover_mask = np.random.rand(self.dim) < adaptive_crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = 0.005 * (bounds.ub - bounds.lb)\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        # Introduce hybrid local search strategy\n        if np.random.rand() < 0.5:\n            local_perturbation = np.random.normal(0, step_size / 2, self.dim)\n            new_candidate += local_perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Introduce adaptive crossover rate and hybrid local search to enhance exploration and exploitation balance.", "configspace": "", "generation": 24, "fitness": 0.7934808935309663, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.793 with standard deviation 0.031. And the mean value of best solutions found was 0.155 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "30360dbd-5419-4f4d-a950-c846292094f8", "metadata": {"aucs": [0.7502624070729638, 0.8150402419073348, 0.8151400316126004], "final_y": [0.1704824088046707, 0.14565812183833793, 0.14892609422155967]}, "mutation_prompt": null}
{"id": "afa1d0b6-2e66-45d1-b3b2-3e174d4a904e", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (1.2 - self.mutation_factor) + self.mutation_factor\n        mutant = a + dynamic_factor * (b - c) + 0.1 * (np.mean(self.population, axis=0) - a)\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        # Change: Use dynamic crossover rate based on exploration need\n        self.crossover_rate = 0.5 + 0.5 * np.random.rand()\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = 0.005 * (bounds.ub - bounds.lb)\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Enhance mutation diversity and employ dynamic crossover rates to improve exploration and convergence balance.", "configspace": "", "generation": 25, "fitness": 0.7992776985725486, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.799 with standard deviation 0.011. And the mean value of best solutions found was 0.151 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "30360dbd-5419-4f4d-a950-c846292094f8", "metadata": {"aucs": [0.8105216893337382, 0.8025195876721009, 0.7847918187118068], "final_y": [0.14434449854281683, 0.14949290244082536, 0.15935770992127196]}, "mutation_prompt": null}
{"id": "2bcafb10-c8cc-41e3-bb15-47a8d115e593", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) + self.mutation_factor\n        mutant = a + dynamic_factor * (b - c) + 0.1 * (np.mean(self.population, axis=0) - a)\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = 0.005 * (bounds.ub - bounds.lb)\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.crossover_rate = 0.9  # Increase the crossover rate when diversity is low\n            self.initialize_population(bounds.lb, bounds.ub)\n        else:\n            self.crossover_rate = 0.7  # Reset to original crossover rate when diversity is sufficient\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Introduced adaptive crossover rate based on population diversity to enhance exploration and exploitation balance.", "configspace": "", "generation": 26, "fitness": 0.8202904207672774, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.820 with standard deviation 0.010. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "30360dbd-5419-4f4d-a950-c846292094f8", "metadata": {"aucs": [0.8100288342198477, 0.8165312370265331, 0.8343111910554515], "final_y": [0.1480008877946004, 0.15032140971794739, 0.14492937967321495]}, "mutation_prompt": null}
{"id": "27ec889d-7c44-4449-a174-8c2fa40b0336", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) + self.mutation_factor\n        mutant = a + dynamic_factor * (b - c) + 0.1 * (np.mean(self.population, axis=0) - a)\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        # Adaptive crossover rate based on the current evaluation budget usage\n        adaptive_crossover_rate = self.crossover_rate + 0.3 * (1 - self.func_evals / self.budget)\n        crossover_mask = np.random.rand(self.dim) < adaptive_crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = 0.005 * (bounds.ub - bounds.lb)\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            # Dynamic population resizing to increase diversity\n            self.population_size = int(self.population_size * 1.2)\n            self.initialize_population(bounds.lb, bounds.ub)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Introduce adaptive crossover rate and dynamic population resizing to enhance convergence speed and solution diversity.", "configspace": "", "generation": 27, "fitness": 0.7862441887914886, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.786 with standard deviation 0.024. And the mean value of best solutions found was 0.156 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "30360dbd-5419-4f4d-a950-c846292094f8", "metadata": {"aucs": [0.7542839872589405, 0.7935086373474695, 0.8109399417680557], "final_y": [0.16747130406176058, 0.1601017669387199, 0.1402758603592842]}, "mutation_prompt": null}
{"id": "402a4095-9139-487e-8209-933d58a46e68", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        # Adaptive mutation factor based on evaluations\n        dynamic_factor = self.mutation_factor * (1 - self.func_evals / self.budget)\n        mutant = a + dynamic_factor * (b - c) + 0.1 * (np.mean(self.population, axis=0) - a)\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = 0.005 * (bounds.ub - bounds.lb) * (1 - self.func_evals / self.budget)  # Adaptive step size\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Introduced adaptive mutation and local search strategies for improved exploration-exploitation balance.", "configspace": "", "generation": 28, "fitness": 0.7974591652274161, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.797 with standard deviation 0.009. And the mean value of best solutions found was 0.149 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "30360dbd-5419-4f4d-a950-c846292094f8", "metadata": {"aucs": [0.8001169366162537, 0.8072534441575339, 0.7850071149084608], "final_y": [0.15148648435601475, 0.1508301696467782, 0.1455340210267606]}, "mutation_prompt": null}
{"id": "ce0c63e3-be50-4c6c-91de-4262a7bdba4a", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (1.2 - self.mutation_factor) + self.mutation_factor \n        if np.random.rand() > 0.5:\n            mutant = a + dynamic_factor * (b - c)  # Alternating mutation strategies\n        else:\n            mutant = a + dynamic_factor * (np.mean(self.population, axis=0) - a)\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        crossover_rate = np.random.uniform(0.6, 0.9)  # Adaptive crossover rate\n        crossover_mask = np.random.rand(self.dim) < crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = 0.005 * (bounds.ub - bounds.lb)  \n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Enhanced exploration through hybrid mutation strategies and adaptive crossover rate.", "configspace": "", "generation": 29, "fitness": 0.7807638052822311, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.781 with standard deviation 0.013. And the mean value of best solutions found was 0.152 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "30360dbd-5419-4f4d-a950-c846292094f8", "metadata": {"aucs": [0.7679322961500196, 0.7984934857758796, 0.7758656339207941], "final_y": [0.1435832500512586, 0.15080265111696411, 0.16188451024861739]}, "mutation_prompt": null}
{"id": "b9d6440b-b4fe-4411-94da-2f22c5c82d77", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) + self.mutation_factor\n        mutant = a + dynamic_factor * (b - c) + 0.1 * (np.mean(self.population, axis=0) - a)\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        diversity = np.std(self.population)\n        self.crossover_rate = 0.9 if diversity > 0.15 else 0.6  # Adaptive crossover based on diversity\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = 0.005 * (bounds.ub - bounds.lb)  \n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Introduce adaptive crossover rate based on population diversity to enhance search exploration.", "configspace": "", "generation": 30, "fitness": 0.8008453745763758, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.801 with standard deviation 0.012. And the mean value of best solutions found was 0.155 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "30360dbd-5419-4f4d-a950-c846292094f8", "metadata": {"aucs": [0.7980023834254708, 0.8162335136982601, 0.7883002266053964], "final_y": [0.15318713485011226, 0.15112667748602482, 0.1615338745511009]}, "mutation_prompt": null}
{"id": "3a3538f1-ad5a-4462-825a-bb9556642e2d", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.initial_crossover_rate = 0.7\n        self.crossover_rate = self.initial_crossover_rate\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) + self.mutation_factor\n        mutant = a + dynamic_factor * (b - c) + 0.1 * (np.mean(self.population, axis=0) - a)\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = 0.005 * (bounds.ub - bounds.lb)  \n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n        else:\n            self.population_size = min(int(self.population_size * 1.1), 20 * self.dim)\n            self.crossover_rate = max(self.initial_crossover_rate - 0.1, 0.4)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Introduce a dynamic population size and adaptive crossover rate for enhanced exploration-exploitation balance.", "configspace": "", "generation": 31, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 106 is out of bounds for axis 0 with size 100').", "error": "IndexError('index 106 is out of bounds for axis 0 with size 100')", "parent_id": "30360dbd-5419-4f4d-a950-c846292094f8", "metadata": {}, "mutation_prompt": null}
{"id": "5e1079c8-40ce-4550-b92f-89fb37948722", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) + self.mutation_factor\n        mutant = a + dynamic_factor * (b - c) + 0.1 * (np.mean(self.population, axis=0) - a)\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        # Adaptive crossover rate based on population diversity\n        self.crossover_rate = 0.5 + 0.5 * (np.std(self.population) / np.mean(np.abs(self.population)))\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = 0.005 * (bounds.ub - bounds.lb)  \n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Introduce adaptive crossover rate based on population diversity to enhance exploration.", "configspace": "", "generation": 32, "fitness": 0.8237064151401646, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.824 with standard deviation 0.008. And the mean value of best solutions found was 0.147 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "30360dbd-5419-4f4d-a950-c846292094f8", "metadata": {"aucs": [0.8205724494889781, 0.8162365596160801, 0.8343102363154358], "final_y": [0.14319159872685883, 0.15112667748602482, 0.14524833855852715]}, "mutation_prompt": null}
{"id": "9790f3f9-99da-4f3a-99c2-7b5ba67bf97d", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) + self.mutation_factor\n        mutant = a + dynamic_factor * (b - c) + 0.1 * (np.mean(self.population, axis=0) - a)\n        if np.random.rand() < 0.1:  # Enhanced mutation probability\n            mutant += np.random.normal(0, 0.1, self.dim)  # Add Gaussian noise\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        # Adaptive crossover rate based on population diversity\n        self.crossover_rate = 0.5 + 0.5 * (np.std(self.population) / np.mean(np.abs(self.population)))\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = 0.005 * (bounds.ub - bounds.lb)  \n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population, best_solution):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n        if best_solution not in new_population:  # Ensure elitism\n            new_population[np.random.randint(self.population_size)] = best_solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population, best_solution)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Enhance dynamic mutation and introduce elitism to improve search efficiency and convergence.", "configspace": "", "generation": 33, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()').", "error": "ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()')", "parent_id": "5e1079c8-40ce-4550-b92f-89fb37948722", "metadata": {}, "mutation_prompt": null}
{"id": "99a09a26-7a08-4498-91e9-29ad7ecff7f8", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = self.mutation_factor * (1 + 0.1 * np.random.rand())  # Change 1/3\n        mutant = a + dynamic_factor * (b - c) + 0.1 * (np.mean(self.population, axis=0) - a)\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        # Adaptive crossover rate based on population diversity\n        self.crossover_rate = 0.5 + 0.5 * (np.std(self.population) / np.mean(np.abs(self.population)))\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = 0.005 * (bounds.ub - bounds.lb)\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n                    self.mutation_factor = self.mutation_factor * 0.9 + 0.1 * np.random.rand()  # Change 2/3\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Introduce dynamic mutation factor adjustment based on fitness improvements to enhance convergence.", "configspace": "", "generation": 34, "fitness": 0.8215184971539568, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.822 with standard deviation 0.026. And the mean value of best solutions found was 0.146 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "5e1079c8-40ce-4550-b92f-89fb37948722", "metadata": {"aucs": [0.8078397971441729, 0.7986019968324313, 0.8581136974852661], "final_y": [0.15266481912970353, 0.1468289943478185, 0.13725315597156418]}, "mutation_prompt": null}
{"id": "cb834ea5-6bb3-44db-b966-bba65eaf53ba", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * dim\n        self.population_size = self.initial_population_size\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) + self.mutation_factor\n        mutant = a + dynamic_factor * (b - c) + 0.1 * (np.mean(self.population, axis=0) - a)\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        self.crossover_rate = 0.5 + 0.5 * (np.std(self.population) / np.mean(np.abs(self.population)))\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = 0.005 * (bounds.ub - bounds.lb)\n        perturbation = np.random.uniform(-step_size, step_size, self.dim) * (1 + np.std(self.population) / 2)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n        else:\n            self.population_size = min(self.initial_population_size, len(new_population) + 1)\n            self.population = np.random.choice(new_population, self.population_size, replace=False)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Introduce dynamic population resizing and adaptive perturbation scaling to balance exploration and exploitation.", "configspace": "", "generation": 35, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('a must be 1-dimensional').", "error": "ValueError('a must be 1-dimensional')", "parent_id": "5e1079c8-40ce-4550-b92f-89fb37948722", "metadata": {}, "mutation_prompt": null}
{"id": "1e97bd2f-547d-48b1-9293-346c7bc0874a", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) + self.mutation_factor\n        mutant = a + dynamic_factor * (b - c) + 0.1 * (np.mean(self.population, axis=0) - a)\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        # Adaptive crossover rate based on population diversity\n        self.crossover_rate = 0.5 + 0.5 * (np.std(self.population) / np.mean(np.abs(self.population)))\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        # Adjust step size based on population diversity\n        step_size = 0.005 * (bounds.ub - bounds.lb) * (np.std(self.population) / np.mean(np.abs(self.population)))\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Improve local search by dynamically adjusting step size based on population diversity for enhanced exploitation.", "configspace": "", "generation": 36, "fitness": 0.8240351779364743, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.824 with standard deviation 0.008. And the mean value of best solutions found was 0.146 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "5e1079c8-40ce-4550-b92f-89fb37948722", "metadata": {"aucs": [0.8212375072098403, 0.8157345515067778, 0.8351334750928047], "final_y": [0.14287254040703523, 0.15132018004278924, 0.14496466499279947]}, "mutation_prompt": null}
{"id": "5002ec1b-3b9f-41b5-98ad-881fea19fc23", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population_size = self.initial_population_size\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) + self.mutation_factor\n        mutant = a + dynamic_factor * (b - c) + 0.1 * (np.mean(self.population, axis=0) - a)\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        self.crossover_rate = 0.5 + 0.5 * (np.std(self.population) / np.mean(np.abs(self.population)))\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = 0.005 * (bounds.ub - bounds.lb) * (np.std(self.population) / np.mean(np.abs(self.population)))\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population, bounds, best_fitness):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n        progress = np.abs(best_fitness - np.min([func(ind) for ind in new_population])) / best_fitness\n        if progress < 0.01:\n            self.population_size = min(20 * self.dim, self.population_size + int(0.2 * self.dim))\n        else:\n            self.population_size = self.initial_population_size\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population, bounds, best_fitness)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Enhance exploration by dynamically adjusting the population size based on convergence progress for better global search.", "configspace": "", "generation": 37, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_id": "1e97bd2f-547d-48b1-9293-346c7bc0874a", "metadata": {}, "mutation_prompt": null}
{"id": "21ea3bf3-fa95-4ff1-90b5-c9c859468655", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        fitness_improvement = (self.budget - self.func_evals) / self.budget\n        dynamic_factor = (0.9 - 0.5) * fitness_improvement + 0.5\n        mutant = a + dynamic_factor * (b - c) + 0.1 * (np.mean(self.population, axis=0) - a)\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        self.crossover_rate = 0.5 + 0.5 * (np.std(self.population) / np.mean(np.abs(self.population)))\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = 0.005 * (bounds.ub - bounds.lb) * (np.std(self.population) / np.mean(np.abs(self.population)))\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Introduce a dynamic mutation factor adjustment based on fitness improvement rate to balance exploration and exploitation.", "configspace": "", "generation": 38, "fitness": 0.7779038497358028, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.778 with standard deviation 0.017. And the mean value of best solutions found was 0.163 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "1e97bd2f-547d-48b1-9293-346c7bc0874a", "metadata": {"aucs": [0.7705909693780242, 0.8008283749956213, 0.7622922048337629], "final_y": [0.16514546269601904, 0.15314543885803678, 0.16973181242093083]}, "mutation_prompt": null}
{"id": "a7dcdf8d-7dea-4209-8bd0-7604dc2a439d", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        # Adaptive mutation factor based on fitness improvements\n        fitness_improvement = np.mean([func(ind) for ind in self.population]) - func(a)\n        dynamic_factor = (0.9 - np.clip(fitness_improvement, 0, 0.9)) * (1 - self.mutation_factor) + self.mutation_factor\n        mutant = a + dynamic_factor * (b - c) + 0.1 * (np.mean(self.population, axis=0) - a)\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        fitness_diversity = np.std([func(ind) for ind in self.population])\n        self.crossover_rate = 0.6 + 0.4 * (fitness_diversity / (1 + fitness_diversity))\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = 0.005 * (bounds.ub - bounds.lb) * (np.std(self.population) / np.mean(np.abs(self.population)))\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Introduce adaptive mutation and crossover strategies based on genetic diversity and fitness improvements to enhance global search capability.", "configspace": "", "generation": 39, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_id": "1e97bd2f-547d-48b1-9293-346c7bc0874a", "metadata": {}, "mutation_prompt": null}
{"id": "2c8693f1-b697-4b90-a5b7-fb52dbf9ab18", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) + self.mutation_factor\n        mutant = a + dynamic_factor * (b - c) + 0.1 * (np.mean(self.population, axis=0) - a)\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        # Adaptive crossover rate based on population diversity\n        self.crossover_rate = 0.5 + 0.5 * (np.std(self.population) / np.mean(np.abs(self.population)))\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        # Adjust step size based on population diversity\n        step_size = 0.005 * (bounds.ub - bounds.lb) * (np.std(self.population) / np.mean(np.abs(self.population)))\n        perturbation = np.random.standard_normal(self.dim) * step_size  # Improved perturbation\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        diversity_threshold = 0.05 * self.dim  # Smaller threshold for early restart\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Enhance solution quality by introducing a stochastic perturbation in local search and improved diversity maintenance.", "configspace": "", "generation": 40, "fitness": 0.7741039156451915, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.774 with standard deviation 0.017. And the mean value of best solutions found was 0.151 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "1e97bd2f-547d-48b1-9293-346c7bc0874a", "metadata": {"aucs": [0.754858327124343, 0.7968515163598301, 0.7706019034514017], "final_y": [0.1601297873012476, 0.15157888939701825, 0.14228532327166143]}, "mutation_prompt": null}
{"id": "255fa781-b8d5-46f2-b10d-0ed046545064", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) + self.mutation_factor\n        mutant = a + dynamic_factor * (b - c) + 0.1 * (np.mean(self.population, axis=0) - a)\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        # Enhanced crossover calculation with diversity emphasis\n        diversity = np.std(self.population) / np.mean(np.abs(self.population))\n        self.crossover_rate = 0.3 + 0.7 * (1 - diversity)\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        # Adjust step size with dynamic scaling\n        step_size = 0.005 * (bounds.ub - bounds.lb) * (np.std(self.population) / np.mean(np.abs(self.population)))\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.population_size = min(10 * self.dim, self.population_size + 1)  # Adaptive resizing\n            self.initialize_population(bounds.lb, bounds.ub)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Incorporate adaptive population resizing and enhanced crossover control to balance exploration and exploitation for improved optimization performance.", "configspace": "", "generation": 41, "fitness": 0.8124755322499769, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.812 with standard deviation 0.019. And the mean value of best solutions found was 0.150 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "1e97bd2f-547d-48b1-9293-346c7bc0874a", "metadata": {"aucs": [0.806089646740702, 0.7935137085193598, 0.8378232414898688], "final_y": [0.14813410717356834, 0.1601017669387199, 0.14307092979140668]}, "mutation_prompt": null}
{"id": "f03ed95a-f51f-4833-a32c-fcde6c551635", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub, best_solution):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) + self.mutation_factor\n        # Adjust mutation factor based on quality of the current best solution\n        quality_factor = 1 - np.linalg.norm(best_solution - a) / np.linalg.norm(ub - lb)\n        mutant = a + dynamic_factor * quality_factor * (b - c) + 0.1 * (np.mean(self.population, axis=0) - a)\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        self.crossover_rate = 0.5 + 0.5 * (np.std(self.population) / np.mean(np.abs(self.population)))\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = 0.005 * (bounds.ub - bounds.lb) * (np.std(self.population) / np.mean(np.abs(self.population)))\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population, best_solution):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n        # Introduce elitism to keep the best solution found so far\n        if best_solution is not None:\n            new_population[np.random.randint(0, self.population_size)] = best_solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub, best_solution)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population, best_solution)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Enhance exploration by integrating a dynamic mutation factor driven by solution quality and introduce elitism to preserve top solutions.", "configspace": "", "generation": 42, "fitness": -Infinity, "feedback": "An exception occurred: TypeError(\"unsupported operand type(s) for -: 'NoneType' and 'float'\").", "error": "TypeError(\"unsupported operand type(s) for -: 'NoneType' and 'float'\")", "parent_id": "1e97bd2f-547d-48b1-9293-346c7bc0874a", "metadata": {}, "mutation_prompt": null}
{"id": "b40afcf4-676e-4bd5-9bf0-e159d6c952b2", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        # Adjust mutation strategy based on population convergence\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) + self.mutation_factor\n        convergence_factor = 1 - np.std(self.population) / (np.ptp(self.population) + 1e-9)\n        mutant = a + dynamic_factor * (b - c) + 0.1 * convergence_factor * (np.mean(self.population, axis=0) - a)\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        self.crossover_rate = 0.5 + 0.5 * (np.std(self.population) / np.mean(np.abs(self.population)))\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = 0.005 * (bounds.ub - bounds.lb) * (np.std(self.population) / np.mean(np.abs(self.population)))\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Enhance local search by adaptively adjusting the mutation strategy based on the population's convergence state.", "configspace": "", "generation": 43, "fitness": 0.8247305716809873, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.825 with standard deviation 0.009. And the mean value of best solutions found was 0.146 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "1e97bd2f-547d-48b1-9293-346c7bc0874a", "metadata": {"aucs": [0.8262498403030472, 0.8129073874954841, 0.8350344872444307], "final_y": [0.14050050219238608, 0.15241738353806844, 0.14499879264218452]}, "mutation_prompt": null}
{"id": "e2f9ff6f-ac67-4034-9207-d31e8da8eb1a", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_population_size = self.population_size\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        # Rank-based selection\n        idxs = np.argsort([func(ind) for ind in self.population])\n        a, b, c = self.population[np.random.choice(idxs[:5], 3, replace=False)]\n        # Adjust mutation strategy based on population convergence\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) + self.mutation_factor\n        convergence_factor = 1 - np.std(self.population) / (np.ptp(self.population) + 1e-9)\n        mutant = a + dynamic_factor * (b - c) + 0.1 * convergence_factor * (np.mean(self.population, axis=0) - a)\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        self.crossover_rate = 0.5 + 0.5 * (np.std(self.population) / np.mean(np.abs(self.population)))\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = 0.005 * (bounds.ub - bounds.lb) * (np.std(self.population) / np.mean(np.abs(self.population)))\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.population_size = int(self.initial_population_size * 0.9)\n            self.initialize_population(bounds.lb, bounds.ub)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Introduce a rank-based mutation strategy and dynamic population resizing to improve diversity and convergence.", "configspace": "", "generation": 44, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_id": "b40afcf4-676e-4bd5-9bf0-e159d6c952b2", "metadata": {}, "mutation_prompt": null}
{"id": "31846366-d25d-40f8-be1a-ba5033de8212", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) + self.mutation_factor\n        convergence_factor = 1 - np.std(self.population) / (np.ptp(self.population) + 1e-9)\n        dynamic_factor *= np.exp(-0.1 * convergence_factor)  # Adjust mutation factor based on diversity\n        mutant = a + dynamic_factor * (b - c) + 0.1 * convergence_factor * (np.mean(self.population, axis=0) - a)\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        self.crossover_rate = 0.5 + 0.5 * (np.std(self.population) / np.mean(np.abs(self.population)))\n        self.crossover_rate *= np.exp(0.1 * (np.std(self.population) / np.mean(np.abs(self.population)))) # Dynamic crossover rate\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = 0.005 * (bounds.ub - bounds.lb) * (np.std(self.population) / np.mean(np.abs(self.population)))\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Incorporates dynamic scaling of mutation and crossover rates based on population diversity to enhance global exploration.", "configspace": "", "generation": 45, "fitness": 0.7985104337087798, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.799 with standard deviation 0.026. And the mean value of best solutions found was 0.147 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "b40afcf4-676e-4bd5-9bf0-e159d6c952b2", "metadata": {"aucs": [0.8039122801305236, 0.8267104962700642, 0.7649085247257517], "final_y": [0.14943217521267782, 0.14717204424205, 0.14451127106937833]}, "mutation_prompt": null}
{"id": "16373d91-bc57-4ac8-9e31-100988f69189", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.learning_rate = 0.01  # Added dynamic learning rate\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) + self.mutation_factor\n        convergence_factor = 1 - np.std(self.population) / (np.ptp(self.population) + 1e-9)\n        mutant = a + dynamic_factor * (b - c) + 0.1 * convergence_factor * (np.mean(self.population, axis=0) - a)\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        self.crossover_rate = 0.5 + 0.5 * (np.std(self.population) / np.mean(np.abs(self.population)))\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = self.learning_rate * 0.005 * (bounds.ub - bounds.lb)  # Adjusted with learning rate\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n        else:\n            self.learning_rate *= 1.01  # Incrementally adjust learning rate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Integrate dynamic learning rate adaptation based on search space exploitation for enhanced convergence.", "configspace": "", "generation": 46, "fitness": 0.8247552317221069, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.825 with standard deviation 0.009. And the mean value of best solutions found was 0.146 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "b40afcf4-676e-4bd5-9bf0-e159d6c952b2", "metadata": {"aucs": [0.826890037420581, 0.8122987559624087, 0.8350769017833306], "final_y": [0.14020016562048976, 0.15265368229856058, 0.14498432611062695]}, "mutation_prompt": null}
{"id": "674f3dad-7d1b-4b58-9dfd-fd7a4c0615c4", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.learning_rate = 0.01\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        diversity = np.std(self.population) / (np.mean(np.abs(self.population)) + 1e-9)\n        dynamic_factor = self.mutation_factor + 0.2 * (1 - diversity)  # Adjusted\n        mutant = a + dynamic_factor * (b - c)\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        diversity = np.std(self.population) / (np.mean(np.abs(self.population)) + 1e-9)\n        self.crossover_rate = 0.5 + 0.5 * diversity  # Adjusted\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = self.learning_rate * 0.005 * (bounds.ub - bounds.lb)\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n        else:\n            self.learning_rate *= 1.01\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Enhance convergence by introducing adaptive mutation and crossover rates influenced by population diversity.", "configspace": "", "generation": 47, "fitness": 0.7872248040190403, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.787 with standard deviation 0.012. And the mean value of best solutions found was 0.152 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "16373d91-bc57-4ac8-9e31-100988f69189", "metadata": {"aucs": [0.797165715758945, 0.7936482522536285, 0.7708604440445471], "final_y": [0.15444067338658973, 0.1601017669387199, 0.14231955672084795]}, "mutation_prompt": null}
{"id": "5c130147-2cb8-4401-bdc4-e761d9b92e58", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.learning_rate = 0.01\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) + self.mutation_factor\n        convergence_factor = 1 - np.std(self.population) / (np.ptp(self.population) + 1e-9)\n        adaptive_factor = np.random.rand() * self.learning_rate\n        mutant = a + dynamic_factor * (b - c) + adaptive_factor * convergence_factor * (np.mean(self.population, axis=0) - a)\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        self.crossover_rate = 0.5 + 0.5 * (np.std(self.population) / np.mean(np.abs(self.population)))\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = self.learning_rate * 0.005 * (bounds.ub - bounds.lb)\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n        else:\n            self.learning_rate *= 1.01\n\n    def adjust_population_size(self):\n        self.population_size = max(5 * self.dim, int(self.population_size * 0.9))\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population)\n            self.adjust_population_size()\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Enhanced Dynamic Differential Evolution with adaptive population size and advanced mutation strategy for improved exploration-exploitation balance.", "configspace": "", "generation": 48, "fitness": 0.7884222454848423, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.788 with standard deviation 0.032. And the mean value of best solutions found was 0.152 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "16373d91-bc57-4ac8-9e31-100988f69189", "metadata": {"aucs": [0.7676624829666262, 0.8336828016494133, 0.7639214518384875], "final_y": [0.15358755137437607, 0.14313602398438796, 0.15839360081974607]}, "mutation_prompt": null}
{"id": "7eb0dd45-fd9f-4683-a8fe-eb034c4e32f8", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.learning_rate = 0.01  # Added dynamic learning rate\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) + self.mutation_factor\n        convergence_factor = 1 - np.std(self.population) / (np.ptp(self.population) + 1e-9)\n        best_individual = self.population[np.argmin([func(p) for p in self.population])]\n        mutant = a + dynamic_factor * (b - c) + 0.1 * convergence_factor * (np.mean(self.population, axis=0) - a) + 0.01 * (best_individual - a)\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        self.crossover_rate = 0.5 + 0.5 * (np.std(self.population) / np.mean(np.abs(self.population)))\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = self.learning_rate * 0.005 * (bounds.ub - bounds.lb)  # Adjusted with learning rate\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n        else:\n            self.learning_rate *= 1.01  # Incrementally adjust learning rate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Enhanced mutation strategy by incorporating historical best solution influence.", "configspace": "", "generation": 49, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_id": "16373d91-bc57-4ac8-9e31-100988f69189", "metadata": {}, "mutation_prompt": null}
{"id": "d4d0cd51-9b26-432b-94b1-68528609ecb4", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.learning_rate = 0.01  # Added dynamic learning rate\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) + self.mutation_factor\n        convergence_factor = 1 - np.std(self.population) / (np.ptp(self.population) + 1e-9)\n        adaptive_mutation = self.mutation_factor * convergence_factor  # Adjusted mutation factor\n        mutant = a + adaptive_mutation * (b - c) + 0.1 * convergence_factor * (np.mean(self.population, axis=0) - a)\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        self.crossover_rate = 0.5 + 0.5 * (np.std(self.population) / np.mean(np.abs(self.population)))\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = self.learning_rate * 0.005 * (bounds.ub - bounds.lb)  # Adjusted with learning rate\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n        else:\n            self.learning_rate *= 1.01  # Incrementally adjust learning rate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Introduce adaptive mutation factor scaling based on convergence rate to enhance exploration-exploitation balance.", "configspace": "", "generation": 50, "fitness": 0.8069500973045188, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.807 with standard deviation 0.034. And the mean value of best solutions found was 0.151 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "16373d91-bc57-4ac8-9e31-100988f69189", "metadata": {"aucs": [0.7726556347064072, 0.7945287369485807, 0.8536659202585688], "final_y": [0.15710169654167794, 0.1562633602277922, 0.13870524054732736]}, "mutation_prompt": null}
{"id": "bdbd2996-f3df-4f78-9151-c8fcf2196a1e", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.learning_rate = 0.01\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) + self.mutation_factor\n        convergence_factor = 1 - np.std(self.population) / (np.ptp(self.population) + 1e-9)\n        entropy_factor = np.clip(np.std(self.population, axis=0) / (np.mean(np.abs(self.population), axis=0) + 1e-9), 0, 1)\n        mutant = a + dynamic_factor * (b - c) + 0.1 * convergence_factor * (np.mean(self.population, axis=0) - a) + 0.1 * entropy_factor * (np.random.uniform(lb, ub, self.dim) - a)\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = self.learning_rate * 0.005 * (bounds.ub - bounds.lb)\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n        else:\n            self.learning_rate *= 1.01\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Enhance exploration capability and diversity control with entropy-based adjustments.", "configspace": "", "generation": 51, "fitness": 0.8125779511510661, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.813 with standard deviation 0.022. And the mean value of best solutions found was 0.144 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "16373d91-bc57-4ac8-9e31-100988f69189", "metadata": {"aucs": [0.8247405104432504, 0.8312418280897759, 0.7817515149201724], "final_y": [0.14170728913335484, 0.14057572697500798, 0.1488241603881193]}, "mutation_prompt": null}
{"id": "cc69fefe-7edc-4fb4-8b3c-c13dcc0bc0d3", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.learning_rate = 0.01  # Added dynamic learning rate\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) + self.mutation_factor\n        convergence_factor = 1 - np.std(self.population) / (np.ptp(self.population) + 1e-9)\n        diversity_factor = np.random.uniform(0.1, 0.3)  # Adds diversity to mutation\n        mutant = a + dynamic_factor * (b - c) + diversity_factor * convergence_factor * (np.mean(self.population, axis=0) - a)\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        self.crossover_rate = 0.5 + 0.5 * (np.std(self.population) / np.mean(np.abs(self.population)))\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = self.learning_rate * 0.005 * (bounds.ub - bounds.lb)  # Adjusted with learning rate\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n        else:\n            self.learning_rate *= 1.01  # Incrementally adjust learning rate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Enhance mutation diversity and adaptive mechanisms in AdaptiveDifferentialEvolution for improved convergence.", "configspace": "", "generation": 52, "fitness": 0.7772201942996313, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.777 with standard deviation 0.016. And the mean value of best solutions found was 0.153 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "16373d91-bc57-4ac8-9e31-100988f69189", "metadata": {"aucs": [0.7680614793544547, 0.7992365087297747, 0.7643625948146644], "final_y": [0.1472404052507159, 0.14174394913258992, 0.1690385216059781]}, "mutation_prompt": null}
{"id": "389bbf4c-59d2-4f30-8ead-6f8472102c87", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.learning_rate = 0.01  # Added dynamic learning rate\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) + self.mutation_factor\n        convergence_factor = 1 - np.std(self.population) / (np.ptp(self.population) + 1e-9)\n        diversity_boost = np.random.normal(0, 0.1, self.dim)  # Boost diversity with Gaussian noise\n        mutant = a + dynamic_factor * (b - c) + 0.1 * convergence_factor * (np.mean(self.population, axis=0) - a) + diversity_boost\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        self.crossover_rate = 0.5 + 0.5 * (np.std(self.population) / np.mean(np.abs(self.population)))\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = self.learning_rate * 0.005 * (bounds.ub - bounds.lb)  # Adjusted with learning rate\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n        else:\n            self.learning_rate *= 1.01  # Incrementally adjust learning rate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Enhance solution diversity by incorporating additional adaptive learning dynamics for mutation and crossover.", "configspace": "", "generation": 53, "fitness": 0.7787332318550022, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.779 with standard deviation 0.012. And the mean value of best solutions found was 0.162 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "16373d91-bc57-4ac8-9e31-100988f69189", "metadata": {"aucs": [0.7771840422738343, 0.7939908474437378, 0.7650248058474346], "final_y": [0.1623893281948423, 0.15856080566281128, 0.1652016841684969]}, "mutation_prompt": null}
{"id": "03c8cd69-a310-416f-b7ea-17fbd321d825", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.learning_rate = 0.01  # Added dynamic learning rate\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) + self.mutation_factor\n        convergence_factor = 1 - np.std(self.population) / (np.ptp(self.population) + 1e-9)\n        diversity_factor = np.random.rand()  # Introduce random diversity factor\n        mutant = a + dynamic_factor * (b - c) + 0.1 * convergence_factor * (np.mean(self.population, axis=0) - a) + diversity_factor * (ub - lb) * np.random.normal(size=self.dim)\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        self.crossover_rate = 0.5 + 0.5 * (np.std(self.population) / np.mean(np.abs(self.population)))\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = self.learning_rate * 0.005 * (bounds.ub - bounds.lb)  # Adjusted with learning rate\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population, bounds):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n            print(\"Diversity too low, restarting population...\")  # Add logging for restarts\n        else:\n            self.learning_rate *= 1.01  # Incrementally adjust learning rate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population, bounds)  # Pass bounds for potential reset\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Enhance diversity through adaptive mutation and dynamic restart strategies in differential evolution.", "configspace": "", "generation": 54, "fitness": 0.7848527305723566, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.785 with standard deviation 0.022. And the mean value of best solutions found was 0.160 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "16373d91-bc57-4ac8-9e31-100988f69189", "metadata": {"aucs": [0.7677583798870193, 0.8166407386273682, 0.7701590732026823], "final_y": [0.16899744869540734, 0.14874612165039136, 0.16190977585964694]}, "mutation_prompt": null}
{"id": "7659179b-2bd7-49c7-8e2e-820776f22e08", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.learning_rate = 0.01  # Added dynamic learning rate\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) + self.mutation_factor\n        convergence_factor = 1 - np.std(self.population) / (np.ptp(self.population) + 1e-9)\n        mutant = a + dynamic_factor * (b - c) + 0.1 * convergence_factor * (np.mean(self.population, axis=0) - a)\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        self.crossover_rate = 0.5 + 0.5 * (np.std(self.population) / np.mean(np.abs(self.population)))\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        diversity_threshold = 0.1 * self.dim\n        step_size = self.learning_rate * 0.005 * (bounds.ub - bounds.lb)\n        # Adjust perturbation based on diversity\n        if np.std(self.population) < diversity_threshold:\n            step_size *= 2  \n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n        else:\n            self.learning_rate *= 1.01  # Incrementally adjust learning rate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Enhance local search by increasing perturbation scope when diversity is low to maintain exploration.", "configspace": "", "generation": 55, "fitness": 0.8247552317221069, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.825 with standard deviation 0.009. And the mean value of best solutions found was 0.146 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "16373d91-bc57-4ac8-9e31-100988f69189", "metadata": {"aucs": [0.826890037420581, 0.8122987559624087, 0.8350769017833306], "final_y": [0.14020016562048976, 0.15265368229856058, 0.14498432611062695]}, "mutation_prompt": null}
{"id": "784c1a7e-8d6a-467c-93bd-2afccc0edb0d", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.learning_rate = 0.01  # Added dynamic learning rate\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) + self.mutation_factor\n        convergence_factor = 1 - np.std(self.population) / (np.ptp(self.population) + 1e-9)\n        scaling_factor = 0.2 + 0.8 * convergence_factor  # Adaptive scaling factor\n        mutant = a + dynamic_factor * scaling_factor * (b - c)\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        self.crossover_rate = 0.5 + 0.5 * (np.std(self.population) / np.mean(np.abs(self.population)))\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = self.learning_rate * 0.005 * (bounds.ub - bounds.lb)\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n            self.learning_rate *= 0.95  # Reduce learning rate to preserve diversity\n        else:\n            self.learning_rate *= 1.01\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n\n            self.update_population(new_population)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Enhance convergence by incorporating a dynamic diversity preservation mechanism and adaptive scaling for mutation.", "configspace": "", "generation": 56, "fitness": 0.804523908336981, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.805 with standard deviation 0.037. And the mean value of best solutions found was 0.149 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "16373d91-bc57-4ac8-9e31-100988f69189", "metadata": {"aucs": [0.7532933306982728, 0.8404995571322337, 0.8197788371804364], "final_y": [0.15404672490812354, 0.14212041463792058, 0.150342483955909]}, "mutation_prompt": null}
{"id": "d6e8f8b2-b33a-45a9-8c2a-a349f6603bcc", "solution": "import numpy as np\n\nclass EnhancedAdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.learning_rate = 0.01\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        improvement_factor = (np.min(self.population) - np.mean(self.population)) / (np.std(self.population) + 1e-9)\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) * improvement_factor + self.mutation_factor\n        mutant = a + dynamic_factor * (b - c)\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        improvement_factor = (np.mean(self.population) - np.min(self.population)) / (np.max(self.population) - np.min(self.population) + 1e-9)\n        self.crossover_rate = 0.5 + 0.5 * improvement_factor\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = self.learning_rate * 0.005 * (bounds.ub - bounds.lb)\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n        else:\n            self.learning_rate *= 1.02\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "EnhancedAdaptiveDifferentialEvolution", "description": "Enhance the algorithm by incorporating adaptive mutation and crossover rates based on fitness improvement, alongside a self-adapting learning rate.", "configspace": "", "generation": 57, "fitness": 0.7945405128244909, "feedback": "The algorithm EnhancedAdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.795 with standard deviation 0.023. And the mean value of best solutions found was 0.152 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "16373d91-bc57-4ac8-9e31-100988f69189", "metadata": {"aucs": [0.7633964992380913, 0.8187251650584346, 0.801499874176947], "final_y": [0.15469891700390503, 0.14895290956259155, 0.15130769961688117]}, "mutation_prompt": null}
{"id": "d3113746-b279-43f0-a7d0-1ff02e2c1efb", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.learning_rate = 0.01\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        diversity = np.std(self.population) / (np.ptp(self.population) + 1e-9)\n        dynamic_factor = self.mutation_factor + 0.2 * diversity\n        convergence_factor = 1 - diversity\n        mutant = a + dynamic_factor * (b - c) + 0.1 * convergence_factor * (np.mean(self.population, axis=0) - a)\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        diversity = np.std(self.population) / (np.mean(np.abs(self.population)) + 1e-9)\n        self.crossover_rate = 0.5 + 0.3 * diversity\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = self.learning_rate * 0.005 * (bounds.ub - bounds.lb)\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n        else:\n            self.learning_rate *= 1.01\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n\n            self.update_population(new_population)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Introduce adaptive mutation and crossover rates based on population diversity to enhance exploration-exploitation balance.", "configspace": "", "generation": 58, "fitness": 0.7975833616574274, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.798 with standard deviation 0.014. And the mean value of best solutions found was 0.152 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "16373d91-bc57-4ac8-9e31-100988f69189", "metadata": {"aucs": [0.7774015389116412, 0.8058517452284977, 0.809496800832143], "final_y": [0.1630585820466529, 0.15410742266229793, 0.1392655337558789]}, "mutation_prompt": null}
{"id": "34e15a3c-3486-48a8-9954-83e7eaa31733", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.learning_rate = 0.01\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) + self.mutation_factor\n        convergence_factor = 1 - np.std(self.population) / (np.ptp(self.population) + 1e-9)\n        mutation_noise = np.random.normal(0, np.std(self.population) * 0.01, self.dim)\n        mutant = a + dynamic_factor * (b - c) + 0.1 * convergence_factor * (np.mean(self.population, axis=0) - a) + mutation_noise\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        self.crossover_rate = 0.5 + 0.5 * (np.std(self.population) / np.mean(np.abs(self.population)))\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        crossover_noise = np.random.normal(0, np.std(self.population) * 0.005, self.dim)\n        return np.clip(trial + crossover_noise, target, mutant)\n\n    def local_search(self, candidate, bounds):\n        step_size = self.learning_rate * 0.005 * (bounds.ub - bounds.lb)\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n        else:\n            self.learning_rate *= 1.01\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Enhance mutation and crossover operations by incorporating population variance for dynamic adaptation and improve convergence speed.", "configspace": "", "generation": 59, "fitness": 0.8042380398168598, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.804 with standard deviation 0.011. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "16373d91-bc57-4ac8-9e31-100988f69189", "metadata": {"aucs": [0.820082904345437, 0.7956198342703881, 0.7970113808347543], "final_y": [0.14209822112765158, 0.1556458135742983, 0.14765372996342263]}, "mutation_prompt": null}
{"id": "d9b820b7-2fa9-4225-8dc1-33db66a40ec2", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.learning_rate = 0.01\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) + self.mutation_factor\n        convergence_factor = 1 - np.std(self.population) / (np.ptp(self.population) + 1e-9)\n        mutant = a + dynamic_factor * (b - c) + 0.1 * convergence_factor * (np.mean(self.population, axis=0) - a)\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        self.crossover_rate = 0.5 + 0.5 * (np.std(self.population) / np.mean(np.abs(self.population)))\n        diversity_measure = np.std(self.population) / (np.mean(np.abs(self.population)) + 1e-9)\n        self.crossover_rate += 0.1 * (1 - diversity_measure)  # Adjusted dynamically\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = self.learning_rate * 0.005 * (bounds.ub - bounds.lb)\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n        else:\n            self.learning_rate *= 1.01\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Enhance adaptive control by incorporating a dynamic crossover rate and mutation factor based on population diversity.", "configspace": "", "generation": 60, "fitness": 0.7957774686789755, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.796 with standard deviation 0.022. And the mean value of best solutions found was 0.155 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "16373d91-bc57-4ac8-9e31-100988f69189", "metadata": {"aucs": [0.8101362329434437, 0.8122997062110204, 0.7648964668824624], "final_y": [0.14752326769481217, 0.15265368229856058, 0.1660117054464313]}, "mutation_prompt": null}
{"id": "3494ae20-90fe-4618-b8f8-5dabdf126f63", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.learning_rate = 0.01\n        self.population = None\n        self.func_evals = 0\n        self.improvement_memory = []  # Track historical improvements\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) + self.mutation_factor\n        convergence_factor = 1 - np.std(self.population) / (np.ptp(self.population) + 1e-9)\n        historical_factor = 1 + np.mean(self.improvement_memory[-5:]) if self.improvement_memory else 1.0\n        mutant = a + historical_factor * dynamic_factor * (b - c) + 0.1 * convergence_factor * (np.mean(self.population, axis=0) - a)\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        self.crossover_rate = 0.5 + 0.5 * (np.std(self.population) / np.mean(np.abs(self.population)))\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = self.learning_rate * 0.005 * (bounds.ub - bounds.lb)\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n        else:\n            self.learning_rate *= 1.01\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                    self.improvement_memory.append(1)  # Record improvement\n                else:\n                    new_population.append(target)\n                    self.improvement_memory.append(0)  # No improvement\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Enhance convergence by introducing adaptive scaling of mutation and crossover rates based on historical performance.", "configspace": "", "generation": 61, "fitness": 0.7957144413749603, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.796 with standard deviation 0.012. And the mean value of best solutions found was 0.151 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "16373d91-bc57-4ac8-9e31-100988f69189", "metadata": {"aucs": [0.7845510492923026, 0.8122987559624087, 0.7902935188701695], "final_y": [0.15938310621716512, 0.15265368229856058, 0.14049434266307537]}, "mutation_prompt": null}
{"id": "6a88066a-9be5-48ac-9041-4678c51297e2", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.learning_rate = 0.01\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) + self.mutation_factor\n        convergence_factor = 1 - np.std(self.population) / (np.ptp(self.population) + 1e-9)\n        mutant = a + dynamic_factor * (b - c) + 0.1 * convergence_factor * (np.mean(self.population, axis=0) - a)\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        self.crossover_rate = 0.5 + 0.5 * (np.std(self.population) / np.mean(np.abs(self.population)))\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = self.learning_rate * 0.005 * (bounds.ub - bounds.lb)\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n        else:\n            self.learning_rate *= 1.01\n        # Adaptive population resizing\n        if self.func_evals > 0.5 * self.budget:  # After half of the budget\n            convergence_ratio = np.std(new_population) / np.ptp(new_population)\n            new_size = int(self.population_size * (1 + convergence_ratio))\n            self.population = self.population[:new_size]\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Incorporate adaptive population resizing based on convergence metrics to enhance exploration and exploitation balance.", "configspace": "", "generation": 62, "fitness": 0.8247552317221069, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.825 with standard deviation 0.009. And the mean value of best solutions found was 0.146 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "16373d91-bc57-4ac8-9e31-100988f69189", "metadata": {"aucs": [0.826890037420581, 0.8122987559624087, 0.8350769017833306], "final_y": [0.14020016562048976, 0.15265368229856058, 0.14498432611062695]}, "mutation_prompt": null}
{"id": "fe5f6943-004d-4b43-904d-82e031be3599", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.learning_rate = 0.01\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) + self.mutation_factor\n        convergence_factor = 1 - np.std(self.population) / (np.ptp(self.population) + 1e-9)\n        mutant = a + dynamic_factor * (b - c) + 0.1 * convergence_factor * (np.mean(self.population, axis=0) - a)\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        diversity_factor = np.std(self.population) / np.mean(np.abs(self.population))\n        self.crossover_rate = 0.5 + 0.5 * diversity_factor\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = self.learning_rate * 0.01 * (bounds.ub - bounds.lb)  # Increased step size\n        perturbation = np.random.uniform(-step_size * np.std(self.population), step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n        else:\n            self.learning_rate *= 1.01\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Enhance local search with adaptive perturbation and introduce adaptive crossover strategy to improve solution diversity and convergence.", "configspace": "", "generation": 63, "fitness": 0.8237698808114654, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.824 with standard deviation 0.012. And the mean value of best solutions found was 0.146 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "16373d91-bc57-4ac8-9e31-100988f69189", "metadata": {"aucs": [0.8265824567142535, 0.8079457250860521, 0.8367814606340905], "final_y": [0.14037738099534125, 0.15435175760442987, 0.1443964062472698]}, "mutation_prompt": null}
{"id": "4acf60ff-b3e2-411a-930f-d006c0f930c4", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.learning_rate = 0.01  # Added dynamic learning rate\n        self.population = None\n        self.func_evals = 0\n        self.success_rates = []  # Track success rates of mutations and crossovers\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) + self.mutation_factor\n        convergence_factor = 1 - np.std(self.population) / (np.ptp(self.population) + 1e-9)\n        mutant = a + dynamic_factor * (b - c) + 0.1 * convergence_factor * (np.mean(self.population, axis=0) - a)\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        if self.success_rates:\n            self.crossover_rate = np.mean(self.success_rates)  # Adjust based on historical success\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = self.learning_rate * 0.005 * (bounds.ub - bounds.lb)  # Adjusted with learning rate\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        diversity_threshold = 0.1 * self.dim\n        success_rate = sum(func(trial) < func(target) for trial, target in zip(new_population, self.population)) / len(new_population)\n        self.success_rates.append(success_rate)\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n        else:\n            self.learning_rate *= 1.01  # Incrementally adjust learning rate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Introduce adaptive mutation and crossover rates based on historical success, enhancing convergence and solution diversity.", "configspace": "", "generation": 64, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_id": "16373d91-bc57-4ac8-9e31-100988f69189", "metadata": {}, "mutation_prompt": null}
{"id": "08747f30-24ba-4599-a3f0-9e704c0dea0f", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.learning_rate = 0.01  # Added dynamic learning rate\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) + self.mutation_factor\n        convergence_factor = 1 - np.std(self.population) / (np.ptp(self.population) + 1e-9)\n        mutant = a + dynamic_factor * (b - c) + 0.1 * convergence_factor * (np.mean(self.population, axis=0) - a)\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        self.crossover_rate = 0.5 + 0.5 * (np.std(self.population) / np.mean(np.abs(self.population)))\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = self.learning_rate * 0.005 * (bounds.ub - bounds.lb)  # Adjusted with learning rate\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population, best_solution):  # Modified this line\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n            new_population[0] = best_solution  # Ensure best solution is retained\n        else:\n            self.learning_rate *= 1.01  # Incrementally adjust learning rate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population, best_solution)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Introduce elitism by keeping track of the best solution found so far and ensuring it remains in the population to improve convergence.", "configspace": "", "generation": 65, "fitness": 0.8247552317221069, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.825 with standard deviation 0.009. And the mean value of best solutions found was 0.146 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "16373d91-bc57-4ac8-9e31-100988f69189", "metadata": {"aucs": [0.826890037420581, 0.8122987559624087, 0.8350769017833306], "final_y": [0.14020016562048976, 0.15265368229856058, 0.14498432611062695]}, "mutation_prompt": null}
{"id": "8665b3e9-829d-4cb5-aa86-10980217e92c", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.learning_rate = 0.01\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        fitness_variance = np.var([func(ind) for ind in self.population])\n        dynamic_factor = (1.0 + fitness_variance) * self.mutation_factor\n        mutant = a + dynamic_factor * (b - c)\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        self.crossover_rate = 0.5 + 0.5 * (np.std(self.population) / np.mean(np.abs(self.population)))\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = self.learning_rate * 0.005 * (bounds.ub - bounds.lb)\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n        else:\n            self.learning_rate *= 1.01\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Enhance search efficiency by incorporating a novel adaptive mutation and crossover strategy based on individual fitness variance.", "configspace": "", "generation": 66, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_id": "16373d91-bc57-4ac8-9e31-100988f69189", "metadata": {}, "mutation_prompt": null}
{"id": "b68949a0-3454-4de2-88ea-69c5152325f1", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.learning_rate = 0.01  # Added dynamic learning rate\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) + self.mutation_factor\n        convergence_factor = 1 - np.std(self.population) / (np.ptp(self.population) + 1e-9)\n        mutant = a + dynamic_factor * (b - c) + 0.1 * convergence_factor * (np.mean(self.population, axis=0) - a)\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        self.crossover_rate = 0.5 + 0.5 * (np.std(self.population) / np.mean(np.abs(self.population)))\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = self.learning_rate * 0.005 * (bounds.ub - bounds.lb)  # Adjusted with learning rate\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        gradient_step = -self.learning_rate * np.gradient(func(candidate))  # Added gradient-based refinement\n        new_candidate = candidate + perturbation + gradient_step\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n        else:\n            self.learning_rate *= 1.01  # Incrementally adjust learning rate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Integrate a gradient-based local refinement step to enhance solution accuracy.", "configspace": "", "generation": 67, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_id": "16373d91-bc57-4ac8-9e31-100988f69189", "metadata": {}, "mutation_prompt": null}
{"id": "4aee8276-6b40-405e-b5e9-5b5180f34ccc", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.learning_rate = 0.01\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) + self.mutation_factor\n        convergence_factor = 1 - np.std(self.population) / (np.ptp(self.population) + 1e-9)\n        # Change: Adjust mutation_factor based on diversity\n        self.mutation_factor = 0.5 + 0.5 * np.std(self.population) / (np.mean(np.abs(self.population)) + 1e-9)\n        mutant = a + dynamic_factor * (b - c) + 0.1 * convergence_factor * (np.mean(self.population, axis=0) - a)\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        self.crossover_rate = 0.5 + 0.5 * (np.std(self.population) / np.mean(np.abs(self.population)))\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = self.learning_rate * 0.005 * (bounds.ub - bounds.lb)\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n        else:\n            self.learning_rate *= 1.01\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Enhance convergence by dynamically adjusting the mutation factor based on population diversity.", "configspace": "", "generation": 68, "fitness": 0.7983932573206078, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.798 with standard deviation 0.003. And the mean value of best solutions found was 0.157 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "16373d91-bc57-4ac8-9e31-100988f69189", "metadata": {"aucs": [0.8011006850606095, 0.799596188898728, 0.7944828980024862], "final_y": [0.15308661949095703, 0.15698788355178028, 0.15966647268142398]}, "mutation_prompt": null}
{"id": "91b8d215-5898-4bbc-9c6c-d9ec156ba55b", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.learning_rate = 0.01\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = 0.5 + 0.5 * np.random.rand()  # Simplified dynamic factor\n        convergence_factor = np.std(self.population) / (np.ptp(self.population) + 1e-9)  # Inverted effect\n        mutant = a + (dynamic_factor * (b - c) + 0.1 * convergence_factor * (np.mean(self.population, axis=0) - a))\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        self.crossover_rate = 0.5 + 0.3 * np.std(self.population)  # Adjusted rate\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = self.learning_rate * 0.005 * (bounds.ub - bounds.lb)\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n        else:\n            self.learning_rate *= 1.01\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Enhance the dynamic adaptation mechanism by introducing a convergence-aware mutation strategy and diversity-based crossover adjustment for improved performance.", "configspace": "", "generation": 69, "fitness": 0.7818815085623799, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.782 with standard deviation 0.024. And the mean value of best solutions found was 0.156 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "16373d91-bc57-4ac8-9e31-100988f69189", "metadata": {"aucs": [0.7492734823966742, 0.8038541621727897, 0.7925168811176757], "final_y": [0.1725872181828234, 0.14308712179910132, 0.1525614268944675]}, "mutation_prompt": null}
{"id": "55b24194-0c03-4e3b-9141-e91176d13fc3", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.learning_rate = 0.01\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) + self.mutation_factor\n        diversity_factor = np.std(self.population, axis=0)\n        mutant = a + dynamic_factor * (b - c) + 0.1 * diversity_factor * (np.mean(self.population, axis=0) - a)\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        self.crossover_rate = 0.5 + 0.5 * (np.std(self.population) / np.mean(np.abs(self.population)))\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = self.learning_rate * 0.005 * (bounds.ub - bounds.lb)\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n        else:\n            self.learning_rate *= 1.01\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Enhance adaptive differential evolution using diversity-based mutation for improved exploration and convergence balance.", "configspace": "", "generation": 70, "fitness": 0.7830378816919591, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.783 with standard deviation 0.031. And the mean value of best solutions found was 0.163 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "16373d91-bc57-4ac8-9e31-100988f69189", "metadata": {"aucs": [0.740473081271305, 0.7935465781186217, 0.8150939856859505], "final_y": [0.17924064183162647, 0.1601017669387199, 0.14862672039306413]}, "mutation_prompt": null}
{"id": "7fc2c6c1-f4dd-473d-970a-dab06cab9bda", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.learning_rate = 0.01\n        self.population = None\n        self.func_evals = 0\n        self.momentum = 0.9  # Added momentum coefficient\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) + self.mutation_factor\n        convergence_factor = 1 - np.std(self.population) / (np.ptp(self.population) + 1e-9)\n        momentum_update = self.momentum * (np.mean(self.population, axis=0) - a)  # Momentum update\n        mutant = a + dynamic_factor * (b - c) + 0.1 * convergence_factor * momentum_update\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        self.crossover_rate = 0.5 + 0.5 * (np.std(self.population) / np.mean(np.abs(self.population)))\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = self.learning_rate * 0.005 * (bounds.ub - bounds.lb)\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n        else:\n            self.learning_rate *= 1.01\n            self.population_size = max(5 * self.dim, int(self.population_size * 0.99))  # Dynamic resizing\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Enhance convergence speed by incorporating a momentum-driven mutation update and dynamic population resizing.", "configspace": "", "generation": 71, "fitness": 0.8088733737582587, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.809 with standard deviation 0.022. And the mean value of best solutions found was 0.151 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "16373d91-bc57-4ac8-9e31-100988f69189", "metadata": {"aucs": [0.7802163366763486, 0.8120282774792399, 0.8343755071191877], "final_y": [0.15629846048973017, 0.15048647311025687, 0.14522617525320725]}, "mutation_prompt": null}
{"id": "b59af563-43f2-497a-9b3a-99e09342bd9c", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.learning_rate = 0.01  # Added dynamic learning rate\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) + self.mutation_factor\n        convergence_factor = 1 - np.std(self.population) / (np.ptp(self.population) + 1e-9)\n        mutant = a + dynamic_factor * (b - c) + 0.1 * convergence_factor * (np.mean(self.population, axis=0) - a)\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        self.crossover_rate = 0.5 + 0.5 * (np.std(self.population) / np.mean(np.abs(self.population)))\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = self.learning_rate * 0.005 * (bounds.ub - bounds.lb)  # Adjusted with learning rate\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        diversity_threshold = 0.15 * self.dim  # Slightly adjusted diversity threshold\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n        else:\n            self.learning_rate *= 1.01  # Incrementally adjust learning rate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Enhance population diversity by slightly adjusting the diversity threshold for better exploration and convergence.", "configspace": "", "generation": 72, "fitness": 0.8247552317221069, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.825 with standard deviation 0.009. And the mean value of best solutions found was 0.146 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "16373d91-bc57-4ac8-9e31-100988f69189", "metadata": {"aucs": [0.826890037420581, 0.8122987559624087, 0.8350769017833306], "final_y": [0.14020016562048976, 0.15265368229856058, 0.14498432611062695]}, "mutation_prompt": null}
{"id": "b2ed9893-5711-4761-aecd-6eea16819516", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.learning_rate = 0.01  # Added dynamic learning rate\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) + self.mutation_factor\n        diversity_factor = np.std(self.population) / (np.mean(np.abs(self.population)) + 1e-9)\n        dynamic_factor *= (1 + diversity_factor)  # New adjustment for mutation factor\n        mutant = a + dynamic_factor * (b - c) + 0.1 * (np.mean(self.population, axis=0) - a)\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        self.crossover_rate = 0.5 + 0.5 * (np.std(self.population) / np.mean(np.abs(self.population)))\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = self.learning_rate * 0.01 * (bounds.ub - bounds.lb)  # Adjusted exploration step\n        perturbation = np.random.normal(0, step_size, self.dim)  # Changed to normal distribution\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n        else:\n            self.learning_rate *= 1.01\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Enhance the Adaptive Differential Evolution algorithm by incorporating an adaptive mutation factor based on population diversity and refining the local search strategy for better exploration-exploitation balance.", "configspace": "", "generation": 73, "fitness": 0.7691133167661824, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.769 with standard deviation 0.018. And the mean value of best solutions found was 0.167 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "16373d91-bc57-4ac8-9e31-100988f69189", "metadata": {"aucs": [0.7508575144043665, 0.7933228958018839, 0.7631595400922966], "final_y": [0.172443025402086, 0.1601017669387199, 0.16950934094094727]}, "mutation_prompt": null}
{"id": "0074b06c-6658-40c6-901b-844726158553", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.learning_rate = 0.01\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        mutation_pool = self.population[np.random.choice(idxs, 5, replace=False)]\n        a, b, c, d, e = mutation_pool\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) + self.mutation_factor\n        mutant = a + dynamic_factor * (b - c) + (1 - dynamic_factor) * (d - e)\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        elite_factor = (self.mutation_factor * np.std(self.population)) / (np.mean(np.abs(self.population)) + 1e-9)\n        self.crossover_rate = 0.5 + elite_factor\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = self.learning_rate * 0.005 * (bounds.ub - bounds.lb)\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n        else:\n            self.learning_rate *= 1.01\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Enhance convergence by introducing adaptive mutation and hybrid crossover strategies.", "configspace": "", "generation": 74, "fitness": 0.8079701606814828, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.808 with standard deviation 0.013. And the mean value of best solutions found was 0.149 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "16373d91-bc57-4ac8-9e31-100988f69189", "metadata": {"aucs": [0.8062940337132364, 0.7932677328592858, 0.8243487154719262], "final_y": [0.14738633121709943, 0.1601017669387199, 0.14040969157972383]}, "mutation_prompt": null}
{"id": "efc95555-b57c-44be-a729-27cca216deb9", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.learning_rate = 0.01\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) + self.mutation_factor\n        convergence_factor = 1 - np.std(self.population) / (np.ptp(self.population) + 1e-9)\n        diversity_factor = np.tanh(np.std(self.population))\n        mutant = a + dynamic_factor * (b - c) + 0.1 * convergence_factor * (np.mean(self.population, axis=0) - a) + 0.05 * diversity_factor\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        self.crossover_rate = 0.5 + 0.5 * (np.std(self.population) / np.mean(np.abs(self.population)))\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = self.learning_rate * 0.005 * (bounds.ub - bounds.lb)\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n        else:\n            self.learning_rate *= 1.01\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Enhanced Adaptive Differential Evolution with diversity-driven mutation and crossover rate adjustment for improved exploration.", "configspace": "", "generation": 75, "fitness": 0.8249003140238114, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.825 with standard deviation 0.009. And the mean value of best solutions found was 0.146 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "16373d91-bc57-4ac8-9e31-100988f69189", "metadata": {"aucs": [0.8268617355212821, 0.812657023865281, 0.835182182684871], "final_y": [0.14020524699156556, 0.15251473756087897, 0.14494814540523282]}, "mutation_prompt": null}
{"id": "89eb52c8-c38e-4dd5-9c72-af7eeae83f08", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.learning_rate = 0.01\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = self.mutation_factor + np.random.rand() * 0.5\n        convergence_factor = 1 - np.std(self.population) / (np.ptp(self.population) + 1e-9)\n        diversity_factor = np.tanh(np.std(self.population))\n        mutant = a + dynamic_factor * (b - c) + 0.1 * convergence_factor * (np.mean(self.population, axis=0) - a)\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        self.crossover_rate = 0.5 + 0.5 * (np.std(self.population) / np.mean(np.abs(self.population)))\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = self.learning_rate * 0.01 * (bounds.ub - bounds.lb)\n        perturbation = np.random.lognormal(mean=0, sigma=0.1, size=self.dim) * step_size\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n        else:\n            self.learning_rate *= 1.01\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Improved Adaptive Differential Evolution with adaptive mutation factor and enhanced local search for robust performance.", "configspace": "", "generation": 76, "fitness": 0.7714617922830748, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.771 with standard deviation 0.018. And the mean value of best solutions found was 0.163 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "efc95555-b57c-44be-a729-27cca216deb9", "metadata": {"aucs": [0.7495416071728715, 0.7935986651349578, 0.7712451045413953], "final_y": [0.16784178890967605, 0.1599321376690126, 0.1624612440196116]}, "mutation_prompt": null}
{"id": "dfe1b264-a846-465e-8a72-9ef07a63e8b0", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.learning_rate = 0.01\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) + self.mutation_factor\n        convergence_factor = 1 - np.var(self.population) / (np.ptp(self.population) + 1e-9)\n        diversity_factor = np.tanh(np.std(self.population))\n        mutant = a + dynamic_factor * (b - c) + 0.2 * convergence_factor * (np.mean(self.population, axis=0) - a) \n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        self.crossover_rate = 0.5 + 0.5 * (np.var(self.population) / np.mean(np.abs(self.population)))\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = self.learning_rate * 0.01 * (bounds.ub - bounds.lb)\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        diversity_threshold = 0.15 * self.dim\n        if np.var(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n        else:\n            self.learning_rate *= 1.02\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Enhanced Adaptive Differential Evolution with improved population diversity and local search adaptation using variance-driven mutation and crossover strategies.", "configspace": "", "generation": 77, "fitness": 0.7639125267046253, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.764 with standard deviation 0.023. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "efc95555-b57c-44be-a729-27cca216deb9", "metadata": {"aucs": [0.7385486477702222, 0.7935157349951358, 0.7596731973485179], "final_y": [0.17924064183162647, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "2320c11c-ddd4-4bb7-8bc0-a51b8461f405", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.learning_rate = 0.01\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        convergence_factor = 1 - np.std(self.population) / (np.ptp(self.population) + 1e-9)\n        diversity_factor = np.tanh(np.std(self.population))\n        adaptive_factor = 1.2 - np.std(self.population) / np.ptp(self.population)\n        mutant = a + adaptive_factor * (b - c) + 0.1 * convergence_factor * (np.mean(self.population, axis=0) - a) + 0.08 * diversity_factor\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        self.crossover_rate = 0.5 + 0.5 * (np.std(self.population) / np.mean(np.abs(self.population)))\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = self.learning_rate * 0.005 * (bounds.ub - bounds.lb)\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population, bounds):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n        else:\n            self.learning_rate *= 1.01\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            best_candidate = None\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if trial_fitness < best_fitness and best_candidate is None:\n                    best_candidate = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n            if best_candidate is not None:\n                new_population[np.random.randint(self.population_size)] = best_candidate\n\n            self.update_population(new_population, bounds)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Enhanced Adaptive Differential Evolution with adaptive mutation factor and population diversity-based elitism for improved exploitation and convergence.", "configspace": "", "generation": 78, "fitness": 0.7788881390287251, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.779 with standard deviation 0.012. And the mean value of best solutions found was 0.161 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "efc95555-b57c-44be-a729-27cca216deb9", "metadata": {"aucs": [0.7751599782287671, 0.7955050259834897, 0.7659994128739186], "final_y": [0.1559583211308151, 0.15808093099051934, 0.1677284335620307]}, "mutation_prompt": null}
{"id": "53afaba2-dfac-4bd6-bb13-f23ddb36583f", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.learning_rate = 0.01\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) + self.mutation_factor\n        convergence_factor = 1 - np.std(self.population) / (np.ptp(self.population) + 1e-9)\n        diversity_factor = np.tanh(np.std(self.population))\n        selective_mutation_factor = np.where(np.random.rand(self.dim) < 0.2, 0.5, dynamic_factor)\n        mutant = a + selective_mutation_factor * (b - c) + 0.1 * convergence_factor * (np.mean(self.population, axis=0) - a) + 0.05 * diversity_factor\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        self.crossover_rate = 0.5 + 0.5 * (np.std(self.population) / np.mean(np.abs(self.population)))\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = self.learning_rate * 0.01 * (bounds.ub - bounds.lb)\n        perturbation = np.random.normal(0, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n        else:\n            self.learning_rate = min(0.05, self.learning_rate * 1.02)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Refined Adaptive Differential Evolution with enhanced local search and adaptive parameter adjustment for improved performance.", "configspace": "", "generation": 79, "fitness": 0.8027855244464481, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.803 with standard deviation 0.025. And the mean value of best solutions found was 0.150 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "efc95555-b57c-44be-a729-27cca216deb9", "metadata": {"aucs": [0.8061528641603186, 0.8311947548838956, 0.7710089542951304], "final_y": [0.14281567865668643, 0.14393687972189262, 0.1641860164435598]}, "mutation_prompt": null}
{"id": "64daf602-5b71-47e2-bf90-4dafd29d432a", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.learning_rate = 0.01\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        self.mutation_factor = 0.5 + 0.5 * np.random.rand()  # Introduce randomness in mutation factor\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        chaotic_factor = np.sin(np.random.rand() * np.pi)  # Introduce chaotic behavior\n        dynamic_factor = chaotic_factor * self.mutation_factor\n        convergence_factor = 1 - np.std(self.population) / (np.ptp(self.population) + 1e-9)\n        diversity_factor = np.tanh(np.std(self.population))\n        mutant = a + dynamic_factor * (b - c) + 0.1 * convergence_factor * (np.mean(self.population, axis=0) - a) + 0.05 * diversity_factor\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        self.crossover_rate = 0.5 + 0.5 * (np.std(self.population) / np.mean(np.abs(self.population)))\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = self.learning_rate * np.abs(np.sin(np.random.rand())) * 0.005 * (bounds.ub - bounds.lb)\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n        else:\n            self.learning_rate *= np.cos(np.random.rand() * np.pi / 2)  # Adaptive learning rate adjustment\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Improved Adaptive Differential Evolution with adaptive step size control and chaotic mutation for enhanced exploration capabilities.", "configspace": "", "generation": 80, "fitness": 0.8135777629222005, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.814 with standard deviation 0.028. And the mean value of best solutions found was 0.145 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "efc95555-b57c-44be-a729-27cca216deb9", "metadata": {"aucs": [0.8012080343429103, 0.8519433429896937, 0.7875819114339975], "final_y": [0.15436579784538118, 0.1312552946276896, 0.14846425239546668]}, "mutation_prompt": null}
{"id": "1a9df866-19aa-4fc8-bdc6-5b2a913c23fd", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.learning_rate = 0.01\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (0.5 - self.mutation_factor) + self.mutation_factor  # Changed\n        convergence_factor = 1 - np.std(self.population) / (np.ptp(self.population) + 1e-9)\n        diversity_factor = np.tanh(np.std(self.population))\n        mutant = a + dynamic_factor * (b - c) + 0.1 * convergence_factor * (np.mean(self.population, axis=0) - a) + 0.05 * diversity_factor\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        self.crossover_rate = 0.5 + 0.5 * (np.std(self.population) / np.mean(np.abs(self.population)))\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = self.learning_rate * 0.0075 * (bounds.ub - bounds.lb)  # Changed\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n        else:\n            self.learning_rate *= 1.01\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Refine Adaptive Differential Evolution by optimizing mutation dynamics and improving local search for more robust adaptation.", "configspace": "", "generation": 81, "fitness": 0.8079035291584967, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.808 with standard deviation 0.035. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "efc95555-b57c-44be-a729-27cca216deb9", "metadata": {"aucs": [0.7620248156842904, 0.8157938376544437, 0.8458919341367563], "final_y": [0.15383674828897154, 0.1489246766346155, 0.14129757980539848]}, "mutation_prompt": null}
{"id": "c662f0b0-bfd5-49ec-8488-356cd135bd91", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.learning_rate = 0.01\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) + self.mutation_factor\n        convergence_factor = 1 - np.std(self.population) / (np.ptp(self.population) + 1e-9)\n        diversity_factor = np.tanh(np.std(self.population))\n        exploration_factor = 0.2 * np.sin(self.func_evals / self.budget * np.pi)\n        mutant = a + dynamic_factor * (b - c) + 0.1 * convergence_factor * (np.mean(self.population, axis=0) - a) + 0.05 * diversity_factor + exploration_factor\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        self.crossover_rate = 0.5 + 0.5 * (np.std(self.population) / (np.mean(np.abs(self.population)) + 1e-9))\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = self.learning_rate * 0.005 * (bounds.ub - bounds.lb)\n        perturbation = np.random.normal(0, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n        else:\n            self.learning_rate *= 1.01\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Refined Adaptive Differential Evolution with dynamic strategy selection and enhanced diversity control for better convergence.", "configspace": "", "generation": 82, "fitness": 0.7725152207844821, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.773 with standard deviation 0.020. And the mean value of best solutions found was 0.163 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "efc95555-b57c-44be-a729-27cca216deb9", "metadata": {"aucs": [0.7491223015474952, 0.7974222683536969, 0.7710010924522542], "final_y": [0.16968053615768697, 0.15626326823493097, 0.16277058930399857]}, "mutation_prompt": null}
{"id": "d9cd03f1-8d19-4497-8174-a094e09d52d9", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.learning_rate = 0.01\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) + self.mutation_factor\n        convergence_factor = 1 - np.std(self.population) / (np.ptp(self.population) + 1e-9)\n        diversity_factor = np.tanh(np.std(self.population))\n        mutant = a + dynamic_factor * (b - c) + 0.1 * convergence_factor * (np.mean(self.population, axis=0) - a) + 0.05 * diversity_factor\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        self.crossover_rate = 0.5 + 0.5 * (np.std(self.population) / np.mean(np.abs(self.population)))\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = self.learning_rate * 0.005 * (bounds.ub - bounds.lb)\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n        else:\n            self.learning_rate *= 1.02  # Slightly increased learning rate increment\n        if self.func_evals > self.budget / 2:  # Adaptive population scaling\n            self.population_size = max(5 * self.dim, int(self.population_size / 1.5))\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Enhanced Adaptive Differential Evolution with dynamic learning rate adjustment and adaptive population scaling for robust exploration-exploitation balance.", "configspace": "", "generation": 83, "fitness": 0.8249002719320173, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.825 with standard deviation 0.009. And the mean value of best solutions found was 0.146 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "efc95555-b57c-44be-a729-27cca216deb9", "metadata": {"aucs": [0.8268616092459, 0.812657023865281, 0.835182182684871], "final_y": [0.1402053000033454, 0.15251473756087897, 0.14494814540523282]}, "mutation_prompt": null}
{"id": "b5e45d26-8b81-4c9e-a55b-1687fc695ae2", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.7  # Increased mutation factor for exploration\n        self.crossover_rate = 0.8  # Increased crossover rate for better diversity\n        self.learning_rate = 0.02  # Adjusted learning rate for effective local search\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) + self.mutation_factor\n        convergence_factor = 1 - np.std(self.population) / (np.ptp(self.population) + 1e-9)\n        diversity_factor = np.tanh(np.std(self.population))\n        mutant = a + dynamic_factor * (b - c) + 0.1 * convergence_factor * (np.mean(self.population, axis=0) - a) + 0.05 * diversity_factor\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        self.crossover_rate = 0.5 + 0.5 * (np.std(self.population) / np.mean(np.abs(self.population)))\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = self.learning_rate * 0.01 * (bounds.ub - bounds.lb)  # Adjusted step size\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation * (1 - np.std(self.population))  # Added population standard deviation influence\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        diversity_threshold = 0.15 * self.dim  # Adjusted diversity threshold\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n        else:\n            self.learning_rate *= 1.02  # Slightly increased learning rate escalation\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Enhanced Diversity Adaptive Differential Evolution with convergence factor-based local search for improved exploration and exploitation balance.  ", "configspace": "", "generation": 84, "fitness": 0.801237390966513, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.801 with standard deviation 0.007. And the mean value of best solutions found was 0.155 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "efc95555-b57c-44be-a729-27cca216deb9", "metadata": {"aucs": [0.810390606229302, 0.7939162876017416, 0.7994052790684955], "final_y": [0.1486783097314781, 0.15990802329944698, 0.15782312289892486]}, "mutation_prompt": null}
{"id": "5921ef5d-0183-49a9-aa0d-68e1605de21d", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(4, int(10 * dim * (1 + 0.1 * np.random.rand())))  # Adaptive pop size\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.learning_rate = 0.01\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) + self.mutation_factor\n        convergence_factor = 1 - np.std(self.population) / (np.ptp(self.population) + 1e-9)\n        diversity_factor = np.tanh(np.std(self.population))\n        mutant = a + dynamic_factor * (b - c) + 0.1 * convergence_factor * (np.mean(self.population, axis=0) - a) + 0.05 * diversity_factor\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        self.crossover_rate = 0.5 + 0.5 * (np.std(self.population) / np.mean(np.abs(self.population)))\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = self.learning_rate * 0.005 * (bounds.ub - bounds.lb)\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n        else:\n            self.learning_rate *= 1.01\n        self.population_size = max(4, int(10 * self.dim * (1 + 0.1 * np.random.rand())))  # Update pop size\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Enhanced Adaptive Differential Evolution with adaptive population size, promoting exploration-exploitation balance and diversity maintenance.", "configspace": "", "generation": 85, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 100 is out of bounds for axis 0 with size 100').", "error": "IndexError('index 100 is out of bounds for axis 0 with size 100')", "parent_id": "efc95555-b57c-44be-a729-27cca216deb9", "metadata": {}, "mutation_prompt": null}
{"id": "b985070e-aa9c-4b08-908f-6a135cf9135d", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.7  # Modified mutation factor\n        self.crossover_rate = 0.7\n        self.learning_rate = 0.01\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = 0.6 + 0.4 * np.random.rand()  # Modified dynamic factor\n        convergence_factor = 1 - np.std(self.population) / (np.ptp(self.population) + 1e-9)\n        diversity_factor = np.tanh(np.std(self.population))\n        mutant = a + dynamic_factor * (b - c) + 0.1 * convergence_factor * (np.mean(self.population, axis=0) - a) + 0.05 * diversity_factor\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        self.crossover_rate = 0.5 + 0.5 * (np.std(self.population) / np.mean(np.abs(self.population)))\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = self.learning_rate * 0.005 * (bounds.ub - bounds.lb)\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n        else:\n            self.learning_rate *= 1.01\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Improved Adaptive Differential Evolution by enhancing mutation and utilizing adaptive search space contraction for better convergence.", "configspace": "", "generation": 86, "fitness": 0.8154423463268995, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.815 with standard deviation 0.006. And the mean value of best solutions found was 0.150 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "efc95555-b57c-44be-a729-27cca216deb9", "metadata": {"aucs": [0.8210977013012262, 0.8071000308124955, 0.8181293068669765], "final_y": [0.14361259858992614, 0.15466626898524982, 0.15094819907456936]}, "mutation_prompt": null}
{"id": "e5d09a55-f2ec-4ffd-80d8-4b144bdb4809", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.learning_rate = 0.01\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) + self.mutation_factor\n        diversity_entropy = -np.sum(np.log2(np.var(self.population, axis=0) + 1e-9) * np.var(self.population, axis=0))\n        diversity_factor = np.tanh(diversity_entropy)\n        mutant = a + dynamic_factor * (b - c) + 0.1 * diversity_factor * (np.mean(self.population, axis=0) - a)\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        self.crossover_rate = 0.5 + 0.5 * (np.std(self.population) / np.mean(np.abs(self.population)))\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = self.learning_rate * 0.005 * (bounds.ub - bounds.lb)\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        diversity_threshold = 0.1 * self.dim\n        diversity_entropy = -np.sum(np.log2(np.var(new_population, axis=0) + 1e-9) * np.var(new_population, axis=0))\n        if diversity_entropy < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n        else:\n            self.learning_rate *= 1.02\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Improved Adaptive Differential Evolution with entropy-based diversity measure and adaptive learning rate adjustment for enhanced exploration and exploitation.", "configspace": "", "generation": 87, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'bounds' is not defined\").", "error": "NameError(\"name 'bounds' is not defined\")", "parent_id": "efc95555-b57c-44be-a729-27cca216deb9", "metadata": {}, "mutation_prompt": null}
{"id": "b05e7aaf-2a3a-4f83-b0fa-60226db991a2", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.learning_rate = 0.01\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        iteration_ratio = self.func_evals / self.budget\n        dynamic_factor = (1 - iteration_ratio) * self.mutation_factor + iteration_ratio * 0.9  # Change here\n        convergence_factor = 1 - np.std(self.population) / (np.ptp(self.population) + 1e-9)\n        diversity_factor = np.tanh(np.std(self.population))\n        mutant = a + dynamic_factor * (b - c) + 0.1 * convergence_factor * (np.mean(self.population, axis=0) - a) + 0.05 * diversity_factor\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        self.crossover_rate = 0.5 + 0.5 * (np.std(self.population) / np.mean(np.abs(self.population)))\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = self.learning_rate * 0.005 * (bounds.ub - bounds.lb)\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def update_population(self, new_population):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n        else:\n            self.learning_rate *= 1.01\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Enhanced Adaptive Differential Evolution with dynamic mutation factor scaling based on the current iteration to balance exploration and exploitation.", "configspace": "", "generation": 88, "fitness": 0.7801545234932847, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.780 with standard deviation 0.012. And the mean value of best solutions found was 0.163 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "efc95555-b57c-44be-a729-27cca216deb9", "metadata": {"aucs": [0.7828589451023988, 0.7935687041911461, 0.7640359211863094], "final_y": [0.16143722163362328, 0.1601017669387199, 0.16827910699084947]}, "mutation_prompt": null}
{"id": "825a27f5-4e9f-4e53-abe2-b2d2f544ec87", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.learning_rate = 0.01\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) + self.mutation_factor\n        convergence_factor = 1 - np.std(self.population) / (np.ptp(self.population) + 1e-9)\n        diversity_factor = np.tanh(np.std(self.population))\n        mutant = a + dynamic_factor * (b - c) + 0.1 * convergence_factor * (np.mean(self.population, axis=0) - a) + 0.05 * diversity_factor\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        self.crossover_rate = 0.5 + 0.5 * (np.std(self.population) / np.mean(np.abs(self.population)))\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = self.learning_rate * 0.003 * (bounds.ub - bounds.lb)  # Modified step size\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def adaptive_learning_rate(self):\n        self.learning_rate = 0.01 * (1 - self.func_evals / self.budget)  # Adaptive learning rate\n\n    def update_population(self, new_population, bounds):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n        else:\n            self.learning_rate *= 1.01\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                self.adaptive_learning_rate()  # Integrate adaptive learning rate\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population, bounds)  # Corrected method signature\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Advanced Adaptive Differential Evolution with adaptive learning rate, constrained mutation, and enhanced local search for improved convergence.", "configspace": "", "generation": 89, "fitness": 0.8249003452888668, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.825 with standard deviation 0.009. And the mean value of best solutions found was 0.146 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "efc95555-b57c-44be-a729-27cca216deb9", "metadata": {"aucs": [0.826867769928943, 0.8126510620255363, 0.8351822039121211], "final_y": [0.14020243135591903, 0.15251705140961658, 0.14494813940940732]}, "mutation_prompt": null}
{"id": "40b2dbc3-2c2c-4b2c-9e41-cdeca8bea817", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 8 * dim  # Changed population size\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.learning_rate = 0.01\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (0.8 - self.mutation_factor) + self.mutation_factor  # Increased range\n        convergence_factor = 1 - np.std(self.population) / (np.ptp(self.population) + 1e-9)\n        diversity_factor = np.tanh(np.std(self.population))\n        mutant = a + dynamic_factor * (b - c) + 0.1 * convergence_factor * (np.mean(self.population, axis=0) - a) + 0.05 * diversity_factor\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        self.crossover_rate = 0.5 + 0.5 * (np.std(self.population) / np.mean(np.abs(self.population)))\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = self.learning_rate * 0.0025 * (bounds.ub - bounds.lb)  # Modified step size\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def adaptive_learning_rate(self):\n        self.learning_rate = 0.01 * (1 - self.func_evals / self.budget)  # Adaptive learning rate\n\n    def update_population(self, new_population, bounds):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n        else:\n            self.learning_rate *= 1.01\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                self.adaptive_learning_rate()  # Integrate adaptive learning rate\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population, bounds)  # Corrected method signature\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Enhanced Adaptive Differential Evolution with dynamic population size, adaptive mutation strategy, and refined local search for improved exploration-exploitation balance.", "configspace": "", "generation": 90, "fitness": 0.7903824744920103, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.790 with standard deviation 0.029. And the mean value of best solutions found was 0.158 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "825a27f5-4e9f-4e53-abe2-b2d2f544ec87", "metadata": {"aucs": [0.7644436229005915, 0.8314823849522349, 0.7752214156232046], "final_y": [0.16724100044404044, 0.14132678544952815, 0.16550550584558854]}, "mutation_prompt": null}
{"id": "048e851e-153b-45bd-b981-f43d47ed420f", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.learning_rate = 0.01\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) + self.mutation_factor\n        convergence_factor = 1 - np.std(self.population) / (np.ptp(self.population) + 1e-9)\n        diversity_factor = np.tanh(np.std(self.population))\n        mutant = a + dynamic_factor * (b - c) + 0.1 * convergence_factor * (np.mean(self.population, axis=0) - a) + 0.05 * diversity_factor\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        self.crossover_rate = 0.5 + 0.5 * (np.std(self.population) / np.mean(np.abs(self.population)))\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = self.learning_rate * 0.003 * (bounds.ub - bounds.lb)\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def adaptive_learning_rate(self):\n        self.learning_rate = 0.01 * (1 - self.func_evals / self.budget)\n\n    def update_population(self, new_population, bounds):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n        else:\n            self.learning_rate *= 1.01\n        # Adjust population size based on diversity\n        self.population_size = int(np.clip(self.population_size * (1 + 0.01 * (diversity_threshold - np.std(new_population))), self.dim, 20 * self.dim))\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                self.adaptive_learning_rate()\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population, bounds)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Enhanced Adaptive Differential Evolution with dynamic population size adjustment for increased diversity and solution quality.", "configspace": "", "generation": 91, "fitness": 0.8176537678120509, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.818 with standard deviation 0.017. And the mean value of best solutions found was 0.139 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "825a27f5-4e9f-4e53-abe2-b2d2f544ec87", "metadata": {"aucs": [0.7973167155518117, 0.816130109977204, 0.8395144779071368], "final_y": [0.13273631010691678, 0.14415404557089717, 0.13893142418760118]}, "mutation_prompt": null}
{"id": "25df4dd5-ef7c-49bb-96ed-76b749697a25", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.learning_rate = 0.01\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) + self.mutation_factor\n        convergence_factor = 1 - np.std(self.population) / (np.ptp(self.population) + 1e-9)\n        diversity_factor = np.tanh(np.std(self.population))\n        dynamic_mutation_factor = self.mutation_factor + 0.1 * np.sin(2 * np.pi * self.func_evals / self.budget)\n        mutant = a + dynamic_mutation_factor * (b - c) + 0.1 * convergence_factor * (np.mean(self.population, axis=0) - a) + 0.05 * diversity_factor\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        self.crossover_rate = 0.5 + 0.5 * (np.std(self.population) / np.mean(np.abs(self.population)))\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = self.learning_rate * 0.003 * (bounds.ub - bounds.lb)  # Modified step size\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def adaptive_learning_rate(self):\n        self.learning_rate = 0.01 * (1 - self.func_evals / self.budget)  # Adaptive learning rate\n\n    def update_population(self, new_population, bounds):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n        else:\n            self.learning_rate *= 1.01\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                self.adaptive_learning_rate()  # Integrate adaptive learning rate\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population, bounds)  # Corrected method signature\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Enhanced Adaptive Differential Evolution with improved mutation factor dynamics boosting exploration-exploitation balance.", "configspace": "", "generation": 92, "fitness": 0.8066409350461171, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.807 with standard deviation 0.045. And the mean value of best solutions found was 0.154 (0. is the best) with standard deviation 0.017.", "error": "", "parent_id": "825a27f5-4e9f-4e53-abe2-b2d2f544ec87", "metadata": {"aucs": [0.7430456368105378, 0.8322321439498878, 0.8446450243779258], "final_y": [0.17760756384150578, 0.1420078607343882, 0.1417168636904984]}, "mutation_prompt": null}
{"id": "fdecf7a3-6970-4583-93a1-2f367db83059", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.learning_rate = 0.01\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = 0.8 * np.random.rand()  # Updated dynamic_factor\n        convergence_factor = 1 - np.std(self.population) / (np.ptp(self.population) + 1e-9)\n        diversity_factor = np.tanh(np.std(self.population) + np.random.rand() * 0.1)  # Updated diversity_factor\n        mutant = a + dynamic_factor * (b - c) + 0.1 * convergence_factor * (np.mean(self.population, axis=0) - a)\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        self.crossover_rate = 0.6 + 0.4 * (np.std(self.population) / np.mean(np.abs(self.population)))  # Adjusted rate\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = self.learning_rate * 0.0035 * (bounds.ub - bounds.lb)  # Modified step size\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def adaptive_learning_rate(self):\n        self.learning_rate = 0.01 * (1 - self.func_evals / self.budget)  # Adaptive learning rate\n\n    def update_population(self, new_population, bounds):\n        diversity_threshold = 0.15 * self.dim  # Adjusted threshold\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n        else:\n            self.learning_rate *= 1.02  # Updated learning rate increment\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                self.adaptive_learning_rate()\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population, bounds)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Enhanced Differential Evolution with adaptive strategies for mutation and crossover rate tuning, and a robust mechanism for population diversity retention.", "configspace": "", "generation": 93, "fitness": 0.7988992056658909, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.799 with standard deviation 0.015. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "825a27f5-4e9f-4e53-abe2-b2d2f544ec87", "metadata": {"aucs": [0.7804538191887347, 0.8165847403864183, 0.7996590574225197], "final_y": [0.1627912482837207, 0.1331643492870831, 0.14741442812264682]}, "mutation_prompt": null}
{"id": "28720aa6-118a-406f-ab5d-1ad8d7d3e649", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.learning_rate = 0.01\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) + self.mutation_factor\n        convergence_factor = 1 - np.std(self.population) / (np.ptp(self.population) + 1e-9)\n        diversity_factor = np.tanh(np.std(self.population))\n        scale_factor = 0.2  # Changed line: Added scale_factor for better dynamic balance\n        mutant = a + scale_factor * dynamic_factor * (b - c) + 0.1 * convergence_factor * (np.mean(self.population, axis=0) - a) + 0.05 * diversity_factor\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        self.crossover_rate = 0.5 + 0.5 * (np.std(self.population) / np.mean(np.abs(self.population)))\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = self.learning_rate * 0.003 * (bounds.ub - bounds.lb)\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def adaptive_learning_rate(self):\n        self.learning_rate = 0.01 * (1 - self.func_evals / self.budget)\n\n    def update_population(self, new_population, bounds):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n        else:\n            self.learning_rate *= 1.01\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                self.adaptive_learning_rate()\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population, bounds)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Improved version of Adaptive Differential Evolution leveraging enhanced mutation dynamics for better exploration and exploitation balance.", "configspace": "", "generation": 94, "fitness": 0.8023687408975446, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.802 with standard deviation 0.006. And the mean value of best solutions found was 0.149 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "825a27f5-4e9f-4e53-abe2-b2d2f544ec87", "metadata": {"aucs": [0.7965369955531816, 0.7999145059235945, 0.8106547212158578], "final_y": [0.13835033067903668, 0.1565641960644274, 0.15067877982774125]}, "mutation_prompt": null}
{"id": "1b3ab7a6-47db-4be1-8e0d-030e2f46308f", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.learning_rate = 0.01\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) + self.mutation_factor\n        convergence_factor = 1 - np.std(self.population) / (np.ptp(self.population) + 1e-9)\n        diversity_factor = np.tanh(np.std(self.population))\n        mutant = a + dynamic_factor * (b - c) + 0.1 * convergence_factor * (np.mean(self.population, axis=0) - a) + 0.05 * diversity_factor\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        self.crossover_rate = 0.5 + 0.5 * (np.std(self.population) / np.mean(np.abs(self.population)))\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = self.learning_rate * 0.005 * (bounds.ub - bounds.lb)  # Enhanced step size\n        perturbation = np.random.normal(0, step_size, self.dim)  # Gaussian perturbation\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def adaptive_learning_rate(self):\n        self.learning_rate = 0.01 * (1 - self.func_evals / self.budget)\n\n    def update_population(self, new_population, bounds):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.population_size = min(2 * self.population_size, 1000)  # Dynamic population control\n            self.initialize_population(bounds.lb, bounds.ub)\n        else:\n            self.learning_rate *= 1.01\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                self.adaptive_learning_rate()\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population, bounds)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Enhanced Adaptive Differential Evolution with dynamic population control and an improved local search strategy for better convergence and exploration.", "configspace": "", "generation": 95, "fitness": 0.7713167520338994, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.771 with standard deviation 0.018. And the mean value of best solutions found was 0.164 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "825a27f5-4e9f-4e53-abe2-b2d2f544ec87", "metadata": {"aucs": [0.7491486205208471, 0.7936054378047749, 0.7711961977760761], "final_y": [0.16902334995957236, 0.1599132603401966, 0.1624893770723499]}, "mutation_prompt": null}
{"id": "62384ab4-1ed0-4a25-971f-eee75fb84b0b", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.learning_rate = 0.01\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) + self.mutation_factor\n        \n        # Modification 1: Enhance dynamic mutation strategy\n        scaling_factor = np.random.normal(0.5, 0.3)  # Normally distributed scaling factor\n        mutant = a + scaling_factor * (b - c) + 0.1 * (np.mean(self.population, axis=0) - a)\n        \n        return np.clip(mutant, lb, ub)\n\n    # Modification 2 & 3: Dynamic crossover rate and selection pressure\n    def crossover(self, target, mutant):\n        self.crossover_rate = 0.5 + 0.3 * np.tanh(np.std(self.population))  # Adjusted crossover rate\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        # Modification 4: Intensified local search\n        step_size = self.learning_rate * 0.005 * (bounds.ub - bounds.lb)\n        perturbation = np.random.normal(0, step_size, self.dim)  # Normal distribution perturbation\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def adaptive_learning_rate(self):\n        self.learning_rate = 0.01 * (1 - self.func_evals / self.budget)\n\n    def update_population(self, new_population, bounds):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n        else:\n            self.learning_rate *= 1.01\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                self.adaptive_learning_rate()\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population, bounds)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Enhanced Adaptive Differential Evolution with dynamic selection pressure, improved mutation strategy, and intensified local search for better exploration and exploitation balance.", "configspace": "", "generation": 96, "fitness": 0.8024672616362073, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.802 with standard deviation 0.004. And the mean value of best solutions found was 0.146 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "825a27f5-4e9f-4e53-abe2-b2d2f544ec87", "metadata": {"aucs": [0.7979348905368246, 0.8064673142742198, 0.8029995800975773], "final_y": [0.14857693941444894, 0.14772057641159664, 0.14251306072219905]}, "mutation_prompt": null}
{"id": "651fdb6f-5947-416c-a2a9-d37d6aa2e703", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.learning_rate = 0.01\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) + self.mutation_factor\n        convergence_factor = 1 - np.std(self.population) / (np.ptp(self.population) + 1e-9)\n        diversity_factor = np.tanh(np.std(self.population))\n        strategic_factor = 0.5 + 0.5 * (np.std(self.population) / np.mean(np.abs(self.population)))\n        mutant = a + strategic_factor * dynamic_factor * (b - c) + 0.1 * convergence_factor * (np.mean(self.population, axis=0) - a) + 0.05 * diversity_factor\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        self.crossover_rate = 0.5 + 0.5 * (np.std(self.population) / np.mean(np.abs(self.population)))\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = self.learning_rate * 0.003 * (bounds.ub - bounds.lb)  # Modified step size\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def adaptive_learning_rate(self):\n        self.learning_rate = 0.01 * (1 - self.func_evals / self.budget)  # Adaptive learning rate\n\n    def update_population(self, new_population, bounds):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n        else:\n            self.learning_rate *= 1.01\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                self.adaptive_learning_rate()  # Integrate adaptive learning rate\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population, bounds)  # Corrected method signature\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Enhanced Adaptive Differential Evolution with strategic dynamic mutation factor and diversity-preserving crossover for improved exploration and convergence balance.", "configspace": "", "generation": 97, "fitness": 0.8069306879801257, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.807 with standard deviation 0.038. And the mean value of best solutions found was 0.151 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "825a27f5-4e9f-4e53-abe2-b2d2f544ec87", "metadata": {"aucs": [0.7601274118881536, 0.8073358916976501, 0.8533287603545736], "final_y": [0.15887868527028282, 0.1546278070560796, 0.1388199510580378]}, "mutation_prompt": null}
{"id": "897aa25a-99a4-4def-bb90-b8734976d2a1", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.base_population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.learning_rate = 0.01\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population_size = self.base_population_size\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (1 - self.mutation_factor) + self.mutation_factor\n        convergence_factor = 1 - np.std(self.population) / (np.ptp(self.population) + 1e-9)\n        diversity_factor = np.tanh(np.std(self.population))\n        exploration_boost = 0.2 * np.random.rand() * (b - c)\n        mutant = a + dynamic_factor * (b - c) + 0.1 * convergence_factor * (np.mean(self.population, axis=0) - a) + 0.05 * diversity_factor + exploration_boost\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        self.crossover_rate = 0.5 + 0.5 * (np.std(self.population) / np.mean(np.abs(self.population)))\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = self.learning_rate * 0.003 * (bounds.ub - bounds.lb)\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def adaptive_learning_rate(self):\n        self.learning_rate = 0.01 * (1 - self.func_evals / self.budget)\n\n    def update_population(self, new_population, bounds):\n        diversity_threshold = 0.1 * self.dim\n        if np.std(new_population) < diversity_threshold:\n            self.population_size = min(self.population_size + 1, 20 * self.dim)\n            self.initialize_population(bounds.lb, bounds.ub)\n        else:\n            self.learning_rate *= 1.01\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                self.adaptive_learning_rate()\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population, bounds)\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Enhanced Adaptive Differential Evolution with dynamic population size adjustment and improved mutation strategy for better exploration and convergence.", "configspace": "", "generation": 98, "fitness": 0.7689516465656102, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.769 with standard deviation 0.022. And the mean value of best solutions found was 0.164 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "825a27f5-4e9f-4e53-abe2-b2d2f544ec87", "metadata": {"aucs": [0.7437138616096289, 0.7967674911833116, 0.7663735869038901], "final_y": [0.1721089041953019, 0.15253471481633096, 0.16634220158932012]}, "mutation_prompt": null}
{"id": "0ee7479e-715f-4d77-945f-27f683dcd493", "solution": "import numpy as np\n\nclass AdaptiveDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.7\n        self.learning_rate = 0.01\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, lb, ub):\n        self.population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def mutate(self, idx, lb, ub):\n        idxs = [i for i in range(self.population_size) if i != idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        dynamic_factor = np.random.rand() * (1.2 - self.mutation_factor) + self.mutation_factor  # Modified scaling factor\n        convergence_factor = 1 - np.std(self.population) / (np.ptp(self.population) + 1e-9)\n        diversity_factor = np.tanh(np.std(self.population))\n        mutant = a + dynamic_factor * (b - c) + 0.1 * convergence_factor * (np.mean(self.population, axis=0) - a) + 0.05 * diversity_factor\n        return np.clip(mutant, lb, ub)\n\n    def crossover(self, target, mutant):\n        self.crossover_rate = 0.5 + 0.5 * (np.std(self.population) / np.mean(np.abs(self.population)))\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(crossover_mask):\n            crossover_mask[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover_mask, mutant, target)\n        return trial\n\n    def local_search(self, candidate, bounds):\n        step_size = self.learning_rate * 0.003 * (bounds.ub - bounds.lb)  # Modified step size\n        perturbation = np.random.uniform(-step_size, step_size, self.dim)\n        new_candidate = candidate + perturbation\n        return np.clip(new_candidate, bounds.lb, bounds.ub)\n\n    def adaptive_learning_rate(self):\n        self.learning_rate = 0.01 * (1 - self.func_evals / self.budget)  # Adaptive learning rate\n\n    def update_population(self, new_population, bounds):\n        diversity_threshold = 0.15 * self.dim  # Increased diversity threshold\n        if np.std(new_population) < diversity_threshold:\n            self.initialize_population(bounds.lb, bounds.ub)\n        else:\n            self.learning_rate *= 1.01\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.initialize_population(bounds.lb, bounds.ub)\n        best_solution = None\n        best_fitness = np.inf\n\n        while self.func_evals < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                self.adaptive_learning_rate()  # Integrate adaptive learning rate\n                target = self.population[i]\n                mutant = self.mutate(i, bounds.lb, bounds.ub)\n                trial = self.crossover(target, mutant)\n                trial = self.local_search(trial, bounds)\n\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < best_fitness:\n                    best_fitness = trial_fitness\n                    best_solution = trial\n\n                if trial_fitness < func(target):\n                    new_population.append(trial)\n                else:\n                    new_population.append(target)\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            self.update_population(new_population, bounds)  # Corrected method signature\n            self.population = np.array(new_population)\n\n        return best_solution", "name": "AdaptiveDifferentialEvolution", "description": "Enhanced Adaptive Differential Evolution with optimized mutation factor scaling and improved diversity threshold for robust convergence and performance.", "configspace": "", "generation": 99, "fitness": 0.7963935110647192, "feedback": "The algorithm AdaptiveDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.796 with standard deviation 0.027. And the mean value of best solutions found was 0.159 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "825a27f5-4e9f-4e53-abe2-b2d2f544ec87", "metadata": {"aucs": [0.765028357153512, 0.7941205430706981, 0.8300316329699478], "final_y": [0.1699395498360159, 0.15919915879134094, 0.14673676861604124]}, "mutation_prompt": null}
