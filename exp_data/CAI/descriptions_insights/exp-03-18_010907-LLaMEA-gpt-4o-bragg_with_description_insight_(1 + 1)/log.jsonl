{"id": "23906e7b-4e69-429d-a8b8-bbde0495cb93", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F = 0.8  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        # Symmetric initialization with a periodic pattern\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        # Run a global optimization using a modified Differential Evolution\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            for i in range(self.population_size):\n                # Select three distinct individuals\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                \n                # Mutation\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                \n                # Crossover\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n                \n                # Encourage periodicity\n                trial = self.enforce_periodicity(trial)\n                \n                # Selection\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                \n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                \n                if evaluations >= self.global_budget:\n                    break\n\n        # Use local optimization to refine the best solution\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution):\n        # Encourage periodicity by averaging layers and repeating\n        period_length = 2\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "The algorithm combines a modified Differential Evolution with local search and periodicity encouragement to optimize multi-layered photonic structures.", "configspace": "", "generation": 0, "fitness": 0.9151797204670725, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.915 with standard deviation 0.008. And the mean value of best solutions found was 0.173 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": null, "metadata": {"aucs": [0.9208737060635168, 0.9205396836841901, 0.9041257716535105], "final_y": [0.172772890295943, 0.17277293429818075, 0.17277318015165732]}, "mutation_prompt": null}
{"id": "14c46374-c474-4243-9ecd-3637c1e367e4", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F = 0.8  # Differential weight\n        self.CR_min = 0.2  # Minimum crossover probability\n        self.CR_max = 0.9  # Maximum crossover probability\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * (1 - evaluations / self.global_budget)\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        period_length = max(2, int((1 - progress) * self.dim / 4))\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Enhanced DE algorithm integrating adaptive crossover rates and dynamic period enforcement to boost exploration and solution refinement in multilayer photonic optimization.", "configspace": "", "generation": 1, "fitness": 0.9218260226312062, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.922 with standard deviation 0.010. And the mean value of best solutions found was 0.173 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "23906e7b-4e69-429d-a8b8-bbde0495cb93", "metadata": {"aucs": [0.9354999836777633, 0.9174395855601786, 0.9125384986556768], "final_y": [0.17277286866476793, 0.17277287153636234, 0.17277286870566844]}, "mutation_prompt": null}
{"id": "9a32a993-fa79-4e34-a09b-f6df859e2443", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, int(budget / 50))  # Adaptive population size\n        self.F = 0.8\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.3)  # Increased local search emphasis\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * (1 - evaluations / self.global_budget)\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        period_length = max(2, int((1 - progress) * self.dim / 4))\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Enhanced DE algorithm with adaptive population size and increased local search emphasis for optimized exploration and exploitation balance in photonic structure design.", "configspace": "", "generation": 2, "fitness": 0.8738666473426181, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.874 with standard deviation 0.029. And the mean value of best solutions found was 0.179 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "14c46374-c474-4243-9ecd-3637c1e367e4", "metadata": {"aucs": [0.8713844997459805, 0.8402160336079828, 0.9099994086738906], "final_y": [0.17936481774757862, 0.17711937493371643, 0.179270825335077]}, "mutation_prompt": null}
{"id": "617ed7e8-33f2-4501-bf70-8167da31082e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F = 0.8  # Differential weight\n        self.CR_min = 0.2  # Minimum crossover probability\n        self.CR_max = 0.9  # Maximum crossover probability\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * (1 - evaluations / self.global_budget)\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n            if evaluations % (self.global_budget // 10) == 0:  # Adaptive population size\n                self.population_size = min(self.population_size + 2, 40)\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        period_length = max(2, int((1 - progress**0.5) * self.dim / 4))  # Refined periodic enforcement\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Enhanced DE with adaptive population size and refined periodic enforcement to improve convergence in photonic optimization.", "configspace": "", "generation": 3, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 21 is out of bounds for axis 0 with size 20').", "error": "IndexError('index 21 is out of bounds for axis 0 with size 20')", "parent_id": "14c46374-c474-4243-9ecd-3637c1e367e4", "metadata": {}, "mutation_prompt": null}
{"id": "1d644c68-632f-4f6d-94de-3a36b76ed86e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5  # New minimum differential weight\n        self.F_max = 0.9  # New maximum differential weight\n        self.CR_min = 0.2  # Minimum crossover probability\n        self.CR_max = 0.9  # Maximum crossover probability\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * (1 - evaluations / self.global_budget)\n            F = self.F_min + (self.F_max - self.F_min) * (evaluations / self.global_budget)  # Dynamic adjustment of F\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3)\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        period_length = max(2, int((1 - progress) * self.dim / 4))\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Enhances the algorithm by dynamically adjusting the differential weight (F) based on optimization progress, aiming for improved exploration and convergence.", "configspace": "", "generation": 4, "fitness": 0.953123004637165, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.953 with standard deviation 0.005. And the mean value of best solutions found was 0.173 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "14c46374-c474-4243-9ecd-3637c1e367e4", "metadata": {"aucs": [0.9596347489262879, 0.9463132968163928, 0.9534209681688144], "final_y": [0.17279621430208392, 0.17277307783512774, 0.17277607719701138]}, "mutation_prompt": null}
{"id": "0222e109-a6fc-4123-baa6-aa0c446b3b83", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.3  # Adjusted minimum crossover probability\n        self.CR_max = 0.95  # Adjusted maximum crossover probability\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * (1 - evaluations / self.global_budget)\n            F = self.F_min + (self.F_max - self.F_min) * (evaluations / self.global_budget)\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3)\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                else:  # Hill-climbing step\n                    small_step = 0.01 * (bounds.ub - bounds.lb)\n                    new_trial = np.clip(trial + np.random.uniform(-small_step, small_step, self.dim), bounds.lb, bounds.ub)\n                    new_score = func(new_trial)\n                    evaluations += 1\n                    if new_score < func(self.population[i]):\n                        self.population[i] = new_trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        period_length = max(2, int((1 - progress) * self.dim / 4))\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Integrates a hill-climbing approach with adaptive mutation and crossover to enhance convergence in reflective multilayer optimization.", "configspace": "", "generation": 5, "fitness": 0.9175047917983158, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.918 with standard deviation 0.012. And the mean value of best solutions found was 0.172 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "1d644c68-632f-4f6d-94de-3a36b76ed86e", "metadata": {"aucs": [0.9163834031131571, 0.9037473019739692, 0.9323836703078211], "final_y": [0.17144179354993017, 0.17165532328389088, 0.17180476562426494]}, "mutation_prompt": null}
{"id": "29974722-d665-4420-9749-e3cc0eaacb6c", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * (1 - evaluations / self.global_budget)\n            F = self.F_min + (self.F_max - self.F_min) * (evaluations / self.global_budget)\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3)\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        period_length = max(2, int((1 - progress) * self.dim / 6))  # Adjusted period length calculation\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Improved the algorithm by enhancing periodicity enforcement to better exploit constructive interference in multilayered structures.", "configspace": "", "generation": 6, "fitness": 0.953123004637165, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.953 with standard deviation 0.005. And the mean value of best solutions found was 0.173 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "1d644c68-632f-4f6d-94de-3a36b76ed86e", "metadata": {"aucs": [0.9596347489262879, 0.9463132968163928, 0.9534209681688144], "final_y": [0.17279621430208392, 0.17277307783512774, 0.17277607719701138]}, "mutation_prompt": null}
{"id": "66013750-18fb-451c-a6c1-c2822cf4a4ad", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * (1 - evaluations / self.global_budget)\n            F = self.F_min + (self.F_max - self.F_min) * (evaluations / self.global_budget)\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                if np.random.rand() < 0.5:  # Hybrid mutation strategy\n                    mutant = x1 + F * (x2 - x3)\n                else:\n                    mutant = x1 + F * (best_solution - x1) + F * (x2 - x3)\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        period_length = max(2, int((1 - progress) * self.dim / 6))  # Adjusted for adaptive periodicity\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Enhances the differential evolution by incorporating hybrid mutation strategies and adaptive periodicity enforcement to balance exploration and exploitation.", "configspace": "", "generation": 7, "fitness": -Infinity, "feedback": "An exception occurred: TypeError(\"unsupported operand type(s) for -: 'NoneType' and 'float'\").", "error": "TypeError(\"unsupported operand type(s) for -: 'NoneType' and 'float'\")", "parent_id": "1d644c68-632f-4f6d-94de-3a36b76ed86e", "metadata": {}, "mutation_prompt": null}
{"id": "463b10fe-2375-4a11-a724-0bd505e6d359", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5  # New minimum differential weight\n        self.F_max = 0.9  # New maximum differential weight\n        self.CR_min = 0.2  # Minimum crossover probability\n        self.CR_max = 0.9  # Maximum crossover probability\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * (evaluations / self.global_budget)  # Dynamic increase of CR\n            F = self.F_min + (self.F_max - self.F_min) * (evaluations / self.global_budget)  # Dynamic adjustment of F\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3)\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        period_length = max(2, int((1 - progress) * self.dim / 4))\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Introduce a gradual increase in crossover probability for better exploration early in the optimization process.", "configspace": "", "generation": 8, "fitness": 0.9467697021366055, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.947 with standard deviation 0.004. And the mean value of best solutions found was 0.173 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "1d644c68-632f-4f6d-94de-3a36b76ed86e", "metadata": {"aucs": [0.9439928084310594, 0.9433027187268107, 0.9530135792519465], "final_y": [0.1728071494471618, 0.17277740983001444, 0.17277288676839941]}, "mutation_prompt": null}
{"id": "937e189b-89aa-4a4c-b3b1-c1eaa3e9cdfb", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5  # New minimum differential weight\n        self.F_max = 0.9  # New maximum differential weight\n        self.CR_min = 0.2  # Minimum crossover probability\n        self.CR_max = 0.9  # Maximum crossover probability\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population  # Quasi-oppositional initialization\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * (1 - evaluations / self.global_budget)\n            F = self.F_min + (self.F_max - self.F_min) * (evaluations / self.global_budget)\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3)\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        period_length = max(1, int((1 - progress) * self.dim / 3))  # Enhance periodic enforcement\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Integrates quasi-oppositional initialization and enhances periodicity enforcement to improve exploration and solution quality.", "configspace": "", "generation": 9, "fitness": 0.9621001109377506, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.962 with standard deviation 0.006. And the mean value of best solutions found was 0.167 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "1d644c68-632f-4f6d-94de-3a36b76ed86e", "metadata": {"aucs": [0.9701334111154754, 0.9583592425900763, 0.9578076791077001], "final_y": [0.16617942287424736, 0.1661219590423535, 0.1684587535288221]}, "mutation_prompt": null}
{"id": "29f257ea-1a43-4afe-8875-e502ee13e4e9", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * (1 - evaluations / self.global_budget)\n            F = self.F_min + (self.F_max - self.F_min) * (evaluations / self.global_budget)\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, 0.05, size=self.dim)  # Adaptive perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        period_length = max(1, int((1 - progress) * self.dim / 4))  # Dynamic periodicity adjustment\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Enhances diversity by introducing adaptive perturbations and dynamic periodicity adjustments to improve convergence and solution quality.", "configspace": "", "generation": 10, "fitness": 0.9673484311490554, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.967 with standard deviation 0.003. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "937e189b-89aa-4a4c-b3b1-c1eaa3e9cdfb", "metadata": {"aucs": [0.966390084462718, 0.9719408328020337, 0.9637143761824145], "final_y": [0.16535566535654744, 0.16536776748671966, 0.16540749807198996]}, "mutation_prompt": null}
{"id": "8ae091b0-8920-486c-8e2f-9b487e48829b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * (1 - evaluations / self.global_budget)\n            F = self.F_min + (self.F_max - self.F_min) * (evaluations / self.global_budget)\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, 0.02, size=self.dim)  # Refined perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        period_length = max(1, int((1 - progress) * self.dim / 4))\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Enhances diversity and convergence by incorporating adaptive rate strategies and refined perturbation within a strict modification limit.", "configspace": "", "generation": 11, "fitness": 0.9672193742688266, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.967 with standard deviation 0.004. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "29f257ea-1a43-4afe-8875-e502ee13e4e9", "metadata": {"aucs": [0.9666715926847104, 0.9721955653014477, 0.9627909648203219], "final_y": [0.1654713353331595, 0.16508894645414396, 0.16604633682482484]}, "mutation_prompt": null}
{"id": "665298e3-d7d7-4125-9670-2e4cd0dbd10f", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * (1 - evaluations / self.global_budget)\n            F = self.F_min + (self.F_max - self.F_min) * (evaluations / self.global_budget) * np.sin(np.pi * evaluations / self.global_budget)\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, 0.05, size=self.dim)  # Adaptive perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        period_length = max(1, int((1 - progress) * self.dim / 4))  # Dynamic periodicity adjustment\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Enhances diversity and convergence by incorporating adaptive periodicity and differential amplitude scaling.", "configspace": "", "generation": 12, "fitness": 0.9637967894228653, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.964 with standard deviation 0.005. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "29f257ea-1a43-4afe-8875-e502ee13e4e9", "metadata": {"aucs": [0.9674016116975392, 0.9677990020996091, 0.9561897544714477], "final_y": [0.16562644417761396, 0.1667313567083084, 0.16520608214149957]}, "mutation_prompt": null}
{"id": "b2be82ae-9664-4e1a-ac52-584f5233dc82", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n        self.layer_weights = np.ones(dim) / dim  # Added line for adaptive layer weights\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * (1 - evaluations / self.global_budget)\n            F = self.F_min + (self.F_max - self.F_min) * (evaluations / self.global_budget)\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                # Modified line to include layer weights in mutation\n                mutant = x1 + F * (x2 - x3) * self.layer_weights + np.random.normal(0, 0.05, size=self.dim)\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                    self.layer_weights = 1 / (1 + np.abs(trial - best_solution))  # Update weights based on performance\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        period_length = max(1, int((1 - progress) * self.dim / 4))  # Dynamic periodicity adjustment\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Introduces adaptive layer weight adjustments leveraging recent performance to enhance convergence rate and solution quality.", "configspace": "", "generation": 13, "fitness": 0.9641390701229442, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.964 with standard deviation 0.007. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "29f257ea-1a43-4afe-8875-e502ee13e4e9", "metadata": {"aucs": [0.9663553091878258, 0.9719422291840905, 0.9541196719969165], "final_y": [0.16535566535654744, 0.16536776748671966, 0.16537680493004792]}, "mutation_prompt": null}
{"id": "566b89f4-1be7-4a4c-8db3-376707bdc667", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()  # Adaptive CR\n            F = self.F_min + (self.F_max - self.F_min) * (evaluations / self.global_budget)\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, 0.05, size=self.dim)  # Adaptive perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        period_length = max(1, int((1 - progress) * self.dim / 4))  # Dynamic periodicity adjustment\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Utilize adaptive crossover probabilities to improve convergence by fostering diversity in trial solutions.", "configspace": "", "generation": 14, "fitness": 0.9690142308669262, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.969 with standard deviation 0.007. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "29f257ea-1a43-4afe-8875-e502ee13e4e9", "metadata": {"aucs": [0.9675923389787674, 0.9780658963591704, 0.9613844572628406], "final_y": [0.16528343930965383, 0.16567124120813814, 0.16520163181182024]}, "mutation_prompt": null}
{"id": "5734821a-8063-459c-bfd1-1659d8c3a8f3", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()  # Adaptive CR\n            F = self.F_min + (self.F_max - self.F_min) * (evaluations / self.global_budget)\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, 0.05, size=self.dim)  # Adaptive perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        period_length = max(1, int((1 - np.sin(progress * np.pi / 2)) * self.dim / 4))  # Sinusoidal periodicity adjustment\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Enhance periodic enforcement by adjusting segment length based on a sinusoidal function of progress, promoting better convergence.", "configspace": "", "generation": 15, "fitness": 0.9732862699094192, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.973 with standard deviation 0.007. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "566b89f4-1be7-4a4c-8db3-376707bdc667", "metadata": {"aucs": [0.9716945001967456, 0.9827714913164872, 0.965392818215025], "final_y": [0.16510269643713116, 0.16510667072215135, 0.16498118136982598]}, "mutation_prompt": null}
{"id": "6e827875-8a6b-4fd4-afb0-b508f01fa28e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()  # Adaptive CR\n            F = self.F_min + (self.F_max - self.F_min) * (evaluations / self.global_budget)\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                perturbation = np.std(self.population[i]) * 0.05  # Adjust perturbation based on solution variance\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, perturbation, size=self.dim)\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        period_length = max(1, int((1 - np.sin(progress * np.pi / 2)) * self.dim / 4))  # Sinusoidal periodicity adjustment\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Enhance periodicity enforcement by dynamically adjusting perturbation based on solution variance for better convergence.", "configspace": "", "generation": 16, "fitness": 0.973245596231748, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.973 with standard deviation 0.007. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "5734821a-8063-459c-bfd1-1659d8c3a8f3", "metadata": {"aucs": [0.9682197181338391, 0.9837431951513816, 0.9677738754100235], "final_y": [0.16496036568875527, 0.16504523054358988, 0.1650436029783704]}, "mutation_prompt": null}
{"id": "a8d628fb-4090-4bf9-ac26-343e7289abe2", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()  # Adaptive CR\n            F = self.F_min + (self.F_max - self.F_min) * (evaluations / self.global_budget)\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, 0.05, size=self.dim)  # Adaptive perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        period_length = max(1, int((1 - np.tan(progress * np.pi / 4)) * self.dim / 4))  # Tangent periodicity adjustment\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Strengthen periodic enforcement by adjusting segment length based on a tangent function of progress for enhanced convergence.", "configspace": "", "generation": 17, "fitness": 0.9654851375958975, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.965 with standard deviation 0.008. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "5734821a-8063-459c-bfd1-1659d8c3a8f3", "metadata": {"aucs": [0.9628950610319633, 0.9761056485898361, 0.9574547031658931], "final_y": [0.16598772204986312, 0.16517753507127908, 0.1655522577615659]}, "mutation_prompt": null}
{"id": "9f44d99a-9e65-480d-b82e-e0a126c5631e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()  # Adaptive CR\n            F = self.F_min + (self.F_max - self.F_min) * (np.std(self.population)/np.ptp(bounds.ub-bounds.lb))  # Adaptive F\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, 0.05, size=self.dim)  # Adaptive perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        period_length = max(1, int((1 - np.sin(progress * np.pi / 2)) * self.dim / 4))  # Sinusoidal periodicity adjustment\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Improve solution diversity and convergence by adjusting the mutation factor F to incorporate adaptive scaling based on the population's spread.", "configspace": "", "generation": 18, "fitness": 0.7399122711683024, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.740 with standard deviation 0.077. And the mean value of best solutions found was 0.254 (0. is the best) with standard deviation 0.040.", "error": "", "parent_id": "5734821a-8063-459c-bfd1-1659d8c3a8f3", "metadata": {"aucs": [0.6732159163090168, 0.8474233863484002, 0.6990975108474902], "final_y": [0.28462513859667404, 0.19816582561357854, 0.2799228774287934]}, "mutation_prompt": null}
{"id": "f04dc698-6f63-4b58-bde1-19aa87fb5176", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()  # Adaptive CR\n            F = self.F_min + (self.F_max - self.F_min) * (evaluations / self.global_budget)\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, 0.05, size=self.dim)  # Adaptive perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        period_length = max(1, int((1 - np.cos(progress * np.pi / 2)) * self.dim / 4))  # Cosine periodicity adjustment\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Fine-tune the sinusoidal periodicity adjustment by altering the progression function to a cosine to potentially enhance convergence.", "configspace": "", "generation": 19, "fitness": 0.8404025747186608, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.840 with standard deviation 0.038. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "5734821a-8063-459c-bfd1-1659d8c3a8f3", "metadata": {"aucs": [0.8756261611600841, 0.78777931739586, 0.857802245600038], "final_y": [0.16828304157011365, 0.17508658176056802, 0.1700559609258625]}, "mutation_prompt": null}
{"id": "17c08a71-1b86-4d06-9a37-9cba867b8071", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()  # Adaptive CR\n            F = self.F_min + (self.F_max - self.F_min) * (evaluations / self.global_budget)\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, 0.05, size=self.dim)  # Adaptive perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.5 + 0.5 * np.cos(progress * np.pi / 2)  # Dynamic scaling introduced\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2)) * self.dim / 4))  # Adjusted for dynamic scaling\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Introduce dynamic scaling in the sinusoidal function to enhance periodic enforcement, promoting better adaptability and convergence.", "configspace": "", "generation": 20, "fitness": 0.9737613933193391, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.974 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "5734821a-8063-459c-bfd1-1659d8c3a8f3", "metadata": {"aucs": [0.9723902431928693, 0.9841916399805922, 0.9647022967845561], "final_y": [0.1649872684863799, 0.16494971134217784, 0.16494015818163343]}, "mutation_prompt": null}
{"id": "d299820e-a380-40b3-9f0c-9b64bcc7a5f6", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()  # Adaptive CR\n            F = self.F_min + (self.F_max - self.F_min) * (evaluations / self.global_budget)\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, 0.05, size=self.dim)  # Adaptive perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        # Introduce stochastic perturbation to L-BFGS-B\n        perturbation = np.random.normal(0, 0.01, size=self.dim)\n        perturbed_solution = np.clip(best_solution + perturbation, bounds.lb, bounds.ub)\n        result = minimize(func, perturbed_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.5 + 0.5 * np.cos(progress * np.pi / 2)  # Dynamic scaling introduced\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2)) * self.dim / 4))  # Adjusted for dynamic scaling\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Introduce stochastic perturbation to the L-BFGS-B local search to enhance solution diversity and escape local minima.", "configspace": "", "generation": 21, "fitness": 0.9737613933193391, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.974 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "17c08a71-1b86-4d06-9a37-9cba867b8071", "metadata": {"aucs": [0.9723902431928693, 0.9841916399805922, 0.9647022967845561], "final_y": [0.1649872684863799, 0.16494971134217784, 0.16494015818163343]}, "mutation_prompt": null}
{"id": "6b6aaf76-f9f0-49e1-b606-741a4f1bcc39", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()  # Adaptive CR\n            F = self.F_min + (self.F_max - self.F_min) * (evaluations / self.global_budget)\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, 0.05, size=self.dim)  # Adaptive perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.5 + 0.5 * np.sin(progress * np.pi)  # Dynamic scaling adjusted for enhanced periodicity\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2)) * self.dim / 4))  # Adjusted for dynamic scaling\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Enhance periodicity by adjusting the dynamic scaling function to improve solution quality and convergence.", "configspace": "", "generation": 22, "fitness": 0.9709082799877212, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.971 with standard deviation 0.007. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "17c08a71-1b86-4d06-9a37-9cba867b8071", "metadata": {"aucs": [0.9695535974727375, 0.9806273191101531, 0.9625439233802732], "final_y": [0.16530343072262466, 0.16523847455319296, 0.16505777036908242]}, "mutation_prompt": null}
{"id": "4f37a51b-339c-4deb-ab9c-6a14150ac96c", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()  # Adaptive CR\n            F = self.F_min + (self.F_max - self.F_min) * (evaluations / self.global_budget)\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, 0.05, size=self.dim)  # Adaptive perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j] + np.random.normal(0, 0.01)  # Added adaptive noise\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.5 + 0.5 * np.cos(progress * np.pi / 2)  # Dynamic scaling introduced\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2)) * self.dim / 4))  # Adjusted for dynamic scaling\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Introduce a small adaptive noise factor in trial vector generation to enhance exploration and escape local minima.", "configspace": "", "generation": 23, "fitness": 0.963847986003903, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.964 with standard deviation 0.006. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "17c08a71-1b86-4d06-9a37-9cba867b8071", "metadata": {"aucs": [0.967418331399249, 0.9557476827760323, 0.9683779438364278], "final_y": [0.16495555565197428, 0.1650128298173591, 0.1650558044380116]}, "mutation_prompt": null}
{"id": "71c08e2f-7471-455d-94f9-b3974585175e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()  # Adaptive CR\n            F = self.F_min + (self.F_max - self.F_min) * (evaluations / self.global_budget)\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, 0.05, size=self.dim)  # Adaptive perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.5 + 0.5 * np.cos(progress * np.pi / 2)  # Dynamic scaling introduced\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2)) * self.dim / 4 + 0.5))  # Adjusted step size\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Enhance periodic enforcement by dynamically adjusting step size in 'enforce_periodicity'.", "configspace": "", "generation": 24, "fitness": 0.9668422735046146, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.967 with standard deviation 0.005. And the mean value of best solutions found was 0.167 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "17c08a71-1b86-4d06-9a37-9cba867b8071", "metadata": {"aucs": [0.9616118712807906, 0.9731109638327679, 0.9658039854002849], "final_y": [0.16737054488475644, 0.16761040694758, 0.16662421330609978]}, "mutation_prompt": null}
{"id": "81041d73-c4ce-4403-8038-a95f75582cd1", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()  # Adaptive CR\n            F = self.F_min + (self.F_max - self.F_min) * (evaluations / self.global_budget) * 1.05  # Slightly increased F\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, 0.05, size=self.dim)  # Adaptive perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.5 + 0.5 * np.cos(progress * np.pi / 2)  # Dynamic scaling introduced\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2)) * self.dim / 4))  # Adjusted for dynamic scaling\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Introduce dynamic scaling in the sinusoidal function to enhance periodic enforcement and fine-tune perturbation strength for convergence.", "configspace": "", "generation": 25, "fitness": 0.9742279925441517, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.974 with standard deviation 0.007. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "17c08a71-1b86-4d06-9a37-9cba867b8071", "metadata": {"aucs": [0.9735847241414455, 0.9832595614980347, 0.9658396919929749], "final_y": [0.16498052079875103, 0.16512063452075376, 0.16499258685582285]}, "mutation_prompt": null}
{"id": "b7e639b5-7aa1-47e9-b2ed-d756b68699ee", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()  # Adaptive CR\n            F = self.F_min + (self.F_max - self.F_min) * (evaluations / self.global_budget) * 0.95  # Adjusted scaling factor\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, 0.05, size=self.dim)  # Adaptive perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.5 + 0.5 * np.cos(progress * np.pi / 2)  # Dynamic scaling introduced\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2)) * self.dim / 4))  # Adjusted for dynamic scaling\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Refine dynamic scaling in perturbation strength to enhance convergence rate by slightly modifying mutation strategy.", "configspace": "", "generation": 26, "fitness": 0.9734159830105297, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.973 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "81041d73-c4ce-4403-8038-a95f75582cd1", "metadata": {"aucs": [0.9728026208231021, 0.983016331252712, 0.964428996955775], "final_y": [0.16508537435907267, 0.16516196691721396, 0.1650971490086267]}, "mutation_prompt": null}
{"id": "7e7e48a3-99ce-4f01-ba54-195395b933fe", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()  # Adaptive CR\n            F = self.F_min + (self.F_max - self.F_min) * (evaluations / self.global_budget) * 1.05  # Slightly increased F\n            perturbation_variance = 0.05 * (1 - evaluations / self.global_budget)  # Dynamically adjust perturbation\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, perturbation_variance, size=self.dim)  # Adaptive perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.5 + 0.5 * np.cos(progress * np.pi / 2)  # Dynamic scaling introduced\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2)) * self.dim / 4))  # Adjusted for dynamic scaling\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Enhance convergence by dynamically adjusting the perturbation variance in the DE mutation based on progress.", "configspace": "", "generation": 27, "fitness": 0.9743456279203434, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.974 with standard deviation 0.007. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "81041d73-c4ce-4403-8038-a95f75582cd1", "metadata": {"aucs": [0.9733594167450762, 0.9835790127766106, 0.9660984542393438], "final_y": [0.16492249625455913, 0.16508683083186682, 0.16495328544640586]}, "mutation_prompt": null}
{"id": "c1ad5577-c4f1-466a-b142-5cc818891d82", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()  # Adaptive CR\n            F = self.F_min + (self.F_max - self.F_min) * (evaluations / self.global_budget) * 1.05  # Slightly increased F\n            perturbation_variance = 0.05 * (1 - evaluations / self.global_budget)  # Dynamically adjust perturbation\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, perturbation_variance, size=self.dim)  # Adaptive perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.45 + 0.55 * np.cos(progress * np.pi / 2)  # Slightly adjusted dynamic scaling\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2)) * self.dim / 4))  # Adjusted for dynamic scaling\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Slightly adjust the scale_factor in the enforce_periodicity method to enhance the periodicity enforcement.", "configspace": "", "generation": 28, "fitness": 0.9743456279203434, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.974 with standard deviation 0.007. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "7e7e48a3-99ce-4f01-ba54-195395b933fe", "metadata": {"aucs": [0.9733594167450762, 0.9835790127766106, 0.9660984542393438], "final_y": [0.16492249625455913, 0.16508683083186682, 0.16495328544640586]}, "mutation_prompt": null}
{"id": "7a974bff-bb70-43e0-b158-76a4e92e4e69", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()  # Adaptive CR\n            F = self.F_min + (self.F_max - self.F_min) * (evaluations / self.global_budget) * 1.08  # Slightly increased F\n            perturbation_variance = 0.05 * (1 - evaluations / self.global_budget)  # Dynamically adjust perturbation\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, perturbation_variance, size=self.dim)  # Adaptive perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.5 + 0.5 * np.cos(progress * np.pi / 2)  # Dynamic scaling introduced\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2)) * self.dim / 4))  # Adjusted for dynamic scaling\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Enhance convergence by dynamically adjusting both perturbation variance and differential weight in the DE mutation based on progress.", "configspace": "", "generation": 29, "fitness": 0.9729258647231952, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.973 with standard deviation 0.007. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "7e7e48a3-99ce-4f01-ba54-195395b933fe", "metadata": {"aucs": [0.969940092520675, 0.9823439980682945, 0.966493503580616], "final_y": [0.16521366494364675, 0.1652021027451248, 0.1650020609986036]}, "mutation_prompt": null}
{"id": "b0a004c6-b5cd-4904-ba4d-24614b84863c", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()  # Adaptive CR\n            F = self.F_min + (self.F_max - self.F_min) * (evaluations / self.global_budget) * 1.05  # Slightly increased F\n            perturbation_variance = 0.05 * np.sqrt(1 - (evaluations / self.global_budget))  # Smoother transition\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, perturbation_variance, size=self.dim)  # Adaptive perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.5 + 0.5 * np.cos(progress * np.pi / 2)  # Dynamic scaling introduced\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2)) * self.dim / 4))  # Adjusted for dynamic scaling\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Enhance convergence by adopting a smoother transition for perturbation variance to stabilize mutation strength.", "configspace": "", "generation": 30, "fitness": 0.9738647106431455, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.974 with standard deviation 0.007. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "7e7e48a3-99ce-4f01-ba54-195395b933fe", "metadata": {"aucs": [0.9724662728712918, 0.9830315788830662, 0.9660962801750785], "final_y": [0.16504788130709414, 0.16520772894537195, 0.164963006138644]}, "mutation_prompt": null}
{"id": "ce5aed4e-0b74-4b5f-81ac-8d08bfe583c1", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n        self.momentum_factor = 0.1  # Introduce momentum factor\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n        momentum_vector = np.zeros(self.dim)  # Initialize momentum vector\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()  # Adaptive CR\n            F = self.F_min + (self.F_max - self.F_min) * (evaluations / self.global_budget) * 1.05  # Slightly increased F\n            perturbation_variance = 0.05 * (1 - evaluations / self.global_budget)  # Dynamically adjust perturbation\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, perturbation_variance, size=self.dim)  # Adaptive perturbation\n                mutant = mutant + self.momentum_factor * momentum_vector  # Apply momentum\n                momentum_vector = mutant - x1  # Update momentum vector\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.5 + 0.5 * np.cos(progress * np.pi / 2)  # Dynamic scaling introduced\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2)) * self.dim / 4))  # Adjusted for dynamic scaling\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Enhance convergence by introducing momentum to the DE mutation vector to balance exploration and exploitation.", "configspace": "", "generation": 31, "fitness": 0.9717408465816663, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.972 with standard deviation 0.003. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "7e7e48a3-99ce-4f01-ba54-195395b933fe", "metadata": {"aucs": [0.9687420346664575, 0.9756893332124807, 0.9707911718660606], "final_y": [0.16505462194004628, 0.16494812688485017, 0.16493052218981374]}, "mutation_prompt": null}
{"id": "15ccb50f-dd6f-4942-9858-507c03a6955f", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()  # Adaptive CR\n            F = self.F_min + (self.F_max - self.F_min) * (evaluations / self.global_budget) * 1.05  # Slightly increased F\n            perturbation_variance = 0.055 * (1 - evaluations / self.global_budget)  # Increased perturbation variance\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, perturbation_variance, size=self.dim)  # Adaptive perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.5 + 0.5 * np.cos(progress * np.pi / 2)  # Dynamic scaling introduced\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2)) * self.dim / 4))  # Adjusted for dynamic scaling\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Improve exploration by slightly increasing the diversity of mutation vectors in Differential Evolution.", "configspace": "", "generation": 32, "fitness": 0.9741710624649187, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.974 with standard deviation 0.007. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "7e7e48a3-99ce-4f01-ba54-195395b933fe", "metadata": {"aucs": [0.9732579561600966, 0.9831482756707578, 0.9661069555639018], "final_y": [0.16489882495793395, 0.1650895035372263, 0.16492979124957907]}, "mutation_prompt": null}
{"id": "15b428e8-c9fe-4bca-a404-92c53f469a83", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()  # Adaptive CR\n            F = self.F_min + (self.F_max - self.F_min) * (evaluations / self.global_budget) * 1.15  # Slightly increased F\n            perturbation_variance = 0.05 * (1 - evaluations / self.global_budget)  # Dynamically adjust perturbation\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, perturbation_variance, size=self.dim)  # Adaptive perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.5 + 0.5 * np.cos(progress * np.pi / 2)  # Dynamic scaling introduced\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2)) * self.dim / 4))  # Adjusted for dynamic scaling\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Improve exploration by slightly increasing the differential weight F in the DE mutation formula.", "configspace": "", "generation": 33, "fitness": 0.9735362501846709, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.974 with standard deviation 0.007. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "7e7e48a3-99ce-4f01-ba54-195395b933fe", "metadata": {"aucs": [0.9717911763205467, 0.9833870538950774, 0.9654305203383889], "final_y": [0.16523164324614237, 0.16512410555962798, 0.16498313191953728]}, "mutation_prompt": null}
{"id": "92d76b4b-9cce-4fbe-acb9-1fb5ab271fd5", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()  # Adaptive CR\n            F = self.F_min + (self.F_max - self.F_min) * (evaluations / self.global_budget) * 1.05  # Slightly increased F\n            perturbation_variance = 0.1 * (1 - evaluations / self.global_budget)  # Increased perturbation variance\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, perturbation_variance, size=self.dim)  # Adaptive perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.5 + 0.5 * np.cos(progress * np.pi / 2)  # Dynamic scaling introduced\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2)) * self.dim / 4))  # Adjusted for dynamic scaling\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Enhance convergence by increasing perturbation variance in DE mutation based on progress and solution diversity.", "configspace": "", "generation": 34, "fitness": 0.973623724590411, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.974 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "7e7e48a3-99ce-4f01-ba54-195395b933fe", "metadata": {"aucs": [0.9710682824240502, 0.9840465975240466, 0.9657562938231362], "final_y": [0.1651573082646256, 0.16517786040325688, 0.16498123095276207]}, "mutation_prompt": null}
{"id": "7b50311e-5e35-4b93-b4fc-14c6274b5fa1", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()  # Adaptive CR\n            F = self.F_min + (self.F_max - self.F_min) * (evaluations / self.global_budget) * 1.05  # Slightly increased F\n            perturbation_variance = 0.05 * (1 - evaluations / self.global_budget)  # Dynamically adjust perturbation\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, perturbation_variance, size=self.dim)  # Adaptive perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                j_rand = np.random.randint(0, self.dim)  # Ensure at least one element is from mutant\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == j_rand:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.5 + 0.5 * np.cos(progress * np.pi / 2)  # Dynamic scaling introduced\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2)) * self.dim / 4))  # Adjusted for dynamic scaling\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Improve convergence by optimizing trial vector generation with a more robust crossover mechanism.", "configspace": "", "generation": 35, "fitness": 0.9705446266124361, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.971 with standard deviation 0.007. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "7e7e48a3-99ce-4f01-ba54-195395b933fe", "metadata": {"aucs": [0.9780013754522061, 0.9714857876044635, 0.962146716780639], "final_y": [0.1652303917852862, 0.16501543903608895, 0.16505478045066146]}, "mutation_prompt": null}
{"id": "a8993d9a-4f88-465b-96be-77d267a1e81a", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()  # Adaptive CR\n            F = self.F_min + (self.F_max - self.F_min) * (evaluations / self.global_budget) * 1.05  # Slightly increased F\n            perturbation_variance = 0.03 * (1 - evaluations / self.global_budget)  # Faster reduction of perturbation variance\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, perturbation_variance, size=self.dim)  # Adaptive perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.5 + 0.5 * np.cos(progress * np.pi / 2)  # Dynamic scaling introduced\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2)) * self.dim / 6))  # Refined period length adaptation\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Enhance convergence further by reducing the perturbation variance dynamically at a faster rate and refining the period length adaptation.", "configspace": "", "generation": 36, "fitness": 0.8400986351916065, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.840 with standard deviation 0.032. And the mean value of best solutions found was 0.172 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "7e7e48a3-99ce-4f01-ba54-195395b933fe", "metadata": {"aucs": [0.8632195936141681, 0.7948345984893792, 0.8622417134712724], "final_y": [0.17412722503358924, 0.17113190061385197, 0.17068881895379306]}, "mutation_prompt": null}
{"id": "dfb814cd-aa28-4c2c-a784-8f0fe91ae441", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()  # Adaptive CR\n            F = self.F_min + (self.F_max - self.F_min) * (0.5 - 0.5 * np.cos(evaluations / self.global_budget * np.pi))  # Dynamic F scaling\n            perturbation_variance = 0.05 * (1 - evaluations / self.global_budget)  # Dynamically adjust perturbation\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, perturbation_variance, size=self.dim)  # Adaptive perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.5 + 0.5 * np.cos(progress * np.pi / 2)  # Dynamic scaling introduced\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2)) * self.dim / 4))  # Adjusted for dynamic scaling\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Introduce dynamic F scaling based on cosine function for better exploration and exploitation balance.", "configspace": "", "generation": 37, "fitness": 0.973461404966546, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.973 with standard deviation 0.006. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "7e7e48a3-99ce-4f01-ba54-195395b933fe", "metadata": {"aucs": [0.9728587571878577, 0.9815802125468455, 0.9659452451649347], "final_y": [0.16501672755851282, 0.1650426623697373, 0.16498605792423748]}, "mutation_prompt": null}
{"id": "a85ed4b4-c442-4830-8cf4-29034cc6f8fa", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()  # Adaptive CR\n            F = self.F_min + (self.F_max - self.F_min) * (evaluations / self.global_budget) * 1.05  # Slightly increased F\n            perturbation_variance = 0.05 * (1 - evaluations / self.global_budget)  # Dynamically adjust perturbation\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, perturbation_variance, size=self.dim)  # Adaptive perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        progress = evaluations / self.global_budget\n        method = 'L-BFGS-B' if progress < 0.5 else 'TNC'  # Adaptive method choice\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method=method, options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.5 + 0.5 * np.cos(progress * np.pi / 2)  # Dynamic scaling introduced\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2)) * self.dim / 4))  # Adjusted for dynamic scaling\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Introduced adaptive local search intensity by adjusting the `method` in `minimize` based on progress.", "configspace": "", "generation": 38, "fitness": 0.9743456279203434, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.974 with standard deviation 0.007. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "7e7e48a3-99ce-4f01-ba54-195395b933fe", "metadata": {"aucs": [0.9733594167450762, 0.9835790127766106, 0.9660984542393438], "final_y": [0.16492249625455913, 0.16508683083186682, 0.16495328544640586]}, "mutation_prompt": null}
{"id": "6817587c-b99a-41b2-9535-113d73a38aa6", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()  # Adaptive CR\n            F = self.F_min + (self.F_max - self.F_min) * (evaluations / self.global_budget) * 1.05  # Slightly increased F\n            perturbation_variance = 0.05 * (1 - evaluations / self.global_budget)  # Dynamically adjust perturbation\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, perturbation_variance, size=self.dim)  # Adaptive perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.6 + 0.4 * np.cos(progress * np.pi / 2)  # Dynamic scaling introduced\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2)) * self.dim / 4))  # Adjusted for dynamic scaling\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Enhance exploitation by modifying the scale factor in enforce_periodicity to improve periodic solution alignment.", "configspace": "", "generation": 39, "fitness": 0.9744815863966559, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.974 with standard deviation 0.007. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "7e7e48a3-99ce-4f01-ba54-195395b933fe", "metadata": {"aucs": [0.9733594167450762, 0.9838214295917572, 0.9662639128531343], "final_y": [0.16492249625455913, 0.1649125281603786, 0.16492275342966367]}, "mutation_prompt": null}
{"id": "dbb6249c-1512-4668-b6ca-cf77b48b0592", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()  # Adaptive CR\n            F = self.F_min + (self.F_max - self.F_min) * (evaluations / self.global_budget) * 1.05  # Slightly increased F\n            perturbation_variance = 0.07 * (1 - evaluations / self.global_budget)  # Adjusted perturbation variance\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, perturbation_variance, size=self.dim)  # Adaptive perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.6 + 0.4 * np.cos(progress * np.pi / 2)  # Dynamic scaling introduced\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2)) * self.dim / 4))  # Adjusted for dynamic scaling\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Enhance exploitation by modifying the perturbation variance in the mutation process to better explore promising areas.", "configspace": "", "generation": 40, "fitness": 0.9742550765994058, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.974 with standard deviation 0.007. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "6817587c-b99a-41b2-9535-113d73a38aa6", "metadata": {"aucs": [0.9730138986947966, 0.983440930655305, 0.9663104004481157], "final_y": [0.1649764817702113, 0.1650530762156246, 0.16494553496816722]}, "mutation_prompt": null}
{"id": "2bdc33d4-6676-4f2a-90d9-2942716e2826", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()  # Adaptive CR\n            factor = (evaluations / self.global_budget) ** 0.5\n            F = self.F_min + (self.F_max - self.F_min) * factor  # Enhanced non-linear scaling\n            perturbation_variance = 0.05 * (1 - evaluations / self.global_budget)  # Dynamically adjust perturbation\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, perturbation_variance, size=self.dim)  # Adaptive perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.6 + 0.4 * np.cos(progress * np.pi / 2)  # Dynamic scaling introduced\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2)) * self.dim / 4))  # Adjusted for dynamic scaling\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Enhanced mutation step by introducing a dynamic non-linear scaling.", "configspace": "", "generation": 41, "fitness": 0.9748917268825945, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.975 with standard deviation 0.007. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "6817587c-b99a-41b2-9535-113d73a38aa6", "metadata": {"aucs": [0.9732683305525245, 0.9841546665740757, 0.9672521835211831], "final_y": [0.16499926012749644, 0.1650318032955933, 0.1651382405265721]}, "mutation_prompt": null}
{"id": "3fa91f3a-a19a-4e55-b706-0f12a5f3ec85", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()  # Adaptive CR\n            factor = (evaluations / self.global_budget) ** 0.5\n            F = self.F_min + (self.F_max - self.F_min) * factor * (1 - best_score)  # Refined scaling\n            perturbation_variance = 0.05 * (1 - evaluations / self.global_budget)  # Dynamically adjust perturbation\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, perturbation_variance, size=self.dim)  # Adaptive perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.6 + 0.4 * np.cos(progress * np.pi / 2)  # Dynamic scaling introduced\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2)) * self.dim / 4))  # Adjusted for dynamic scaling\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Refined exploration by introducing an adaptive mutation factor based on current best solution proximity.", "configspace": "", "generation": 42, "fitness": 0.9646048063616192, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.965 with standard deviation 0.006. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "2bdc33d4-6676-4f2a-90d9-2942716e2826", "metadata": {"aucs": [0.9626399339341405, 0.9730832257254869, 0.95809125942523], "final_y": [0.16496311905016592, 0.16522741414353204, 0.1653705560705997]}, "mutation_prompt": null}
{"id": "18445262-af70-4fed-9fb7-632797366cf6", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()  # Adaptive CR\n            factor = (evaluations / self.global_budget) ** 0.5\n            F = self.F_min + (self.F_max - self.F_min) * factor  # Enhanced non-linear scaling\n            perturbation_variance = 0.05 * (1 - evaluations / self.global_budget) * np.std(self.population)  # Enhanced perturbation\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, perturbation_variance, size=self.dim)  # Adaptive perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.6 + 0.4 * np.cos(progress * np.pi / 2)  # Dynamic scaling introduced\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2)) * self.dim / 4))  # Adjusted for dynamic scaling\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Introduced a diversity-preserving mechanism and enhanced perturbation strategy for improved exploration.", "configspace": "", "generation": 43, "fitness": 0.9740368689035875, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.974 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "2bdc33d4-6676-4f2a-90d9-2942716e2826", "metadata": {"aucs": [0.9733886015536903, 0.9842857611224104, 0.9644362440346617], "final_y": [0.16501434438060048, 0.16514440145794607, 0.16538212631470406]}, "mutation_prompt": null}
{"id": "7923209f-1b1b-40e1-9a15-589066c5fed1", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()  # Adaptive CR\n            factor = (evaluations / self.global_budget) ** 0.5\n            F = self.F_min + (self.F_max - self.F_min) * (np.sin(factor * np.pi / 2))  # Enhanced non-linear scaling\n            perturbation_variance = 0.05 * (1 - evaluations / self.global_budget)  # Dynamically adjust perturbation\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, perturbation_variance, size=self.dim)  # Adaptive perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.6 + 0.4 * np.cos(progress * np.pi / 2)  # Dynamic scaling introduced\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2)) * self.dim / 4))  # Adjusted for dynamic scaling\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Enhanced dynamic non-linear scaling by introducing a sine-based adjustment for better convergence rate.", "configspace": "", "generation": 44, "fitness": 0.9727323544559937, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.973 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "2bdc33d4-6676-4f2a-90d9-2942716e2826", "metadata": {"aucs": [0.9727016415297187, 0.9828361905514311, 0.9626592312868312], "final_y": [0.16507707867348353, 0.16533846656176054, 0.165387911855852]}, "mutation_prompt": null}
{"id": "9a5d63c3-f07b-4cb7-9710-76378255223e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()  # Adaptive CR\n            factor = (evaluations / self.global_budget) ** 0.5\n            F = self.F_min + (self.F_max - self.F_min) * factor  # Enhanced non-linear scaling\n            perturbation_variance = 0.05 * (1 - evaluations / self.global_budget)  # Dynamically adjust perturbation\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, perturbation_variance, size=self.dim)  # Adaptive perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.6 + 0.4 * np.cos(progress * np.pi / 2)  # Dynamic scaling introduced\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2)) * self.dim / 4))  # Adjusted for dynamic scaling\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Enhanced periodicity enforcement by introducing adaptive period length and alignment with progress.", "configspace": "", "generation": 45, "fitness": 0.9748917268825945, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.975 with standard deviation 0.007. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "2bdc33d4-6676-4f2a-90d9-2942716e2826", "metadata": {"aucs": [0.9732683305525245, 0.9841546665740757, 0.9672521835211831], "final_y": [0.16499926012749644, 0.1650318032955933, 0.1651382405265721]}, "mutation_prompt": null}
{"id": "e7fa3f53-a601-460d-9440-3df25a75d549", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()  # Adaptive CR\n            factor = (1 - np.exp(-evaluations / self.global_budget))  # Exponential function for mutation scaling\n            F = self.F_min + (self.F_max - self.F_min) * factor\n            perturbation_variance = 0.05 * (1 - evaluations / self.global_budget)  # Dynamically adjust perturbation\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, perturbation_variance, size=self.dim)  # Adaptive perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.6 + 0.4 * np.cos(progress * np.pi / 2)  # Dynamic scaling introduced\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2)) * self.dim / 4))  # Adjusted for dynamic scaling\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Fine-tuned mutation scaling using an exponential function for improved convergence.", "configspace": "", "generation": 46, "fitness": 0.9737758107504324, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.974 with standard deviation 0.007. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "2bdc33d4-6676-4f2a-90d9-2942716e2826", "metadata": {"aucs": [0.97264112416752, 0.9834590099000806, 0.9652272981836965], "final_y": [0.16499631807872595, 0.16498383980573694, 0.16500967039511072]}, "mutation_prompt": null}
{"id": "a7656fed-55ec-4704-90e3-c0ae969447b8", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()  # Adaptive CR\n            factor = (evaluations / self.global_budget) ** 0.5\n            F = self.F_min + (self.F_max - self.F_min) * factor  # Enhanced non-linear scaling\n            perturbation_variance = 0.05 * (1 - evaluations / self.global_budget)  # Dynamically adjust perturbation\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, perturbation_variance, size=self.dim)  # Adaptive perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.6 + 0.4 * np.cos(progress * np.pi / 2)  # Dynamic scaling introduced\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2)) * self.dim / 4))  # Adjusted for dynamic scaling\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                weighted_avg_value = (0.7 * avg_value + 0.3 * solution[start])  # Introduced weighted average\n                solution[start:end] = weighted_avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Introduced a weighted average in periodicity enforcement to enhance solution consistency.", "configspace": "", "generation": 47, "fitness": 0.9673209199119318, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.967 with standard deviation 0.006. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "2bdc33d4-6676-4f2a-90d9-2942716e2826", "metadata": {"aucs": [0.9755972819490613, 0.9615599673570224, 0.9648055104297117], "final_y": [0.16504555873665905, 0.16499469410353018, 0.16501709068507475]}, "mutation_prompt": null}
{"id": "d80dbe35-d1f4-4490-8abb-cb9c74c2ba0a", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()  # Adaptive CR\n            factor = (evaluations / self.global_budget) ** 0.5\n            F = self.F_min + (self.F_max - self.F_min) * factor  # Enhanced non-linear scaling\n            perturbation_variance = 0.05 * (1 - evaluations / self.global_budget)  # Dynamically adjust perturbation\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, perturbation_variance, size=self.dim)  # Adaptive perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.6 + 0.4 * np.cos(progress * np.pi / 2)  # Dynamic scaling introduced\n        phase_shift = 0.5 * np.sin(progress * np.pi)  # Dynamic phase shift for periodicity\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2 + phase_shift)) * self.dim / 4))  # Adjusted for dynamic scaling\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Introduced periodic mutation by dynamically altering the periodicity's phase to enhance solution diversity.", "configspace": "", "generation": 48, "fitness": 0.9752264516495274, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.975 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "2bdc33d4-6676-4f2a-90d9-2942716e2826", "metadata": {"aucs": [0.9750287031774827, 0.9853618299530236, 0.9652888218180757], "final_y": [0.16512962507411044, 0.16507404711692908, 0.16523952096978467]}, "mutation_prompt": null}
{"id": "50c499a0-3047-4bce-bd5e-756f43c0c63c", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()  # Adaptive CR\n            factor = (evaluations / self.global_budget) ** 0.5\n            F = self.F_min + (self.F_max - self.F_min) * np.sin(factor * np.pi)  # Enhanced non-linear scaling\n            perturbation_variance = 0.05 * (1 - evaluations / self.global_budget)  # Dynamically adjust perturbation\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, perturbation_variance, size=self.dim)  # Adaptive perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.6 + 0.4 * np.cos(progress * np.pi / 2)  # Dynamic scaling introduced\n        phase_shift = 0.5 * np.sin(progress * np.pi)  # Dynamic phase shift for periodicity\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2 + phase_shift)) * self.dim / 4))  # Adjusted for dynamic scaling\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Enhanced exploration by introducing a dynamic scaling factor based on the sine function for adaptive mutation.", "configspace": "", "generation": 49, "fitness": 0.9671419297841726, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.967 with standard deviation 0.011. And the mean value of best solutions found was 0.167 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "d80dbe35-d1f4-4490-8abb-cb9c74c2ba0a", "metadata": {"aucs": [0.9706572087876959, 0.9789811198375701, 0.9517874607272518], "final_y": [0.16543094428942529, 0.16591005998039643, 0.16985168413033636]}, "mutation_prompt": null}
{"id": "2bdbf817-ce56-4640-b304-256ebdb8338f", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()  # Adaptive CR\n            factor = (evaluations / self.global_budget) ** 0.5\n            F = self.F_min + (self.F_max - self.F_min) * factor  # Enhanced non-linear scaling\n            perturbation_variance = 0.05 * (1 - evaluations / self.global_budget)  # Dynamically adjust perturbation\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, perturbation_variance, size=self.dim)  # Adaptive perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.6 + 0.4 * np.cos(progress * np.pi / 2)  # Dynamic scaling introduced\n        phase_shift = 0.7 * np.sin(progress * np.pi)  # More pronounced dynamic phase shift for periodicity\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2 + phase_shift)) * self.dim / 4))  # Adjusted for dynamic scaling\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Introduced a more pronounced dynamic phase shift to enhance periodicity and avoid local minima.", "configspace": "", "generation": 50, "fitness": 0.9722402520300254, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.972 with standard deviation 0.010. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "d80dbe35-d1f4-4490-8abb-cb9c74c2ba0a", "metadata": {"aucs": [0.9721131325681663, 0.9843084557623408, 0.960299167759569], "final_y": [0.16506460567242653, 0.16496003674624882, 0.16584436021204219]}, "mutation_prompt": null}
{"id": "44c90438-0305-4757-bb93-292c90f874f1", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()  # Adaptive CR\n            factor = (evaluations / self.global_budget) ** 0.5\n            F = self.F_min + (self.F_max - self.F_min) * factor  # Enhanced non-linear scaling\n            perturbation_variance = 0.05 * np.exp(-evaluations / self.global_budget)  # Refined perturbation variance decay\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, perturbation_variance, size=self.dim)  # Adaptive perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.6 + 0.4 * np.cos(progress * np.pi / 2)  # Dynamic scaling introduced\n        phase_shift = 0.5 * np.sin(progress * np.pi)  # Dynamic phase shift for periodicity\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2 + phase_shift)) * self.dim / 4))  # Adjusted for dynamic scaling\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Introduced refined perturbation variance decay for better convergence balance between exploration and exploitation.", "configspace": "", "generation": 51, "fitness": 0.9753521550688439, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.975 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "d80dbe35-d1f4-4490-8abb-cb9c74c2ba0a", "metadata": {"aucs": [0.9750321417547652, 0.9857290686248323, 0.9652952548269341], "final_y": [0.16512681337936652, 0.16507690050272206, 0.1652879065056363]}, "mutation_prompt": null}
{"id": "92810052-350d-4120-8a5d-24a2792ee555", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()  # Adaptive CR\n            factor = (evaluations / self.global_budget) ** 0.5\n            F = self.F_min + (self.F_max - self.F_min) * factor  # Enhanced non-linear scaling\n            perturbation_variance = 0.05 * np.exp(-evaluations**1.1 / self.global_budget)  # Refined perturbation variance decay\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, perturbation_variance, size=self.dim)  # Adaptive perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.6 + 0.4 * np.cos(progress * np.pi / 2)  # Dynamic scaling introduced\n        phase_shift = 0.5 * np.sin(progress * np.pi)  # Dynamic phase shift for periodicity\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2 + phase_shift)) * self.dim / 4))  # Adjusted for dynamic scaling\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Introduced strategic perturbation decay tuning for enhanced exploration-exploitation balance.", "configspace": "", "generation": 52, "fitness": 0.9751747404191073, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.975 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "44c90438-0305-4757-bb93-292c90f874f1", "metadata": {"aucs": [0.9749806299438752, 0.9852692129474301, 0.9652743783660167], "final_y": [0.1652240309479821, 0.16524546062091372, 0.16524554174060224]}, "mutation_prompt": null}
{"id": "4493ea44-79e6-4254-b47b-8598380c4b68", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()  # Adaptive CR\n            factor = (evaluations / self.global_budget) ** 0.5\n            F = self.F_min + (self.F_max - self.F_min) * factor  # Enhanced non-linear scaling\n            perturbation_variance = 0.05 * np.exp(-evaluations / self.global_budget)  # Refined perturbation variance decay\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, perturbation_variance, size=self.dim)  # Adaptive perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.6 + 0.4 * np.cos(progress * np.pi / 2)  # Dynamic scaling introduced\n        phase_shift = 0.5 * np.sin(progress * np.pi)  # Dynamic phase shift for periodicity\n        skew_factor = 0.3 * np.cos(progress * np.pi)  # Skew factor for block alignment\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2 + phase_shift + skew_factor)) * self.dim / 4))  # Adjusted for dynamic scaling\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Improved periodicity enforcement by introducing a skew factor for dynamic periodic block alignment.", "configspace": "", "generation": 53, "fitness": 0.7875247029047876, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.788 with standard deviation 0.025. And the mean value of best solutions found was 0.191 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "44c90438-0305-4757-bb93-292c90f874f1", "metadata": {"aucs": [0.7936384672713963, 0.8145828899040963, 0.7543527515388702], "final_y": [0.1972947819134656, 0.17177191410544257, 0.20496801605129933]}, "mutation_prompt": null}
{"id": "4dc63e9b-889d-495e-bb99-d6fde822f080", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * (1 - evaluations / self.global_budget)  # Dynamic CR update\n            factor = (evaluations / self.global_budget) ** 0.5\n            F = self.F_min + (self.F_max - self.F_min) * factor  # Enhanced non-linear scaling\n            perturbation_variance = 0.05 * np.exp(-evaluations / self.global_budget)  # Refined perturbation variance decay\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, perturbation_variance, size=self.dim)  # Adaptive perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.6 + 0.4 * np.cos(progress * np.pi / 2)  # Dynamic scaling introduced\n        phase_shift = 0.5 * np.sin(progress * np.pi)  # Dynamic phase shift for periodicity\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2 + phase_shift)) * self.dim / 4))  # Adjusted for dynamic scaling\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Improved PhotonicOptimizer by dynamically adjusting crossover rates to enhance convergence.", "configspace": "", "generation": 54, "fitness": 0.9644727522479478, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.964 with standard deviation 0.012. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "44c90438-0305-4757-bb93-292c90f874f1", "metadata": {"aucs": [0.9700903162043322, 0.9753145390713187, 0.9480134014681929], "final_y": [0.16544816471724844, 0.1649817349452043, 0.1657598958968436]}, "mutation_prompt": null}
{"id": "c7a8de8d-fab4-4da4-8b16-0700f6905887", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.25)  # Changed from 0.2 to 0.25\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()  # Adaptive CR\n            factor = (evaluations / self.global_budget) ** 0.5\n            F = self.F_min + (self.F_max - self.F_min) * factor  # Enhanced non-linear scaling\n            perturbation_variance = 0.05 * np.exp(-evaluations / self.global_budget)  # Refined perturbation variance decay\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, perturbation_variance, size=self.dim)  # Adaptive perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.6 + 0.4 * np.cos(progress * np.pi / 2)  # Dynamic scaling introduced\n        phase_shift = 0.5 * np.sin(progress * np.pi)  # Dynamic phase shift for periodicity\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2 + phase_shift)) * self.dim / 5))  # Changed from /4 to /5\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Enhanced local search by increasing local budget and refined periodicity enforcement for better modular characteristics.", "configspace": "", "generation": 55, "fitness": 0.7822413883107644, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.782 with standard deviation 0.032. And the mean value of best solutions found was 0.200 (0. is the best) with standard deviation 0.016.", "error": "", "parent_id": "44c90438-0305-4757-bb93-292c90f874f1", "metadata": {"aucs": [0.7969339756925116, 0.811481105100016, 0.7383090841397655], "final_y": [0.18966154826323567, 0.18896875973048854, 0.2223415141543159]}, "mutation_prompt": null}
{"id": "d29482a2-b190-4654-b57c-7b41bec9f1fa", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()  # Adaptive CR\n            factor = (evaluations / self.global_budget) ** 0.5\n            F = self.F_min + (self.F_max - self.F_min) * factor * (0.8 + 0.2 * np.sin(evaluations * np.pi / self.global_budget))  # Dynamic scaling adjustment\n            perturbation_variance = 0.05 * np.exp(-evaluations / self.global_budget)  # Refined perturbation variance decay\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, perturbation_variance, size=self.dim)  # Adaptive perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.6 + 0.4 * np.cos(progress * np.pi / 2)  # Dynamic scaling introduced\n        phase_shift = 0.5 * np.sin(progress * np.pi)  # Dynamic phase shift for periodicity\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2 + phase_shift)) * self.dim / 4))  # Adjusted for dynamic scaling\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Enhanced exploration by adding dynamic adaptation of scaling factor in Differential Evolution.", "configspace": "", "generation": 56, "fitness": 0.9726881511269637, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.973 with standard deviation 0.009. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "44c90438-0305-4757-bb93-292c90f874f1", "metadata": {"aucs": [0.9734691531347228, 0.9837680010623653, 0.9608272991838029], "final_y": [0.16517516253537579, 0.16547061477221248, 0.16579798543145396]}, "mutation_prompt": null}
{"id": "76aa66ee-0fae-4c8f-86dd-f7dfef902b13", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()  # Adaptive CR\n            factor = (evaluations / self.global_budget) ** 0.5\n            F = self.F_min + (self.F_max - self.F_min) * factor  # Enhanced non-linear scaling\n            perturbation_variance = 0.05 * np.exp(-evaluations / self.global_budget)  # Refined perturbation variance decay\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, perturbation_variance, size=self.dim)  # Adaptive perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                mutation_probability = np.cos(evaluations / self.global_budget * np.pi / 2)  # Dynamic mutation probability\n                for j in range(self.dim):\n                    if np.random.rand() < (CR * mutation_probability):  # Adjusted condition with dynamic factor\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.6 + 0.4 * np.cos(progress * np.pi / 2)  # Dynamic scaling introduced\n        phase_shift = 0.5 * np.sin(progress * np.pi)  # Dynamic phase shift for periodicity\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2 + phase_shift)) * self.dim / 4))  # Adjusted for dynamic scaling\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Introduced dynamic adaptive mutation probability to enhance exploration during early stages, improving convergence.", "configspace": "", "generation": 57, "fitness": 0.9736489207847051, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.974 with standard deviation 0.011. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "44c90438-0305-4757-bb93-292c90f874f1", "metadata": {"aucs": [0.9757325837154199, 0.9855372553425569, 0.9596769232961385], "final_y": [0.1651510861658292, 0.16523513223334008, 0.16566800728625186]}, "mutation_prompt": null}
{"id": "7aaa6e45-0eba-41d0-a420-e582453aa70c", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()  # Adaptive CR\n            factor = (evaluations / self.global_budget) ** 0.5\n            F = self.F_min + (self.F_max - self.F_min) * factor  # Enhanced non-linear scaling\n            perturbation_variance = 0.05 * np.exp(-evaluations / self.global_budget)  # Refined perturbation variance decay\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, perturbation_variance, size=self.dim)  # Adaptive perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.6 + 0.4 * np.cos(progress * np.pi / 2)  # Dynamic scaling introduced\n        phase_shift = 0.5 * np.sin(progress * np.pi)  # Dynamic phase shift for periodicity\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2 + phase_shift)) * self.dim / 4))  # Adjusted for dynamic scaling\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Enhanced population initialization with opposition-based learning for better diversity and exploration.", "configspace": "", "generation": 58, "fitness": 0.9753521550688439, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.975 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "44c90438-0305-4757-bb93-292c90f874f1", "metadata": {"aucs": [0.9750321417547652, 0.9857290686248323, 0.9652952548269341], "final_y": [0.16512681337936652, 0.16507690050272206, 0.1652879065056363]}, "mutation_prompt": null}
{"id": "fd7a4ab1-6924-42c7-9b1c-53d839bf68ec", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()  # Adaptive CR\n            factor = (evaluations / self.global_budget) ** 0.5\n            F = self.F_min + (self.F_max - self.F_min) * factor  # Enhanced non-linear scaling\n            perturbation_variance = 0.05 * np.exp(-evaluations / self.global_budget)  # Refined perturbation variance decay\n            self.population_size = max(10, int(20 * (1 - factor)))  # Adaptive population resizing\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, perturbation_variance, size=self.dim)  # Adaptive perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.6 + 0.4 * np.cos(progress * np.pi / 2)  # Dynamic scaling introduced\n        phase_shift = 0.5 * np.sin(progress * np.pi)  # Dynamic phase shift for periodicity\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2 + phase_shift)) * self.dim / 4))  # Adjusted for dynamic scaling\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Introduced adaptive population resize strategy for enhanced convergence by dynamically adjusting based on progress.", "configspace": "", "generation": 59, "fitness": 0.9756653589625014, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.976 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "44c90438-0305-4757-bb93-292c90f874f1", "metadata": {"aucs": [0.974217591642498, 0.9862289166660969, 0.9665495685789092], "final_y": [0.1648628510851443, 0.1648660004447331, 0.16493833992680496]}, "mutation_prompt": null}
{"id": "0bcff77b-d40d-4e15-9dfe-32492824ceec", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()  # Adaptive CR\n            factor = (evaluations / self.global_budget) ** 1.2  # Enhanced non-linear scaling\n            F = self.F_min + (self.F_max - self.F_min) * factor  # Enhanced non-linear scaling\n            perturbation_variance = 0.05 * np.exp(-evaluations / self.global_budget)  # Refined perturbation variance decay\n            self.population_size = max(10, int(20 * (1 - factor)))  # Adaptive population resizing\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, perturbation_variance, size=self.dim)  # Adaptive perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.6 + 0.4 * np.cos(progress * np.pi / 2)  # Dynamic scaling introduced\n        phase_shift = 0.5 * np.sin(progress * np.pi)  # Dynamic phase shift for periodicity\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2 + phase_shift)) * self.dim / 4))  # Adjusted for dynamic scaling\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Enhanced nonlinear scaling factor to improve exploration and exploitation balance.", "configspace": "", "generation": 60, "fitness": 0.9762509592893288, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.976 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "fd7a4ab1-6924-42c7-9b1c-53d839bf68ec", "metadata": {"aucs": [0.9694462148521051, 0.9875200158491275, 0.9717866471667538], "final_y": [0.16487866048429922, 0.16485934872719132, 0.1649027416912563]}, "mutation_prompt": null}
{"id": "00bf7ed4-6230-4bb3-b220-a9eb30ed2075", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * (1 - evaluations / self.global_budget)  # Adaptive CR\n            factor = (evaluations / self.global_budget) ** 1.2  # Enhanced non-linear scaling\n            F = self.F_min + (self.F_max - self.F_min) * factor  # Enhanced non-linear scaling\n            perturbation_variance = 0.05 * np.exp(-evaluations / self.global_budget)  # Refined perturbation variance decay\n            self.population_size = max(10, int(20 * (1 - factor)))  # Adaptive population resizing\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, perturbation_variance, size=self.dim)  # Adaptive perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget, 'ftol': 1e-9})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.6 + 0.4 * np.cos(progress * np.pi / 2)  # Dynamic scaling introduced\n        phase_shift = 0.5 * np.sin(progress * np.pi)  # Dynamic phase shift for periodicity\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2 + phase_shift)) * self.dim / 4))  # Adjusted for dynamic scaling\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Introduced adaptive crossover probability and enhanced local search strategy for improved convergence.", "configspace": "", "generation": 61, "fitness": 0.975065840006458, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.975 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0bcff77b-d40d-4e15-9dfe-32492824ceec", "metadata": {"aucs": [0.9795618716606806, 0.9816084159845725, 0.9640272323741209], "final_y": [0.16486939179848725, 0.16488001446754053, 0.16489177927651055]}, "mutation_prompt": null}
{"id": "c18de750-f51b-4fb1-b462-bd01a1d3f280", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.3)  # Adjusted local budget\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()  # Adaptive CR\n            factor = (evaluations / self.global_budget) ** 1.2  # Enhanced non-linear scaling\n            F = self.F_min + (self.F_max - self.F_min) * factor  # Enhanced non-linear scaling\n            perturbation_variance = 0.05 * np.exp(-evaluations / self.global_budget)  # Refined perturbation variance decay\n            self.population_size = max(10, int(20 * (1 - factor)))  # Adaptive population resizing\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, perturbation_variance, size=self.dim)  # Adaptive perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.6 + 0.4 * np.cos(progress * np.pi / 2)  # Dynamic scaling introduced\n        phase_shift = 0.5 * np.sin(progress * np.pi)  # Dynamic phase shift for periodicity\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2 + phase_shift + 0.1)) * self.dim / 4))  # Fine-tuned for increased adaptability\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Refined local search integration and periodicity enhancement for improved convergence in black box optimization.", "configspace": "", "generation": 62, "fitness": 0.9666486980518018, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.967 with standard deviation 0.012. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0bcff77b-d40d-4e15-9dfe-32492824ceec", "metadata": {"aucs": [0.9535202942653812, 0.9824313607961462, 0.9639944390938776], "final_y": [0.16488407856168297, 0.16490481092193798, 0.16488406640500453]}, "mutation_prompt": null}
{"id": "e18d3a38-6b00-4b41-a4ed-513d9eecdda3", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.sin(evaluations * np.pi / (2 * self.global_budget))  # Dynamic CR adaptation\n            factor = (evaluations / self.global_budget) ** 1.2  # Enhanced non-linear scaling\n            F = self.F_min + (self.F_max - self.F_min) * factor  # Enhanced non-linear scaling\n            perturbation_variance = 0.05 * np.exp(-evaluations / self.global_budget)  # Refined perturbation variance decay\n            self.population_size = max(10, int(20 * (1 - factor)))  # Adaptive population resizing\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, perturbation_variance, size=self.dim)  # Adaptive perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.6 + 0.4 * np.cos(progress * np.pi / 2)  # Dynamic scaling introduced\n        phase_shift = 0.5 * np.sin(progress * np.pi)  # Dynamic phase shift for periodicity\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2 + phase_shift)) * self.dim / 4))  # Adjusted for dynamic scaling\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Introduced dynamic crossover rate adaptation based on evaluation progress to enhance solution diversity.", "configspace": "", "generation": 63, "fitness": 0.9629921788746953, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.963 with standard deviation 0.006. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0bcff77b-d40d-4e15-9dfe-32492824ceec", "metadata": {"aucs": [0.9718778743026164, 0.9576366076692674, 0.9594620546522021], "final_y": [0.16491240886838565, 0.16488176209861305, 0.16508880202587806]}, "mutation_prompt": null}
{"id": "ccb8c738-5ea7-4a01-8cdb-f78cd597753a", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()  # Adaptive CR\n            factor = (evaluations / self.global_budget) ** 1.15  # Enhanced non-linear scaling, adjusted exponent\n            F = self.F_min + (self.F_max - self.F_min) * factor  # Enhanced non-linear scaling\n            perturbation_variance = 0.05 * np.exp(-evaluations / self.global_budget)  # Refined perturbation variance decay\n            self.population_size = max(10, int(20 * (1 - factor)))  # Adaptive population resizing\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, perturbation_variance, size=self.dim)  # Adaptive perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.65 + 0.35 * np.cos(progress * np.pi / 2)  # Adjusted dynamic scaling\n        phase_shift = 0.5 * np.sin(progress * np.pi)  # Dynamic phase shift for periodicity\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2 + phase_shift)) * self.dim / 4))  # Adjusted for dynamic scaling\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Enhanced adaptive scaling and periodicity alignment for improved optimization performance.", "configspace": "", "generation": 64, "fitness": 0.9754293357472937, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.975 with standard deviation 0.009. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0bcff77b-d40d-4e15-9dfe-32492824ceec", "metadata": {"aucs": [0.9678264225973755, 0.988035109412449, 0.9704264752320569], "final_y": [0.1648705472583566, 0.16486458274042382, 0.16487075315843902]}, "mutation_prompt": null}
{"id": "c215bf51-574a-4229-9424-3d3691694a15", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()  # Adaptive CR\n            factor = 1 / (1 + np.exp(-10 * (evaluations / self.global_budget - 0.5)))  # Logistic-based scaling\n            F = self.F_min + (self.F_max - self.F_min) * factor  # Enhanced non-linear scaling\n            perturbation_variance = 0.05 * np.exp(-evaluations / self.global_budget)  # Refined perturbation variance decay\n            self.population_size = max(10, int(20 * (1 - factor)))  # Adaptive population resizing\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, perturbation_variance, size=self.dim)  # Adaptive perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.6 + 0.4 * np.cos(progress * np.pi / 2)  # Dynamic scaling introduced\n        phase_shift = 0.5 * np.sin(progress * np.pi)  # Dynamic phase shift for periodicity\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2 + phase_shift)) * self.dim / 4))  # Adjusted for dynamic scaling\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Introducing a logistic-based adaptive scaling factor to enhance convergence speed and solution accuracy.", "configspace": "", "generation": 65, "fitness": 0.9706658001721445, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.971 with standard deviation 0.004. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0bcff77b-d40d-4e15-9dfe-32492824ceec", "metadata": {"aucs": [0.9737423664905613, 0.9730455084279481, 0.9652095255979241], "final_y": [0.16489306189704644, 0.16495515972101782, 0.1648952109414873]}, "mutation_prompt": null}
{"id": "58161ec5-d4e9-4fd1-a489-c8fe72b5eaa5", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()  # Adaptive CR\n            factor = (evaluations / self.global_budget) ** 1.2  # Enhanced non-linear scaling\n            F = self.F_min + (self.F_max - self.F_min) * factor  # Enhanced non-linear scaling\n            perturbation_variance = 0.05 * np.exp(-evaluations / self.global_budget)  # Refined perturbation variance decay\n            self.population_size = max(10, int(20 * (1 - factor)))  # Adaptive population resizing\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, perturbation_variance, size=self.dim)  # Adaptive perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.6 + 0.4 * np.cos(progress * np.pi / 2)  # Dynamic scaling introduced\n        phase_shift = 0.5 * np.sin(2 * progress * np.pi)  # Adjusted phase shift dynamics\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2 + phase_shift)) * self.dim / 4))  # Adjusted for dynamic scaling\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Improved periodicity enforcement by adjusting phase shift dynamics. ", "configspace": "", "generation": 66, "fitness": 0.9726927277636682, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.973 with standard deviation 0.011. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0bcff77b-d40d-4e15-9dfe-32492824ceec", "metadata": {"aucs": [0.9599717193634865, 0.9860047876282733, 0.972101676299245], "final_y": [0.1649099291646915, 0.1648846838805188, 0.1648603419920156]}, "mutation_prompt": null}
{"id": "e559e0dc-dfd3-452d-a5a0-6426d0c580a8", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()  # Adaptive CR\n            factor = (evaluations / self.global_budget) ** 1.2  # Enhanced non-linear scaling\n            F = self.F_min + (self.F_max - self.F_min) * factor  # Enhanced non-linear scaling\n            perturbation_variance = 0.05 * np.exp(-evaluations / self.global_budget)  # Refined perturbation variance decay\n            self.population_size = max(10, int(20 * (1 - factor)))  # Adaptive population resizing\n            if evaluations % 10 == 0:  # Added periodic selection pressure\n                self.population = self.population[np.argsort([func(ind) for ind in self.population])]\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, perturbation_variance, size=self.dim)  # Adaptive perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.6 + 0.4 * np.cos(progress * np.pi)  # Adjusted dynamic scaling\n        phase_shift = 0.5 * np.sin(progress * np.pi)  # Dynamic phase shift for periodicity\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2 + phase_shift)) * self.dim / 4))  # Adjusted for dynamic scaling\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Introduced periodic selection pressure and enhanced dynamic scaling for improved solution quality.", "configspace": "", "generation": 67, "fitness": 0.9689883926022462, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.969 with standard deviation 0.004. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0bcff77b-d40d-4e15-9dfe-32492824ceec", "metadata": {"aucs": [0.9716614736884388, 0.9725875944857759, 0.9627161096325241], "final_y": [0.1648637025820856, 0.16486557210087815, 0.16487248930233267]}, "mutation_prompt": null}
{"id": "a4e9e5cd-a1e7-4e1a-b954-c70621f5f451", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()  # Adaptive CR\n            factor = (evaluations / self.global_budget) ** 1.2  # Enhanced non-linear scaling\n            F = self.F_min + (self.F_max - self.F_min) * factor  # Enhanced non-linear scaling\n            perturbation_variance = 0.05 * np.exp(-evaluations / self.global_budget)  # Refined perturbation variance decay\n            self.population_size = max(10, int(20 * (1 - factor)))  # Adaptive population resizing\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = sorted(self.population[indices], key=lambda x: func(x))[:3]  # Prioritize best individuals\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, perturbation_variance, size=self.dim)  # Adaptive perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.6 + 0.4 * np.cos(progress * np.pi / 2)  # Dynamic scaling introduced\n        phase_shift = 0.5 * np.sin(progress * np.pi)  # Dynamic phase shift for periodicity\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2 + phase_shift)) * self.dim / 4))  # Adjusted for dynamic scaling\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Enhance convergence by refining trial vector selection to prioritize best individuals.", "configspace": "", "generation": 68, "fitness": 0.9594124961985339, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.959 with standard deviation 0.005. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0bcff77b-d40d-4e15-9dfe-32492824ceec", "metadata": {"aucs": [0.9579950937398376, 0.9537954090163815, 0.9664469858393827], "final_y": [0.16539794328564483, 0.16510150447338734, 0.1649558200582889]}, "mutation_prompt": null}
{"id": "2bcfe1d4-450e-4879-885d-96b61b38cc24", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()  # Adaptive CR\n            factor = (evaluations / self.global_budget) ** 1.2  # Enhanced non-linear scaling\n            F = self.F_min + (self.F_max - self.F_min) * factor  # Enhanced non-linear scaling\n            perturbation_variance = 0.05 * np.exp(-evaluations / self.global_budget)  # Refined perturbation variance decay\n            self.population_size = max(10, int(20 * (1 - factor)))  # Adaptive population resizing\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, perturbation_variance, size=self.dim)  # Adaptive perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.6 + 0.4 * np.cos(progress * np.pi / 2)  # Dynamic scaling introduced\n        phase_shift = 0.5 * np.sin(progress * np.pi)  # Dynamic phase shift for periodicity\n        # Enhanced periodic adjustment using Fourier basis\n        frequencies = np.fft.fftfreq(len(solution))\n        spectrum = np.fft.fft(solution)\n        spectrum[np.abs(frequencies) > 0.1 * (1 - scale_factor)] = 0  # Filter high frequencies\n        adjusted_solution = np.fft.ifft(spectrum).real\n        return adjusted_solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Refine scaling and periodicity enforcement using Fourier basis to enhance solution diversity.", "configspace": "", "generation": 69, "fitness": 0.9703707068018108, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.970 with standard deviation 0.000. And the mean value of best solutions found was 0.173 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0bcff77b-d40d-4e15-9dfe-32492824ceec", "metadata": {"aucs": [0.9702321081959645, 0.9701595878863483, 0.9707204243231196], "final_y": [0.1733185746126853, 0.17331857461267863, 0.1733185746128617]}, "mutation_prompt": null}
{"id": "e4bcba0f-c130-4396-beb0-7c29c8051eab", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()  # Adaptive CR\n            factor = (evaluations / self.global_budget) ** 1.2  # Enhanced non-linear scaling\n            F = self.F_min + (self.F_max - self.F_min) * factor  # Enhanced non-linear scaling\n            perturbation_variance = 0.05 * np.exp(-evaluations / self.global_budget)  # Refined perturbation variance decay\n            self.population_size = max(10, int(20 * (1 - factor)))  # Adaptive population resizing\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, perturbation_variance, size=self.dim)  # Adaptive perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.6 + 0.35 * np.cos(progress * np.pi / 2 + 0.1)  # Adjusted dynamic scaling\n        phase_shift = 0.55 * np.sin(progress * np.pi / 2 + 0.1)  # Adjusted phase shift for periodicity\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2 + phase_shift)) * self.dim / 4))  # Adjusted for dynamic scaling\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Improved dynamic scaling and phase shift to enhance periodicity enforcement and solution diversity.", "configspace": "", "generation": 70, "fitness": 0.976562407853573, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.977 with standard deviation 0.007. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0bcff77b-d40d-4e15-9dfe-32492824ceec", "metadata": {"aucs": [0.9694399151846339, 0.9864781064643539, 0.9737692019117308], "final_y": [0.1648776049784928, 0.1648723741176067, 0.16486149897864522]}, "mutation_prompt": null}
{"id": "4a026773-5c08-457b-be5a-af9f7a1fe5d5", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()  # Adaptive CR\n            factor = (evaluations / self.global_budget) ** 1.2 * 0.8  # Enhanced non-linear scaling, adjusted\n            F = self.F_min + (self.F_max - self.F_min) * factor  # Enhanced non-linear scaling\n            perturbation_variance = 0.05 * np.exp(-evaluations / self.global_budget)  # Refined perturbation variance decay\n            self.population_size = max(10, int(20 * (1 - factor)))  # Adaptive population resizing\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, perturbation_variance, size=self.dim)  # Adaptive perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.6 + 0.35 * np.cos(progress * np.pi / 2 + 0.1)  # Adjusted dynamic scaling\n        phase_shift = 0.55 * np.sin(progress * np.pi / 2 + 0.1)  # Adjusted phase shift for periodicity\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2 + phase_shift)) * self.dim / 4))  # Adjusted for dynamic scaling\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Enhanced adaptive mechanisms and diversity to optimize periodicity enforcement and solution exploration.", "configspace": "", "generation": 71, "fitness": 0.9755516707728966, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.976 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e4bcba0f-c130-4396-beb0-7c29c8051eab", "metadata": {"aucs": [0.9678064066641525, 0.9862547494637078, 0.9725938561908296], "final_y": [0.16488136922911012, 0.16486645633552988, 0.16486034644880643]}, "mutation_prompt": null}
{"id": "b1abd52d-5bca-461a-b392-275aaa6a4b37", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()  # Adaptive CR\n            factor = (evaluations / self.global_budget) ** 1.1  # Slightly refined non-linear scaling\n            F = self.F_min + (self.F_max - self.F_min) * factor  # Enhanced non-linear scaling\n            perturbation_variance = 0.05 * np.exp(-evaluations / self.global_budget)  # Refined perturbation variance decay\n            self.population_size = max(10, int(20 * (1 - factor)))  # Adaptive population resizing\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, perturbation_variance, size=self.dim)  # Adaptive perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.65 + 0.30 * np.cos(progress * np.pi / 2 + 0.1)  # Adjusted dynamic scaling\n        phase_shift = 0.55 * np.sin(progress * np.pi / 2 + 0.1)  # Adjusted phase shift for periodicity\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2 + phase_shift)) * self.dim / 4))  # Adjusted for dynamic scaling\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Enhanced diversity and convergence by refining scaling strategies and periodicity enforcement in differential evolution.", "configspace": "", "generation": 72, "fitness": 0.9761544200388302, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.976 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e4bcba0f-c130-4396-beb0-7c29c8051eab", "metadata": {"aucs": [0.9676674879261439, 0.9864539137834205, 0.9743418584069261], "final_y": [0.1648730482964862, 0.16486381609674483, 0.16486401321836563]}, "mutation_prompt": null}
{"id": "9c989f97-f4c4-40b6-b4fc-bbe9e286199b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()  # Adaptive CR\n            factor = (evaluations / self.global_budget) ** 1.2  # Enhanced non-linear scaling\n            F = self.F_min + (self.F_max - self.F_min) * factor  # Enhanced non-linear scaling\n            perturbation_variance = 0.05 * np.exp(-evaluations / self.global_budget)  # Refined perturbation variance decay\n            self.population_size = max(10, int(20 * (1 - factor)))  # Adaptive population resizing\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, perturbation_variance, size=self.dim)  # Adaptive perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.6 + 0.35 * np.cos(progress * np.pi / 2 + 0.1)  # Adjusted dynamic scaling\n        phase_shift = 0.55 * np.sin(progress * np.pi / 2 + 0.1) + 0.05  # Adjusted phase shift for periodicity\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2 + phase_shift)) * self.dim / 4))  # Adjusted for dynamic scaling\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Introduced a phase shift correction factor to enhance periodicity enforcement in the optimization process.", "configspace": "", "generation": 73, "fitness": 0.9731395692952653, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.973 with standard deviation 0.011. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e4bcba0f-c130-4396-beb0-7c29c8051eab", "metadata": {"aucs": [0.9601756083945524, 0.9873809782003253, 0.9718621212909184], "final_y": [0.16504584784028486, 0.16487394814042422, 0.1648690873427463]}, "mutation_prompt": null}
{"id": "e7968e49-aff3-4bf5-89a2-817fab2e9d22", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()\n            factor = (evaluations / self.global_budget) ** 1.15  # Slightly reduced non-linear scaling\n            F = self.F_min + (self.F_max - self.F_min) * factor\n            perturbation_variance = 0.06 * np.exp(-evaluations / (self.global_budget * 0.8))  # Adjusted decay rate\n            self.population_size = max(12, int(20 * (1 - factor)))  # Slightly larger minimum population size\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, perturbation_variance, size=self.dim)\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.6 + 0.35 * np.cos(progress * np.pi / 2 + 0.1)\n        phase_shift = 0.55 * np.sin(progress * np.pi / 2 + 0.1)\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2 + phase_shift)) * self.dim / 4))\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Enhanced adaptive mechanisms and perturbation strategies to improve solution diversity and convergence efficiency.", "configspace": "", "generation": 74, "fitness": 0.9754131668312187, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.975 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e4bcba0f-c130-4396-beb0-7c29c8051eab", "metadata": {"aucs": [0.9665571664252951, 0.986347003293603, 0.9733353307747578], "final_y": [0.16487482860658753, 0.16486523534718645, 0.1648648688864246]}, "mutation_prompt": null}
{"id": "e059a1a6-12d8-4e3e-b588-5d5283e059a5", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand() * (0.5 * (1 + np.cos(np.pi * evaluations / self.global_budget)))  # Enhanced adaptive CR\n            factor = (evaluations / self.global_budget) ** 1.2  # Enhanced non-linear scaling\n            F = self.F_min + (self.F_max - self.F_min) * factor  # Enhanced non-linear scaling\n            perturbation_variance = 0.05 * np.exp(-evaluations / self.global_budget)  # Refined perturbation variance decay\n            self.population_size = max(10, int(20 * (1 - factor)))  # Adaptive population resizing\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, perturbation_variance, size=self.dim)  # Adaptive perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.6 + 0.35 * np.cos(progress * np.pi / 2 + 0.1)  # Adjusted dynamic scaling\n        phase_shift = 0.55 * np.sin(progress * np.pi / 2 + 0.1)  # Adjusted phase shift for periodicity\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2 + phase_shift)) * self.dim / 4))  # Adjusted for dynamic scaling\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Enhanced adaptive crossover rate to improve exploration and exploitation balance.", "configspace": "", "generation": 75, "fitness": 0.9753319605827294, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.975 with standard deviation 0.007. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e4bcba0f-c130-4396-beb0-7c29c8051eab", "metadata": {"aucs": [0.9691037530259393, 0.9852489428114034, 0.9716431859108453], "final_y": [0.16496067972924977, 0.1648663295867615, 0.16494725234452645]}, "mutation_prompt": null}
{"id": "0a3ab45d-603f-439c-8313-58503f54f225", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()  # Adaptive CR\n            factor = (evaluations / self.global_budget) ** 1.2  # Enhanced non-linear scaling\n            F = self.F_min + (self.F_max - self.F_min) * factor  # Enhanced non-linear scaling\n            perturbation_variance = 0.05 * np.exp(-evaluations / self.global_budget)  # Refined perturbation variance decay\n            self.population_size = max(10, int(20 * (1 - factor)))  # Adaptive population resizing\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, perturbation_variance, size=self.dim)  # Adaptive perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.6 + 0.4 * np.cos(progress * np.pi / 2 + 0.2)  # Adjusted dynamic scaling\n        phase_shift = 0.6 * np.sin(progress * np.pi / 2 + 0.2)  # Refined phase shift for periodicity\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2 + phase_shift)) * self.dim / 4))  # Adjusted for dynamic scaling\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Enhanced periodicity enforcement by refining dynamic phase shifts and adaptive mutation strategies.", "configspace": "", "generation": 76, "fitness": 0.9712008890063615, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.971 with standard deviation 0.013. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e4bcba0f-c130-4396-beb0-7c29c8051eab", "metadata": {"aucs": [0.9545568746601125, 0.986601496319393, 0.9724442960395789], "final_y": [0.16493627285210366, 0.1648795638056757, 0.1648596205334365]}, "mutation_prompt": null}
{"id": "d510cc04-1f65-469a-9cc5-0b2866db0f9c", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * (0.5 + 0.5 * np.cos(evaluations / self.global_budget * np.pi))  # Cosine adaptive CR\n            factor = (evaluations / self.global_budget) ** 1.2  # Enhanced non-linear scaling\n            F = self.F_min + (self.F_max - self.F_min) * factor  # Enhanced non-linear scaling\n            perturbation_variance = 0.05 * np.exp(-evaluations / self.global_budget)  # Refined perturbation variance decay\n            self.population_size = max(10, int(20 * (1 - factor)))  # Adaptive population resizing\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, perturbation_variance, size=self.dim)  # Adaptive perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.6 + 0.35 * np.cos(progress * np.pi / 2 + 0.1)  # Adjusted dynamic scaling\n        phase_shift = 0.55 * np.sin(progress * np.pi / 2 + 0.1)  # Adjusted phase shift for periodicity\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2 + phase_shift)) * self.dim / 4))  # Adjusted for dynamic scaling\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n            else:\n                correction = avg_value * 0.5  # Predictive correction for incomplete periods\n                solution[start:end] += correction\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Incorporating cosine adaptation in crossover rate (CR) and adding a predictive correction step in periodicity enforcement to enhance convergence accuracy.", "configspace": "", "generation": 77, "fitness": 0.9743765560303248, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.974 with standard deviation 0.007. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e4bcba0f-c130-4396-beb0-7c29c8051eab", "metadata": {"aucs": [0.97857497422976, 0.9804907159622491, 0.9640639778989654], "final_y": [0.16517897916542146, 0.16487013223527336, 0.16486864170611515]}, "mutation_prompt": null}
{"id": "cf0de976-4aa4-42b5-abef-098d7ecef20e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()  # Adaptive CR\n            factor = (evaluations / self.global_budget) ** 1.3  # Enhanced non-linear scaling\n            F = self.F_min + (self.F_max - self.F_min) * np.sin(factor * np.pi)  # Improved oscillatory scaling\n            perturbation_variance = 0.07 * np.exp(-evaluations / self.global_budget)  # Adjusted perturbation variance decay\n            self.population_size = max(10, int(22 * (1 - factor)))  # Adaptive population resizing\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, perturbation_variance, size=self.dim)  # Adaptive perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.6 + 0.37 * np.cos(progress * np.pi / 2 + 0.1)  # Adjusted dynamic scaling\n        phase_shift = 0.55 * np.sin(progress * np.pi / 2 + 0.15)  # Adjusted phase shift for periodicity\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2 + phase_shift)) * self.dim / 4))  # Adjusted for dynamic scaling\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Introducing adaptive oscillatory exploration and refined periodicity fostering for enhanced solution discovery.", "configspace": "", "generation": 78, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 20 is out of bounds for axis 0 with size 20').", "error": "IndexError('index 20 is out of bounds for axis 0 with size 20')", "parent_id": "e4bcba0f-c130-4396-beb0-7c29c8051eab", "metadata": {}, "mutation_prompt": null}
{"id": "d073bced-ea09-4296-ac8e-8ba542266730", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()  # Adaptive CR\n            factor = (evaluations / self.global_budget) ** 1.2  # Enhanced non-linear scaling\n            F = self.F_min + (self.F_max - self.F_min) * factor  # Enhanced non-linear scaling\n            self.population_size = max(8, int(20 * (1 - factor ** 1.1)))  # Improved adaptive population resizing\n            perturbation_variance = 0.05 * np.exp(-evaluations / self.global_budget)  # Refined perturbation variance decay\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, perturbation_variance, size=self.dim)  # Adaptive perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.6 + 0.35 * np.cos(progress * np.pi / 2 + 0.1)  # Adjusted dynamic scaling\n        phase_shift = 0.55 * np.sin(progress * np.pi / 2 + 0.1)  # Adjusted phase shift for periodicity\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2 + phase_shift)) * self.dim / 4))  # Dynamic scaling\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Enhanced PhotonicOptimizer by introducing multi-scale periodicity enforcement and improved adaptive population resizing.", "configspace": "", "generation": 79, "fitness": 0.9748197842648763, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.975 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e4bcba0f-c130-4396-beb0-7c29c8051eab", "metadata": {"aucs": [0.9667839326473308, 0.9855964652632754, 0.9720789548840226], "final_y": [0.16488675365986227, 0.1649182803176218, 0.16487298309960963]}, "mutation_prompt": null}
{"id": "241bcfdc-b4fb-4829-9756-b111d84f5fe5", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()  # Adaptive CR\n            factor = (evaluations / self.global_budget) ** 1.2  # Enhanced non-linear scaling\n            F = self.F_min + (self.F_max - self.F_min) * factor  # Enhanced non-linear scaling\n            perturbation_variance = 0.05 * np.exp(-evaluations / self.global_budget)  # Refined perturbation variance decay\n            self.population_size = max(10, int(20 * (1 - factor)))  # Adaptive population resizing\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, perturbation_variance, size=self.dim)  # Adaptive perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n            # Introduce random reset for diversity enhancement\n            if evaluations % (self.global_budget // 10) == 0:\n                worst_idx = np.argmax([func(ind) for ind in self.population])\n                self.population[worst_idx] = np.random.uniform(bounds.lb, bounds.ub, size=self.dim)\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.6 + 0.35 * np.cos(progress * np.pi / 2 + 0.1)  # Adjusted dynamic scaling\n        phase_shift = 0.55 * np.sin(progress * np.pi / 2 + 0.1)  # Adjusted phase shift for periodicity\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2 + phase_shift)) * self.dim / 4))  # Adjusted for dynamic scaling\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Enhance diversity by introducing a random reset mechanism for the worst-performing solutions.", "configspace": "", "generation": 80, "fitness": 0.976562407853573, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.977 with standard deviation 0.007. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e4bcba0f-c130-4396-beb0-7c29c8051eab", "metadata": {"aucs": [0.9694399151846339, 0.9864781064643539, 0.9737692019117308], "final_y": [0.1648776049784928, 0.1648723741176067, 0.16486149897864522]}, "mutation_prompt": null}
{"id": "87fcabf6-4a0a-4667-9b06-8971a98bc562", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.cos(evaluations / self.global_budget * np.pi/2)  # Adaptive CR\n            factor = (evaluations / self.global_budget) ** 1.2  # Enhanced non-linear scaling\n            F = self.F_min + (self.F_max - self.F_min) * factor  # Enhanced non-linear scaling\n            perturbation_variance = 0.05 * np.exp(-evaluations / self.global_budget)  # Refined perturbation variance decay\n            self.population_size = max(10, int(20 * (1 - factor)))  # Adaptive population resizing\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, perturbation_variance, size=self.dim)  # Adaptive perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.6 + 0.35 * np.cos(progress * np.pi / 2 + 0.2)  # Adjusted dynamic scaling\n        phase_shift = 0.55 * np.sin(progress * np.pi / 2 + 0.2)  # Adjusted phase shift for periodicity\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2 + phase_shift)) * self.dim / 4))  # Adjusted for dynamic scaling\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Improved periodicity enforcement and adaptive crossover for enhanced local search and solution refinement.", "configspace": "", "generation": 81, "fitness": 0.9753147971165067, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.975 with standard deviation 0.007. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e4bcba0f-c130-4396-beb0-7c29c8051eab", "metadata": {"aucs": [0.9772689057388076, 0.9832596303378139, 0.9654158552728989], "final_y": [0.16495604058598734, 0.16486927127852768, 0.16488978261293674]}, "mutation_prompt": null}
{"id": "9ba9d6bc-194c-4bc8-a248-030dc839b472", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.3  # Changed from 0.2 for better exploration\n        self.CR_max = 0.95  # Changed from 0.9 for better exploration\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()  # Adaptive CR\n            factor = (evaluations / self.global_budget) ** 1.2  # Enhanced non-linear scaling\n            F = self.F_min + (self.F_max - self.F_min) * factor  # Enhanced non-linear scaling\n            perturbation_variance = 0.07 * np.exp(-evaluations / self.global_budget)  # Changed from 0.05 for better diversity\n            self.population_size = max(10, int(20 * (1 - factor)))  # Adaptive population resizing\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, perturbation_variance, size=self.dim)  # Adaptive perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.65 + 0.35 * np.cos(progress * np.pi / 2 + 0.1)  # Changed from 0.6 for stronger periodicity\n        phase_shift = 0.6 * np.sin(progress * np.pi / 2 + 0.1)  # Changed from 0.55 for better periodicity\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2 + phase_shift)) * self.dim / 4))  # Adjusted for dynamic scaling\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Enhanced diversity and convergence by dynamic crossover rate and mutation strategies with improved periodicity constraints.", "configspace": "", "generation": 82, "fitness": 0.972630817576848, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.973 with standard deviation 0.003. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e4bcba0f-c130-4396-beb0-7c29c8051eab", "metadata": {"aucs": [0.9683959526595763, 0.9762804385893462, 0.9732160614816214], "final_y": [0.16492697131429412, 0.16486730217236345, 0.1648617722264566]}, "mutation_prompt": null}
{"id": "40cb504e-1cd8-4771-ae2c-ab8bae296a13", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()  # Adaptive CR\n            factor = (evaluations / self.global_budget) ** 1.2  # Enhanced non-linear scaling\n            F = self.F_min + (self.F_max - self.F_min) * factor  # Enhanced non-linear scaling\n            perturbation_variance = 0.05 * np.exp(-evaluations / self.global_budget)  # Refined perturbation variance decay\n            self.population_size = max(10, int(20 * (1 - factor)))  # Adaptive population resizing\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, perturbation_variance, size=self.dim)  # Adaptive perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.65 + 0.3 * np.cos(progress * np.pi + 0.2)  # Adjusted dynamic scaling\n        phase_shift = 0.5 * np.sin(progress * np.pi / 1.5 + 0.15)  # Adjusted phase shift for periodicity\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi + phase_shift)) * self.dim / 4))  # Adjusted for dynamic scaling\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Enhanced phase shift and scaling dynamics to refine periodicity and solution exploration.", "configspace": "", "generation": 83, "fitness": 0.9712008890063615, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.971 with standard deviation 0.013. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e4bcba0f-c130-4396-beb0-7c29c8051eab", "metadata": {"aucs": [0.9545568746601125, 0.986601496319393, 0.9724442960395789], "final_y": [0.16493627285210366, 0.1648795638056757, 0.1648596205334365]}, "mutation_prompt": null}
{"id": "fd3717ff-dd03-4b5e-8889-c0db5ebacd08", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()  # Adaptive CR\n            factor = (evaluations / self.global_budget) ** 1.1  # Enhanced non-linear scaling\n            F = self.F_min + (self.F_max - self.F_min) * factor  # Enhanced non-linear scaling\n            perturbation_variance = 0.04 * np.exp(-evaluations / self.global_budget)  # Refined perturbation variance decay\n            self.population_size = max(10, int(20 * (1 - factor)))  # Adaptive population resizing\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, perturbation_variance, size=self.dim)  # Adaptive perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.65 + 0.30 * np.cos(progress * np.pi / 2)  # Adjusted dynamic scaling\n        phase_shift = 0.60 * np.sin(progress * np.pi / 2)  # Adjusted phase shift for periodicity\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2 + phase_shift)) * self.dim / 3))  # Adjusted for dynamic scaling\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Enhanced balance between exploration and exploitation by refining perturbation variance and periodicity constraints.", "configspace": "", "generation": 84, "fitness": 0.9677054290857227, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.968 with standard deviation 0.009. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e4bcba0f-c130-4396-beb0-7c29c8051eab", "metadata": {"aucs": [0.9563061906299138, 0.9686963254154073, 0.978113771211847], "final_y": [0.16539292757880175, 0.16580662565116966, 0.16550948500119422]}, "mutation_prompt": null}
{"id": "9aacb508-5ecc-438f-8a24-c1c8d48c653d", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()  # Adaptive CR\n            factor = (evaluations / self.global_budget) ** 1.2  # Enhanced non-linear scaling\n            F = self.F_min + (self.F_max - self.F_min) * factor  # Enhanced non-linear scaling\n            perturbation_variance = 0.05 * np.exp(-evaluations / self.global_budget) * (0.5 + 0.5 * np.random.rand())  # Dynamic perturbation variance\n            self.population_size = max(10, int(20 * (1 - factor)))  # Adaptive population resizing\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, perturbation_variance, size=self.dim)  # Adaptive perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.6 + 0.35 * np.cos(progress * np.pi / 2 + 0.1)  # Adjusted dynamic scaling\n        phase_shift = 0.55 * np.sin(progress * np.pi / 2 + 0.1)  # Adjusted phase shift for periodicity\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2 + phase_shift)) * self.dim / 4))  # Adjusted for dynamic scaling\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Introduced a dynamic perturbation variance to enhance solution diversity and exploration.", "configspace": "", "generation": 85, "fitness": 0.9698700678142256, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.970 with standard deviation 0.004. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e4bcba0f-c130-4396-beb0-7c29c8051eab", "metadata": {"aucs": [0.9747981595224617, 0.9658743142863168, 0.9689377296338979], "final_y": [0.16487335217888377, 0.16491063855997368, 0.1648661029020827]}, "mutation_prompt": null}
{"id": "e6aaf3a7-5936-46ad-b6c2-cf0e3583ce93", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()  # Adaptive CR\n            factor = (evaluations / self.global_budget) ** 1.1  # Enhanced non-linear scaling\n            F = self.F_min + (self.F_max - self.F_min) * factor  # Enhanced non-linear scaling\n            perturbation_variance = 0.05 * np.exp(-evaluations / self.global_budget)  # Refined perturbation variance decay\n            self.population_size = max(15, int(20 * (1 - factor)))  # Adaptive population resizing\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, perturbation_variance, size=self.dim)  # Adaptive perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.6 + 0.35 * np.cos(progress * np.pi / 2 + 0.1)  # Adjusted dynamic scaling\n        phase_shift = 0.55 * np.sin(progress * np.pi / 2 + 0.1)  # Adjusted phase shift for periodicity\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2 + phase_shift)) * self.dim / 4))  # Adjusted for dynamic scaling\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Enhanced adaptive population resizing and dynamic scaling to improve convergence efficiency.", "configspace": "", "generation": 86, "fitness": 0.976302043459382, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.976 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e4bcba0f-c130-4396-beb0-7c29c8051eab", "metadata": {"aucs": [0.9677459345545305, 0.98647370308756, 0.9746864927360557], "final_y": [0.1649116375255144, 0.1648744408567201, 0.16486468997149029]}, "mutation_prompt": null}
{"id": "8a12f279-9a61-45be-a902-e2e0b00a33c1", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()  # Adaptive CR\n            factor = (evaluations / self.global_budget) ** 1.2  # Enhanced non-linear scaling\n            F = self.F_min + (self.F_max - self.F_min) * factor  # Enhanced non-linear scaling\n            perturbation_variance = 0.03 * np.exp(-evaluations / self.global_budget)  # Refined perturbation variance decay\n            self.population_size = max(10, int(20 * (1 - factor)))  # Adaptive population resizing\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, perturbation_variance, size=self.dim)  # Adaptive perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.6 + 0.35 * np.cos(progress * np.pi / 2 + 0.1)  # Adjusted dynamic scaling\n        phase_shift = 0.65 * np.sin(progress * np.pi / 2 + 0.1)  # Adjusted phase shift for periodicity\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2 + phase_shift)) * self.dim / 4))  # Adjusted for dynamic scaling\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Enhanced periodicity enforcement via dynamic phase adjustment and smarter perturbation decay.", "configspace": "", "generation": 87, "fitness": 0.9733119888395295, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.973 with standard deviation 0.010. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e4bcba0f-c130-4396-beb0-7c29c8051eab", "metadata": {"aucs": [0.96074627617859, 0.9858394911996798, 0.9733501991403184], "final_y": [0.165071314053148, 0.1649311319831861, 0.1648604525535895]}, "mutation_prompt": null}
{"id": "10b4a3e3-a85c-478e-92e0-89b0addb5157", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()  # Adaptive CR\n            factor = (evaluations / self.global_budget) ** 1.2  # Enhanced non-linear scaling\n            F = self.F_min + (self.F_max - self.F_min) * factor  # Enhanced non-linear scaling\n            perturbation_variance = 0.05 * np.exp(-evaluations / self.global_budget)  # Refined perturbation variance decay\n            self.population_size = max(10, int(20 * (1 - factor)))  # Adaptive population resizing\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, perturbation_variance, size=self.dim)  # Adaptive perturbation\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget + int(self.local_budget * 0.1)})  # Slightly increased local budget\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.6 + 0.35 * np.cos(progress * np.pi / 2 + 0.1)  # Adjusted dynamic scaling\n        phase_shift = 0.55 * np.sin(progress * np.pi / 2 + 0.1)  # Adjusted phase shift for periodicity\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2 + phase_shift)) * self.dim / 4))  # Adjusted for dynamic scaling\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = 0.9 * solution[start:end] + 0.1 * avg_value  # Fine-tuned periodic enforcement\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Enhanced PhotonicOptimizer with refined period enforcement and adaptive local search initiation to improve convergence on complex landscapes.", "configspace": "", "generation": 88, "fitness": 0.8982100802313586, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.898 with standard deviation 0.036. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "e4bcba0f-c130-4396-beb0-7c29c8051eab", "metadata": {"aucs": [0.9212310913976259, 0.9264500032631967, 0.8469491460332532], "final_y": [0.16505471948589023, 0.16492890632027624, 0.16757930934213217]}, "mutation_prompt": null}
{"id": "857041b9-7106-40cb-a86b-9a8e259f6d94", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.2\n        self.CR_max = 0.9\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        for i in range(self.population_size):\n            self.population[i] = self.population[i] - np.mean(self.population[i]) + np.mean(bounds.lb + bounds.ub) / 2\n\n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.exp(-evaluations / self.global_budget)  # 1. Dynamic CR scaling\n            factor = (evaluations / self.global_budget) ** 1.2\n            F = self.F_min + (self.F_max - self.F_min) * factor\n            perturbation_variance = 0.08 * np.exp(-evaluations / self.global_budget)  # 2. Adjusted perturbation variance decay\n            self.population_size = max(10, int(20 * (1 - factor)))\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, perturbation_variance, size=self.dim)\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.6 + 0.35 * np.cos(progress * np.pi / 2 + 0.1)\n        phase_shift = 0.55 * np.sin(progress * np.pi / 2 + 0.1)\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2 + phase_shift)) * self.dim / 4))\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Introducing a dynamic crossover (CR) scaling and adaptive perturbation variance for enhanced convergence and diversity.", "configspace": "", "generation": 89, "fitness": 0.9762590056520697, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.976 with standard deviation 0.007. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e4bcba0f-c130-4396-beb0-7c29c8051eab", "metadata": {"aucs": [0.9803635638279115, 0.9826686605913912, 0.9657447925369065], "final_y": [0.16485750241246577, 0.16486318543748524, 0.16486926903102062]}, "mutation_prompt": null}
{"id": "7e61bca3-42f6-46a2-a854-3f1c28f4bfcd", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.4  # Changed for refined exploration\n        self.F_max = 0.85  # Changed for refined exploration\n        self.CR_min = 0.1  # Adjusted for diversity\n        self.CR_max = 0.8  # Adjusted for diversity\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        \n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()\n            factor = (evaluations / self.global_budget) ** 1.1  # Slightly altered non-linear scaling\n            F = self.F_min + (self.F_max - self.F_min) * factor\n            perturbation_variance = 0.04 * np.exp(-evaluations / self.global_budget)  # Fine-tuned perturbation variance decay\n            self.population_size = max(10, int(20 * (1 - factor)))\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, perturbation_variance, size=self.dim)\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.6 + 0.35 * np.cos(progress * np.pi / 2 + 0.1)\n        phase_shift = 0.55 * np.sin(progress * np.pi / 2 + 0.1)\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2 + phase_shift)) * self.dim / 4))\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Fine-tuned adaptive parameters and mutation strategies to enhance exploration while maintaining solution diversity.", "configspace": "", "generation": 90, "fitness": 0.9808505472233277, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.981 with standard deviation 0.002. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e4bcba0f-c130-4396-beb0-7c29c8051eab", "metadata": {"aucs": [0.9841585777597168, 0.978432550340204, 0.9799605135700621], "final_y": [0.1648879985821361, 0.16489975935156365, 0.16487693794920089]}, "mutation_prompt": null}
{"id": "244b3ca1-57dd-4032-908a-95882069b003", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.4  # Changed for refined exploration\n        self.F_max = 0.85  # Changed for refined exploration\n        self.CR_min = 0.1  # Adjusted for diversity\n        self.CR_max = 0.8  # Adjusted for diversity\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        \n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()\n            factor = (evaluations / self.global_budget) ** 1.1  # Slightly altered non-linear scaling\n            F = self.F_min + (self.F_max - self.F_min) * factor\n            perturbation_variance = 0.04 * np.exp(-evaluations / self.global_budget)  # Fine-tuned perturbation variance decay\n            self.population_size = max(10, int(20 * (1 - factor)))\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, perturbation_variance * (1 + factor), size=self.dim)  # Adjusted mutation strategy\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.6 + 0.35 * np.cos(progress * np.pi / 2 + 0.1)\n        phase_shift = 0.55 * np.sin(progress * np.pi / 2 + 0.1)\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2 + phase_shift)) * self.dim / 4))\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Enhanced exploration by refining the mutation strategy for greater diversity and adaptability.", "configspace": "", "generation": 91, "fitness": 0.9806953364044567, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.981 with standard deviation 0.002. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "7e61bca3-42f6-46a2-a854-3f1c28f4bfcd", "metadata": {"aucs": [0.9841941340286755, 0.9785637235316426, 0.9793281516530523], "final_y": [0.16487249990752129, 0.1648799577678174, 0.16489005217263553]}, "mutation_prompt": null}
{"id": "b3ba1cfc-dddb-4d14-9ee9-2abc8d3e3f19", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.4  # Changed for refined exploration\n        self.F_max = 0.85  # Changed for refined exploration\n        self.CR_min = 0.1  # Adjusted for diversity\n        self.CR_max = 0.8  # Adjusted for diversity\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        \n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()\n            factor = (evaluations / self.global_budget) ** 1.1  # Slightly altered non-linear scaling\n            F = self.F_min + (self.F_max - self.F_min) * factor\n            perturbation_variance = 0.04 * np.exp(-evaluations / self.global_budget)  # Fine-tuned perturbation variance decay\n            self.population_size = max(10, int(20 * (1 - factor)))\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, perturbation_variance, size=self.dim)\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget, 'ftol': 1e-9})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.6 + 0.35 * np.cos(progress * np.pi / 2 + 0.1)\n        phase_shift = 0.55 * np.sin(progress * np.pi / 2 + 0.1)\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2 + phase_shift)) * self.dim / 4))\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Fine-tuned adaptive parameters and mutation strategies to enhance exploration while maintaining solution diversity, with improved local search accuracy using a refined L-BFGS-B method setup.", "configspace": "", "generation": 92, "fitness": 0.9808505472233277, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.981 with standard deviation 0.002. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "7e61bca3-42f6-46a2-a854-3f1c28f4bfcd", "metadata": {"aucs": [0.9841585777597168, 0.978432550340204, 0.9799605135700621], "final_y": [0.1648879985821361, 0.16489975935156365, 0.16487693794920089]}, "mutation_prompt": null}
{"id": "0ea75458-8dea-4888-bc09-76e16bdf3f62", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.4  # Changed for refined exploration\n        self.F_max = 0.85  # Changed for refined exploration\n        self.CR_min = 0.1  # Adjusted for diversity\n        self.CR_max = 0.8  # Adjusted for diversity\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        \n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()\n            factor = (evaluations / self.global_budget) ** 1.1  # Slightly altered non-linear scaling\n            F = self.F_min + (self.F_max - self.F_min) * factor\n            perturbation_variance = 0.04 * np.exp(-evaluations / self.global_budget)  # Fine-tuned perturbation variance decay\n            self.population_size = max(10, int(20 * (1 - factor)))\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, perturbation_variance, size=self.dim)\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        if np.random.rand() < 0.5:  # Introduced dynamic local search probability\n            result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n            return result.x\n        return best_solution\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.6 + 0.35 * np.cos(progress * np.pi / 2 + 0.1)\n        phase_shift = 0.55 * np.sin(progress * np.pi / 2 + 0.1)\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2 + phase_shift)) * self.dim / 4))\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Introduce a dynamic local search probability to enhance convergence in promising regions while maintaining broad exploration.", "configspace": "", "generation": 93, "fitness": 0.9808505472233277, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.981 with standard deviation 0.002. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "7e61bca3-42f6-46a2-a854-3f1c28f4bfcd", "metadata": {"aucs": [0.9841585777597168, 0.978432550340204, 0.9799605135700621], "final_y": [0.1648879985821361, 0.16489975935156365, 0.16487693794920089]}, "mutation_prompt": null}
{"id": "c349d20d-101a-4753-a387-d31f4f5fc7e8", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.4  # Changed for refined exploration\n        self.F_max = 0.85  # Changed for refined exploration\n        self.CR_min = 0.1  # Adjusted for diversity\n        self.CR_max = 0.8  # Adjusted for diversity\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        \n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()\n            factor = (evaluations / self.global_budget) ** 1.05  # Slightly altered non-linear scaling for improved balance\n            F = self.F_min + (self.F_max - self.F_min) * factor\n            perturbation_variance = 0.04 * np.exp(-evaluations / self.global_budget)  # Fine-tuned perturbation variance decay\n            self.population_size = max(10, int(20 * (1 - factor)))\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, perturbation_variance, size=self.dim)\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.6 + 0.35 * np.cos(progress * np.pi / 2 + 0.1)\n        phase_shift = 0.55 * np.sin(progress * np.pi / 2 + 0.1)\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2 + phase_shift)) * self.dim / 4))\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Enhanced PhotonicOptimizer by adjusting the factor scaling for more balanced exploration and exploitation phases.", "configspace": "", "generation": 94, "fitness": 0.9798230430778494, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.980 with standard deviation 0.004. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "7e61bca3-42f6-46a2-a854-3f1c28f4bfcd", "metadata": {"aucs": [0.9840946312276878, 0.9751784315784998, 0.9801960664273606], "final_y": [0.16486745628881283, 0.16491392250015857, 0.16485931633108752]}, "mutation_prompt": null}
{"id": "31b5dd4b-834a-4425-826f-6f5c2c603452", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 18  # Modified size for better convergence\n        self.F_min = 0.3  # Tweaked for dynamic exploration\n        self.F_max = 0.9  # Tweaked for dynamic exploration\n        self.CR_min = 0.15  # Adjusted for better diversity\n        self.CR_max = 0.85  # Adjusted for better diversity\n        self.local_budget = int(budget * 0.25)  # Increased local optimization\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        \n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()\n            factor = (evaluations / self.global_budget) ** 1.05  # Slightly altered non-linear scaling\n            F = self.F_min + (self.F_max - self.F_min) * factor\n            perturbation_variance = 0.05 * np.exp(-evaluations / self.global_budget)  # Adjusted perturbation decay\n            self.population_size = max(12, int(20 * (1 - factor)))  # Adjusted population scaling\n            for i in range(self.population_size):\n                indices = np.random.choice(len(self.population), 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, perturbation_variance, size=self.dim)\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.6 + 0.35 * np.cos(progress * np.pi / 2 + 0.1)\n        phase_shift = 0.55 * np.sin(progress * np.pi / 2 + 0.1)\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2 + phase_shift)) * self.dim / 4))\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Refined exploration and exploitation balance in PhotonicOptimizer through dynamic parameter adjustment and adaptive population control for enhanced convergence.", "configspace": "", "generation": 95, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 18 is out of bounds for axis 0 with size 18').", "error": "IndexError('index 18 is out of bounds for axis 0 with size 18')", "parent_id": "7e61bca3-42f6-46a2-a854-3f1c28f4bfcd", "metadata": {}, "mutation_prompt": null}
{"id": "dd8881bd-41b3-4b71-9d17-47f693d7f521", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.4  # Changed for refined exploration\n        self.F_max = 0.85  # Changed for refined exploration\n        self.CR_min = 0.1  # Adjusted for diversity\n        self.CR_max = 0.8  # Adjusted for diversity\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        \n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()\n            factor = (evaluations / self.global_budget) ** 1.1  # Slightly altered non-linear scaling\n            F = self.F_min + (self.F_max - self.F_min) * factor\n            perturbation_variance = 0.05 * np.exp(-evaluations / self.global_budget)  # Adjusted perturbation variance decay\n            self.population_size = max(10, int(20 * (1 - factor)))\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, perturbation_variance, size=self.dim)\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.6 + 0.35 * np.cos(progress * np.pi / 2 + 0.1)\n        phase_shift = 0.55 * np.sin(progress * np.pi / 2 + 0.1)\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2 + phase_shift)) * self.dim / 4))\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Enhanced exploration by adjusting the perturbation variance decay for improved convergence.", "configspace": "", "generation": 96, "fitness": 0.9809703541151523, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.981 with standard deviation 0.002. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "7e61bca3-42f6-46a2-a854-3f1c28f4bfcd", "metadata": {"aucs": [0.984078129367097, 0.9793152924027219, 0.9795176405756377], "final_y": [0.16488507090177584, 0.16485894926229416, 0.16489189171736218]}, "mutation_prompt": null}
{"id": "ce70a23b-a680-46c9-9d88-a0e508cba3c0", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.4  # Changed for refined exploration\n        self.F_max = 0.85  # Changed for refined exploration\n        self.CR_min = 0.1  # Adjusted for diversity\n        self.CR_max = 0.8  # Adjusted for diversity\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        \n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()\n            factor = (evaluations / self.global_budget) ** 1.1  # Slightly altered non-linear scaling\n            F = self.F_min + (self.F_max - self.F_min) * factor\n            perturbation_variance = 0.05 * np.exp(-evaluations / self.global_budget)  # Adjusted perturbation variance decay\n            self.population_size = max(10, int(20 * (1 - factor)))\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, perturbation_variance, size=self.dim)\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.65 + 0.35 * np.cos(progress * np.pi / 2 + 0.1)  # Adjusted scale_factor modulation\n        phase_shift = 0.55 * np.sin(progress * np.pi / 2 + 0.1)\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2 + phase_shift)) * self.dim / 4))\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Enhanced periodicity enforcement by refining scale factor modulation for better periodic solutions.", "configspace": "", "generation": 97, "fitness": 0.9784314886233179, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.978 with standard deviation 0.004. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "dd8881bd-41b3-4b71-9d17-47f693d7f521", "metadata": {"aucs": [0.9831976660489739, 0.9730891442992432, 0.9790076555217365], "final_y": [0.16488661546928118, 0.16490448247489276, 0.16487182149131852]}, "mutation_prompt": null}
{"id": "7d2ba1df-9a93-4a61-84bf-fb0ca9bcaf86", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.4  # Changed for refined exploration\n        self.F_max = 0.85  # Changed for refined exploration\n        self.CR_min = 0.1  # Adjusted for diversity\n        self.CR_max = 0.8  # Adjusted for diversity\n        self.local_budget = int(budget * 0.25)  # Increased local budget for refined local search\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        \n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()\n            factor = (evaluations / self.global_budget) ** 1.1  # Slightly altered non-linear scaling\n            F = self.F_min + (self.F_max - self.F_min) * factor\n            perturbation_variance = 0.05 * np.exp(-evaluations / self.global_budget)  # Adjusted perturbation variance decay\n            self.population_size = max(10, int(20 * (1 - factor)))\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, perturbation_variance, size=self.dim)\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.6 + 0.35 * np.cos(progress * np.pi / 2 + 0.1)\n        phase_shift = 0.55 * np.sin(progress * np.pi / 2 + 0.1)\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2 + phase_shift)) * self.dim / 4))\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Improved local search convergence by increasing the local optimization budget allocation.", "configspace": "", "generation": 98, "fitness": 0.9799388003849425, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.980 with standard deviation 0.003. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "dd8881bd-41b3-4b71-9d17-47f693d7f521", "metadata": {"aucs": [0.9839996959171111, 0.9761209439253334, 0.9796957613123829], "final_y": [0.16486624816579798, 0.16488906501155642, 0.16491916128651984]}, "mutation_prompt": null}
{"id": "4db09744-785c-4d11-b87b-d20b5ce77a1c", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PhotonicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min = 0.4  # Changed for refined exploration\n        self.F_max = 0.85  # Changed for refined exploration\n        self.CR_min = 0.1  # Adjusted for diversity\n        self.CR_max = 0.8  # Adjusted for diversity\n        self.local_budget = int(budget * 0.2)\n        self.global_budget = budget - self.local_budget\n        self.population = None\n\n    def initialize_population(self, bounds):\n        self.population = np.random.uniform(low=bounds.lb, high=bounds.ub, size=(self.population_size, self.dim))\n        quasi_opposite_population = bounds.lb + bounds.ub - self.population\n        self.population = np.vstack((self.population, quasi_opposite_population))[:self.population_size]\n        \n    def optimize(self, func, bounds):\n        evaluations = 0\n        self.initialize_population(bounds)\n        best_solution = None\n        best_score = np.inf\n\n        while evaluations < self.global_budget:\n            CR = self.CR_min + (self.CR_max - self.CR_min) * np.random.rand()\n            factor = (evaluations / self.global_budget) ** 1.1  # Slightly altered non-linear scaling\n            F = self.F_min + (self.F_max - self.F_min) * factor\n            perturbation_variance = 0.05 * np.exp(-factor)  # Adjusted perturbation variance parameterization\n            self.population_size = max(10, int(20 * (1 - factor)))\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = self.population[indices]\n                mutant = x1 + F * (x2 - x3) + np.random.normal(0, perturbation_variance, size=self.dim)\n                mutant = np.clip(mutant, bounds.lb, bounds.ub)\n                trial = np.copy(self.population[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n                trial = self.enforce_periodicity(trial, evaluations / self.global_budget)\n                score_trial = func(trial)\n                evaluations += 1\n                if score_trial < best_score:\n                    best_score = score_trial\n                    best_solution = trial\n                if score_trial < func(self.population[i]):\n                    self.population[i] = trial\n                if evaluations >= self.global_budget:\n                    break\n\n        result = minimize(func, best_solution, bounds=[(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)], method='L-BFGS-B', options={'maxfun': self.local_budget})\n        return result.x\n\n    def enforce_periodicity(self, solution, progress):\n        scale_factor = 0.6 + 0.35 * np.cos(progress * np.pi / 2 + 0.1)\n        phase_shift = 0.55 * np.sin(progress * np.pi / 2 + 0.1)\n        period_length = max(1, int((1 - scale_factor * np.sin(progress * np.pi / 2 + phase_shift)) * self.dim / 4))\n        for start in range(0, len(solution), period_length):\n            end = start + period_length\n            if end <= len(solution):\n                avg_value = np.mean(solution[start:end])\n                solution[start:end] = avg_value\n        return solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        return self.optimize(func, bounds)", "name": "PhotonicOptimizer", "description": "Improve exploration by refining the perturbation variance parameterization for enhanced convergence.", "configspace": "", "generation": 99, "fitness": 0.9809768306439288, "feedback": "The algorithm PhotonicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.981 with standard deviation 0.002. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "dd8881bd-41b3-4b71-9d17-47f693d7f521", "metadata": {"aucs": [0.9841975751766623, 0.9792858397484177, 0.9794470770067067], "final_y": [0.1648940109119036, 0.1648668570255828, 0.16497949707202442]}, "mutation_prompt": null}
