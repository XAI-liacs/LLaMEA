{"id": "b1d34d43-af89-4591-ad8e-8265afd92fe9", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20  # Number of particles in the swarm\n        self.inertia_weight = 0.7\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social (global) weight\n        self.temperature = 1000  # Initial temperature for simulated annealing\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        # Initialize particle positions and velocities\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        # Initialize personal and global bests\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Update velocities and positions\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)  # Ensure within bounds\n                \n                # Evaluate new position\n                score = func(positions[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                # Simulated annealing perturbation\n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                # Update global best\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            # Decrease temperature\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "A hybrid Particle Swarm Optimization with Simulated Annealing (PSO-SA) that balances exploration and exploitation by adapting velocities and perturbing solutions for diverse search space traversal.", "configspace": "", "generation": 0, "fitness": 0.25955022219596435, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.260 with standard deviation 0.021. And the mean value of best solutions found was 0.083 (0. is the best) with standard deviation 0.039.", "error": "", "parent_id": null, "metadata": {"aucs": [0.2422341662871894, 0.28887611461215323, 0.2475403856885504], "final_y": [0.0669169073401792, 0.045176295952874, 0.1374124566619749]}, "mutation_prompt": null}
{"id": "cac43548-7592-4010-954a-aca88964e5b0", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20  # Number of particles in the swarm\n        self.inertia_weight = 0.7\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social (global) weight\n        self.temperature = 1000  # Initial temperature for simulated annealing\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        # Initialize particle positions and velocities\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        # Initialize personal and global bests\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Update velocities and positions\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], -0.5 * (ub - lb), 0.5 * (ub - lb))  # Adaptive Velocity Clamping\n                \n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)  # Ensure within bounds\n                \n                # Evaluate new position\n                score = func(positions[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                # Simulated annealing perturbation\n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                # Update global best\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            # Decrease temperature\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Introduce Adaptive Velocity Clamping in PSO-SA to enhance convergence by dynamically adjusting particle velocities based on search space boundaries.", "configspace": "", "generation": 1, "fitness": 0.25304231234527497, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.253 with standard deviation 0.025. And the mean value of best solutions found was 0.111 (0. is the best) with standard deviation 0.062.", "error": "", "parent_id": "b1d34d43-af89-4591-ad8e-8265afd92fe9", "metadata": {"aucs": [0.28716835066652113, 0.2445063928580703, 0.22745219351123347], "final_y": [0.030152510531530393, 0.12265036394673487, 0.17981942976765503]}, "mutation_prompt": null}
{"id": "293535d5-e384-43a4-9321-2bdfc4c54fab", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20  # Number of particles in the swarm\n        self.inertia_weight = 0.7\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social (global) weight\n        self.temperature = 1000  # Initial temperature for simulated annealing\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        # Initialize particle positions and velocities\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        # Initialize personal and global bests\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Update velocities and positions\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = ((0.9 - 0.5 * evaluations / self.budget) * velocities[i] +  # Adaptive inertia weight change\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)  # Ensure within bounds\n                \n                # Evaluate new position\n                score = func(positions[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                # Simulated annealing perturbation\n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                # Update global best\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            # Decrease temperature\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "A hybrid Particle Swarm Optimization with Simulated Annealing (PSO-SA) refined to include adaptive inertia weight for enhanced performance.", "configspace": "", "generation": 2, "fitness": 0.23218216446971818, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.232 with standard deviation 0.009. And the mean value of best solutions found was 0.094 (0. is the best) with standard deviation 0.033.", "error": "", "parent_id": "b1d34d43-af89-4591-ad8e-8265afd92fe9", "metadata": {"aucs": [0.24465675624341, 0.22799120315831178, 0.22389853400743276], "final_y": [0.05877461591042604, 0.08481743355991919, 0.13781011364191806]}, "mutation_prompt": null}
{"id": "5ed4afb0-dc42-4845-b0bf-6a5aa0a7fb22", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20  # Number of particles in the swarm\n        self.inertia_weight = 0.9  # Changed from 0.7 to 0.9 for adaptive inertia\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social (global) weight\n        self.temperature = 1000  # Initial temperature for simulated annealing\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        # Initialize particle positions and velocities\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        # Initialize personal and global bests\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Update velocities and positions\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)  # Ensure within bounds\n                \n                # Evaluate new position\n                score = func(positions[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                # Simulated annealing perturbation\n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                # Update global best\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            # Decrease temperature\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "PSO-SA with adaptive inertia weight to dynamically balance exploration and exploitation by adjusting search velocity over iterations.", "configspace": "", "generation": 3, "fitness": 0.19778368923497266, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.198 with standard deviation 0.025. And the mean value of best solutions found was 0.492 (0. is the best) with standard deviation 0.387.", "error": "", "parent_id": "b1d34d43-af89-4591-ad8e-8265afd92fe9", "metadata": {"aucs": [0.21611116866857705, 0.21499557154808369, 0.16224432748825723], "final_y": [0.16675717786644795, 0.2723921417918292, 1.0364415752286467]}, "mutation_prompt": null}
{"id": "6dc05ce8-0adf-465d-8de6-6874e5effab8", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20  # Number of particles in the swarm\n        self.inertia_weight = 0.7\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social (global) weight\n        self.temperature = 1000  # Initial temperature for simulated annealing\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        # Initialize particle positions and velocities\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        # Initialize personal and global bests\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Update velocities and positions\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.inertia_weight = 0.9 - 0.7 * (evaluations / self.budget)  # Adaptive inertia weight\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)  # Ensure within bounds\n                \n                # Evaluate new position\n                score = func(positions[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                # Simulated annealing perturbation\n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                # Update global best\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            # Decrease temperature\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Enhanced PSO-SA with adaptive inertia weight to improve convergence and exploration-exploitation balance.", "configspace": "", "generation": 4, "fitness": 0.235085363247441, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.235 with standard deviation 0.010. And the mean value of best solutions found was 0.051 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "b1d34d43-af89-4591-ad8e-8265afd92fe9", "metadata": {"aucs": [0.2473854756959779, 0.22281165926924373, 0.23505895477710137], "final_y": [0.04423072719692156, 0.06362543706300029, 0.04489631625048598]}, "mutation_prompt": null}
{"id": "a1dcdc3e-261f-4752-971c-2f38f3666ce1", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20  # Number of particles in the swarm\n        self.inertia_weight = 0.9  # Adjusted for adaptive inertia\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social (global) weight\n        self.temperature = 1000  # Initial temperature for simulated annealing\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        # Initialize particle positions and velocities\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        # Initialize personal and global bests\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        max_evaluations = self.budget\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Update velocities and positions\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.inertia_weight = 0.9 - 0.5 * (evaluations / max_evaluations)  # Adaptive inertia\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)  # Ensure within bounds\n                \n                # Evaluate new position\n                score = func(positions[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                # Simulated annealing perturbation\n                if np.random.rand() < (1 - evaluations / self.budget):  # Dynamic acceptance probability\n                    perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                    perturbed_position = np.clip(perturbed_position, lb, ub)\n                    perturbed_score = func(perturbed_position)\n                    evaluations += 1\n\n                    if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                        positions[i] = perturbed_position\n\n                # Update global best\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            # Decrease temperature\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Enhanced PSO-SA by adaptive inertia and selective annealing based on dynamic acceptance probability.", "configspace": "", "generation": 5, "fitness": 0.23682541950925276, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.237 with standard deviation 0.004. And the mean value of best solutions found was 0.012 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "b1d34d43-af89-4591-ad8e-8265afd92fe9", "metadata": {"aucs": [0.23188687846315192, 0.24227697637578915, 0.23631240368881723], "final_y": [0.01168025442750437, 0.00118613990288733, 0.023933806143450774]}, "mutation_prompt": null}
{"id": "83e14072-bef7-4227-8ec0-6ff2c71bcf02", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20  # Number of particles in the swarm\n        self.inertia_weight = 0.7\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social (global) weight\n        self.temperature = 1000  # Initial temperature for simulated annealing\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        # Initialize particle positions and velocities\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        # Initialize personal and global bests\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Update velocities and positions\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = ((0.4 + (self.budget - evaluations) / self.budget * 0.3) * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)  # Ensure within bounds\n                \n                # Evaluate new position\n                score = func(positions[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                # Simulated annealing perturbation\n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                # Update global best\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            # Decrease temperature\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Enhancing PSO-SA by introducing a dynamic inertia weight that decreases over time to improve convergence towards the global best.", "configspace": "", "generation": 6, "fitness": 0.26897253151914047, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.269 with standard deviation 0.023. And the mean value of best solutions found was 0.029 (0. is the best) with standard deviation 0.024.", "error": "", "parent_id": "b1d34d43-af89-4591-ad8e-8265afd92fe9", "metadata": {"aucs": [0.2889829953343176, 0.2807097342925363, 0.2372248649305675], "final_y": [0.01742744362272155, 0.007326226446883149, 0.06322569473477065]}, "mutation_prompt": null}
{"id": "f3d8f3af-5b93-4115-af33-8889292bd47d", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20  # Number of particles in the swarm\n        self.inertia_weight = 0.7\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social (global) weight\n        self.temperature = 1000  # Initial temperature for simulated annealing\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        # Initialize particle positions and velocities\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        # Initialize personal and global bests\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Update velocities and positions\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dynamic_factor = evaluations / self.budget\n                self.c1 = 1.5 + 0.5 * dynamic_factor\n                self.c2 = 1.5 - 0.5 * dynamic_factor\n                velocities[i] = ((0.4 + (self.budget - evaluations) / self.budget * 0.3) * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)  # Ensure within bounds\n                \n                # Evaluate new position\n                score = func(positions[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                # Simulated annealing perturbation\n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                # Update global best\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            # Decrease temperature\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Introduced a dynamic personal and social weight adjustment in PSO-SA to enhance exploration and exploitation balance.", "configspace": "", "generation": 7, "fitness": 0.20493182772449767, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.205 with standard deviation 0.015. And the mean value of best solutions found was 0.136 (0. is the best) with standard deviation 0.062.", "error": "", "parent_id": "83e14072-bef7-4227-8ec0-6ff2c71bcf02", "metadata": {"aucs": [0.1962816819760106, 0.193041897307772, 0.2254719038897104], "final_y": [0.1323435058231208, 0.21416066355506377, 0.06139065828861139]}, "mutation_prompt": null}
{"id": "5b9115c9-dccb-4867-8ce5-d4b7b4ce6c04", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20  # Number of particles in the swarm\n        self.inertia_weight = 0.7\n        self.c1 = 1.5  # Cognitive (personal) weight\n        self.c2 = 1.5  # Social (global) weight\n        self.temperature = 1000  # Initial temperature for simulated annealing\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        # Initialize particle positions and velocities\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        # Initialize personal and global bests\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Update velocities and positions\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.c2 = 1.5 + (0.5 * evaluations / self.budget)  # Dynamic adjustment of social weight\n                velocities[i] = ((0.4 + (self.budget - evaluations) / self.budget * 0.3) * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)  # Ensure within bounds\n                \n                # Evaluate new position\n                score = func(positions[i])\n                evaluations += 1\n                \n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                # Simulated annealing perturbation\n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                # Update global best\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            # Decrease temperature\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Incorporating a dynamic social weight adjustment to balance exploration and exploitation in PSO-SA.", "configspace": "", "generation": 8, "fitness": 0.22613665284415974, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.226 with standard deviation 0.013. And the mean value of best solutions found was 0.101 (0. is the best) with standard deviation 0.044.", "error": "", "parent_id": "83e14072-bef7-4227-8ec0-6ff2c71bcf02", "metadata": {"aucs": [0.21604743692030137, 0.21855263075302878, 0.24380989085914906], "final_y": [0.07757717593559994, 0.16354175477279434, 0.06332031062124814]}, "mutation_prompt": null}
{"id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = ((0.4 + (self.budget - evaluations) / self.budget * 0.3) * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Augment PSO-SA by introducing adaptive parameters based on swarm diversity to strategically balance exploration and exploitation.", "configspace": "", "generation": 9, "fitness": 0.2762988342717243, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.276 with standard deviation 0.015. And the mean value of best solutions found was 0.032 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "83e14072-bef7-4227-8ec0-6ff2c71bcf02", "metadata": {"aucs": [0.2661968055258095, 0.2652192445433653, 0.2974804527459981], "final_y": [0.04528426326361952, 0.023999440341696328, 0.027554340745365703]}, "mutation_prompt": null}
{"id": "c9be0719-f2d6-42f9-ba4e-63a84f3b46b2", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.9  # Updated from 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = ((self.inertia_weight - (evaluations / self.budget * 0.5)) * velocities[i] +  # Modified\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbed_position = positions[i] + np.random.normal(0, 0.05 + (0.1 - 0.05) * (evaluations / self.budget), self.dim)  # Modified\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Enhance PSO-SA by incorporating adaptive inertia and mutation strategies to improve convergence and exploration balance.", "configspace": "", "generation": 10, "fitness": 0.22518898624122388, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.225 with standard deviation 0.012. And the mean value of best solutions found was 0.066 (0. is the best) with standard deviation 0.042.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.215394525044448, 0.2185624921530548, 0.24160994152616888], "final_y": [0.056146495702847646, 0.12142709912603544, 0.02074563868102169]}, "mutation_prompt": null}
{"id": "e55ab79a-b1a8-44b9-b71a-0c39a5f6db37", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = ((0.4 + (self.budget - evaluations) / self.budget * 0.3) * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))\n                positions[i] += velocities[i] * (0.5 + 0.5 * np.random.rand())\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbed_position = positions[i] + np.random.normal(0, 0.1 * (self.budget - evaluations) / self.budget, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Introduce dynamic velocity scaling and adaptive perturbation magnitude to enhance exploration-exploitation balance.", "configspace": "", "generation": 11, "fitness": 0.22252475588332196, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.223 with standard deviation 0.020. And the mean value of best solutions found was 0.019 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.21352663663609928, 0.20425455941257853, 0.24979307160128805], "final_y": [0.011597800505146095, 0.0333474962784026, 0.012288520433279552]}, "mutation_prompt": null}
{"id": "cdc22ead-61ca-447a-83f6-9f763584f378", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        no_improvement_counter = 0  # Added line for tracking no improvement\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = ((0.4 + (self.budget - evaluations) / self.budget * 0.3) * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n                    no_improvement_counter = 0  # Reset no improvement counter\n                else:\n                    no_improvement_counter += 1  # Increment if no improvement\n\n            if no_improvement_counter > 10:  # Random restart condition\n                positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n                no_improvement_counter = 0  # Reset counter after restart\n\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Introduce a random restart mechanism when the global best score does not improve, promoting diversity and escaping local optima.", "configspace": "", "generation": 12, "fitness": 0.16318812344381636, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.163 with standard deviation 0.005. And the mean value of best solutions found was 0.783 (0. is the best) with standard deviation 0.158.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.16990007010861463, 0.15969513861567597, 0.15996916160715846], "final_y": [0.561595200800577, 0.8654840348555679, 0.9221950110746998]}, "mutation_prompt": null}
{"id": "c1071516-becb-4a5c-a966-452eee5b889a", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                \n                # Modified line to dynamically adjust inertia_weight\n                self.inertia_weight = 0.5 + 0.5 * (1 - np.exp(-distance_to_best))\n                \n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Enhance PSO_SA by dynamically adjusting inertia weight based on swarm convergence to improve balance between exploration and exploitation.", "configspace": "", "generation": 13, "fitness": 0.20380099412067396, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.204 with standard deviation 0.032. And the mean value of best solutions found was 0.350 (0. is the best) with standard deviation 0.163.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.24341889043311804, 0.16619246465036253, 0.20179162727854127], "final_y": [0.1263313887780038, 0.5073466611671354, 0.4173733411973681]}, "mutation_prompt": null}
{"id": "5391ea81-c7e3-45e5-8cf5-7fc019840325", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.initial_temp = 1000\n        self.temperature = self.initial_temp\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            diversity_factor = np.mean(np.linalg.norm(positions - global_best_position, axis=1))\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = ((0.4 + (self.budget - evaluations) / self.budget * 0.3) * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.exp(-distance_to_best / (np.sum(np.linalg.norm(velocities, axis=1)) + diversity_factor))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature = self.initial_temp * (1 - evaluations / self.budget)\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Enhance PSO-SA by incorporating dynamic temperature scaling and diversity-based velocity adjustments to improve convergence.", "configspace": "", "generation": 14, "fitness": 0.23670192319083924, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.237 with standard deviation 0.053. And the mean value of best solutions found was 0.366 (0. is the best) with standard deviation 0.485.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.16117728614307536, 0.2776843854490051, 0.27124409798043725], "final_y": [1.0511738121466232, 0.028161122311996457, 0.01774182407200847]}, "mutation_prompt": null}
{"id": "dbf3d605-e13e-48f7-ae3a-668db4b33119", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = ((0.4 + (self.budget - evaluations) / self.budget * 0.3) * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                # Opposition-based learning for better exploration\n                opposite_positions = lb + ub - positions[i]\n                opposite_positions = np.clip(opposite_positions, lb, ub)\n                opposite_score = func(opposite_positions)\n                evaluations += 1\n                \n                if opposite_score < score or np.random.rand() < np.exp((score - opposite_score) / self.temperature):\n                    positions[i] = opposite_positions\n                \n                # Adaptive mutation based on diversity\n                diversity = np.mean(np.linalg.norm(personal_best_positions - global_best_position, axis=1))\n                mutation_strength = 0.1 * (1 - diversity / (ub - lb).mean())\n                perturbed_position = positions[i] + np.random.normal(0, mutation_strength, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Introduce opposition-based learning and adaptive mutation strategy to enhance diversity and convergence in the PSO-SA optimizer.", "configspace": "", "generation": 15, "fitness": 0.1423621912503633, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.142 with standard deviation 0.019. And the mean value of best solutions found was 1.843 (0. is the best) with standard deviation 0.797.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.11832054023927774, 0.16588195614473855, 0.14288407736707365], "final_y": [2.8739826223644225, 0.934172014963687, 1.7205768413128222]}, "mutation_prompt": null}
{"id": "a2118cc2-b26d-431c-82aa-65a9f1f7f901", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = ((0.4 + (self.budget - evaluations) / self.budget * 0.3) * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbed_position = positions[i] + np.random.normal(0, 0.3, self.dim)  # Increased perturbation\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Enhance global exploration by increasing perturbation effect using larger random normal distribution.", "configspace": "", "generation": 16, "fitness": 0.27206432545478576, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.272 with standard deviation 0.013. And the mean value of best solutions found was 0.042 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.2902697877881961, 0.2654469576660732, 0.260476230910088], "final_y": [0.036009966213663896, 0.04188960150398, 0.048103058357532244]}, "mutation_prompt": null}
{"id": "f23cc1d8-be31-4662-9887-5626174b3ce2", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = ((0.4 + (self.budget - evaluations) / self.budget * 0.3) * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))\n                positions[i] += velocities[i] * np.random.uniform(0.9, 1.1)  # Dynamic velocity scaling\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            if np.abs(global_best_score - np.mean(personal_best_scores)) < 1e-6:  # Early stopping condition\n                break\n            \n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Enhance particle diversity by introducing dynamic velocity scaling and an early stopping mechanism to improve convergence efficiency.", "configspace": "", "generation": 17, "fitness": 0.24343904642760805, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.243 with standard deviation 0.012. And the mean value of best solutions found was 0.040 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.259357664296028, 0.2413890424916726, 0.22957043249512354], "final_y": [0.05078411420545477, 0.029299133181242096, 0.04053021538510092]}, "mutation_prompt": null}
{"id": "33ecd51f-6c98-4327-95e9-88c30427ca16", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            velocity_clamp = (ub - lb) / 5  # Dynamic velocity clamping\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i])\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = ((0.4 + (self.budget - evaluations) / self.budget * 0.3) * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))\n                velocities[i] = np.clip(velocities[i], -velocity_clamp, velocity_clamp)  # Apply velocity clamping\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.98  # Adaptive cooling schedule\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Enhance the PSO-SA optimizer by integrating dynamic velocity clamping and adaptive cooling schedule to improve convergence speed and solution quality.", "configspace": "", "generation": 18, "fitness": 0.2596408177358962, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.260 with standard deviation 0.039. And the mean value of best solutions found was 0.064 (0. is the best) with standard deviation 0.044.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.312147365734212, 0.24707694492125065, 0.21969814255222597], "final_y": [0.007183897783208886, 0.07003458049987218, 0.11471331086514207]}, "mutation_prompt": null}
{"id": "55920ea4-7542-4cd0-bbed-5a9178085625", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        self.velocity_clamp = (0.1, 1.0)  # New line: introduce velocity clamping\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = ((0.4 + (self.budget - evaluations) / self.budget * 0.3) * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], self.velocity_clamp[0], self.velocity_clamp[1])  # New line: apply velocity clamping\n                velocities[i] *= np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.97  # Modified line: adjust temperature annealing rate\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Enhance PSO-SA by introducing velocity clamping and dynamic temperature annealing for improved convergence and stability.", "configspace": "", "generation": 19, "fitness": 0.18709889972980057, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.187 with standard deviation 0.006. And the mean value of best solutions found was 0.517 (0. is the best) with standard deviation 0.134.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.1954464767895282, 0.18566346091434383, 0.1801867614855297], "final_y": [0.37081728048048207, 0.4855872035562605, 0.6955374212768393]}, "mutation_prompt": null}
{"id": "2c949dd6-e71f-4a58-bd69-1b92053437de", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = ((0.5 + (self.budget - evaluations) / self.budget * 0.2) * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.exp(-distance_to_best / (np.sum(np.linalg.norm(velocities, axis=1)) + 1e-9))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Enhance swarm diversity and adaptive inertia for improved exploration-exploitation balance.", "configspace": "", "generation": 20, "fitness": 0.24165804446372494, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.242 with standard deviation 0.013. And the mean value of best solutions found was 0.071 (0. is the best) with standard deviation 0.018.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.24192602475406377, 0.2575764341776342, 0.2254716744594768], "final_y": [0.09568728359695115, 0.06431809322354431, 0.05361652806666209]}, "mutation_prompt": null}
{"id": "d25113c6-30c2-421a-8867-4ab015422162", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                # Adjusted line for dynamic inertia weight\n                self.inertia_weight = 0.9 - 0.5 * (evaluations / self.budget)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Introduce dynamic adjustment of inertia weight to enhance exploration-exploitation balance in PSO.", "configspace": "", "generation": 21, "fitness": 0.20965085812918424, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.210 with standard deviation 0.009. And the mean value of best solutions found was 0.141 (0. is the best) with standard deviation 0.039.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.21684879983119787, 0.21548296296728142, 0.1966208115890734], "final_y": [0.17342438038438757, 0.16408471664094781, 0.08566029907530666]}, "mutation_prompt": null}
{"id": "95659901-695e-4532-9a75-c592b99fe91f", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                # Adjust inertia weight based on current temperature\n                velocities[i] = ((0.4 + (self.budget - evaluations) / self.budget * 0.3) * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.99\n            self.inertia_weight = 0.4 + (self.temperature / 1000) * 0.3  # Modified line\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Enhance exploration by dynamically adjusting inertia weight based on temperature decay.", "configspace": "", "generation": 22, "fitness": 0.24256450990680853, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.243 with standard deviation 0.022. And the mean value of best solutions found was 0.043 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.2569151564330293, 0.2590154515236961, 0.21176292176370015], "final_y": [0.05586023391181802, 0.026535481899261176, 0.04551771864569205]}, "mutation_prompt": null}
{"id": "6e8f8e2d-7c6e-4985-9c2c-c18af685989f", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Calculate neighborhood velocity influence\n                neighborhood_best = np.mean(positions, axis=0)\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = ((0.4 + (self.budget - evaluations) / self.budget * 0.3) * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]) +\n                                 0.1 * (neighborhood_best - positions[i]))  # Added neighborhood influence\n                velocities[i] *= np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Enhance PSO-SA by incorporating a neighborhood-based velocity update to intensify local search around promising areas.", "configspace": "", "generation": 23, "fitness": 0.24323666007293124, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.243 with standard deviation 0.016. And the mean value of best solutions found was 0.054 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.25404653864014426, 0.2549886481351651, 0.2206747934434844], "final_y": [0.04333953788900877, 0.044920390287253566, 0.07277820162573533]}, "mutation_prompt": null}
{"id": "ad162eb3-4084-45a7-8920-81c1a425b020", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            diversity = np.std(positions)\n            self.inertia_weight = 0.5 + 0.2 * diversity  # Adjust inertia based on diversity\n\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i])\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +  # Adjusted line\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n\n                velocities[i] += np.random.uniform(-0.1, 0.1, self.dim)  # Introduce adaptive perturbation\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Introduce adaptive velocity components and diversity-based inertia weight adjustment to enhance convergence in PSO-SA.", "configspace": "", "generation": 24, "fitness": 0.1320475256440039, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.132 with standard deviation 0.013. And the mean value of best solutions found was 2.249 (0. is the best) with standard deviation 0.621.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.11585634888146046, 0.14651247403973966, 0.1337737540108116], "final_y": [3.0740236109650305, 1.5748875651143626, 2.0980247135013497]}, "mutation_prompt": null}
{"id": "7517d7f1-0b7d-4897-8bc2-4a6868d1bf13", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                # Adjusted inertia weight strategy\n                inertia_weight = 0.9 - (evaluations / self.budget * 0.5)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Augment PSO-SA by refining the inertia weight strategy to improve convergence speed by gradually decreasing it based on evaluations.", "configspace": "", "generation": 25, "fitness": 0.20515741638389992, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.205 with standard deviation 0.006. And the mean value of best solutions found was 0.099 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.19697362771509963, 0.20570518280183026, 0.21279343863476985], "final_y": [0.08037124317513682, 0.11309487092738948, 0.10442622140744048]}, "mutation_prompt": null}
{"id": "999b1eb5-f9a4-4b34-90a7-d99123eebbc2", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.inertia_weight = 0.7 if personal_best_scores[i] < global_best_score else 0.4\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Introduce adaptive inertia weight based on particle's success to enhance convergence and diversity balance.", "configspace": "", "generation": 26, "fitness": 0.22417827199384588, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.224 with standard deviation 0.042. And the mean value of best solutions found was 0.280 (0. is the best) with standard deviation 0.331.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.1646165754359854, 0.2568705177418362, 0.251047722803716], "final_y": [0.7473667946712566, 0.0414916964806075, 0.0497193763076478]}, "mutation_prompt": null}
{"id": "20749693-a824-4822-9823-3e1196361383", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Update inertia weight based on particle diversity\n                diversity = np.mean(np.linalg.norm(positions - global_best_position, axis=1))\n                inertia_weight = 0.7 * (1 - evaluations / self.budget) + 0.3 * (diversity / np.max(np.linalg.norm(positions, axis=1)))\n                \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.exp(-np.linalg.norm(global_best_position - positions[i]) / np.sum(np.linalg.norm(velocities, axis=1)))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Introduce adaptive inertia based on particle diversity to enhance convergence speed and solution accuracy.", "configspace": "", "generation": 27, "fitness": 0.2508774176921507, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.251 with standard deviation 0.018. And the mean value of best solutions found was 0.037 (0. is the best) with standard deviation 0.016.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.2386120673422134, 0.23796441718854844, 0.27605576854569036], "final_y": [0.05872121409544334, 0.03458818367131963, 0.018785989359562664]}, "mutation_prompt": null}
{"id": "6ab2cae6-21f6-4303-8c7d-05b4f27b7b97", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                adaptive_inertia = 0.4 + (self.budget - evaluations) / self.budget * 0.3\n                adaptive_c1 = self.c1 * (1.0 - evaluations / self.budget)\n                adaptive_c2 = self.c2 * (evaluations / self.budget)\n                velocities[i] = (adaptive_inertia * velocities[i] +\n                                 adaptive_c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 adaptive_c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbation_std = max(0.1, self.temperature / 1000)\n                perturbed_position = positions[i] + np.random.normal(0, perturbation_std, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Enhance PSO-SA by incorporating adaptive learning rates and a self-tuning perturbation mechanism to further refine exploration and exploitation balance.", "configspace": "", "generation": 28, "fitness": 0.19160320609086154, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.192 with standard deviation 0.017. And the mean value of best solutions found was 0.217 (0. is the best) with standard deviation 0.060.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.16899953213149377, 0.20877589410501396, 0.19703419203607686], "final_y": [0.2003891005592107, 0.15328402025698756, 0.29629056163133116]}, "mutation_prompt": null}
{"id": "7deb1680-78e0-42c7-b5be-9e170744662a", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.9  # Changed line (original value: 0.7)\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                # Linearly decrease inertia weight\n                inertia = self.inertia_weight - (0.5 * evaluations / self.budget)  # Changed line\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = (inertia * velocities[i] +  # Changed line\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.95  # Changed line (original value: 0.99)\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Enhance PSO_SA by introducing a linearly decreasing inertia weight and improved exploitation via dynamic temperature adaptation.", "configspace": "", "generation": 29, "fitness": 0.25506206141539556, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.255 with standard deviation 0.032. And the mean value of best solutions found was 0.032 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.21732106806289508, 0.2530747100833002, 0.2947904060999914], "final_y": [0.036945596684113596, 0.03405953392268058, 0.025680168196543264]}, "mutation_prompt": null}
{"id": "5e1dcb20-8c91-489e-8286-0152555c0efa", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = ((0.4 + (self.budget - evaluations) / self.budget * 0.3) * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                neighborhood_size = 0.1 + 0.9 * evaluations / self.budget  # Changed line\n                perturbed_position = positions[i] + np.random.normal(0, neighborhood_size, self.dim)  # Changed line\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Enhance PSO-SA by incorporating variable neighborhood sizes based on iteration progress to improve convergence.", "configspace": "", "generation": 30, "fitness": 0.22449991956291196, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.224 with standard deviation 0.010. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.060.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.23077796792280258, 0.2323397669560241, 0.21038202380990922], "final_y": [0.1382680383465353, 0.11938652698294211, 0.25508647267685297]}, "mutation_prompt": null}
{"id": "d4037356-ab76-465d-9ccf-4b290564812c", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.9  # Changed from 0.7 to 0.9 for better exploration\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            # Dynamic inertia weight adjustment based on evaluations\n            inertia_weight = 0.4 + 0.5 * (1 - evaluations / self.budget)\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            # Dynamic cooling schedule\n            self.temperature *= 0.98  # Changed from 0.99 to 0.98 for faster cooling\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Enhance PSO-SA by incorporating a dynamic cooling schedule and adaptive inertia weight to improve convergence speed and accuracy.", "configspace": "", "generation": 31, "fitness": 0.24210871258166153, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.242 with standard deviation 0.018. And the mean value of best solutions found was 0.058 (0. is the best) with standard deviation 0.028.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.21641661947430535, 0.2516509480897944, 0.2582585701808848], "final_y": [0.0965677206203237, 0.03079296951538385, 0.04694217951228953]}, "mutation_prompt": null}
{"id": "26cbed56-81d1-4c51-9f98-e6e98cbf642c", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight_initial = 0.9  # Changed from 0.7\n        self.inertia_weight_final = 0.4    # New parameter\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            inertia_weight = self.inertia_weight_initial - (self.inertia_weight_initial - self.inertia_weight_final) * (evaluations / self.budget)\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Introduce a dynamic inertia weight decreasing with evaluations to enhance convergence speed.", "configspace": "", "generation": 32, "fitness": 0.22199225298096625, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.222 with standard deviation 0.035. And the mean value of best solutions found was 0.227 (0. is the best) with standard deviation 0.226.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.2533793886369512, 0.23976542894423902, 0.17283194136170854], "final_y": [0.04703594840084217, 0.08814515822565798, 0.5459652025702707]}, "mutation_prompt": null}
{"id": "e85af76d-4526-47ea-98c6-12798030d72a", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        self.velocity_clamp = 0.2  # New parameter for velocity clamping\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim)) * self.velocity_clamp\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = ((0.4 + (self.budget - evaluations) / self.budget * 0.3) * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], -self.velocity_clamp, self.velocity_clamp)\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.97  # Modified adaptive cooling schedule\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Integrate a dynamic velocity clamping and adaptive cooling schedule in PSO-SA to enhance convergence speed and robustness.", "configspace": "", "generation": 33, "fitness": 0.20127708312246395, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.201 with standard deviation 0.023. And the mean value of best solutions found was 0.347 (0. is the best) with standard deviation 0.207.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.21006763839809062, 0.22355173246165438, 0.17021187850764685], "final_y": [0.3253008779056646, 0.10523889149633212, 0.6114393075624666]}, "mutation_prompt": null}
{"id": "db4d1790-f73a-40b5-9abf-3382c75376f1", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = ((0.4 + (self.budget - evaluations) / self.budget * 0.3) * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbed_position = positions[i] + np.random.normal(0, 0.1 * (self.temperature / 1000), self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Improve local search by introducing an adaptive perturbation scale during simulated annealing based on temperature.", "configspace": "", "generation": 34, "fitness": 0.2722133232093869, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.272 with standard deviation 0.024. And the mean value of best solutions found was 0.058 (0. is the best) with standard deviation 0.046.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.2556635212283568, 0.3059893308176458, 0.2549871175821582], "final_y": [0.1126592879885501, 0.00045093826275685307, 0.05956558457193995]}, "mutation_prompt": null}
{"id": "e3e3b90c-bdae-4274-891f-d80fb65a66d8", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i])\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                adaptive_c1 = self.c1 + (distance_to_best / np.sum(np.linalg.norm(positions, axis=1)))\n                velocities[i] = ((0.4 + (self.budget - evaluations) / self.budget * 0.3) * velocities[i] +\n                                 adaptive_c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Enhance global best influence by adapting cognitive component based on distance to global best.", "configspace": "", "generation": 35, "fitness": 0.22288347804871222, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.223 with standard deviation 0.014. And the mean value of best solutions found was 0.054 (0. is the best) with standard deviation 0.016.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.22399283488833366, 0.20513470069372686, 0.23952289856407616], "final_y": [0.034291651553114644, 0.07309816308450487, 0.05569355046487538]}, "mutation_prompt": null}
{"id": "4440ed11-b7fd-4c07-8ab3-aadf2062e509", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight_initial = 0.9\n        self.inertia_weight_final = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                inertia_weight = (self.inertia_weight_initial - \n                                  (self.inertia_weight_initial - self.inertia_weight_final) * \n                                  (evaluations / self.budget))  \n                distance_to_best = np.linalg.norm(global_best_position - positions[i])\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Enhance PSO-SA by introducing a dynamic inertia weight that decreases linearly to improve convergence speed and solution quality.", "configspace": "", "generation": 36, "fitness": 0.2459525180690866, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.246 with standard deviation 0.013. And the mean value of best solutions found was 0.069 (0. is the best) with standard deviation 0.020.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.22715173601251515, 0.2538358906867233, 0.2568699275080214], "final_y": [0.09678474802585188, 0.05959862971952554, 0.05048453030430793]}, "mutation_prompt": null}
{"id": "6479c32e-2be9-481c-9a5a-b27e332c3deb", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                inertia_weight = 0.9 - (0.5 * (evaluations / self.budget))  # Dynamically adjust inertia weight\n                velocities[i] = ((inertia_weight) * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Enhance the velocity update rule with dynamic inertia weight adjustment to improve convergence.", "configspace": "", "generation": 37, "fitness": 0.23363700184433225, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.234 with standard deviation 0.007. And the mean value of best solutions found was 0.063 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.2303820001761988, 0.24289141781389345, 0.22763758754290453], "final_y": [0.07238215265415619, 0.052819382658754625, 0.06508066120787663]}, "mutation_prompt": null}
{"id": "3cad3d2a-1320-48dc-ad32-3e02806cf246", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                diversity = np.std(positions, axis=0).mean()\n                inertia_weight = 0.4 + (self.budget - evaluations) / self.budget * 0.3 * (1 - diversity)  # Dynamic inertia weight\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Integrate dynamic inertia weight adaptation based on swarm diversity to enhance PSO-SA convergence.", "configspace": "", "generation": 38, "fitness": 0.0995521555010006, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.100 with standard deviation 0.031. And the mean value of best solutions found was 5.286 (0. is the best) with standard deviation 2.587.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.0720347570471983, 0.08422195101367924, 0.14239975844212427], "final_y": [7.80532267244815, 6.3250038745372725, 1.7284664490651505]}, "mutation_prompt": null}
{"id": "7845169e-1a87-4914-b124-6f43f405f3d8", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            diversity = np.std(positions, axis=0).mean()  # Calculate swarm diversity\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = ((0.4 + (self.budget - evaluations) / self.budget * 0.3) * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbed_position = positions[i] + np.random.normal(0, 0.1 * diversity, self.dim)  # Dynamic perturbation scale\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.98  # Adjusted cooling rate\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Enhance PSO-SA by incorporating a dynamic perturbation scale based on swarm diversity and adaptively adjusting the cooling rate for better convergence.", "configspace": "", "generation": 39, "fitness": 0.226434345780382, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.226 with standard deviation 0.044. And the mean value of best solutions found was 0.061 (0. is the best) with standard deviation 0.033.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.16743151951043966, 0.2380358928141616, 0.2738356250165447], "final_y": [0.10721557188292802, 0.044598869677747885, 0.03144036442843601]}, "mutation_prompt": null}
{"id": "3572552a-6b4b-4971-b3db-7574262e020d", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.inertia_weight = 0.5 + 0.2 * (self.budget - evaluations) / self.budget  # Changed line\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbation_scale = 0.1 * (self.budget - evaluations) / self.budget  # Changed line\n                perturbed_position = positions[i] + np.random.normal(0, perturbation_scale, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Enhance PSO-SA by adapting inertia weight and perturbation scale based on evaluations for improved convergence.", "configspace": "", "generation": 40, "fitness": 0.23878949951352066, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.239 with standard deviation 0.003. And the mean value of best solutions found was 0.032 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.2359270840298041, 0.2383179877588789, 0.24212342675187892], "final_y": [0.029048369554085424, 0.04924279244922035, 0.018867822734772884]}, "mutation_prompt": null}
{"id": "b23021a2-9b08-48a0-b559-63bd30f349e3", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = ((0.4 + (self.budget - evaluations) / self.budget * 0.3) * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                # Change 1: Added adaptive perturbation scaling\n                perturbation_scale = 0.1 * (1 - evaluations / self.budget)\n                perturbed_position = positions[i] + np.random.normal(0, perturbation_scale, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            # Change 2: Adjust temperature decay for enhanced convergence\n            self.temperature *= 0.995\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Enhance local search by incorporating adaptive perturbation scaling based on convergence progress.", "configspace": "", "generation": 41, "fitness": 0.2534554206771774, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.253 with standard deviation 0.008. And the mean value of best solutions found was 0.025 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.25583253777346227, 0.2428913885648969, 0.2616423356931731], "final_y": [0.029839364361631752, 0.03199774560422063, 0.01381033338321039]}, "mutation_prompt": null}
{"id": "7216bf6f-55d8-4783-adc5-2d5d9d88b3cb", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = ((0.4 + (self.budget - evaluations) / self.budget * 0.3) * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbed_position = positions[i] + np.random.normal(0, 0.2, self.dim)  # Increased std deviation\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Enhance the SA step by increasing the exploration with larger perturbations using an increased standard deviation of 0.2.", "configspace": "", "generation": 42, "fitness": 0.2574290870721405, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.257 with standard deviation 0.041. And the mean value of best solutions found was 0.079 (0. is the best) with standard deviation 0.056.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.30750439592099876, 0.2567643990773102, 0.2080184662181126], "final_y": [0.02314408906086145, 0.057925534917227434, 0.1551108741164194]}, "mutation_prompt": null}
{"id": "493be3e9-882e-4dcd-8540-3127d9656889", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        last_global_score = global_best_score\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                improvement_rate = (last_global_score - global_best_score) / last_global_score\n                adapt_factor = 1 + 0.2 * np.tanh(5 * improvement_rate)\n                velocities[i] = (adapt_factor * (0.4 + (self.budget - evaluations) / self.budget * 0.3) * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.99\n            last_global_score = global_best_score\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Introduce dynamic adjustment of particle velocity factors based on the convergence rate to enhance exploration at critical stages.", "configspace": "", "generation": 43, "fitness": 0.2237774828036272, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.224 with standard deviation 0.015. And the mean value of best solutions found was 0.036 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.2168751879269356, 0.21013303716415244, 0.24432422331979353], "final_y": [0.04930738951163112, 0.03526739724794937, 0.024334365600829393]}, "mutation_prompt": null}
{"id": "4f47f7ff-66f0-4d96-a5a6-b3d44fe567ee", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = ((0.4 + (self.budget - evaluations) / self.budget * 0.3) * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))\n                # Dynamic re-scaling of velocities\n                velocities[i] *= (1 + 0.5 * (self.budget - evaluations) / self.budget)\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Integrate dynamic re-scaling of velocities based on swarm convergence to enhance exploration and prevent premature convergence.", "configspace": "", "generation": 44, "fitness": 0.18712158262405243, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.187 with standard deviation 0.005. And the mean value of best solutions found was 0.136 (0. is the best) with standard deviation 0.080.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.19345320769277075, 0.1877732839121884, 0.18013825626719815], "final_y": [0.06909739190756475, 0.0904617185888425, 0.24767460437090594]}, "mutation_prompt": null}
{"id": "5e48d726-9d69-4a78-85f1-639fd3793dd7", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = ((0.4 + (self.budget - evaluations) / self.budget * 0.3) * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))\n                # Dynamic velocity scaling based on fitness\n                velocities[i] *= (1 - personal_best_scores[i] / (global_best_score + 1e-9))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Enhance PSO-SA by incorporating dynamic velocity scaling based on particle fitness to improve convergence precision.", "configspace": "", "generation": 45, "fitness": 0.14255482027100508, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.143 with standard deviation 0.034. And the mean value of best solutions found was 1.904 (0. is the best) with standard deviation 1.330.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.18054724485446805, 0.14949836116099924, 0.09761885479754795], "final_y": [0.560588825815823, 1.4360017353214738, 3.714937761491136]}, "mutation_prompt": null}
{"id": "85da5ce0-215c-466b-a263-fabbdcac4b39", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = ((0.4 + (self.budget - evaluations) / self.budget * 0.3) * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.99\n            if evaluations % 50 == 0:  # Reset temperature occasionally to improve exploration\n                self.temperature = max(1000, self.temperature * 1.1)\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Enhance PSO-SA by dynamically adjusting velocity based on global best stability and introducing temperature resetting for better exploration.", "configspace": "", "generation": 46, "fitness": 0.24315728843818593, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.243 with standard deviation 0.044. And the mean value of best solutions found was 0.204 (0. is the best) with standard deviation 0.263.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.27178077045478255, 0.18051433749528145, 0.27717675736449376], "final_y": [0.025609084868859606, 0.5757991711208396, 0.011255997330169179]}, "mutation_prompt": null}
{"id": "d162c730-117e-4ba7-abe0-c87f50d0588c", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = ((0.4 + (self.budget - evaluations) / self.budget * 0.3) * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.99 + 0.01 * (evaluations / self.budget)  # Modified line\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Enhance PSO-SA by introducing a dynamic cooling schedule for the temperature parameter to improve exploration-exploitation balance.", "configspace": "", "generation": 47, "fitness": 0.23991212133615344, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.240 with standard deviation 0.012. And the mean value of best solutions found was 0.073 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.22783831951246836, 0.2563123718237674, 0.23558567267222452], "final_y": [0.07842563723036368, 0.07566483855827011, 0.06445636753549963]}, "mutation_prompt": null}
{"id": "f3e5ea47-137b-440b-a16e-e14ccce324a7", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                # Change 1: Dynamic inertia weight adjustment based on evaluations\n                dynamic_inertia_weight = 0.4 + (0.5 * (1 - evaluations / self.budget))\n                velocities[i] = (dynamic_inertia_weight * velocities[i] + \n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Integrate dynamic inertia adjustment in PSO to enhance convergence efficiency while maintaining balance between exploration and exploitation.", "configspace": "", "generation": 48, "fitness": 0.25120314612078365, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.251 with standard deviation 0.020. And the mean value of best solutions found was 0.055 (0. is the best) with standard deviation 0.018.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.2228981999549443, 0.2670321704451548, 0.2636790679622518], "final_y": [0.07511720189200684, 0.031343872326526474, 0.05998879166642524]}, "mutation_prompt": null}
{"id": "de69f99a-2d2f-46fa-aa11-78ca541dd0fc", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.inertia_weight = 0.4 + 0.3 * (1 - evaluations / self.budget)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Introduce adaptive inertia weight based on convergence progress to enhance exploitation-exploration balance.", "configspace": "", "generation": 49, "fitness": 0.271411212857776, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.271 with standard deviation 0.031. And the mean value of best solutions found was 0.023 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.24726637665200102, 0.25218127311609917, 0.3147859888052278], "final_y": [0.04005660470296376, 0.006657575501700816, 0.02317218456527325]}, "mutation_prompt": null}
{"id": "d7325826-dc17-416b-84b0-53245e361741", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = ((0.4 + (self.budget - evaluations) / self.budget * 0.3) * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                # Introduce a diversity-driven mutation mechanism\n                if np.random.rand() < 0.1:  # 10% chance for mutation\n                    mutation = np.random.normal(0, np.std(positions, axis=0), self.dim)\n                    mutated_position = positions[i] + mutation\n                    mutated_position = np.clip(mutated_position, lb, ub)\n                    mutated_score = func(mutated_position)\n                    evaluations += 1\n                    if mutated_score < score:\n                        positions[i] = mutated_position\n                        score = mutated_score\n\n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Enhance PSO-SA by integrating a diversity-driven mutation mechanism to maintain exploration and prevent premature convergence.", "configspace": "", "generation": 50, "fitness": 0.2470496529714902, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.247 with standard deviation 0.002. And the mean value of best solutions found was 0.071 (0. is the best) with standard deviation 0.022.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.24966366338787116, 0.2476355755942845, 0.24384971993231497], "final_y": [0.04108881120195981, 0.0939576901202179, 0.07919284338106719]}, "mutation_prompt": null}
{"id": "922e9488-7b8e-4036-8d4f-048acabe7211", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                inertia_weight = 0.5 + 0.5 * (1 - evaluations / self.budget)  # Changed line\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbation_magnitude = 0.1 * (1 - evaluations / self.budget)  # Changed line\n                perturbed_position = positions[i] + np.random.normal(0, perturbation_magnitude, self.dim)  # Changed line\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Enhance PSO-SA by dynamically adjusting inertia and velocity perturbations based on exploration-exploitation feedback.", "configspace": "", "generation": 51, "fitness": 0.21898480935195586, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.219 with standard deviation 0.006. And the mean value of best solutions found was 0.058 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.22041951906522805, 0.22541296854077564, 0.21112194044986388], "final_y": [0.05981673322568914, 0.055725505147732945, 0.05928024949780269]}, "mutation_prompt": null}
{"id": "eb00f10b-1bcc-49e2-aca3-06fad33e26b5", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i])\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = ((0.6 - evaluations / (2 * self.budget)) * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= (0.95 + 0.05 * evaluations / self.budget) # Dynamic cooling schedule\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Enhance PSO-SA by adapting the number of particles and introducing a dynamic cooling schedule to balance convergence speed and solution accuracy.", "configspace": "", "generation": 52, "fitness": 0.24381147520823773, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.244 with standard deviation 0.038. And the mean value of best solutions found was 0.019 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.26609911832392374, 0.27557763293270254, 0.18975767436808688], "final_y": [0.03333663675332671, 0.0021188245273294484, 0.022730143871966334]}, "mutation_prompt": null}
{"id": "7e7aebc8-67dc-433f-9df4-3f0c7130e4a3", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = ((0.4 + (self.budget - evaluations) / self.budget * 0.3) * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.99\n            # New line: Adaptive velocity clamping based on global best score\n            velocities = np.clip(velocities, -abs(global_best_score), abs(global_best_score))\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Enhance PSO-SA by introducing adaptive velocity clamping based on global best score to stabilize convergence quality.", "configspace": "", "generation": 53, "fitness": 0.2308793598352057, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.231 with standard deviation 0.038. And the mean value of best solutions found was 0.210 (0. is the best) with standard deviation 0.192.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.2364070270975719, 0.2738471796289661, 0.18238387277907908], "final_y": [0.13409928909866803, 0.0225170257316471, 0.47449939058796076]}, "mutation_prompt": null}
{"id": "5cc7268f-0b7e-493c-b8a9-a7de22979778", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                # Adjust inertia weight dynamically based on progress\n                dynamic_inertia_weight = self.inertia_weight * (0.5 + 0.5 * (1 - evaluations / self.budget))\n                velocities[i] = (dynamic_inertia_weight * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Enhance PSO-SA by adjusting the inertia weight dynamically based on progress to better balance exploration and exploitation.", "configspace": "", "generation": 54, "fitness": 0.2555038867990152, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.256 with standard deviation 0.011. And the mean value of best solutions found was 0.040 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.24623676366104574, 0.24954308631834043, 0.27073181041765937], "final_y": [0.05277956561203482, 0.04763519311023148, 0.020229963356328397]}, "mutation_prompt": null}
{"id": "a7f888a3-b380-42da-8546-ba8914cc5516", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                # Change: Modify inertia weight using a cosine function\n                self.inertia_weight = 0.4 + 0.3 * (1 + np.cos(np.pi * evaluations / self.budget)) / 2\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Enhance PSO-SA by introducing a dynamic inertia weight adjustment using a cosine function to better adapt to the optimization landscape.", "configspace": "", "generation": 55, "fitness": 0.24904316818883418, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.249 with standard deviation 0.012. And the mean value of best solutions found was 0.042 (0. is the best) with standard deviation 0.026.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.24319586143406136, 0.26574661275694944, 0.23818703037549172], "final_y": [0.018748362411527414, 0.028590361835862287, 0.07726548608549115]}, "mutation_prompt": null}
{"id": "048e68cd-44de-410c-a484-9eb251d835d0", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            improvement = np.abs(np.min(personal_best_scores) - global_best_score) \n            self.inertia_weight = 0.4 + 0.3 * (1 - improvement / (improvement + 1e-10))  # Dynamic inertia weight\n\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Enhance velocity update by incorporating dynamic inertia weight adaptation based on global best improvement.", "configspace": "", "generation": 56, "fitness": 0.25340409466846026, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.253 with standard deviation 0.011. And the mean value of best solutions found was 0.046 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.26088966214692766, 0.2614775632323719, 0.23784505862608118], "final_y": [0.05243514151133662, 0.05730343152603277, 0.027790477874726292]}, "mutation_prompt": null}
{"id": "dc73fdac-b8ea-4fee-b960-8b428c75de4d", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                convergence_factor = np.mean(personal_best_scores) / global_best_score  # Dynamic update factor\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = ((0.5 + 0.2 * convergence_factor) * velocities[i] +  # Adjusted inertia\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.97  # Faster cooling rate\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Enhance PSO-SA by introducing dynamic temperature and velocity updates based on particle convergence trends for improved optimization efficiency.", "configspace": "", "generation": 57, "fitness": 0.16235277663109282, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.162 with standard deviation 0.016. And the mean value of best solutions found was 0.982 (0. is the best) with standard deviation 0.521.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.18440906381363809, 0.14640085789303958, 0.1562484081866008], "final_y": [0.2544772180941798, 1.4483398846753988, 1.2437156249291192]}, "mutation_prompt": null}
{"id": "61de1ca0-6a9c-486c-a08c-14bb00df30d9", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = ((0.4 + (self.budget - evaluations) / self.budget * 0.3) * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]) +\n                                 0.1 * r3 * (ub - lb))  # Added random term for improved diversity\n                velocities[i] *= np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Enhance global learning by modifying the velocity update formula to include an additional random term for improved diversity.", "configspace": "", "generation": 58, "fitness": 0.22655303902628446, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.227 with standard deviation 0.006. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.019.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.21889954285418112, 0.23340181125935133, 0.22735776296532095], "final_y": [0.11628859039848238, 0.15702987539255603, 0.11890382925667713]}, "mutation_prompt": null}
{"id": "2ab0fbc0-4c42-4e64-bf73-870d79e405fc", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                progress = evaluations / self.budget\n                self.c1 = 2.5 * (1 - progress) + 0.5 * progress  # dynamically adjust c1\n                self.c2 = 0.5 * (1 - progress) + 2.5 * progress  # dynamically adjust c2\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                velocities[i] = ((0.4 + (self.budget - evaluations) / self.budget * 0.3) * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.99\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Enhance PSO-SA by dynamically adjusting cognitive and social coefficients based on iteration progress to improve convergence speed and solution quality.", "configspace": "", "generation": 59, "fitness": 0.24563238175656013, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.246 with standard deviation 0.018. And the mean value of best solutions found was 0.081 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.27091448714729904, 0.22947735993220697, 0.2365052981901744], "final_y": [0.06883989762394557, 0.09006313256985027, 0.08457766566989706]}, "mutation_prompt": null}
{"id": "3c2ce298-aadc-4705-bf65-ac7d96b13e40", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = ((0.4 + (self.budget - evaluations) / self.budget * 0.3) * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.tanh(1 / (1 + np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.95 + 0.05 * (global_best_score / max(personal_best_scores))\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Enhance PSO-SA with a dynamic temperature cooling schedule and adaptive velocity scaling to improve exploration-exploitation balance.", "configspace": "", "generation": 60, "fitness": 0.30394932767604205, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.304 with standard deviation 0.005. And the mean value of best solutions found was 0.011 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "8adbfa92-4126-44b0-bed4-e35fe2141d98", "metadata": {"aucs": [0.29682256932662954, 0.3087430869675327, 0.30628232673396394], "final_y": [0.01576220344156474, 0.01024779406354691, 0.007044199776572567]}, "mutation_prompt": null}
{"id": "98f5fc51-563d-4063-bb96-15f3b6c1a9a6", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n\n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.num_particles\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.inertia_weight = 0.4 + 0.3 * ((self.budget - evaluations) / self.budget)  # Adaptive inertia weight\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.tanh(1 / (1 + np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.95 + 0.05 * (global_best_score / max(personal_best_scores))\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Introduce an adaptive inertia weight update based on the current iteration to boost convergence speed.", "configspace": "", "generation": 61, "fitness": 0.197724322998322, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.198 with standard deviation 0.109. And the mean value of best solutions found was 1.460 (0. is the best) with standard deviation 1.198.", "error": "", "parent_id": "3c2ce298-aadc-4705-bf65-ac7d96b13e40", "metadata": {"aucs": [0.13470911887640014, 0.10801257214278004, 0.3504512779757858], "final_y": [1.4401008458084539, 2.937129753200418, 0.002029188657230022]}, "mutation_prompt": null}
{"id": "96702d0e-e4db-4084-a52c-f359ce945550", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            inertia_adaptive = 0.4 + (0.3 * (1 - evaluations / self.budget))\n            diversity = np.mean(np.linalg.norm(positions - global_best_position, axis=1))\n            \n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = (inertia_adaptive * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.tanh(1 / (1 + np.exp(-np.linalg.norm(global_best_position - positions[i]) / np.sum(np.linalg.norm(velocities, axis=1)))))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbation_strength = 0.1 * (diversity / (1 + evaluations / self.budget))\n                perturbed_position = positions[i] + np.random.normal(0, perturbation_strength, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n            \n            self.temperature *= 0.95 + 0.05 * (global_best_score / max(personal_best_scores))\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Integrate adaptive inertia and diversity-driven perturbation to balance exploration and exploitation further.", "configspace": "", "generation": 62, "fitness": 0.22740794771886988, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.227 with standard deviation 0.061. And the mean value of best solutions found was 0.464 (0. is the best) with standard deviation 0.641.", "error": "", "parent_id": "3c2ce298-aadc-4705-bf65-ac7d96b13e40", "metadata": {"aucs": [0.2475530553156915, 0.14407935024485008, 0.2905914375960681], "final_y": [0.01819231344055113, 1.3706787652967627, 0.001874564335527458]}, "mutation_prompt": null}
{"id": "7e8cf6ff-7922-4cd7-97d2-ee5d1a1834da", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = ((self.inertia_weight * (1 - evaluations / self.budget) + 0.5) * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.tanh(1 / (1 + np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.95 + 0.05 * (global_best_score / max(personal_best_scores)) * (evaluations / self.budget)\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Introduce adaptive inertia weight and temperature cooling to enhance convergence and stability.", "configspace": "", "generation": 63, "fitness": 0.2633498875905807, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.263 with standard deviation 0.024. And the mean value of best solutions found was 0.024 (0. is the best) with standard deviation 0.015.", "error": "", "parent_id": "3c2ce298-aadc-4705-bf65-ac7d96b13e40", "metadata": {"aucs": [0.24932581694729472, 0.2432384397916848, 0.29748540603276263], "final_y": [0.02513845988401848, 0.042144761600596374, 0.005780125942596655]}, "mutation_prompt": null}
{"id": "3f79d7ba-0084-4ab6-b643-2acfea54c151", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = ((0.4 + (self.budget - evaluations) / self.budget * 0.3) * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.tanh(1 / (1 + np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.93 + 0.07 * (global_best_score / max(personal_best_scores))\n            velocities *= 0.99  # Introducing velocity decay\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Enhance PSO-SA by introducing velocity decay and tweaking the cooling factor for improved convergence.", "configspace": "", "generation": 64, "fitness": 0.20866043965557604, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.209 with standard deviation 0.083. And the mean value of best solutions found was 0.629 (0. is the best) with standard deviation 0.460.", "error": "", "parent_id": "3c2ce298-aadc-4705-bf65-ac7d96b13e40", "metadata": {"aucs": [0.1730896534352826, 0.32362503963701494, 0.1292666258944306], "final_y": [0.7574584297028623, 0.012367677329246068, 1.1158567941882591]}, "mutation_prompt": null}
{"id": "c73b32d0-bf33-4f6b-9796-92e19716cdc5", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = ((self.inertia_weight * 0.99 ** (evaluations / self.budget)) * velocities[i] +  # Changed line\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.tanh(1 / (1 + np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.95 + 0.05 * (global_best_score / max(personal_best_scores))\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Introduce a decay factor to the inertia weight for improved convergence performance.", "configspace": "", "generation": 65, "fitness": 0.22541906070763906, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.225 with standard deviation 0.032. And the mean value of best solutions found was 0.196 (0. is the best) with standard deviation 0.138.", "error": "", "parent_id": "3c2ce298-aadc-4705-bf65-ac7d96b13e40", "metadata": {"aucs": [0.21912444541407028, 0.2678099293938767, 0.1893228073149702], "final_y": [0.17083926678655165, 0.04029420456752486, 0.3754581722705366]}, "mutation_prompt": null}
{"id": "1429cd3f-d746-4a66-8324-272693d33c23", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 20\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i]) \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.inertia_weight = 0.5 + 0.5 * (self.budget - evaluations) / self.budget  # Adaptive inertia\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.tanh(1 / (1 + np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))))\n                positions[i] += velocities[i] + self.levy_flight(self.dim)  # Levy flight\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.95 + 0.05 * (global_best_score / max(personal_best_scores))\n\n        return global_best_position, global_best_score\n\n    def levy_flight(self, dim, beta=1.5):\n        sigma = (np.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.normal(0, sigma, size=dim)\n        v = np.random.normal(0, 1, size=dim)\n        return u / np.abs(v)**(1 / beta)", "name": "PSO_SA_Optimizer", "description": "Integrate Levy flights and adaptive inertia to further enhance exploration while maintaining stable convergence.", "configspace": "", "generation": 66, "fitness": -Infinity, "feedback": "An exception occurred: AttributeError(\"module 'numpy' has no attribute 'gamma'\").", "error": "AttributeError(\"module 'numpy' has no attribute 'gamma'\")", "parent_id": "3c2ce298-aadc-4705-bf65-ac7d96b13e40", "metadata": {}, "mutation_prompt": null}
{"id": "71d29170-30e3-4bda-8cb4-06481da5596b", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = max(10, 20 - int(0.1 * budget))  # Dynamic number of particles\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i])\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = ((0.4 + (self.budget - evaluations) / self.budget * 0.3) * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.tanh(1 / (1 + np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.95 + 0.05 * (global_best_score / max(personal_best_scores))\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Introduce a dynamic number of particles based on remaining budget and a stochastic perturbation threshold for enhanced exploration-exploitation balance.", "configspace": "", "generation": 67, "fitness": 0.3046597236664011, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.305 with standard deviation 0.019. And the mean value of best solutions found was 0.021 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "3c2ce298-aadc-4705-bf65-ac7d96b13e40", "metadata": {"aucs": [0.3304344794301992, 0.2867806382935558, 0.2967640532754483], "final_y": [0.008895117537398786, 0.01986460938466121, 0.035367554668085985]}, "mutation_prompt": null}
{"id": "6ab275d0-06b1-4eb6-a24f-1de33d0011c1", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = max(10, 20 - int(0.1 * budget))  # Dynamic number of particles\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i])\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = ((0.4 + (self.budget - evaluations) / self.budget * 0.3) * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.tanh(1 / (1 + np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                # Change made here: adjusting velocity damping near the global best\n                if distance_to_best < 0.1:\n                    velocities[i] *= 0.9\n                \n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.95 + 0.05 * (global_best_score / max(personal_best_scores))\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Introduce velocity damping for particles near the global best to enhance convergence precision.", "configspace": "", "generation": 68, "fitness": 0.23207937379036056, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.232 with standard deviation 0.096. And the mean value of best solutions found was 1.458 (0. is the best) with standard deviation 2.044.", "error": "", "parent_id": "71d29170-30e3-4bda-8cb4-06481da5596b", "metadata": {"aucs": [0.09655712651524384, 0.29495196780474797, 0.30472902705108984], "final_y": [4.348552173723954, 0.011192569221570123, 0.013601396752507806]}, "mutation_prompt": null}
{"id": "789595cc-431f-4650-8714-ad4f4072d6a4", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = max(10, 20 - int(0.1 * budget))  # Dynamic number of particles\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            diversity = np.std(positions, axis=0).mean()\n            inertia_weight = 0.9 - 0.5 * (evaluations / self.budget)  # Adaptive inertia\n\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i])\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.tanh(1 / (1 + np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                # Adaptive perturbation based on diversity\n                perturb_scale = 0.1 * (1 + diversity)\n                perturbed_position = positions[i] + np.random.normal(0, perturb_scale, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.95 + 0.05 * (global_best_score / max(personal_best_scores))\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Incorporate adaptive inertia and diversity control to enhance convergence speed and solution quality in PSO-SA.", "configspace": "", "generation": 69, "fitness": 0.2839272346267693, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.284 with standard deviation 0.018. And the mean value of best solutions found was 0.044 (0. is the best) with standard deviation 0.026.", "error": "", "parent_id": "71d29170-30e3-4bda-8cb4-06481da5596b", "metadata": {"aucs": [0.26114180320857616, 0.2848614590376882, 0.30577844163404344], "final_y": [0.07461099440552657, 0.0438939737501804, 0.01213250367123187]}, "mutation_prompt": null}
{"id": "94bff6a5-a45c-459a-9f27-8628b45e9c9e", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = max(10, 20 - int(0.1 * budget))  # Dynamic number of particles\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i])\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = ((0.4 + (self.budget - evaluations) / self.budget * 0.3) * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.tanh(1 / (1 + np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbed_position = positions[i] + np.random.normal(0, 0.1 * (1 - evaluations/self.budget), self.dim)  # Change made here\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.95 + 0.05 * (global_best_score / max(personal_best_scores))\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Introduce adaptive perturbation step size based on progress to enhance exploration.", "configspace": "", "generation": 70, "fitness": 0.15290814988895773, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.153 with standard deviation 0.029. And the mean value of best solutions found was 1.393 (0. is the best) with standard deviation 0.958.", "error": "", "parent_id": "71d29170-30e3-4bda-8cb4-06481da5596b", "metadata": {"aucs": [0.1157649617430958, 0.18726719684789284, 0.15569229107588456], "final_y": [2.6895410686871073, 0.40660601783298295, 1.0814174576145215]}, "mutation_prompt": null}
{"id": "1fd29a1b-432a-4745-80ab-5fecdb9c741b", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = max(10, 20 - int(0.1 * budget))  # Dynamic number of particles\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i])\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                adaptive_c1 = self.c1 * (1 + (self.budget - evaluations) / self.budget)  # Adaptive learning coefficient\n                velocities[i] = ((0.4 + (self.budget - evaluations) / self.budget * 0.3) * velocities[i] +\n                                 adaptive_c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.tanh(1 / (1 + np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                perturbed_position = positions[i] + np.random.normal(0, 0.1, self.dim)\n                perturbed_position = np.clip(perturbed_position, lb, ub)\n                perturbed_score = func(perturbed_position)\n                evaluations += 1\n\n                if perturbed_score < score or np.random.rand() < np.exp((score - perturbed_score) / self.temperature):\n                    positions[i] = perturbed_position\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.95 + 0.05 * (global_best_score / max(personal_best_scores))\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Enhance velocity update by introducing adaptive learning coefficients based on global convergence status.", "configspace": "", "generation": 71, "fitness": 0.21966350712672342, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.220 with standard deviation 0.019. And the mean value of best solutions found was 0.257 (0. is the best) with standard deviation 0.130.", "error": "", "parent_id": "71d29170-30e3-4bda-8cb4-06481da5596b", "metadata": {"aucs": [0.24640942685918332, 0.20313564854161303, 0.20944544597937387], "final_y": [0.07362782630708425, 0.34854241529183166, 0.34823381458672126]}, "mutation_prompt": null}
{"id": "b0abda38-b2c6-491e-8995-acbbb43b5a4e", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = max(10, 20 - int(0.1 * budget))\n        self.inertia_weight = 0.6  # Adjusted inertia weight\n        self.c1 = 1.8  # Increased cognitive parameter\n        self.c2 = 1.4  # Reduced social parameter\n        self.temperature = 900  # Adjusted initial temperature\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i])\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = ((0.4 + (self.budget - evaluations) / self.budget * 0.3) * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.tanh(1 / (1 + np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                # Differential evolution inspired mutation\n                a, b, c = np.random.choice(self.num_particles, 3, replace=False)\n                mutant_vector = positions[a] + 0.5 * (positions[b] - positions[c])\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                # Adjusted acceptance criteria using DE mutant\n                if func(mutant_vector) < score:\n                    positions[i] = mutant_vector\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.95 + 0.05 * (global_best_score / max(personal_best_scores))\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Enhance particle selection by hybridizing differential evolution with PSO for better exploration and convergence.", "configspace": "", "generation": 72, "fitness": 0.3206836789195509, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.321 with standard deviation 0.115. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.210.", "error": "", "parent_id": "71d29170-30e3-4bda-8cb4-06481da5596b", "metadata": {"aucs": [0.47309015087167716, 0.2933133846367577, 0.1956475012502178], "final_y": [9.494484059692396e-07, 0.03596301272821908, 0.46297443839421487]}, "mutation_prompt": null}
{"id": "b81ce04d-68b2-4d0c-8a66-e287cef6423b", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = max(10, 20 - int(0.1 * budget))\n        self.inertia_weight = 0.9  # Adjusted initial inertia weight\n        self.c1 = 1.8\n        self.c2 = 1.4\n        self.temperature = 900\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            self.inertia_weight = 0.4 + 0.5 * (1 - evaluations / self.budget)  # Dynamic inertia weight\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i])\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +  # Use dynamic inertia weight\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.tanh(1 / (1 + np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                # Differential evolution inspired mutation with adaptive scaling\n                F = 0.8 * (1 - evaluations / self.budget)  # Adaptive scaling factor\n                a, b, c = np.random.choice(self.num_particles, 3, replace=False)\n                mutant_vector = positions[a] + F * (positions[b] - positions[c])\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                if func(mutant_vector) < score:\n                    positions[i] = mutant_vector\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.95 + 0.05 * (global_best_score / max(personal_best_scores))\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Introduce a dynamic adjustment of the inertia weight and enhance mutation with adaptive parameter scaling for improved convergence.", "configspace": "", "generation": 73, "fitness": 0.3620763923162942, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.362 with standard deviation 0.069. And the mean value of best solutions found was 0.010 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "b0abda38-b2c6-491e-8995-acbbb43b5a4e", "metadata": {"aucs": [0.4065146320741867, 0.2652211383959816, 0.41449340647871435], "final_y": [0.00013207948896632295, 0.030520307854811003, 2.5536438987527994e-05]}, "mutation_prompt": null}
{"id": "ef39ea27-50ff-4923-b8c5-be98e75cfe98", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = max(10, 20 - int(0.1 * budget))\n        self.inertia_weight = 0.9  # Adjusted initial inertia weight\n        self.c1 = 1.8\n        self.c2 = 1.4\n        self.temperature = 900\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            self.inertia_weight = 0.4 + 0.5 * (1 - evaluations / self.budget)  # Dynamic inertia weight\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i])\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +  # Use dynamic inertia weight\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], -0.5 * (ub - lb), 0.5 * (ub - lb))  # Adaptive velocity clamping\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                F = 0.8 * (1 - evaluations / self.budget)  # Adaptive scaling factor\n                a, b, c = np.random.choice(self.num_particles, 3, replace=False)\n                mutant_vector = positions[a] + F * (positions[b] - positions[c])\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                \n                # Competitive selection between current position and mutant\n                if func(mutant_vector) < func(positions[i]):\n                    positions[i] = mutant_vector\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.95 + 0.05 * (global_best_score / max(personal_best_scores))\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "An improved PSO with adaptive velocity clamping and a hybrid mutation strategy incorporating competitive selection for enhanced exploration.", "configspace": "", "generation": 74, "fitness": 0.2553682255939569, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.255 with standard deviation 0.025. And the mean value of best solutions found was 0.059 (0. is the best) with standard deviation 0.023.", "error": "", "parent_id": "b81ce04d-68b2-4d0c-8a66-e287cef6423b", "metadata": {"aucs": [0.23326939642340982, 0.28974883825493003, 0.2430864421035308], "final_y": [0.09167235331678135, 0.04531307107126183, 0.03954601016793526]}, "mutation_prompt": null}
{"id": "833e7ccf-cb5a-4208-a673-c573bab1011b", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = max(10, 20 - int(0.1 * budget))\n        self.inertia_weight = 0.9\n        self.c1 = 1.8\n        self.c2 = 1.4\n        self.temperature = 900\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            diversity = np.mean(np.std(positions, axis=0))  # Calculate swarm diversity\n            self.inertia_weight = 0.4 + 0.5 * (1 - evaluations / self.budget)\n            adaptive_learning_rate = 0.5 + 0.5 * (diversity / (ub - lb).mean())  # Adaptive learning rate\n            \n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i])\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] + \n                                 adaptive_learning_rate * self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 adaptive_learning_rate * self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.tanh(1 / (1 + np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                F = 0.8 * (1 - evaluations / self.budget)\n                a, b, c = np.random.choice(self.num_particles, 3, replace=False)\n                mutant_vector = positions[a] + F * (positions[b] - positions[c])\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                if func(mutant_vector) < score:\n                    positions[i] = mutant_vector\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.95 + 0.05 * (global_best_score / max(personal_best_scores))\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Introduce an adaptive learning rate based on swarm diversity to enhance exploration and balance convergence.", "configspace": "", "generation": 75, "fitness": 0.5264175402224976, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.526 with standard deviation 0.109. And the mean value of best solutions found was 0.001 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "b81ce04d-68b2-4d0c-8a66-e287cef6423b", "metadata": {"aucs": [0.3767027411736956, 0.5716346609921839, 0.6309152185016136], "final_y": [0.002907005254082318, 1.949963406793465e-06, 5.319665215942017e-11]}, "mutation_prompt": null}
{"id": "234ab0e7-60e6-4be6-a5da-73db00c5fed7", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = max(10, 20 - int(0.1 * budget))\n        self.inertia_weight = 0.9\n        self.c1 = 1.8\n        self.c2 = 1.4\n        self.temperature = 900\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            diversity = np.mean(np.std(positions, axis=0))  # Calculate swarm diversity\n            self.inertia_weight = 0.4 + 0.5 * (1 - evaluations / self.budget)\n            adaptive_learning_rate = 0.5 + 0.5 * (diversity / (ub - lb).mean())  # Adaptive learning rate\n            \n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i])\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] + \n                                 adaptive_learning_rate * self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 adaptive_learning_rate * self.c2 * r2 * (global_best_position - positions[i]))\n                velocity_scaling = np.tanh(1 / (1 + np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))))\n                velocities[i] *= velocity_scaling * 0.9  # Nonlinear scaling factor\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                F = 0.8 * (1 - evaluations / self.budget)\n                a, b, c = np.random.choice(self.num_particles, 3, replace=False)\n                mutant_vector = positions[a] + F * (positions[b] - positions[c])\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                if func(mutant_vector) < score:\n                    positions[i] = mutant_vector\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.95 + 0.05 * (global_best_score / max(personal_best_scores))\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Introduce a nonlinear velocity scaling factor and momentum adaptation to enhance convergence speed and solution robustness.", "configspace": "", "generation": 76, "fitness": 0.29262031516975323, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.293 with standard deviation 0.180. And the mean value of best solutions found was 1.519 (0. is the best) with standard deviation 2.068.", "error": "", "parent_id": "833e7ccf-cb5a-4208-a673-c573bab1011b", "metadata": {"aucs": [0.532074461185269, 0.09807501976499844, 0.2477114645589923], "final_y": [2.8601446225097364e-08, 4.443615536521097, 0.11455261506712988]}, "mutation_prompt": null}
{"id": "85f3fb23-0bac-4416-98e1-84dd6aa7b3a0", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = max(10, 20 - int(0.1 * budget))\n        self.inertia_weight = 0.9\n        self.c1 = 1.8\n        self.c2 = 1.4\n        self.temperature = 900\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            diversity = np.mean(np.std(positions, axis=0))  # Calculate swarm diversity\n            self.inertia_weight = 0.4 + 0.5 * (1 - evaluations / self.budget)\n            adaptive_learning_rate = 0.6 + 0.4 * (diversity / (ub - lb).mean())  # Refined adaptive learning rate\n            \n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i])\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] + \n                                 adaptive_learning_rate * self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 adaptive_learning_rate * self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.tanh(1 / (1 + np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                F = 0.8 * (1 - evaluations / self.budget)\n                a, b, c = np.random.choice(self.num_particles, 3, replace=False)\n                mutant_vector = positions[a] + F * (positions[b] - positions[c])\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                if func(mutant_vector) < score:\n                    positions[i] = mutant_vector\n                \n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            # Local search around the best solution\n            local_perturbation = np.random.uniform(-0.02, 0.02, self.dim)\n            candidate_position = np.clip(global_best_position + local_perturbation, lb, ub)\n            candidate_score = func(candidate_position)\n            evaluations += 1\n            \n            if candidate_score < global_best_score:\n                global_best_position = candidate_position\n                global_best_score = candidate_score\n\n            self.temperature *= 0.95 + 0.05 * (global_best_score / max(personal_best_scores))\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Enhance global convergence by incorporating local search around the best solution and refining adaptive learning rate.", "configspace": "", "generation": 77, "fitness": 0.3017097744273653, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.302 with standard deviation 0.145. And the mean value of best solutions found was 0.556 (0. is the best) with standard deviation 0.757.", "error": "", "parent_id": "833e7ccf-cb5a-4208-a673-c573bab1011b", "metadata": {"aucs": [0.4887278738396823, 0.13422201397523958, 0.28217943546717394], "final_y": [1.833463734500867e-05, 1.6266029698785704, 0.0421334359293008]}, "mutation_prompt": null}
{"id": "d9328d80-3c44-4c6c-ba15-7f8c3b6f4fed", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = max(10, 20 - int(0.1 * budget))\n        self.inertia_weight = 0.9\n        self.c1 = 1.8\n        self.c2 = 1.4\n        self.temperature = 900\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            diversity = np.mean(np.std(positions, axis=0))  # Calculate swarm diversity\n            self.inertia_weight = 0.4 + 0.5 * (1 - evaluations / self.budget) * (1 - 0.5 * np.tanh(diversity))  # Nonlinear inertia adaptation\n            adaptive_learning_rate = 0.5 + 0.5 * (diversity / (ub - lb).mean())  # Adaptive learning rate\n            \n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i])\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] + \n                                 adaptive_learning_rate * self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 adaptive_learning_rate * self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.tanh(1 / (1 + np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                F = 0.8 * (1 - evaluations / self.budget)\n                a, b, c = np.random.choice(self.num_particles, 3, replace=False)\n                mutant_vector = positions[a] + F * (positions[b] - positions[c])\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                if func(mutant_vector) < score:\n                    positions[i] = mutant_vector\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.95 + 0.05 * (global_best_score / max(personal_best_scores))\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Introduce a nonlinear inertia weight adaptation based on swarm diversity and temperature to enhance convergence stability.", "configspace": "", "generation": 78, "fitness": 0.4474751161931693, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.447 with standard deviation 0.173. And the mean value of best solutions found was 0.107 (0. is the best) with standard deviation 0.152.", "error": "", "parent_id": "833e7ccf-cb5a-4208-a673-c573bab1011b", "metadata": {"aucs": [0.545064686604691, 0.5926111376715588, 0.20474952430325832], "final_y": [1.0629359416737193e-08, 3.11044910011576e-09, 0.3220484493852263]}, "mutation_prompt": null}
{"id": "abc1dbec-9161-41e8-a60a-6bd65f29e93c", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = max(10, 20 - int(0.1 * budget))\n        self.inertia_weight = 0.9\n        self.c1 = 1.8\n        self.c2 = 1.4\n        self.temperature = 900\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            diversity = np.mean(np.std(positions, axis=0))  # Calculate swarm diversity\n            self.inertia_weight = 0.4 + 0.5 * (1 - evaluations / self.budget)\n            adaptive_learning_rate = 0.5 + 0.5 * (diversity / (ub - lb).mean())  # Adaptive learning rate\n            \n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i])\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] + \n                                 adaptive_learning_rate * self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 adaptive_learning_rate * self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.tanh(1 / (1 + np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                F = 0.8 * (1 - evaluations / self.budget)\n                a, b, c = np.random.choice(self.num_particles, 3, replace=False)\n                mutant_vector = positions[a] + F * (positions[b] - positions[c])\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n\n                crossover_prob = 0.5  # New line\n                trial_vector = np.where(np.random.rand(self.dim) < crossover_prob, mutant_vector, positions[i])  # New line\n\n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                if func(trial_vector) < score:  # Modified line\n                    positions[i] = trial_vector  # Modified line\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.95 + 0.05 * (global_best_score / max(personal_best_scores))\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Incorporate crossover operation to diversify search and improve convergence.", "configspace": "", "generation": 79, "fitness": 0.25057108612610973, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.251 with standard deviation 0.098. And the mean value of best solutions found was 0.869 (0. is the best) with standard deviation 1.191.", "error": "", "parent_id": "833e7ccf-cb5a-4208-a673-c573bab1011b", "metadata": {"aucs": [0.35721923079304296, 0.12125468934503436, 0.2732393382402518], "final_y": [0.004004318868591317, 2.5535204664385756, 0.049514835280689506]}, "mutation_prompt": null}
{"id": "c9d74373-c45d-474d-a196-253cfef3a5c6", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = max(10, 20 - int(0.1 * budget))\n        self.inertia_weight = 0.9\n        self.c1 = 1.8\n        self.c2 = 1.4\n        self.temperature = 900\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            diversity = np.mean(np.std(positions, axis=0))  # Calculate swarm diversity\n            self.inertia_weight = 0.4 + 0.5 * (1 - evaluations / self.budget)\n            adaptive_learning_rate = 0.5 + 0.5 * (diversity / (ub - lb).mean())  # Adaptive learning rate\n            \n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i])\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] + \n                                 adaptive_learning_rate * self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 adaptive_learning_rate * self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.tanh(1 / (1 + np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                F = 0.8 * (1 - evaluations / self.budget) * np.random.rand()  # Self-adaptive control parameter\n                a, b, c = np.random.choice(self.num_particles, 3, replace=False)\n                mutant_vector = positions[a] + F * (positions[b] - positions[c])\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                if func(mutant_vector) < score:\n                    positions[i] = mutant_vector\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.95 + 0.05 * (global_best_score / max(personal_best_scores))\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Enhance mutation strategy by introducing a self-adaptive control parameter for better exploration.", "configspace": "", "generation": 80, "fitness": 0.2565228408668743, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.257 with standard deviation 0.094. And the mean value of best solutions found was 0.487 (0. is the best) with standard deviation 0.554.", "error": "", "parent_id": "833e7ccf-cb5a-4208-a673-c573bab1011b", "metadata": {"aucs": [0.38070122315841903, 0.2364488552985875, 0.15241844414361638], "final_y": [0.003124600825886649, 0.19533232557141456, 1.2625376263705703]}, "mutation_prompt": null}
{"id": "dea0953e-b73f-46f0-a09a-b3f37a883ad5", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = max(10, 20 - int(0.1 * budget))\n        self.inertia_weight = 0.9\n        self.c1 = 1.8\n        self.c2 = 1.4\n        self.temperature = 900\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            diversity = np.mean(np.std(positions, axis=0))  \n            self.inertia_weight = 0.4 + 0.5 * (1 - evaluations / self.budget)\n            adaptive_learning_rate = 0.5 + 0.5 * (diversity / (ub - lb).mean()) \n            \n            for i in range(self.num_particles):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 adaptive_learning_rate * self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 adaptive_learning_rate * self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.tanh(1 / (1 + np.exp(-np.linalg.norm(global_best_position - positions[i]) / np.sum(np.linalg.norm(velocities, axis=1)))))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                # Hybrid local search\n                if evaluations % 10 == 0:\n                    gradient = np.gradient([func(positions[i] + 0.01 * v) for v in velocities[i]])\n                    positions[i] -= 0.01 * np.array(gradient)\n                    positions[i] = np.clip(positions[i], lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.95 + 0.05 * (global_best_score / max(personal_best_scores))\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Introduce a hybrid local search strategy leveraging gradient descent for improved convergence speed and precision.", "configspace": "", "generation": 81, "fitness": 0.2255909274078578, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.226 with standard deviation 0.132. And the mean value of best solutions found was 1.437 (0. is the best) with standard deviation 1.171.", "error": "", "parent_id": "833e7ccf-cb5a-4208-a673-c573bab1011b", "metadata": {"aucs": [0.41194072176936447, 0.14690955741136447, 0.11792250304284446], "final_y": [0.0014354184764321896, 1.4383447822700666, 2.87017044621456]}, "mutation_prompt": null}
{"id": "d3ac2f6c-a889-4b6e-be34-2202c27f80e4", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = max(10, 20 - int(0.1 * budget))\n        self.inertia_weight = 0.9\n        self.c1 = 1.8\n        self.c2 = 1.4\n        self.temperature = 900\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            diversity = np.mean(np.std(positions, axis=0))  # Calculate swarm diversity\n            self.inertia_weight = 0.4 + 0.5 * (1 - evaluations / self.budget)\n            adaptive_learning_rate = 0.5 + 0.5 * (diversity / (ub - lb).mean())  # Adaptive learning rate\n\n            improvement_factor = 0.5 + 0.5 * (1 - global_best_score / max(personal_best_scores))  # New line\n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i])\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] + \n                                 improvement_factor * adaptive_learning_rate * self.c1 * r1 * (personal_best_positions[i] - positions[i]) +  # Modified line\n                                 adaptive_learning_rate * self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.tanh(1 / (1 + np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                F = 0.8 * (1 - evaluations / self.budget)\n                a, b, c = np.random.choice(self.num_particles, 3, replace=False)\n                mutant_vector = positions[a] + F * (positions[b] - positions[c])\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                if func(mutant_vector) < score:\n                    positions[i] = mutant_vector\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.95 + 0.05 * (global_best_score / max(personal_best_scores))\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Enhance exploration with dynamic particle acceleration factors based on global performance improvement.", "configspace": "", "generation": 82, "fitness": 0.4744440767773961, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.474 with standard deviation 0.133. And the mean value of best solutions found was 0.008 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "833e7ccf-cb5a-4208-a673-c573bab1011b", "metadata": {"aucs": [0.549924574064692, 0.5853932770478503, 0.2880143792196459], "final_y": [3.175567211982414e-08, 1.342764395857706e-10, 0.023347660217099376]}, "mutation_prompt": null}
{"id": "4f20f9fc-49a0-416c-bf76-178df8d85922", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = max(10, 20 - int(0.1 * budget))\n        self.inertia_weight = 0.9\n        self.c1 = 1.8\n        self.c2 = 1.4\n        self.temperature = 900\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            diversity = np.mean(np.std(positions, axis=0))  \n            self.inertia_weight = 0.4 + 0.5 * (1 - evaluations / self.budget)\n            adaptive_learning_rate = 0.5 + 0.5 * (diversity / (ub - lb).mean())  \n            \n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i])\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] + \n                                 adaptive_learning_rate * self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 adaptive_learning_rate * self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.tanh(1 / (1 + np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                F = 0.8 * (1 - evaluations / self.budget)\n                a, b, c = np.random.choice(self.num_particles, 3, replace=False)\n                mutant_vector = positions[a] + F * (positions[b] - positions[c])\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                if func(mutant_vector) < score:\n                    positions[i] = mutant_vector\n                    \n                levy_step = np.random.normal(0, 1, self.dim) * (global_best_position - positions[i]) * evaluations / self.budget\n                positions[i] += levy_step\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.95 + 0.05 * (global_best_score / max(personal_best_scores))\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Integrate a self-adaptive mutation rate and enhance swarm exploration by leveraging the Levy flight strategy.", "configspace": "", "generation": 83, "fitness": 0.31216480159486454, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.312 with standard deviation 0.168. And the mean value of best solutions found was 0.906 (0. is the best) with standard deviation 1.266.", "error": "", "parent_id": "833e7ccf-cb5a-4208-a673-c573bab1011b", "metadata": {"aucs": [0.5285344096719777, 0.11876034341150599, 0.28919965170110995], "final_y": [2.9909672295297426e-08, 2.6958792084519385, 0.0217695751984514]}, "mutation_prompt": null}
{"id": "7de49778-130a-4607-b7cc-40d2ecdd4967", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = max(10, 20 - int(0.1 * budget))\n        self.inertia_weight = 0.9\n        self.c1 = 1.8\n        self.c2 = 1.4\n        self.temperature = 900\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            diversity = np.mean(np.std(positions, axis=0))  # Calculate swarm diversity\n            self.inertia_weight = 0.4 + 0.5 * (1 - evaluations / self.budget)\n            adaptive_learning_rate = 0.5 + 0.5 * (diversity / (ub - lb).mean())  # Adaptive learning rate\n            \n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i])\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] + \n                                 adaptive_learning_rate * self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 adaptive_learning_rate * self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.tanh(1 / (1 + np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1))))) * (1 + 0.1 * (global_best_score / np.max(personal_best_scores)))  # Adjust velocity update\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                F = 0.8 * (1 - evaluations / self.budget)\n                a, b, c = np.random.choice(self.num_particles, 3, replace=False)\n                mutant_vector = positions[a] + F * (positions[b] - positions[c])\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                if func(mutant_vector) < score:\n                    positions[i] = mutant_vector\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.95 + 0.05 * (global_best_score / max(personal_best_scores))\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Introduce a dynamic adjustment to the velocity update rule based on the best-performing particle's influence to slightly enhance convergence.", "configspace": "", "generation": 84, "fitness": 0.46739516122420827, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.467 with standard deviation 0.072. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "833e7ccf-cb5a-4208-a673-c573bab1011b", "metadata": {"aucs": [0.43721266155311844, 0.5669927567187016, 0.39798006540080477], "final_y": [8.811160982161309e-05, 1.322456579689799e-07, 0.0007159341662479575]}, "mutation_prompt": null}
{"id": "be10b33f-f799-40cf-9bbe-a11267115fe3", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = max(10, 20 - int(0.1 * budget))\n        self.inertia_weight = 0.9\n        self.c1 = 1.8\n        self.c2 = 1.4\n        self.temperature = 900\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            diversity = np.mean(np.std(positions, axis=0))\n            self.inertia_weight = 0.4 + 0.5 * (1 - evaluations / self.budget)\n            adaptive_learning_rate = 0.5 + 0.5 * (diversity / (ub - lb).mean())\n            \n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i])\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] + \n                                 adaptive_learning_rate * self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 adaptive_learning_rate * self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.tanh(1 / (1 + np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))))\n                velocities[i] *= 0.9 + 0.1 * (1 - global_best_score / max(personal_best_scores))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                F = 0.8 * (1 - evaluations / self.budget)\n                a, b, c = np.random.choice(self.num_particles, 3, replace=False)\n                mutant_vector = positions[a] + F * (positions[b] - positions[c])\n                mutant_vector += np.random.normal(0, 0.1, self.dim) ** 2\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                if func(mutant_vector) < score:\n                    positions[i] = mutant_vector\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.95 + 0.05 * (global_best_score / max(personal_best_scores))\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Enhance exploration and convergence by introducing quadratic mutation and adaptive velocity damping based on global best improvements.", "configspace": "", "generation": 85, "fitness": 0.2388139446748424, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.239 with standard deviation 0.118. And the mean value of best solutions found was 0.872 (0. is the best) with standard deviation 0.880.", "error": "", "parent_id": "833e7ccf-cb5a-4208-a673-c573bab1011b", "metadata": {"aucs": [0.4019037053664566, 0.1286975643652164, 0.18584056429285423], "final_y": [0.00018560611630755167, 2.077682267058855, 0.5373879699647103]}, "mutation_prompt": null}
{"id": "7902d520-8744-4e87-b5ca-374472a643a6", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = max(10, 20 - int(0.1 * budget))\n        self.inertia_weight = 0.9\n        self.c1 = 1.8\n        self.c2 = 1.4\n        self.temperature = 900\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            diversity = np.mean(np.std(positions, axis=0))  # Calculate swarm diversity\n            self.inertia_weight = 0.4 + 0.5 * (1 - evaluations / self.budget)\n            adaptive_learning_rate = (0.5 + 0.5 * (diversity / (ub - lb).mean())) * (1 - global_best_score)  # Adjusted adaptive learning rate\n            \n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i])\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] + \n                                 adaptive_learning_rate * self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 adaptive_learning_rate * self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.tanh(1 / (1 + np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                F = 0.8 * (1 - evaluations / self.budget)\n                a, b, c = np.random.choice(self.num_particles, 3, replace=False)\n                mutant_vector = positions[a] + F * (positions[b] - positions[c])\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                if func(mutant_vector) < score:\n                    positions[i] = mutant_vector\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.95 + 0.05 * (global_best_score / max(personal_best_scores))\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Adjust adaptive learning rate calculation to improve convergence by considering both diversity and current global best score.", "configspace": "", "generation": 86, "fitness": 0.3119898588681565, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.312 with standard deviation 0.140. And the mean value of best solutions found was 1.037 (0. is the best) with standard deviation 1.466.", "error": "", "parent_id": "833e7ccf-cb5a-4208-a673-c573bab1011b", "metadata": {"aucs": [0.4022088546983562, 0.11364271947038629, 0.42011800243572694], "final_y": [3.6367454433442176e-05, 3.1105821944044485, 0.0001595237317012542]}, "mutation_prompt": null}
{"id": "341c5c72-8726-4567-8075-4c6a0005ba6c", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = max(10, 20 - int(0.1 * budget))\n        self.inertia_weight = 0.9\n        self.c1 = 1.8\n        self.c2 = 1.4\n        self.temperature = 900\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            diversity = np.mean(np.std(positions, axis=0))  \n            self.inertia_weight = 0.4 + 0.5 * (1 - evaluations / self.budget)\n            adaptive_learning_rate = 0.5 + 0.5 * (diversity / (ub - lb).mean()) \n            \n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i])\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] + \n                                 adaptive_learning_rate * self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 adaptive_learning_rate * self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.tanh(1 / (1 + np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                F = 0.8 * (1 - evaluations / self.budget)\n                a, b, c = np.random.choice(self.num_particles, 3, replace=False)\n                mutant_vector = positions[a] + F * (positions[b] - positions[c])\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                if np.random.rand() < 0.3 and func(mutant_vector) < score:\n                    positions[i] = mutant_vector\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.9 + 0.1 * (global_best_score / max(personal_best_scores))\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Incorporate a dynamic cooling schedule and mutation strategy to enhance global search capability and convergence rate.", "configspace": "", "generation": 87, "fitness": 0.2319723360181067, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.232 with standard deviation 0.128. And the mean value of best solutions found was 1.645 (0. is the best) with standard deviation 2.000.", "error": "", "parent_id": "833e7ccf-cb5a-4208-a673-c573bab1011b", "metadata": {"aucs": [0.40457486500803774, 0.09870960108678284, 0.19263254195949953], "final_y": [0.0009933180832761962, 4.460583522772942, 0.4740675107137493]}, "mutation_prompt": null}
{"id": "c2cc3a4b-cc93-47c8-b955-43870730b9e5", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = max(10, 20 - int(0.1 * budget))\n        self.inertia_weight = 0.9\n        self.c1 = 1.8\n        self.c2 = 1.4\n        self.temperature = 900\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            diversity = np.mean(np.std(positions, axis=0))  # Calculate swarm diversity\n            self.inertia_weight = 0.4 + 0.5 * (1 - evaluations / self.budget)\n            adaptive_learning_rate = 0.5 + 0.5 * (diversity / (ub - lb).mean())  # Adaptive learning rate\n            \n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i])\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocity_scaling = 1 - 0.5 * (diversity / (ub - lb).mean())  # New scaling factor based on diversity\n                velocities[i] = (self.inertia_weight * velocities[i] + \n                                 adaptive_learning_rate * self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 adaptive_learning_rate * self.c2 * r2 * (global_best_position - positions[i])) * velocity_scaling\n                velocities[i] *= np.tanh(1 / (1 + np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                F = 0.8 * (1 - evaluations / self.budget)\n                a, b, c = np.random.choice(self.num_particles, 3, replace=False)\n                mutant_vector = positions[a] + F * (positions[b] - positions[c])\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                if func(mutant_vector) < score:\n                    positions[i] = mutant_vector\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.95 + 0.05 * (global_best_score / max(personal_best_scores))\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Introduce a diversity-based damping factor to scale velocities and enhance convergence stability.", "configspace": "", "generation": 88, "fitness": 0.43236720741774465, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.432 with standard deviation 0.172. And the mean value of best solutions found was 0.159 (0. is the best) with standard deviation 0.225.", "error": "", "parent_id": "833e7ccf-cb5a-4208-a673-c573bab1011b", "metadata": {"aucs": [0.1889092772937171, 0.5673900083526868, 0.54080233660683], "final_y": [0.4763038339242649, 5.721490400322548e-07, 9.28701850215822e-09]}, "mutation_prompt": null}
{"id": "485f0a1b-1777-4542-a5ec-e1edb33829c1", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = max(10, 20 - int(0.1 * budget))\n        self.inertia_weight = 0.9\n        self.c1 = 2.0  # Adjusted learning factor\n        self.c2 = 1.6  # Adjusted learning factor\n        self.temperature = 1000  # Increased initial temperature\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            diversity = np.mean(np.std(positions, axis=0))\n            self.inertia_weight = 0.4 + 0.5 * (1 - evaluations / self.budget)\n            adaptive_learning_rate = 0.5 + 0.5 * (diversity / (ub - lb).mean())\n            \n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i])\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] + \n                                 adaptive_learning_rate * self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 adaptive_learning_rate * self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.tanh(1 / (1 + np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                F = 0.8 * (1 - evaluations / self.budget)\n                a, b, c = np.random.choice(self.num_particles, 3, replace=False)\n                mutant_vector = positions[a] + F * (positions[b] - positions[c])\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                if func(mutant_vector) < score:\n                    positions[i] = mutant_vector\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.90 + 0.10 * (global_best_score / max(personal_best_scores))  # Dynamic temperature scaling\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Refine swarm dynamics and integrate dynamic temperature scaling for improved solution quality and convergence rate.", "configspace": "", "generation": 89, "fitness": 0.412498343563447, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.412 with standard deviation 0.100. And the mean value of best solutions found was 0.015 (0. is the best) with standard deviation 0.021.", "error": "", "parent_id": "833e7ccf-cb5a-4208-a673-c573bab1011b", "metadata": {"aucs": [0.47398232212167524, 0.49139520827206307, 0.27211750029660253], "final_y": [6.458054515209814e-08, 2.519836676914106e-06, 0.04540641208358872]}, "mutation_prompt": null}
{"id": "70f6f4ee-3d02-4cb2-b913-31b66bfc8913", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = max(10, 20 - int(0.1 * budget))\n        self.inertia_weight = 0.9\n        self.c1 = 1.8\n        self.c2 = 1.4\n        self.temperature = 900\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            diversity = np.mean(np.std(positions, axis=0))  # Calculate swarm diversity\n            self.inertia_weight = 0.4 + 0.5 * (1 - evaluations / self.budget)\n            adaptive_learning_rate = 0.5 + 0.5 * (diversity / (ub - lb).mean())  # Adaptive learning rate\n            \n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i])\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] + \n                                 adaptive_learning_rate * self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 adaptive_learning_rate * self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.tanh(1 / (1 + np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                F = 0.8 * (1 - evaluations / self.budget)\n                a, b, c = np.random.choice(self.num_particles, 3, replace=False)\n                mutant_vector = positions[a] + F * (positions[b] - positions[c])\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                \n                local_search = positions[i] + np.random.uniform(-0.1, 0.1, self.dim)  # Added\n                local_search = np.clip(local_search, lb, ub)  # Added\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                if func(mutant_vector) < score or func(local_search) < score:  # Modified\n                    positions[i] = mutant_vector if func(mutant_vector) < func(local_search) else local_search  # Modified\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.95 + 0.05 * (global_best_score / max(personal_best_scores))\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Integrate a localized search strategy and improved adaptive behaviors to enhance the convergence speed and accuracy of the PSO_SA_Optimizer.", "configspace": "", "generation": 90, "fitness": 0.2935489101548621, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.294 with standard deviation 0.038. And the mean value of best solutions found was 0.007 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "833e7ccf-cb5a-4208-a673-c573bab1011b", "metadata": {"aucs": [0.31480480940273303, 0.23984401139111944, 0.32599790967073394], "final_y": [0.004288696557544046, 0.01599298160049706, 0.0003052457527987169]}, "mutation_prompt": null}
{"id": "33635540-551d-4303-9748-b6fc48d694dd", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = max(10, 20 - int(0.1 * budget))\n        self.inertia_weight = 0.9\n        self.c1 = 1.8\n        self.c2 = 1.4\n        self.temperature = 900\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            diversity = np.mean(np.std(positions, axis=0))  # Calculate swarm diversity\n            self.inertia_weight = 0.4 + 0.5 * (1 - evaluations / self.budget)\n            adaptive_learning_rate = 0.5 + 0.5 * (diversity / (ub - lb).mean())  # Adaptive learning rate\n            \n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i])\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] + \n                                 adaptive_learning_rate * self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 adaptive_learning_rate * self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.tanh(1 / (1 + np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                F = 0.8 * (1 - evaluations / self.budget)\n                a, b, c = np.random.choice(self.num_particles, 3, replace=False)\n                mutant_vector = positions[a] + F * (positions[b] - positions[c])\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                if func(mutant_vector) < score:\n                    positions[i] = mutant_vector\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= (0.95 + 0.05 * np.random.rand())  # Randomized cooling schedule\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Introduce a randomized cooling schedule in simulated annealing to improve escape from local optima.", "configspace": "", "generation": 91, "fitness": 0.28064698514421277, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.281 with standard deviation 0.163. And the mean value of best solutions found was 0.580 (0. is the best) with standard deviation 0.475.", "error": "", "parent_id": "833e7ccf-cb5a-4208-a673-c573bab1011b", "metadata": {"aucs": [0.1804603371956779, 0.15150545097891288, 0.5099751672580475], "final_y": [0.5784689093729601, 1.1624336120175276, 2.945976345161336e-07]}, "mutation_prompt": null}
{"id": "73235ee6-f6c7-482b-a63a-ec1966ae8cc3", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = max(10, 20 - int(0.1 * budget))\n        self.inertia_weight = 0.8  # Adjusted inertia weight for better balance\n        self.c1 = 1.5  # Adjusted cognitive coefficient\n        self.c2 = 1.7  # Adjusted social coefficient\n        self.temperature = 900\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            diversity = np.mean(np.std(positions, axis=0)) \n            self.inertia_weight = 0.5 + 0.4 * (1 - evaluations / self.budget)\n            adaptive_learning_rate = 0.6 + 0.4 * (diversity / (ub - lb).mean())\n            \n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i])\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] + \n                                 adaptive_learning_rate * self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 adaptive_learning_rate * self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.tanh(1 / (1 + np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                F = 0.9 * (1 - evaluations / self.budget)  # Adjusted mutation factor\n                a, b, c = np.random.choice(self.num_particles, 3, replace=False)\n                mutant_vector = positions[a] + F * (positions[b] - positions[c])\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                if func(mutant_vector) < score:\n                    positions[i] = mutant_vector\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n            \n            # Introduced elite perturbation mechanism\n            for j in range(min(3, self.num_particles)):\n                if np.random.rand() < 0.1:  # Probability of perturbation\n                    perturbation = np.random.normal(0, (ub - lb) * 0.05, self.dim)\n                    elite_position = global_best_position + perturbation\n                    elite_position = np.clip(elite_position, lb, ub)\n                    elite_score = func(elite_position)\n                    evaluations += 1\n                    if elite_score < global_best_score:\n                        global_best_position = elite_position\n                        global_best_score = elite_score\n\n            self.temperature *= 0.95 + 0.05 * (global_best_score / max(personal_best_scores))\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Refine PSO with adaptive perturbation and elite selection to enhance convergence and solution quality.", "configspace": "", "generation": 92, "fitness": 0.5101587025370361, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.510 with standard deviation 0.101. And the mean value of best solutions found was 0.000 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "833e7ccf-cb5a-4208-a673-c573bab1011b", "metadata": {"aucs": [0.6192302109752654, 0.5357258335184825, 0.3755200631173602], "final_y": [2.5526274623625537e-10, 4.9929526340693445e-09, 0.0010934819085792948]}, "mutation_prompt": null}
{"id": "95854ca7-aa3f-430a-8b82-49fd3e400ecf", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = max(10, 20 - int(0.1 * budget))\n        self.inertia_weight = 0.9\n        self.c1 = 1.8\n        self.c2 = 1.4\n        self.temperature = 900\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            diversity = np.mean(np.std(positions, axis=0))  # Calculate swarm diversity\n            self.inertia_weight = 0.4 + 0.5 * (1 - evaluations / self.budget)\n            adaptive_learning_rate = 0.5 + 0.5 * (diversity / (ub - lb).mean())  # Adaptive learning rate\n            \n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i])\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] + \n                                 adaptive_learning_rate * self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 adaptive_learning_rate * self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.tanh(1 / (1 + np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                F = 0.8 * (1 - evaluations / self.budget) * (self.temperature / (self.temperature + evaluations))  # Apply cooling schedule\n                a, b, c = np.random.choice(self.num_particles, 3, replace=False)\n                mutant_vector = positions[a] + F * (positions[b] - positions[c])\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                if func(mutant_vector) < score:\n                    positions[i] = mutant_vector\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.95 + 0.05 * (global_best_score / max(personal_best_scores))\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Introduce a cooling schedule to improve the efficiency of the mutation strategy by adjusting the mutation factor over time.", "configspace": "", "generation": 93, "fitness": 0.32470831719545107, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.325 with standard deviation 0.123. And the mean value of best solutions found was 0.370 (0. is the best) with standard deviation 0.522.", "error": "", "parent_id": "833e7ccf-cb5a-4208-a673-c573bab1011b", "metadata": {"aucs": [0.37395094114566263, 0.4443582389883749, 0.15581577145231562], "final_y": [0.002376849597948665, 0.00016247362909002462, 1.1089141058220335]}, "mutation_prompt": null}
{"id": "994c0414-f03c-40f3-916b-f8742bbb3a71", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = max(10, 20 - int(0.1 * budget))\n        self.inertia_weight = 0.9\n        self.c1 = 1.8\n        self.c2 = 1.4\n        self.temperature = 900\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            diversity = np.mean(np.std(positions, axis=0))  \n            self.inertia_weight = 0.4 + 0.5 * (1 - evaluations / self.budget)\n            adaptive_learning_rate = 0.5 + 0.5 * (diversity / (ub - lb).mean())  \n            \n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i])\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] + \n                                 adaptive_learning_rate * self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 adaptive_learning_rate * self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.tanh(1 / (1 + np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                F = 0.8 * (1 - evaluations / self.budget)\n                a, b, c = np.random.choice(self.num_particles, 3, replace=False)\n                mutant_vector = positions[a] + F * (positions[b] - positions[c])\n                hybrid_vector = 0.5 * (positions[i] + mutant_vector)\n                hybrid_vector = np.clip(hybrid_vector, lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                if func(hybrid_vector) < score:\n                    positions[i] = hybrid_vector\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.9 + 0.1 * (global_best_score / (max(personal_best_scores) + 1e-9))\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Introduce a hybrid mutation strategy and dynamic temperature adaptation to enhance exploration and exploitative balance in PSO.", "configspace": "", "generation": 94, "fitness": 0.2863474087272364, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.286 with standard deviation 0.186. And the mean value of best solutions found was 0.932 (0. is the best) with standard deviation 0.898.", "error": "", "parent_id": "833e7ccf-cb5a-4208-a673-c573bab1011b", "metadata": {"aucs": [0.5482137699664524, 0.13015579415644696, 0.18067266205880983], "final_y": [7.304915924204654e-07, 2.145340750877923, 0.6514870781002728]}, "mutation_prompt": null}
{"id": "f6da33a4-464d-494e-9914-ea22fc20b8f0", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = max(10, 20 - int(0.1 * budget))\n        self.inertia_weight = 0.9\n        self.c1 = 1.8\n        self.c2 = 1.4\n        self.temperature = 900\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            diversity = np.mean(np.std(positions, axis=0))  \n            self.inertia_weight = 0.4 + 0.5 * (1 - evaluations / self.budget)\n            adaptive_learning_rate = 0.5 + 0.5 * (diversity / (ub - lb).mean())\n            \n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i])\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] + \n                                 adaptive_learning_rate * self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 adaptive_learning_rate * self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.tanh(1 / (1 + np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                # Modified mutation strategy\n                F = 0.9 * (1 - evaluations / self.budget)\n                a, b, c = np.random.choice(self.num_particles, 3, replace=False)\n                mutant_vector = positions[a] + F * (positions[b] - positions[c])\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                if func(mutant_vector) < score:\n                    positions[i] = mutant_vector\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.95 + 0.05 * (global_best_score / max(personal_best_scores))\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Enhance global search by introducing novel crossover and mutation strategies to improve exploration capability.", "configspace": "", "generation": 95, "fitness": 0.3832909491988859, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.383 with standard deviation 0.152. And the mean value of best solutions found was 0.231 (0. is the best) with standard deviation 0.327.", "error": "", "parent_id": "833e7ccf-cb5a-4208-a673-c573bab1011b", "metadata": {"aucs": [0.4691831018233986, 0.17012059762277432, 0.5105691481504848], "final_y": [1.2089555011987273e-06, 0.6933741130946155, 3.975400556088173e-08]}, "mutation_prompt": null}
{"id": "b5880e50-8159-4df3-8ab7-00ccca5a3e27", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = max(10, 20 - int(0.1 * budget))\n        self.inertia_weight = 0.9\n        self.c1 = 1.8\n        self.c2 = 1.4\n        self.temperature = 900\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            diversity = np.mean(np.std(positions, axis=0))  \n            self.inertia_weight = 0.4 + 0.5 * (1 - evaluations / self.budget)\n            adaptive_learning_rate = 0.5 + 0.5 * (diversity / (ub - lb).mean())  \n            \n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i])\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] + \n                                 adaptive_learning_rate * self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 adaptive_learning_rate * self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.tanh(1 / (1 + np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                F = 0.8 * (1 - evaluations / self.budget) + 0.1 * (global_best_score / max(personal_best_scores))\n                a, b, c = np.random.choice(self.num_particles, 3, replace=False)\n                mutant_vector = positions[a] + F * (positions[b] - positions[c])\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                if func(mutant_vector) < score:\n                    positions[i] = mutant_vector\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.95 + 0.05 * (global_best_score / max(personal_best_scores))\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Enhance exploration by integrating differential evolution into PSO and introduce a feedback mechanism for dynamic parameter tuning.  ", "configspace": "", "generation": 96, "fitness": 0.36244258122650236, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.362 with standard deviation 0.171. And the mean value of best solutions found was 0.650 (0. is the best) with standard deviation 0.919.", "error": "", "parent_id": "833e7ccf-cb5a-4208-a673-c573bab1011b", "metadata": {"aucs": [0.5335515820261665, 0.12848375311442728, 0.42529240853891326], "final_y": [7.575118448130509e-08, 1.9499572544342345, 9.073492453796442e-07]}, "mutation_prompt": null}
{"id": "3a469393-1636-4b4f-866e-9c9837e75967", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = max(10, 20 - int(0.1 * budget))\n        self.inertia_weight = 0.9\n        self.c1 = 1.8\n        self.c2 = 1.4\n        self.temperature = 900\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            diversity = np.mean(np.std(positions, axis=0)) \n            self.inertia_weight = 0.4 + 0.5 * (1 - evaluations / self.budget)\n            adaptive_learning_rate = 0.5 + 0.5 * (diversity / (ub - lb).mean())\n            \n            fitness_variance = np.var(personal_best_scores)\n            adaptive_mutation_factor = 1 + np.log1p(fitness_variance)  # Dynamic mutation factor\n            \n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i])\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] + \n                                 adaptive_learning_rate * self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 adaptive_learning_rate * self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.tanh(1 / (1 + np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                F = 0.8 * (1 - evaluations / self.budget) * adaptive_mutation_factor  # Apply adaptive mutation factor\n                a, b, c = np.random.choice(self.num_particles, 3, replace=False)\n                mutant_vector = positions[a] + F * (positions[b] - positions[c])\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                if func(mutant_vector) < score:\n                    positions[i] = mutant_vector\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.95 + 0.05 * (global_best_score / max(personal_best_scores))\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Enhance PSO_SA_Optimizer by introducing a dynamic mutation strategy based on fitness variance to increase diversity and escape local optima.", "configspace": "", "generation": 97, "fitness": 0.21769682824946926, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.218 with standard deviation 0.098. And the mean value of best solutions found was 1.378 (0. is the best) with standard deviation 1.727.", "error": "", "parent_id": "833e7ccf-cb5a-4208-a673-c573bab1011b", "metadata": {"aucs": [0.3423735953554359, 0.10427132819644047, 0.20644556119653146], "final_y": [0.007115087645310777, 3.814362821405061, 0.3126944618438893]}, "mutation_prompt": null}
{"id": "5d9eac20-5803-47f7-89e9-01037be7857a", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = max(10, 20 - int(0.1 * budget))\n        self.inertia_weight = 0.9\n        self.c1 = 1.8\n        self.c2 = 1.4\n        self.temperature = 900\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            diversity = np.mean(np.std(positions, axis=0))  # Calculate swarm diversity\n            self.inertia_weight = 0.4 + 0.5 * (1 - evaluations / self.budget)\n            adaptive_learning_rate = 0.5 + 0.5 * (diversity / (ub - lb).mean())  # Adaptive learning rate\n            \n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i])\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] + \n                                 adaptive_learning_rate * self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 adaptive_learning_rate * self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.tanh(1 / (1 + np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))))\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                F = 0.8 * (1 - evaluations / self.budget)\n                a, b, c = np.random.choice(self.num_particles, 3, replace=False)\n                mutant_vector = positions[a] + F * (positions[b] - positions[c])\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n\n                gaussian_perturbation = positions[i] + np.random.normal(0, 0.05, self.dim)\n                gaussian_perturbation = np.clip(gaussian_perturbation, lb, ub)\n                if func(gaussian_perturbation) < score:\n                    positions[i] = gaussian_perturbation\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.95 + 0.05 * (global_best_score / max(personal_best_scores))\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Introduce a local search strategy using Gaussian perturbation on best solutions to refine exploration and exploitation balance.", "configspace": "", "generation": 98, "fitness": 0.2719967200530508, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.272 with standard deviation 0.157. And the mean value of best solutions found was 1.354 (0. is the best) with standard deviation 1.790.", "error": "", "parent_id": "833e7ccf-cb5a-4208-a673-c573bab1011b", "metadata": {"aucs": [0.48219036050979236, 0.10364129138287492, 0.2301585082664851], "final_y": [1.772251701136336e-05, 3.8829779163516176, 0.17873756226392462]}, "mutation_prompt": null}
{"id": "5e678712-0747-45e4-9074-5f77d99c40f3", "solution": "import numpy as np\n\nclass PSO_SA_Optimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = max(10, 20 - int(0.1 * budget))\n        self.inertia_weight = 0.9\n        self.c1 = 1.8\n        self.c2 = 1.4\n        self.temperature = 900\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        \n        positions = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        \n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(p) for p in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n        \n        evaluations = self.num_particles\n        \n        while evaluations < self.budget:\n            diversity = np.mean(np.std(positions, axis=0))  # Calculate swarm diversity\n            self.inertia_weight = 0.4 + 0.5 * (1 - evaluations / self.budget)\n            adaptive_learning_rate = 0.5 + 0.5 * (diversity / (ub - lb).mean())  # Adaptive learning rate\n            \n            for i in range(self.num_particles):\n                distance_to_best = np.linalg.norm(global_best_position - positions[i])\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] + \n                                 adaptive_learning_rate * self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 adaptive_learning_rate * self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= np.tanh(1 / (1 + np.exp(-distance_to_best / np.sum(np.linalg.norm(velocities, axis=1)))))\n                positions[i] += velocities[i] + np.random.uniform(-0.1, 0.1, self.dim)  # Add random perturbation\n                positions[i] = np.clip(positions[i], lb, ub)\n                \n                F = 0.8 * (1 - evaluations / self.budget)\n                a, b, c = np.random.choice(self.num_particles, 3, replace=False)\n                mutant_vector = positions[a] + F * (positions[b] - positions[c])\n                mutant_vector = np.clip(mutant_vector, lb, ub)\n                \n                score = func(positions[i])\n                evaluations += 1\n                \n                if score < personal_best_scores[i]:\n                    personal_best_positions[i] = positions[i]\n                    personal_best_scores[i] = score\n                \n                if func(mutant_vector) < score:\n                    positions[i] = mutant_vector\n\n                if personal_best_scores[i] < global_best_score:\n                    global_best_position = personal_best_positions[i]\n                    global_best_score = personal_best_scores[i]\n\n            self.temperature *= 0.95 + 0.05 * (global_best_score / max(personal_best_scores))\n\n        return global_best_position, global_best_score", "name": "PSO_SA_Optimizer", "description": "Integrate random perturbation to enhance the global exploration capability of particles.", "configspace": "", "generation": 99, "fitness": 0.26224554620355217, "feedback": "The algorithm PSO_SA_Optimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.262 with standard deviation 0.006. And the mean value of best solutions found was 0.043 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "833e7ccf-cb5a-4208-a673-c573bab1011b", "metadata": {"aucs": [0.2674614534625147, 0.25426124615475276, 0.2650139389933891], "final_y": [0.037126038927162465, 0.04531416928375034, 0.045688885620356126]}, "mutation_prompt": null}
